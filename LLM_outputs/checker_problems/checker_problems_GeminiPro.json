[
  {
    "entry_id": 0,
    "retraction_id": "2303.17613v10",
    "paper_id": "2303.17613v9",
    "retraction_comment": "The theoretical structure, in particular the existence of the Riemannian metric, was flawed and will be resubmitted after reconsideration",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect update rule for `t_l` in gradient descent.",
        "Location": "Eq. (22), Section 3.3, Page 8",
        "Explanation": "The update rule for the scalar parameter `t_l` is given as `t_l_new = t_l - ev * Term_l`, where `Term_l` is `(d_exp|t_l v)^T P (d_2prod|m,exp(t_l v))^T (-2)p_l log (p_l^{-1}x_l)`. The presence of the projection matrix `P=C^+C` (which projects onto a subspace of the tangent space `T_eG`) in the calculation of the gradient with respect to the scalar `t_l` is unjustified and appears incorrect. The chain rule for the derivative `d/dt_l (d^2(m exp(t_l v), x_l))` should yield a scalar and should not involve this projection `P`, which is related to the optimization of `v`."
      },
      {
        "Problem": "Incorrect update rule for `v` in gradient descent.",
        "Location": "Eq. (23), Section 3.3, Page 8",
        "Explanation": "The update rule for the Lie algebra element `v \\in T_eG` is `v_new = v - e' P sum_l t_l * Term_l`, where `Term_l` is the same expression from Eq. (22)'s update. If `Term_l` is the gradient for `t_l` (a scalar), then `sum_l t_l * Term_l` is also a scalar. The update for `v` would then be `v - e' * P * scalar_value`. This implies `v` is updated by `P` (an N x N matrix) applied to a vector representation of this scalar (e.g., `P * constant_vector * scalar_value`), which would incorrectly restrict `v`'s update to a single, fixed direction within the subspace `span{u_j}` (or `P` applied to `v * scalar_value`, which is also problematic). This formulation does not represent the correct gradient `nabla_v sum_l d^2(m exp(t_l v), x_l)` and appears dimensionally and structurally incorrect for a gradient descent step for `v`."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 17457,
      "output": 550
    }
  },
  {
    "entry_id": 1,
    "retraction_id": "2103.13332v3",
    "paper_id": "2103.13332v1",
    "retraction_comment": "The notion of stabilizing ordinal is not well-defined, i.e., Definition 14 is flawed. As a consequence the results presented in the paper are either incorrect or remain unproved",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of stabilizing ordinal for the safe belief operator Kψ.",
        "Location": "Definition 14, page 13",
        "Explanation": "The stabilizing ordinal for Kψ at world w, pf(w)(Kψ), is defined as Sup({pf(w)(ψ), pf(w)(¬ψ)}) (if Kψ is not in Basew). This definition is critically flawed because it only considers the stabilizing ordinals of ψ and ¬ψ at the same world w. However, the semantic truth of Kψ at w depends on Bψ at w, and on ψ (and Bψ) at other potentially different worlds v (specifically, minimal Bψ-worlds in Ww). An adequate definition would need to account for these modal dependencies across worlds. This error undermines the subsequent proofs (e.g., Lemma 32 in the appendix) that rely on this definition to show sentences stabilize, and thus casts doubt on the main result about the existence of fixed points for the K-jump (Proposition 20)."
      },
      {
        "Problem": "Incorrect or missing definition of stabilizing ordinal for the belief operator Bψ and its negation ¬Bψ.",
        "Location": "Definition 14, page 13",
        "Explanation": "The definition of the stabilizing ordinal pf(w)(φ) appears to be missing a clear and correct clause for Bψ when Bψ is not in Basew. If it's intended to be pf(w)(ψ) (by misinterpreting the layout), this is incorrect as Bψ at w depends on ψ at all R-accessible worlds from w. Furthermore, the clause for ¬Bψ, given as 'pf(w)(¬ψ), if φ = ¬Bψ, ¬Kψ ∉ Base', is also incorrect as it improperly localizes the dependency to pf(w)(¬ψ) at the same world w and includes an unrelated condition '¬Kψ ∉ Base'. Since Kψ is defined in terms of Bψ, these flaws also critically impact the soundness of the paper's main construction of fixed points."
      },
      {
        "Problem": "Flawed derivation in the proof of Lemma 12 regarding the Kripke jump for subjunctive conditionals.",
        "Location": "Proof of Lemma 12, page 11",
        "Explanation": "In the proof that the Kripke jump C (for subjunctive conditionals) has no fixed points, a specific semantic condition (ii) derived from Definition 10 (16) is claimed to be equivalent to '∃z ∈ Ww[M, z |= T「λ¹ & ∀u(u <w z ⇒ M, u |= T「λ¹)]'. This stated equivalence is incorrect. The original condition is ∃z ∈ Ww[M, z |= T「λ¹ & ∀u(u ≤w z & M, u |= T「λ¹ ⇒ M, u |= ⊥)]. The paper's version changes ≤w to <w and, more importantly, changes the consequent of the inner implication from ⊥ to T「λ¹. While the lemma's ultimate conclusion (that C has no fixed points) might be true, this step in the provided proof is erroneous and misrepresents the semantics of the subjunctive conditional as defined."
      }
    ],
    "token_usage": {
      "input": 6832,
      "thinking": 10470,
      "output": 710
    }
  },
  {
    "entry_id": 2,
    "retraction_id": "1602.07129v2",
    "paper_id": "1602.07129v1",
    "retraction_comment": "this paper has been withdrawn due to minor error in the calculation of dielectric constant",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential incorrect starting material composition",
        "Location": "Page 3, Experimental section, first paragraph",
        "Explanation": "The text states, 'The starting reagents SrCO3, BaCO3, TiO2 and MnO2 were dried...'. The target compound is Sr2TiMnO6. The inclusion of BaCO3 as a starting reagent is problematic. If BaCO3 was indeed used and not a typo for SrCO3, the synthesized material would not be pure Sr2TiMnO6 but would likely contain Barium (e.g., (Sr,Ba)2TiMnO6 or a phase mixture). This would fundamentally alter the material's identity, structural parameters, ionic radii, tolerance factor, and consequently its magnetic and electronic properties. All subsequent analyses and conclusions in the paper are based on the premise of pure Sr2TiMnO6, which would be invalidated if Ba is present due to the use of BaCO3."
      },
      {
        "Problem": "Inconsistent Mn ionic state and magnetic moment",
        "Location": "Page 4, discussion of Curie-Weiss fit; Page 5-6, specific heat analysis",
        "Explanation": "The experimentally determined effective magnetic moment (μ_eff = 5.01 μB/Mn) is significantly higher than the spin-only value for Mn4+ (S=3/2, μ_eff_so ≈ 3.87 μB), which the paper assumes to be the sole magnetic ion. This discrepancy (approx. 29% higher) is dismissed as 'slightly higher' but could indicate a different or mixed Mn valence state (e.g., presence of Mn3+ with S=2, μ_eff_so ≈ 4.9 μB). Despite this, the entire theoretical framework, particularly the calculation of theoretical magnetic entropy (Smag_theo = Rln(2S+1) = 11.5 J/mol-K based on S=3/2 for Mn4+), relies on the pure Mn4+ (S=3/2) assignment. This fundamental inconsistency regarding the Mn spin state undermines the quantitative magnetic analysis and comparisons to theory, making them unsound."
      },
      {
        "Problem": "Contradictory and poorly justified specific heat analysis for magnetic entropy",
        "Location": "Page 5-6, Specific Heat section, Equations 1-3, Figure 4",
        "Explanation": "The paper presents two conflicting methods for subtracting the lattice specific heat contribution (Clatt) to determine the magnetic entropy change (Smag), leading to vastly different experimental Smag values: 0.5 J/mol-K and 10.86 J/mol-K. The first value (0.5 J/mol-K from a polynomial fit of Clatt over 20-40K) shows a large discrepancy with the theoretical Smag for Mn4+ (S=3/2), which is 11.5 J/mol-K. The second value (10.86 J/mol-K from a Debye model for Clatt with θD=545K) is claimed to be a 'best physical fit' and matches the theoretical value. However, the justification for this specific θD is weak, the fitting range is not clearly defined, and the visual representation of this Debye fit in the inset of Fig. 4(a) suggests it may not accurately model Clatt, potentially underestimating it at low temperatures where the magnetic anomaly is significant, thereby artificially inflating the calculated Smag. The paper uses arguments based on both Smag values without robustly defending one method over the other or reconciling the large differences, rendering conclusions about the magnetic entropy and the nature of the magnetic ordering unreliable."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 9086,
      "output": 809
    }
  },
  {
    "entry_id": 3,
    "retraction_id": "2006.00175v4",
    "paper_id": "2006.00175v3",
    "retraction_comment": "In eq 38, misses a d^2 phi term, breaking down the results of the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear and potentially flawed derivation of symmetry conditions.",
        "Location": "Section II, Eq. (39)-(41); Section IV, Eq. (59)-(62); Section VI, Eq. (71)-(73).",
        "Explanation": "The paper defines 'quantum symmetry' as a transformation where the action S changes by S → S + ∫d⁴x ε [f(φ,φ*) (δL/δψ) + k ψ (δL/δφ)] + c.c. (page 3, 13). However, the derivations of conditions for W₁ and W₂ (e.g., Eq. 41) appear to be based on making an effective Lagrangian variation (δL_calculated + 'added terms') equal to zero (e.g., Eq. 40: δS + ∫d⁴x[ε(dL/dψ̄)(dW/dφ) - c.c.] = 0). It is not demonstrated that these 'added terms' precisely correspond to -[∫d⁴x ε [f(φ,φ*) (δL/δψ) + k ψ (δL/δφ)] + c.c.] for the original Lagrangian L and some f, k. This logical gap makes the derived conditions (Eq. 41, 62, 73) and thus the construction of symmetric Lagrangians potentially unfounded."
      },
      {
        "Problem": "The argument for the non-supersymmetric nature of the symmetry algebra is weak and lacks rigor.",
        "Location": "Page 6, paragraph following Eq. (36).",
        "Explanation": "The paper claims that the quantum generators (Q') of the proposed symmetry (Eq. 4) do not satisfy a standard supersymmetry algebra relation like {Q', Q'†} ~ σμPμ. The argument provided is that this would require the energy-momentum tensor component T₀μ to contain an explicit coordinate-dependent Green's function G(x), which is deemed not possible for local theories. This argument is qualitative and not a rigorous proof. The non-local nature of Q' (due to E⁰ involving ∇⁻²) and its full implications for the algebra are not sufficiently analyzed or proven, making the 'non-supersymmetric' claim inadequately substantiated."
      },
      {
        "Problem": "The restrictive nature of the conditions imposed on the potential W(φ,φ*) is not fully acknowledged or explored.",
        "Location": "Derived from conditions like Eq. (41) and their consistency with the form of W₁ in Eq. (42). For example, the combination implies -∂²W*/(∂φ∂φ*) - ∂²W*/∂φ² = ∂²W/∂φ², in conjunction with Eq. (41.2) ∂W*/∂φ* = (∂²W*/∂φ*²) / (∂²W/∂φ²).",
        "Explanation": "The conditions derived for the 'superpotential' W(φ,φ*) (from which W₁ and W₂ are determined) are a set of coupled partial differential equations. While the paper emphasizes that W 'need not be holomorphic,' the actual severity of these constraints is not discussed. These PDEs might admit only trivial solutions or a very limited class of functions for W, potentially undermining the generality and novelty of the proposed symmetry construction. The implications of these strong constraints on the phenomenological viability or theoretical interest of the models are not explored."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 13579,
      "output": 761
    }
  },
  {
    "entry_id": 4,
    "retraction_id": "2108.05829v5",
    "paper_id": "2108.05829v4",
    "retraction_comment": "There is a mistake in the proof. The second term of the last equation in Lemma 2.2 does not have the desired asymptotic behavior. I am grateful with [REDACTED-NAME] for pointing out this mistake",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Faulty deduction that individual ideal sheaves are locally monomial because their product is.",
        "Location": "Page 3, Proof of Lemma 2.1, first paragraph.",
        "Explanation": "The proof of Lemma 2.1(1) states that Hironaka's monomialization makes `σ⁻¹I = σ⁻¹(m_xo I_U)` locally monomial. From the equality `σ⁻¹I = (σ⁻¹m_xo)(σ⁻¹I_U)`, it's concluded that `σ⁻¹m_xo` and `σ⁻¹I_U` are 'locally monomial as well'. This inference is not generally valid in ideal theory; a product of ideals being monomial does not imply each factor is monomial. Lemma 2.1(1) (that `σ⁻¹I_U` is locally monomial) is crucial for the subsequent construction in Lemma 2.2, specifically for asserting that `Ũ = U ο σ` has a local monomial representation `±w_1^{d_1}...w_n^{d_n}`, which is the basis for defining the vector field `Ṽ_p` and deriving its properties."
      },
      {
        "Problem": "Insufficient justification for the covariant derivative calculation of the vector field V_p.",
        "Location": "Page 4, Proof of Lemma 2.2, calculation of `<v, ∇_v V_p>`.",
        "Explanation": "The proof of Lemma 2.2 asserts that `<v, ∇_v V_p> = g_{ab}v^a v^b + (1/2)V_p(g_{ab})v^a v^b = (1+o(1))||v||²`. This equality, particularly the first part, is non-trivial and specific to certain types of vector fields or coordinate systems. The vector field `V_p` is a pushforward of `Σ w_i ∂w_i` by `σ`, and the coordinates `w'_i` used are `w_i ο σ⁻¹`. The derivation is condensed, and it's unclear if the conditions for this formula are met or if the `o(1)` term is correctly estimated without more detailed calculations or justifications. This property is essential for the main proof, as it determines the behavior of `Ḟ(t)`."
      },
      {
        "Problem": "Flawed reasoning in the argument for the existence of a suitable neighborhood W.",
        "Location": "Page 4, Proof of Lemma 2.2, last paragraph.",
        "Explanation": "The argument for the existence of a neighborhood `W` of `x_0` such that `W - V(U) ⊂ W'` (where `W' = ∪_{p∈H} σ(W_p – E)`) contains a logical flaw. It states: 'otherwise there would be a sequence (`x_n`) ... and a subsequence of (`σ⁻¹(x_n)`) converging to some point `y` in `H` ... hence eventually contained in `W_y - E` which is absurd.' If `x_n ∉ W'`, then `x_n ∉ σ(W_y - E)`, which implies its preimage `σ⁻¹(x_n)` would *not* be in `W_y - E`. The absurdity should arise from `σ⁻¹(x_n)` being in `W_y ∩ E`. While the claim about the existence of `W` might be true (possibly salvageable using `σ(E) ⊂ V(U)`), the provided justification is unsound."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 16792,
      "output": 802
    }
  },
  {
    "entry_id": 5,
    "retraction_id": "2403.19848v2",
    "paper_id": "2403.19848v1",
    "retraction_comment": "We're withdrawing our paper from arXiv due to a critical error in our review methodology, which excluded key studies on sustainable road freight transport. This oversight could mislead the scientific community. We plan to correct this, ensuring comprehensive study inclusion, and will resubmit our paper for a more accurate review",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Vague and Undisclosed Review Methodology",
        "Location": "Section 2. Methodology, Page 4, first paragraph",
        "Explanation": "The paper claims to conduct a 'systematic review' but fails to adequately detail its methodology. Crucial information such as the search strategy (databases, keywords), specific criteria for paper selection beyond general 'sustainable criteria,' the inclusion/exclusion process, and any quality assessment of the selected studies is missing. This lack of transparency makes it impossible to evaluate the review's comprehensiveness, potential biases, and the reliability of its findings, thereby undermining the validity of its conclusions."
      },
      {
        "Problem": "Overstated or Potentially Misleading Claims about Reviewed Literature",
        "Location": "Section 3. Results and discussion, Page 8, first paragraph; Conclusion, Page 10",
        "Explanation": "The paper makes generalizations about the reviewed literature that are not strongly supported by, or appear contradicted by, its own summary data in Table 1. For example, the assertion that 'Recent studies on sustainability measure in road freight transportation combined the analysis of the three dimensions' (Page 8) is not clearly supported by Table 1, where only one study (Aloui et al., 2021) is explicitly shown covering all three. Such overstatements can misrepresent the actual state of research and weaken the credibility of the paper's conclusions."
      },
      {
        "Problem": "Lack of Clearly Defined Specific Research Gap and Novel Contribution",
        "Location": "Abstract, Page 1; Introduction, Page 3, last paragraph; Conclusion, Page 10",
        "Explanation": "The paper mentions a 'research gap' (Page 3) but does not articulate a specific, nuanced gap that the review intends to address. Furthermore, the paper's claim in the abstract to 'provide a theoretical research findings' is not substantiated with new theoretical insights or a novel conceptual framework. The conclusions largely reiterate general knowledge rather than offering new perspectives derived from a rigorous synthesis, making its unique contribution unclear."
      },
      {
        "Problem": "Inconsistent or Ambiguous Data Presentation in Table 1",
        "Location": "Table 1, Pages 4-6 (e.g., duplicate entries for Holguín-Veras et al., 2016 on page 4 and page 5 with different 'Sustainable dimension' attributions)",
        "Explanation": "Table 1, which forms the core evidence for the review, contains inconsistencies such as the duplicate listing of at least one study with different sustainability dimensions attributed across its entries. This raises concerns about the rigor of data extraction and the reliability of the categorization of studies, which is fundamental to the paper's analysis and subsequent discussion of sustainability dimensions."
      },
      {
        "Problem": "Superficial Analysis of Methodologies Used in Reviewed Studies",
        "Location": "Table 1 (Method column); Discussion of dimensions, Pages 6-8; Conclusion, Page 10",
        "Explanation": "While the paper lists methods used in the reviewed studies (Table 1) and mentions them in the text, it lacks a critical analysis or in-depth discussion of these methodologies. There is no substantive evaluation of their evolution, strengths, weaknesses, or suitability for addressing sustainability in road freight transport. This superficial treatment limits the paper's ability to provide meaningful insights into 'how the researchers have used different analysis techniques' (Page 10) beyond a descriptive summary."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 3541,
      "output": 759
    }
  },
  {
    "entry_id": 6,
    "retraction_id": "2210.14117v3",
    "paper_id": "2210.14117v2",
    "retraction_comment": "Error in formulation of Bronold-Fehske model. The plots shown are actually in terms of E' + chi, shifted incorrectly by a factor of the electron affinity. The apparent perfect reflection region is therefore nonphysical",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified parameters and lack of sensitivity analysis for the artificial collision model.",
        "Location": "Page 4, Section II.C, Eq. 15",
        "Explanation": "The paper employs an artificially inflated and spatially varying collision frequency to maintain a Maxwellian presheath distribution. However, the specific parameters chosen for this model (e.g., base collision rate `ν0,ss = vth,s / (50λD)`, sigmoid parameters `xs`, `Δxs` for Eq. 15) are not fully justified, and no sensitivity analysis is presented. Since the electron distribution function at the wall, which dictates reflection and gain `γ`, is shown to be highly sensitive to collision frequency (Fig. 5), the quantitative (and potentially qualitative) results depend significantly on these unvalidated choices."
      },
      {
        "Problem": "Potentially incomplete explanation for plasma cooling and its impact on non-steady state results.",
        "Location": "Page 5, Section III (discussion of Fig. 9)",
        "Explanation": "The simulations do not reach steady state, with electron temperature apparently decreasing over time, causing the gain `γ` to evolve (Fig. 9). This is attributed to 'collision-driven cooling' via energy loss from particles hitting the wall. This explanation may be incomplete, as electron-ion collisional energy transfer (with `Te_initial >> Ti_initial` and artificially high collision frequencies) could be a dominant cooling mechanism for electrons. A clear identification of the primary cooling driver is crucial for interpreting whether the evolving sheath structures are robust physical predictions or artifacts of the specific numerical setup and its thermal non-equilibrium."
      },
      {
        "Problem": "Assumption of material parameter `C` for Boron Nitride without specific validation.",
        "Location": "Page 2, Eq. 7 and discussion of material choices",
        "Explanation": "The disordered interface parameter `C=2` in the Bronold-Fehske reflection model (Eq. 7) is adopted from fits to Magnesium Oxide (MgO) data. This value is then assumed 'sufficiently applicable' for Boron Nitride (BN) without specific experimental validation for BN or a sensitivity study. Since `C` affects the angular dependence of reflection and thus the overall gain `γ`, using an unverified `C` for BN could compromise the accuracy of its simulated sheath behavior and the validity of comparisons to MgO, where `C=2` is better justified."
      },
      {
        "Problem": "Particle source model may not ensure thermal equilibrium in a cooling plasma.",
        "Location": "Page 4, Eq. 14 and Page 5 discussion of cooling",
        "Explanation": "The particle source (Eq. 14) replenishes wall losses by injecting particles with a distribution corresponding to the *initial* plasma temperature. If the bulk plasma cools significantly (as suggested by the 'collision-driven cooling' and evolving `γ`), this fixed-temperature source introduces a thermal imbalance. While the paper states the source's effect is small due to low particle loss, the interaction between this source, actual energy loss mechanisms, and collisional redistribution in a non-steady, cooling system is complex and could artificially influence the temperature evolution and thus the long-term behavior of the gain `γ`."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 6394,
      "output": 716
    }
  },
  {
    "entry_id": 7,
    "retraction_id": "1902.09447v2",
    "paper_id": "1902.09447v1",
    "retraction_comment": "We have to change the simulations section since the authors of the RANA method do not agree that we did fair comparisons with their method",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Frequency mismatch in gradient calculation",
        "Location": "Eq. (5), Eq. (6), Eq. (38), Appendix B",
        "Explanation": "The objective function term l_{k,p} (Eq. 4) is based on the k-th frequency component of the estimated FROG trace, A_{p,k}(z) = sum_n z[n]z[n+pL]exp(-2*pi*i*n*k/N). However, the Wirtinger derivative calculation in Eq. (6) (and detailed in Appendix B, e.g., Eq. 38 for p_{k,p}(z)) uses f_k^H g_p = sum_n z[n]z[n+pL]exp(-2*pi*i*n*(k-1)/N), which corresponds to the (k-1)-th frequency component, A_{p,k-1}(z). The gradient term v_{k,p} (defined below Eq. 6) and p_{k,p}(z) (Eq. 38) incorrectly combine the k-th measurement Z[p,k] with this (k-1)-th component of the estimate. This mismatch means the calculated gradient direction is incorrect. This error also propagates to the convergence analysis (Lemma 1, Theorem 1), as the bounds derived would be based on these mismatched terms, potentially invalidating the proof of convergence."
      },
      {
        "Problem": "Misidentification of matrix G_l structure and its invertibility condition",
        "Location": "Page 4, Section IV-A, paragraph after Eq. (15)",
        "Explanation": "In the initialization algorithm for L=1 (Section IV-A), the matrix G_l is defined by G_l[p,n] = x[n+p]x[n+l+p] (for L=1). This structure defines a Hankel matrix (G_l[p,n] is a function of p+n), not a circulant matrix as claimed. Consequently, the statement that 'G_l is invertible if and only if the DFT of its first column...is non-vanishing' is incorrect, as this condition applies to circulant matrices. While the motivation for using a proximal step (Eq. 23) due to potential non-invertibility of G_l might still hold for Hankel matrices, the fundamental analysis of G_l's structure and properties is flawed."
      },
      {
        "Problem": "Incorrect algorithm reference in L>1 initialization",
        "Location": "Algorithm 3, Line 7",
        "Explanation": "Algorithm 3, describing the initialization procedure for L > 1, states in Line 7: 'Compute x^(0) <- Algorithm 1(Z^(I), T)'. Algorithm 1 is the main BSGA iterative refinement method, not an initialization procedure. This reference should likely be to Algorithm 2, which is the initialization procedure designed for the (effectively) L=1 case (after upsampling Z to Z^(I)). Using Algorithm 1 here would mean running the full iterative solver as part of an initialization step for the same solver, which is either circular, computationally redundant, or simply an incorrect procedural step."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 13615,
      "output": 723
    }
  },
  {
    "entry_id": 8,
    "retraction_id": "1610.03889v2",
    "paper_id": "1610.03889v1",
    "retraction_comment": "There is a serious gap about the tangent space of the dimension 2 foliations induced by a linear pull-back. I do not know if the scheme is reduced and so it is possible that the dimension of the tangent space of this scheme is bigger than his topological dimension",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assertion of tangent sheaf splitting",
        "Location": "Page 2, paragraph after the definition of Π = (∂/∂X_n) ∧ Y, also mentioned in the Abstract and used in the proof conclusion on Page 6.",
        "Explanation": "The paper asserts that the foliation F, induced by the Poisson structure Π = (∂/∂X_n) ∧ Y (where Y is a quadratic vector field on P^(n-1) and ∂/∂X_n relates to projection), has a tangent sheaf TF that splits as O_Pn(-1) ⊕ O_Pn(1). This is a very strong condition and is critical for the main argument, particularly for applying the stability theorem from reference [3] and concluding the form of the deformed foliation F_ε. The paper does not provide a proof or a specific citation for why this particular construction of F must have a split tangent sheaf of this form. If TF does not split as claimed, the foundation of the stability argument is undermined."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 22963,
      "output": 230
    }
  },
  {
    "entry_id": 9,
    "retraction_id": "1208.1540v2",
    "paper_id": "1208.1540v1",
    "retraction_comment": "This paper has been withdrawn because there is a gap in the construction of the canonical quadratic refinement on a mapping torus",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect application of Theorem 2.9 in the proof of Theorem 4.7 (formula for Arf invariant A(Q^c_phi)) due to unjustified vanishing of Q^c_phi(b).",
        "Location": "Page 21, Proof of Theorem 4.7 (also impacts Eq. 1.3 and Theorem 4.11).",
        "Explanation": "The derivation of the formula for the Arf invariant A(Q^c_phi) (Eq. 4.11, also Eq. 1.3) uses Theorem 2.9, which generally includes a term Q^c_phi(b). The proof of Theorem 4.7 asserts that this term vanishes (effectively b=0) because 'Q^c_phi(z) obviously vanishes for z a torsion class'. However, Proposition 4.5 only shows Q^c_phi vanishes on specific direct summands of the torsion cohomology of the mapping torus M_phi (namely H^{2l+1}_{tors,phi} and H^{2l+2}_{tors,phi}), not necessarily on all torsion classes z that are restrictions of classes from the bounding manifold W, which is required for Q^c_phi(b) to vanish. If Q^c_phi(b) is non-zero, the formula for A(Q^c_phi) would be incorrect, impacting a key result of the paper."
      },
      {
        "Problem": "Insufficient justification for the canonicity (uniqueness) of the 'canonical' quadratic refinement Q^c.",
        "Location": "Section 4.3, 4.4 (definition of mu^c, Q^c_phi), Section 5.2 (definition of Q^c_M), and Remarks 4.3, 5.3.",
        "Explanation": "The 'canonical' quadratic refinement Q^c (for mapping tori Q^c_phi, and for manifolds M, Q^c_M) is constructed via a 'canonical relative lift' X^c, which depends on a class mu^c. The class mu^c is obtained by adjusting an initial choice mu (where 2mu = nu_check, nu_check being the functorial lift of the Wu class) using terms u1, u2 derived from an intermediate quadratic refinement Q(mu). Remarks 4.3 and 5.3 explicitly state that Q(mu) depends on the choice of mu (specifically, its 2-torsion part beyond certain initial normalizations). While the specific construction a(mu^c) = a(mu) + u1(Q(mu)) + u2(Q(mu)) might ultimately yield a result independent of the initial choices allowed for mu, the paper does not provide an explicit proof of this independence. This leaves a gap in rigorously establishing that Q^c is uniquely and canonically defined as claimed, which is crucial for its status as a well-defined (topological) invariant."
      }
    ],
    "token_usage": {
      "input": 9928,
      "thinking": 19010,
      "output": 655
    }
  },
  {
    "entry_id": 10,
    "retraction_id": "1708.09822v3",
    "paper_id": "1708.09822v2",
    "retraction_comment": "incorrect example (Example 5)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect analysis of the structure of Hλ,p for p prime, specifically for p=17.",
        "Location": "Page 21, Section 4.4, The Decomposition of Hp,p and Hλ,p, p ≥ 3 prime.",
        "Explanation": "The paper correctly establishes that for Hλ,p ≅ Q × Q × Mat_r(R), if Z(R) = Q(ζ_p + ζ_p⁻¹), then r²[R:Z(R)] = 4. Letting k² = [R:Z(R)] (where k ≥ 1 is an integer), this implies (rk)² = 4, so rk=2. This restricts the possibilities to (r,k) = (1,2) or (r,k) = (2,1). This means r can only be 1 or 2.\nHowever, the paper, when discussing p=17, states 'If p=17 however, then r=2 or r=4'. The possibility of r=4 is incorrect. If r=4, then Mat_4(R) is the algebra component. Its center Z(R) must be Q(ζ₁₇ + ζ₁₇⁻¹), which has dimension (17-1)/2 = 8 over Q. If r=4, then from rk=2, k=1/2, which is not an integer. Alternatively, if one uses r²|2(p-1) (so r²|32 for p=17, allowing r=4), then dim_Q(R) = 2(p-1)/r² = 32/16 = 2. A division ring R of dimension 2 over Q must be a quadratic field extension of Q. Its center Z(R) is R itself, so dim_Q Z(R) = 2. This contradicts Z(R) = Q(ζ₁₇ + ζ₁₇⁻¹) which has dimension 8. Therefore, the conclusion that Hλ,p could be Q × Q × Mat₄(R) with dim_Q(R)=2 for p=17 is erroneous and invalidates this part of the structural analysis for Hλ,p."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 22537,
      "output": 507
    }
  },
  {
    "entry_id": 11,
    "retraction_id": "2011.04373v3",
    "paper_id": "2011.04373v2",
    "retraction_comment": "paper withdrawn since dimension reduction might not hold in the parabolic setting",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption (H5) is mathematically questionable",
        "Location": "Page 3, Eq. (1.2); used in Page 7, Eq. (3.11)",
        "Explanation": "Assumption (H5), specifically the inequality `sup_{-θ<t<θ} ∫_{B_ρ} u^2 dx ≥ ∫_0^ρ sup_{-θ<t<θ} ∫_{S_r} u^2 dH^(N-1) dr`, appears to state that `sup_t E_r[f(r,t)] ≥ E_r[sup_t f(r,t)]` where `E_r` is integration with respect to the measure `r^(N-1)dr` and `f(r,t) = ∫_{S_r} u(x,t)^2 dH^(N-1)`. Standard inequality theory suggests the reverse inequality `E_r[sup_t f(r,t)] ≥ sup_t E_r[f(r,t)]` (related to Fatou's Lemma or Tonelli's theorem context for sup vs integral). If this assumption does not hold for general weak solutions, or only for a very restricted class, the theorem's applicability is severely limited or the proof is invalid. The acknowledgement indicates this assumption was added to fix a previous error, highlighting its critical role."
      },
      {
        "Problem": "Definition of the iteration quantity M_i and its relation to estimates",
        "Location": "Page 8, Eq. (3.15) and Eq. (3.16)",
        "Explanation": "The definition of `M_i := Y_i + Y_i^{1/(N+1)} Z_i^{(p-q*)/(N+1)} + Z_i^{1/(N+1)}` in Eq. (3.15) is unusual. The exponents `1/(N+1)` and `(p-q*)/(N+1)` are not clearly derived from the preceding estimates in Eq. (3.14). Standard iteration schemes build `M_i` from terms that appear naturally in the energy estimates. If `M_i` is not appropriately defined, the subsequent iterative step Eq. (3.16), `sup (...) + ∫|∇(u-k_{i+1})_+|^p dz ≤ b^i A_k |Q_i| M_i`, and the overall convergence argument (Section 4) may be unsound."
      },
      {
        "Problem": "Derivation of the bound in Eq. (3.20)",
        "Location": "Page 9, Eq. (3.20)",
        "Explanation": "In Eq. (3.20), the estimate for `∫∫_{Q_i} |(u-k_{i+1})_+|^{p#} ζ_i^{p#} dz` combines terms from the parabolic Sobolev inequality (3.19). The RHS of (3.19) involves `(sup ∫ (u-k_{i+1})_+^2 dx)^{p/N}`, `∫∫ |∇(u-k_{i+1})_+|^p dz`, and a term estimated by (3.6). These are then collectively bounded by `2(b^2 A_k |Q_i| M_i)^{1+κ}`. This step is condensed, and it's not immediately clear how these terms, with different origins and potentially different magnitudes, combine so neatly into a single expression involving `M_i` raised to the power `1+κ`. A rigorous justification for this combination is needed, as imprecision here could affect the exponents in the final iterative inequality for `Y_i`."
      },
      {
        "Problem": "Potential singularity due to k_i in denominators",
        "Location": "Page 6, Eq. (3.6) and (3.7)",
        "Explanation": "The estimates (3.6) and (3.7) use `k_i^{ε_0}` and `k_i^{p+ε_0-2}` respectively in their denominators (in the intermediate and final lines of (3.6), and the final line of (3.7)). According to Eq. (3.4), `k_i := k - k/2^i`, which means `k_0 = 0`. If `i=0` is a valid index for these estimates (e.g. starting the iteration), then `k_0=0` would lead to a singularity. Standard applications of Lemma 3.1 (DiBenedetto's Lemma 7.1, Chapter V) typically involve the total height `k` (i.e., `k_∞`) in the denominator, not the partial height `k_i`. If this is not a typo for `k`, it's an error."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 18614,
      "output": 1083
    }
  },
  {
    "entry_id": 12,
    "retraction_id": "2401.02488v3",
    "paper_id": "2401.02488v2",
    "retraction_comment": "Lemma 3.4 on page 7 is incorrect. This is crucial to the argument. The problem that could not be fixed is if there are parts of hilden subgroup elements that contain parts of powers of the garside element",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsupported claim that the Garside element Δ is in the Hilden subgroup.",
        "Location": "Page 6, Proof of Lemma 3.1",
        "Explanation": "The proof of Lemma 3.1 critically relies on the statement: 'The key observation is that Δ is actually in the Hilden subgroup.' This claim is used to argue that P_0 (from the Garside decomposition β = Δ^m P_0) is in the same Hilden double coset as β. However, the Garside element Δ is generally not an element of the Hilden subgroup H_N. The geometric argument provided (lifting and moving bridges) describes a cyclic permutation of bridges, which is an element of H_N, but this operation is not equivalent to the Garside element Δ (a half-twist of all strands). If Δ ∉ H_N, then the argument that P_0 ∈ [β]⁺ (and thus that [β]⁺ is non-empty and contains P_0) is unfounded, undermining the subsequent algorithm."
      },
      {
        "Problem": "Incorrect deduction that elements A and B of the Hilden subgroup must be Δ-free if AaB=P and P is Δ-free.",
        "Location": "Page 7, Proof of Lemma 3.4",
        "Explanation": "In the proof of Lemma 3.4, it's assumed that A, B ∈ H_N, and a, P are positive Δ-free braids. From A = Δ^{m_A}P_A, B = P_BΔ^{k_B} (corrected Garside form for B should be Δ^{k_B}P_B or P_B should be suffix of Δ^{k_B}P_B), and Δ^{m_A} P_A a P_B Δ^{k_B} = P, the proof concludes that P_A a P_B = P. This implicitly requires m_A=0 and k_B=0, meaning A and B must be Δ-free. This deduction is not justified; Δ factors from A and B could potentially cancel each other or be absorbed in a way that still results in a Δ-free P, without A and B themselves being Δ-free. This error invalidates the core argument for bounding the search space for A and B."
      },
      {
        "Problem": "Unjustified length additivity formula for braid words involving Hilden subgroup elements.",
        "Location": "Page 7, Proof of Lemma 3.4",
        "Explanation": "The proof of Lemma 3.4 states that if AaB = P, then 'Len(AaB) = Len(A) + Len(a) + Len(B) = Len(P) because each term is positive.' This assertion is problematic for several reasons: 1) It relies on the incorrect deduction that A and B are Δ-free (P_A and P_B respectively, as per Problem 2). If A = Δ^{m_A}P_A, its length involves Len(Δ). 2) Elements A, B ∈ H_N are not necessarily positive words; they are general subgroup elements. The length of a braid group element is typically its length in a normal form (e.g., Garside normal form word length). Simple additivity of word lengths (Len(X)+Len(Y)+Len(Z)) for a product XYZ=P only holds under strong conditions (like X,Y,Z being positive words and no Artin generator cancellations). This length formula is crucial for the claim that the search for A and B is finite, so its unsoundness breaks the proposed algorithm for solving Problem 3.3."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 11346,
      "output": 813
    }
  },
  {
    "entry_id": 13,
    "retraction_id": "1208.2556v8",
    "paper_id": "1208.2556v7",
    "retraction_comment": "This paper has been withdrawn by the author because (k+1)n<k(n+2) is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified deduction that z0 = 2n+1",
        "Location": "Page 5, lines 1-5, leading to the conclusion 'precisely 2n+1' on line 5.",
        "Explanation": "The paper correctly derives z0 = 2n + n/k (where k is from m0=2k+1, and n is from z1=2z0-n, with k|n and n>=k, so n/k is an integer >=1). To conclude that z0 = 2n+1, it must be shown that n/k = 1 (i.e., n=k). The paper argues this by attempting to show z0 < 2n+2. This upper bound z0 < 2n+2 is derived from the inequality (k+1)n < k(n+2), which simplifies to n < 2k. Thus, the conclusion z0 = 2n+1 is only justified if n < 2k (which implies n=k, as n/k must be an integer >=1). However, the paper does not rule out the cases n=2k (which implies n/k=2 and z0=2n+2) or n > 2k (e.g., n=3k, implying n/k=3 and z0=2n+3). Failure to eliminate these possibilities (where n/k >= 2) means the crucial step of establishing n/k=1 (and thus z0=2n+1) is unsound. This invalidates the subsequent argument that relies on z0=2n+1 to reach 3^x+1=2^y."
      },
      {
        "Problem": "Incorrect statement of property (iv) 'm2 is odd'",
        "Location": "Page 2, Section 2, list of properties, item iv).",
        "Explanation": "Property iv) states 'm2 is odd' for any min-normal cycle Mx = {m0, ..., mi}. The proof provided for this property relies on the inequality (3k+2)/2 < 2k+1 (where m0=2k+1), which simplifies to 0 < k. This means the proof only holds if k > 0. If k=0, then m0=1; for the known {1,4,2} cycle (normalized to m0=1), m2=C(C(1))=C(4)=2, which is even. In this k=0 case, (3k+2)/2 = 1 and 2k+1 = 1, so m3=m0, which is not a contradiction to m0 being the smallest element. Therefore, the property 'm2 is odd' is not true for all min-normal cycles. While the main theorem aims to prove no *other* cycle exists (which would imply k>0 for such a cycle, making m2 odd in that specific context), the property is stated as a general one, which is inaccurate."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 20747,
      "output": 678
    }
  },
  {
    "entry_id": 14,
    "retraction_id": "1905.08897v3",
    "paper_id": "1905.08897v2",
    "retraction_comment": "Although the quasi-nodal surface has been identified in our preprint, there is a tiny band gap (millivolt-level) in the non high symmetry k-line (e.g.,K1-K5). In this regard, the proposed bct-C40 should be a nodal net semimetal based on the strict definition of topological semimetal. We would like to withdraw this work to avoid misleading the readers from Arxiv",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Insufficient demonstration of continuous 2D degeneracy for nodal surfaces",
        "Location": "Page 3, paragraph starting 'To ascertain the actual situation...', Figure 2",
        "Explanation": "The paper asserts the formation of nodal surfaces based on 3D Brillouin Zone calculations but does not provide sufficient methodological detail on how the continuous 2D nature of these degeneracies was rigorously established. It is not detailed how these were distinguished from, for example, a very dense collection of 1D nodal lines or potential artifacts arising from k-space sampling density or interpolation methods. This lack of detail makes it difficult to fully assess the robustness of the primary evidence supporting the nodal surface claim."
      },
      {
        "Problem": "Lack of explicit symmetry analysis for the claimed nodal surfaces",
        "Location": "Page 3, last paragraph; Page 4, first paragraph; citing Ref [5]",
        "Explanation": "The paper classifies the claimed nodal features as 'Class-I nodal surfaces' purportedly protected by mirror symmetry. However, it omits a specific symmetry analysis for bct-C40 (space group I4/mmm) that would identify the particular mirror symmetries responsible for protecting the claimed surfaces. It also does not demonstrate how these symmetries lead to the extensive 2D degeneracies depicted in Figure 2. Such analysis is crucial for establishing the topological nature and stability of the claimed nodal surfaces."
      },
      {
        "Problem": "Potential oversimplification of the relationship between nodal nets and nodal surfaces",
        "Location": "Overall argument, e.g., Page 1, Abstract ('in fact a nodal surface semimetal'), Page 4, Conclusion ('Thus bct-C40 is actually just a new member of topological nodal surface semimetals')",
        "Explanation": "The paper frames its findings as a reclassification from a nodal-net to a nodal-surface semimetal, implying these descriptions are mutually exclusive for bct-C40. It does not consider or discuss the possibility that nodal lines (potentially forming a net) could coexist with nodal surfaces, or that the lines reported in the original study (Ref. [1]) might be specific features embedded within, or constituting parts of, the more extensive surfaces the 'Comment' authors find. This potentially oversimplified dichotomy might affect the interpretation of how the previous findings relate to the new claims."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 9224,
      "output": 513
    }
  },
  {
    "entry_id": 15,
    "retraction_id": "1712.07752v2",
    "paper_id": "1712.07752v1",
    "retraction_comment": "Based on the numerous reviews I have received, the figures illustrated in the paper are highly incorrect and vague. This might guide a novice reader towards a wrong direction and lead to improper understanding of the subject. Also, the paper covers a diverse range of topics but doesn't get into the details of any and hence the proposals remain pragmatically irrelevant",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Reliance on Utopian Preconditions for Global Cooperation",
        "Location": "Page 3, 'AI and Nationalism'; Page 4, 'Artificial Intelligence, MNCs and Law'; Page 4, 'Why the United Nations?'",
        "Explanation": "The paper's proposed solution (UIRB-AI) and the peaceful development of AI are predicated on unrealistic levels of global unity, such as citizens 'quitting nationalism,' MNCs universally and voluntarily supporting UN hard laws, and achieving a 'One world with a common plan.' These highly idealistic preconditions are historically unprecedented and practically unachievable, rendering the UIRB-AI concept and its purported benefits fundamentally unsound."
      },
      {
        "Problem": "Unrealistic Financial and Power Requirements for UIRB-AI",
        "Location": "Page 4, Figure 2 and its interpretation; Page 5, 'Need for an economically superior UIRB-AI'; Page 5, 'AI Tax and Robot Tax'",
        "Explanation": "The paper asserts that the UIRB-AI must be 'economically superior' to its member states (e.g., 'as rich as the world's richest country') to be effective, based on a questionable interpretation of Figure 2. It also proposes the UIRB-AI would levy global 'AI taxes.' These financial prerequisites are impossibly high, and the notion of a UN-based body having such sovereign tax-levying power is politically unfeasible, invalidating the practical basis of the UIRB-AI."
      },
      {
        "Problem": "Unfeasible Operational Mandate of Surveillance and Control",
        "Location": "Page 5, 'Objectives of the UIRB-AI'",
        "Explanation": "The UIRB-AI is proposed to register every AI lab/company, mandate disclosure of all research, and require that any AI breakthrough be reported to it *first* for approval before public release. This implies a global surveillance and control system that nations and corporations would almost certainly reject due to sovereignty, national security, economic competition, and intellectual property concerns. The inability to enforce such a mandate makes this core function of the UIRB-AI, and thus its overall effectiveness, unsound."
      },
      {
        "Problem": "Contradictory Stance on UN's Role and Feasibility of Proposed Reforms",
        "Location": "Page 1, 'AI and the fourth Industrial Revolution' & Figure 1; Page 3, 'Need for an unanimous international regulatory body for AI' & 'Artificial Intelligence and National Governance'; Page 4, 'Organizational structure of UIRB-AI' & 'Why the United Nations?'",
        "Explanation": "The paper dismisses current UN efforts as ineffective and easily overridden, yet proposes the UIRB-AI be established 'Under the United Nations' and spearheaded by existing UN agencies. Its success hinges on 'major reforms to the UN' (e.g., direct global elections for UN delegates, 'One world with a common plan') that are profoundly radical and whose feasibility is not substantiated. This creates an internal contradiction regarding the institutional basis for the UIRB-AI."
      },
      {
        "Problem": "Oversimplification of Achieving 'Unanimity' and Governance Challenges",
        "Location": "Title; Abstract; Page 5, 'Multipolar governance for the UIRB-AI'",
        "Explanation": "The proposal for a 'Unanimous International Regulatory Body' (UIRB-AI) inherently requires unanimous agreement on complex and contentious AI policies. The paper fails to adequately address how such unanimity would be achieved or maintained among diverse nations with competing interests, especially on issues with profound economic and security implications. The suggestion of a Swiss-style council does not scale to global governance of 190+ nations. This lack of a credible mechanism for achieving and maintaining unanimity makes the UIRB-AI's decision-making and enforcement capabilities appear unworkable."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 4132,
      "output": 862
    }
  },
  {
    "entry_id": 16,
    "retraction_id": "2110.09901v3",
    "paper_id": "2110.09901v2",
    "retraction_comment": "It relies on maximizing the distance over an intersection of balls to a given point. The used algorithm for this however, is not able to solve the class of problem the SSP generates",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Critical Flaw in Problem Formulation for n >= 3",
        "Location": "Page 3, Eq. (4) and Eq. (9); Analysis on Page 3 and its implications throughout",
        "Explanation": "The constraint `(1/n) * 1^T * x - x^T * x / 2 >= 0` (which is `sum_k ((1/n)*x_k - (1/2)*x_k^2) >= 0`) is part of the problem formulation (4) and definition of polytope P (9). For this sum of quadratic terms to be non-negative, each term `(1/n)*x_k - (1/2)*x_k^2` must be non-negative if we consider the 'worst-case' distribution, or rather, each `x_k` is constrained. Each function `g_k(z) = (1/n)*z - (1/2)*z^2` is non-negative for `z in [0, 2/n]`. If `n >= 3`, then `2/n < 1`. This implies that for the constraint to hold, each `x_k` must be in `[0, 2/n]`. Consequently, if `x_k` must also be in `{0,1}` for the objective function of (4) to reach its maximum of 0 (a condition for solving RSSP), then `x_k` must be 0 for all `k` when `n >= 3`. This would mean the formulation can only find the trivial solution `x=0` for RSSP when `n >= 3`, making it incorrect for the general subset sum problem."
      },
      {
        "Problem": "Misleading FPTAS Claim and Unclear Complexity",
        "Location": "Abstract, Page 1; Section 1.3; Section 3.5; Conclusion Page 17",
        "Explanation": "The paper claims to provide an FPTAS for RSSP. However, the discussion in Section 3.5 and the conclusion suggests an exact algorithm that runs in polynomial time (in the BSS model of computation, assuming polytope containment can be solved in P time). If RSSP is NP-hard in the BSS model (as variations of subset sum often are), an exact polynomial-time algorithm would imply P=NP. The paper does not clearly reconcile this: is it an approximation scheme (FPTAS) or an exact algorithm? If it's an FPTAS, the approximation guarantees concerning the target sum (which is 0) are not clearly established in the standard FPTAS sense for subset sum. The role of 'epsilon' from page 3 versus 'epsilon' in bisection (page 16) is also not clarified in this context."
      },
      {
        "Problem": "Unjustified Uniqueness Assumption for Minimizer",
        "Location": "Page 6, Section 2.2, near Eq. (18)",
        "Explanation": "The paper states: 'We assume in this paper that X_p^* = {x_p^*} i.e. contains a single point!'. X_p^* is the set of minimizers of `(h_p - f)(x)` over `{x | h_p(x) <= 1}`. The function `(h_p - f)(x)` is `max_k (-2*C_k^T*x + ||C_k||^2 - r_k^2)`, which is convex but not necessarily strictly convex. Therefore, its minimizer over a convex set is not guaranteed to be unique. This assumption is a significant restriction on the types of problems the method can handle or means the algorithm might fail if the minimizer is a set."
      },
      {
        "Problem": "Approximation of Non-Linear Constraint with Incorrect Linear One",
        "Location": "Page 8, construction of C_h, r_h (Eq. 28-30) and text below (30)",
        "Explanation": "The polytope P is defined using the non-linear (though convex) constraint `H(x) = sum_k ((1/n)*x_k - (1/2)*x_k^2) >= 0`. However, when constructing the approximating set Q_p, the ball B(C_h, r_h) is designed to approximate a region involving the *linear* half-space `1^T*x - n/2 >= 0` (as stated in the text below Eq. 30: '{x | ||x - 1/2 * 1|| <= sqrt(n)/2, 1^T*x - n/2 >= 0} subset B(C_h,r_h)'). The linear constraint `1^T*x - n/2 >= 0` is not equivalent to the original non-linear constraint `H(x) >= 0`. Therefore, Q_p is not correctly approximating P with respect to this crucial constraint, potentially invalidating Q_p as a proper outer approximation for the intended P."
      },
      {
        "Problem": "Potentially Unsound Argument for Equivalence of Polytope Containment Conditions",
        "Location": "Pages 13-16 (Section 3.4, particularly Remark 7 and subsequent argument)",
        "Explanation": "A crucial part of the algorithm's correctness relies on proving that if RSSP has a solution, then `R^*_{p,C} = R^0_{p,C}`. This means `inf{R | P_{p,R^2,C} subset Q_p} = inf{R | P_{p,R^2,C} subset P}`. The argument for this (pages 13-16) involves a complex proof by contradiction, constructing a tighter approximation `Q_hat_rho` and using Lemma 3.5. Key assertions within this proof, such as 'It follows that R_1 = R^*_{p,C}' on page 16 (referring to parameters from different optimization contexts), are not sufficiently justified. A gap or flaw in this intricate argument would undermine the method's claim to correctly solve the problem by checking containment in P instead of Q_p."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 14139,
      "output": 1385
    }
  },
  {
    "entry_id": 17,
    "retraction_id": "2001.09967v3",
    "paper_id": "2001.09967v2",
    "retraction_comment": "This paper is withdrawn because there is an error in the last section: the algebraic identities, in the limit n-> \\infty, all collapse to the first conservation law. One could wonder whether this can be fixed via a suitable renormalization scheme but at present, the argument is incomplete",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof for Proposition in Section 4.1 supporting Hilbert Transform Identities.",
        "Location": "Page 14, derivation of d/dx (sqrt(1-x^2)(Hf)(x)) and subsequent integration.",
        "Explanation": "The standard identity for differentiating Chebyshev-related terms is d/dx (sqrt(1-x^2)U_{k-1}(x)) = -k T_k(x) / sqrt(1-x^2), where U_k and T_k are Chebyshev polynomials. The paper's formula for d/dx (sqrt(1-x^2)(Hf)(x)) on page 14, stated as (1/sqrt(1-x^2)) Sum_{k=1 to inf} a_k k T_k(x), appears to miss a crucial minus sign. If the correct derivative Sum a_k (-k T_k(x) / sqrt(1-x^2)) is used, the left-hand side of the proposition's identity evaluates to - Integral xf(x)dx. The right-hand side is Integral xf(x)dx. This would imply that the proposition holds only if Integral xf(x)dx = 0, rather than for general functions f as claimed. This undermines the specific 'further evidence' (Proposition on page 13) presented for the conjectured Hilbert transform identity."
      },
      {
        "Problem": "Incorrect derivation of the k=3 conservation law functional J(f(x)).",
        "Location": "Page 11, equations for 'Sum x_i^3' and '3an-3' in terms of power sums, and the resulting functional J(f(x)).",
        "Explanation": "The paper derives a functional J(f(x)) for the k=3 conservation law. The derivation relies on expressing 3a_{n-3} (where a_{n-3} is a coefficient of the polynomial, related to e_3, the third elementary symmetric polynomial of roots) in terms of power sums p_k (Sum x_i^k). The standard identity is 3e_3 = (p_1^3 - 3p_1p_2 + 2p_3)/2. Since a_{n-3} = -e_3, then 3a_{n-3} = -3e_3 = -(p_1^3 - 3p_1p_2 + 2p_3)/2. The paper's expression for 3a_{n-3} (bottom of page 11, 'Rewriting everything in terms of power sums, we obtain') is effectively stated as -p_1^3 + 3p_1p_2 - p_3. The equality -(p_1^3 - 3p_1p_2 + 2p_3)/2 = -p_1^3 + 3p_1p_2 - p_3 is not generally true; it holds if p_1^3 - 3p_1p_2 = 0, which is not true for arbitrary root distributions. This error in the algebraic manipulation makes the specific form of the functional J(f(x)) and thus the k=3 conservation law J(u(t,x)) = (1-t)^3 J(u(0,x)) as presented on page 11 unsound."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 19577,
      "output": 756
    }
  },
  {
    "entry_id": 18,
    "retraction_id": "2003.01493v2",
    "paper_id": "2003.01493v1",
    "retraction_comment": "Theorem 3.3 is not true in general. If it holds, for example, when n=2, we infer that all 2-cluster tilting subcategories are 2Z-cluster tilting, but it can't hold in general",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Missing assumption in Theorem 4.2 (n-abelian Wakamatsu's Lemma).",
        "Location": "Theorem 4.2, page 17, and its proof on page 18.",
        "Explanation": "The proof of Theorem 4.2(1) requires that nE^1(X, X_C) = 0, where X and X_C are objects in the subcategory X. This is derived from the fact that the map (phi)_{*,1}: nE^1(X, X_C) -> nE^1(X, C) is shown to be a monomorphism, and for the sequence in Theorem 4.2(1) to terminate with '-> 0', nE^1(X, X_C) must be the kernel of (phi)_{*,1}, hence nE^1(X, X_C) must be 0. The stated condition that X is 'extension closed' (as defined on p. 17) does not necessarily imply nE^1_A(X, X_C) = 0. A stronger assumption, such as nE^1_A(X,X')=0 for all X,X' in X (akin to nExt^1_A(X,X)=0 in projectively generated categories), appears necessary for the theorem to hold as stated, similar to the assumption in [14, Theorem 6.3]."
      },
      {
        "Problem": "Unjustified assumption about 'good n-pushout' properties in the proof of Lemma 3.2.",
        "Location": "Page 12, Proof of Lemma 3.2, line starting 'Taking good n-pushout...'.",
        "Explanation": "The proof of Lemma 3.2 (case r=s=1, (iii)=>(ii)) states: 'Taking good n-pushout in the sense of [10, Definition-Proposition 2.14], such that f^2, ..., f^n are split monomorphism...'. While n-pushouts exist in n-abelian categories (Jasso [10]), it is not justified that one can always choose an n-pushout representative where these specific maps (f^2, ..., f^n, which are components of the morphism between complexes in the n-pushout diagram) are split monomorphisms. This property, if essential for the subsequent diagram chase (e.g., for deducing d^1 t = 0 from f^1 t = 0), needs explicit justification or a reference confirming its general availability in n-abelian categories."
      },
      {
        "Problem": "Unsubstantiated claims regarding left n-exactness and weak cokernel properties in the proof of Lemma 3.2.",
        "Location": "Page 13, lines 1-3 (Proof of Lemma 3.2, case r=s=1, (iii)=>(ii)).",
        "Explanation": "In the proof of Lemma 3.2, it is asserted that 'the second column is left n-exact'. This 'second column' is not clearly defined from the preceding text, and its left n-exactness is not demonstrated. Subsequently, it is claimed that 'f^1 is a weak cokernel of ua^{n-1}'. While Ker(f^1) = Im(ua^{n-1}) is argued on page 12, this exactness condition alone does not suffice to prove that f^1 is a weak cokernel of ua^{n-1} according to the definition of weak cokernel (which involves factorization of other maps). These claims are crucial for the construction of the n-exact sequence G and the subsequent factorization E = G . (omega mu_F), which are central to the lemma."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 18565,
      "output": 836
    }
  },
  {
    "entry_id": 19,
    "retraction_id": "2005.08379v2",
    "paper_id": "2005.08379v1",
    "retraction_comment": "Figure 1 is incorrect. Will be updated in the revision",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially Biased Country Grouping and Limited Generalizability for Spread Comparison",
        "Location": "Section 3.1, Case Study (Page 4-5); Abstract (Page 1); Section 4 (Page 8)",
        "Explanation": "The division of countries into S1 (higher spread: USA, Italy, Spain) and S2 (lower spread: Sweden, Austria, Belgium) is based on case counts at a specific early point in the pandemic (April 2020) using only three countries per group. The paper states S2 countries were chosen 'at random, namely Sweden, Austria, and Belgium' (Page 4), which is contradictory as they were specifically named. This grouping, especially considering the diverse and evolving pandemic trajectories of these countries (e.g., Sweden, Belgium), may not robustly represent 'lower' vs 'higher' spread in a generalizable way. Conclusions drawn about differences in Twitter activity based on this specific, small, and potentially non-representative grouping are therefore of questionable general validity."
      },
      {
        "Problem": "Exclusion of Neutral Tweets Leading to Potentially Skewed Sentiment Analysis",
        "Location": "Section 3.3, Sentiment Analysis (Page 7); Figure 5 (Page 7)",
        "Explanation": "The methodology states, 'We eliminated tweets with a neutral score of \"0\" to focus purely on tweets with a positive or negative sentiment.' (Page 7). Removing all tweets classified as neutral by TextBlob can significantly distort the overall sentiment landscape. If a substantial portion of the discussion is neutral (e.g., factual information, questions), its exclusion means the analysis is performed only on a more opinionated subset. This can lead to misinterpretation of the actual public sentiment, for instance, when a sentiment score of 0.1 is described as 'close to neutral' after the true neutral baseline (0.0) has been removed from the dataset."
      },
      {
        "Problem": "Ambiguous and Potentially Flawed Algorithm for COVID-19 Content Identification",
        "Location": "Algorithm 1 (Page 4); Section 3.1 (Page 4-5, referencing Algorithm 1 for Figure 3)",
        "Explanation": "Algorithm 1, which is crucial for identifying COVID-19 related trends and tweets for the temporal analysis (Figure 3), contains ambiguities, uses an undefined variable ('Trends' likely meaning 'Terms'), and has syntactical errors (e.g., 'TrList -text.trend' in line 10). The precise logic for how a tweet's text and its associated trend contribute to classifying content as COVID-19 related, and how these classifications populate 'TwList' and 'TrList' for the distinct metrics in Figure 3a and 3b, is not clearly or correctly specified by the pseudocode. This lack of clarity and potential errors in a core data processing step could compromise the validity of the subsequent temporal analysis."
      },
      {
        "Problem": "Unsupported Causal Inferences Regarding Twitter's Influence on Pandemic Spread",
        "Location": "Abstract (Page 1); Introduction, Key Question 2 (Page 1); Section 4, Discussion and Conclusion (Page 8)",
        "Explanation": "The paper suggests that 'awareness through Twitter was useful in influencing the pandemic spread' (Page 1) and that 'effective social media usage can influence public behavior' (Page 1, Page 8). While a disclaimer about correlation versus causation is briefly mentioned in the discussion, the overall framing and several statements lean towards implying a causal impact of Twitter activity on pandemic outcomes. The study's observational and correlational design, based on a limited set of countries during an early phase of the pandemic, cannot adequately support such causal claims, as numerous confounding factors (e.g., government policies, healthcare infrastructure, traditional media, cultural norms) were not controlled for."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 5879,
      "output": 847
    }
  },
  {
    "entry_id": 20,
    "retraction_id": "2408.09172v3",
    "paper_id": "2408.09172v2",
    "retraction_comment": "The model diagram in Figure 1 on page 3 of the paper has significant ambiguities. It may lead readers to mistakenly believe that the experiments were conducted in a multi-turn dialogue format. Therefore, we request the withdrawal of this submission",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mischaracterization of specific outcome patterns (e.g., 011) as 'Uncertainty'.",
        "Location": "Section 3.2 'Uncertainty Category Labeling', Figure 1, Page 4 (definition of 011), Page 6 (discussion of 011 as 'most informative' uncertain type).",
        "Explanation": "The Unc-TTP framework classifies outcome pattern 011 (Incorrect on no-label, Correct on right-label, Correct on wrong-label) as 'Uncertain' and 'Wavering'. However, a model that is initially incorrect, becomes correct when given the true label, and then *maintains correctness despite being presented with a contradictory (wrong) label* demonstrates robustness and an ability to resist misinformation after correction. Labeling this behavior as 'uncertainty' is counterintuitive and potentially misrepresents the model's state. Since 011 is highlighted as a key 'informative' uncertain category, this mischaracterization could undermine the conceptual soundness of what Unc-TTP measures and the explanation for why its selected examples are effective for ICL."
      },
      {
        "Problem": "Underspecified selection method for the 'one-example-for-all' ICL strategy.",
        "Location": "Section 5.1 'Example Selection Details' (page 6-7), references to 'one-example-for-all' (e.g., Page 2).",
        "Explanation": "The paper proposes a 'one-example-for-all' ICL strategy where a single example, chosen based on its Unc-TTP category, is used for all test instances. While it states that 'We choose the one category with the highest accuracy on the validation set', it fails to specify how the *single example* is selected if the chosen optimal Unc-TTP category contains multiple instances from the training/validation set. This omission is a critical methodological gap that affects the reproducibility of the ICL experiments and the precise understanding of how the purportedly superior in-context examples are obtained."
      },
      {
        "Problem": "The prompt in label-injection settings may confound measurement of inherent uncertainty.",
        "Location": "Section 3.1 'The Uncertainty Tripartite Testing Paradigm' (Page 4).",
        "Explanation": "The Unc-TTP method uses a specific, complex prompt for the right-label and wrong-label conditions: '...Despite having to refer to the provided labels, you should still have your own thinking and do not change your stance so easily.' This prompt instructs the LLM to perform a balancing act between adhering to a given label and maintaining its own stance. The paper does not analyze the sensitivity of Unc-TTP classifications to this particular phrasing or explore simpler alternatives. It's possible that the LLM's responses, and thus the resulting uncertainty classifications, are significantly influenced by the cognitive load or conflicting nature of this specific instruction, rather than solely reflecting the model's inherent uncertainty about the task instance. This could mean Unc-TTP measures sensitivity to this prompt type more than general uncertainty."
      },
      {
        "Problem": "The claim that Unc-TTP is 'stricter' and its implications for identifying useful uncertainty are not fully substantiated.",
        "Location": "Page 2 (Summary), Page 6 ('Label interference improves the strictness...'), Figure 3.",
        "Explanation": "The paper argues Unc-TTP imposes a 'stricter' standard for certainty, meaning more instances are classified as 'Uncertain' compared to sampling-based methods (as shown in Figure 3). While a stricter criterion for certainty logically leads to more instances being labeled uncertain, the paper doesn't sufficiently demonstrate that this broader set of 'Uncertain' instances identified by Unc-TTP is inherently more informative or a more accurate reflection of the LLM's actual knowledge boundaries. The superiority in ICL is shown empirically, but the link between this specific notion of 'stricter' (i.e., more inclusive) uncertainty and its utility needs stronger theoretical backing, especially if some categories within 'Uncertain' (like 011) are conceptually misclassified (as per Problem 1)."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 7299,
      "output": 922
    }
  },
  {
    "entry_id": 21,
    "retraction_id": "1207.2800v2",
    "paper_id": "1207.2800v1",
    "retraction_comment": "This paper has been withdrawn by the authors because the proof of Lemma 3.3 has a gap. More precisely, the claim \"If R has a pylonic vertex, v, incident with at least two cables, the pylonicity of v is destroyed by the splitting of any corner\", as stated, is unjustified and looks false in whole generality; the authors overlooked some cases",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect redefinition of 'rod' and 'irreducible' for punctured surfaces.",
        "Location": "Page 4, Section 3, first paragraph (the 'agreement')",
        "Explanation": "The paper makes an 'agreement' that for punctured surfaces S-D (S != S0), an edge 'e is a rod provided e occurs in some non-null-homotopic 3-cycle, and e is a cable otherwise.' This redefines what a 'rod' (unshrinkable edge) is. However, an edge is fundamentally unshrinkable (a rod) if shrinking it creates multiple edges or changes topology. An edge in a null-homotopic, non-facial 3-cycle would create multiple edges upon shrinking, making it a rod by the primary definition (page 3). Under the new 'agreement,' such an edge would be classified as a 'cable.' This redefinition could mean that triangulations considered 'irreducible' under this new agreement might actually contain shrinkable edges (cables by the primary definition), invalidating the concept of irreducibility used and potentially affecting the finiteness proof (Theorem 3.5) and enumeration results for punctured surfaces (e.g., Mobius band in Section 5)."
      },
      {
        "Problem": "Contradictory argument in the proof of Lemma 3.4 regarding boundary edges.",
        "Location": "Page 6, Proof of Lemma 3.4, Case 2",
        "Explanation": "In Case 2 of the proof of Lemma 3.4, it is assumed that 'The length of dD is equal to 3.' The proof then proceeds to 'Assume that there is at least one cable in dD.' However, condition (2.3) on page 3 states: 'e is a boundary edge in the case in which the boundary cycle is a 3-cycle' is an impediment to shrinkability, meaning such an edge is a rod. If the boundary dD is a 3-cycle, its edges are boundary edges and thus should be rods in T, not cables. This contradiction regarding the nature of edges in dD (if they are edges of T) makes this part of the proof of a key lemma unsound. Lemma 3.4 is crucial for establishing the finiteness of irreducible triangulations for punctured surfaces."
      },
      {
        "Problem": "Flawed reasoning in the proof of Lemma 6.1 for pinched torus triangulations.",
        "Location": "Page 13, Proof of Lemma 6.1",
        "Explanation": "The proof of Lemma 6.1 states that if T is an irreducible triangulation of S0[2], then V(T) = {s1, s2} U N(s1) U N(s2). In the proof by contradiction, for a vertex v not in this set, it considers deg(v,T) >= 4. It then claims 'each edge incident with v could only satisfy condition (6.1)' for being a rod. This dismisses conditions (6.2) (edge in a path of length 3 joining s1 with s2) and (6.3) (edge in dSt(si) if it's a 3-cycle) without sufficient justification. An edge incident to v could potentially satisfy (6.2) if v is an internal vertex of such a path, even if v is not a neighbor of s1 or s2. The subsequent argument relying on Kuratowski's Theorem is based on this possibly incorrect premise, weakening the proof of a lemma fundamental to the classification of irreducible pinched torus triangulations (Theorem 6.3)."
      },
      {
        "Problem": "Incorrect argument for non-isomorphism of projective plane triangulations P1 and P2.",
        "Location": "Page 9, paragraph preceding Theorem 4.2",
        "Explanation": "The paper argues for the pairwise non-isomorphism of triangulations in Fig. 2 by stating they 'have pairwise non-isomorphic cable-subgraphs (emphasized by bold lines) except for the pairs: {P1,P2}, ...'. P1 (also referred to as P_R) and P2 are the two irreducible triangulations of the projective plane (stated on page 7). By definition, irreducible triangulations contain no cables. Therefore, their cable-subgraphs are empty. Empty graphs are isomorphic to each other. Thus, the claim that P1 and P2 have non-isomorphic cable-subgraphs is false. While P1 and P2 are indeed non-isomorphic (as later argued by vertex-degree sequences), this specific part of the reasoning is erroneous."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 10052,
      "output": 1009
    }
  },
  {
    "entry_id": 22,
    "retraction_id": "2212.04565v2",
    "paper_id": "2212.04565v1",
    "retraction_comment": "There is an error. Some cases were not considered in the proof of Theorem 1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Corollary 2.2 is incorrect.",
        "Location": "Page 3, Corollary 2.2",
        "Explanation": "The equality stated in Corollary 2.2, N[(gk, hk)] \\ U_{i=1}^{k-1}N[(gi, hi)] = {(c, d) : c ∈ N[gk] \\ U_{i=1}^{k-1}N[gi], d ∈ N[hk]} U {(c, d) : c ∈ N[gk], d ∈ N[hk] \\ U_{i=1}^{k-1}N[hi]}, does not generally hold. An element (c,d) in the left-hand side set means c ∈ N[gk], d ∈ N[hk] and for all i ∈ [1, k-1], (c ∉ N[gi] OR d ∉ N[hi]). This condition is not equivalent to (for all i, c ∉ N[gi]) OR (for all i, d ∉ N[hi]), which is what would be required for (c,d) to be in the right-hand side set. A counterexample can be constructed. This incorrect corollary is a cornerstone of the subsequent proof of Conjecture 1.1."
      },
      {
        "Problem": "The concluding argument in the proof of Conjecture 1.1 is an unsupported assertion.",
        "Location": "Page 4, Proof of Conjecture 1.1, last sentence",
        "Explanation": "The proof of Conjecture 1.1 concludes with the statement: 'Since each element in S is a vertex v = (a,b) ∈ G ⊠ H, and at most γ_gr(G) unique vertices of G are allowed in the first position of any v ∈ S, and at most γ_gr(H) unique vertices of H are allowed in the second position of v, |S| ≤ γ_gr(G)γ_gr(H).' This assertion is not justified by the preceding arguments, which themselves rely on the flawed Corollary 2.3. It is not evident why a sequence S being a Grundy sequence in G ⊠ H imposes such strict limits on the number of unique components from G and H that can appear in S. This statement essentially assumes a key part of what needs to be proven."
      },
      {
        "Problem": "The stated goal of the proof in Section 2 is logically flawed.",
        "Location": "Page 2, Section 2, first paragraph",
        "Explanation": "The paper states: 'In order to prove Conjecture 1.1, we want to show that every ordered sequence of vertices {(gi, hi)}_{i=1}^k in G ⊠ H satisfies |N[(gk, hk)] \\ U_{j=1}^{k-1}N[(gi, hi)]| = 0 for some k ≤ γ_gr(G)γ_gr(H).' If this were true, it would imply that the Grundy domination number of G ⊠ H is less than γ_gr(G)γ_gr(H), which contradicts Proposition 1.2 (γ_gr(G ⊠ H) ≥ γ_gr(G)γ_gr(H)) unless in very specific cases. To prove γ_gr(G ⊠ H) ≤ γ_gr(G)γ_gr(H), one must show that any sequence of length k > γ_gr(G)γ_gr(H) (e.g., k = γ_gr(G)γ_gr(H) + 1) is not a Grundy sequence (i.e., the condition fails for some element in such a sequence)."
      },
      {
        "Problem": "An incorrect set equality is used in the proof of Lemma 2.1.",
        "Location": "Page 3, near the top, the line starting 'Note that (B ∩ D) U (C ∩ D) = ...'",
        "Explanation": "In the proof of Lemma 2.1, it is claimed that (B ∩ D) U (C ∩ D) = {(c, d) : c ∈ N[g1] \\ N[g2], d ∈ N[h1]}. Given B ∩ D = {(c, h₁) : c ∈ N[g1] \\ N[g2]} and C ∩ D = {(c, d) : c ∈ N(g₁) \\ N[g2], d ∈ N(h₁)}, this equality does not hold in general. For example, if g1 ∉ N[g2] and h1 has neighbors other than itself (i.e., N(h1) is non-empty), then elements (g1, d) where d ∈ N(h1) are in the right-hand set but not in the left-hand set because g1 ∉ N(g1). While the statement of Lemma 2.1 itself is correct (interpreting N[(x,y)] as N[x] x N[y]), this flaw in its proof is significant as the proof methodology seems to be extended, incorrectly, to Corollary 2.2."
      },
      {
        "Problem": "The derivation of the inequality in Corollary 2.3 is unsound.",
        "Location": "Page 3, Corollary 2.3 and its proof",
        "Explanation": "The proof of Corollary 2.3 states that |N[(gk, hk)] \\ U_{i=1}^{k-1}N[(gi, hi)]| = |(N[gk] \\ U_{i=1}^{k-1}N[gi], N[hk]) U (N[gk], N[hk] \\ U_{i=1}^{k-1}N[hi])|, based on Corollary 2.2. It then applies the union bound |A U B| ≤ |A| + |B|. Since Corollary 2.2 (the equality) is incorrect, this derivation of the inequality in Corollary 2.3 is invalid. The inequality itself might be true or false, but the justification provided is critically flawed."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 17787,
      "output": 1336
    }
  },
  {
    "entry_id": 23,
    "retraction_id": "2209.08741v2",
    "paper_id": "2209.08741v1",
    "retraction_comment": "This manuscript has been withdrawn by the authors. Condition (B) needs to be modified for the proofs to work",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Applicability of Theorem 2.3 in the proof of Theorem 1.1 (planar case).",
        "Location": "Proof of Theorem 1.1, page 14; relies on proof of Theorem 1.4, page 10; which uses Theorem 2.3, page 9.",
        "Explanation": "Theorem 1.1 deals with planar domains (n=1) and Gaussian curvature -2 (implying c^2=2). The proof of Theorem 1.1, Part 1, refers to the proof method of Theorem 1.4, Part 1. The latter relies on Theorem 2.3, which states that a domain Ω is biholomorphic to a ball if and only if a condition involving the diastasis function blowing up holds AND the dimension n satisfies n = 2/c^2 - 1. For n=1 and c^2=2, this dimensional condition becomes 1 = (2/2) - 1 = 0, which is a contradiction. This makes the cited proof path for establishing the biholomorphism to a disc (possibly less a polar set) in Theorem 1.1 unsound, as Theorem 2.3 is not applicable under these specific dimensional and curvature constraints."
      },
      {
        "Problem": "Ambiguity in the definition and role of the pluripolar set E in Theorem 1.4.",
        "Location": "Theorem 1.4 statement (page 4) and its proof, particularly page 10.",
        "Explanation": "Theorem 1.4 states that T(z) maps Ω to a ball 'possibly less a relatively closed pluripolar set E'. The proof constructs a larger domain Ω~ = Ω ∪ (∪_j P_j) (where P_j = U_j \\ Ω are pluripolar sets) such that Ω~ is biholomorphic to a full ball B_0. Thus, Ω is biholomorphic to B_0 \\ T(∪_j P_j). The paper then defines 'E := ∪_j P_j = ∪_j U_j ∩ ∂Ω = Ω~ ∩ ∂Ω' (page 10). This definition of E appears to describe a set within Ω~ or related to ∂Ω, rather than clearly identifying the set T(∪_j P_j) that is removed from the target ball B_0. This creates confusion regarding what the set E in the theorem's conclusion precisely represents."
      },
      {
        "Problem": "Discrepancy in Lemma 3.1 concerning the relationship between |T'(z)| and |K(z,p)|.",
        "Location": "Lemma 3.1 (page 13) and its proof; also related to formula (3.3) on page 14.",
        "Explanation": "Lemma 3.1 states |T'(z)| ≤ (2π/g(p)) |K(z,p)|. The derivation steps in its proof lead to |T'(z)| ≤ sqrt(2π / (g(p)K(p,p))) |K(z,p)|. While the stated inequality is a valid consequence of this derived one (given g(p) ≤ 2πK(p,p) by Suita's inequality), it is not the direct result. More significantly, if the Bergman representative coordinate T(z) is normalized such that T'(p)=1 (as assumed in the proof of Corollary 1.2, page 14), and given that for domains biholomorphic to a disc with constant curvature Suita's inequality becomes an equality (K(z,z) = g(z)/(2π)), then formula (3.3) implies an equality: |T'(z)| = (2π/g(p))|K(z,p)|. The lemma's statement as an inequality, and the specific coefficient used, could be misleading or lack precision if an equality is expected under typical normalizations and conditions."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 20760,
      "output": 877
    }
  },
  {
    "entry_id": 24,
    "retraction_id": "1603.02871v2",
    "paper_id": "1603.02871v1",
    "retraction_comment": "Problems in the proof....specifically maximal pivotality. The estimates on the number of pivotal edges is fine",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Insufficient justification for establishing positive probability of local events from global conditions without ergodicity.",
        "Location": "Proof of Proposition 1 (Page 6, last sentence of proof) and Proof of Lemma 2 (Page 7, last two sentences of proof before the black square).",
        "Explanation": "The proofs of Proposition 1 and Lemma 2 rely on a key step: if a global condition on the number of infinite clusters holds (e.g., Pp(N>=3)>0 or Pp(N=2)>0, implying events F_L or E_M intersect F_M^c occur with positive probability), then a specific local structure (trifurcation at the origin, or edge e0 being pivotal for A={N=1}) can be made to occur with a strictly positive probability (ε1 or ε0 respectively). This is achieved by 'changing the configuration inside' a large box B_L or B_M, conditional on the external configuration. For the argument to hold, the conditional probability of forming the local structure must be bounded below by some δ > 0, uniformly for all relevant external configurations. This uniformity and the strictly positive nature of this probability (ε1 or ε0) are asserted without detailed justification. While such 'sprinkling' or 're-wiring' arguments are common in percolation, their rigorous establishment, especially when trying to avoid ergodicity arguments (which often simplify averaging over external configurations), requires careful demonstration that is not fully provided."
      },
      {
        "Problem": "Relationship between global pivotality (He1) and local event (TM(e1)) in variance bound.",
        "Location": "Page 8, discussion around Eq (14) and (15), specifically the statement 'TM(e1) intersect A12 decreases to He1', and its use in Page 9, Eq (17).",
        "Explanation": "The proof of Lemma 3 (variance bound) relies on approximating the global event He1 (edge e1 is pivotal for A={N=1}) with a local event TM(e1) defined within a box B'_M(e1). The argument uses 'TM(e1) intersect A12 decreases to He1', which implies He1 is a subset of TM(e1) (on event A12, for large M). This inclusion (He1 => TM(e1)) is necessary to justify Pp(He1 intersect He2) <= Pp(TM(e1) intersect TM(e2)) (used in step (17) on page 9). While the implication He1 => TM(e1) appears plausible upon detailed check of definitions (as global pivotality should ensure paths exist and reach the boundary of any large box containing e1), the paper asserts this relationship without explicit proof. Given its centrality to the variance estimate, a more detailed justification of this convergence and its consequences for the probability inequalities would strengthen the argument."
      },
      {
        "Problem": "Conciseness of the argument for Lemma 4(i) regarding the structure of pivotal sets.",
        "Location": "Page 9, Proof of Lemma 4 (i).",
        "Explanation": "Lemma 4(i) states that if N=2 and the maximally pivotal set Pe(ω) (associated with edge e) is non-empty, then Pe(ω) is identical to En(ω), the set of all pivotal edges in Bn. The proof involves showing Pe ⊆ En and En ⊆ Pe. The argument for En ⊆ Pe relies on the set En itself being jointly pivotal, and Pe being the maximal jointly pivotal set containing e (if e is in En). While the steps appear logically sound if the premise (En is jointly pivotal) holds, the argument is very condensed. This lemma implies a strong structural property: if N=2, all pivotal edges belong to a single, unique maximal pivotal set. Given the importance of this structural property for identifying #Pe0 with Xn in the main contradiction, a more expansive justification would be beneficial."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 18147,
      "output": 872
    }
  },
  {
    "entry_id": 25,
    "retraction_id": "1110.2623v5",
    "paper_id": "1110.2623v4",
    "retraction_comment": "This paper has been withdrawn since a necessary condition for the existence of an asymptotically cylindrical Calabi-Yau metric on W_1 is in fact not satisified",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed construction of admissible pairs in Section 6 of the original paper.",
        "Location": "Section 6 (particularly pages 17-18, claim that D is anti-canonical) and Erratum, Appendix A (page 35).",
        "Explanation": "The paper's original construction of admissible pairs (W,D) for K3 surfaces with non-symplectic automorphisms of prime order p > 2 (Section 6) claims that the divisor D is anti-canonical in the threefold W. The erratum (Appendix A) correctly points out that this claim is false for p > 2. Specifically, the condition L(D)^k = K_W^{-l} implies k/l = -2/p, which is not k=l=1 as required for D to be anti-canonical when p is not -2. This invalidates the primary building blocks (admissible pairs) for the G2-manifold construction for p > 2 as presented in the main body of the paper."
      },
      {
        "Problem": "The erratum's proposed new construction of admissible pairs (Appendix B) appears to be flawed.",
        "Location": "Erratum, Appendix B, Step 3 (page 36).",
        "Explanation": "The erratum proposes a new multi-step construction for admissible pairs. In Step 3, it claims that for a p-fold cover pi: W' -> W_0, the divisor D' := pi^{-1}(D_0) is an anti-canonical divisor of W'. However, using standard canonical bundle formulas for cyclic covers (K_{W'} = pi^*(K_{W_0}) + ((p-1)/p)D') and the erratum's preceding assertion that L(D_0) = (K_{W_0})^{-p} (meaning D_0 represents -p K_{W_0}), the condition for D' to be anti-canonical in W' (i.e., D' represents -K_{W'}) leads to a contradiction (p=1), unless K_{W_0} is numerically trivial (which is not the case here). This suggests the erratum's proposed fix for constructing admissible pairs for p > 2 is itself incorrect, undermining the paper's main claims even with the erratum."
      },
      {
        "Problem": "Unsoundness of Theorem 7.7 in the original paper for constructing G2-manifolds.",
        "Location": "Theorem 7.7 (pages 29-31) and its proof, particularly its reliance on Section 6.",
        "Explanation": "Theorem 7.7 provides conditions for matching an admissible pair (W1, D1) of non-symplectic type (with p1=3, constructed via Section 6) with a Fano-type pair (W2, D2) to build a G2-manifold. Since the construction of (W1, D1) from Section 6 is flawed (as D1 is not anti-canonical, see Problem 1), W1 is not an admissible pair as required by Kovalev's theory (Theorem 2.3). Therefore, the premise of Theorem 7.7 is not met for the W1 used in the original paper, rendering the theorem's conclusions about constructing G2-manifolds from these specific components unsound. The erratum (Appendix D) acknowledges this by proposing to replace W1, but this relies on the erratum's new construction (see Problem 2)."
      },
      {
        "Problem": "The paper's main conclusions about constructing new G2-manifolds with specific large Betti numbers are unsubstantiated.",
        "Location": "Section 7 (e.g., Theorem 7.9, examples on pages 32-34) and Erratum, Appendix D (page 38).",
        "Explanation": "The explicit examples of G2-manifolds and their calculated Betti numbers (e.g., b^2=42 claimed to be new) are derived from applying Theorem 7.7, which in turn relies on the construction of admissible pairs. Given that the original construction of these pairs for p>2 is flawed (Problem 1) and the erratum's proposed fix also appears flawed (Problem 2), the existence and properties of these G2-manifolds are not rigorously established. The claims in both the original paper and the erratum (Appendix D) about new G2-manifolds with Betti numbers exceeding previously known values are therefore unsubstantiated."
      }
    ],
    "token_usage": {
      "input": 10444,
      "thinking": 10059,
      "output": 991
    }
  },
  {
    "entry_id": 26,
    "retraction_id": "1307.5957v4",
    "paper_id": "1307.5957v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent formulation of NLS, its associated conserved energy, and Lagrangian.",
        "Location": "Eq. (1.1), Eq. (2.7), Eq. (3.1)",
        "Explanation": "Equation (1.1) presents the focusing NLS: `i u_t + Δu = |u|^2 u`. The energy functional in Eq. (3.1), `L(u) = ∫ (1/2 |∇u|^2 - 1/4 |u|^4) dx`, is consistent with this focusing NLS (if L(u) is interpreted as the Hamiltonian). However, the conserved energy defined in Eq. (2.7) is `E = ∫ (1/2 |∇u|^2 + 1/4 |u|^4) dx`, which corresponds to the defocusing NLS (`i u_t + Δu = -|u|^2 u`). This fundamental contradiction regarding the sign of the nonlinearity affects any conclusions drawn."
      },
      {
        "Problem": "Incorrect action functional for the NLS equation.",
        "Location": "Eq. (3.5), p. 4",
        "Explanation": "The action `S(u(t,x))` defined in Eq. (3.5) as `∫∫ (1/2 |∇u|^2 - 1/4 |u|^4) dx dt` is not the correct action functional for the time-dependent NLS equation. It is missing the crucial kinetic term involving time derivatives of `u` (e.g., `(i/2)(u ū_t - ū u_t)`). Applying the variational principle to this action would yield an elliptic equation (`Δu - |u|^2 u = 0`), not the NLS equation (1.1). This invalidates any discussion of deriving NLS from this action."
      },
      {
        "Problem": "Fundamentally flawed application of Lagrangian mechanics in Proposition 3.1.",
        "Location": "Section 3, Proposition 3.1 (Eqs. (3.1)-(3.4)), pp. 3-4",
        "Explanation": "Proposition 3.1 attempts to derive an equation of motion (3.2) for a coordinate `x(t)` by applying the Euler-Lagrange equation for a point particle (3.3) to the NLS energy functional (3.1), mistakenly treating the latter as a particle Lagrangian `L(x, ẋ)`. This is a category error, as (3.1) is a functional of the field `u(t,x)`. The resulting equation (3.2), `∂_{tt}x ||u(x)||_{L^2(R)}^2 = -1/4 ∫|u(x)|^4 dx`, is ill-defined and its derivation is incorrect, indicating a misunderstanding of Lagrangian field theory versus particle mechanics."
      },
      {
        "Problem": "Incorrect definition of the stress tensor component `F_{jk}`.",
        "Location": "Eq. (2.3), p. 2",
        "Explanation": "The definition of `F_{jk}` includes the term `- (1/4) δ_{jk} Δ(|u(t,x)|^2)`, where `Δ` is the Laplacian operator. This term, involving second spatial derivatives of `|u|^2`, is not standard in the stress-energy tensor for NLS and is likely incorrect. If `F_{jk}` is incorrect, the claimed conservation law `∂_t F_{j0} + ∂_{x_k} F_{jk} = 0` (Eq. 2.4) may not hold, undermining results based on it."
      },
      {
        "Problem": "Inconsistent specification of spatial dimension `d` and related mathematical setup.",
        "Location": "Abstract (p.1), Eq. (1.1) (p.1), and initial condition statement for `u_0` (p.1)",
        "Explanation": "The paper states a focus on one dimension (`d=1`) in the abstract and subsequent sections. However, the NLS equation (1.1) is written with a Laplacian `Δ_{R^{d+1}}u`. For a function `u: R × R^d → C`, the Laplacian should act on `R^d`, i.e., `Δ_{R^d}u`. Furthermore, the initial condition `u_0(x)` is stated to be in `H_x^1(R^2)`, which implies `d=2`. These inconsistencies in the fundamental problem setup (PDE and initial data space) make it unclear what system is being studied and undermine the coherence of the analysis."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 8909,
      "output": 1040
    }
  },
  {
    "entry_id": 27,
    "retraction_id": "2211.05302v2",
    "paper_id": "2211.05302v1",
    "retraction_comment": "We just noted the explanation on phase retardation was incorrect and accordingly, the inhibition mechanism of zeroth-order light was not properly elucidated. We will submit a revised version soon",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental Misunderstanding or Misrepresentation of Vc, Vo, and Δφ in SLM Operation",
        "Location": "Page 1, description of Eq. (1); Page 2, Eq. (5) and surrounding text",
        "Explanation": "The paper defines Vc as 'threshold voltage (Dark voltages)' and Vo as 'excess voltage (Bright voltages)' in the context of Eq. (1). Equation (1) describes intrinsic liquid crystal (LC) behavior, where Vc is an LC threshold and Vo is a parameter related to the steepness of the voltage-response curve. These are typically not the user-settable 'Bright' and 'Dark' voltages of an SLM driver, which define the 0 and 2π phase points. The paper does not clarify how adjusting user-settable 'Bright/Dark' voltages would modify the intrinsic Vc and Vo of Eq. (1). Furthermore, Δφ, the phase retardation derived from Eq. (1) and (3), is described as a 'contamination' in the context of T = Tc + Δφ (Eq. 5), where Tc is the designed phase. However, Δφ(V) is the fundamental phase modulation mechanism of the SLM; it's how Tc is realized. This apparent contradiction suggests a misunderstanding of how SLMs generate phase patterns and what the parameters Vc, Vo, and Δφ physically represent in the model used, undermining the soundness of the proposed optimization method."
      },
      {
        "Problem": "Unclear Physical Mechanism for Zeroth-Order Elimination from 'Pixelation Effect'",
        "Location": "Page 1, Abstract & Introduction; Page 4, Discussion of results",
        "Explanation": "The paper claims its primary achievement is eliminating zeroth-order light 'caused by the pixelation effect of SLM' by adjusting Vc and Vo. The 'pixelation effect' typically refers to diffraction from the SLM's discrete pixel structure and inter-pixel gaps. The paper does not provide a clear physical mechanism explaining how tuning global phase response parameters Vc and Vo (as defined in Eq. 1, which affect the overall voltage-to-phase curve) specifically counteracts or eliminates the zeroth-order diffraction arising from these fixed structural characteristics of the SLM. While optimizing phase modulation fidelity can improve diffraction efficiency and reduce unwanted light, the direct causal link to mitigating the 'pixelation effect' component of the zeroth order via the described Vc/Vo adjustment is not established, making the central claim about zeroth-order elimination poorly substantiated."
      },
      {
        "Problem": "Inconsistent and Contradictory Definition of 'Default' SLM Parameters (Vc and Vo)",
        "Location": "Page 3, first paragraph, and Figure 2 caption",
        "Explanation": "There is a direct contradiction in the stated 'default values' for Vc and Vo, which are critical for establishing the baseline performance and understanding the optimization strategy. The text on page 3 states the default values are 'Vc = 6.19 and Vo = 0.03'. In contrast, the caption for Figure 2(a) (and Fig 2(a1)) states, '(a) Vo = 6.19 and Vc = 0.03 are the default values from the manufacture'. The roles of Vc and Vo are swapped between these two statements. This inconsistency makes it impossible to reliably interpret the optimization process (e.g., 'properly increasing Vc and decreasing Vo from their default values') and assess the reported improvements relative to a well-defined baseline. Such a discrepancy in fundamental parameters raises concerns about the reliability and carefulness of the study's presentation."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 6186,
      "output": 795
    }
  },
  {
    "entry_id": 28,
    "retraction_id": "1910.05809v3",
    "paper_id": "1910.05809v2",
    "retraction_comment": "Need to fix some error in the paper. In the last step of the proof, the hypersurface of the minimal principle curvature equal to zero may be tangent to the boundary of the domain",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear or potentially flawed contradiction argument in the proof of Theorem 1.1.",
        "Location": "Page 9, lines 1-5, concluding paragraph of the proof of Theorem 1.1.",
        "Explanation": "The proof of Theorem 1.1 (strict convexity) concludes by arguing that if the smallest principal curvature K_1 of the graph Σ^T is zero at a boundary point P ∈ Γ^T, a contradiction arises. The argument states: \n1. The Hopf boundary point lemma implies |∇K_1(P)| ≠ 0, so Λ = {K_1=0} is a smooth hypersurface.\n2. It is claimed that \"Λ is transversal to Γ^T at P since u^T_n(P) > 0\".\n3. This transversality is then used to imply that Λ enters Ω^T, leading to K_1=0 at interior points, which contradicts that rank(D²u^T) = n in Ω^T (meaning K_1 > 0 in Ω^T).\n\nThe critical step \"Λ is transversal to Γ^T at P since u^T_n(P) > 0\" is not standard and its justification is missing. Standard application of the Hopf lemma to the derived inequality Δ_{Σ^T} K_1 ≤ 0 (or Δ_{Σ^T} K_1 + C(x)K_1 ≤ 0 with C(x)>0, K_1(P)=0, K_1>0 in Ω^T) implies ∂K_1/∂n_outward(P) > 0. This means K_1 increases as one exits Ω^T, which is not in itself a contradiction to K_1 > 0 inside Ω^T. The paper's argument for transversality and the subsequent contradiction needs further substantiation or clarification, as it is pivotal to the main result."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 18516,
      "output": 426
    }
  },
  {
    "entry_id": 29,
    "retraction_id": "1108.1348v2",
    "paper_id": "1108.1348v1",
    "retraction_comment": "Withdrawn because of a crucial error in eq.(15)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unchecked Hamiltonian Constraint for B≠0, n≠0 Asymptotic Solutions",
        "Location": "Page 9, first paragraph of Section 3.3 (after eq. 29)",
        "Explanation": "The paper states: 'Additionally, we have not checked if solutions with the above asymptotic behavior of Eq. (30) indeed satisfy the Hamiltonian constraint.' The derived asymptotic solution for n(r) (Eq. 30) and the subsequent calculation of the Newtonian potential (Eq. 31) showing problematic oscillations are central to the argument against recovering Newtonian physics for B≠0, n≠0 when A is independent. If this asymptotic solution does not satisfy the Hamiltonian constraint (Eq. 13, which includes both kinetic term T and potential V), it is not a valid physical solution of the theory. This omission means a key part of the paper's argument for this case is unproven and potentially invalid."
      },
      {
        "Problem": "Applicability of the Oscillating Potential Argument in the λ→1 Limit",
        "Location": "Page 9, Eq. (31) and Page 10, Eq. (32) and surrounding discussion",
        "Explanation": "The paper argues that for B≠0, λ≠1, the potential φ(r) exhibits 1/r oscillating terms (Eq. 31), preventing Newtonian recovery. This potential is derived from an asymptotic expansion for n(r) (Eq. 26, 30) stated to be valid for r >> r_c, where r_c ~ B/(λ-1). As λ→1, r_c→∞. This implies that for any fixed r, the region of validity for this asymptotic expansion (and thus for the oscillating potential Eq. 31) vanishes in the λ→1 limit. While the paper then argues that n(r)→0 in this limit (also non-Newtonian), the prominent argument relying on Eq. (31) for oscillations as the reason for non-recovery of Newtonian physics is not applicable in the strict λ→1 limit. This weakens the specific argument based on oscillations for this limit."
      },
      {
        "Problem": "Unaddressed Issues with the Potential Term V for B≠0 Solutions",
        "Location": "Implicit in Section 3.3; explicitly mentioned for B≠0 cases on Page 6, paragraph 2 of Section 3.2 (referring to Ref. [10])",
        "Explanation": "The paper mentions (citing Ref. [10]) that for B≠0, the potential term V in the action can blow up at r→0, potentially requiring an unphysical lower bound in space to satisfy the Hamiltonian constraint. Section 3.3 analyzes B≠0, n≠0 solutions without explicitly addressing the form of V or how this potential issue is resolved for the proposed asymptotic solutions. The Hamiltonian constraint (Eq. 13) involves both the kinetic term T (derived from n(r)) and V. If V is inherently problematic for all B≠0 solutions (e.g., requiring unphysical conditions or preventing well-behaved solutions), then the entire analysis of Sec 3.3 might be based on unphysical grounds, irrespective of the specific asymptotic form of n(r) or the check of T against the Hamiltonian constraint."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 15250,
      "output": 725
    }
  },
  {
    "entry_id": 30,
    "retraction_id": "1505.02494v2",
    "paper_id": "1505.02494v1",
    "retraction_comment": "This paper has been withdrawn by the author due to crucial sign errors in Theorem 5 and equation (10)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the bound on the number of λ-solutions in Theorem 1.",
        "Location": "Page 6, Theorem 1, and Page 7, line 3.",
        "Explanation": "The derivation of the bound for the (GEiCP-T)_J, based on the steps shown and Lemma 1, leads to the expression `(nm - n + |J|) m^{n-|J|-1} (m-1)^{|J|-1}` (or equivalently `(m|J| + m|Jbar| - |Jbar|) m^{|Jbar|-1} (m-1)^{|J|-1}` which is `(mn - |Jbar|) m^{|Jbar|-1} (m-1)^{|J|-1}`). However, the paper states the final bound as `(mn - |J|)m^{|J|-1}(m-1)^{n-1-|J|}`. These expressions are not equivalent. Consequently, the claimed bound for the EiCP-T (where J=[n], so |J|=n and |Jbar|=0) of `nm^{n-1}` (stated on page 7, line 3) is also likely incorrect; the derivation suggests it should be `n(m-1)^{n-1}`."
      },
      {
        "Problem": "The formula for the Hessian H(x) of the Rayleigh quotient λ(x) in Equation (10) appears incorrect or non-standard.",
        "Location": "Page 14, Equation (10).",
        "Explanation": "The provided formula for H(x) seems to differ from established derivations of the Hessian for a tensor Rayleigh quotient, such as Equation (3.7) in Kolda & Mayo (2014) [Ref 10 of the paper]. An incorrect Hessian formula would invalidate the method for choosing the shift parameter α in Algorithm 2 (Step 1), which is crucial for ensuring local convexity of the shifted objective function `tilde_f(x)` and for the algorithm's convergence analysis (Theorem 9)."
      },
      {
        "Problem": "The proof of Theorem 7, which establishes an ascent property for a projected gradient step, is flawed or insufficiently justified.",
        "Location": "Page 13, Theorem 7.",
        "Explanation": "Theorem 7 aims to show that if f(x) is convex in a neighborhood Σ of w, and v = d(w)/||d(w)|| (where d(w) is the projected gradient and v ∈ Σ, v != w), then f(v) - f(w) > 0. The proof uses the inequality `f(v) - f(w) >= ∇f(w)^T(v-w)` and states that `∇f(w)^T(v-w) = ||d(w)|| - ∇f(w)^T w`. For the theorem to hold, it must be shown that `||d(w)|| - ∇f(w)^T w > 0`. This crucial step is not adequately demonstrated in the proof. A flaw here undermines Lemma 4 and the subsequent convergence arguments for Algorithm 2, which rely on this ascent property."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 20149,
      "output": 714
    }
  },
  {
    "entry_id": 31,
    "retraction_id": "1504.07542v2",
    "paper_id": "1504.07542v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial sign error in equation 9",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Ginzburg-Landau free energy form",
        "Location": "Page 4, Eq. (21) and related discussion; Eq. (1)",
        "Explanation": "The Ginzburg-Landau free energy in Eq. (21) includes a term `2u|Ψ|`, linear in the order parameter `|Ψ|`. This term is attributed to the external pair potential `H_ext`. However, the expectation value of `H_ext` as defined in Eq. (1) (`H_ext = v Σ_k (Δ⁺ a_k a_{-k} + Δ a_{-k}⁺ a_k⁺)`) is proportional to `|Δ|^2` (i.e., `|Ψ|^2`), not `|Δ|`. Specifically, `<H_ext> = 2v(V/U_{ph})|Δ|^2`. A term quadratic in `|Δ|` would renormalize the coefficient `a` in the GL expansion, rather than introducing a term linear in `|Δ|`. A linear term implies an external field directly conjugate to `Δ`, which `H_ext` from Eq. (1) is not. This incorrect form of the free energy invalidates the subsequent derivations of `Ψ_0`, `Hc`, `λ`, `χ`, and `Hc1` (Eqs. 26-31)."
      },
      {
        "Problem": "Constraint on gap for positive external potential (v > 0)",
        "Location": "Page 1, Eq. (3) and its discussion",
        "Explanation": "The self-consistency equation (3) requires its right-hand side to be positive (since LHS is 1 and `g>0`). The integral part is positive. Thus, the prefactor `(1-v/|Δ|)` must be positive. If `v > 0`, this means `v/|Δ| < 1`, or `|Δ| > v`. This implies that the gap `|Δ|` must always be greater than `v`. This prevents `|Δ|` from approaching zero if `v` is finite and positive, making the concept of a critical temperature `Tc` (where `Δ(Tc)=0` for a second-order transition) and the statement that `v>0` 'suppresses superconductivity' ill-defined or requiring a first-order transition where `Δ` jumps from a value `>v` to 0."
      },
      {
        "Problem": "Unjustified claim of infinite Hc2",
        "Location": "Page 6, first paragraph; Ginzburg-Landau equations on page 5 (Eqs. 22-25, 28)",
        "Explanation": "The paper claims on page 6 that 'the second critical magnetic field Hc2 is infinity formally ... if temperature is T < T_c^*'. However, the Ginzburg-Landau (GL) theory presented (Eqs. 21-25) leads to a finite `Hc2 = Φ_0/(2πξ^2)`. According to Eq. (28), `ξ^2 = ħ^2/(4ma)`. For `T < Tc`, `a < 0`, so `ξ` is real and finite (diverging only at `Tc`). Even if `ξ` were to diverge at `T_c^*`, `Hc2` would diverge at `T_c^*`, not be infinite for all `T < T_c^*`. The claim of infinite `Hc2` for `T < T_c^*` is not supported by the provided GL formalism and contradicts its standard results unless `ξ=0`, which is unphysical."
      },
      {
        "Problem": "Inconsistent temperature dependence of Hc1",
        "Location": "Page 5, Eq. (31), also (29), (30)",
        "Explanation": "The derived temperature dependence of `Hc1` in Eq. (31), `Hc1 ~ (1-T/T_c^*)^2`, is inconsistent with the standard formula `Hc1 ≈ (Φ_0/(4πλ^2)) ln χ` (for large `χ`) and the paper's own expressions for `λ` (Eq. 29: `λ ~ (1-T/T_c^*)^{-1}`) and `χ` (Eq. 30: `χ ~ (1-T/T_c^*)^{-1}`). Using the paper's expressions, `1/λ^2 ~ (1-T/T_c^*)^2` and `χ ~ (1-T/T_c^*)^{-1}`. Substituting these into `Hc1 ~ (ln χ)/λ^2` yields `Hc1 ~ -ln(1-T/T_c^*) * (1-T/T_c^*)^2`. If the approximation `Hc1 ~ χ/λ^2` is used (as suggested by the text 'Hc1 = Φ_0/(4πλ^2) κ'), then `Hc1 ~ (1-T/T_c^*)^{-1} * (1-T/T_c^*)^2 = (1-T/T_c^*)`. Both results differ from the claimed `(1-T/T_c^*)^2` dependence in Eq. (31)."
      },
      {
        "Problem": "Problematic asymptotic behavior of gap Δ for v > 0 at high temperatures",
        "Location": "Page 1, Eq. (3) and Eq. (4)",
        "Explanation": "The derivation of `|Δ(T → ∞)| = gω|v|/(2T)` (Eq. 4) from Eq. (3) is problematic for `v > 0`. For Eq. (3) to be valid, `1-v/|Δ|` must be positive. If `v > 0`, this requires `|Δ| > v`. This condition prevents `|Δ|` from approaching zero as `T → ∞` (as implied by Eq. 4). If `|Δ|` indeed tends to zero, then `1-v/|Δ|` would become large and negative for large `T`, invalidating the starting equation (3). While Eq. (4) is consistent for `v < 0`, its application or derivation for `v > 0` is unsound due to the `|Δ| > v` constraint."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 19056,
      "output": 1425
    }
  },
  {
    "entry_id": 32,
    "retraction_id": "2012.10766v4",
    "paper_id": "2012.10766v3",
    "retraction_comment": "Propositions 3 and 4 are incorrect, and so is their proof. The proof requires the shifted convolution problem for the coefficients of the cusp forms, which is not presented here. The definition of the mollifier M(f,s) is wrong. It needs to be defined as a convolution inverse of the Fourier coefficients of the automorphic forms",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and critically flawed definition/usage of the auxiliary Dirichlet series P(f,s).",
        "Location": "Page 5 (definition of P(f,s)), Page 9 (definition of P_0(f,s) and usage in Lemma 3 for Proposition 2), Page 11-12 (proof of Proposition 3, Lemma 4).",
        "Explanation": "The paper defines P(f,s) on page 5 as sum_{2<n<=X} lambda_f(n)/(n^s log n). Proposition 2 states that R(P(f,s)) is normally distributed with variance ~1/2 log log T. However, the proof of Proposition 2 (via Lemma 3, page 9-10) calculates moments for P_0(f,s) = sum_{p<X} lambda_f(p)/p^s, and this P_0(f,s) is the quantity that would have the stated variance. The P(f,s) defined on page 5 would have variance O(1), which cannot lead to the Central Limit Theorem for log|L(f,s)|. Similarly, Lemma 4 (page 12), used in proving Proposition 3, states |P_1(f,s)| <= log log T, which holds if P_1 is part of P_0(f,s) (sum over primes without log p in denominator), not P(f,s) as defined on page 5. This fundamental inconsistency in the definition and properties of P(f,s) undermines the core arguments for Theorem 1."
      },
      {
        "Problem": "Contradictory and potentially insufficient justification for Lemma 7, a key integral evaluation for Proposition 4.",
        "Location": "Page 17 (statement of Lemma 7), Page 20 (Remarks on Proposition 4 proof).",
        "Explanation": "Lemma 7 provides a formula for I(h,k), a general shifted moment of L-functions, which is crucial for proving Proposition 4 (that L(f,s)M(f,s) ~ 1). On page 17, the paper claims Lemma 7 can be proven by 'a similar proof of Theorem 1.1 of [11]' (Hughes & Young, for zeta functions). However, on page 20, it states 'we can not follow the calculation of [11]' and that 'The error term calculation follows from [14]' (Kühn, Robles, Zeindler). This direct contradiction regarding the provenance and proof of Lemma 7 makes its validity in this context questionable. If results from [14] are used, it must be ensured that they apply to the specific setup and parameters of Lemma 7, which is not made clear."
      },
      {
        "Problem": "Potentially unjustified application of mean value results for L(f,s)M(f,s) with the specific mollifier M(f,s) used.",
        "Location": "Page 14 (Proof of Proposition 4, lines 1-5), Page 5 (definition of a(n) for M(f,s)).",
        "Explanation": "Proposition 4 requires showing (1/T) integral |1 - L(f,s)M(f,s)|^2 dt = o(1). This typically involves showing (1/T)integral L M dt = 1 + o(1) and (1/T)integral |L M|^2 dt = 1 + o(1). The paper claims the first part as 'T + O(T^{1/2+epsilon})' (page 14), implying the sum of diagonal terms is 1. However, the mollifier M(f,s) uses a specific coefficient a(n) (defined on page 5 with sharp cutoffs on prime factor counts). It is not shown that this specific a(n) leads to the required sum (sum_n mu(n)a(n)|lambda_f(n)|^2/n^{2sigma_0}) being 1. Standard results for mollifiers (e.g., from [11] or [14]) often use different mollifier constructions (e.g., with smooth polynomial weights). Applying results from these references without verifying compatibility with the paper's specific M(f,s) is a potential gap."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 17290,
      "output": 971
    }
  },
  {
    "entry_id": 33,
    "retraction_id": "1703.02535v2",
    "paper_id": "1703.02535v1",
    "retraction_comment": "Error in the diffusion constant of Theorem 2.2, equation (2.4) due to a delicate issue in the method of the proof which is not trivial to correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The analytical characterization of universality classes and synchronization levels for the disordered system (Theorems 2.7 and 2.8) relies on a key inequality in Lemma 4.9 that has only been verified numerically, not proven analytically.",
        "Location": "Lemma 4.9 (page 26), its use in Section 4.3 (page 26) for proving Theorems 2.7 and 2.8. Acknowledgement of numerical verification is in the proof of Lemma 4.9 (page 26) and on page 13 (paragraph preceding Theorem 2.7).",
        "Explanation": "Lemma 4.9 provides bounds for the function Vμ(λ) related to the synchronization level in the disordered system. Specifically, the lower bound Vμ(λ) ≥ V_δ0(Iμ λ) is stated to be 'verified numerically in Appendix B.2 for three different types of disorder.' Theorems 2.7 (Criteria for the universality classes for disordered systems) and 2.8 (Bounds for the block synchronization levels for disordered systems) depend critically on this inequality for their derivation. Without a general analytical proof of this inequality for all symmetric, unimodal disorder distributions μ (as assumed for these theorems), the conclusions regarding the explicit characterizations of universality classes and bounds for disordered systems are not rigorously established for this general class of disorder. While numerical evidence for specific cases is provided, it does not constitute a mathematical proof, leaving a gap in the analytical foundation of these central results for the disordered system."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 18757,
      "output": 338
    }
  },
  {
    "entry_id": 34,
    "retraction_id": "1611.01102v3",
    "paper_id": "1611.01102v2",
    "retraction_comment": "The paper fails to appreciate that the necessitation rule is tacitly presupposed in the formulation of the Girle-Priest tableau rules. If those presuppositions were made explicit, the proofs of this paper would depend on a use of necessitation, contra what was claimed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of the existence of a self-referential proposition `q` whose defining property (`q` is identical to `~□q`) holds necessarily.",
        "Location": "Page 1, definition of `q` in relation to (i), and premise (Def) `□(q = ~□q)` on page 3.",
        "Explanation": "The argument's foundation is the existence of a proposition `q` that is identical to the proposition `~□q`, and that this identity `q ↔ ~□q` is a necessary truth (leading to (Def) `□(q = ~□q)`). Standard propositional modal logics (like system T) typically define well-formed formulas syntactically from propositional atoms and logical connectives. These systems do not inherently possess mechanisms (such as a diagonalization lemma or fixed-point theorem for propositions) to guarantee the existence or expressibility of such a self-referential proposition `q`. The paper does not demonstrate how `q` can be constructed or why its definitional identity should be considered necessary within standard operator modal logic. Without this, the paradox appears to arise not from system T itself, but from augmenting T with a strong, external assumption about the availability of such self-referential propositions whose definitions are necessary. The author's claim (page 4) that 'modal logic contains no stipulation against something like (Def)' is insufficient, as formal systems are defined by their constructive capabilities, not by the absence of explicit prohibitions against arbitrary additions."
      },
      {
        "Problem": "Lack of specification of the formal language that can express the self-referential proposition `q` and justify its properties.",
        "Location": "General, but particularly relevant to the setup on page 1 and the introduction of (Def) on page 3.",
        "Explanation": "The paper employs notation and rules common to propositional modal logic. However, the central self-referential proposition `q` (where `q` is `~□q`) and the assumption that its defining equivalence is necessary (i.e., `□(q ↔ ~□q)`) require a language with expressive capabilities beyond standard propositional modal logic. Such capabilities might include mechanisms for self-reference, proposition-forming operators from predicates, or a theory of propositions that allows for fixed points. The paper does not specify such a richer formal language wherein `q` is constructible and (Def) is either derivable or a well-motivated axiom. Without this specification, it is unclear whether the demonstrated paradox applies to the 'operator view' as commonly understood in modal logic (e.g., standard Kripke semantics for propositional modal languages) or only to some unspecified, more powerful system. This ambiguity undermines the claim that standard systems like T inherently 'breed paradox'."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 11481,
      "output": 595
    }
  },
  {
    "entry_id": 35,
    "retraction_id": "2205.15802v2",
    "paper_id": "2205.15802v1",
    "retraction_comment": "The proof of Theorem 3 is wrong: in the display equation below Equation (22), bottom of page 15, the gradient of $\\phi_{t+1}$ is missing a factor $1/(\\alpha\\eta_t)$",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The analysis of the parameter-free algorithm (Theorem 5) appears to be flawed, leading to an overly optimistic regret bound. The gradients fed to the KT-OCO algorithm for learning the norm ||U||_s(1) are bounded by sqrt(N) (or a related quantity), not 1. This means the regret contribution from KT-OCO should be scaled by sqrt(N), which, when propagated, would remove the 1/sqrt(N) factor from the leading term of the final regret bound. This potentially invalidates the claim that the parameter-free algorithm achieves a sqrt(N) improvement over independent learning in its dominant regret term.",
        "Location": "Proof of Theorem 5 (Appendix A.5, p. 17, Eq. 23-24), Theorem 5 statement (p. 7, Eq. 14), Algorithm 1 (p. 7).",
        "Explanation": "The KT-OCO regret bound (Eq. 13) is typically for gradients bounded by 1. The gradients s_t' = (sqrt(N)/L) <G_t, X_t'> used in the proof (p.17) are bounded by sqrt(N) because |<G_t, X_t'>| <= L. Thus, the regret for KT-OCO (Term A' in the proof's structure) should be sqrt(N) times the 1-Lipschitz regret. When this is substituted into the overall regret (Eq. 23, which has an L/sqrt(N) prefactor for Term A'), the L/sqrt(N) * sqrt(N) cancels out, leading to a term like 2L ||U||_s(1) sqrt(T log(...)) instead of 2L ||U||_s(1) sqrt(T/N) log(...). This makes the leading term of the parameter-free regret not improve by sqrt(N) over simpler strategies."
      },
      {
        "Problem": "The definition of the scalar gradient s_t in Algorithm 1, used for the KT-OCO component, depends on y_t, which is the output of KT-OCO in the same time step t. This is a non-standard formulation for online learning algorithms and creates a circular dependency if y_t is computed using s_t. If s_t uses y_t from the current step, the loss function for KT-OCO is not fixed before prediction. The proof in Appendix A.5, however, assumes KT-OCO receives gradients s_t' = (sqrt(N)/L) <G_t, X_t'>, which do not depend on y_t.",
        "Location": "Algorithm 1, line 'Set s_t = ...' (p. 7), and its relation to the proof in Appendix A.5 (p. 17).",
        "Explanation": "In Algorithm 1, s_t = (sqrt(N)/L) * (g_t, [X_t]_it:), and X_t = y_t X_t'. Thus, s_t depends on y_t. Standard online convex optimization, including KT-OCO, requires the gradient (or loss function) at time t to be determined based on information available before the learner's prediction y_t, or as a function of y_t but not circularly. The analysis in Appendix A.5 uses gradients for KT-OCO that depend on X_t' (denoted ~X_t in the proof), not y_t * X_t'. This mismatch means Algorithm 1 as stated is either not what was analyzed, or its analysis is non-standard and not properly justified."
      }
    ],
    "token_usage": {
      "input": 6832,
      "thinking": 17885,
      "output": 810
    }
  },
  {
    "entry_id": 36,
    "retraction_id": "2006.05804v2",
    "paper_id": "2006.05804v1",
    "retraction_comment": "Lemma 2.2 is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect coefficient in the cubic self-interaction term of the gauge field A_ν in the derived wave equations.",
        "Location": "Page 3, Eq. (1.13); Page 4, Eq. (1.17)",
        "Explanation": "The wave equations for A_ν, derived under the Lorenz gauge, are given as □A_ν = -2[A^μ, ∂_μA_ν] + [A^μ, ∂_νA_μ] + J_ν(source) - 2[A^μ, [A_μ, A_ν]]. Standard derivation (e.g., from D^μ F_μν = J_ν) yields □A_ν = -[A_μ, ∂^μA_ν] - [A^μ, ∂_μ A_ν] + [A^μ, ∂_ν A_μ] - [A^μ, [A_μ, A_ν]] + J_ν. The coefficient of the cubic term [A^μ, [A_μ, A_ν]] should be -1, but it is -2 in the paper. This error in a key nonlinear term affects the subsequent analysis for both YMH and YMD systems."
      },
      {
        "Problem": "Ambiguity and potential misrepresentation of the Yang-Mills-Dirac (YMD) system structure.",
        "Location": "Page 3, Section 1.3; Page 7, Notations section; Page 17-18, Appendix (Section 6.1)",
        "Explanation": "The paper states for the YMD system: 'Hence we assume n=1 and then omit T^a_ij for brevity' (p.3) where T^a are su(n,C) generators. If n=1, SU(1) is trivial, implying A=0. If U(1) was meant, the system is Maxwell-Dirac (Abelian). However, Eq. (1.17) for YMD includes non-Abelian commutator terms like [A^μ, ∂_μA_ν] and [A^μ, [A_μ, A_ν]]. If the system is indeed Maxwell-Dirac, these terms should be zero. If it is non-Abelian, the 'n=1 for SU(n)' assumption is problematic. The Appendix discussion does not sufficiently clarify this ambiguity, which is critical for understanding the YMD system being studied and the validity of Eq. (1.17)."
      },
      {
        "Problem": "Misstatement of a key angular regularity lemma.",
        "Location": "Page 10, Lemma 2.2",
        "Explanation": "Lemma 2.2, as stated on page 10, is '|| P_{K_{N,L}} H_l u ||_{L^2} <= N^{-1/2} L^{1/2} l^{-1} || P_{K_{N,L}} H_l u ||_{L^2}'. This inequality is mathematically incorrect as it would imply 1 <= N^{-1/2} L^{1/2} l^{-1} for non-zero u. While this is likely a typographical error for the intended Lemma 2.3 from reference [11] (which is described differently on page 6), its erroneous statement in the preliminaries section, where tools and norms are defined, is a significant flaw. This lemma is central to the paper's strategy of using angular regularity."
      },
      {
        "Problem": "Incorrect formulation of the initial data component f_dot_0i.",
        "Location": "Page 4, Eq. (1.21) for YMH; Page 5, Eq. (1.23) for YMD",
        "Explanation": "The initial data f_dot_0i represents ∂_t F_0i(0) (i.e., ∂_t E_i(0)). The expressions given, e.g., f_dot_0i = ∂^0 f_ji + [a^0, f_0i] + source_terms, include the term ∂^0 f_ji, which is ∂_0 F_ji (representing ∂_t B_k(0) where B is the magnetic field). The time evolution equation for E (Ampere-Maxwell law, ∂_t E = ∇ x B - J_YM - J_matter) implies that ∂_t E depends on B (i.e., f_ji) via its curl, not on ∂_t B. This suggests an error in setting up the initial value problem for the field strength F, which is fundamental for the well-posedness argument."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 14417,
      "output": 1042
    }
  },
  {
    "entry_id": 37,
    "retraction_id": "1708.02698v3",
    "paper_id": "1708.02698v2",
    "retraction_comment": "It turns out that there is an error in the argument for the curve case in Lemma 2.5 which makes the main result (Theorem 2.4) partially incorrect. We will post a modified version of the paper in which this is fixed. Meanwhile we withdraw the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption about the existence of a prime ideal p such that the localization A_p is a Discrete Valuation Ring (DVR) at each step of the main inductive construction.",
        "Location": "Page 16, Proof of Theorem 2.4, lines 8-12 (and its implicit application in the r=0 base case).",
        "Explanation": "The core of Theorem 2.4 is an inductive construction of algebras R^(i). In each step, starting with an algebra A (which is R^(r) in the paper's notation), the construction requires finding a G_m^r-invariant prime ideal p = rad(f) in A such that the localization A_p is a DVR. This condition is essential for applying Theorem 1.6, which guarantees the finite generation of the symbolic Rees algebra A_v(A) used to construct R^(r+1). Lemma 2.5 is invoked to find infinitely many suitable G_m^r-invariant prime ideals p=rad(f) such that V(p) intersects the stable locus Y^s. However, the paper then states (lines 10-12): 'Since there are only finitely many one-dimensional local rings of A that are not normal, we can moreover assume that for such a prime ideal p, the localization A_p is normal and hence a discrete valuation ring.' This claim is not sufficiently justified. The set of height 1 primes q in A for which A_q is not a DVR (i.e., A is not R1 at q) can be infinite if the non-normal (or non-R1) locus of A has components of dimension one or higher. The algebras A = R^(r) generated in the process are not necessarily normal or R1. It must be demonstrated that the 'good' primes p (where A_p is a DVR) exist among the candidates provided by Lemma 2.5, or that the construction can proceed even if A_p is not a DVR (which would require a different version of Theorem 1.6 or an alternative argument for finite generation). Without this justification, the main inductive step is potentially invalid, as Theorem 1.6 might not be applicable, and the subsequent Rees algebra might not be finitely generated, thereby breaking the entire degeneration sequence."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 16819,
      "output": 502
    }
  },
  {
    "entry_id": 38,
    "retraction_id": "1201.3873v3",
    "paper_id": "1201.3873v2",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial gap in the estimates for m>=4",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula used for the sum of coefficients in the Bohnenblust-Hille inequality for the m=2 case.",
        "Location": "Page 5, the expression for D2 and f2(a,b,c).",
        "Explanation": "The Bohnenblust-Hille inequality for an m-homogeneous polynomial P(z) = sum a_alpha z^alpha is (sum |a_alpha|^(2m/(m+1)))^((m+1)/(2m)) <= D_m ||P||. For m=2, and P2(z1,z2) = az1^2 + bz2^2 + cz1z2, the coefficients are a, b, c. The LHS term involving coefficients should be (|a|^(4/3) + |b|^(4/3) + |c|^(4/3))^(3/4). The paper, in the numerator of the expression for D2 (and f2(a,b,c)), uses (sqrt(a^4) + sqrt(b^4) + sqrt(c^4))^(1/2) which simplifies to (a^2+b^2+c^2)^(1/2). This is the l_2 norm of the coefficients, not the correct expression derived from the Bohnenblust-Hille inequality. This error invalidates the derived lower bound for D2 (D2 >= 1.1066)."
      },
      {
        "Problem": "Incorrect calculation of the sum of powered absolute values of coefficients for polynomials P_m = (P_2)^k when m >= 4.",
        "Location": "Page 5 (bottom, formula for f4(a,b,c)), Page 6 (formulae for g4(a,c) and g6(a,c), and by extension, other D_m for m>=8).",
        "Explanation": "When calculating the term (sum_{|alpha|=m} |a_alpha|^(2m/(m+1))) for P_m = (P_2(z1,z2))^(m/2), the coefficients a_alpha of P_m must be determined by first fully expanding (P_2)^(m/2) and collecting terms for each distinct monomial (e.g., z1^i z2^(m-i)). The paper's method, exemplified in the formulae for g4(a,c) and g6(a,c), appears to sum the powered absolute values of constituent parts of coefficients *before* these parts are algebraically summed to form the actual coefficient of a monomial. For example, if a monomial's true coefficient is (X+Y), the calculation requires |X+Y|^(2m/(m+1)). The paper's formulae effectively use |X|^(2m/(m+1)) + |Y|^(2m/(m+1)) instead. For p = 2m/(m+1) > 1, |X+Y|^p is generally not equal to |X|^p+|Y|^p, and if X and Y have opposite signs, |X+Y|^p can be significantly smaller than |X|^p+|Y|^p. This error generally leads to an overestimation of the sum of powered coefficients, meaning the reported D_m values are not valid lower bounds."
      },
      {
        "Problem": "The main conclusions regarding the exponential growth of D_m and the lower bound for the constant of hypercontractivity C are unsupported.",
        "Location": "Abstract (page 1), Page 3 (discussion of exponential growth and table of D_m estimates), Page 7 (Figure 2, equation (5.1) and related discussion of C).",
        "Explanation": "The paper's central claims, including that the constants D_m grow exponentially (specifically, that D_m^(1/m) does not tend to 1, contrasting with the multilinear case) and that the constant of hypercontractivity C satisfies C > 1.0845, rely critically on the numerical lower bounds derived for D_m. Due to the errors in calculating these lower bounds (as detailed in Problem 1 and Problem 2), the provided D_m values are not proven to be actual lower bounds and are likely overestimates of what the chosen family of polynomials can achieve with correct calculations. Consequently, the 'strong numerical evidence' for exponential growth is undermined, and the derived lower bound for C (1.0845) is not substantiated by the paper's methodology."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 13434,
      "output": 1005
    }
  },
  {
    "entry_id": 39,
    "retraction_id": "1006.2189v2",
    "paper_id": "1006.2189v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The proof of the verification of axiom 1 for the smoothing functor that is given in the paper is false, since it would violate what is known in dimension 4. If U is a subset of V and both are diffeomorphic to R^4, then the restriction map of smoothing spaces sm(V) -> sm(U) need not be one-to-one on path components. Thus axiom 1 is violated in dimension 4. The verification of axiom 1 in higher dimensions is probably a consequence of the product structure theorem",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Insufficient justification for excision property of Sm",
        "Location": "Page 8, Proof of Proposition 3.5",
        "Explanation": "The proof that the functor Sm is excisive concludes with 'Since the right vertical map is a Kan fibration, we are done.' This step is insufficient. For a square of spaces to be a homotopy pullback, having one map be a fibration simplifies checking the condition, but does not automatically satisfy it. A more detailed argument, likely involving a gluing construction for smoothings or appeal to a specific theorem from Weiss calculus about such diagrams, is needed to establish that Sm(K1 U K2) is indeed homotopy equivalent to the homotopy pullback of the other three terms."
      },
      {
        "Problem": "Flawed argument for W being diffeomorphic to D^m",
        "Location": "Page 9, Proof of Proposition 4.1",
        "Explanation": "In the proof of Proposition 4.1, it is stated that for a smoothing V of U (where U is diffeomorphic to R^m, m >= 6), V is diffeomorphic to the interior of a compact manifold W. The paper then argues: 'By deleting a small m-disk from W and applying the h-cobordism theorem, we deduce that W is diffeomorphic to D^m.' This step is unclear and likely incorrect as phrased. Deleting an interior disk from a general compact manifold W does not typically simplify it to D^m. While the conclusion that V is diffeomorphic to R^m is correct for m >= 6 (by Stallings' theorem, using the fact that V is a smooth manifold homeomorphic to R^m), the specific argument provided for why W is diffeomorphic to D^m is unsound."
      },
      {
        "Problem": "Incorrect derivation of the splitting formula in Theorem 5.3",
        "Location": "Page 13, Proof of Theorem 5.3",
        "Explanation": "The derivation of the formula Sm(N x S^1) ~ Sm(N x I) x ΩSm(N x I) appears to be algebraically flawed. The argument establishes a fibration Sm(N x I) -> Sm(N x S^1) -> Sm(N x R) which splits due to a section, implying Sm(N x S^1) ~ Sm(N x I) x Sm(N x R). Corollary 4.8 states Sm(N x I) ~ ΩSm(N x R). To obtain the theorem's formula Sm(N x S^1) ~ Sm(N x I) x ΩSm(N x I) from the split sequence, one would need Sm(N x R) ~ ΩSm(N x I). Substituting Sm(N x I) ~ ΩSm(N x R) into this yields Sm(N x R) ~ Ω(ΩSm(N x R)), i.e., Sm(N x R) ~ Ω^2 Sm(N x R). This 2-fold periodicity for Sm(N x R) is not generally true and indicates an error in the substitution or the target formula relative to the intermediate steps."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 16581,
      "output": 689
    }
  },
  {
    "entry_id": 40,
    "retraction_id": "1207.1467v2",
    "paper_id": "1207.1467v1",
    "retraction_comment": "This paper has been withdrawn due to a logica error in equation 1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mischaracterization of the Bird, Lightfoot, Stewart (BLS) model and Stefan Flow.",
        "Location": "Section 3.1, pp. 7-10, particularly the statement on p.10 that Eq. (3.10) 'falsely reports enhanced diffusion'.",
        "Explanation": "The paper argues that the nonlinear term 1/(1-C_gv) in the BLS-type model (Eq. 3.10, derived from assuming stagnant air, v_ga=0) 'falsely reports enhanced diffusion.' This is a mischaracterization. The BLS model correctly describes diffusion of a component A through a stagnant component B, where the nonlinearity accounts for the induced bulk flow (Stefan flow) necessary to keep B stagnant. Comparing this to a linear diffusion model (which assumes zero bulk velocity, v_g=0, a different physical scenario) does not mean the BLS model is 'false' for its stated assumptions. The authors' derivation (Eq. 3.12-3.13) shows that if one does not assume v_ga=0 but relates v_ga to a general bulk velocity v_g, the standard advection-diffusion equation relative to v_g is recovered; this does not invalidate the BLS model for the v_ga=0 case."
      },
      {
        "Problem": "Contradictory conclusions regarding bulk velocity in natural convection (Pe ~ 1).",
        "Location": "Section 4, pp. 16-19, specifically the recurring conclusion that 'bulk velocity... is negligibly small' (e.g., p.19, and repeated in Section 5 Conclusions).",
        "Explanation": "The paper analyzes natural convection assuming a Péclet number Pe ~ 1, which implies that advective transport by bulk velocity is comparable to diffusive transport (i.e., bulk velocity v_c ~ D/L). However, the subsequent scaling analysis of the momentum equation (e.g., Eq. 4.13 and its interpretation) leads the authors to conclude that the bulk velocity itself is 'negligibly small.' This contradicts the initial premise of Pe ~ 1. If bulk velocity were negligible, Pe would be << 1. While the analysis might correctly show that inertial and time-dependent terms in the momentum equation are small compared to pressure gradient and buoyancy terms (leading to a quasi-static force balance like Eq. 4.17), this does not imply that the velocity itself (which causes the Pe ~ 1 advection) is negligible."
      },
      {
        "Problem": "Inconsistent analysis of the momentum equation for the constant gas pressure case in natural convection.",
        "Location": "Section 4, p. 19, discussion surrounding Eq. (4.18b).",
        "Explanation": "For natural convection with 'approximately constant' gas phase pressure, the non-dimensionalized momentum equation (4.18b) is given as ∂v/∂τ + v⋅∇v = (L^2 g / D^2) e_3. The authors estimate the gravitational term (L^2 g / D^2) to be very large (e.g., 10^5 for L=1mm). Such a large term would typically drive significant flow or require a large balancing pressure gradient (if pressure is not entirely constant spatially, or if 'constant pressure' does not mean ∇p=0). However, the paper again concludes that 'the bulk velocity term is likely negligible.' This conclusion is inconsistent with a large, potentially unbalanced driving term and the initial Pe ~ 1 assumption. There is also a discrepancy in the text referring to the gravitational term coefficient as L^2g/D^3 (p.19, line below (4.18a)) versus L^2g/D^2 in Eq. (4.18b)."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 10180,
      "output": 850
    }
  },
  {
    "entry_id": 41,
    "retraction_id": "1503.03121v2",
    "paper_id": "1503.03121v1",
    "retraction_comment": "This paper has been withdrawn by the author because the duality is indefensible speculation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The CBE Assumption's Physical Mechanism is Unspecified",
        "Location": "Page 2, Section 1, paragraph starting 'The CBE (Comes Back Empty) assumption...'",
        "Explanation": "The model's central 'Come Back Empty' (CBE) assumption posits that at turnaround, all matter (luminous and dark) and black holes are jettisoned into an 'extroverse,' while the 'introverse' (our observable universe) retains only radiation, dark energy, and curvature to begin its contraction. No physical mechanism or theoretical basis for this highly selective jettisoning process is provided. This process is essential for resetting entropy and enabling infinite cyclicity, but without a plausible mechanism, it remains an ad-hoc stipulation that undermines the physical plausibility of the entire model."
      },
      {
        "Problem": "Contradictory or Unsound Argument for Flatness Solution",
        "Location": "Page 4, Section 2, first paragraph, sentence starting 'As shown in [7], this reduction in size...'",
        "Explanation": "The paper claims the CBE model solves the flatness problem, referencing arguments in its companion paper [7] (arXiv:1501.03054, Sec 3.1). However, the argument in [7] appears to be internally inconsistent regarding how the comoving radius of curvature (R_C) and the curvature density parameter (Ω_k) scale with the factor f(t_T). Specifically, [7] states both that R_C(contracting) = f(t_T)R_C(expanding) (which implies increased curvature for f(t_T) < 1) and that Ω_k is effectively scaled by f(t_T)^2 (which implies decreased curvature, i.e., flatter). These two assertions about how f(t_T) affects curvature are contradictory, making the claimed solution to the flatness problem unsound."
      },
      {
        "Problem": "Absence of Bounce Physics",
        "Location": "Page 2, Eq. (1) ('Expansion → Turnaround → Contraction → Bounce → etc.') and general framework",
        "Explanation": "The model relies on a cosmological bounce to transition from a contracting phase to an expanding one in every cycle. However, the paper offers no discussion of the physical conditions, new physics (e.g., quantum gravity effects, modified gravity), or mechanism required to achieve such a bounce while avoiding a singularity and ensuring a smooth transition. The omission of any treatment of bounce physics leaves a critical gap in establishing the model's viability for 'infinite cyclicity.'"
      },
      {
        "Problem": "Stability of the Contracting Universe Not Addressed",
        "Location": "Page 4, Section 2, statement 'The contraction is radiation dominated throughout', and the general assumption of a smooth contraction",
        "Explanation": "The model assumes a smooth, homogeneous, and isotropic contraction phase that is radiation-dominated. However, contracting universes are generically unstable to the growth of anisotropies and inhomogeneities (e.g., the BKL instability), which could lead to a chaotic singularity rather than the required smooth bounce. The paper does not address how these instabilities are controlled or avoided in the CBE model, a crucial aspect for the feasibility of repeated cycles."
      },
      {
        "Problem": "Handling of Dark Energy and its Entropy in Cyclical Context",
        "Location": "Page 2, Section 1, statement 'The CBE (Comes Back Empty) assumption is that the retained introverse contains energy of radiation, dark energy and curvature...'",
        "Explanation": "The CBE assumption states dark energy is retained in the introverse. If dark energy is a cosmological constant (as suggested by the use of de Sitter expansion in Eq. 4), its constant energy density would dominate rapidly during contraction, potentially preventing a bounce or leading to a problematic collapse. Furthermore, the entropy associated with dark energy (e.g., Gibbons-Hawking entropy for a de Sitter horizon) and its management across cycles to comply with the second law of thermodynamics is not adequately detailed in this paper, especially concerning how it fits into the 'Come Back Empty' paradigm which primarily focuses on jettisoning matter and black hole entropy."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 10144,
      "output": 919
    }
  },
  {
    "entry_id": 42,
    "retraction_id": "2405.12710v3",
    "paper_id": "2405.12710v2",
    "retraction_comment": "The author has withdrawn this paper due to a critical definitional error in concept learning for global/local-interaction learning during training. This error led to an alignment issue with the definition of the text-video retrieval task, causing an unfair comparison with state-of-the-art (SOTA) methods. Consequently, this hindered the accurate evaluation of the paper's contributions",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially detrimental formulation of the Inter-Consistency Loss (ICL) regularization term.",
        "Location": "Page 4, Eq (7); Page 6 (PDF, corresponds to OCR page 5 end / page 8 start), Sec IV-A-c (Implementation Details for λ value); Page 8 (PDF, corresponds to OCR page 6/8), Sec IV-C-e and Fig 4c (ablation for α).",
        "Explanation": "The Inter-Consistency Loss (ICL) includes a regularization term γ = Σ (λ - (c_i^v)^T c_i^t)^2, where λ is a fixed slack factor (set to 0.75). This term penalizes deviations of the dot product similarity between corresponding visual (c_i^v) and textual (c_i^t) concepts from this fixed value λ. Forcing all concept pair similarities to be exactly λ=0.75 is a very strong and potentially counterproductive constraint. It assumes a uniform ideal similarity for all diverse concept pairs, which is unlikely. This could prevent the model from learning stronger alignments (similarity > 0.75) or penalize weaker but still valid alignments (similarity < 0.75), potentially limiting the model's ability to capture nuanced semantic relationships. The ablation study shows ICL contributes, but its specific formulation as targeting a fixed similarity value is theoretically questionable for optimal performance."
      },
      {
        "Problem": "Inconsistent and potentially misleading reporting of computational cost (FLOPs) and speedup claims.",
        "Location": "Page 1, Abstract & Fig 1; Page 2, 'Effectiveness and Efficiency Analysis'; Page 5, Table I caption & FLOPs column; Page 6 (PDF, corresponds to OCR page 6), Sec IV-B-b; Page 8 (PDF, corresponds to OCR page 8), Table V.",
        "Explanation": "The paper claims GLSCL is 'nearly 220 times faster' (Abstract, Page 6). However, there are inconsistencies in reported FLOPs. Fig 1 shows GLSCL at ~25 GFLOPs, while Table I states 1.0 GFLOPs for GLSCL, specifying this is for the 'similarity calculation head'. If the 220x speedup compares the 1.0G head-only FLOPs of GLSCL to the total FLOPs of methods like X-CLIP (~220G) or PromptSwitch (~300G), it's an unfair comparison. If it compares head-only FLOPs (e.g., 1.0G for GLSCL vs. 298.5G for PromptSwitch head from Table I), the ratio is ~300x. If total FLOPs from Fig 1 are used (GLSCL ~25G vs. PromptSwitch ~300G), the speedup is ~12x. The actual inference times in Table V show GLSCL is faster than some SOTA but not by such a large factor (e.g., 36.6s for GLSCL vs. 68.6s for PromptSwitch, ~1.87x). This discrepancy and lack of clarity on what FLOPs are being compared makes the headline efficiency claim potentially misleading and undermines the assessment of practical speedup."
      },
      {
        "Problem": "Ambiguous formulation and potential error in the Intra-Diversity Loss (IDL).",
        "Location": "Page 4, Eq (10); Page 6 (PDF, corresponds to OCR page 5 end / page 8 start), Sec IV-A-c (Implementation Details for Δ value); Page 8 (PDF, corresponds to OCR page 6/8), Sec IV-C-e and Fig 4d (ablation for β).",
        "Explanation": "The Intra-Diversity Loss (IDL) in Eq (10) is L_IDL^v = (1/N_q) Σ_{i=1, i!=j}^{N_q} [max(0, Δ + o_ij^v - o_ii^v)]. There are two issues: 1. The summation index 'j' is used in o_ij^v but is not explicitly defined or iterated over in the outer sum Σ_{i=1, i!=j}^{N_q}. It should likely be a double summation, e.g., Σ_i Σ_{j!=i}. 2. The normalization factor (1/N_q) seems incorrect if the sum is over all N_q * (N_q-1) distinct pairs of concepts. It should typically be 1/(N_q(N_q-1)) or an equivalent formulation. While the intent to penalize high similarity o_ij^v between different concepts (i.e., o_ij^v > o_ii^v - Δ) is clear and sensible for diversity, the mathematical expression of the sum and its normalization is ambiguous or erroneous. This could lead to incorrect scaling or application of the diversity objective, potentially affecting the model's training and performance."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 8397,
      "output": 1121
    }
  },
  {
    "entry_id": 43,
    "retraction_id": "1305.5284v3",
    "paper_id": "1305.5284v2",
    "retraction_comment": "This paper has been withdrawn by the author due to missing phase-space factor in eq(1)/(2), thus the whole structure is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed argument for a prolonged, purely gluonic Glasma phase due to suppression of quark-antiquark pair production.",
        "Location": "Page 1, end of right column; Page 2, discussion around Eqs. (1) and (2). Specifically, the statement: \"Then how can the plasma stays as gluons long? What suppresses the process like gg → q qbar to hinder the appearance of quarks? Tempertaure!\"",
        "Explanation": "The paper claims that high temperature suppresses quark-antiquark pair production (gg → qqbar), allowing the Glasma to remain purely gluonic for an extended period. This is counter-intuitive, as high temperatures typically provide more energy and phase space for particle production, including qqbar pairs. The statistical argument based on n_B/n_F using the E/T → 0 limit is misapplied or insufficient to justify a prolonged suppression of quark chemical equilibration. A robust kinetic mechanism for preventing rapid quark appearance in a very hot gluon system is not provided, undermining the premise of a long-lived, purely gluonic phase."
      },
      {
        "Problem": "Unsubstantiated and physically implausible claims that Glasma is a candidate for cosmological dark matter and dark energy.",
        "Location": "Page 1, Abstract; Page 2, section \"A simple statistical analysis...\"; Page 3, first two paragraphs.",
        "Explanation": "The paper suggests Glasma as a candidate for dark matter and dark energy. This is highly speculative and inconsistent with known properties. Cosmological dark matter is typically cold or warm, stable, and interacts very weakly (other than gravitationally). A hot, dense, strongly interacting gluon plasma (Glasma) would rapidly cool, expand, and hadronize, making it unsuitable as dark matter. Similarly, Glasma would have positive pressure (P ≈ E/3), contrasting with the negative pressure required for dark energy. The analogy drawn between pressure gradients in heavy-ion collisions and cosmic acceleration is unsound."
      },
      {
        "Problem": "Assertion of strictly zero photon and dilepton emission from the Glasma phase.",
        "Location": "Page 2, paragraph starting \"Now let's high temperature...\", and the Table.",
        "Explanation": "The paper claims that Glasma, being a pure gluon plasma, emits no photons or dileptons. While direct coupling of photons to gluons is forbidden at leading order because gluons are electrically neutral, higher-order processes (e.g., gluon fusion into a quark loop that subsequently radiates a photon, or gg → qqbarγ) can still produce photons and dileptons. Claiming strictly zero emission from an extremely hot and dense gluon system is a strong assertion that lacks sufficient justification or quantification of how suppressed these higher-order processes would be. This 'darkness' is crucial for the paper's explanation of photon/dilepton v2 puzzles."
      },
      {
        "Problem": "Potentially misleading critique of existing photon and dilepton emission rate calculations.",
        "Location": "Page 2, paragraph starting \"So if the system evolution is well constrained...\"",
        "Explanation": "The paper argues that current photon/dilepton emission rate calculations overestimate high-temperature emission by using an \"approximation of classic limit, replacing Eq.(1) and (2) with 1/exp(E/T) in [18]\", which is claimed to be valid only for E >> T. Standard calculations for QGP emission rates (e.g., Kapusta et al. [18], AMY [19]) generally use full quantum statistical factors (Bose-Einstein/Fermi-Dirac), not merely a classical Boltzmann approximation (which is exp(-E/T), not 1/exp(E/T)). The critique seems to misrepresent the classical limit and the methods used in established calculations, thereby potentially creating a straw man argument to motivate the need for the Glasma hypothesis."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 4422,
      "output": 849
    }
  },
  {
    "entry_id": 44,
    "retraction_id": "2307.11176v2",
    "paper_id": "2307.11176v1",
    "retraction_comment": "There is an irrecoverable error in Lemma 2.5. There are counterexamples even in case R=Q[x]. The lemma is crucial for the rest of the paper and it does not work unless strong assumptions are made (like: the modules are graded)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Validity of Proposition 3.2 and its implications for the scope of the main theorem.",
        "Location": "Proposition 3.2 (page 3), its proof (pages 4-5), and Definition 1.2(b) (page 1).",
        "Explanation": "Proposition 3.2 states that a finitely generated regularly Z-filtered R[w,w^-1]-module M is isomorphic to gr(M) = R[w,w^-1] tensor_R N (where N = F^0 M / F^1 M). This isomorphism, if true, implies that F^0 M is isomorphic to R[w] tensor_R N. A necessary condition for this latter isomorphism is that multiplication by w must be injective on F^0 M (i.e., w is a non-zero-divisor on F^0 M).\n\nHowever, Definition 1.2(b) for a regularly Z-filtered module M, along with the clarification that M being 'finitely generated as a filtered module' means F^0 M is a finitely generated R[w]-module (Lemma 2.3), does not explicitly state that w must be a non-zero-divisor on F^0 M. The condition wF^j M = F^{j+1} M only implies surjectivity of w: F^j M -> F^{j+1} M.\n\nIf modules M exist that satisfy Definition 1.2(b) but where w is a zero-divisor on F^0 M (e.g., consider R=k[x] and F^0 M = k[x,w]/(xw), then M = k[x,w,w^-1]/(xw)), Proposition 3.2 would not hold for such modules. The proof of Proposition 3.2 (Lemmas 3.4 and 3.5) appears internally consistent, suggesting that it implicitly assumes or proves this non-zero-divisor property.\n\nIf Definition 1.2(b) does not inherently imply this property, then Proposition 3.2 is either incorrect as stated for the full class of modules defined, or its proof is flawed. Since Proposition 3.2 is fundamental for subsequent results (Lemma 4.2, Lemma 4.5, Lemma 5.3), which are then used in the proof of the main Theorem 1.3 (via Proposition 7.1, specifically the equivalence (C-3) <=> (C-4)), this issue could either invalidate the main theorem's conclusions for the stated generality or significantly restrict its scope to a subclass of modules where w is a non-zero-divisor on F^0 M. This critical property should be made explicit in the definitions or as a preliminary lemma."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 21132,
      "output": 605
    }
  },
  {
    "entry_id": 45,
    "retraction_id": "0804.4876v3",
    "paper_id": "0804.4876v2",
    "retraction_comment": "A counterexample to Theorem 1.2 has been pointed out to the author (x^2+3 reduced modulo 2). The mistake cannot be corrected at this time",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misleading claim of generality for Theorem 1.2 (Generalized Kummer-Dedekind Theorem).",
        "Location": "Theorem 1.2 (p.2), Remark 1.3 (p.2), Abstract (p.1).",
        "Explanation": "Theorem 1.2 assumes that the polynomial c(x) modulo p factors into distinct irreducible polynomials (c̄ = c̄₁...c̄ᵣ). This assumption implies that p does not divide the discriminant of c(x). Standard algebraic number theory shows that Disc(c(x)) = [O_K : O_k[α]]² Disc(O_K/O_k). Thus, if p does not divide Disc(c(x)), then p does not divide the index [O_K : O_k[α]] and p is unramified in K (i.e., p does not divide Disc(O_K)). Consequently, Theorem 1.2, under its stated hypothesis, applies only to primes p that do not divide the index and are unramified in K. This contradicts Remark 1.3, which claims the theorem is 'completely free of any special assumptions on the field extension K/k and the prime p' and does not require that p avoids dividing the index. The abstract's claim of 'removal of all artificial constraints from the Kummer-Dedekind Theorem' is therefore not substantiated by Theorem 1.2 as presented."
      },
      {
        "Problem": "The proof of Theorem 1.2 implies a more restricted scope than claimed, specifically that p must be unramified in K.",
        "Location": "Section 4, Step 2 and Step 3 (p.11).",
        "Explanation": "In the proof of Theorem 1.2, Step 2 aims to establish an isomorphism that implies |Rᵢ| = e(Pᵢ|p)f(Pᵢ|p), where Rᵢ is the set of roots of c(x) reducing to roots of c̄ᵢ mod Q, and |Rᵢ| = deg(c̄ᵢ). Part (iii) of Theorem 1.2 states f(Pᵢ|p) = fᵢ = deg(c̄ᵢ). Combining these, deg(c̄ᵢ) = e(Pᵢ|p)deg(c̄ᵢ), which forces e(Pᵢ|p) = 1. This means the prime p must be unramified in K. This restriction is not acknowledged in Remark 1.3 or the abstract, which claim broad generality. The proof sketch in Step 2 is also insufficient to rigorously establish the claimed D-isomorphism for Rᵢ without implicitly relying on conditions (like p not dividing the index) that are supposedly lifted."
      },
      {
        "Problem": "Proposition 1.5's claim of generality is undermined by its reliance on the restricted Theorem 1.2.",
        "Location": "Proposition 1.5 (p.3).",
        "Explanation": "Proposition 1.5 states that K/k is normal if and only if every factorization of c(x) modulo unramified primes of k results in factors of equal degree. The proof of this proposition depends on Theorem 1.2. Since Theorem 1.2, as stated and proven, effectively applies only when c(x) mod p is square-free (which implies p is unramified in K and does not divide the index [O_K:O_k[α]]), Proposition 1.5 is similarly restricted. It cannot generally apply to all 'unramified primes of k' if some of those primes lead to non-square-free factorizations of c(x) mod p (e.g., if p divides the index [O_K:O_k[α]] while being unramified in K). The proposition's scope is therefore narrower than its wording suggests."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 16770,
      "output": 852
    }
  },
  {
    "entry_id": 46,
    "retraction_id": "2105.09970v2",
    "paper_id": "2105.09970v1",
    "retraction_comment": "The proof of the main Lemma (3.11, section 3.4) is incomplete: in the middle of page 22, the fact that $\\gamma$ is weakly distributive is not sufficient to justify the chain of two inclusions used to invoke Proposition 2.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption in aperiodicity proof for associated forest algebras.",
        "Location": "Page 11, paragraph 'Weakly distributive spas whose stick monoid is aperiodic.'",
        "Explanation": "The proof that if a spa H=(H,S) has an aperiodic stick semigroup S, then its associated forest algebra H^0 has an aperiodic vertical monoid V^0, assumes (τ+1)h = τh for h in H (the spa's horizontal semigroup). However, the definition of a spa does not require H to possess this τ-aperiodic property. This assumption is crucial for the derivation v^(2τ+1) = v^(2τ) used to show V^0 is aperiodic, potentially affecting the characterization of the class D∧Â."
      },
      {
        "Problem": "Potentially flawed step in proving a weakly distributive algebra divides M^α_1.",
        "Location": "Page 20, Proof of Proposition 3.10, specifically the derivation μ_1(x) = Jα(x).",
        "Explanation": "The proof that a weakly distributive forest algebra G = α(A^Δ) divides M^α_1 relies on establishing μ_1(x) = Jα(x) (the ideal generated by α(x) in G). The definition of μ_1(x) is {α(u) : ∃z ∈ Π(u), x ≃ z}. The equality μ_1(x) = Jα(x) seems to implicitly require that if pathword(x) = pathword(z) (denoted x ≃ z), then α(x) = α(z). This is not generally true because ≃ is based on pathword structure, not necessarily syntactic congruence with respect to G and the fixed homomorphism α. If this step is incorrect, the proof of G < M^α_1 is undermined, which is critical for the base case of Lemma 3.11."
      },
      {
        "Problem": "Ambiguity in the definition of the 'LPL hierarchy' and its implications.",
        "Location": "Page 13, paragraph 'The leaf path language (LPL) hierarchy', and its use in Proposition 3.4 (Page 16).",
        "Explanation": "The LPL hierarchy is defined using mE^kL (counting leaf pathwords) at level 1. For higher levels (n > 1), it uses E^kL where L is over an alphabet A × P_{n-1}(L). It is unclear whether this E^kL for n > 1 also refers to counting leaf pathwords (i.e., mE^kL over the new alphabet) or if it switches to counting arbitrary pathwords (as E^kL was defined on page 6 in a more general context). This ambiguity affects Proposition 3.4, which connects n-fold wreath products of weakly distributive algebras (which count leaf paths) to level n of this hierarchy. If the hierarchy definition is inconsistent or mixes counting types, the proposition's statement or proof might be flawed."
      },
      {
        "Problem": "Unclear argument in proof of non-recognizability by *D.",
        "Location": "Page 17, Proof of Proposition 3.6.",
        "Explanation": "The proof aims to show that the 'set of all trees over A' is not recognizable by any algebra G in *D. It derives α(t) = α(t+t) for a specific tree t and then claims this 'contradicts the hypothesis' (that G recognizes the language). The argument is unclear because: (1) The language 'set of all trees over A' is not precisely defined (e.g., does it distinguish a single tree t from a forest t+t?). (2) If both t and t+t are in the language, then α(t) = α(t+t) with both images in the accepting set is not inherently a contradiction. A more precise language definition and a clearer explanation of why the equality leads to a contradiction for recognizability are needed."
      }
    ],
    "token_usage": {
      "input": 9154,
      "thinking": 13541,
      "output": 907
    }
  },
  {
    "entry_id": 47,
    "retraction_id": "1508.06018v3",
    "paper_id": "1508.06018v2",
    "retraction_comment": "This paper has been withdrawn by the authors due the fact that the main results Proposition 4.1 and Theorem 4.8 are not correct. Anonymous reviewers notice, that In the former the set B\\A is not necessarily nonempty while, in the latter, the formulation and proof are unclear",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The 'Moreover' clause in Theorem 4.8 is problematic and potentially unsound.",
        "Location": "Page 10, Theorem 4.8; and Page 24, Section 6.3 (Proof of Theorem 4.8)",
        "Explanation": "Theorem 4.8 lists Assumptions 3.1 (for D-paths) and 4.5 (for density propagation) as foundational. The 'Moreover' clause then discusses specific convergence outcomes if either of these assumptions 'fails' for a particular region 'j'. This is problematic because: 1. It discusses the failure of hypotheses that the theorem itself relies on. 2. It implicitly assumes that if one method (e.g., D-path via Ass 3.1) fails for a region, the other method (e.g., density propagation via Ass 4.5) must necessarily hold for that same region and lead to a specific alternative convergence. This 'automatic fallback' is not guaranteed by the stated assumptions. The proof sketch on page 24 for the case 'if Assumption 4.5 fails' is particularly underspecified, merely stating 'A similar situation happens...' without detailing how Assumption 3.1 would then ensure the claimed convergence to A_{j+1}."
      },
      {
        "Problem": "The formulation of Assumption 3.1.iv appears ill-posed or contains a typo.",
        "Location": "Page 6, Assumption 3.1, condition (iv), equation (3.2)",
        "Explanation": "Assumption 3.1.iv states: 'For every compact set K subset (m,m_bar) there exist constant values 0 < c < C such that, for every index i = 1,...,n, the inequality m < c <= (sigma_i^-1)'(r) <= C < m_bar holds at every point r in K...'. Here, m = max M_i and m_bar = min Mbar_i are bounds on Lyapunov function values (V_i). The terms c and C are bounds on the derivative (sigma_i^-1)'(r). The conditions 'm < c' and 'C < m_bar' compare these derivative bounds directly with the V_i-space bounds m and m_bar. This seems to be a dimensional mismatch or a conceptual error, imposing potentially overly restrictive or nonsensical constraints on the D-path's derivative. For instance, if m (lower bound of V-region) is large, c (lower bound of derivative) must be even larger. The essential part of the condition for the derivative is likely 0 < c <= (sigma_i^-1)'(r) <= C < infinity."
      },
      {
        "Problem": "The main conditional statement of Theorem 4.8 is unclearly formulated regarding the application of Assumptions 3.1 and 4.5.",
        "Location": "Page 10, Theorem 4.8 (main statement)",
        "Explanation": "Theorem 4.8 states its hypotheses as 'Let Assumption 3.1 holds with... D paths sigma_j' AND 'Let also Assumption 4.5 holds with... Functions rho_j and sets D_j'. It then states the condition for its conclusion: 'If, for every index j = 0, ..., L, the inclusion S_j subseteq cl{D_j} holds, then system (1.3) is aISS...'. A literal interpretation of this structure implies that for the theorem to apply, *all* D-paths sigma_j must exist, *all* density functions/sets rho_j/D_j must exist, AND *all* regions S_j must be covered by the density regions D_j. This would render the D-path assumption (Ass. 3.1 for sigma_j) largely irrelevant for the main conditional check, as the density condition S_j subseteq cl{D_j} would be paramount for all j. This contradicts the proof (Section 6.3), which clearly employs both D-path arguments (Prop 4.1) and density arguments (Thm 4.6 logic) for different aspects or regions. The theorem should more clearly state how the state space decomposition S_j is covered by *either* the D-path mechanism *or* the density propagation mechanism for each respective segment."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 17067,
      "output": 950
    }
  },
  {
    "entry_id": 48,
    "retraction_id": "1310.8403v3",
    "paper_id": "1310.8403v2",
    "retraction_comment": "This paper has been withdrawn as a bug has been discovered in the proof of Claim 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound reasoning in Claim 3 (and by extension Claim 5) due to unjustified assumptions.",
        "Location": "Page 5, Proof of Claim 3 (also impacts Lemma 2, Lemma 4, Claim 5)",
        "Explanation": "The proof of Claim 3 assumes that R1 (the rectangle anchored at p1) is common to the optimal packings R(Pn) and R(Qn) when a point pi (not p1) is perturbed to pi'. This is stated as: \"Now as R(Qn) and R(Pn) both contain R1...\". This assumption is not justified, as changing the point set from Pn to Qn can alter the entire optimal packing, including the rectangle R1. Furthermore, the subsequent step comparing sums of other rectangles (e.g., \"one can choose rectangles of R(Qn) \\ {R', R1} in the packing corresponding to Pn thereby increasing the covered area\") is not adequately substantiated, as the optimality and validity of these sub-packings are context-dependent."
      },
      {
        "Problem": "The inductive argument for Theorem 6 relies on an unjustified decomposition of the problem space.",
        "Location": "Page 6, paragraph before Theorem 6 (deriving Theorem 6 from Lemma 4)",
        "Explanation": "Theorem 6 (all points of a MIN-MAX set Pn* lie on the principal diagonal) is derived by an inductive argument. This argument assumes that after identifying a point pb=(x*,x*) on the diagonal related to p1, the problem recursively decomposes to the n-1 points in the square region U_rem = U \\ (V(p1) U H(p1)). However, V(p1) and H(p1) are reference rectangles, not necessarily the actual rectangles R1 and R_b in the optimal packing R(Pn*). The remaining region for the other n-1 points is determined by the actual packed rectangles (e.g., U \\ R1 if R1 is chosen), which is not necessarily the neat square U_rem. This invalidates the simple recursive structure assumed for the induction."
      },
      {
        "Problem": "Arguments for area changes of specific rectangles under perturbation are oversimplified.",
        "Location": "Page 5, paragraph after Claim 3 (proof of Lemma 2 continuation)",
        "Explanation": "The proof that A(Qn) < A(Pn) in Lemma 2 requires showing A_Pn(Ri) > A_Qn(Ri'). The justification provided (e.g., \"Suppose Ri is bounded by the point pi and Ri' is bounded by the point pj. Clearly, x(pi) < x(pi') < x(pj) < x(pi) ... Again A(Rij) > A_Qn(Ri') by construction of Qn...\") relies on overly simplified geometric assumptions about how rectangles are bounded (e.g., by a single point as in Figure 6) and how their areas change. In a maximal packing, a rectangle's dimensions are determined by complex interactions with potentially many other rectangles or the main boundary, not just its anchor and one other point. This simplification may not hold generally."
      },
      {
        "Problem": "Unaddressed reliance on general position assumption.",
        "Location": "Page 3, start of Section 2.2; implicitly throughout perturbation arguments",
        "Explanation": "The paper assumes \"no two points of P inside U share the same x or y-coordinates.\" Many arguments, particularly those involving how rectangles (like V(p1), H(p1), or R1) are bounded by other points, or how areas change upon point perturbation, implicitly rely on this general position assumption (e.g., a unique point defining a boundary). The paper does not discuss the validity of its conclusions if this assumption is relaxed. Critical steps, like identifying a single bounding point or the behavior of areas under perturbation, might fail or require significantly more complex arguments in degenerate cases. This omission is critical as the conjecture should hold for any set of points."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 18767,
      "output": 892
    }
  },
  {
    "entry_id": 49,
    "retraction_id": "2003.05237v3",
    "paper_id": "2003.05237v2",
    "retraction_comment": "There is an issue in the proof of Lemma 3.7: evaluation of the involved classes gives back the same values for the coinvariants and not necessarily for the coefficients themselves. At the moment I do not see how to fix it. The lemma is needed in the proof of the main Theorem",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear or potentially flawed proof of Γ_l x Γ_r equivariance in Lemma 3.2.",
        "Location": "Page 16, Lemma 3.2",
        "Explanation": "The proof of Γ_l x Γ_r equivariance for the cochain map C*(F) is difficult to follow. The derivation steps, the group actions used, and the final assertion 'and since χ(λ⁻¹x)β_Ω(λ⁻¹,[x]) = χ(x) the claim follows' seem to involve inconsistencies or rely on unstated, non-obvious properties of the maps χ (retraction) and F (natural map), or the cocycle β_Ω. For instance, the transformation of arguments like γ⁻¹(λ⁻¹x) and the specific relation χ(λ⁻¹x)β_Ω(λ⁻¹,[x]) = χ(x) are not clearly justified. This lemma is foundational for Proposition 3.3 and Proposition 3.5, which are crucial for the main proof strategy involving factorization of cohomology maps."
      },
      {
        "Problem": "Overstated generality of the main result in Corollary 3.11 and the Abstract.",
        "Location": "Page 25, Corollary 3.11; Page 1, Abstract",
        "Explanation": "Corollary 3.11 claims 'the same proof can be adapted to every rank-one Lie group of non-compact type' if d(n-1)>2. The abstract states the paper 'concludes the study of 1-tautness of rank-one Lie groups'. However, the proof method relies on Patterson-Sullivan densities (page 13), which require d(n-1)≥2. This condition is not met by PO(2,1) (where d=1, n=2, so d(n-1)=1), which is a rank-one Lie group. The paper does not recover the known result for PO(2,1) (1-taut relative to Homeo(S^1) from [BFS13b]). Thus, the claim of covering *every* rank-one Lie group or concluding the study is too strong without further qualifications or handling of such cases. The proof also uses PU(n,1)-specific notation (H_C^n) and a rigorous adaptation to all other rank-one types (e.g., quaternionic or Cayley hyperbolic spaces) is asserted rather than demonstrated in detail."
      },
      {
        "Problem": "Soundness of Theorems 2 and 3 relies on insufficiently detailed 'mutatis mutandi' arguments.",
        "Location": "Page 3, Theorem 2; Page 4, Theorem 3",
        "Explanation": "The proofs of Theorem 2 (classification of measure equivalent groups) and Theorem 3 (consequences for stable orbit equivalence) are stated to follow 'mutatis mutandi' from existing literature ([Fur99a, Lemma 4.6] and [BFS13b, Theorem D] for Theorem 2; [Fur99a] for Theorem 3). Theorem D in [BFS13b], for example, has a complex proof. Asserting that these significant results follow by analogy once Theorem 1 (1-tautness of PU(n,1)) is established, without providing further details on how the arguments adapt, makes their conclusions less rigorously supported within this paper. Such 'mutatis mutandi' claims can overlook subtle but crucial differences between the contexts, potentially affecting the validity of the theorems as stated for PU(n,1) lattices."
      }
    ],
    "token_usage": {
      "input": 7348,
      "thinking": 12403,
      "output": 789
    }
  },
  {
    "entry_id": 50,
    "retraction_id": "2203.03600v2",
    "paper_id": "2203.03600v1",
    "retraction_comment": "The main technical result, Lemma 4, has a major error in the proof: The claim in the proof \"... we could decompose $y^i$, and therefore $y$ into at least two sign-compatible, non-zero cycles of $\\mc A$ ...\" is NOT true. This claim is based on our claim in Lemma 3 that the decomposition of cycles $y^i$ into bricks $y^{i^j}$ yields cycles $y^{i^j}$ of the N-fold matrix $\\mc A$. This is not true",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Omission of d^(O(d)) factor in runtime for Corollaries 1, 2, and 3.",
        "Location": "Corollaries 1, 2 (Page 8), Corollary 3 (Page 9), Table 2 (Page 8).",
        "Explanation": "The runtime for N-fold IPs from Theorem 1 includes a factor (SA)^(O(r+s)). For problems in Corollaries 1, 2 (Q||Cmax, Q||Cmin, Q||sum wjCj) and Corollary 3 (Q|cc|Cmax), the parameters are r=d, s=O(1) (s=1 or s=2), and SA=d (number of parts in the partition of global A-matrix rows). This results in a factor of d^(O(d)). The term (pA pB ∆)^(O(r pA pB + s pA pB)) evaluates to Pmax^(O(d)) using pA=1, pB=O(1). Thus, the overall fixed-parameter part of the complexity should be d^(O(d)) * Pmax^(O(d)), which is (d*Pmax)^(O(d)). The corollaries state runtimes of Pmax^(O(d)) (times polynomial factors), omitting the d^(O(d)) term. This omission makes the stated runtime appear better with respect to parameter d than what Theorem 1 implies."
      },
      {
        "Problem": "Discrepancy in runtime complexity for Corollary 4 (Q|rj|Cmax and Q|dj|Cmax).",
        "Location": "Corollary 4 (Page 10).",
        "Explanation": "Corollary 4 states a runtime of (Pmax)^(O(d^3)) (times polynomial factors). A direct application of Theorem 1 with parameters derived for this problem (r=d, s=2d+1, t=2d, ∆=Pmax, SA=d, pA=1, and pB=O(d) as all 2d+1 local constraints for a machine are interconnected) yields a runtime of (d*Pmax)^(O(d^2)) (times polynomial factors). The stated runtime in Corollary 4 has a worse dependency on d in the exponent (d^3 vs d^2) and omits the factor of d from the base. This means either the paper understates the performance improvement from Theorem 1 for this specific problem, or there is an error in the parameterization or application of Theorem 1 specific to this corollary."
      },
      {
        "Problem": "Discrepancy in runtime complexity for Corollary 5 (R||Cmax).",
        "Location": "Corollary 5 (Page 10), Table 3 (Page 11).",
        "Explanation": "Corollary 5 states a runtime of (Pmax)^(O(dK^2)) (times polynomial factors). A direct application of Theorem 1, using parameters r=(d+1)K, s=2, t=(d+1)K, ∆=Pmax, SA=(d+1)K, pA=1, pB=1 (as derived from the problem description and correcting apparent typos in Table 3 where r and t are listed as (d+1)^K), yields a runtime of ((dK)*Pmax)^(O(dK)) (times polynomial factors). The stated runtime in Corollary 5 has a worse dependency on K in the exponent (K^2 vs K) and omits the dK factor from the base. Similar to Corollary 4, this suggests either an understatement of Theorem 1's implication for this problem or an error in its application/parameterization for this case."
      },
      {
        "Problem": "Inconsistent definition of parameter pA.",
        "Location": "Abstract (Page 1) vs. Theorem 1 (Page 3) and Lemma 4 (Page 6).",
        "Explanation": "The abstract states: 'PA and PB are the size of the largest set in such a partition of A(i) and B(i), respectively'. This implies pA is derived from local matrices A(i). However, Theorem 1 states: 'pA is a partition of A = (A(1), ..., A(n)) ... with its respective parameters pA', and the proof of Lemma 4 uses pA as the maximum size of a part in a partition of the global A matrix. The applications in Section 5 also use pA based on the global A matrix. While the main body of the paper consistently uses pA for the global A matrix, the abstract's definition is contradictory and could mislead readers about the nature of this parameter."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 20156,
      "output": 1048
    }
  },
  {
    "entry_id": 51,
    "retraction_id": "2001.10983v3",
    "paper_id": "2001.10983v2",
    "retraction_comment": "A case in the proof of Proposition 2.8 was overlooked (thanks to [REDACTED-NAME] for pointing out this) and I withdraw the paper until that gap is filled",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear justification for focusing on a specific reflection (sa2) to prove realizability of all automorphisms.",
        "Location": "Page 5, Proof of Proposition 1.9",
        "Explanation": "The proof of Proposition 1.9 aims to show that any automorphism sigma in W(E6) can be realized by a monodromy loop. It states: 'By Corollary 1.7, we only need to prove for sigma = sa1, as W(E6) is generated by such reflections. And by Lemma 1.8, we may assume sigma = sa2.' Lemma 1.8 states that W6 acts transitively on R6 (the set of 72 roots). It is not clear how this transitivity on roots allows reducing the proof for all generating reflections (or all of W(E6)) to the specific case of sa2. A clear argument for why realizing sa2 (or a class of reflections represented by sa2) is sufficient is missing, making the proof strategy for the full W(E6) group incomplete within the paper's own logic, even if the result itself (citing [Har79]) is standard."
      },
      {
        "Problem": "Potentially overly general statement in Proposition 1.17 with author's expressed uncertainty.",
        "Location": "Page 10, Proposition 1.17 and Footnote 3",
        "Explanation": "Proposition 1.17 states that for any simply-laced root system R, the Weyl group W(R) is generated by reflections s_vi associated with *any* set of vectors {vi} that are roots and span the root lattice A. Footnote 3 ('There should be some classical result which can cover this, but I did not find it.') indicates the author's uncertainty about this general statement. While standard results state that W(R) is generated by reflections corresponding to simple roots, or by reflections corresponding to *all* roots, the claim for *any* spanning set of roots {vi} is very general. If this proposition is not a standard result or is incorrect in its full stated generality, its use might be problematic. Although its application in the paper is to the set of all vanishing cycles {delta_i}, which is known to generate W(E6), the soundness of the general proposition as stated and proven in the paper is a concern due to the author's note."
      }
    ],
    "token_usage": {
      "input": 4768,
      "thinking": 20568,
      "output": 528
    }
  },
  {
    "entry_id": 52,
    "retraction_id": "2307.05226v3",
    "paper_id": "2307.05226v2",
    "retraction_comment": "The paper has been withdrawn because of the basic mistake: the map $f$ has in general rank q, not p < q (Section 3)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Insufficient justification for `codim Sing(Fx) >= 3`.",
        "Location": "Page 7, paragraph after Remark 3.1",
        "Explanation": "The paper claims that if (X,0) is normal (implying codim_C^n Sing(X) >= p+2), then `codim Sing(Fx) >= 3`. The justification provided is 'it follows as before from equality 3.1'. However, 'equality 3.1' (dim g(Sing(G)) <= p-1) and the entities g and G are not clearly defined in their first mention, and how this implies codim Sing(Fx) >= 2 (let alone >=3 using normality of X) is not adequately explained. Standard results usually guarantee codim Sing(Fx) >= 2 if Fx is reduced. Achieving codim >= 3 is a strong condition crucial for the subsequent argument (applying Corollary 1.4 to get H^1(U \\ Sing(Fx), O) = 0), and its derivation here is opaque and insufficiently justified."
      },
      {
        "Problem": "Unclear justification for `H^2(U \\ Sing(Fx), Z) = 0`.",
        "Location": "Page 8, first paragraph",
        "Explanation": "The argument for the existence of the global p-form ω_X relies on `H^1(U \\ Sing(Fx), O*) = 0`. This is derived from the long exact sequence associated with `0 -> Z -> O -> O* -> 0`, requiring both `H^1(U \\ Sing(Fx), O) = 0` (which depends on `codim Sing(Fx) >= 3`) and `H^2(U \\ Sing(Fx), Z) = 0`. The paper asserts `H^2(U \\ Sing(Fx), Z) = 0` by citing '[3, Chapter V, § 2]' (Giraldo-Roeder 2020). However, the vanishing of this cohomology group for the sheaf of integers is a non-trivial topological condition on `U \\ Sing(Fx)`. Without further details on why the conditions of the cited result are met, or a more direct argument, this step remains a critical unverified assertion."
      },
      {
        "Problem": "Incorrect algebraic manipulation involving the differential form η in the proof of Proposition 4.2.",
        "Location": "Page 13, definitions of η and d~f_L, and the relation `h_L(φ(y)) · η(y) = d~f_L(y)`",
        "Explanation": "In the proof of Proposition 4.2, the p-form η is defined as `η := Σ_I a_I(φ(y)) dy_I`, where `a_I(x)` are coefficients of `ω_X = Σ_I a_I(x) dx_I`, and `dy_I` are basis p-forms in y-coordinates. It is also stated that `d~f_L := d(f_L ο φ) = (h_L ο φ) · φ*(ω_X)`. The paper then claims `h_L(φ(y)) · η(y) = d~f_L(y)`. This equality implies `η(y) = φ*(ω_X)(y)` (assuming `h_L(φ)` is not identically zero). However, `φ*(ω_X) = Σ_I a_I(φ(y)) d(φ_I)`, where `d(φ_I) = d(φ_{i1}) ^ ... ^ d(φ_{ip})`. In general, `dy_I` (which is `dy_{i1} ^ ... ^ dy_{ip}`) is not equal to `d(φ_I)`. This apparent misidentification of forms invalidates the stated equality and the subsequent derivations in Section 5 that rely on it, including the application of Theorem 1.7 and the eventual contradiction via Lemma 5.1."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 11075,
      "output": 904
    }
  },
  {
    "entry_id": 53,
    "retraction_id": "1702.07688v4",
    "paper_id": "1702.07688v3",
    "retraction_comment": "I no longer believe that the conclusions are supported by the calculations done in this manuscript. The paper tried to determine what will limit the precision in practice. I incorrectly pointed to small 1 qubit (precision) errors happening everywhere in the circuits",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The critical role of 'a second round of rotations' (idle qubit errors) for linear error scaling, mentioned in the Supplement, is not adequately addressed in the main text's core argument.",
        "Location": "Main text (Fig. 2, discussion on pages 3-4) and Supplement (page 7, second bullet point under 'Let us end this pedestrian section with a few comments.')",
        "Explanation": "The Supplement (page 7) states: 'Without this second round of rotations, we would get results similar to the discrete error model.' This implies that the linear error scaling (E_0 ~ p_epsilon), which is the paper's main numerical result supporting its central claim, is not solely due to the CNOT error model of Eq. 5 (representing imperfect measurement direction) but critically depends on additional idle qubit errors occurring between stabilizer measurements. The main text attributes the linear scaling primarily to the precision p_epsilon of the measurement direction itself. If these intermediate idle errors (whose strength and justification are not detailed in the main text's simulation description) are essential for the linear scaling, the paper's argument that the 'direction of the measurement' is the fundamental loophole is significantly weakened or at least incompletely presented."
      },
      {
        "Problem": "The paper's CNOT error model (Eq. 5), representing imperfect measurement direction, is a specific type of coherent gate error. The argument that this error is fundamentally uncorrectable by fault tolerance (FT) and distinct from other coherent errors considered in FT literature needs stronger justification.",
        "Location": "Page 3 (Eq. 3 and surrounding discussion on measurement direction), Page 4 (Eq. 5 and surrounding text, particularly the claim 'the stabilizers g_tilde_i are not perfectly known').",
        "Explanation": "The error model in Eq. 5, Cx(i,j) = [(I_i + m_e . Sigma_i)I_j + (I_i - m_e . Sigma_i)X_j]/2, is equivalent to R_i CNOT_ideal R_dagger_i, where R_i is a small random rotation on the control qubit. This is a form of local coherent error. Standard FT frameworks have been developed to handle various types of coherent errors, often showing they can be mitigated if below a threshold. The paper needs to more rigorously demonstrate why this specific coherent error model, claimed to arise from 'measurement direction uncertainty,' uniquely circumvents all known FT principles, leading to a logical error E_L ~ p_epsilon. The assertion that the error is 'unknowable' because m_e is unknown (page 3) does not sufficiently distinguish it, as all random errors involve unknown instances."
      },
      {
        "Problem": "The methodology for simulating the measurement of effectively non-commuting stabilizers (g_tilde_i) and using the outcomes for syndrome extraction and correction is insufficiently detailed.",
        "Location": "Page 4, first column, statement: 'With finite precision, the stabilizers g_tilde_i are not perfectly known and do not commute perfectly with each other, a very different situation.' Also, the simulation protocol described on page 3, column 2.",
        "Explanation": "If the operators g_tilde_i (which are effectively measured due to the CNOT errors) do not commute, they cannot be simultaneously diagonalized. This means a 'syndrome' as a set of simultaneous eigenvalues is ill-defined. The order of measurements would matter, and measurements would disturb each other. Furthermore, if m_e in Eq. 5 is random for each CNOT instance, then the g_tilde_i themselves are random operators for each stabilizer measurement circuit execution. The paper does not explain how the simulation handles these issues to obtain a well-defined syndrome for correction, which is critical for the validity of the numerical results (e.g., Fig. 2)."
      },
      {
        "Problem": "The paper's statement about the equivalence of its CNOT error model to a global rotation is potentially inaccurate and misleading.",
        "Location": "Page 4, first column, the sentence following Eq. 5: 'Note that this is equivalent to applying a small one qubit rotation before and after an exact CNOT gate on all the physical qubits (except the ancilla).'",
        "Explanation": "Equation 5 describes the CNOT error as Cx(i,j) = [(I_i + m_e . Sigma_i)I_j + (I_i - m_e . Sigma_i)X_j]/2. This is equivalent to R_i CNOT_ideal R_dagger_i, where R_i is a rotation acting only on the control qubit 'i'. The cited statement, however, suggests an equivalence to a global rotation applied to 'all the physical qubits' in conjunction with each CNOT. This is a significantly different error model (a global coherent error or frame error vs. a local coherent error on the control qubit). Clarification is needed whether Eq. 5 or the described global rotation was simulated. If Eq. 5 was simulated, the description of its equivalence is inaccurate and could misrepresent the nature of the error being analyzed."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 11913,
      "output": 1126
    }
  },
  {
    "entry_id": 54,
    "retraction_id": "1408.2493v2",
    "paper_id": "1408.2493v1",
    "retraction_comment": "This paper has been withdrawn by the author. The proof of Theorem 6.2 is incorrect and the Theorem probably fails to be true",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Extreme complexity in the proof of OI([0,1]) ⇒ CBW",
        "Location": "Theorem 6.2, pages 19-20",
        "Explanation": "The proof that the Principle of Open Induction on [0,1] (OI([0,1])) implies the Contrapositive Bolzano-Weierstrass Theorem (CBW) involves a highly intricate construction of multiple auxiliary sequences (β, λ, κ, ρ, σ, ζ, μ) and a complex chain of deductions to establish that η ∈ H_α. The sheer number of intermediate steps and the subtlety of their interactions in a constructive proof make it difficult to verify its soundness exhaustively. A hidden flaw in this complex machinery could invalidate this specific implication and, consequently, parts of the equivalence chain relying on it, which is a central conclusion of the paper."
      },
      {
        "Problem": "Extreme complexity in the proof of AFT ⇒ (Bar ⊆ WF)",
        "Location": "Theorem 11.2 (i) ⇒ (ii), pages 39-40",
        "Explanation": "The proof that the Approximate-Fan Theorem (AFT) implies that 'any bar is well-founded under the Kleene-Brouwer ordering' (Bar ⊆ WF) is exceptionally complex. It involves constructing a fan Z from a supposed <_KB-descending chain, defining 'dead ends', a bar B, a thin bar B', applying AFT to B', and then constructing a sequence α from B' whose repetition leads to a contradiction. The validity of this proof hinges on the correctness of numerous sophisticated constructions and their properties (e.g., Z being a valid Explicit Approximate Fan, B' being a thin bar, the argument for α's repetition leading to the specific contradiction). This complexity may conceal errors, potentially invalidating a key implication for establishing equivalences with AFT."
      },
      {
        "Problem": "Extreme complexity in the proof of (Bar ⊆ WF) ⇒ EnDec?!",
        "Location": "Theorem 11.2 (ii) ⇒ (iii), pages 41-42",
        "Explanation": "The proof that 'Bar ⊆ WF' (if a set is a bar, its complement is well-founded under Kleene-Brouwer ordering) implies the principle EnDec?! is highly intricate. It involves defining auxiliary concepts like 's is fine for δ' and 's is final for δ', constructing a specific bar B from these, and then using sequences ε, ζ, λ to apply the Bar ⊆ WF principle. The deduction that λ(m) having an initial part in B leads to the conclusion n ∈ E_γ (the consequent of EnDec?!) is complex and relies on the precise interplay of these definitions. The high level of abstraction and multiple nested constructions make this proof susceptible to subtle errors, which could affect the claimed equivalence of EnDec?! with other principles."
      }
    ],
    "token_usage": {
      "input": 13540,
      "thinking": 15310,
      "output": 638
    }
  },
  {
    "entry_id": 55,
    "retraction_id": "2112.06228v2",
    "paper_id": "2112.06228v1",
    "retraction_comment": "Theorem 4.3 is missing the terms corresponding to the linear pentagon equation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency in the definition and usage of truncated multiple zeta values (MZVs) `ζ^n(w)`.",
        "Location": "Section 3.3 (especially Eq 3.4), Proof of Theorem 3.4 (p. 12-13), Corollary 4.4 (p. 15), Eq (1.1) (p.2).",
        "Explanation": "The paper defines truncated MZVs, denoted `ζ^m(k_1,...,k_r)` or `ζ^n(w)`, primarily through sum formulas (e.g., Eq (1.1), Eq (3.4) at x=1), which are linked to 'virtual posets'. Corollary 4.4 states that new associators `Φ_{KZ,m}` are formed by replacing MZV coefficients of `Φ_{KZ}` with these sum-defined truncated versions (`ζ_S^m`). However, the proof of Theorem 3.4, which is crucial for establishing that the transformation yields new associators (via Theorem 4.3), defines the action of the map `σ^n` (equivalent to `σ^m`) by modifying the *integral representation* of MZVs. Specifically, it replaces `dt/(1-t)` terms with `t^n dt/(1-t)` in the iterated integrals (see integrals on p.13). The values obtained from these modified integrals (`ζ_I^n`) are generally different from the sum-defined `ζ_S^n`. For instance, for `ζ(k)`, `ζ_I^n(k) = Σ_{s=n+k}^∞ 1/s`, while `ζ_S^n(k) = Σ_{n<j} 1/j^k = Σ_{j=n+1}^∞ 1/j^k`. These are different if k>1. This fundamental discrepancy means either the main result (Corollary 4.4) describes coefficients for which the associator property is not proven, or the proof of the associator property (Theorem 3.4 & 4.3) applies to different coefficients than those described in Corollary 4.4 and motivated by virtual posets."
      },
      {
        "Problem": "The argument that the map `σ^n` (transforming MZVs to truncated MZVs `ζ_S^n`) is a shuffle algebra morphism on the algebra of MZV values is incomplete or potentially incorrect.",
        "Location": "Theorem 3.4, Lemma 2.3, Theorem 4.3.",
        "Explanation": "The construction of new associators (Theorem 4.3) relies on `σ^n` being a shuffle algebra morphism acting on the MZV coefficients of `Φ_{KZ}`. The proof of Theorem 3.4 invokes Lemma 2.3, which requires that the map `w ↦ ζ_S^n(w)` (where `ζ_S^n(w)` are the sum-defined truncated MZVs from Eq 3.4 / Corollary 4.4) is itself a shuffle morphism from the algebra of words `(h^0, ш)` to `(R, .)`. It is not proven in the paper that these sum-defined truncated MZVs `ζ_S^n(w)` satisfy the shuffle relations (i.e., that `ζ_S^n(w_1) ζ_S^n(w_2) = ζ_S^n(w_1 ш w_2)`). Truncated sums of this type often do not preserve all algebraic relations of the original full sums. If `w ↦ ζ_S^n(w)` is not a shuffle morphism, Lemma 2.3 does not apply, and `σ^n` (mapping `ζ(w) ↦ ζ_S^n(w)`) is not guaranteed to be an algebra morphism on the algebra of MZV values. This would undermine the proof that `σ^n(Φ_{KZ})` satisfies the pentagon equation and is group-like."
      },
      {
        "Problem": "The definition of coefficients for the 'disk of associators' introduces a third, distinct type of modified MZV, for which the shuffle algebra morphism property is also not established.",
        "Location": "Section 4.2 (p. 15-16, especially the sum formula at the top of p. 16).",
        "Explanation": "Section 4.2 generalizes the discrete truncation parameter `m` to a complex parameter `z`. The explicit sum formula provided for the coefficients `σ^z(ζ(k_1,...,k_r))` on page 16 (top) is `ζ_D^z = Σ_{0<n_1<...<n_r} 1/((z+n_1)^{k_1}(2z+n_2)^{k_2}...(rz+n_r)^{k_r})`. This definition (`ζ_D^z`) is structurally different from both the sum-defined `ζ_S^z` (from Eq 3.4, which would be `Σ_{z<n_1, n_1+z<n_2,...} 1/(n_1^{k_1}...n_r^{k_r})`) and the integral-defined `ζ_I^z` (from the proof of Theorem 3.4, involving `t^z` factors in integrals). The paper does not demonstrate that these `ζ_D^z` coefficients arise from a shuffle algebra morphism `ζ(w) ↦ ζ_D^z(w)`. Without this, the claim that these `Φ_{KZ,z}` (using `ζ_D^z`) form a family of associators is unsupported, as the arguments from Theorem 3.4 and 4.3 do not directly apply to `ζ_D^z`."
      },
      {
        "Problem": "The derivation of the specific sum formula for truncated MZVs (Eq 3.4) from the 'virtual poset' operations is unclear and potentially inconsistent.",
        "Location": "Section 3.2 (p. 9-11), Section 3.3 (p.12, definition of `ζ^n(A^{q_r}B^{p_r}...A^{q_1}B^{p_1})` and its intended connection to Eq 3.4).",
        "Explanation": "The paper aims to derive the sum-defined truncated MZVs `ζ_S^m` (Eq 3.4) using operations on power series associated with 'virtual posets'. The key starting block is `||*^{m+1}(x) = x^{m+1}/(1-x)`. Applying `k-1` operations of `\\<1>|` (which corresponds to `∫ dy/y`) to this and evaluating at `x=1` yields `Σ_{s=m+1}^∞ 1/s^k`. This matches `ζ_S^m(k)`. However, for multiple zeta values, Eq (3.4) involves nested sums with characteristically shifted indices like `m<n_1`, `n_1+m<n_2`, etc. The paper uses a `circledast` operation for concatenation (defined on p.10 as `f(x) circledast g(x) := |<1>|*^+(f(x)*g(x))`, which simplifies to `(1/(1-x))f(x)g(x)` if `|<1>|(x)=x/(1-x)^2`). It is not shown how this operation, combined with others, leads to the specific shifted sum structure of Eq (3.4). If this derivation is flawed, the foundational link between the virtual poset formalism and the sum-defined truncated MZVs `ζ_S^m` is weakened, impacting the conceptual basis of the construction."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 14256,
      "output": 1736
    }
  },
  {
    "entry_id": 56,
    "retraction_id": "1311.7114v2",
    "paper_id": "1311.7114v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the derivation of equation 24 and 25",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect analytical formula for partitioned two-electron integrals.",
        "Location": "Page 3, Eqs. (25)-(28)",
        "Explanation": "The analytical formula (Eq. 26) provided for calculating partitioned two-electron integrals over s-type Gaussian functions, which forms the basis for all two-electron integrals in the Obara-Saika scheme, appears fundamentally incorrect. The structure `[S(p)_rt S(q)_su + S(q)_rt S(p)_su] F₀(T)` involves products of partitioned overlap integrals where each overlap integral (e.g., `S(p)_rt = ∫ φ_r(r) θ_p(r) φ_t(r) dr`) mixes basis functions associated with different electrons (e.g., `φ_r` for electron 1, `φ_t` for electron 2). This structure does not correspond to the required integral form `∫dr₁dr₂ [Θ_p,q(r₁,r₂)/|r₁-r₂|] (φ_r(r₁)φ_s(r₁)) (φ_t(r₂)φ_u(r₂))`, which describes the interaction of electron densities. The normalization prefactor in Eq. (26) also appears inconsistent with standard two-electron integral expressions. If this formula is implemented as written, the calculated partitioned two-electron interaction energies, and consequently the total partitioned energies, would be erroneous, invalidating the quantitative results of the study."
      },
      {
        "Problem": "Incorrect analytical formula for partitioned kinetic energy integrals.",
        "Location": "Page 3, Eq. (21)",
        "Explanation": "The analytical formula for partitioned kinetic energy integrals, `T(p)_rs = -(1/2) [3η - 2η²(R_A - R_B)²] S(p)_rs`, appears dimensionally incorrect. Given η = ξ_rξ_s/(ξ_r+ξ_s) (where ξ are Gaussian exponents with units of length⁻²), the term `[3η - 2η²(R_A - R_B)²]` has units of length⁻², not energy. For the equation to yield energy, a physical constant (like ħ²/2m_e, which is 1/2 in a.u.) or appropriate conversion factor is missing. Additionally, the formula seems to rely on an approximation `T(p)_rs ≈ (T_rs/S_rs)S(p)_rs` (after correcting units/factors), where `T_rs` is the unpartitioned kinetic energy integral. This approximation, which factors the operator's effect from the spatial partitioning `θ_p(r)`, can lead to inaccuracies, particularly for basis functions near the boundary of the subsystem."
      },
      {
        "Problem": "Incorrect analytical formula for partitioned nuclear attraction integrals.",
        "Location": "Page 3, Eq. (23)",
        "Explanation": "The analytical formula for partitioned nuclear attraction integrals, `V(p)_rs = Σ_α (-Z_α) (2(π/ζ)¹ᐟ²) F₀(ζ(R_P-R_α)²) S(p)_rs`, contains a factor `(π/ζ)¹ᐟ²` which is typically associated with 1D Gaussian integrals, while `2π/ζ` (or `π/ζ`) is expected for 3D s-Gaussians interacting with a point charge. More critically, similar to the kinetic energy integrals, this formula relies on the approximation `V(p)_α,rs ≈ (V_α,rs/S_rs)S(p)_rs`, where `V_α,rs` is the unpartitioned nuclear attraction integral. Factoring the operator's effect from the spatial partitioning `θ_p(r)` is a questionable approximation that can introduce significant errors, especially when basis functions are near or cross the subsystem boundary."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 10718,
      "output": 868
    }
  },
  {
    "entry_id": 57,
    "retraction_id": "1206.3652v3",
    "paper_id": "1206.3652v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in Theorem 2.6 under the metric of Grassmannian manifolds induced from the riemannian submersion",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed su(2) algebra construction for complex surfaces.",
        "Location": "Page 9, proof of Theorem 2.5, part 2 (Im μ ≠ 0 case).",
        "Explanation": "The paper claims that elements X̂, iX̂ (tangent vectors to the complex surface S) and K̂ (proportional to [X̂, iX̂]) form a Lie algebra isomorphic to su(2). However, deriving the necessary commutation relations (e.g., [K̂, X̂] = const⋅(iX̂), [K̂, iX̂] = const⋅X̂) using the condition (2-1) (X*X=λI_n, XX*=(λ+2)I_m) leads to contradictions (e.g., requiring λ=-2 and X=0, which contradicts λ≠0 from condition (2-1) for Im μ ≠ 0). This failure to establish the su(2) algebra invalidates the claimed isomorphism to a Hopf bundle structure, which is essential for the λ=1/2 conclusion in Theorem 2.6."
      },
      {
        "Problem": "Inconsistent properties of the Lie algebra element K.",
        "Location": "Page 9, proof of Theorem 2.5, part 2.",
        "Explanation": "In the context of Im μ ≠ 0 (complex surface S), the element K (denoted K̂ in thought process) is described in two contradictory ways. First, it's implicitly defined as part of an su(2) algebra, K = [X̂, iX̂]/2 (scaled). This calculation yields K = [[iXX*, 0]; [0, iX*X]]. Given X*X=λI_n from condition (2-1) (where λ≠0 for this case), K has a non-zero u(m)-component iλI_n. Second, K is explicitly stated as K = [[-M_K, 0]; [0, O_m]], implying K ∈ u(n) (i.e., its u(m)-component is zero). These two descriptions of K are contradictory if λ≠0. This inconsistency undermines the argument that K generates a U(1) action purely within the U(n) fiber, which is necessary for the Hopf bundle analogy."
      },
      {
        "Problem": "Erroneous orthogonality argument for K.",
        "Location": "Page 9, proof of Theorem 2.5, part 2, the sentence starting 'Since Span_R{X̂, iX̂, K̂} ⊥ u(m)...'",
        "Explanation": "The proof states that Span_R{X̂, iX̂, K̂} is orthogonal to u(m). While X̂ and iX̂ (as elements of m_G) are orthogonal to u(m), the element K̂ = [X̂,iX̂]/2 is not. As shown, K̂ has a u(m)-component equal to iX*X = iλI_n. If λ≠0 (the case for complex surfaces), this component is non-zero, meaning K̂ is not orthogonal to u(m). This false premise invalidates the subsequent argument for inducing the bundle map from the S(U(1)xU(1)) fibration to the target U(n) fibration over S, which is a key step in proving Theorem 2.5 part 2."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 14166,
      "output": 767
    }
  },
  {
    "entry_id": 58,
    "retraction_id": "1511.00057v2",
    "paper_id": "1511.00057v1",
    "retraction_comment": "Several proofs were found to be incomplete or in error including the proof that quantum rotations can induce arbitrary noise weights. A fully corrected version of this paper is published as: A. Paris, G. Atia, A. Vosoughi, and S. Berman, \"Hidden quantum processes, quantum ion channels, and 1/f-type noise\", [REDACTED-NAME], vol. 30, num. 7, pp. 1830-1929 (2018), doi:https://doi.org/10.1162/neco_a_01067",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition and properties of the multi-time state for an 'activated measurement process' are inadequately specified and justified, with a critical part of Corollary 2.2.2.1 missing.",
        "Location": "Definition 2.2.2.3 (page 13), Corollary 2.2.2.1 (page 13)",
        "Explanation": "Definition 2.2.2.3 provides a differential equation for the multi-time state Ψ(t1,...,tn). The resulting structure is unusual and its properties, particularly its characterization as a 'Poisson mixture of states' for the multi-time case, are not clearly established. Crucially, Corollary 2.2.2.1, which should elaborate on the properties of Ψ(t1,...,tn-1,tn), has an incomplete statement ('satisfies ... for tn ≥ tn-1'), leaving a gap in the formal description of this process. This undermines the foundation of subsequent theorems that rely on this process."
      },
      {
        "Problem": "The proof of Theorem 2.2.4.1, establishing the equivalence between diagonalizable hidden activated measurement models and formal hidden Markov models, relies on an unsubstantiated and potentially contradictory assertion about the structure of the multi-time quantum state Ψ(t1,...,tn).",
        "Location": "Proof of Theorem 2.2.4.1 (pages 17-18, specifically the assertion on page 18, top)",
        "Explanation": "The proof claims that the full quantum stochastic process Ψ(t1,...,tn) 'is the tensor product of such Poisson-Markov states.' However, the explicit construction of Ψ(t1,...,tn) in Definition 2.2.2.3 (page 13) does not obviously lead to such a simple tensor product structure. If Ψ(t1,...,tn) does not conform to this asserted structure, the subsequent derivation of HMM-like posterior probabilities is invalid, thereby undermining the paper's central claim of distributional equivalence between its quantum model and HMMs."
      },
      {
        "Problem": "The claim that Equation 10 uniquely defines a 'nonnegative definite hermitian operator E' (configuration energy operator) from a given kinetic rate matrix K lacks sufficient justification, and the construction of the auxiliary matrix Dπ is potentially problematic.",
        "Location": "Definition 3.1.0.3 and Equation 10 (pages 18-19)",
        "Explanation": "Equation 10 aims to extract an energy operator E from an HMM rate matrix K. The existence and uniqueness of E with the required properties (hermitian, non-negative definite) are asserted but not proven. The transformation involves a matrix Dπ, whose definition and example (Dπ = diag(πH)) require specific conditions (e.g., p∞ entries positive, π complex). The properties of K and Dπ must ensure that λ(T)⁻¹ Dπ⁻¹ K Dπ, when restricted to the relevant subspace, is hermitian and positive semi-definite to guarantee a valid E. This is not shown, and the hermiticity of E is critical for its physical interpretation."
      },
      {
        "Problem": "Equation 11, which defines the squared modulus of the ion activator Q(T)|2| based on the energy operator E, appears to be inconsistent with its role in generating a general HMM kinetic rate matrix K.",
        "Location": "Equation 11 (page 19) and its relation to Theorem 3.1.0.2 and K = λ(Q|2|-I)",
        "Explanation": "Equation 11 presents Q(T)|2| as I + a matrix that is diagonal in the E-basis (or nearly so, with a single specific non-zero entry structure). If Q(T)|2| is diagonal (or very sparse), then the resulting kinetic rate matrix K = λ(T)(Q(T)|2| - I) would also be diagonal (or very sparse). This implies that the HMM states do not transition between each other, or do so in a very restricted way, which contradicts the behavior of typical multi-state ion channel models described by non-diagonal K matrices. This disconnects the derived energy E from the original HMM kinetics."
      },
      {
        "Problem": "The major claim that the proposed framework can explain 1/f-type noise in neuronal signals is not substantiated within the paper.",
        "Location": "Abstract (page 1), Introduction (page 2, §1.2.3), and Section 3.2 (page 19)",
        "Explanation": "The abstract and introduction highlight the explanation of 1/f noise as a key result, to be demonstrated in §3.2 using a 'generalized van der Ziel-McWhorter formalism.' However, Section 3.2 ('Neuronal Noise') only presents Lemma 3.2.0.1, which describes the autocovariance function for a standard HMM. This function leads to a sum of exponentials (Lorentzian spectra), not 1/f noise. The promised derivation or explanation of 1/f noise is absent from §3.2 and the rest of the provided text, leaving a critical application unsupported."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 10166,
      "output": 1150
    }
  },
  {
    "entry_id": 59,
    "retraction_id": "1704.08680v2",
    "paper_id": "1704.08680v1",
    "retraction_comment": "Withdrawn by the author. In particular, Lemma 4 and hence Lemma 5 are incorrect invalidating the claimed result",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Justification for short-cutting node selection in Phase III",
        "Location": "Page 7 (Algorithm description, short-cutting operation), Page 8 (Algorithm 3, line 11), Page 13 (Setup for Lemma 5)",
        "Explanation": "The short-cutting operation in Phase III requires selecting 'd' frontier nodes from Δ2(C) (the frontier of C in T2) that are described as having no \"incoming edges\" from within C along T2. The paper justifies the possibility of such selection by stating (page 13): \"This is possible by the proof of Lemma 4 since there can be at most 1 node with an incoming edge.\" However, Lemma 4 (page 12) establishes this structural property (\"at most one of the s_i's has an incoming edge\") for nodes s_i ∈ Δ1(C) (the frontier of C in T1) based on the structure of T1 resulting from Phase I. It is not demonstrated or proven that this structural property transfers to Δ2(C) with respect to T2, which can differ from T1. If the required nodes for short-cutting cannot always be selected from Δ2(C) as described, the short-cutting operation is ill-defined, potentially invalidating Phase III of the algorithm and, consequently, the main result."
      },
      {
        "Problem": "Soundness of Lemma 5 proof for bounding short-cut edge costs",
        "Location": "Page 13, Proof of Lemma 5",
        "Explanation": "Lemma 5 is critical as it bounds the cost of short-cut edges, a necessary step for the overall cost analysis in Theorem 7. The proof of Lemma 5 appears to contain unclear or potentially flawed arguments. For instance, it references conditions from Phase I (e.g., \"Assume now that e_i is deleted in the reverse-delete step of the first phase\") when analyzing edges related to T2 and dual variables from Phase II or III (y^2 or y^3). The logical progression to the contradiction (\"degree of C is higher in the first phase than the assumed value\") is not clearly established. Furthermore, assertions about relationships between dual values (e.g., \"y_C1 ≤ y^2_C1\" where y_C1 is implicitly y^3_C1) are not sufficiently justified in the context of comparing duals accumulated in different phases or iterations. If Lemma 5 is unsound, the cost accounting for the final tree T in Theorem 7 is compromised, potentially invalidating the claimed 6/5 approximation ratio."
      },
      {
        "Problem": "Insufficient justification for the \"at most one incoming edge\" structural claim in Lemma 4",
        "Location": "Page 12, Proof of Lemma 4",
        "Explanation": "The proof of Lemma 4 asserts a key structural property: \"First, observe that at most one of the s_i's [nodes in Δ1(C), the frontier of C in T1] has an incoming edge [an edge (u, s_i) where u is also in C and (u,s_i) is in T1] since others are redundant and deleted in the first phase.\" This property is foundational for the argument in Lemma 4 and is later invoked (problematically, as noted in Problem 1) to justify short-cutting in Phase III. While this property might hold for tree structures generated by a primal-dual algorithm with a reverse-delete step, it is presented as an observation rather than being rigorously proven. A more detailed proof of this non-trivial structural claim for Δ1(C) within T1 would be necessary to solidify the argument, even before considering its extension to Δ2(C) in T2."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 15224,
      "output": 825
    }
  },
  {
    "entry_id": 60,
    "retraction_id": "2406.04846v2",
    "paper_id": "2406.04846v1",
    "retraction_comment": "The claim in this manuscript is incorrect due to a mistake in Eq. (6). The reason is that expression in Eq. (6) is derived in real arithmetic. It is incompatible with the modulo 2 arithmetic in the state ket",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Circular dependency in the proposed recursive gate construction",
        "Location": "Page 2, Fig. 1 (red zone) and Fig. 2; and their interplay in the recursion described on p.2-3.",
        "Explanation": "The proposed method aims to construct a fault-tolerant logical gate P(α)_L. This is done using gate teleportation (Fig. 2), which requires the state |Θ(α)⟩_L and the gate P(2α)_L. The state |Θ(α)⟩_L = (|0⟩_L + e^(iα)|1⟩_L)/√2 is prepared using the circuit in Fig. 1. The red zone of Fig. 1, which creates |Θ(α)⟩_L, explicitly applies the logical gate P(α)_L to H_L|0⟩_L. Therefore, the gate P(α)_L (or a gate of the same angle α) is used as a component in the preparation of a state that is then used to implement P(α)_L itself. This constitutes a circular dependency, invalidating the construction method as a way to generate P(α)_L from simpler or already available gates."
      },
      {
        "Problem": "Flawed state verification protocol in fault-tolerant state preparation",
        "Location": "Page 2, Fig. 1 and its caption/description.",
        "Explanation": "Fig. 1 describes the fault-tolerant preparation of the state |Θ(α)⟩_L. After the state is supposedly created by the circuit in the red zone, it is verified by measuring the operator M = P(α)_L X_L P(-α)_L. The state is kept only if the measurement yields +1. However, the state |Θ(α)⟩_L = (|0⟩_L + e^(iα)|1⟩_L)/√2 is generally not an eigenstate of M for arbitrary α (it is an eigenstate only for α=0 or α=π, where M becomes ±X_L). For other α, measuring M projects |Θ(α)⟩_L onto a different state or a superposition, so the described post-selection step is ill-defined for verifying |Θ(α)⟩_L. This makes the claimed fault-tolerant state preparation procedure unsound."
      },
      {
        "Problem": "Unjustified assumption of readily available fault-tolerant arbitrary physical phase gates",
        "Location": "Page 2, Eq. (4) and its surrounding text; Page 3, Conclusions.",
        "Explanation": "The paper proposes implementing logical phase gates P(β)_L (such as P(2α)_L in Fig. 2, or P(α)_L used in Fig. 1) via transversal application of physical gates: P(β)_L = Π_j P(βv_j) (Eq. 4). For the logical gate P(β)_L to be fault-tolerant, the constituent physical gates P(βv_j) must themselves be fault-tolerant. The paper assumes that such physical P(θ) gates for arbitrary (or very finely-grained) angles θ = βv_j can be applied fault-tolerantly (e.g., page 3, Conclusions: \"one can apply P(α) on each qubit and hence P(α)_L on the logical qubit relatively easily\"). This is a strong assumption that sidesteps the primary challenge of fault-tolerant quantum computing, which is typically limited to a discrete set of elementary fault-tolerant gates (e.g., Clifford+T). The cost and method for achieving these arbitrary physical FT phase gates are not addressed, yet they are crucial for the entire scheme's validity and claimed efficiency."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 10215,
      "output": 820
    }
  },
  {
    "entry_id": 61,
    "retraction_id": "2306.09163v2",
    "paper_id": "2306.09163v1",
    "retraction_comment": "Theorem 1 is false for A = F_2[x]/(x^3): (A, +) \\cong C_2 x C_2; (A, \\circ) \\cong C_4",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Theorem 1, claiming s(A,o) = s(A,+), appears flawed.",
        "Location": "Section 2, Proof of Theorem 1, pages 3-4.",
        "Explanation": "The proof of Theorem 1, which asserts that the number of subgroups of the circle group (A,o) equals the number of Fp-subspaces of A (subgroups of (A,+)), seems to incorrectly apply Fp-linear algebra counting methods (RREF, parameter counting p^(n(M))) to subgroups of (A,o). Subgroups of (A,o) are not generally Fp-vector subspaces. The argument that o-row operations are equivalent to +-row operations 'modulo A^(i+1)' does not sufficiently establish that the global count of subgroups will be identical, as the nature of subgroups and the definition of scalar multiplication (integer vs. Fp scalar) differ. This equality is foundational to all GCR calculations in the paper."
      },
      {
        "Problem": "The asymptotic expression for GCR in the statement of Theorem 3 is inconsistent with its derivation.",
        "Location": "Section 4, Theorem 3 statement and its derivation, page 9.",
        "Explanation": "The asymptotic expression for the GCR given in the statement of Theorem 3 (GCR is at most ~ p^X where X is given as -(n_e/2)^2(n^(2e)(n-1)), interpreting n_e as a term involving n and e) does not match the exponent t = di_max - ds derived on page 9 (where t = (n^2/4) * [ (n^(2e)-1)/(n^2-1) - ((n^e-1)/(n-1))^2 ]). The derived t simplifies to approximately -(1/2)n^(2e-1) for large n and e. The exponent stated in Theorem 3 implies a significantly different and stronger rate of decay. This is a substantial discrepancy in the paper's main asymptotic result."
      },
      {
        "Problem": "Potential miscalculation of the number of left ideals i(A) for the algebra A_24.",
        "Location": "Section 3, page 6.",
        "Explanation": "In the calculation of the number of left ideals i(A) for the algebra A_24, the paper arrives at i(A) = p^3 + 2p + 4. This sum relies on the number of parameters (Ms) for specific pivot sequences corresponding to ideals. For the pivot sequence S=234, the paper implicitly uses Ms=0 (contributing a '1' to the sum of p^Ms terms). However, an ideal whose RREF has pivot sequence S=234 (e.g., generated by {b+xa, c, d}) appears to have Ms=1 free parameter (x). If Ms=1 for S=234, i(A_24) would be p^3 + 3p + 3. This would alter the GCR for this specific illustrative example."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 16581,
      "output": 689
    }
  },
  {
    "entry_id": 62,
    "retraction_id": "1607.07976v3",
    "paper_id": "1607.07976v2",
    "retraction_comment": "The statement about approximate equality of phase and group velocities is incorrect. Therefore, all arguments based on this statement are unfounded",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental issue with the assumed equality of laser phase and group velocities (v_ph,laser = v_g).",
        "Location": "Page 30 (assumption [ω_0 ≈ 0]|_PCM), Page 21 (justification for v_ph=v_g), Eq. (10) and related discussions.",
        "Explanation": "The paper assumes that the laser carrier frequency is approximately zero in the pulse co-moving (PCM) frame (ω_0|_PCM ≈ 0). This leads to the conclusion that the laser's phase velocity (v_ph,laser) equals its group velocity (v_g). This equality is generally incorrect for a pulse propagating in a dispersive medium like plasma, as it implies either no dispersion (ω_p=0) or v_g=c (which also implies ω_p=0 if the standard EM dispersion relation ω² = ω_p² + c²k² holds). The paper's justification on page 21 that 'the laser pulse is a pure radiation and not a packet of electromagnetic modes, therefore its local phase and group velocities may equal' is physically unsound for a pulse, which is inherently a superposition of modes. This flawed premise underpins key derivations for spectral evolution (e.g., Eq. (10)) and subsequent interpretations of pulse dynamics, potentially invalidating conclusions regarding quantitative predictions of frequency shifts and pulse amplification."
      },
      {
        "Problem": "Incorrect formula for frequency shift in electromagnetic cascading and its use to derive vacuum dispersion for generated modes.",
        "Location": "Equation (11b) on page 40, and derivation of Equation (11e) on page 42.",
        "Explanation": "Equation (11b) for the frequency ω of generated modes, given as ω = ω_0 + γ_g c Δk|_PCM, appears to be incorrect. A consistent Lorentz transformation for frequency from the PCM frame (where ω|_PCM ≈ ω_0|_PCM and k|_PCM = k_0|_PCM + Δk|_PCM) to the lab frame yields ω = ω_0 + γ_g v_g Δk|_PCM (or ω = ω_0 + γ_g c β_g Δk|_PCM). The paper seems to use the form with 'c' instead of 'v_g' (or cβ_g) to derive Eq. (11e) (ω=ck), concluding that new modes appear on the vacuum dispersion curve. If Eq. (11b) is incorrect as stated, then the derivation of Eq. (11e) is not sound. This would invalidate the conclusion that the generated spectral components follow the vacuum dispersion relation under the stated conditions."
      },
      {
        "Problem": "Unjustified substitution of global group velocity with local phase velocity in the non-adiabatic model.",
        "Location": "Page 47, discussion on modifying Eqs. (10), (11a), (11b) for non-adiabatic effects.",
        "Explanation": "To model non-adiabatic effects such as phase modulation, the paper proposes replacing the global pulse group velocity parameters {β_g, γ_g} with local plasma phase velocity parameters {β_ph.l, γ_ph.l} in equations (10, 11a, 11b). These equations were originally derived based on Lorentz transformations pertaining to a single, global PCM frame (moving at v_g) and the assumption of ω|_PCM ≈ 0. Substituting a spatially varying local phase velocity (β_ph.l) into these global-frame equations lacks rigorous justification. This ad-hoc modification appears to break the self-consistency of the theoretical framework established for the adiabatic regime, making the subsequent predictions for spectral changes due to phase deceleration (e.g., multi-hump structures) unreliable."
      }
    ],
    "token_usage": {
      "input": 13282,
      "thinking": 9605,
      "output": 836
    }
  },
  {
    "entry_id": 63,
    "retraction_id": "2006.15984v5",
    "paper_id": "2006.15984v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial definition error of Canonical Huffman Table",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The optimization objective F(x) for file size increment neglects byte-alignment and zero-byte padding, yet these factors are later acknowledged as sources of fluctuation in experimental file increment results.",
        "Location": "Page 10, end of Section 4.1; Page 23, discussion of Table 3",
        "Explanation": "The paper states on page 10 that file size changes from byte alignment and zero-byte padding are neglected in the objective function F(x) because they are considered small and hard to calculate pre-encoding. However, on page 23, fluctuations in the experimental file increment (FI) are attributed to these very factors. This discrepancy means the Genetic Algorithm (GA) is optimizing an imprecise target. If these unmodelled factors are significant enough to cause noticeable fluctuations, their omission from the optimization objective could lead to suboptimal solutions in terms of actual file size, potentially missing the true minimum file increment."
      },
      {
        "Problem": "The GA-based optimization strategy has unclear, poorly justified, and potentially suboptimal NFRS selection criteria for its fixed set of 10 NFRSs, and does not specify behavior for images with fewer than 10 NFRSs.",
        "Location": "Page 15, Section 5.1.1; Section 5.1.2",
        "Explanation": "The GA implementation optimizes the mapping sequence `x_i` for a fixed number of 10 NFRSs. The method for selecting these 10 NFRSs is opaquely described on page 15 as 'consecutively ones, and the leftmost one is the closest to and greater than the required capacity,' which is confusing and difficult to reproduce. This arbitrary restriction to 10 NFRSs (out of potentially many more) and the unclear selection criteria could lead to suboptimal solutions for the general N-dimensional problem stated in Section 4.1. Furthermore, the paper does not specify how the GA adapts if an image contains fewer than 10 NFRSs, which could lead to errors or invalid operations."
      },
      {
        "Problem": "The GA optimization for 10 NFRSs does not appear to dynamically incorporate the JPEG constraint that the total sum of customized VLCs (sum(xi) over all NFRSs) must be less than or equal to 256.",
        "Location": "Page 9 (Constraint 2 for Eq. 1); Page 10 (sum of x is N to 256); Section 5.1",
        "Explanation": "The JPEG standard limits the total number of entries in the HUFFVAL list (i.e., `sum(xi)` over all N NFRSs) to 256. The GA optimizes `x_i` for 10 NFRSs. If the remaining `N_total - 10` NFRSs are assigned `x_j=1` (to ensure they can be encoded), then the sum of the 10 optimized `x_i` values is constrained by `sum_{k=1 to 10} x_k <= 256 - (N_total - 10)`. This upper bound can be very restrictive if `N_total` (total number of NFRSs in the image) is large. The GA description in Section 5.1 does not state that it adapts this constraint for the 10 chosen `x_i`s based on `N_total`. If this overall constraint is not properly managed by the GA, it might generate individuals (mapping sequences) that are invalid for images with a large number of NFRSs, as the total `sum(xi)` could exceed 256."
      }
    ],
    "token_usage": {
      "input": 8896,
      "thinking": 15698,
      "output": 809
    }
  },
  {
    "entry_id": 64,
    "retraction_id": "1512.06616v5",
    "paper_id": "1512.06616v4",
    "retraction_comment": "Withdrawn after detection of a major error in the C-E expansion",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Maxwell-Boltzmann approximation for negative-chirality electrons.",
        "Location": "Page 10, Eq (51) to Eq (52); Remark 5.3 (page 11)",
        "Explanation": "The derivation of the Maxwell-Boltzmann (M-B) diffusive transmission conditions (Eq. 52) from the Fermi-Dirac (FD) form (Eq. 51) relies on approximating w_s^eq (or related ftilde_s^eq). For negative chirality electrons (s=-), w_-^eq describes particles in the lower Dirac cone. The M-B approximation effectively used for w_-^eq (or ftilde_-^eq = w_-^eq(x,-p)) appears to be w_-^eq(x,-p) ~ exp(A_-^w + beta*c*|p|). This form is valid if the chemical potential A_-^w (for w_-) is very negative, which corresponds to the chemical potential for holes (A_-^f = -A_-^w) being very positive. A very positive A_-^f signifies a highly degenerate regime for holes. This contradicts the usual M-B assumption of non-degeneracy (A_s^f << 0). This inconsistency in applying the M-B approximation for the s=- case could undermine the validity of the derived M-B transmission conditions (Eq. 52, 53) and the final model."
      },
      {
        "Problem": "Non-standard formulation of the Milne problem.",
        "Location": "Page 9, Section 5.2, Eq (41), (43), (44); Page 10, Theorem 5.2",
        "Explanation": "The Milne problem, crucial for deriving the boundary layer corrector and diffusive transmission conditions, is defined by Eq. (41) (or 43a, 43b) where the equilibrium distribution f_s^eq (or theta_s^(i,eq)) is constrained by Eq. (44): its integral (density) must match the integral of the solution f_s (or theta_s^i) itself. This means the chemical potential of theta_s^(i,eq) becomes spatially dependent within the boundary layer, A_s^(i,eq)(xi), and coupled to the solution theta_s^i(xi). This is a non-standard, potentially non-linear, formulation of the Milne problem. Classical results on Milne problems (e.g., Ref. [1]) typically assume a fixed equilibrium distribution on the right-hand side of the transport equation. The existence, uniqueness, and stated asymptotic behavior (Theorem 5.2) for this non-standard Milne problem may require more rigorous justification than provided, and if these properties do not hold as claimed, the subsequent derivation of the diffusive transmission conditions is compromised."
      },
      {
        "Problem": "Unsubstantiated claim about the Fermi-Dirac transmission condition being 'too demanding'.",
        "Location": "Page 10, discussion between Eq (51) and Eq (52)",
        "Explanation": "The paper states that the first-order Fermi-Dirac transmission condition (Eq. 51) 'is in general a too demanding condition,' and this serves as a motivation to adopt the Maxwell-Boltzmann (M-B) approximation leading to Eq. (52). However, the reasons why Eq. (51) would be 'too demanding' are not provided. Eq. (51) represents B(w^eq + tau * theta^inf) = 0, which implies B(w^eq) = -tau * B(theta^inf). This is a standard structure for first-order corrections to boundary conditions, where the deviation from bulk equilibrium (B(w^eq)) is related to a flux-dependent term (B(theta^inf)). While solving this with Fermi-Dirac statistics might be complex, calling it 'too demanding' without further justification is a weak point. If Eq. (51) is actually well-posed, then resorting to the M-B approximation is a choice of simplification, not a necessity forced by the ill-posedness of the FD condition. The lack of explanation for this critical step makes it difficult to assess the true need for the M-B approximation at this juncture."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 15782,
      "output": 942
    }
  },
  {
    "entry_id": 65,
    "retraction_id": "2309.14057v2",
    "paper_id": "2309.14057v1",
    "retraction_comment": "Our description in Chapter 3, Section 3.2 of the paper is too repetitive with the paper \"Object detection meets knowledge graphs\". There is an error in the description of formula (5) in Section 3.3. And a detailed reasoning process is required for formula (5). Therefore, we wish to request a retraction of the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Matrix operation inconsistency in GRM update rule",
        "Location": "Equation (8), Page 16; Figure 5, Page 15",
        "Explanation": "Equation (8) defines the GRM update as X^(l+1) = σ(H_v * V^(l+1)) + X. Given H_v ∈ R^(C x HW) (compatibility matrix) and V^(l+1) (GCN output V' ∈ R^(C x D)), the standard matrix multiplication H_v * V^(l+1) is not well-defined. Figure 5 suggests a different operation, likely involving V'^T * H_v, which would result in dimensions (D x C) * (C x HW) = (D x HW), compatible for reshaping and adding to X. This inconsistency between the textual equation and the probable intended operation (and diagrammatic representation) makes the core GRM update rule unclear and potentially erroneous as written."
      },
      {
        "Problem": "Incorrect or unsubstantiated formula for Semantic Relation Matrix",
        "Location": "Equation (3), Page 13",
        "Explanation": "Equation (3) defines the semantic relationship E_c,c' as E_c,c' = E_c',c = sqrt(R_c,c' / R_c',c), where R_c,c' is a transition probability. This formula is not generally symmetric if R_c,c' ≠ R_c',c. For example, if R_c,c'=0.8 and R_c',c=0.2, then E_c,c' = sqrt(4)=2, while E_c',c based on the formula would be sqrt(0.2/0.8)=0.5, contradicting the stated E_c,c' = E_c',c. The cited reference (Fang et al., 2017) uses a different, symmetric formula (average of probabilities). This suggests the formula in Equation (3) is either a misrepresentation, a typo, or a novel, unexplained formulation that lacks clear justification for its structure and claimed symmetry."
      },
      {
        "Problem": "Ambiguity in definition and dimensionality of weight matrix W in GRM compatibility calculation",
        "Location": "Equation (7) and its description, Page 16; Figure 5, Page 15",
        "Explanation": "The compatibility score in Equation (7) is h_v->x_i = exp([v, x_i]W) / ..., where v is a class embedding (dim D_gcn) and x_i is a visual feature (dim D_img). The paper states 'W ∈ R^(D×D) is a trainable weight matrix obtained by a 1 × 1 convolution.' This description is confusing. If [v, x_i] is a concatenation (dim D_gcn + D_img), a 1x1 convolution (linear layer on channels) would typically have weights of size 1 x (D_gcn + D_img) to produce a scalar output before softmax. The 'W ∈ R^(D×D)' part seems to conflict with this, or the 'D' is not clearly defined in this context relative to D_gcn and D_img. This lack of precise definition for W and its interaction with concatenated features makes the compatibility calculation difficult to understand and reproduce."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 7595,
      "output": 753
    }
  },
  {
    "entry_id": 66,
    "retraction_id": "1206.0667v2",
    "paper_id": "1206.0667v1",
    "retraction_comment": "This paper is withdrawn by the author because the paper did not prove the second inequality of (4.3), which is unlikely to hold in general",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between the statement of Theorem 3.1 and its proof.",
        "Location": "Theorem 3.1 (page 6) and its proof (pages 7-9).",
        "Explanation": "Theorem 3.1 states an inequality for the integral of h_{H(1)} over phi_F^*(o_Delta), where h_{H(1)} is the generating function associated with a t-Hamiltonian H(1) and its flow phi_F. However, the provided proof on pages 7-9 derives an estimate for an integral involving h_G, associated with an s-Hamiltonian G and its flow phi_G. This discrepancy is critical because Corollary 3.2, which relies on Theorem 3.1, is a key component in the paper's main argument to show max f_{H(1)} >= 0. If Theorem 3.1 is intended for h_G, its statement is incorrect; if it is for h_{H(1)}, its proof is not provided for h_{H(1)}."
      },
      {
        "Problem": "The crucial equality f_{H(1)_i} = f_{G_i} for approximating sequences is asserted with reference to prior work, but its application in this specific approximation context needs clearer justification.",
        "Location": "Page 6, first paragraph; Page 12, 'Proof of Theorem 1.1'.",
        "Explanation": "The entire proof strategy hinges on equating the basic phase function f_{H(1)_i} (related to the original Hamiltonian loop being studied) with f_{G_i} (related to a C^0-small Hamiltonian flow derived from the homotopy) for each element of the approximating sequences. This equality is stated to be from [Oh3] (where 'f_{K^1} = f_{H(1)}' is proved for exact Hamiltonians). Its direct application to the sequences F_i = H_i(1) and G_i(s,x) = K_i(s,1,x) within the limit process for topological Hamiltonians needs to be robustly established or more thoroughly justified, as this equality is used to transfer all key properties from the G_i framework to the H(1)_i framework."
      },
      {
        "Problem": "The critical estimate |df_{G_i}| <= C d(phi_{G_i}, id) (implying ||df_{G_i}|| -> 0) is asserted without sufficient proof or a precise reference within the note.",
        "Location": "Page 10, paragraph preceding Lemma 4.1; Page 13, derivation of osc f_{H(1)} = 0.",
        "Explanation": "The conclusion that f_{H(1)} = 0 relies on showing osc f_{H(1)} = 0. This step uses osc f_{G_i} -> 0, which in turn depends on the assertion that ||df_{G_i}|| (the norm of the gradient of the basic phase function f_{G_i}) tends to zero as the C^0-distance d(phi_{G_i}, id) tends to zero. This inequality is introduced by 'Recalling the inequality |df_G(q)| <= C d(phi_G, id)' and is fundamental for Lemma 4.1 and the vanishing of the oscillation. However, its justification is not provided within this note, making a key part of the argument difficult to verify."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 13486,
      "output": 768
    }
  },
  {
    "entry_id": 67,
    "retraction_id": "1503.03000v3",
    "paper_id": "1503.03000v2",
    "retraction_comment": "This paper has been withdrawn by the author because the renormalization constructed in it is not compatible with renormalization in perturbative quantum field theory. Main Theorem of \\S5 is not true",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsupported Assumption on Divergence Structure",
        "Location": "Page 5, 'The main technical assumption...'",
        "Explanation": "The paper assumes that for any graph Γ, the divergent part of the regularized amplitude Uε(Γ) is a polynomial in ε⁻¹ and log ε without a constant term. This assumption is crucial for the subsequent renormalization procedure (the projection T and Birkhoff decomposition). However, this specific structure of divergences is not justified for 'arbitrary Hamiltonians' and an unspecified 'Hamiltonian regularization' as claimed. While common in specific renormalizable theories with particular regularizations, its general validity for the broad scope claimed by the paper is not established, potentially invalidating the renormalization mechanism for many Hamiltonians."
      },
      {
        "Problem": "Unproven and Non-Constructive Equivalence to Standard Perturbative QFT",
        "Location": "Page 10, Theorem and subsequent Comment",
        "Explanation": "The central theorem stating that the paper's 'mathematical S-matrix and Green functions... coincide with the renormalized perturbation series of perturbative quantum field theory' is presented without proof. The subsequent 'Comment' outlines three highly non-trivial and unexplained steps required to establish this connection: (1) changing the regularization scheme, (2) transforming the 'renormalization over all graphs' to one over 1PI graphs, and (3) performing additional renormalization for normal ordering. The lack of proof and the opacity of these crucial transformation steps make it impossible to verify the paper's claim of reproducing standard QFT results, which is a key part of its stated conclusions."
      },
      {
        "Problem": "Inability to Determine Physical Parameters",
        "Location": "Page 2, second paragraph, 'However, up to now we are unable to recover the effective physical parameters of the theory (like masses, coupling constants, etc.) from our construction.'",
        "Explanation": "The paper explicitly states its inability to recover fundamental physical parameters such as renormalized masses and coupling constants from its construction. A primary goal of renormalization is to relate the bare parameters of a theory to observable, physical quantities. The failure to achieve this severely limits the physical applicability and predictive power of the proposed framework, undermining its claim to be a comprehensive renormalization theory for physical field theories."
      },
      {
        "Problem": "Vague Definition and Unclear Impact of 'Hamiltonian Regularization'",
        "Location": "Page 5, 'let us first regularize the Hamiltonian...'; Page 1 (Abstract/Intro); Page 11, 'Some open questions'",
        "Explanation": "The entire renormalization procedure relies on an initial 'Hamiltonian regularization' Hε(t), but the paper does not specify the class of allowed regularizations beyond Hε(t) being 'regular' (smooth and rapidly decreasing). The properties of divergences, and thus the success of their removal, critically depend on the regularization scheme. Without a concrete definition or constraints on this regularization, the 'main technical assumption' about divergence structure (Problem 1) is difficult to assess. Furthermore, the paper itself (page 11) lists the dependence of the renormalized evolution operator on the regularization as an open question, suggesting that the uniqueness and universality of the final renormalized result are not established."
      },
      {
        "Problem": "Use of All-Graphs Hopf Algebra for Renormalization Lacks Physical Justification",
        "Location": "Page 1, Introduction ('Hopf algebra of all graphs'); Page 5, Section 2; Page 10, Comment",
        "Explanation": "The paper employs a Hopf algebra of *all* graphs for its renormalization procedure, departing from the standard Connes-Kreimer approach which typically focuses on 1PI graphs for physical counterterms. While mathematically definable, the physical justification for subtracting divergences based on all subgraphs (not just 1PI) is not provided. It's unclear if this method correctly isolates and removes all physical ultraviolet divergences without over-subtracting or misidentifying finite parts. The 'Comment' on page 10, which mentions a necessary (but unexplained) transformation to a 'renormalization over one-particle irreducible graphs' to connect to standard QFT, suggests that the all-graphs approach alone may not be physically complete or standard."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 4375,
      "output": 920
    }
  },
  {
    "entry_id": 68,
    "retraction_id": "2010.16005v2",
    "paper_id": "2010.16005v1",
    "retraction_comment": "There is a potential issue with trilinear estimates and the indices needs to be adjusted",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed justification of trilinear estimates for s > 0 due to incorrect frequency factor inequality.",
        "Location": "Page 10, top, inequality preceding the main integral estimate for (3.8). Specifically, the use of ⟨ξ⟩^s ≤ ⟨ξ-ξ₁⟩^s ⟨ξ₁-ξ₂⟩^s ⟨ξ₂⟩^s.",
        "Explanation": "The proof of Theorem 2 (trilinear estimates) for s > 0 relies on the inequality ⟨ξ⟩^s ≤ ⟨ξ-ξ₁⟩^s ⟨ξ₁-ξ₂⟩^s ⟨ξ₂⟩^s to distribute the Sobolev regularity factor ⟨ξ⟩^s among the terms in the convolution. This inequality is generally false for s > 0 (e.g., if ξ-ξ₁, ξ₁-ξ₂, ξ₂ are O(1) and ξ is large, then ⟨ξ⟩^s can be much larger than the product on the right). This step is crucial for establishing the trilinear estimates for H^s data with s > 0. Without a correct way to handle the ⟨ξ⟩^s factor, the proof of Theorem 2, and consequently Theorem 1, is invalid for s > 0."
      },
      {
        "Problem": "Incorrect derivation and justification of crucial asymptotic polynomial behavior in trilinear estimate.",
        "Location": "Page 12, equation (3.9) and the preceding sentence: 'Next, by Lemma 5 we have, ...'.",
        "Explanation": "Equation (3.9) presents a specific asymptotic factorization for a high-degree polynomial that arises in the estimation of the Riesz derivative term: (Polynomial P(ξ₂))^(1/2) ~ ⟨ξ₂⟩^(1.5) |ξ₂ - (4τ-γ(ξ))|^(1/2). The paper claims this factorization is derived 'by Lemma 5'. However, Lemma 5, as stated on page 8 and proven on page 9 (|q(x)| ≤ C(1+|p(x)|)), only provides a bound on polynomial magnitude relative to another and cannot yield such a specific asymptotic form involving roots and precise powers. The asymptotic form (3.9) is critical for the convergence of the subsequent integral estimate. Its incorrect justification (and potential incorrectness of the form itself) undermines the trilinear estimate for the Riesz term, which is highlighted as the most challenging part of the analysis."
      },
      {
        "Problem": "Misleading or incorrect derivation of Lipschitz continuity for the data-to-solution map.",
        "Location": "Page 4, equation (2.11) and the argument for the 'second term' leading to (2.12).",
        "Explanation": "In the proof of Lipschitz continuous dependence on initial data, equation (2.11) states: |||T_φ u - T_χ v|||_{s,b} = |||ψW(φ-χ) + T_φ u - T_χ v|||_{s,b}. This algebraic identity is incorrect as written. The intended argument likely involves u - v = ψW(φ-χ) + (N(u) - N(v)), where N denotes the nonlinear part of the operator. The subsequent justification for bounding the 'second term' (referred to as |||T_φ u - T_χ v|||_{s,b} in the text, but should correspond to |||N(u) - N(v)|||_{s,b}) by (9/16)|||u-v|||_{s,b} using arguments from (2.9) is obscured by this error. This flawed step in reasoning makes the proof of Lipschitz continuity difficult to follow and potentially unsound as presented."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 12943,
      "output": 835
    }
  },
  {
    "entry_id": 69,
    "retraction_id": "2305.08639v2",
    "paper_id": "2305.08639v1",
    "retraction_comment": "Proof of Theorem 5.4 is wrong. In particular, the map that is claimed to be a homomorphism, it is not a homomorphism. Also, some of the main results of the paper rely on that Theorem",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Discrepancy in the quotient group of Theorem E",
        "Location": "Theorem E (page 3), and its proof components (Lemmas 3.2, 3.3, page 9-10)",
        "Explanation": "Theorem E states that the quotient group in its short exact sequence is Z/p^(n choose 2). However, the derivation outlined in the proof, relying on Lemmas 3.2 and 3.3, suggests this quotient should be sp_{n-1}(Z/p) (for n odd) or Ann(u,Z/p) (for n even). These groups are generally not isomorphic to Z/p^(n choose 2). For example, if n=3 (odd), sp_2(Z/p) is SL_2(Z/p), which is not isomorphic to (Z/p)^3. This indicates an error in the statement of Theorem E or its proof."
      },
      {
        "Problem": "Issues with the definition of the bracket (a,b), the group N, and subsequent derivations",
        "Location": "Page 11 (definition of (a,b) and N; identity \"(u,v) = [v,u]uv^{-1}\"), Page 15 (proof of Proposition 4.8), Page 16 (Proposition 5.1)",
        "Explanation": "The paper defines a non-standard bracket (a,b) = abab^{-1}a^{-1}b^{-1}. The subsequent claim on page 11 that (u,v) = [v,u]uv^{-1} (where u,v are conjugates of generators of π) appears incorrect based on the given definition of (a,b). This identity is foundational for defining a homomorphism from N (the subgroup generated by such brackets) to π'I. Furthermore, the derivation of linear additive equations from the multiplicative Lemma 4.5 Relation 5 in the proof of Proposition 4.8 (page 15) lacks clear justification. The proof of Proposition 5.1 (that G_n^3 acts trivially on π/N) is also very brief and its validity depends critically on the properties of this specific N. These issues are fundamental to the construction of the main homomorphisms used in Theorems A and B."
      },
      {
        "Problem": "Ambiguity and potentially incorrect strong claims about the generation of B_n[3]",
        "Location": "Page 2 (claim B_n[3]=G_n^3 for n=3,4), Page 6 (claim \"If n <= 4, then B_n[3] is generated by σ_i^3\")",
        "Explanation": "G_n^m is defined as the normal subgroup generated by σ_1^m (and thus all σ_i^m). The statement on page 6, \"If n <= 4, then B_n[3] is generated by σ_i^3,\" is problematic. If \"generated by\" means as a subgroup (i.e., B_n[3] = <σ_1^3, ..., σ_{n-1}^3>), this is a very strong claim implying this subgroup is itself normal and coincides with B_n[3]. This would also imply G_n^3 = <σ_1^3, ..., σ_{n-1}^3>, which is unusual for a normal closure unless the subgroup <σ_i^3> is already normal. While B_n[3] being normally generated by σ_i^3 (making B_n[3]=G_n^3) for n<=4 might be true (citing [17]), the phrasing suggests a stronger, less likely form of generation. This claim is critical for relating results about G_n^3 to B_n[3], such as in Corollary 1.1 and the computations for Theorem B."
      },
      {
        "Problem": "Incomplete proof for the generating set of B_4[3] in Proposition 2.2",
        "Location": "Proposition 2.2 (page 6) and its proof (pages 6-8)",
        "Explanation": "Proposition 2.2 asserts that the group B_4[3] is generated by a specific set of 12 elements. The provided proof defines T as the subgroup generated by these 12 elements and then demonstrates that T has certain closure properties under conjugation by some elements. However, this does not suffice to prove that T is equal to B_4[3]. A complete proof would require showing that a known set of generators for B_4[3] (presumably from reference [17]) is contained within T, or that T contains all of B_4[3]. The crucial step establishing that these 12 elements indeed generate the entirety of B_4[3] appears to be assumed from [17] rather than fully demonstrated within the paper's proof. This proposition is key for Lemma 6.2, which calculates the rank for Theorem B in the n=4 case."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 13087,
      "output": 1112
    }
  },
  {
    "entry_id": 70,
    "retraction_id": "1706.06242v2",
    "paper_id": "1706.06242v1",
    "retraction_comment": "An error has occurred: The classical Kolmogorov result about characterization of compactness is usually applied with linear operators. Unfortunately, commutator of Hardy-Littlewood maximal operator is a sublinear one",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The argument to bound sup_Q ||G||_{L^p(Q)} by C||G||_{L^p(R^n)} (or C||M(G)||_{L^p(R^n)}) in the proof of Theorem 1.1 (a)=>(b) is flawed or insufficiently justified.",
        "Location": "Page 7, derivation of ||[Σb, M](f)||_{F_p^{\\alpha,\\infty}} bound, specifically the step from `C sup_Q (1/|Q|) integral_Q Ms(f1)(x)Ms(f2)(x) dx ||_{Lp}` to `C||M(Ms(f1)Ms(f2))||_{Lp}`.",
        "Explanation": "In the proof of Theorem 1.1 (a)=>(b), after estimating the local difference |U(x)-U_Q|, the argument leads to bounding sup_Q ||G||_{L^p(Q)}, where G = Ms(f1)Ms(f2) and ||G||_{L^p(Q)} = ((1/|Q|) integral_Q |G(x)|^p dx)^{1/p}. The paper then bounds this by C||M(G)||_{Lp(R^n)} or C||G||_{Lp(R^n)}. However, sup_Q ||G||_{L^p(Q)} is not generally controlled by ||G||_{Lp(R^n)} or ||M(G)||_{Lp(R^n)} in this direct manner. For G >= 0, ||G||_{L^p(Q)} <= M(G^p)(z)^{1/p} for any z in Q, which implies sup_Q ||G||_{L^p(Q)} <= ||M(G^p)^{1/p}||_{L^\\infty(R^n)}, not an Lp norm that would lead to the desired conclusion using boundedness of M or properties of Ms."
      },
      {
        "Problem": "The proof of Claim 1 does not consistently derive the term Ms(f1)Ms(f2) and fails to rigorously establish the crucial |x-x'|^alpha factor in Case 1.",
        "Location": "Pages 5-6, Proof of Claim 1.",
        "Explanation": "Claim 1 is essential for proving Theorem 1.1. Its proof has two issues: (1) The estimates for various terms (e.g., Case 1 on page 5, and I1 in Case 2 on page 6) yield bounds in terms of M(f1)M(f2) or a mix like M(f1)Ms(f2), not consistently Ms(f1)Ms(f2) as required by the claim's conclusion. (2) In Case 1 (r < |x-x'|), the factor |x-x'|^alpha is introduced by noting that |x-x'|^alpha / |B2|^{alpha/n} is of order 1, rather than being derived from the analysis of the integral difference. A rigorous derivation of this factor is necessary for the subsequent application in the F_p^{\\alpha,\\infty} estimate."
      },
      {
        "Problem": "The formulation of the F_p^{\\alpha,\\infty} norm used in the proof of Theorem 1.1 (a)=>(b) is incorrect.",
        "Location": "Page 7, first line after 'Therefore, it follows from lemma 2.1 that...'",
        "Explanation": "The paper states ||[Σb, M](f)||_{F_p^{\\alpha,\\infty}} = sup_Q (1/|Q|^{1+\\alpha/n}) || integral_Q |[Σb, M](f)(x) - ([Σb, M](f))_Q| dx ||_{Lp}. This expression does not match the characterization of F_p^{\\alpha,\\infty} given in Lemma 2.1(b), which is ||f||_{F_p^{\\alpha,\\infty}} approx sup_Q |Q|^{-\\alpha/n} ||f - f_Q||_{L^p(Q)}, where ||f - f_Q||_{L^p(Q)} = ((1/|Q|) integral_Q |f(x)-f_Q|^p dx)^{1/p}. The incorrect placement of the Lp norm and the integral over Q affects the validity of the subsequent derivation."
      },
      {
        "Problem": "The estimate for J2 in the proof of Claim 2 contains an unjustified factor of |B2|.",
        "Location": "Page 11, line 2 (estimate for J2).",
        "Explanation": "In the proof of Claim 2, the term J2 is estimated as `J2 <= C|B2|( (|B2|-|B1|)/|B2| )^{1/s'} Ms(f1)(x)M(f2)(x)`. Given that J2 (defined on page 10) involves an integral divided by |B2|^2 (an average-like structure), the appearance of a multiplicative factor |B2| in its bound is dimensionally inconsistent or at least highly suspect without explicit justification. This likely makes the resulting bound incorrect and too large."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 24551,
      "output": 1186
    }
  },
  {
    "entry_id": 71,
    "retraction_id": "1510.01988v2",
    "paper_id": "1510.01988v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to an error in Lemma 2; terms involving the normal derivative of $\\rho$ are missing",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation and formula for div_{Sigma, rho^2g} U^T in Lemma 2(1).",
        "Location": "Page 3, Proof of Lemma 2(1), lines 3-8 of the proof.",
        "Explanation": "The derivation of div_{Sigma, rho^2g} U^T involves calculating (1/rho^k) div_{Sigma,g} ((I(|x|)/|x|^k)x^T). The paper implicitly assumes div_{Sigma,g} x^T = (k/|x|^2)|x^T|^2 (from line 3 to line 4 of the calculation), which is not generally correct. The correct formula for div_{Sigma,g} x^T involves the mean curvature of Sigma with respect to the Euclidean metric g, which is generally non-zero as Sigma is minimal with respect to rho^2g. Furthermore, there is an algebraic error in the manipulation from line 5 to line 6 of the same proof: (1/rho^k)[(kI/|x|^(k+2))|x^T|^2] is effectively replaced by (1/rho^k)[(kI/|x|^(k+2))|x|^2] by adding a non-zero term (1/rho^k)(kI/|x|^(k+2))|x^perp|^2. These errors make the final formula for div_{Sigma, rho^2g} U^T unreliable."
      },
      {
        "Problem": "The crucial inequality div_{Sigma, rho^2g} U^T <= 1 (stated as the conclusion of Lemma 2(1)) does not follow from the paper's derived formula for div_{Sigma, rho^2g} U^T.",
        "Location": "Page 3, Lemma 2(1) statement, and Page 4, first paragraph.",
        "Explanation": "The paper's derived formula for div_{Sigma, rho^2g} U^T is 1 + (k I(|x|) / (rho^k(|x|)|x|^(k+2))) - (1/|x|^2) |x^perp|^2. The argument on page 4 uses the estimate (k I(|x|) / (rho^k(|x|)|x|^(k+2))) <= 1/|x|^2 (which is correct given C2). Substituting this into their formula yields div_{Sigma, rho^2g} U^T <= 1 + 1/|x|^2 - (1/|x|^2) |x^perp|^2. This expression is not necessarily <= 1. For instance, if x is tangent to Sigma (so x^perp = 0), the expression becomes 1 + (k I(|x|) / (rho^k(|x|)|x|^(k+2))), which is strictly greater than 1 since I(|x|) > 0. If div_{Sigma, rho^2g} U^T is not <= 1, then Lemma 4 fails, invalidating the main proof."
      },
      {
        "Problem": "The vector field W is not generally tangential to the boundary dB^n(r), contradicting Lemma 3, except for specific cases.",
        "Location": "Page 5, Lemma 3 and its proof.",
        "Explanation": "The proof of Lemma 3 shows that (W,x)_{rho^2g} = (1/2) rho^(k-2)(r) r^(k-2) - 1 / (2 rho^(k-2)(r) r^(k-2)) when |x|=r. This expression is zero if and only if (rho(r)r)^(2k-4) = 1. This condition holds if k=2 or if rho(r)r=1. However, Theorem 1 is stated for general k and for any r in (0,R) where rho(r)r is not necessarily 1. If (W,x)_{rho^2g} is not zero on dB^n(r), then W is not tangential to dB^n(r). This invalidates a crucial step in the application of the Divergence Theorem on page 6 (equation (1) and the sentence following it), where it's claimed that the boundary integral of W over dSigma intersect dB^n(r) vanishes due to W being tangential and the orthogonality condition."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 16708,
      "output": 985
    }
  },
  {
    "entry_id": 72,
    "retraction_id": "1212.5552v2",
    "paper_id": "1212.5552v1",
    "retraction_comment": "There are signal errors in eqs. (17) to (25)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Sign error in Boltzmann factors w_i",
        "Location": "Page 4, Eqs (41)-(43)",
        "Explanation": "The Boltzmann factors w(n_d,i, n_d,i+1) are defined as Tr_a,b,c (exp(-β H_i,i+1)). The energies E_k derived in Eqs (16-21) are standard eigenvalues. Therefore, the terms in the sum for w_i should be exp(-β E_k). However, Eqs (41-43) effectively use exp(β E_k) by taking the negative of the energies in the exponents (e.g., for E1 = -2t-μ, the term is exp(β(2t+μ))). This sign flip in all exponents makes the calculated w_i incorrect, and consequently, all thermodynamic quantities (f, μ̃, Ṽ, Z, entropy, specific heat, etc.) derived from them at finite temperature are quantitatively incorrect."
      },
      {
        "Problem": "Inconsistent Particle-Hole Transformation and its Consequences",
        "Location": "Page 2, discussion around Eq (3); Page 3, half-filling condition; Page 5, Eq (52)",
        "Explanation": "The paper states a canonical particle-hole transformation (a_α -> a_α^+, a_α^+ -> a_α, leading to n_α -> 1-n_α) on page 2. Applying this to the Hamiltonian H_i,i+1 (Eq 2) does not yield the form given in the 'transformed Hamiltonian' (Eq 3); for instance, the fermionic hopping term like -t a_a^+ a_b should transform to -t a_a a_b^+, but it remains unchanged in Eq (3). If Eq (3) is foundational to their understanding or application of particle-hole symmetry, then conclusions like the free energy relation in Eq (52) or the specific condition μ=3V/2 for half-filling (when V1=V) become suspect as their justification might rely on this flawed transformation or its interpretation."
      },
      {
        "Problem": "Incorrect formula for effective chemical potential μ̃",
        "Location": "Page 4, Eq (38), Eq (45), Eq (46)",
        "Explanation": "The effective Hamiltonian in Eq (38) includes a term -μ̃/2 (n_d,i + n_d,i+1). The Boltzmann factors for this effective model are given in Eq (46) as ῶ0=1, ῶ1=x, ῶ2=x^2y, where x = exp(βμ̃/2). The mapping from the original model (Eq 45) yields f=w0, and relates ῶ1 to w1 via ῶ1 = w1/f = w1/w0. Thus, x = w1/w0. Equating the expressions for x, exp(βμ̃/2) = w1/w0, which implies μ̃ = (2/β) ln(w1/w0). However, Eq (45) states μ̃ = (1/β) ln(w1/w0). This discrepancy by a factor of 2 in the definition of μ̃ will lead to incorrect parameters for the effective model and thus incorrect thermodynamic results, independently of other errors in w_i."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 14202,
      "output": 765
    }
  },
  {
    "entry_id": 73,
    "retraction_id": "1612.09148v2",
    "paper_id": "1612.09148v1",
    "retraction_comment": "The second equality in eq. 11 does not hold for the general case. Thus, the conclusion does not follow from the premises and the claim of the paper is not proven",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mischaracterization of the standard dynamical matrix D(q) (Eq. 1) regarding its Hermiticity.",
        "Location": "Page 1, paragraph 2, sentence: \"This form of dynamical matrix is not explicitly Hermitian, which is crucial for guaranteeing reality of its eigenvalues - squares of phonon frequencies (ω²).\"",
        "Explanation": "The standard dynamical matrix D(q) as defined in Eq. (1) is inherently Hermitian (i.e., D(q) = D†(q)). This Hermiticity is a standard result and directly guarantees that its eigenvalues (ω²) are real, regardless of whether the matrix elements themselves are complex. The paper's claim that it is 'not explicitly Hermitian' and that this is an issue for guaranteeing real eigenvalues is incorrect and undermines a key motivation for seeking an alternative form."
      },
      {
        "Problem": "The derived real form of the dynamical matrix (Eq. 13) is not generally equivalent to the standard complex form (Eq. 1); its validity is restricted.",
        "Location": "Page 2, derivation of Eq. (12) and (13) from Eq. (1).",
        "Explanation": "The derivation of the real symmetric dynamical matrix D_ia,i'a'(q) = Σ_n (Φ_ia,i'a'(n)/√m_i m_i') cos(q.R_n) (Eq. 13) from the standard form (Eq. 1) requires the condition Φ_ia,i'a'(R_n) = Φ_ia,i'a'(-R_n). This means the force constants must be an even function of the cell separation vector R_n. This condition is only met for crystals possessing inversion symmetry when the origin is chosen appropriately (e.g., at a center of inversion). The paper does not adequately state this strong restriction when presenting Eq. (13) as a general 'alternative form', thus misrepresenting its applicability."
      },
      {
        "Problem": "A flawed argument is presented for the reality of the dynamical matrix D(q) based on the alleged universal reality of its eigenvectors.",
        "Location": "Page 2, right column, paragraph starting \"The last conclusion is actually proven somewhat more elaborately...\", particularly the step \"But the set of eigenvectors of the dynamical matrix can be always made real [1, 2]. Thus, the U matrix is in fact real and orthogonal, which again means that the D matrix...is also real\".",
        "Explanation": "The argument states that if D is Hermitian and its eigenvectors can always be made real, then D itself must be real. The premise that eigenvectors of any Hermitian D(q) 'can be always made real' is false. For a general complex Hermitian matrix (which D(q) is for an arbitrary q-vector, especially in non-centrosymmetric crystals), the eigenvectors are generally complex and cannot be made real while remaining eigenvectors. Therefore, the conclusion that D(q) must be real based on this premise is unsound."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 11142,
      "output": 673
    }
  },
  {
    "entry_id": 74,
    "retraction_id": "1205.5450v3",
    "paper_id": "1205.5450v2",
    "retraction_comment": "The paper has been withdrawn due to an error in the maximal norm estimate that we haven't been able to overcome",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect phase function in the definition of Φ_{a,t,a}(f)(x) (2.69), essential for Lemma 1.2.",
        "Location": "Page 13, Definition (2.69); its use in Lemma 1.2 via (2.73)-(2.75) and estimates in Lemma 2.7 (e.g. (2.70)).",
        "Explanation": "Lemma 1.2, a key result for handling weighted norms, relies on estimates for Φ_{a,t,a}. This term should arise from the interaction of the fractional weight |x|^α with the linear DGBO propagator W_a(t), whose Fourier symbol involves S(ξ) = tξ|ξ|^{1+a_DGBO}. Thus, Φ should involve S(ξ+η) - S(ξ). However, (2.69) defines Φ_{a,t,a}(f)(x) using a phase t(|x+y|^{1+a(x+y)} - |x|^{1+ax}). If 'a' is the DGBO parameter and 'x' is the variable (ξ in application), the exponent 1+ax (or 1+a(x+y)) becomes variable-dependent. This is inconsistent with the DGBO symbol. While the estimates for Φ in Lemma 2.7 (e.g., (2.61)-(2.63), (2.70)) are based on a phase function consistent with t x|x|^{1+a_DGBO} (from its derivative (2.62)), the definition of Φ in (2.69) uses a different, problematic phase. This mismatch invalidates the bounds on Φ and consequently Lemma 1.2, which is crucial for the weighted norm estimates in Theorem 1.1."
      },
      {
        "Problem": "The globalization argument for Theorem 1.1 appears to have a gap for a certain range of the parameter 'a'.",
        "Location": "Page 18, assumption for (3.98) and the subsequent iterative argument on pages 17-19.",
        "Explanation": "The proof of global existence in Z_{s,ρ} (Theorem 1.1) extends a local solution iteratively. This relies on an a priori bound for the Z_{s,ρ} norm. The derivation of this bound, particularly for the weighted part |||x|^ρ u_3||_2 in (3.97)-(3.99), uses an estimate of the form T^{3/4} ||∂_x u||_{L_t^∞ L_x^4} < 1/2 (from (3.98)). It's assumed that ||∂_x u||_{L_t^∞ L_x^4} is controlled by M, where M depends on the initial H^s norm. For u ∈ H^s, ∂_x u is in H^{s-1}. The Sobolev embedding H^{s-1}(ℝ) into L^4(ℝ) requires s-1 > 1/4. Given the condition s > 3/2 - 3a/4 from Theorem 1.1, the embedding condition s-1 > 1/4 translates to 1/2 - 3a/4 > 1/4, which simplifies to a < 1/3. For a ∈ [1/3, 1), this embedding is not guaranteed by this simple argument. Thus, the crucial step of controlling ||∂_x u||_{L_t^∞ L_x^4} by M (and making the product with T^{3/4} small) is not justified for this range of 'a' without further argument, potentially limiting Theorem 1.1 to local well-posedness or requiring a more refined globalization proof for a ≥ 1/3."
      },
      {
        "Problem": "Incorrect Hölder conjugate exponents in the definition of the solution space norm (3.84).",
        "Location": "Page 15, definition of exponents p1, p2 below (3.84) and their stated Hölder relation.",
        "Explanation": "The norm |||v||| for the solution space, defined in (3.84), includes terms ||D_x^{s-(1-a)/2}v||_{L_t^{p1}L_x^{q1}} and ||∂_x v||_{L_t^{p2}L_x^{q2}}. The paper states the Hölder relation 1/p1 + 1/p2 = 1. However, using the provided definitions for p1 = (1+a)(2s+1+a)/(2s-1+a) and p2 = (1+a)(2s+1+a)/2, a direct calculation yields 1/p1 + 1/p2 = 1/(1+a). Since 'a' is in (0,1) for Theorem 1.1, 1/(1+a) ≠ 1. If these exponents were intended for product estimates (e.g., in applying a fractional Leibniz rule to D^s(u ∂_x u) for the H^s part of the norm in (3.86)), this discrepancy is a critical error. It undermines the estimates for the H^s component of the nonlinear term in the contraction argument."
      },
      {
        "Problem": "Key parameters in the Gagliardo-Nirenberg type inequality (2.45) are undefined or their application is unclear.",
        "Location": "Page 9, Remark 2.5, inequality (2.45), and its application in the proof of (3.89) on page 16.",
        "Explanation": "Inequality (2.45), ||J_x^v(<x>^{w+}f)||_{L^2} ≤ ||<x>^ρ f||_{L^2}^{1-η} ||J_x^{3/2-3a/4} f||_{L^2}^η, is cited as a tool from [45] and used in (3.89) to estimate the ||u||_{L_t^{4/(1+a)} L_x^∞} norm. However, the parameter 'η' (nu) is not defined in Remark 2.5. Additionally, the parameter 'w+' is not explicitly defined (Lemma 2.4 defines 'w'). The application of (2.45) in (3.89) aims to bridge estimates from Lemma 2.4 (involving 'w' and 'β') to bounds involving 'ρ' (which is p_a) and 's'. Without clear definitions of 'η' and 'w+', and a transparent derivation showing how these parameters align to achieve the stated bounds in (3.89), the validity of this step in the contraction argument is questionable. This affects the control of one of the key Strichartz-like norms in the solution space."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 17408,
      "output": 1554
    }
  },
  {
    "entry_id": 75,
    "retraction_id": "1806.09512v2",
    "paper_id": "1806.09512v1",
    "retraction_comment": "The calculations are not strictly correct because the Fermi momenta for protons and neutrons were not scaled correctly",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of a Constant M* per Nucleus is Contradicted by Evidence in the Paper",
        "Location": "Page 21 (Fig. 18 and surrounding text, Section L 'M* uncertainty'); Page 23 (Section M, discussion of 48Ti and 12C JLab data)",
        "Explanation": "The model assumes a single, constant relativistic effective mass M* for each nucleus. However, Fig. 18 shows that M* extracted from experimental peak positions often varies with energy transfer (ω) and deviates from the model's constant M* band. Furthermore, the discussion on page 23 regarding new JLab data for 12C and 48Ti explicitly states that different M* values (0.9 for 12C, 0.85 for 48Ti) are favored for those specific kinematics, compared to originally fitted values (e.g. M*=0.8 for 12C). The paper itself admits (p.23) that 'the RMF model with a constant effective mass starts to fail for high momentum transfer, favoring an energy dependence of the effective mass', undermining this core assumption."
      },
      {
        "Problem": "Model Performance Degradation and Assumption Breakdown for Heavy Nuclei",
        "Location": "Page 3 (Table II, χ²/N_QE values for 208Pb, 238U); Page 19 (Section J, discussion of 208Pb); Page 20 (Section K, discussion of 238U)",
        "Explanation": "The SuSAM* model's ability to describe experimental data significantly worsens for heavy nuclei like 208Pb and 238U. Table II shows high χ²/N_QE values (1.223 for 208Pb, 1.74 for 238U from the global fit). The text (p.20) notes the 238U description is 'the worst' and suggests that for heavy nuclei, 'strong effects breaking the impulse approximation and the superscaling hypothesis should play an important role'. This challenges the 'global' applicability of the model and indicates a potential breakdown of its fundamental assumptions (e.g., factorization, universal scaling function) in this mass regime."
      },
      {
        "Problem": "Arbitrary Constant Width Assumption in Global Fit Procedure",
        "Location": "Page 7 (Section III.C, 'The global fit'); Page 8 (first paragraph of Section III.C continued)",
        "Explanation": "The global fit, which simultaneously determines the kF and M* parameters for all nuclei and the parameters of the central scaling function (leading to Band C), assumes a fixed, constant width of +/- 0.1 for the 'scaling' band during the optimization. This is an arbitrary choice. The actual phenomenological scaling band derived post-fit (Band C in Table I) is not constrained to have a constant width. Using a fixed, potentially unrepresentative width during the primary parameter determination step could bias the resulting kF, M*, and scaling function parameters, affecting the model's foundation."
      },
      {
        "Problem": "Ambiguous Physical Interpretation of the Effective Mass M*",
        "Location": "Page 21 (Fig. 18 and discussion); Page 23 (Ti/C JLab data discussion); Page 24 (Conclusions, regarding M* and transverse enhancement)",
        "Explanation": "While M* is introduced based on Relativistic Mean Field (RMF) theory, its role in the SuSAM* model becomes that of a phenomenological fit parameter that appears to absorb various unmodeled and potentially kinematics-dependent nuclear effects (e.g., complex Final State Interactions, Meson Exchange Current contributions beyond simple enhancement). The evidence within the paper suggesting M* might need to be kinematics-dependent (Fig. 18, p.23) indicates it's not solely the RMF effective mass. This makes its direct physical interpretation as a pure RMF-derived nuclear property within this model ambiguous and potentially oversimplified."
      },
      {
        "Problem": "Oversimplified Averaging of Non-Quasielastic Effects into M* and the Scaling Function",
        "Location": "Page 5 (end of Section A, regarding ψ* < -1); Page 24 (Conclusions, 'Whatever nuclear effect...is included only on the average')",
        "Explanation": "The model accounts for complex nuclear effects beyond the impulse approximation (like MEC, FSI, 2p2h contributions) by implicitly 'averaging' them into the phenomenologically determined scaling function f*(ψ*) and the effective mass M*. This averaging process may be too simplistic if these effects have strong, non-universal kinematic dependencies within the quasielastic peak region. The paper acknowledges that such effects are included 'only on the average'. If this average is not representative across different kinematics, it could lead to systematic deficiencies, such as the apparent kinematic dependence of M*, and limit the model's accuracy in disentangling true quasielastic processes from other reaction mechanisms."
      }
    ],
    "token_usage": {
      "input": 6832,
      "thinking": 6929,
      "output": 1110
    }
  },
  {
    "entry_id": 76,
    "retraction_id": "2102.11234v2",
    "paper_id": "2102.11234v1",
    "retraction_comment": "In step (3) of the proof of Theorem 1.3. it is claimed that $\\delta^2_{N,N} = 2\\delta$. This is not the only case that can occur and therefore there is a gap in the proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed definition of h_i(N) and consequently Lemma 2.1.",
        "Location": "Page 4, Definition of h_i(N) before Lemma 2.1, and Lemma 2.1 itself.",
        "Explanation": "The definition of h_i(N) as 'nn_1(ia)/alpha be the closest neighbor in the counting metric' is problematic. Dividing a point nn_1(ia) by a vector alpha is not standard. The term 'counting metric' is confusing in this context, as it typically makes all distinct points equidistant. Lemma 2.1 (h_{1+k}(n+k) = h_1(n)) relies on this definition, and its brief proof ('pulled back by R_alpha^{-k}') is insufficient, especially for finite N, and does not clearly connect to the geometric distances relevant to the paper's main claims. This lemma is later invoked in the proof of Theorem 1.3 and in Section 3."
      },
      {
        "Problem": "Internal contradiction in the statement of Lemma 2.2 and unjustified assertion in its proof.",
        "Location": "Page 5-6, Lemma 2.2 and its proof.",
        "Explanation": "Lemma 2.2 states 'd(v_i, nn_2(v_i)) > d(v_i, nn_1(v_i)), i.e. there are at most two points having the minimum distance from v_i'. These two clauses are contradictory: if there are two points at the minimum distance, and nn_1 and nn_2 select them (after tie-breaking for nn_1), then d(v_i, nn_2(v_i)) would equal d(v_i, nn_1(v_i)). Furthermore, the proof for the L_q metric (q < infinity) claims that for d_q(v,w)^q = d_q(v, nn_1(v))^q, 'all the terms in the sum have to be equal because the a_i are algebraic independent.' This strong assertion is not justified."
      },
      {
        "Problem": "Proof of Theorem 1.3 (g_N^2 <= g_N + 1) contains questionable claims and logical gaps, particularly in Steps 1 and 2.",
        "Location": "Page 6-7, Proof of Theorem 1.3, Steps (1) and (2).",
        "Explanation": "In Step (1), the equality 'delta_{N,N}^{(2)} = ... = delta_{N-1,N-1}^{(1)}' under the condition nn_1(Na) = a (meaning (N-1)a) is asserted without clear justification. Step (2) is convoluted, appearing to confuse instance-specific values (g_N, g_N^2) with their maximal possible values (g(d,q), g^2(d,q)). It makes strong, unproven claims such as the existence of an N_2 for which '|A_{N2}| = |{delta_{N2,N2}^{(1)}}| = 1' based on prior deductions that are themselves unclear. The notation A_N for the set of 1st NN distances and B_N for the set of 1st/2nd NN distances is used, where g_N = |A_N| and g_N^2 = |B_N|."
      },
      {
        "Problem": "Step (3) of the proof of Theorem 1.3 relies on overly specific and unproven geometric configurations.",
        "Location": "Page 7, Proof of Theorem 1.3, Step (3).",
        "Explanation": "Step (3) analyzes the case where delta_{N,N}^{(1)} is in A_{N-1} and delta_{N,N}^{(2)} is not in B_{N-1}. It asserts this implies 'nn_2(Na) = a and vice versa nn_2(a) = Na', and then 'delta_{N,N}^{(2)} = 2 delta for some delta in A_{N-1}'. Later, it introduces highly specific relations like 'nn_1(a) = (N+1)/2 * a' which depend on N being odd and a particular point arrangement. These assumptions are not shown to hold generally, undermining the proof's validity for all cases."
      },
      {
        "Problem": "The justification for Theorem 1.2 (g_N >= 9) based on the numerical example and Corollary 2.3 is unsound.",
        "Location": "Page 3 (Theorem 1.2 statement), Page 8 (Justification using numerical example, Theorem 1.1, Corollary 2.3).",
        "Explanation": "The paper presents a numerical example where g_N^2 = 9 for N=39. It then claims this, along with Theorem 1.1 and Corollary 2.3, establishes Theorem 1.2 (that for d>=3, there exists alpha with g_N >= 9 for infinitely many N). However, Corollary 2.3 states that if g_N^2 reaches its maximum possible value g^2(d,q), then g_N=1. If the example's g_N^2=9 is assumed to be this maximum (i.e., g^2(3,2)=9), Corollary 2.3 would imply g_N=1 for this instance, contradicting the goal of showing g_N is large. If g_N^2=9 is just an instance, then Theorem 1.3 (g_N^2 <= g_N + 1), if it were sound, would imply g_N >= 8 for this instance. This is significant (disproving the <=7 conjecture) but does not directly prove Theorem 1.2's claim of g_N >= 9. The logical chain from g_N^2=9 to g_N >= 9 via the cited results is flawed or missing."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 10801,
      "output": 1343
    }
  },
  {
    "entry_id": 77,
    "retraction_id": "1303.3756v2",
    "paper_id": "1303.3756v1",
    "retraction_comment": "This paper has been withdrawn by the author because Jarzynski's equality takes also processes into consideration which do not satisfy the 2nd law. Consequently, a modified non-equilibrium thermodynamics has to be developped taking into account the \"anti-irreversible admixtures\"",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed logical deduction restricting Jarzynski's equality to reversible processes.",
        "Location": "Section 3.2 (interpretation of Eq. 30 and transition to Eq. 31) and Section 5 (Discussion).",
        "Explanation": "The author derives an inequality (Eq. 30: exp(-βΔF) ≥ ⟨exp(-βWk)⟩), which is consistent with the second law (Wk ≥ ΔF). Jarzynski's equality is ⟨exp(-βWk)⟩ = exp(-βΔF). The author then incorrectly argues that because their derivation leads to an inequality, Jarzynski's *equality* must only be valid in the reversible limit. This is a non-sequitur. If Jarzynski's equality is generally true for non-equilibrium processes (as established in the literature), it means the author's derived inequality (Eq. 30) actually holds as an equality. This flawed reasoning does not invalidate Jarzynski's equality for irreversible processes or restrict its established validity."
      },
      {
        "Problem": "Misrepresentation of the conditions and framework of Jarzynski's equality, particularly regarding temperature and equilibrium.",
        "Location": "Page 5 (items i, ii, footnote 4, and statement 'T = T* = 1/kβ. That is really a restricting presupposition...').",
        "Explanation": "The paper incorrectly claims Jarzynski's use of a thermostatic temperature T (for the reservoir and initial system state) is a 'restricting presupposition' because a non-equilibrium system doesn't have such a temperature, and that T_system = T_reservoir implies no heat exchange (footnote 6). This misinterprets Jarzynski's setup: T is the constant temperature of the heat bath and defines the initial canonical ensemble. The system itself undergoes a non-equilibrium process and is not assumed to be at temperature T throughout; heat exchange is integral. Footnote 4 also incorrectly suggests Jarzynski 'presupposes that the system is in equilibrium' throughout the non-equilibrium process, contrary to the explicitly non-equilibrium nature of the driven processes considered by Jarzynski."
      },
      {
        "Problem": "The paper's central conclusion that Jarzynski's equality is only valid in the reversible limit fundamentally contradicts the established scope and significance of the equality.",
        "Location": "Abstract; Page 7 (conclusion of Section 3.2: 'Consequently, the validity of Jarzynski's equality from a thermodynamical point of view is clear: It is only valid in the reversible limit.'); Section 5.",
        "Explanation": "Jarzynski's equality is a key result in statistical mechanics precisely because it relates free energy differences (an equilibrium property) to averages of work performed during *non-equilibrium* (irreversible) processes. The paper's primary conclusion—that the equality holds only for reversible processes—negates the very essence and utility of Jarzynski's finding. This conclusion stems from the flawed reasoning and misinterpretations identified in other problems, rather than from a sound critique of Jarzynski's original statistical mechanical derivation."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 7115,
      "output": 696
    }
  },
  {
    "entry_id": 78,
    "retraction_id": "2002.03104v2",
    "paper_id": "2002.03104v1",
    "retraction_comment": "As pointed out by [REDACTED-NAME] via MO: \"This only shows that there is no trivial, i.e. purely analytic, argument proving that this expression is unbounded. But there might be only finitely many odd perfect numbers, or there might be some relation between n and q, which implies that the ratio is bounded.\"",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Reliance on unproven 'expectation' for contradiction",
        "Location": "Preliminaries (1) (page 2), Theorem 4.4 (page 4), Theorem 4.5 (page 5), Theorem 4.6 (page 6)",
        "Explanation": "The paper asserts in Preliminaries (1) that the sum S = σ(q²)/n + σ(n)/q² is 'not expected to be bounded from above'. This assertion is not proven. Theorems 4.4, 4.5, and the main result Theorem 4.6 rely on deriving an upper bound for S under certain assumptions, then claiming a contradiction with this 'expectation'. A mathematical proof cannot be based on contradicting an unproven expectation or intuition."
      },
      {
        "Problem": "Analysis based on σ(q²) which implies an exponent k=2 for the special prime q, inconsistent with OPN properties",
        "Location": "Throughout the paper, e.g., Preliminaries (3) (page 2), definition of I(q²)",
        "Explanation": "The paper analyzes relationships involving σ(q²) and I(q²) = σ(q²)/q². This implicitly assumes the exponent of the special prime q is 2. However, for an odd perfect number q^k n², Euler proved that k must satisfy k ≡ 1 (mod 4). Thus, k ≠ 2. This means the properties of I(q²) (e.g., its upper bound 31/25) and any arguments based on it (like the 'expectation' in Preliminaries (1)) are not directly applicable to the special prime component σ(q^k)/q^k of an OPN, fundamentally undermining the relevance of the analysis to OPNs."
      },
      {
        "Problem": "Flawed biconditional in Corollary 4.4.1",
        "Location": "Corollary 4.4.1 (page 4)",
        "Explanation": "Corollary 4.4.1 claims the biconditional σ(q²) < σ(n) ⇔ σ(q²)/n < σ(n)/q² holds, with the proof stated as 'Trivial'. This biconditional is not generally true. For example, let σ(q²)=10, σ(n)=20, n=1, q²=100. Then σ(q²) < σ(n) (10 < 20) is true. However, σ(q²)/n = 10/1 = 10 and σ(n)/q² = 20/100 = 0.2. Here, σ(q²)/n > σ(n)/q², so the biconditional fails. This corollary is used to justify the case analysis structure."
      },
      {
        "Problem": "Use of an unproven conjecture (q < n) in the main theorem's proof",
        "Location": "Proof of Theorem 4.6, case n < q² (page 6)",
        "Explanation": "In the proof of Theorem 4.6, specifically for the case n < q², the argument relies on the inequality q < n. This inequality is a known conjecture for odd perfect numbers (q^k n_0^2, where q is the special prime and n_0 is the other component), proven under some conditions (e.g. k=1) but not in general for all OPNs. The paper cites preprints for this, and one is noted as unpublished. Using this conjecture as a proven fact invalidates this part of the proof."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 17459,
      "output": 805
    }
  },
  {
    "entry_id": 79,
    "retraction_id": "1401.5295v2",
    "paper_id": "1401.5295v1",
    "retraction_comment": "This paper has been withdrawn due to non-inclusion of some terms in equation 16",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Mean-Field Hopping Definition and Dimensionality Issue",
        "Location": "Page 4, Eqs. (16), (19), (20)",
        "Explanation": "The effective hopping parameter derived from the mean-field Hamiltonian H_MF (Eq. 16) would be t'_eff,ij = (t + E_ij - iJ_ij)e^(iA_ij) (as the coefficient of the c†_i c_j term, assuming A_ij is absorbed into the definition of c_j or link). However, the paper defines effective hopping parameters t'_ij via Eqs. (19) and (20). Specifically, Eq. (19), X_ij = te^(iA_ij)(E_ij - iJ_ij), is dimensionally inconsistent: if E_ij and J_ij (defined in Eqs. 17, 18 from V times an expectation value) have units of energy, and t is an energy, then X_ij would have units of (energy)^2 / (energy_scale_of_t) * energy = energy^2. This cannot be subtracted from the hopping term t e^(iA_ij) (units of energy) as done in Eq. (20), t'_ij = t e^(iA_ij) - X_ij. If Eq. (19) is a typo and, for instance, X_ij = (E_ij - iJ_ij) was intended (units of energy), then Eq. (20) would yield t'_ij = (t - E_ij + iJ_ij)e^(iA_ij). This resulting effective hopping still differs in the signs of E_ij and J_ij compared to what is directly implied by the terms in H_MF (Eq. 16). Such sign errors or dimensional inconsistencies in defining effective interactions within MFT can critically alter the phase diagram and stability of predicted phases."
      },
      {
        "Problem": "Ambiguity in 'Translational Symmetry Breaking' and its Impact on Chern Number Calculation",
        "Location": "Page 6, Section IV B, Fig. 5",
        "Explanation": "The paper claims that translational symmetry is broken in phases PH2 and PH3, leading to the assertion that the 'periodic nature of PB curvature is now absent' (Page 6). However, it proceeds to assign quantized Chern numbers (via Hall conductivity σH = νe^2/h) to these phases, which are calculated by integrating the PB curvature over the Brillouin zone (Eq. 14). If the magnetic translation symmetry (period q) is genuinely broken such that the mean-field solution is no longer periodic (e.g., a glassy state), then k-space is not well-defined, and the Chern number calculation via Eq. 14 becomes invalid. If, more likely, the mean fields E_ij, J_ij adopt a pattern with a larger supercell periodicity (Nq), the Brillouin zone would fold, but the PB curvature B(k) should still be periodic over this new, smaller BZ, allowing a valid Chern number calculation. The current patterns described for q=5 (J1=J5, J2=J4, J3=0) appear to respect the q-periodicity of the magnetic unit cell, which would mean the PB curvature should remain periodic in the original magnetic BZ, contradicting the claim that its periodicity is 'absent'. The paper lacks clarity on the precise nature of the symmetry breaking and its compatibility with the Chern number calculations presented for PH2 and PH3."
      },
      {
        "Problem": "Insufficient Direct Evidence for 'No Gap Closing' at All Claimed Topological Phase Transitions",
        "Location": "Page 5 (Sec IV A), Page 7 (Sec IV D)",
        "Explanation": "A central claim of the paper is the occurrence of first-order topological phase transitions (TPTs) without the closure of the energy gap. While the effective potential analysis for q=3 (Fig. 7) is consistent with a first-order transition between two competing states (PH1 and PH3), and the text states that 'the lowest band is well separated from the next higher band throughout the range of V' (implying the individual phases are gapped), explicit data demonstrating the persistence of the gap for *both* competing phases across the transition point (e.g., plots of gap size vs. V for each phase near Vc) is not consistently provided for all claimed TPTs. This includes the PH2-PH3 transition for q=5-8 and the transitions discussed in Sec. IV D (for flux 6π/7). The assertion 'At transition points, we notice that there is no gap closing' (Page 5) requires more direct supporting evidence within the paper to fully substantiate this critical aspect of the findings for all transitions discussed."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 12993,
      "output": 1065
    }
  },
  {
    "entry_id": 80,
    "retraction_id": "1402.6435v2",
    "paper_id": "1402.6435v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in page 20",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Circular reasoning in the proof of Theorem 5.6 (a)=>(b).",
        "Location": "Page 21, Proof of Theorem 5.6, implication (a)=>(b). Also relevant: Corollary 3.6 (Page 11) and Lemma 3.5 (Page 11).",
        "Explanation": "The proof of Theorem 5.6 (a)=>(b) (if an adelic R-divisor D is nef, then its concave transform G_D >= 0) states it 'follows from Corollary 3.6 (1)'. Corollary 3.6(1) asserts that if D is nef and big, then vol^0(D) = vol(D). According to Lemma 3.5, this equality is equivalent to G_D >= 0 (for D big). Consequently, Corollary 3.6 effectively presupposes the conclusion of Theorem 5.6 (a)=>(b) for the specific case where D is big. Employing this to establish the general implication in Theorem 5.6 (a)=>(b) constitutes circular reasoning, as an independent demonstration that 'D nef => G_D >= 0' is necessary."
      },
      {
        "Problem": "Potentially flawed justification in the proof of Corollary 5.5.",
        "Location": "Page 20, Proof of Corollary 5.5.",
        "Explanation": "The proof of Corollary 5.5 (if tilde_sigma_x(D) = 0, then h_D(x) >= 0) contains two steps that may be problematic: 1. The inference from tilde_sigma_x(D) = 0 to the existence of an effective divisor D_eff = D + tilde{A} + (phi) (where tilde{A} is a specific auxiliary ample divisor from Proposition 5.1) with mult_x(D_eff) < epsilon is not clearly justified. The definition of tilde_sigma_x(D) involves D + delta A_0 + (phi), where A_0 is a general nef and big divisor, not necessarily tilde{A}. 2. The proof assumes h_{tilde{A}}(x) >= 0. However, tilde{A} is an auxiliary ample adelic divisor, and its height h_{tilde{A}}(x) at a specific rational point x is not guaranteed to be non-negative. If h_{tilde{A}}(x) is negative, the inequality h_D(x) + 2 epsilon h_{tilde{A}}(x) >= 0 might not imply h_D(x) >= 0 as epsilon tends to zero."
      },
      {
        "Problem": "Insufficient justification for Theorem 5.6 (b)=>(c).",
        "Location": "Page 21, Proof of Theorem 5.6, implication (b)=>(c). Also relevant: Theorem 4.8 (Page 18).",
        "Explanation": "The proof of Theorem 5.6 (b)=>(c) (if G_D >= 0, then D is pseudo-effective and NBs_tilde(D) = 0) states it 'follows from Theorem 4.8'. If G_D >= 0, then by Lemma 3.5, vol^0(D) = vol(D). Theorem 4.8(1) implies D is pseudo-effective and tilde_sigma_xi(D) = hat_sigma_xi(D) (if D is big). However, Theorem 4.8 does not directly establish that these sigma-invariants must be zero solely under the condition G_D >= 0. Theorem 4.8(2) concludes NBs_tilde(D) = 0 but necessitates D being nef, which is part of conclusion (a) of Theorem 5.6 and cannot be assumed in the (b)=>(c) step. Thus, the deduction that NBs_tilde(D) = 0 is not adequately justified by the provided reference to Theorem 4.8."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 14248,
      "output": 901
    }
  },
  {
    "entry_id": 81,
    "retraction_id": "2210.17003v2",
    "paper_id": "2210.17003v1",
    "retraction_comment": "The main theorems of the paper (Theorem 13 and 17) are wrong. The statements are only valid in R^2",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The argument for convergence in the cardinality 3 case of Theorem 13 is unsound.",
        "Location": "Page 4, Proof of Theorem 13, paragraph starting 'If the cardinality of {x,y,z} is 3...'",
        "Explanation": "The proof states that if x, y=RA(x), and z=RB(RA(x)) are distinct, then CT(x) = 0. This relies on the argument that since ||x|| = ||y|| = ||z||, these points lie on a sphere centered at the origin, and therefore their circumcenter is the origin. This is not generally true. The circumcenter of three points on a sphere is the origin if and only if the origin lies in the affine hull of these three points. For example, if A and B are the x-axis and y-axis in R^3 (which are closed convex cones/subspaces), and x=(1,1,1), then RA(x)=(1,-1,-1) and RB(RA(x))=(-1,-1,1). These three points are distinct and equidistant from the origin, but they are linearly independent, so their affine hull (a plane) does not contain the origin. Their circumcenter is (1/3, -1/3, 1/3), not 0. This error invalidates the claim that CRM converges in at most 3 steps for cones, as this specific step is used to guarantee convergence when new iterates result in three distinct points or when prior cases reduce to this scenario (e.g., page 4, case (i)(b))."
      },
      {
        "Problem": "Theorem 13 is misapplied in the proof of Theorem 17 for polyhedral sets.",
        "Location": "Page 6, Proof of Theorem 17",
        "Explanation": "The proof of Theorem 17 aims to show finite convergence for polyhedral sets A and B. It considers an iterate xn close to a point x* in A intersect B. It then defines sets K_A = ((A intersect B_r(x*)) - x*) and K_B = ((B intersect B_r(x*)) - x*) and claims these are 'closed, convex, and locally conic at 0'. Theorem 13 is then invoked on K_A and K_B to conclude convergence in at most N+3 steps. However, Theorem 13 is specifically for *closed convex cones*. The sets K_A and K_B, being derived from intersections with a ball B_r(x*) and then translated, are bounded sets (contained within B_r(0)). Bounded sets (unless they are just {0}) cannot be cones in the sense required by Theorem 13 (i.e., satisfying the property that if k is in the set, then lambda*k is in the set for all lambda > 0). Therefore, applying Theorem 13 to these bounded sets K_A and K_B is invalid, making the proof of finite convergence for polyhedral sets unsound."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 16863,
      "output": 672
    }
  },
  {
    "entry_id": 82,
    "retraction_id": "1503.00700v2",
    "paper_id": "1503.00700v1",
    "retraction_comment": "This preprint was withdrawn because the theoretical discussion of the inferred temperature of qubit couplers assumes an equilibrium distribution, which is not the case during the annealing cycles",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Oversimplified model for J_ij calibration",
        "Location": "Page 6, Eq. (9) and surrounding discussion; Page 7, discussion of T_eff for J-couplers",
        "Explanation": "The model for calibrating J_ij coefficients (Eq. 9) treats each qubit pair (s_i s_j) as an isolated two-level system. The paper itself acknowledges (page 6) that this is not physically valid because each qubit is connected to multiple J couplers, making the true partition function more complex. Using this oversimplified model casts doubt on the accuracy of the derived J_offset values for representing the true biases in the coupled system and on the physical meaning of the derived effective temperature, which the paper admits (page 7) 'no longer corresponds to a physically realistic temperature'."
      },
      {
        "Problem": "Sequential and potentially non-optimal calibration of coupled h_i and J_ij parameters",
        "Location": "Sections III, IV, V (especially page 7, paragraph 1 under section V, and Table III)",
        "Explanation": "The h_i and J_ij biases are determined largely independently (h_i calibration assumes J_ij=0, and J_ij calibration assumes h_i=0). However, these parameters are coupled in the Ising Hamiltonian. The paper acknowledges (page 7) that 'it is likely that interactions between the two corrections might lead to complications.' While Table III, case (f), attempts a sequential correction, this approach may not find the true optimal corrections for both sets of parameters simultaneously. The paper notes (page 8) that for combined corrections, 'the improvement to s_i and ss_i is not as crisp as the individual corrections before,' suggesting sub-optimality."
      },
      {
        "Problem": "Unsupported interpretation of the effective temperature from J_ij calibration",
        "Location": "Page 7, paragraph 2 after Eq. (10)",
        "Explanation": "The paper states that the effective temperature derived from the J_ij calibration (using the oversimplified Eq. 9), while not physically realistic, 'in some sense it is a measure of the improvement of the quantum annealing computation over an equilibrium classical device for this specific null problem.' This is a strong interpretative leap based on a fitting parameter from a model acknowledged to be an approximation. Such an interpretation lacks rigorous justification and may misrepresent the system's behavior or the nature of the observed improvement."
      },
      {
        "Problem": "Unexplained perturbation of qubits by neighbors with h_i=0",
        "Location": "Page 3, paragraph 3 (describing Fig. 2 observations)",
        "Explanation": "The paper reports an 'unexpected observation that qubits surrounded by neighbors that are set exactly to 0.0 are perturbed away from their ideal calibration' during h_i calibration. This suggests that the model of independent qubit biases (Eq. 5, treating each qubit as an isolated two-level system when J_ij=0) is incomplete. If neighboring qubits with h_j=0 affect qubit i, there are unmodelled interactions (e.g., residual couplings, crosstalk) not captured by the simple h_i s_i term, potentially limiting the accuracy and effectiveness of the h_i offset determination."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 3613,
      "output": 726
    }
  },
  {
    "entry_id": 83,
    "retraction_id": "1202.1896v2",
    "paper_id": "1202.1896v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical mistake in the circle graph algorithm",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Algorithm for permutation graphs potentially solves a restricted problem due to \"optimal\" coloring definition.",
        "Location": "Page 2, definition of \"optimal black-and-white coloring\" and Lemma 1; Page 3, Proof of Theorem 1.",
        "Explanation": "The algorithm for permutation graphs relies on Lemma 1, which assumes an \"optimal\" coloring where every uncolored vertex has both a black and a white neighbor. The original problem (Definition 1) seeks any valid coloring. It is not shown that if any valid coloring exists, an \"optimal\" one (in this specific sense, with the same b and w values) must also exist. If non-\"optimal\" solutions exist that cannot be transformed into \"optimal\" ones, the algorithm might incorrectly report no solution."
      },
      {
        "Problem": "Unclear or potentially very high polynomial complexity for the permutation graph algorithm.",
        "Location": "Page 3, Proof of Theorem 1, complexity analysis paragraph.",
        "Explanation": "The complexity analysis for Theorem 1 is problematic. The text states O(n^4) pieces and O(n^6) time to compute the table for one piece. This implies a total time of O(n^10). This calculation seems to stem from assuming O(n^2) scanlines and O(n^2) choices for an intermediate scanline. If a more standard O(n) elemental scanlines are used, pieces become O(n^2) and intermediate scanline choices O(n). Even with this, the cost per piece appears to be O(n^5) (O(n) choices for intermediate scanline * O(n^4) to combine tables by iterating b1,w1,b2,w2), leading to O(n^7) total. The remark about easily improving the timebound does not clarify these figures or provide a convincing path to a lower, well-justified polynomial complexity."
      },
      {
        "Problem": "Crucial reduction step for circle graphs asserted without justification.",
        "Location": "Page 4, paragraph before Theorem 2: \"As in the previous section, it is easy to see that the black-and-white coloring problem reduces to finding a collection of noncrossing scanlines.\"",
        "Explanation": "The algorithm for circle graphs relies on the idea that the problem can be reduced to finding a collection of noncrossing scanlines that partition the graph. This is analogous to Lemma 1 for permutation graphs. However, this reduction is merely asserted (\"it is easy to see\") without any proof, argument, or discussion of how properties like \"optimal\" colorings (if applicable here) would lead to such a structure for circle graphs. This is a foundational gap for the circle graph algorithm."
      },
      {
        "Problem": "Dynamic programming for circle graphs makes an unsubstantiated restrictive assumption.",
        "Location": "Page 5, Proof of Theorem 2, description of table contents for scanline s', item (c).",
        "Explanation": "The dynamic programming state for circle graphs includes an assumption (item (c) of the table contents) that a certain region of vertices R (defined as an 'area' bounded by scanlines and not part of other subproblems) is entirely colored black. This is a strong, specific structural assumption about solutions. There is no justification provided for why such a region R must be monochromatic black in a valid or optimal coloring; it might need to be white, uncolored, or have a mixed coloring. This restriction could cause the algorithm to miss valid solutions."
      },
      {
        "Problem": "Vague and underspecified dynamic programming algorithm for circle graphs.",
        "Location": "Page 4-5, Proof of Theorem 2.",
        "Explanation": "The description of the dynamic programming algorithm for circle graphs is very high-level and lacks necessary details for verification. Key aspects, such as the precise definition of the set R, the chain of scanlines Δ, the transitions, and the proof of \"important observations\" (e.g., \"each chord that crosses s' crosses at most one other scanline of Δ\"), are missing or unclear. The paper also explicitly avoids analyzing the DP table size, stating it is \"rather large\" though polynomial, which obscures the actual complexity and feasibility of the proposed method."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 9560,
      "output": 940
    }
  },
  {
    "entry_id": 84,
    "retraction_id": "1304.5962v2",
    "paper_id": "1304.5962v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect problem formulation: missing discount factor",
        "Location": "Page 2, Equation after 'optimization problem'",
        "Explanation": "The formulation of the option price V(S,τ) = inf_u E_x [ψ(S_T) + 1_{u<T}e^{-ru}Y(S_u)] does not discount the terminal payoff ψ(S_T). If τ is time to maturity, this term should be discounted by e^{-rτ} (or e^{-rT} if T is time to maturity in that expression). This is a fundamental error in the problem setup."
      },
      {
        "Problem": "Incorrect solution form in Lemma 3.1 for the heat equation BVP",
        "Location": "Page 5, Lemma 3.1 and its application in Theorem 3.2 (Eq. 13 and page 7)",
        "Explanation": "The solution u(x,t) provided in Lemma 3.1 for the quarter-plane heat equation problem (u_t = c^2 u_xx, u(x,0)=k, u(0,t)=f(t)) appears incorrect. Specifically, the integral term x/(2c√t) ∫ f(t-τ) exp(-x^2/(4c^2τ)) τ^(-3/2) dτ does not match standard solution forms (e.g., involving convolution with x/(Cτ'^(3/2))exp(-x^2/(Dτ')) where τ' is the integration variable). The prefactor x/(2c√t) and the use of τ^(-3/2) inside the integral where the argument of f is (t-τ) is non-standard. This lemma is crucial for deriving the main pricing formula (13), so an error here invalidates the formula. The application on page 7 for w(ȳ,τ̄) also reflects this potentially incorrect solution structure."
      },
      {
        "Problem": "Incorrect coefficient 'a' in PDE transformation",
        "Location": "Page 6, Definition of 'a' below Eq (19)",
        "Explanation": "The coefficient 'a' used in the transformation ε = e^(aτ̄ - bȳ)w to simplify the PDE (17) to the heat equation (20) is given as a = ((r-σ^2/2)^2)/(2σ^2) - r. A standard derivation yields a = -((r-σ^2/2)^2)/(2σ^2) - r. The sign of the first term is incorrect. This error propagates into the exponential factors of the final pricing formula (13)."
      },
      {
        "Problem": "Incorrect exponential term in the final pricing formula (13)",
        "Location": "Page 6, Equation (13)",
        "Explanation": "The final formula for ε(S,τ) in Equation (13) contains an exponential term e^(-a(τ-s)) inside the integral and a factor K^b outside. Deriving the solution using the stated transformations (even with the corrected 'a') and the heat equation solution leads to a different structure for these exponential terms, typically involving e^(as) (where s is the integration variable) and different powers of S and K outside the integral (e.g., S^(-b)K^(2b) or similar). This indicates a significant error in the construction of the final solution from the transformed problem, beyond just the error in 'a'."
      },
      {
        "Problem": "Incorrect formula for Theta used in Newton method",
        "Location": "Page 5, Equation for ∂v_K=1^E(K,τ)/∂τ",
        "Explanation": "The formula provided for the time derivative of the European option price (Theta), used for the Newton method to find τ*, is incorrect. The standard Theta for a call option is -S N'(d1)σ/(2√τ) - rKe^(-rτ)N(d2). The paper's formula includes a term +N(d1(τ)) which does not belong in Theta, and other terms may also have incorrect coefficients or signs (e.g. missing S or K factors). This would lead to an incorrect calculation of τ*."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 14157,
      "output": 948
    }
  },
  {
    "entry_id": 85,
    "retraction_id": "1908.07349v3",
    "paper_id": "1908.07349v2",
    "retraction_comment": "the results of theorem 2 is not correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The case M=1/2 for the class H_Σ(λ, τ, δ; M) leads to a degenerate function class.",
        "Location": "Page 4, Definition 2.2; Page 7, Remark 2",
        "Explanation": "Definition 2.2 introduces a class H_Σ(λ, τ, δ; M) for M ≥ 1/2, which corresponds to φ(z) = (1+z)/(1-mz) with m = 1 - 1/M. If M=1/2, then m=-1, so φ(z)=1. This implies φ'(0)=0, which contradicts the general assumption on φ stated on page 1 (φ'(0)>0). Furthermore, if φ(z)=1, the subordination condition Op(f) ≺ φ(z) (where Op(f)(0)=0) implies Op(f) ≡ 0. This forces all coefficients a_k (k≥2) to be zero, meaning f(z)=z. Thus, for M=1/2, the class H_Σ(λ, τ, δ; M) contains only the identity function, making coefficient estimation problems trivial (all coefficients are zero). The paper does not acknowledge this, and proceeds to give bounds that would imply zero for M=1/2 (e.g. B_1 = m+1 = 0)."
      },
      {
        "Problem": "Incorrect use of B_1 instead of |B_1| in the bound for |a_3|.",
        "Location": "Page 8, Theorem 3.6, Equation (3.16), third term in min function",
        "Explanation": "The third term in the minimum for the bound of |a_3| in equation (3.16) is given as |τ|(2B_1+|B_2|)/(1+2λ+6δ). The coefficient B_1 = φ'(0) can be complex or real (positive or negative), as per Carathéodory's Lemma (|B_n|≤2). If B_1 is complex or a negative real number, the expression 2B_1+|B_2| is not guaranteed to be a positive real number, and |2B_1+|B_2|| is not necessarily equal to 2|B_1|+|B_2|. For an upper bound, it should be (2|B_1|+|B_2|)|τ|/(1+2λ+6δ). As written, if 2B_1+|B_2| is negative, the bound would be incorrect."
      },
      {
        "Problem": "The middle term in the bound for |a_3| in Theorem 3.6 is not justified by the provided proof.",
        "Location": "Page 8, Theorem 3.6, Equation (3.16), second term in min function; Page 9, proof explanation",
        "Explanation": "The proof of Theorem 3.6 states that the estimate for |a_3| (Eq. 3.16) is derived from inequalities (3.23), (3.24) and (3.25). Eq. (3.25) is |a_3| ≤ |a_2^2| + |B_1 τ| / (1+2λ+6δ). Substituting the two bounds for |a_2^2| (derived from (3.23) and (3.24)) into (3.25) yields the first and third terms in (3.16). The middle term in (3.16) is (|B_1 τ|/(1+λ+2δ))^2 + |B_2 τ|/(1+2λ+6δ). This implies an alternative bound |a_3 - a_2^2| ≤ |B_2 τ|/(1+2λ+6δ), which contradicts the derivation of (3.25) that relies on c_1 = -d_1 (making the B_2(c_1^2-d_1^2) term zero in the expression for a_3-a_2^2). The provided proof steps do not support the inclusion of this middle term."
      },
      {
        "Problem": "The coefficient bound in Corollary 3.4 does not follow from Theorem 3.1 with standard parameter choices.",
        "Location": "Page 7, Corollary 3.4",
        "Explanation": "Corollary 3.4 provides a bound for |a_n| for functions f ∈ N_Σ^(α,λ). Assuming this class is a special case of H_Σ(τ, λ, δ; φ) with τ=1-α, δ=0, and φ(z)=(1+z)/(1-z) (so B_1=2), Theorem 3.1 would yield |a_n| ≤ 2(1-α) / (1 + (n-1)λ). However, Corollary 3.4 states |a_n| ≤ 2(1-α) / (n(1+λ(n-1))). The denominator n(1+λ(n-1)) is different from 1+(n-1)λ. This discrepancy makes the corollary, as a direct deduction from Theorem 3.1, incorrect."
      },
      {
        "Problem": "Inconsistent sign in coefficient equations when applying general Faber polynomial expansion formulas.",
        "Location": "Page 6, Eq. (3.9) vs Page 8, Eq. (3.18)",
        "Explanation": "Equation (3.9) states that the coefficient a_n is related to -B_1 K_{n-1}^1(...). Specifically, (1/τ)[1+(n-1)(λ+nδ)]a_n = -B_1 K_{n-1}^1(c_1,...,c_{n-1}; B_1,...,B_{n-1}). For n=2, assuming K_1^1=c_1, this would give (1/τ)[1+λ+2δ]a_2 = -B_1 c_1. However, equation (3.18), which is the case n=2 used in Theorem 3.6, states (1+λ+2δ)/τ * a_2 = B_1 c_1 (without the minus sign). While the derivation of bounds for |a_2| and |a_3| in Theorem 3.6 proceeds with relations like c_1 = -d_1 which are robust to this initial sign choice for B_1 terms, the inconsistency between the general formula (3.9) and its specific application in (3.18) indicates a flaw in the paper's logical consistency or presentation of its foundational equations."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 17405,
      "output": 1520
    }
  },
  {
    "entry_id": 86,
    "retraction_id": "1310.0331v4",
    "paper_id": "1310.0331v3",
    "retraction_comment": "this paper has been withdrawn by the author due to a crucial error in equation 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of the origin of fractional statistics",
        "Location": "Section II (e.g., page 1, paragraph 1 of Sec II; page 2, last paragraph of Sec II) and Abstract",
        "Explanation": "The paper claims that a specific pairwise entanglement structure (Eq. 1, 5, 7) 'results in' or 'is' fractional statistics. However, it primarily shows that known Laughlin wave functions (which exhibit fractional statistics) can be algebraically decomposed into such structures. This decomposition does not inherently explain or derive the fundamental characteristics of fractional statistics, such as anyonic exchange properties or fractional quasiparticle charges, which arise from the specific form of the Laughlin Jastrow factor."
      },
      {
        "Problem": "Unsupported core assumption of equal mean occupation numbers due to entanglement",
        "Location": "Page 3, Section III, first paragraph",
        "Explanation": "The derivation of modified Bose-Einstein and Fermi-Dirac statistics relies critically on the assumption that entanglement between particles in energy level e_i and e_{i+1} implies their mean occupation numbers (n_i and n_{i+1}) are equal. The paper states this 'can be derived' but provides no derivation or rigorous justification for this strong claim, leaving the foundation of the modified statistics unsubstantiated."
      },
      {
        "Problem": "Inconsistency or error in the derived bosonic occupation number",
        "Location": "Page 3, Eq. (12) and the derivation method described before it (N_i = (1/β) dlnZ/de_i)",
        "Explanation": "The paper states the average particle number N_i = (1/β) d(lnZ)/de_i. Applying this formula to the derived partition function for bosons (Eq. 11) yields N_i = -1/[exp(β(e_i+e_{i+1}-2μ)) - 1], which is a negative and unphysical occupation number. Equation (12) presents this result with a positive sign, indicating either an error in the presented equation or an inconsistency with the stated derivation method, leading to a physically invalid result for bosons as derived."
      },
      {
        "Problem": "Incorrect claim regarding the zero-temperature limit of modified statistics",
        "Location": "Page 3, Section III, paragraph after Eq. (12) and discussion of Eq. (15)",
        "Explanation": "The paper asserts that its modified statistical distributions recover the standard (non-entangled) distributions at T=0. This claim is generally incorrect. For example, the modified Fermi-Dirac distribution (Eq. 15) forces paired levels e_i and e_{i+1} to be either both occupied or both empty, based on their average energy relative to the chemical potential. This differs from standard Fermi-Dirac statistics, where occupation depends on individual energy levels, leading to different ground state configurations if e_i ≠ e_{i+1}."
      },
      {
        "Problem": "Ambiguous and potentially inconsistent treatment of state degeneracies in the entanglement model",
        "Location": "Page 3, Section III, last paragraph",
        "Explanation": "The model assumes 'every particle in energy level e_i is entangled with a particle in energy level e_{i+1}', leading to the condition n_i = n_{i+1} (equal particle numbers in the paired levels). If these energy levels have different degeneracies (state densities f(e_i) ≠ f(e_{i+1})), it is unclear how such a one-to-one entanglement scheme and the consequent equality of total particle numbers in these levels can be consistently maintained. The paper's brief mention of multiplying by f(e_i) does not adequately address this structural issue, potentially limiting the model's applicability to cases where f(e_i) = f(e_{i+1}) without this being explicitly stated."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 10828,
      "output": 868
    }
  },
  {
    "entry_id": 87,
    "retraction_id": "2308.02854v2",
    "paper_id": "2308.02854v1",
    "retraction_comment": "The assumption that the convex hull of d+2 points in R^d is either a d-simplex or a bi d-simplex is true only in d<4. In higher dimensions, there are more simplical polytopes, among which the cyclic polytope maximalizes the number of facets. As a consequence, there is no simple linear relation between the number of vertices and facets in d>3, from which one could connect the expected values",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Theorem 1 predicts negative expected volumes.",
        "Location": "Page 4, Theorem 1 (Equation 5) and its derivation.",
        "Explanation": "Theorem 1 states E[vol_d(H_{d+1})] = [2d / ((d-1)(d+2))] - [(d+1) / (2(d-1))] * I, where I is an integral term. The integral I = Integral_{K^d} [Gamma^2 + (1-Gamma)^2] dX^(1)...dX^(d) is bounded between 1/2 and 1, as 0 <= Gamma <= 1 and K has unit volume. Let C1 = 2d / ((d-1)(d+2)) and C2 = (d+1) / (2(d-1)). For d >= 2, C1 and C2 are positive. The expected volume can be negative if C1 - C2 * I < 0. This occurs if I > C1/C2. The inequality C1 < C2 is equivalent to 4d < (d+1)(d+2), which simplifies to d^2 - d + 2 > 0. This quadratic is always positive for any real d. Thus, C1 < C2 for all d >= 2. Since I can be arbitrarily close to 1 (e.g., for a 'thin' convex body K where Gamma is often near 0 or 1), the predicted expected volume E[vol_d(H_{d+1})] can be negative (specifically, if I > C1/C2, and C1/C2 < 1). Since expected volume cannot be negative, Theorem 1 is unsound as a general formula."
      },
      {
        "Problem": "Contradictory statements regarding Equation (1) and its relation to Efron's general formula and Theorem 1.",
        "Location": "Page 1, Equation (1); Page 2, statement below Theorem 1; Page 3, derivation of Efron's formula.",
        "Explanation": "Equation (1) presents a formula for E[vol_3(H_4)] as (3/5) * Integral [Gamma^2 + (1-Gamma)^2]. The paper claims this is a special case of the general Efron's formula (page 1) and that Theorem 1 reduces to Equation (1) for d=3 (page 2). However, the general Efron's formula, as stated on page 1 and derived on page 3 (for n=5, giving H_4), yields E[vol_3(H_4)] = 3/5 - Integral [Gamma^2 + (1-Gamma)^2]. Theorem 1 also yields E[vol_3(H_4)] = 3/5 - Integral [Gamma^2 + (1-Gamma)^2] for d=3. These two forms, (3/5) * Integral and 3/5 - Integral, are contradictory unless the Integral is universally 3/8, which is not true. This indicates a fundamental inconsistency in how Equation (1) is presented and related to the paper's main result and established formulas."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 19624,
      "output": 713
    }
  },
  {
    "entry_id": 88,
    "retraction_id": "1501.01153v3",
    "paper_id": "1501.01153v2",
    "retraction_comment": "Submission withdrawn due to the error in equation 35 on dimensional grounds",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent QGP Equation of State and Subsequent Derivations at Finite Chemical Potential.",
        "Location": "Primarily Eq. (49), Eq. (65), and their combination into Eq. (66). Also affects Fig. 2, Eq. (67-68), and related discussions on pages 8-9.",
        "Explanation": "The QGP pressure `P_p` at finite chemical potential (Eq. 49) is inconsistent with the paper's stated SU(2) degeneracies (page 6) and its foundational formulae for fermion and boson pressures (Eq. 36, 37). For example, the `T⁴` coefficient in Eq. (49) is `(2/3)π²`, whereas a consistent derivation from their SU(2) setup (used for `μ_q=0` in Eq. 60) yields `(20/90)π²`. Furthermore, the phase equilibrium condition at finite chemical potential (Eq. 66), which purportedly equates `P_p` from Eq. (49) and nucleon pressure `P_N` from Eq. (65), does not algebraically follow from these equations. These inconsistencies invalidate the quantitative results for the phase transition at finite chemical potential."
      },
      {
        "Problem": "Inconsistent Use of SU(2) vs. SU(3) Frameworks.",
        "Location": "Page 4 (Table 1, Eq. 43 for `B` derivation), Page 6 (SU(2) QGP degeneracy factors), Page 10 (use of SU(3)-typical \"heavy bag\" `B^(1/4)=0.250` GeV with SU(2) EoS).",
        "Explanation": "The paper inconsistently mixes elements from SU(3) and SU(2) QCD. The bag constant `B` is either derived using glueball masses (Table 1, Eq. 43) from a dual QCD model typically aimed at SU(3) phenomenology, or a \"heavy bag\" value `B^(1/4)=0.250` GeV (characteristic of SU(3) QCD) is employed. However, the quark-gluon plasma equation of state explicitly uses degeneracy factors for an SU(2) color group (page 6). This mismatch between the scale of `B` (often SU(3)-motivated) and the QGP degrees of freedom (SU(2)) undermines the physical basis and quantitative predictions of the model, particularly its relevance to real-world heavy-ion collisions governed by SU(3) QCD."
      },
      {
        "Problem": "Temperature Independence of Bag Constant `B`.",
        "Location": "Section 4 (Eq. 43 where `B` is derived from T=0 parameters), and its application throughout finite-temperature calculations in Sections 5 and 6.",
        "Explanation": "The bag constant `B`, representing the energy difference between the perturbative and non-perturbative QCD vacua, is treated as temperature-independent throughout the analysis. It is derived from zero-temperature glueball masses or assumed to be a fixed value. However, `B` is physically expected to be a decreasing function of temperature, vanishing at or above the deconfinement transition. Using a T=0 bag constant for finite-temperature phase transition studies is a significant oversimplification that can lead to inaccurate critical temperatures and may artificially impose a first-order phase transition (as `Δε = 4B`)."
      },
      {
        "Problem": "Weak Justification for Choice of Scalar Potential in Dual QCD Model.",
        "Location": "Page 4, discussion surrounding Eq. (10) and the choice of Eq. (11).",
        "Explanation": "The paper switches from a one-loop effective potential for the scalar field `φ` (Eq. 10), described as \"extremely reliable in the deep infrared sector,\" to a simpler quadratic potential (Eq. 11) claimed to be for a \"relatively weak coupling near-infrared regime.\" The justification for this substitution, especially for studying QCD phase transitions which are inherently non-perturbative, is insufficient. This choice directly impacts the derived glueball masses (Table 1) and, if Eq. (43) is used, the bag constant `B`, thereby affecting all subsequent thermodynamic calculations and conclusions about the phase transition."
      },
      {
        "Problem": "Oversimplification of the Hadronic Equation of State.",
        "Location": "Section 5, Equations (56) and (57) for pion gas properties.",
        "Explanation": "The hadronic phase is modeled as an ideal gas consisting solely of three massless pion species. This significantly oversimplifies the actual hadronic equation of state, which should include contributions from other light and strange hadrons, numerous resonances, their finite masses, and interactions, all of which become increasingly important near the critical temperature. Comparing this highly simplified hadronic EoS with the QGP EoS to determine phase transition parameters (like `T_c`) using Gibbs criteria can lead to quantitatively unreliable results and may misrepresent the actual phase boundary."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 12704,
      "output": 1116
    }
  },
  {
    "entry_id": 89,
    "retraction_id": "1910.10153v2",
    "paper_id": "1910.10153v1",
    "retraction_comment": "The function \\phi(x) which we define above Eq.8 is infinitely peaked in the thermodynamic limit; the long-time-tail behavior enters through higher derivatives of the entropy",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Eigenstate Factorization Assumption",
        "Location": "Page 2, paragraph 'Derivation', item (i); Supplement, Page 8, paragraph below Eq. (27)",
        "Explanation": "The assumption that 'Each eigenstate |n> of the entire system factorizes into a product of eigenstates of weakly coupled thermal blocks' is a very strong simplification. In a system with (even weak) coupling between blocks, the true eigenstates of the total Hamiltonian are entangled superpositions, not simple product states. This factorization is fundamental to the paper's method of calculating transport coefficients from the Kubo formula (e.g., leading to Eq. 6 and subsequent expressions for K_ij). If this assumption is invalid, the derived expressions for transport coefficients may not be rigorously obtained from the microscopic Hamiltonian, potentially invalidating the quantitative conclusions drawn from them."
      },
      {
        "Problem": "Approximation for Thermal Current Operator (J^Q)",
        "Location": "Page 7, Eq. (21); Motivation on Page 8, Eqs. (24-26)",
        "Explanation": "The thermal current operator J^Q is approximated as J^Q_i -> 1/2 [J^E_i, H_R - H_L], where J^E is the electric current density and H_R, H_L are Hamiltonians of adjacent blocks. The justification provided is for a specific 1D model and involves neglecting boundary terms. The generality of this approximation for arbitrary Hamiltonians and dimensions is not established. Since this operator is essential for calculating thermal conductivity (κ) and thermoelectric coefficients (K_12, K_21), an inaccurate approximation could lead to incorrect expressions for these quantities and any relations involving them, such as the generalized Wiedemann-Franz law."
      },
      {
        "Problem": "Matrix Element Assumption at Low Temperature",
        "Location": "Page 10, Eq. (40) and preceding paragraph",
        "Explanation": "At low temperatures (T << U), the matrix element of the restricted current operator J_ξτ between initial many-body states with energy ~T is assumed to be equal to its matrix element involving the ground state: |<M1,M2|J_ξτ|N1,N2>|^2 = |<g.s.|J_ξτ|n1,n2>|^2. The justification that an electron traveling distance ξτ is insensitive to finite temperature effects does not fully address why thermal excited states would yield the same matrix element magnitude as the ground state. This simplification directly impacts the derivation of K_ij(ω) at low temperatures (Eq. 9 and 45) by allowing the use of T=0 conductivity to determine these thermal matrix elements, potentially affecting the predicted temperature dependence and form of low-T transport coefficients."
      },
      {
        "Problem": "Random Matrix Theory (RMT) Assumption for Electron Operator Matrix Elements",
        "Location": "Page 3, Eq. (7); Supplement Page 9, Eq. (30)",
        "Explanation": "The paper assumes that matrix elements of the electron operator 'c' within a thermal block are constant, |<m1|c|n1>|^2 = ξ^d / Zξ(β=0) * Θ(U - |Em1 - En1|), independent of the specific many-body states m1, n1 and their energy difference (below a sharp cutoff U). This is an acknowledged extension of RMT 'beyond its intended validity'. Applying such a strong, simplified form of RMT directly to the electron operator, which is central to current transport, might oversimplify the actual structure and energy dependence of these crucial matrix elements. This could affect the accuracy of the derived high-temperature transport coefficients (Eq. 8) and subsequent conclusions."
      },
      {
        "Problem": "Incoherent Summation of Currents from Coherence Volumes at Low Temperature",
        "Location": "Page 10, Eq. (38) and (39)",
        "Explanation": "At low temperatures, the total current is obtained by incoherently summing contributions from different 'coherence volumes b' (of size ξτ) within each larger thermal block B (of size ξ(ω)). If transport within a coherence volume ξτ is coherent, the assumption that contributions from adjacent or overlapping coherence volumes within the same thermal block add incoherently needs stronger justification. This is particularly relevant if ξτ can be comparable to ξ(ω). This simplification might neglect interference effects between these coherence volumes, potentially impacting the accuracy of the low-temperature conductivity expression (Eq. 9 and 45)."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 4758,
      "output": 1010
    }
  },
  {
    "entry_id": 90,
    "retraction_id": "1306.5006v3",
    "paper_id": "1306.5006v2",
    "retraction_comment": "We have decided to withdraw the paper due to a crucial error in equation (9), that is in the definition of the p-value. This invalidates the results reported into the manuscript",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Bandwidth selection for testing",
        "Location": "Page 4, Section 3.1",
        "Explanation": "The paper acknowledges that bandwidths optimal for density estimation (like h_LCV, which is used) are often suboptimal for hypothesis testing, yet it claims h_LCV is appropriate and no oversmoothing is needed for the proposed KL-divergence based test, relying on findings from Bagnato et al. (2013b). This dismissal of potential suboptimality for testing power, without more direct justification or sensitivity analysis within this paper, is a concern, as inappropriate bandwidth can significantly affect test performance."
      },
      {
        "Problem": "Limited number of permutations for p-value computation",
        "Location": "Page 9, Section 6.1 (referencing B=99 permutations)",
        "Explanation": "The use of B=99 permutations for p-value calculation in the KL-autodependogram provides limited resolution for p-values (minimum 0.01) and can lead to less stable estimates of power and size in the simulation study. While sufficient for testing at alpha=0.05, a larger number of permutations would yield more reliable and precise comparisons of test performance, which is crucial when claiming 'substantial improvement' or 'supremacy'."
      },
      {
        "Problem": "Accuracy of KL divergence integral approximation",
        "Location": "Page 5, Equation (8) and surrounding text",
        "Explanation": "The KL divergence integral is approximated by a summation over a fixed 100x100 grid with a specific range extension rule. The paper does not provide a sensitivity analysis or justification for why this grid resolution and range are sufficiently accurate for the diverse models and sample sizes considered. Inaccuracies in this numerical integration could lead to a flawed test statistic, potentially affecting both the size and power of the test and thus the validity of the performance comparisons."
      },
      {
        "Problem": "Assumption of equal bandwidths in bivariate kernel density estimation",
        "Location": "Page 4, Section 3.1, description of Equation (6)",
        "Explanation": "The bivariate kernel density estimate uses a product of two one-dimensional Gaussian kernels with equal bandwidths, chosen 'for simplicity'. This simplification, while common, may not be optimal as the underlying data structure might benefit from different bandwidths for each variable (X_t and X_{t+r}) or a full bandwidth matrix. Using a single, potentially suboptimal bandwidth for both dimensions could lead to less accurate joint density estimation and consequently reduce the power of the proposed test."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 4560,
      "output": 574
    }
  },
  {
    "entry_id": 91,
    "retraction_id": "1704.08680v6",
    "paper_id": "1704.08680v5",
    "retraction_comment": "Algorithm does not terminate. Even if fixed, Claim 9 is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent explanation of variable growth rates in the central example.",
        "Location": "Page 13, explanation of Table 1 and Figure 4 (related to Algorithm 3 on page 11).",
        "Explanation": "The paper's explanation for its main example (Figure 4, Table 1) regarding the application of variable growth rates in phase 2 appears inconsistent with Algorithm 3. It states that Steiner node s2 (with delta1(s2)=3) grows with unit rate, while s1 and s3 (also delta1=3, assuming symmetry) grow with rate 2/3. Algorithm 3 (lines 19-20) specifies a modified growth rate for any node v with delta1(v) >= 2, determined by the factor R_v = (|Delta1(v) intersect L_v^t| / |L_v^t|). For full Steiner nodes (where Delta1(v) comprises all initial links L_v), if their set of active links L_v^t remains unchanged, R_v should be 1, leading to a unit effective rate. The differing rates (unit for s2, 2/3 for s1/s3) are not clearly justified by the algorithm description or the static nature of the example, making it difficult to understand and verify the core 'variable rates' mechanism."
      },
      {
        "Problem": "Potentially flawed derivation of hitting time for partial Steiner nodes in Proposition 7.",
        "Location": "Page 14, Proof of Proposition 7.",
        "Explanation": "Proposition 7 derives the hitting time tau''(v) for a Steiner node v. For partial Steiner nodes (those with delta1(v) >= 2, subject to variable growth rates), Algorithm 3 implies their coordinates grow at a rate scaled by R_v = (|Delta1(v) intersect L_v^t| / |L_v^t|). If v is linked to 'i' components, the sum of its coordinates should increase at rate 'i * R_v'. However, the proof of Proposition 7 asserts that for partial nodes, 'the sum of the increments ... is still i(t_{i+1} - t_i)' and concludes 'the desired equality holds as in the case of the full Steiner node.' This seems to overlook the scaling factor R_v, which if less than 1, would slow down the growth and alter the formula for tau''(v). An incorrect formula for tau''(v) would impact subsequent analyses that rely on it, such as Claim 10 and Theorem 8."
      },
      {
        "Problem": "Questionable soundness of the structural claim about optimal solutions (Claim 9).",
        "Location": "Page 15, Claim 9 and its proof.",
        "Explanation": "Claim 9 makes a strong structural assertion: an optimal solution T in instance I1 can be assumed to use either all links (L_v) of any algorithmic Steiner component K_v, or none of them. The proof provided is an exchange argument that appears to conflate properties of an arbitrary optimal solution T with properties derived from the algorithm's execution (e.g., hitting times like t_u, t_max, and costs based on Proposition 7). It's unclear how these algorithm-specific values and bounds apply to a generic optimal solution T, especially if T's structure is significantly different from the algorithm's output T^r. The justification for why the proposed edge exchanges maintain optimality or improve the structure in the desired way without increasing cost is not sufficiently rigorous. If Claim 9 is unsound, the subsequent proof of Theorem 8, which relies on it, may be invalid."
      },
      {
        "Problem": "The final accounting step in the proof of Theorem 8 (OPT_I1 >= OPT_I2) is unclear and potentially insufficient.",
        "Location": "Page 19, paragraph starting 'Finally, note that T must contain a set of edges...'",
        "Explanation": "Theorem 8 aims to prove OPT_I1 >= OPT_I2 by defining modified costs c2. The proof involves bounding the difference sum(c1(e) - c2(e)) for edges e in an optimal solution T. For edges e in L_p (links of a partial Steiner component), the analysis shows that sum_{e in L_p} (c2(e) - c1(e)) can be positive (e.g., (3ts - 2t)/7 for s=3), meaning these parts of T could be more expensive under c2. The final step of the proof cursorily argues that edges in E(T) \\ L (not part of any L_p) provide a 'decrease of cost' (since c2(e') = (6/7)c1(e') for these edges) that will offset any increase from the L_p parts. This argument ('This implies that each p induces a smaller cost on OPT_I2 than OPT_I1. Applying this observation to all p, we get OPT_I1 >= OPT_I2') is not sufficiently detailed. It does not provide a clear summation or global accounting to demonstrate that the total cost of T under c1 is indeed greater than or equal to its total cost under c2."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 14225,
      "output": 1159
    }
  },
  {
    "entry_id": 92,
    "retraction_id": "0710.2117v5",
    "paper_id": "0710.2117v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical error in the geometric formulation of the principle of inertial motion",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsupported foundational claim for Euclidean Special Relativity",
        "Location": "Section 2 (especially Eq. 1) and Page 5 ('Minimal set of assumptions')",
        "Explanation": "The paper claims that Special Relativity (SR) and Lorentz transformations can be derived from a 4D Euclidean metric (Eq. 1: d² = Δx² + Δy² + Δz² + c²Δt²) and an assumption that changing an object's speed does not change its 'Euclidean space-time volume.' However, a rigorous derivation is not provided. Standard SR is based on the Minkowski metric, and it's unclear how a positive-definite Euclidean metric can reproduce SR phenomena like length contraction and time dilation without contradicting established physics or requiring unconventional interpretations of coordinates and volumes. This unsubstantiated foundational claim undermines the basis of the proposed framework."
      },
      {
        "Problem": "Arbitrary and inadequately justified Law of Inertial Motion",
        "Location": "Section 3.2, Eq. (6) and Eq. (7)",
        "Explanation": "The proposed Law of Inertial Motion states that a particle's acceleration is directly proportional to the 'acceleration' of local light speeds (Eq. 6: dv/dt = dc/dt, or Eq. 7 involving a parameter K). The physical justification for this direct linkage, especially why massive particles should mimic changes in light speed so precisely, is insufficient. Eq. (7) introduces an undefined weighting factor K (0 ≤ K ≤ 1) without derivation or clear physical meaning, making the law lack predictive power or fundamental grounding. The admission that this law is not generally Lorentz covariant is also a significant weakness for a theory aiming to generalize SR."
      },
      {
        "Problem": "Mathematical errors in the derivation of radial acceleration, leading to a result contradicting the target model",
        "Location": "Section 5.2, specifically the derivation from Eq. (21) through Eq. (28) and its comparison to Broekaert's Eq. (13)",
        "Explanation": "The derivation in Section 5.2 aims to show compatibility between the author's motion law and Broekaert's model for radial acceleration. However, the derivation appears to contain sign errors or inconsistencies. For instance, the derived equation for radial acceleration (Eq. 28, which should be dv₂(r)/dt = +κc²e^(-4κ/r)/r² - 3κv₂(r)²/r² based on the steps shown) yields a repulsive primary gravitational term (+κc²...). This directly contradicts the attractive term (-κc²...) in Broekaert's model (Eq. 13, for radial motion). This mathematical discrepancy invalidates the paper's claim of successfully reinterpreting Broekaert's attractive gravity within its framework."
      },
      {
        "Problem": "Ad-hoc and poorly justified reinterpretation strategy using 'Model 0'",
        "Location": "Section 5.2, particularly the introduction and use of 'Model 0'",
        "Explanation": "The reconciliation of Broekaert's model (Model 2) with the author's framework relies on an intermediate 'Model 0,' which supposedly inherits properties from Model 2 and 'Model 1' (a configuration yielding attraction). The definition of Model 0 is vague, and the justification for its properties and for applying the motion law to it as if it were Model 1 (despite potentially different underlying light speed behaviors, e.g., sign of dc/dr) is not provided. The relationships assumed (e.g., Eq. 19: v₂(r) = v₁(r)e^(-3κ/r), Eq. 24: c₁/v₁ = c₂/v₂) appear to be constructed to achieve a desired outcome rather than derived from fundamental principles of the Euclidean framework, making the reinterpretation seem artificial."
      },
      {
        "Problem": "Ambiguity of 'Euclidean General Covariance' and its mechanism for describing gravity",
        "Location": "Section 3.1, 'The Euclidean principle of general covariance'",
        "Explanation": "The paper proposes a 'Euclidean principle of general covariance' within a 4D Euclidean space-time (++++ signature). It's unclear how this principle, and a fundamentally flat Euclidean geometry, can adequately describe gravity, which in General Relativity involves a curved pseudo-Riemannian manifold. The mechanism by which gravity arises (variable light speeds c(r) and modified cell extensions X(r), T(r) imposed on a Euclidean background) seems more akin to an ether-drift or bimetric theory rather than a truly geometric theory of gravity in the sense of GR. The nature and scope of the allowed 'coordinate transformations between space-time observers' and how they relate to physical gravitational effects are not clearly defined, making the soundness and utility of this covariance principle questionable."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 11091,
      "output": 1064
    }
  },
  {
    "entry_id": 93,
    "retraction_id": "1111.3825v3",
    "paper_id": "1111.3825v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in lemma 3.7",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption of 'real structure' for the harmonic bundle from Jost-Zuo [3]",
        "Location": "Page 2, lines 7-8; Theorem 3.1; Theorem 3.11",
        "Explanation": "The paper claims (page 2) that the harmonic bundle obtained via Jost-Zuo [3] for a reductive representation possesses a 'real structure'. This property is then assumed in Theorem 3.1 and is crucial for applying Theorem 3.11 (Mochizuki's purity theorem). However, the existence of a real structure is a strong condition not generally guaranteed by Jost-Zuo [3] for arbitrary complex reductive representations. If this assumption is not justified for the general case of Theorem 1.2, then Theorem 3.11 is inapplicable, breaking a key step in the proof of the main results."
      },
      {
        "Problem": "Unjustified assumption of 'trivial parabolic structure' for the harmonic bundle from Jost-Zuo [3]",
        "Location": "Page 2, lines 7-8; Theorem 3.1; Lemma 3.8",
        "Explanation": "The paper claims (page 2) that the harmonic bundle from Jost-Zuo [3] has a 'trivial parabolic structure'. This is assumed in Theorem 3.1 and is essential for Lemma 3.8, whose proof relies on Mochizuki [5, Thm 9.3], a work focused on bundles with trivial parabolic structure. 'Tame' (which Jost-Zuo [3] provides) does not automatically imply 'trivial parabolic structure' in the specific sense of Mochizuki [5] or Definition 2.4 of this paper. Without justification for this property, Lemma 3.8 (providing metric estimates) and subsequent arguments may be invalid."
      },
      {
        "Problem": "Mismatch in the definition of operator A and application of eigenvalue bounds",
        "Location": "Definition 3.12; Proposition 3.13",
        "Explanation": "Definition 3.12 defines an operator A = (K + 2p)u, where 'p denotes the degree of u with respect to dx1...dxn'. Proposition 3.13 then provides eigenvalue bounds for this A, citing Kashiwara-Kawai [4, Prop 5.11.1]. However, Kashiwara-Kawai's operator (A_KK) is K_0 + k (where k is the form degree), and their bounds apply to A_KK. The paper's operator A, due to the factor '2p' and the unclear definition of 'p', appears different from A_KK. If A is indeed different, applying Kashiwara-Kawai's eigenvalue bounds is unjustified. If p is intended to be the form degree k, then A = K+2k, which is still different from K+k, making the direct application of the bounds from [4] questionable."
      },
      {
        "Problem": "Overly strong and potentially incomplete claim for the final proof step",
        "Location": "Page 9, last paragraph of main text before references",
        "Explanation": "The paper concludes its proof by stating: 'The rest of the proof is exactly the same as Kashiwara-Kawai in [4], §5.12.' Kashiwara-Kawai's §5.12 is a complex, multi-page argument tailored to Variations of Polarized Hodge Structures (PVHS), which possess rich, specific properties (e.g., polarization, detailed structure of Hodge filtration). Asserting the argument is 'exactly the same' for the more general harmonic bundles considered in this paper (even with assumed real and trivial parabolic structures) is a very strong claim that requires detailed verification. It's possible that Kashiwara-Kawai implicitly used PVHS-specific properties that do not have direct or equally effective analogues in this generalized setting. This could hide a significant logical gap or an unaddressed subtlety in generalizing the argument."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 8858,
      "output": 887
    }
  },
  {
    "entry_id": 94,
    "retraction_id": "1711.04838v3",
    "paper_id": "1711.04838v2",
    "retraction_comment": "Lemma 9.1 is incorrect and so the main result is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect conclusion that T3 must be of type (1) in Lemma 8.4.",
        "Location": "Page 9, Lemma 8.4, Proof.",
        "Explanation": "The proof of Lemma 8.4 states that if the two b/t-edges at a triple point T3 are degenerate (because they end at branch points), then T3 must be of type (1) (i.e., color (x,x,x)). However, a triple point T3 of type (4) (color (x,y,x) with x!=y) satisfying the additional condition x*y=x also has both its b/t-edges degenerate (both become color (x,x)). If T3 is this specific type (4) rather than type (1), its cocycle weight W(T3) = theta(x,y,x)^e(T3) is not necessarily 1_G. Furthermore, such a T3 is not fully degenerate (it has non-degenerate b/m and m/t edges). This error invalidates the subsequent Lemma 8.5 (which assumes T3's edges are all degenerate) and the proof of Theorem 8.6 for the t(F)=3 case (which assumes W(T3)=1_G and that T1, T2 are degenerate)."
      },
      {
        "Problem": "The argument in the proof of Lemma 9.1 regarding double decker curves is likely unsound.",
        "Location": "Page 11, Proof of Lemma 9.1.",
        "Explanation": "The proof of Lemma 9.1, which claims that a diagram of a genus-one surface-knot with three triple points must have at least two non-trivial double point circles, contains a confusing and likely incorrect statement. It says: 'In the double decker set of Delta, the closed decker curve C^U_C1 meets the upper decker closed curve C^U at exactly one crossing...'. Here, C1 is defined as a double point arc, so its corresponding decker object C^U_C1 would also be an arc, not a 'closed decker curve'. An arc meeting a closed curve at a single crossing has different topological implications than two closed curves. The subsequent homology argument based on this premise is therefore suspect, potentially invalidating Lemma 9.1 and, consequently, Theorem 9.2 which relies on it to show there is no genus-one surface-knot with triple point number three."
      },
      {
        "Problem": "The argument that non-degenerate triple points T1 and T2 must have the same color in Lemma 8.2 is incomplete or potentially unsound.",
        "Location": "Page 9, Proof of Lemma 8.2, paragraph discussing non-degenerate T1 and T2.",
        "Explanation": "In the proof of Lemma 8.2 for a surface-knot with t(F)=2, when considering the case where T1 and T2 are both non-degenerate, the paper argues that this leads to T1 and T2 having the same color (and thus forming a cancelling pair). The crucial step involves analyzing how edges connect T1 and T2. The paper states: 'Let e3 be the b/m-edge at T1 whose colour is (x1, y1). From Table 1, another endpoint of e3 is neither T1 nor T2... Hence, this case is impossible.' This assertion is too brief and not sufficiently justified. A more detailed analysis of quandle algebraic conditions (e.g., if an edge (x1,y1) from T1 connects to an edge (x2*x1, y1*x1) at T2) is required. If it's possible for T1 and T2 to be non-degenerate, connected by edges, but not have the same color, then they would not form a cancelling pair, and the cocycle weight W(C) for such a coloring might not be 1_G. This would affect the conclusion of Theorem 8.6 for the t(F)=2 case."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 15090,
      "output": 896
    }
  },
  {
    "entry_id": 95,
    "retraction_id": "2010.13204v2",
    "paper_id": "2010.13204v1",
    "retraction_comment": "The conclusion of the paper is likely wrong. The second necessary integration step which is barely mentioned at the end of section B introduces another correlation between the vacuum fluctuations which will negate any gain of the here proposed method. I overlooked this. Thanks to [REDACTED-NAME] for figuring it out",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The fundamental equation governing the feedback signal amplitude `P_sig_int` is dimensionally inconsistent.",
        "Location": "Page 2, Section II.A, the first unnumbered equation for `P_sig_int` (derived from `E_PD`).",
        "Explanation": "The equation `P_sig_int = 2E_0 g P_sig e^{i(\\Omega(t-2\\tau)+\\phi_{RF})} + E_0 E_{sig} e^{i\\Omega(t-\\tau)}` attempts to define an electrical signal amplitude `P_sig_int` (e.g., in Volts or Amperes). However, if `E_0` and `E_sig` are optical field amplitudes (e.g., in V/m), the term `E_0 E_{sig}` is proportional to optical power (e.g., (V/m)^2) and requires a detector responsivity factor to become an electrical signal. The feedback term `2E_0 g P_sig_int` (assuming `P_sig_int` is `P_sig`) becomes dimensionally problematic: if `g P_sig_int` is a dimensionless modulation index, then `E_0` times this index is an optical field, not an electrical signal. This dimensional mismatch invalidates the subsequent derivation of the loop gain `r` and the overall signal analysis."
      },
      {
        "Problem": "The derived expression for the open loop gain `r = 2E_0 g` is inconsistent with standard models of optoelectronic feedback loops involving amplitude modulation.",
        "Location": "Page 2, Section II.A, definition of `r` (near `where we use r = 2E_0g`).",
        "Explanation": "A standard derivation for the open loop gain `r` in such a system typically involves the local oscillator optical power (proportional to `E_0^2`), detector responsivity, and modulator efficiency/gain. The paper's expression `r = 2E_0 g` (where `g` would need units of inverse optical field for `r` to be dimensionless, if `P_sig_int` and `E_0 E_{sig}` were consistently electrical signals) does not conform to this structure. This suggests an error in modeling the feedback mechanism or is a direct consequence of the dimensional inconsistency in the preceding equation. An incorrect `r` invalidates the calculated signal enhancement and stability conditions."
      },
      {
        "Problem": "The noise analysis fails to account for electronic noise originating from the active feedback components.",
        "Location": "Page 3-4, Section II.B, \"Random noise in active regeneration systems\".",
        "Explanation": "The analysis exclusively considers shot noise from the local oscillator. However, the active feedback loop necessarily includes electronic components, such as amplifiers providing the gain `g` and the amplitude modulator's driver. These components introduce their own noise (e.g., Johnson noise, amplifier input noise). This electronic noise will modulate the local oscillator, be injected into the optical path, and then amplified by the effective loop gain (related to `1/(1-r)`). This additional noise source can significantly degrade the actual signal-to-noise ratio (SNR), potentially invalidating the conclusion that the active system's SNR is 'essentially identical' to that of an ideal passive regeneration cavity."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 14330,
      "output": 743
    }
  },
  {
    "entry_id": 96,
    "retraction_id": "2208.11892v3",
    "paper_id": "2208.11892v2",
    "retraction_comment": "Lemma 3.2 does not hold. A counter example is $f \\equiv 1$",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect power of h in the estimate for the boundary term R5, leading to an incorrect coefficient for the pressure error term ζh in the global Lp error estimate for velocity (7.1).",
        "Location": "Page 15, estimate for R5; Page 16, equation (7.1).",
        "Explanation": "The term R5 = -(ζ̃h, w·n)∂Ωh in Lemma 7.1 is estimated. Using the paper's assumption (2.8) for ζ̃h (||ζ̃h||_Lp(∂Ωh) ≤ Ch^(-1/p)||ζh||_Lp(Ωh)) and the boundary estimate (2.4) for w (which implies ||w||_Lp'(∂Ωh) ≤ Ch^(2-1/p')||∇²w||_Lp'(Ω) ≤ Ch^(2-1/p')||Φ||_Lp'(Ω)), the product of scalings yields h^(-1/p) * h^(2-1/p') = h^(2-(1/p+1/p')) = h. Thus, R5 should contribute a term of order Ch||ζh||_Lp(Ωh) to the estimate for ||(e,Φ)h||. However, the paper's estimate for |R5| on page 15 is Ch^(2-1/p)||ζh||_Lp(Ωh)||Φ||_Lp'(Ω). This stated estimate for R5 does not directly follow from (2.4) and (2.8). Furthermore, this leads to the term Ch^(1-1/p)||ζh||_Lp(Ωh) in the final estimate (7.1) for ||e||_Lp(Ωh). If R5 contributes Ch||ζh||, then the term in (7.1) (after dividing by the overall Ch factor) should be ||ζh||_Lp(Ωh), not h^(-1/p)||ζh||_Lp(Ωh) (which becomes Ch^(1-1/p)||ζh||_Lp(Ωh) due to the Ch prefactor in (7.1)). This discrepancy in the power of h for a key error term is critical and affects subsequent results derived from (7.1), such as (2.22)."
      },
      {
        "Problem": "Misleading and confusing definition and properties of the function ψ̃h related to the quasi-preservation of divergence assumption (H2) for Taylor-Hood elements.",
        "Location": "Page 4, assumption (H2) (equations 2.7, 2.8); Page 5, definition of ψ̃h; Appendix A.2, Theorem A.1 and its proof (page 26-28).",
        "Explanation": "Assumption (H2) introduces a function ψ̃h on the boundary ∂Ωh, involved in the term (v·n, ψ̃h)∂Ωh in (2.7). On page 5, for Taylor-Hood elements, ψ̃h is defined as 'ψ̃h|T = (1/|T|)∫T ψhdx'. This defines ψ̃h over elements T ⊂ Ωh, not directly as a function on ∂Ωh for use in the boundary integral. The appendix (page 28) shows that (2.7) is satisfied with an 'effective' ψ̃h on each boundary edge e(T) (of T∈T∂h) being -(1/|T|)∫T ψh dx. This specific form of ψ̃h on ∂Ωh is not clearly stated when (H2) is introduced. Additionally, the property 'supp ψ̃h = supp ψh' stated in (H2) is problematic as ψ̃h is on ∂Ωh and ψh is in Ωh (unless it refers to the support of their traces). This lack of clarity and misleading initial definition can make it difficult to verify the assumptions and follow the arguments, potentially obscuring the precise requirements for ψ̃h and the validity of (2.8) for it."
      },
      {
        "Problem": "The derivation of the lower bound for the range of p (p > 2N/(N+2)) in the main theorem (Theorem 2.1) is not provided or justified within the presented error analysis.",
        "Location": "Page 1, statement of p range; Page 6, Remark 2.2(ii); Section 8.1 (Proof of (2.21) for p>2, pages 18-19).",
        "Explanation": "The paper claims the Lp-resolvent estimate holds for p ∈ (2N/(N+2), 2N/(N-2)). The error analysis in Section 8.1 (pages 18-19), particularly the conditions for the kick-back argument involving the constant K (related to N/p - N/2 - 1 < 0), primarily justifies the upper bound p < 2N/(N-2). The paper mentions that 'The restriction for p is caused by the treatment of lower-order terms appearing in the local energy error estimate' (page 1), which corresponds to this upper bound derivation. However, the origin or necessity of the lower bound p > 2N/(N+2) (e.g., p > 6/5 for N=3, or p > 1 for N=2 as stated in Remark 2.2(ii)) is not explicitly derived or explained from the local energy estimates or other parts of the error analysis presented in the paper. While this range is common in Stokes theory, its justification within the paper's specific finite element analysis framework is incomplete."
      }
    ],
    "token_usage": {
      "input": 8380,
      "thinking": 19146,
      "output": 1267
    }
  },
  {
    "entry_id": 97,
    "retraction_id": "1507.00282v2",
    "paper_id": "1507.00282v1",
    "retraction_comment": "This paper has been withdrawn due to a crucial error in the proof of Proposition 14. The authors are very thankful to [REDACTED-NAME] for kindly pointing it out",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential miscalculation of a key term in Proposition 14.",
        "Location": "Page 7, Equation (22)",
        "Explanation": "Equation (22) states that (δJφ)(e1) = ... = 2N(Jφ)(e2, e3, e4) = 4N1v – 4N2u. The term N(Jφ)(e2, e3, e4) is defined via Definition 11 as (Jφ)(e2, N(e3,e4)) + (Jφ)(e3, N(e4,e2)) + (Jφ)(e4, N(e2,e3)). Using the provided decomposition of N and definitions of Jφ, ρ, Jρ, a term-by-term calculation yields N(Jφ)(e2,e3,e4) = u(N1+N4) - v(N2+N3). This would make 2N(Jφ)(e2,e3,e4) = 2[u(N1+N4) - v(N2+N3)]. The paper's expression is 2(2N1v - 2N2u). If this calculation is incorrect as suggested, the resulting relation (20) uN2 = vN1 would change, impacting the core argument. While the overall proof strategy might still hold with modified relations, a miscalculation in such a central formula is a critical issue in the presented derivation."
      },
      {
        "Problem": "Ambiguity or potential error in the definition or application of N(Z1, Z2) in the proof of Proposition 12.",
        "Location": "Page 5, around equation (13)",
        "Explanation": "In the proof of Proposition 12, the paper states 'Inserting N(Z1, Z2) = -[Z1, Z2]^(1,0) gives (13)...'. For Z1, Z2 of type (1,0), the Nijenhuis tensor N(Z1,Z2) typically has a (0,2) component related to -[Z1,Z2]^(0,2) (this is the N^(0,2) part of N). The (1,0) component of N(Z1,Z2) is not standardly used this way, or N(Z1,Z2) itself is a vector, not a (1,0) vector. If N(Z1,Z2) in φ(Z3, N(Z1,Z2)) refers to the Nijenhuis tensor (a vector), and φ is a (2,0)+(0,2) form, then φ(Z3, N(Z1,Z2)) would be zero if Z3 is (1,0) and N(Z1,Z2) has no (1,0) component that φ can pair with. The notation and usage here are unclear and potentially incorrect, which could affect the derivation of (dJφ)^(1,2) and thus Proposition 12."
      },
      {
        "Problem": "Notation for type decomposition of forms and their differentials in Proposition 12 proof.",
        "Location": "Page 5, proof of Proposition 12",
        "Explanation": "The proof of Proposition 12 uses notation like (dφ)^(1,2)(Z3, Z1, Z2) where Z1, Z2, Z3 are all local sections of T^(1,0)M. A (1,2)-form should typically take one T^(1,0)M argument and two T^(0,1)M arguments (or their duals). If Z1, Z2, Z3 are all of type (1,0), this expression would correspond to a (3,0)-form component of dφ, not a (1,2)-form component. This notational confusion makes the steps involving complex type decomposition difficult to verify and could hide errors in the argument leading to the formula for d(Jφ)."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 23166,
      "output": 900
    }
  },
  {
    "entry_id": 98,
    "retraction_id": "1707.00947v2",
    "paper_id": "1707.00947v1",
    "retraction_comment": "I am so sorry, the hypothesis proposed by this paper would be not appropriate because there is no mechanism on which can be based between money and output value in this paper. The equation maybe more empty",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsupported 'Natural Cycle' Mechanism",
        "Location": "Page 14, Figure 2, Section 'The hypothesis of natural cycle and driving cycle'",
        "Explanation": "The core model (Equation 2) describes convergence to a long-run equilibrium path (e.g., c=q-g). The 'Natural Cycle' hypothesis posits that the economy makes periodic movements *along* this path even when money growth (q) is constant. This cyclical movement along the equilibrium line is not derived from or explained by the mechanics of Equation 2, which details how the economy reaches the line, not how it oscillates along it. This is a critical gap, as the Natural Cycle is a fundamental component of the paper's business cycle theory."
      },
      {
        "Problem": "Empirical Rules Not Derived from Core Model",
        "Location": "Pages 22-23, Section 'The economic cycle of China'",
        "Explanation": "The 'Buffer Rule' (e.g., a buffer period before a Double Drop) and aspects of the 'Sensitivity Rule' (e.g., why an economy is at risk of crisis if q is near g, beyond c being near 0) are presented as outcomes or explanations within the model's framework. However, these rules appear to be primarily empirical observations from Chinese data or qualitative arguments. The core dynamic equation (Equation 2), being a first-order ODE, does not inherently predict such buffer periods or the specific mechanisms of sensitivity described without further assumptions or model extensions."
      },
      {
        "Problem": "Counterintuitive Inflation Dynamics for Non-Exponential Money Growth",
        "Location": "Page 9, conclusion of analysis for M(t)=V₀t, and subsequent generalization",
        "Explanation": "The model predicts that long-run inflation c ≈ -g for any non-exponential money supply growth (e.g., M(t)=constant or M(t)=V₀t). This implies that different forms of sustained, non-exponential money growth (like constant money supply versus linearly increasing money supply) have the same long-run impact on the inflation rate. This is a strong and counterintuitive claim compared to standard monetary theories where persistently faster, even if not exponential, money growth typically leads to higher inflation. While mathematically derived from Equation 2, its general economic soundness is questionable."
      },
      {
        "Problem": "Unexplored Nature and Impact of Parameter 'k'",
        "Location": "Page 5 (definition of k), Pages 10-11 (role in inflation regimes), Pages 12-13 (empirical test)",
        "Explanation": "The parameter 'k', representing the characteristic time for adjustment, is crucial for the model's dynamics. It influences the speed of convergence and determines the threshold (q = -1/k) for different long-run inflation behaviors. The paper does not discuss the determinants of 'k', its stability, or how it might vary with economic conditions (e.g., q, g, or institutional factors). The empirical validation of c=q-g (Figure 1) implicitly assumes q > -1/k for all observations and does not attempt to estimate or control for 'k', potentially limiting the robustness of the empirical support for the claimed c=q-g path."
      },
      {
        "Problem": "Over-interpretation of Model Output as Structural Functions",
        "Location": "Page 12, discussion of Equation (16) P(Y)",
        "Explanation": "Equation (2) is a macroeconomic adjustment model for nominal sales (PY) based on the gap M-PY. The paper interprets its solution, particularly Equation (16) which expresses price P as a function of output Y (derived by substituting time out of P(t) and Y(t)), as 'both a demand function of product and a supply function of product.' This is an overstatement, as the model does not derive these relationships from microeconomic foundations of optimizing agents or market clearing conditions typically associated with structural supply and demand functions. It's an outcome of an aggregate adjustment dynamic."
      }
    ],
    "token_usage": {
      "input": 7606,
      "thinking": 7584,
      "output": 887
    }
  },
  {
    "entry_id": 99,
    "retraction_id": "2212.04536v2",
    "paper_id": "2212.04536v1",
    "retraction_comment": "Thm. A, Cor. B, are incorrect as stated and would require additional assumptions on q (a result of a missing assumption in another paper). Withdrawn until I obtain a working solution",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The final step in the proof of Theorem C, reducing the problem from the general group G to an almost simple group H, has insufficient justification.",
        "Location": "Page 6, Proof of Theorem C, last paragraph",
        "Explanation": "The proof states 'From here, we argue exactly as in the proof of [DNT08, Thm. A]'. However, the setup is different. Theorem 4.1 provides a character χ_H ∈ Irr(H) that is σ-invariant for the given σ. Let θ be an irreducible constituent of (χ_H)|_S1. The character η = θ × 1... × 1 ∈ Irr(N) is then considered. \n1. Unlike in [DNT08] where the base character ψ is rational (hence σ-invariant for any σ), here θ may not be σ-invariant. If χ_H|_S1 is reducible and σ permutes its constituents (e.g., σ(θ_1)=θ_2), then η_1 = θ_1 × 1... is not σ-invariant. This complicates finding a σ-invariant character of I_G(η_1).\n2. Even if η is σ-invariant (e.g., if (χ_H)|_S1 is irreducible, making θ σ-invariant), the existence of a σ-invariant irreducible character ξ ∈ Irr(I_G(η)|η) of even degree needs justification for a general order-2 Galois automorphism σ. [DNT08] relies on results for specific types of σ (complex conjugation or field automorphisms).\n3. The irreducibility of Ind_{N_G(S)}^G(χ̃_H) (where χ̃_H is the inflation of χ_H) is claimed, which requires N_G(S1) = I_G(η). This equality is not justified."
      },
      {
        "Problem": "The proof of Theorem A contains a critical ambiguity regarding the condition on the Galois automorphism σ.",
        "Location": "Page 3, Proof of Theorem A, first paragraph of the proof proper",
        "Explanation": "The proof states: 'Let σ ∈ G be an element of the subgroup stabilizing Q(χ)'. If 'stabilizing Q(χ)' means that σ fixes Q(χ) pointwise (i.e., σ(v)=v for all v ∈ Q(χ)), then χ^σ = χ, and the subsequent argument that x̂^σ is an extension of χ (and thus x̂^σ ∈ {x̂, x̂β}) holds. However, standard field theory terminology for 'stabilizer of a subfield L' is the set of automorphisms g such that g(L)=L (setwise). If setwise stabilization is meant, then χ^σ is not necessarily equal to χ (e.g., if χ is not rational-valued and σ is complex conjugation acting on Q(χ)). In that case, x̂^σ would be an extension of χ^σ, not χ, and the argument x̂^σ ∈ {x̂, x̂β} would fail, invalidating the proof that Q(x̂) ⊆ Q(χ). This ambiguity is critical for the validity of Theorem A."
      },
      {
        "Problem": "The argument for the existence and properties of the common extension x̂ in the proof of Corollary B is not fully justified.",
        "Location": "Page 4, Proof of Corollary B",
        "Explanation": "The proof states: 'Then we may take x̂ to be the the unique common extension of χ̃1 and χ̃2. The uniqueness forces Q(x̂) = Q'. \n1. Uniqueness of a common extension of χ̃1 (on S̃<τ>) and χ̃2 (on S̃<F0>) to Aut(S) = S̃<τ,F0> is not guaranteed in general. While a rational common extension x̂ exists because χ̃1 and χ̃2 are rational and Aut(S)/S̃ is abelian (applying results like Navarro, Thm 10.2), this does not imply it is the *unique* common extension. Other non-rational common extensions might exist.\n2. The reasoning 'The uniqueness forces Q(x̂)=Q' is problematic. If multiple common extensions exist, it's unclear why uniqueness (if it holds) would force rationality. It's more direct to state that a rational common extension can be chosen. If this chosen rational extension is not unique among all common extensions, the argument as phrased is insufficient."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 20756,
      "output": 999
    }
  },
  {
    "entry_id": 100,
    "retraction_id": "1405.2435v10",
    "paper_id": "1405.2435v9",
    "retraction_comment": "lemmas 11 is wrong. The conjecture is not proved.",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified spanning argument in Lemma 2",
        "Location": "Page 5, Proof of Lemma 2",
        "Explanation": "The proof that the n(k-1)+1 constructed matrices (Vi,j and K) span the space V of all relevant n x k word matrices relies on the statement 'Therefore ΣVi,j - (m-1)K = T'. The variable 'm' is not clearly defined in this context, and the equation itself is not derived or justified. If these matrices do not span V, or if the dimension of V is different, then the dimension n(k-1)+1 is incorrect. This would invalidate Corollary 2, which claims a dimension of (n-1)^2 for k=n-1, a cornerstone for the paper's main result."
      },
      {
        "Problem": "Unsubstantiated step in Lemma 11's proof concerning matrix relationships",
        "Location": "Page 14, Proof of Lemma 11, around equation (8)",
        "Explanation": "The proof of Lemma 11 makes a critical step: 'Lx = Lßy = MßLy (S,y)=(S,x) Ly ∈ Wm'. The equality Lx = Lßy (or the direct transformation Lx = MßLy where Ly is a solution for Muß) is justified by 'Definition 2, common Mu and minimality of solutions imply Lx = Lßy by Lemma 9'. However, Lemma 9 primarily relates (S,x) to |N(u)| and does not directly imply this structural equality or transformation property between solutions for Mu and Muß. If this relationship is incorrect, the subsequent argument that Mß acts as an endomorphism on the space Wm, leading to the contradiction Lz = MsLw, is unsound, invalidating Lemma 11."
      },
      {
        "Problem": "Assumption that any word matrix in the space Vp is an L-type matrix in Lemma 11",
        "Location": "Page 13, Proof of Lemma 11, lines 9-11",
        "Explanation": "The proof of Lemma 11 states: 'Therefore for every matrix of word Mw ∈ Vp, Mw = Lw and (S,w) > 0 by Lemma 8.' The space Vp is generated by L-type matrices (solutions Lx to MuLx=Ms). While Lemma 8 argues that if a linear combination of L-type matrices results in a word matrix, that resultant matrix is also an L-type matrix (Mt=Lt), it does not automatically follow that any arbitrary word matrix Mw that happens to belong to the span Vp must itself be one of these specific L-type forms (Mw=Lw). This is a strong assumption about the structure of word matrices within Vp and is crucial for the subsequent arguments in Lemma 11 that rely on all relevant matrices being of the special L-type."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 10561,
      "output": 649
    }
  },
  {
    "entry_id": 101,
    "retraction_id": "1705.07013v2",
    "paper_id": "1705.07013v1",
    "retraction_comment": "The proofs involve use of structured input states which could not be generalized",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency between derived constraints and parameters for the claimed optimal fidelity sum.",
        "Location": "Page 3, paragraph after Eq. (13) (parameter values) and Eq. (12) (constraints).",
        "Explanation": "The specific parameter values provided (η₁=1, bx=1, η₂=0, txx=tyy=tzz=0, p₁=p₅=1, q₁=q₅=1, other pᵢ,qᵢ=0) which are claimed to achieve the optimal fidelity sum Fd+Fp=1.5, are inconsistent with the paper's own derived no-signaling constraints in Eq. (12). For example, substituting η₂=0 into the fourth line of Eq. (12) yields bxη₂=0 on the left side. However, with the given pᵢ and qᵢ values (p₁=1, p₂=0, q₁=1, q₂=0), the right-hand side 2(p₂² - p₁² + q₂² - q₁²) evaluates to 2(0² - 1² + 0² - 1²) = -4. This leads to the contradiction 0 = -4, invalidating the claim that these parameters satisfy the derived constraints and thus achieve the stated optimal sum."
      },
      {
        "Problem": "Unsound or inadequately justified application of the No-Communication Theorem (NCT) to derive key constraints.",
        "Location": "Page 3, derivation of Eq. (12), purportedly from the no-signaling condition involving Eq. (10) and Eq. (11).",
        "Explanation": "The derivation of the crucial constraints in Eq. (12) from the NCT is not clear or appears unsound. The initial application of NCT via Eq. (10) is based on input mixtures that are identical (both are I/4 ⊗ I/4), leading to a trivial condition (D(I/4 ⊗ I/4) = D(I/4 ⊗ I/4)) that imposes no constraints on the deletion machine's parameters (ηᵢ, tᵢⱼ). The subsequent step, which involves states from 'invalid inputs' like ρ(↑)⊗ρ(↓) (Eq. 11, producing |Φ⟩, |γ⟩ etc.), and connects their properties (pᵢ, qᵢ) with the machine parameters (ηᵢ, tᵢⱼ) via Eq. (12), lacks clear physical or mathematical justification within the NCT framework. Standard interpretations of NCT applied to the universal deletion machine (Eq. 4) do not readily yield such combined constraints."
      },
      {
        "Problem": "Potentially incorrect expressions for eigenvalues of the output state matrix.",
        "Location": "Page 3, Eq. (13).",
        "Explanation": "The eigenvalues of the output density matrix ρ(→) (i.e., ρ^(out)(m) for m along the x-direction) provided in Eq. (13) do not seem to correctly correspond to those derived from the general form of the output state (Eq. 4) under the stated covariance conditions and the condition t_zy=0 (from Eq. 12). A direct calculation of eigenvalues from the matrix representation in Eq. (9) (with m along x and t_zy=0) yields expressions different from those in Eq. (13). Since the non-negativity of these eigenvalues is a fundamental constraint for the optimization process, an error in their calculation would lead to an incorrect feasible parameter space, thereby potentially invalidating the derived bounds on fidelities."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 12691,
      "output": 801
    }
  },
  {
    "entry_id": 102,
    "retraction_id": "1801.01544v2",
    "paper_id": "1801.01544v1",
    "retraction_comment": "We withdraw the manuscript because Lemma 2.3 is false",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent range for parameter 's' and its impact on proofs.",
        "Location": "Abstract states s in (1/2, 1). Page 2, after Eq. (1.1), states s in (0,1). Theorem 1.2 implicitly assumes s in (0,1) via definition of pc. However, the proof of Theorem 3.1 (a version of Theorem 1.2 for f(u)=u^p) on Page 10, for estimate (3.14), explicitly states 'we have used s > 1/2'.",
        "Explanation": "The paper presents conflicting ranges for the fractional order 's'. The abstract specifies s in (1/2, 1), while the main body often implies s in (0,1) for key definitions and theorems (e.g., Theorem 1.2). A critical step in the proof of the a priori estimates (Theorem 3.1 / Theorem 1.2) explicitly requires s > 1/2 (page 10, derivation of Lipschitz continuity for w_k). If the theorems are meant to hold for s in (0,1), this part of the proof is invalid for s <= 1/2. This ambiguity affects the scope and validity of the main results."
      },
      {
        "Problem": "Unusual and potentially problematic definition of the test function space X_s(Omega).",
        "Location": "Page 4, Definition 1.5, condition (iii).",
        "Explanation": "The definition of the test function space X_s(Omega), used for defining weak solutions (Definition 1.5), includes a highly non-standard condition (iii): 'there exists phi in L^1(Omega, delta^s) and epsilon_0 > 0 such that |(-Delta)^(epsilon/2)_x zeta(x)| <= phi(x) a.e. in Omega, for all epsilon in (0, epsilon_0]'. This condition, requiring a uniform L^1(Omega, delta^s) bound for fractional Laplacians of the test function zeta for a continuous range of small orders epsilon, is very restrictive. It is unclear if this space X_s(Omega) is sufficiently large (e.g., non-trivial beyond the zero function, or dense in any useful larger space) for the theory of weak solutions to be well-posed or standard. If X_s(Omega) is too small, the notion of weak solution might be too weak or ill-defined, which would be a foundational issue for several results relying on this definition (e.g., Theorem 1.7, Theorem 1.8)."
      },
      {
        "Problem": "Flawed derivation of a key estimate in Lemma 4.1 used for Theorem 1.8.",
        "Location": "Page 14, Equations (4.5)-(4.7) in the proof of Lemma 4.1.",
        "Explanation": "Lemma 4.1 provides an L^p estimate for solutions, which is then used in Theorem 1.8 to prove the finiteness of the critical parameter rho*. The derivation of estimate (4.7) from (4.5) and (4.6) is problematic. Specifically, the application of Young's inequality as presented in (4.6) is not standard, and the algebraic steps leading from (4.5) and (4.6) to (4.7) appear incorrect or are at least unclearly justified with the given forms. An error in (4.7) would undermine the proof that rho* is finite in Theorem 1.8, Case I."
      },
      {
        "Problem": "Error in an application of Hölder's inequality and its propagation in the proof of Lemma 4.3.",
        "Location": "Page 16, Equations (4.19), (4.20), and the subsequent algebraic equation for hat(Lambda) in the proof of Lemma 4.3.",
        "Explanation": "In the proof of Lemma 4.3, which establishes existence for an auxiliary problem used in Theorem 1.7, estimate (4.19) incorrectly applies Hölder's inequality (or a related inequality). It states 'integral v^p delta^s dx <= C (integral v^q delta^s dx) ...' where the term (integral v^q delta^s dx) should be raised to the power p/q. This error affects the subsequent estimate (4.20), which should be Q(S_n(v)) <= C(a Q(v)^p + ...)^(1/q) instead of C(a Q(v)^p + ...), and consequently alters the algebraic equation used to find the bound hat(Lambda). While the existence of such a hat(Lambda) might still hold under a corrected derivation, the proof as presented is flawed. Lemma 4.3 is a step towards proving the main existence result Theorem 1.7."
      }
    ],
    "token_usage": {
      "input": 7090,
      "thinking": 19032,
      "output": 1090
    }
  },
  {
    "entry_id": 103,
    "retraction_id": "2101.02111v2",
    "paper_id": "2101.02111v1",
    "retraction_comment": "We have found some data mistakes in our paper. The inverse transition in Section 3 (Figure 3d) and 7.1 (Figure 31) is probably consequence of inappropriate mesh configuration",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential inconsistency or lack of clarity in Global Energy Balance equations and interpretation.",
        "Location": "Page 26-28, Equations (5.10), (5.11), Table 2, and related discussion.",
        "Explanation": "The formulation of the global energy balance, particularly Equation (5.11) and the role of the term `[G1]g`, appears potentially inconsistent or is unclearly defined. `[G1]g` represents an energy transfer between radial and circumferential fluctuating components due to mean swirl. Its appearance as a net source term in both the equation for `Awall` (input power from wall motion) and the equation for `Nu` (turbulent dissipation, equated to total TKE production) is problematic. If `[G1]g` is an internal TKE redistribution term, it should not appear as a net source for total TKE or be directly funded by `Awall` in this manner. This ambiguity could affect the quantitative breakdown and interpretation of energy flows presented in Table 2."
      },
      {
        "Problem": "Interpretation of 'laminarisation' may be affected by computational domain length.",
        "Location": "Page 8 (laminarisation claims, Fig. 3), Page 44-46 (Discussion 7.1, inverse transition and pipe length).",
        "Explanation": "The paper claims achieving 'laminarisation' for certain control parameters. However, the computational pipe length (L=3πD ≈ 9.42D) might be insufficient to definitively distinguish between true, sustained global laminarisation and the suppression/decay of turbulence structures (like puffs, typically ~20D long) that cannot be sustained in a domain of this length due to self-cancelling effects of periodic boundary conditions. While acknowledged as an area for future study, this limitation could affect the robustness of the laminarisation claims, especially for inverse transition phenomena, if these states are not shown to be independent of domain length."
      },
      {
        "Problem": "Explanation for drag reduction mechanism with thin SSL (low control wavelengths) could be more direct.",
        "Location": "Page 17 (discussion related to Figure 10(d) and low-wavelength cases).",
        "Explanation": "For low control wavelengths, the paper argues the Spatial Stokes Layer (SSL) is thin, minimally affecting streaks, and attributes drag reduction to a decline in Reynolds shear stress (RSS). However, the primary mechanism by which the thin SSL causes this initial reduction in RSS (or its constituent fluctuations) is not fully elucidated in that section. The conclusion (p.48) mentions that for thin SSL, 'suppression of turbulence activity is more pronounced... in the viscous sublayer,' which is a more direct cause. The initial discussion on p.17 would be strengthened by more clearly linking the thin SSL's properties to a direct impact on RSS generation/maintenance, rather than primarily stating streaks are unmodified."
      }
    ],
    "token_usage": {
      "input": 13540,
      "thinking": 12153,
      "output": 652
    }
  },
  {
    "entry_id": 104,
    "retraction_id": "1703.04839v2",
    "paper_id": "1703.04839v1",
    "retraction_comment": "Our discussion omits the dominant tree-level shift (discussed in 1203.0237) of the Higgs quartic coupling in the full theory relative to the Higgs quartic coupling of the low-energy effective Standard Model. This shift can easily the electroweak vacuum. Therefore our conclusions (and upper bound on $f_a$) are invalid",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect RGE term for the PQ scalar self-coupling λ_Φ.",
        "Location": "Page 2, Eq. (4)",
        "Explanation": "The Renormalization Group Equation for λ_Φ includes a term `+ 12s_Q s_Φ y_Q^2 λ_hΦ`. This term, representing a contribution to the Φ self-coupling (λ_Φ) from KSVZ fermion (Q) loops involving the Higgs-Φ portal coupling (λ_hΦ) and the KSVZ fermion Yukawa coupling (y_Q), is not a standard textbook form (like y^4 or λ_Φ y^2 terms). If this term is incorrect (e.g., a typo in structure or coefficient), the running of λ_Φ would be erroneous. This would lead to an incorrect evolution of the PQ scalar mass m_ϕ(μ), which is critical for determining the decoupling scale μ_c and thus would directly impact the calculation of the f_a upper bound, potentially invalidating the quantitative conclusion."
      },
      {
        "Problem": "Unclear or potentially flawed justification for a key step in the f_a bound derivation.",
        "Location": "Page 4, paragraph 2, sentence: 'Requiring that μ_c < μ_0 then requires smaller values of λ_hΦ(m_t).'",
        "Explanation": "The derivation of the upper bound on the axion decay constant f_a includes the assertion that as f_a increases (which tends to increase the PQ scalar decoupling scale μ_c), maintaining the condition μ_c < μ_0 (the SM instability scale) necessitates *smaller* values of the initial Higgs-PQ portal coupling λ_hΦ(m_t). This statement is counterintuitive, as a smaller active window [μ_c, μ_0] for the new physics might be expected to require a *larger* initial λ_hΦ(m_t) to achieve the same stabilizing effect on the Higgs potential at μ_0. This crucial step in the paper's line of reasoning for the f_a bound is not clearly justified, potentially undermining the logical soundness of how the bound is established."
      },
      {
        "Problem": "Oversimplification in the effective potential calculation for stability analysis.",
        "Location": "Page 2, Eq. (7) and surrounding text",
        "Explanation": "The Higgs effective potential is approximated as V(h) = λ_h(μ)h^4/4 with the renormalization scale μ set equal to the Higgs field value h. While choosing μ=h is a common technique to resum leading logarithms, determining absolute vacuum stability by solely checking if λ_h(h) > 0 can be an oversimplification, especially when new scalar fields (like the PQ scalar Φ) and their interactions are introduced near the instability scale. A more rigorous analysis would typically involve the full multi-field effective potential V_eff(h, ϕ) or a more sophisticated scale-setting procedure. The precise stability boundary, and consequently the derived f_a limit, could be sensitive to this approximation, potentially affecting the accuracy of the conclusions."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 13965,
      "output": 690
    }
  },
  {
    "entry_id": 105,
    "retraction_id": "1704.03487v2",
    "paper_id": "1704.03487v1",
    "retraction_comment": "Due to the limitations of the interatomic potential used, it was not possible to ensure the accuracy of some of the results in the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear physical basis and potential artifactual nature of void formation during successive shearing.",
        "Location": "Page 14 (Fig. 8), Page 22 (Conclusions)",
        "Explanation": "The paper reports void formation at the matrix/precipitate interface during successive shearing (Fig. 8), attributed to 'differences in the plastic shearing of the matrix and the precipitate.' The physical justification for this voiding mechanism at the nanoscale is not thoroughly provided, raising concerns that it might be an artifact of the simulation methodology (e.g., interatomic potential limitations under large localized strain, boundary conditions, or lack of mechanisms for mass redistribution). If artifactual, this void formation could unduly influence the observed interaction behavior and the conclusions regarding precipitate degradation and sustained shearing."
      },
      {
        "Problem": "Inconsistency between observed precipitate damage and claimed constant CRSS during successive shearing.",
        "Location": "Page 18 (Fig. 12), Page 14 (Fig. 8), Page 22 (Conclusions)",
        "Explanation": "The paper concludes that 'Successive shearing of the precipitates did not change the CRSS' (page 22, based on Fig. 12). However, it also reports significant microstructural damage, including the formation of multiple steps and voids at the matrix/precipitate interface after repeated shearing (Fig. 8). Such accumulated damage would intuitively be expected to alter the precipitate's resistance to subsequent dislocations, likely by weakening it or creating stress concentrations. The assertion of a constant CRSS appears inconsistent with these observations of progressive damage, and the data in Fig. 12 itself shows scatter that might not unequivocally support this claim for all conditions."
      },
      {
        "Problem": "Lack of quantitative derivation of activation free energy (ΔF₀) for Mg-Al shearing.",
        "Location": "Section 4.3 (Pages 20-22), Fig. 13",
        "Explanation": "A central argument is that the activation free energy (ΔF) for shearing β-Mg17Al12 precipitates is 'very low,' explaining why shearing is dominant at finite temperatures. While MD simulations (Fig. 13) show shearing occurs at lower stresses at higher temperatures, the paper does not present a quantitative value for the zero-stress activation barrier (ΔF₀) for the Mg-Al system, derived from their own simulation data using the provided Equations 2 and 4. It only gives ΔF₀ for Al-Cu from a reference. Without a calculated ΔF₀ for Mg-Al, the claim that it is 'very small' remains qualitative, and the rigor of the comparison to Al-Cu and the subsequent conclusions about the dominant role of thermal activation are weakened."
      },
      {
        "Problem": "Insufficient explanation for the absence of Orowan looping at 0K when CRSS for cutting exceeds Orowan stress.",
        "Location": "Abstract, Page 16, Page 22 (Conclusions)",
        "Explanation": "The paper states that at 0K, the Critical Resolved Shear Stress (CRSS) to cut precipitates is often larger than the theoretical Orowan stress, yet Orowan loops were 'never observed.' In athermal conditions, if the stress to cut an obstacle is higher than the stress to bypass it via Orowan looping, looping should be the energetically preferred mechanism. The paper does not adequately explain why Orowan looping is completely suppressed in their 0K (molecular statics) simulations under these conditions. This could be due to simulation constraints (e.g., simulation cell size, method of applying strain/stress that forces shearing, or insufficient simulation time/degrees of freedom to allow loop formation) which are not fully discussed in this context. This unexplained absence at 0K is critical, as it forms the baseline for their argument about the role of thermal activation at finite temperatures."
      }
    ],
    "token_usage": {
      "input": 7348,
      "thinking": 6118,
      "output": 844
    }
  },
  {
    "entry_id": 106,
    "retraction_id": "2402.04633v2",
    "paper_id": "2402.04633v1",
    "retraction_comment": "An auxiliary result (Theorem 2.4) turns out to be wrong. This invalidates the proof of the main result",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation for the non-Riemannian nature of the example foliation.",
        "Location": "Page 20, Section 3.1, derivation of equation (37) and subsequent argument.",
        "Explanation": "In Example 3.1, the paper claims the foliation F is not Riemannian. The derivation of equation (37), specifically the step 'Since L_∂t gT vanishes by assumption (35), we obtain the identity fij(A(θ),t)λi⁻¹λj⁻¹ = fij(θ,t+1)λi⁻¹λj⁻¹', is not clear and seems incorrect. The operator L_∂t acting on the given form of gT would typically lead to a condition involving logarithms of eigenvalues if fij are independent of t, or ∂t fij = 0. The subsequent implication 'This equality implies that λiλj fij(A(θ),t) = fij(θ,t)' also does not transparently follow. While the conclusion that this specific foliation is non-Riemannian is likely correct (and can be shown by a simpler argument, e.g., by considering the constancy of g(Yk, Yl) for basic Yk and invariance under holonomy A), the derivation presented in the paper is problematic. This affects the self-contained logical soundness of this particular claim within the paper."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 15867,
      "output": 306
    }
  },
  {
    "entry_id": 107,
    "retraction_id": "2408.08124v4",
    "paper_id": "2408.08124v3",
    "retraction_comment": "Achieving reliable simulation of closed new domain formation processes using a single phase-field method is unconvincing and requires the use of multiple algorithms for parallel comparison with experiments",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of cutoff frequency (ft)",
        "Location": "Page 3, left column, near end of Section III; Equation (3)",
        "Explanation": "The claimed cutoff frequency of 0.228 THz is inconsistent with the provided transconductance (gm = 2.75 µS) and input capacitance (Cin = 12.10 aF). Using the formula ft = gm / (2π * Cin) from Equation (3), the calculated frequency is approximately 36.17 GHz. This is significantly lower than claimed (by a factor of ~6.3) and not generally considered 'sub-terahertz level' in this context, undermining a primary performance claim of the paper."
      },
      {
        "Problem": "Incorrect Fowler-Nordheim equation parameters (AFN and BFN)",
        "Location": "Page 1, Section I, Equations (2.1)-(2.3)",
        "Explanation": "The Fowler-Nordheim equations (2.1-2.3) for current density JFN use parameters AFN and BFN. The provided `AFN = 1.54 × 10^-6 × φ` (Eq. 2.2) and `BFN = 8.83 × 10^7 × φ^(3/2)` (Eq. 2.3) are incorrect. Standard AFN is proportional to `1/φ` (e.g., `1.54 × 10^-6 / φ  A eV / V^2`), not `φ`. The numerical prefactor in BFN (`8.83 × 10^7`) also differs from the commonly accepted value of `6.83 × 10^7` (for electric field E in V/cm). These inaccuracies in fundamental field emission equations would lead to erroneous simulated emission currents and derived device parameters like transconductance (gm), impacting the overall quantitative validity of the simulations."
      },
      {
        "Problem": "Unsupported claim of 'spontaneous stopping' of sacrificial etch process",
        "Location": "Page 2, Section II, paragraph 2",
        "Explanation": "The paper claims that the sacrificial etching process, critical for forming the vacuum cavity, 'can be stopped spontaneously due to the chemical difference between the cathode material (Lanthanum Hexaboride) and the sacrificial layer medium.' However, the sacrificial material and etchant are not specified, and no data or references are provided to substantiate this claim of highly selective, spontaneous etch stop on LaB6. This is a critical assumption for the proposed fabrication process, and its lack of support raises concerns about feasibility."
      },
      {
        "Problem": "Contradictory statements regarding the necessity of an additional lithography step",
        "Location": "Page 2, Section III, paragraphs 2 and 4; Fig. 2",
        "Explanation": "The paper presents conflicting information regarding an additional lithography step for self-packaging. Initially (paragraph 2), it states that 'an additional step of lithography was additionally considered to obtain tilt-coating steps on reliable self-packaged microcavity formation.' However, later (paragraph 4), it claims this step (illustrated in Fig. 2b vs 2c) 'is nonessential'. This contradiction creates ambiguity about the actual fabrication process and the requirements for achieving reliable self-packaged microcavities. The figures do not sufficiently clarify why this step would be nonessential for reliable cavity sealing."
      },
      {
        "Problem": "Lack of demonstration for claimed stability improvement",
        "Location": "Abstract; Section III (Results and Discussion)",
        "Explanation": "The abstract claims that the self-packaged microcavity improves 'the frequency performance and stability of the device.' While frequency performance (cutoff frequency) is addressed (albeit with calculation errors), there is no specific data, simulation, or discussion presented in Section III (Process and Performance Simulation) to substantiate the claim of improved 'stability.' Stability could refer to reduced noise, less current fluctuation, or robustness to environmental changes, none of which are quantitatively demonstrated for the proposed device."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 6076,
      "output": 901
    }
  },
  {
    "entry_id": 108,
    "retraction_id": "1901.08297v2",
    "paper_id": "1901.08297v1",
    "retraction_comment": "The significance and novelty of the paper were not addressed. There are a couple of errors about calculations: the excitonic decay rates were computed by solving Eq (11), not based on Eq. (13) that was only an initial guess for the decay rate",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified exclusion of states with large vibronic coupling in non-radiative rate calculations.",
        "Location": "Page 10, second paragraph, particularly the statement: \"This means the problematic states are always excluded automatically and shall not change significantly the data analysis.\"",
        "Explanation": "The paper states that electronic states with large vibronic coupling terms |<Φ<sub>i</sub>|∂/∂Q<sub>k</sub>|Φ<sub>j</sub>>| (where the adiabatic approximation is likely to fail) lead to \"artificially large nonradiative relaxation rate W<sub>i->j</sub>\" and are subsequently \"neglected in the MEG analysis, since only small W<sub>i->j</sub> are counted.\" This approach is unsound. If the model predicts large rates due to its own limitations (e.g., breakdown of the adiabatic approximation), selectively ignoring these rates rather than employing a more suitable model or rigorously justifying their exclusion can lead to a significant underestimation of non-radiative relaxation. This could, in turn, result in an overestimation of MEG efficiency and potentially invalidate conclusions drawn from the comparison between inelastic scattering and non-radiative relaxation rates."
      },
      {
        "Problem": "Limited validation of the approximation for excitonic inelastic scattering rates.",
        "Location": "Page 6, Eq. (13) and the justification paragraph below Figure 1.",
        "Explanation": "The calculation of excitonic inelastic scattering rates (Γ<sup>e-e</sup>) relies on an approximation (Eq. 13) that simplifies the dynamic Bethe-Salpeter equation by considering only the first two Feynman diagrams (diagonal elements in Eq. 11, which is misreferenced as Eq. 14 in Fig. 1 caption) and using GW electronic rates. The primary justification is \"good agreement\" with full DBSE results for a Si20 cluster from a previous study (Ref. 14). Extrapolating this agreement from a single, potentially smaller, cluster (Si20) to the Si26 and Si46 clusters studied in this work, across a broad range of high excitation energies crucial for MEG, may not be sufficiently robust without further validation. The accuracy of this approximation is critical for all conclusions regarding excitonic MEG performance, its comparison with electronic MEG, and the derived \"relative phonon bottleneck\" concept."
      },
      {
        "Problem": "Assumption of temperature-independent inelastic scattering rates for both electrons and excitons.",
        "Location": "Page 16, first paragraph (for electronic rates γ<sup>e-e</sup>) and Page 20, first paragraph (implicitly for excitonic rates Γ<sup>e-e</sup>).",
        "Explanation": "The study assumes that both electronic (γ<sup>e-e</sup>) and excitonic (Γ<sup>e-e</sup>) inelastic scattering rates are temperature-independent when evaluating MEG performance at 300 K. All temperature effects are attributed solely to the non-radiative relaxation pathways. However, inelastic electron-electron and exciton-electron scattering processes can exhibit temperature dependence due to factors such as changes in carrier distribution functions (e.g., Fermi-Dirac for electrons involved in scattering or forming excitons) and temperature-dependent screening effects. Neglecting this potential temperature dependence for inelastic rates can lead to an inaccurate assessment of the overall temperature impact on MEG efficiency and the relative importance of competing decay channels at finite temperatures, thereby affecting the conclusions about MEG performance deterioration."
      },
      {
        "Problem": "Potential inaccuracies introduced by the Displaced Potential Surface (DPS) approximation and harmonic approximation in non-radiative rate calculations.",
        "Location": "Page 8, Eq. (23) (harmonic approximation); Page 9, Eq. (28)-(34) and surrounding text describing the DPS approximation.",
        "Explanation": "The calculation of non-radiative relaxation rates (W<sub>i->j</sub>) employs the harmonic approximation (Eq. 23) for potential energy surfaces and the Displaced Potential Surface (DPS) approximation (Eq. 28-34). The DPS model assumes that vibrational frequencies and normal mode characters are identical for the initial and final electronic/excitonic states, neglecting Duschinsky rotation (mode mixing) and changes in vibrational frequencies upon excitation. Anharmonic effects are also neglected. While these are common approximations, their use can lead to inaccuracies in the computed non-radiative rates, especially for systems with significant structural relaxation or changes in vibrational landscape upon excitation. The paper acknowledges the adiabatic approximation as \"crude\" (Page 10), and these additional simplifications further impact the quantitative accuracy of non-radiative rates, which are critical for assessing MEG efficiency by comparison with inelastic scattering rates."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 4705,
      "output": 993
    }
  },
  {
    "entry_id": 109,
    "retraction_id": "1705.01127v2",
    "paper_id": "1705.01127v1",
    "retraction_comment": "Paper has been withdrawn since we find that dust effects have an unignorable impact on our analyses. A part of analyses are reported by arXiv:1809.03715",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Dominance of Measurement Uncertainty in Hα/UV Scatter",
        "Location": "Page 2, Section 2 (uncertainties); Page 3, Section 3 (interpretation of Hα/UV dispersion); Figure 1",
        "Explanation": "The paper reports typical uncertainties for individual log(SFR_Hα,corr) as 0.06 dex and for log(SFR_UV+IR) as 0.3 dex. Propagating these errors, the expected uncertainty in log(Hα/UV) = log(SFR_Hα,corr / SFR_UV+IR) would be sqrt(0.06^2 + 0.3^2) ≈ 0.306 dex. However, the observed dispersion of log(Hα/UV) is reported as 0.28 dex (Figure 1). If the propagated measurement uncertainty is comparable to or exceeds the observed dispersion, the paper's claim (Page 3) that 'the dispersion in the Ha/UV ratio (0.28 dex; Fig. 1) is not only caused by measurement uncertainty but also intrinsic variation in the Ha flux' is unsound. This would mean that most, if not all, of the observed Hα/UV scatter is attributable to measurement noise (primarily from SFR_UV+IR), undermining the basis for using this ratio to robustly trace intrinsic SFH variations as the signal would be overwhelmed by noise."
      },
      {
        "Problem": "Severe Sample Completeness and Selection Bias",
        "Location": "Page 2, Section 2 (Data, Figure 1); Abstract; Page 4, Section 4.4",
        "Explanation": "The study's sample is derived from cross-matching with AKARI FIS, resulting in a drastic reduction from 78,731 SDSS-GALEX galaxies to 1,200 (finally 1,050). Figure 1 indicates extremely low completeness, e.g., 2.6% for SFR_Hα,corr > 1 Msun/yr and 24% for SFR_Hα,corr > 10 Msun/yr over the full redshift range. This strong bias towards IR-bright galaxies means the sample is not representative of the general star-forming population. While acknowledged, the severity of this bias calls into question the generalizability of the quantitative conclusions, such as SFH variability contributing 0.04 dex to the main sequence scatter. The actual impact on a complete sample could be substantially different."
      },
      {
        "Problem": "Robustness of the 0.04 dex Contribution of SFH to MS Scatter",
        "Location": "Page 4, Section 4.1; Abstract",
        "Explanation": "The paper concludes that SFH variability accounts for 0.04 dex of the main sequence (MS) scatter. This value is derived by attempting to remove the trend between ΔMS and Hα/UV. However, if the Hα/UV ratio's observed scatter is dominated by measurement uncertainties (as suggested by Problem 1), then the correlation between ΔMS and Hα/UV may be largely driven by noise or systematic effects in Hα/UV. Correcting the MS scatter based on such a noise-dominated variable is unlikely to yield a robust or meaningful quantification of the true physical contribution from SFH variability. The paper itself notes that this 0.04 dex decrement 'is thought to be dependent on the measurement accuracy of the Ha/UV ratio', which, if poor, makes this key quantitative conclusion unreliable."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 8548,
      "output": 778
    }
  },
  {
    "entry_id": 110,
    "retraction_id": "2105.03304v2",
    "paper_id": "2105.03304v1",
    "retraction_comment": "Eq (2.4) is not correct and as such this invalidates Theorem 2.3 and consequently all the claimed results on the modulus of the zeros of chromatic polynomial. As fas as we can tell the results for the edge based block polynomials are correct (this concerns Sections 4 and 5). We will probably resubmit this part as part of a new paper at some point in the future",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Theorem 2.3, a central result for establishing zero-free regions, appears to be flawed.",
        "Location": "Page 6, Proof of Theorem 2.3, from 'From the induction hypothesis part (2)...' to '... = 1/a > 0'",
        "Explanation": "The proof relies on relating a sum derived from an inductive expansion to the condition (2.2). Specifically, the ratio B(G|U U P; w) / B(G|U U {v}; w) is bounded by a^t. The paper states t = |P_vert|-1 where P_vert = {v_0, ..., v_t} is a sequence of vertices associated with the block path P. The bound used in the paper is a^{|P_vert|-2}, which seems to be an initial error (should be a^{|P_vert|-1}=a^t). More critically, to satisfy the theorem's conditions, the proof then implicitly requires an equality of the form t = sum_{B in B(P)} (|V(B)|-1) - 1 (to match the a^{-1} * product form). If P_vert is interpreted as the sequence of cut-vertices defining the block path P (so |P_vert| = m_P+1, where m_P is the number of blocks in P, thus t=m_P), this equality becomes m_P = sum_{B in B(P)} (|V(B)|-1) - 1. This equality does not hold for general block paths. For instance, if P is a single block B (m_P=1), the condition becomes 1 = |V(B)|-1-1, implying |V(B)|=3. If all blocks in P are K2s (edges, so |V(B)|=2), the condition becomes m_P = sum(2-1)-1 = m_P-1, which is 0=-1, also false. The argument seems to only hold under very restrictive conditions on the structure of the block paths (e.g. if all blocks are K2s, then m_P = sum(2-1)-1 = m_P-1, which is still false. If the exponent used was a^{m_P-1} as in similar literature, it would require m_P-1 = sum(|V(B)|-1)-1, so m_P = sum(|V(B)|-1). This holds if all blocks are K2s. However, the theorem is stated for general block paths.) This discrepancy invalidates a key step in the proof of Theorem 2.3."
      },
      {
        "Problem": "The main results for Fisher zeros (Theorem 1.3) rely on Theorem 4.2, which is stated to have a proof analogous to Theorem 2.3 and would thus inherit its flaws.",
        "Location": "Page 13, statement regarding proof of Theorem 4.2: 'Our proof of Theorem 4.2 now goes exactly along the same lines as the proof of Theorem 2.3. We therefore omit it.'",
        "Explanation": "Theorem 4.2 is an edge-based analogue of Theorem 2.3 and is crucial for the results on Fisher zeros of the Ising model (Theorem 1.3). Since its proof is claimed to follow the same lines as that of Theorem 2.3, it would suffer from the same problem identified in Problem 1 (i.e., the step relating the inductively derived bound to the condition (4.2) via an exponent equality that does not hold generally). This would render Theorem 4.2, and consequently Theorem 1.3, unsound."
      },
      {
        "Problem": "Mismatch between the condition required by Theorem 2.3 and the condition stated and used for chromatic polynomials in equation (3.3).",
        "Location": "Page 7, equation (3.3) and surrounding text.",
        "Explanation": "Theorem 2.3 requires the condition sum_S (prod_B |w(B)|a^{|B|-1}) <= a-1. For XG(z), w(B) involves (1/z)^{|B|-1}. This leads to needing bv,U;G(a/|z|) <= a-1, where bv,U;G(q) is defined for q>0 (as in Corollary 3.3, page 8). However, equation (3.3) on page 7 defines bv,U;G(a/z) with potentially complex (a/z) terms and states the condition as |bv,U;G(a/z)| <= a-1 (i.e., modulus of the whole sum). These two conditions (|sum Z_i| vs sum |Z_i|) are not equivalent. While later proofs (e.g., Lemma 3.8) correctly work with bv,U;G(q) for positive q (effectively using bv,U;G(a/|z|)), the initial statement in (3.3) is formally incorrect or at least misleading about how Theorem 2.3 is applied."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 22835,
      "output": 1145
    }
  },
  {
    "entry_id": 111,
    "retraction_id": "1608.03378v2",
    "paper_id": "1608.03378v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in equation 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory outcome from the composite model application.",
        "Location": "Page 5, derivation of beta and discussion of Eq. (10).",
        "Explanation": "The composite cube model is used to explain the lower metallic phase carrier concentration. The derived value of beta=1/4, combined with the stated mu1/mu2=200 and measured n*/n1=0.01 in Eq. (10), implies an intergrain-to-grain resistivity ratio (rho2/rho1) of approximately 0.79. This means the intergrain region is *less* resistive than the metallic grain, which contradicts the model's fundamental assumption that the intergrain region is 'highly resistive' or 'untransitional' (i.e., semiconducting and thus more resistive). This invalidates the quantitative conclusion about the untransitional phase size."
      },
      {
        "Problem": "Neglect of high film roughness effects.",
        "Location": "Table I (page 2) and throughout the transport data interpretation (Pages 3-5).",
        "Explanation": "The XRR data in Table I indicates a VO2 film roughness of 55 Å for a 422 Å thick film, corresponding to over 13% of the film thickness. Such high roughness in an 'ultra-thin' film can lead to non-uniform current distribution, increased surface/interface scattering, and questions the applicability of idealized models (like the composite cube model or even standard Hall analysis assuming uniform films). The paper does not acknowledge or discuss these potential impacts, which could significantly affect the accuracy and validity of the extracted transport parameters and subsequent conclusions."
      },
      {
        "Problem": "Unclear justification for the crucial mobility ratio mu1/mu2.",
        "Location": "Page 5, paragraph 1, and reference to Figure 6.",
        "Explanation": "The calculation of beta=1/4 relies on a grain-to-intergrain mobility ratio (mu1/mu2) of approximately 200, which the paper claims is 'shown in figure 6'. However, Figure 6 does not directly provide the intergrain mobility (mu2), nor does it explicitly show how this ratio is obtained for the grain vs. intergrain material. The origin of this specific ratio is not transparently justified from the presented data, yet it is a critical parameter in the model. If this ratio is an assumed or fitted parameter without clear basis, it undermines the reliability of the derived beta value and the conclusion about the untransitional phase."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 11697,
      "output": 563
    }
  },
  {
    "entry_id": 112,
    "retraction_id": "1709.00434v2",
    "paper_id": "1709.00434v1",
    "retraction_comment": "Some of the content, including the assumption of vanishing vector potential at the interface and the application of the formalism to the gapped Dirac materials, are wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Sign error in the expression for the 2D charge density ρ_2D^±(y)",
        "Location": "Eq (35), page 5",
        "Explanation": "The term involving (σ_{x,y}+σ_{y,x}) in Eq (35) is written as `±iq (σ_{x,y}+σ_{y,x}) d/dy`. A careful derivation from Eqs (30-32) suggests this term should be `∓iq (σ_{x,y}+σ_{y,x}) d/dy`. This sign error propagates to the coefficient of the first derivative term in the crucial differential equation Eq (50), thereby affecting the definitions or usage of the auxiliary functions χ^± and χ̄^±, and consequently invalidating the final dispersion relation."
      },
      {
        "Problem": "Inconsistent definitions or usage of auxiliary functions χ^±, χ̄^±, η^±, η̄^± in the primary ordinary differential equation",
        "Location": "Eq (50) and definitions (51-54), page 6",
        "Explanation": "When substituting the expression for ρ_2D^±(y) (from Eq 35) into Eq (48) to derive Eq (50), the resulting coefficients for the terms d²Φ/dy², dΦ/dy, and Φ in Eq (50) do not consistently match the definitions of η^±, η̄^±, χ^±, χ̄^± provided in Eqs (51-54). For instance, the coefficient of dΦ/dy in Eq (50) is q[χ^± + χ̄^±]. However, deriving this from Eq (48) and (35) (even considering the sign error mentioned in Problem 1) and using definitions (53-54) leads to a mismatch in factors of 'q' (e.g., q²(...) instead of q(...)). Similar inconsistencies appear for other terms, such as the one involving η̄^±. These mismatches render the characteristic equation (57) and the subsequent dispersion relations unreliable."
      },
      {
        "Problem": "Problematic definition of edge charge density ρ_ED^±(y) and its impact on boundary conditions at y=0",
        "Location": "Eq (34), page 5; Eq (58), (59), page 7",
        "Explanation": "The edge charge density ρ_ED^±(y) in Eq (34) is defined using the term (dΦ^±/dy)|_{y=0}. The derivative dΦ^±/dy is expected to be discontinuous at y=0, a discontinuity that arises precisely from this edge charge. Including this derivative (even as an average, as in Eq 58) in the definition of the source term itself is self-referential. This approach makes the derivation of the jump condition for dΦ^±/dy (Eq 59) conceptually unsound, as the source of the discontinuity depends on the value of the discontinuous function/derivative at the point of discontinuity. This can lead to ill-defined mathematical problems or incorrect boundary conditions, thereby affecting the entire solution."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 18863,
      "output": 712
    }
  },
  {
    "entry_id": 113,
    "retraction_id": "1610.01669v7",
    "paper_id": "1610.01669v6",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error on linear implication between games",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Definition of Predicative Games and their initial protocol.",
        "Location": "Definition 3.4.1, Page 30",
        "Explanation": "The definition of moves `M_G` for a predicative game appears to use `M_σ` (moves of a strategy σ) in a self-referential or ill-phrased way within the sum `Σ_{σ ∈ st(G)} M_σ`. More critically, the paper acknowledges that the initial moves `q_G, (σ)` of a predicative game are not standard game moves (lacking labels/justifiers) and that predicative games are 'not strictly games'. This informality regarding foundational components could undermine the rigorous definition of legal positions, strategies, and subsequent game constructions (like composition) for predicative games, which are central to the entire semantic model."
      },
      {
        "Problem": "Internal contradiction regarding Uniqueness of Identity Proofs (UIP).",
        "Location": "Abstract (page 1), Definition 4.4.1 (page 40), Section 4.6.3 (page 48), Section 6.3 (page 64)",
        "Explanation": "The abstract states that a 'fine-grained interpretation of Id-types (that, e.g., refutes uniqueness of identity proofs...) is left as future work.' However, the Id-type semantics actually presented (Def 4.4.1, 4.6.3) leads to the validation of UIP, as explicitly argued in Section 6.3: 'It is now clear that there is a strategy on the game Π([Γ], [Π_{a1,a2:A} Π_{p,q:a1=a2} p=q]) in EPG'. This is a direct contradiction concerning a key property of Id-types, making the paper's stance and contribution regarding Id-types unclear and inconsistent."
      },
      {
        "Problem": "Potentially problematic definition of substitution `A{φ}` in the CwF WPG.",
        "Location": "Page 42, definition of `A{φ}` for the CwF WPG.",
        "Explanation": "The substitution `A{φ}` is defined as `{A(φ•δ) | δ:Δ}`. Here, `A ∈ Ty(Γ) = DG(Γ)` is a family of games `(A_γ)_{γ:!Γ}` indexed by strategies on `!Γ`. The morphism `φ: !Δ → Γ`. The notation `δ:Δ` is problematic: if `Δ` is a game (an object in WPG), `δ:Δ` is not standard for an indexing strategy. `A{φ}` should be a dependent game over `Δ`, i.e., a family `( (A{φ})_σ )_{σ:!Δ}`. A likely interpretation is `(A{φ})_σ = A_{φ•σ}`. The paper's notation `A(φ•δ)` with `δ:Δ` is unclear and could indicate a type mismatch or a conceptual issue in how substitution for dependent games is defined, which is critical for the CwF structure."
      },
      {
        "Problem": "Preservation of uniformity in the composition of products of Point-wise Linear Implications (PLIs).",
        "Location": "Definition 3.7.1 (page 34), Definition 3.7.2 (page 35), Theorem 3.7.3 (page 35)",
        "Explanation": "The construction of linear implication `G1 → G2` between predicative games involves `∫ PLI(G1, G2)`, where PLIs are families of strategies `(&_{σ:A} φ_σ)` that must be 'uniform' (Def 3.7.1). The composition of such strategies (and thus morphisms in WPG) is defined in Def 3.7.2. Theorem 3.7.3 claims that 'uniformity of strategies on linear implication is clearly preserved under composition.' However, this preservation is crucial for the well-definedness of the category WPG but is stated without proof or detailed argument. Given that uniformity is a global property of the family of strategies and composition is defined pointwise, this preservation is not self-evident."
      },
      {
        "Problem": "The nature of surjectivity claimed for the EPG interpretation weakens syntax-independence.",
        "Location": "Section 5 (page 56), Corollary 5.2.1 (page 57), footnote 5 (page 4), footnote 31 (page 60)",
        "Explanation": "The paper claims the interpretation in the sub-CwF EPG is surjective (Corollary 5.2.1). However, footnotes 5 and 31 acknowledge this surjectivity is 'merely by an inductive definition' and 'cheap' because EPG's construction (inductively defined elementary games/strategies) essentially mirrors MLTT's syntax. While not necessarily an error invalidating the model of MLTT, this approach means the semantic domain EPG is tailored to be the image of the syntax. This significantly qualifies the claim of providing a 'syntax-independent manner' (page 3) for this aspect of the semantics, as surjectivity is achieved by construction rather than by showing an independently defined rich semantic universe happens to be fully covered by the syntax."
      }
    ],
    "token_usage": {
      "input": 17668,
      "thinking": 7599,
      "output": 1190
    }
  },
  {
    "entry_id": 114,
    "retraction_id": "1605.05588v2",
    "paper_id": "1605.05588v1",
    "retraction_comment": "It had to be noted that the assumption was made that all sensors have access to all observations and state estimate vectors. In addition, the summations in the DAQKF Algorithm are on all sensors, not just the neighbouring sensors",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound State Representation and Dynamics Model for 3D Rotation Application",
        "Location": "Section IV, Page 4, description of state vector x_n and its evolution function.",
        "Explanation": "The paper defines the state for aircraft rotation tracking as x_n = [κ, dκ/dt]^T, where κ = ln(e^(iα)e^(jβ)e^(kγ)). A simple linear constant-velocity dynamic model (A = [[1, ΔT], [0, 1]]) is used for [κ, dκ/dt]^T. This state representation (logarithm of a quaternion) and its assumed linear dynamics do not accurately model general 3D rigid body rotations. For instance, constant angular velocity does not lead to a linear change in κ or dκ/dt. This fundamentally undermines the suitability of the proposed filter for the primary application of tracking aircraft rotations."
      },
      {
        "Problem": "Missing Definition of Observation Model for the Application",
        "Location": "Section IV, Page 4, description of application and simulations.",
        "Explanation": "The paper states that Euler angles (α, β, γ) are measured for the aircraft rotation tracking application. However, it fails to provide the crucial observation model that relates these measurements to the state x_n = [κ, dκ/dt]^T. Specifically, the observation matrix H_{m,n}^a and the method for forming the augmented observation vector y_{m,n}^a from Euler angles are not defined. Without this, the application of the filter is underspecified, and the simulation results cannot be verified or reproduced. Additionally, the claim that 'accelerometers are used to measure the three Euler angles' is generally incorrect for dynamic flight conditions."
      },
      {
        "Problem": "Inconsistent Derivation of the Fault Detection Statistic",
        "Location": "Page 4, Equation (7) and its preceding text; Algorithm 3 on Page 3.",
        "Explanation": "The fault detection statistic r_{l,m,n} is defined as Δx_{l,l,n}^a - Δx_{l,m,n}^a. According to Algorithm 3, Δx_{l,m,n}^a (the update at node l using data from node m) is calculated using node l's own prior estimate, x_{l,n|n-1}^a. However, the derivation of r_{l,m,n} in Equation (7) implicitly uses x_{m,n|n-1}^a (the prior from node m) in the term M_{l,n|n}P_{l,m,n}(x_n^a - x_{m,n|n-1}^a). This inconsistency between the algorithm's definition of the update term and its use in the derivation of the fault detection statistic makes the stated statistical properties of r_{l,m,n} and its covariance C_{r_{l,m}} unsound."
      },
      {
        "Problem": "Inconsistent Dimensionality/Type for State Variables and Process Noise in Application",
        "Location": "Section IV, Page 4, description of state vector and noise characteristics.",
        "Explanation": "In the application (Section IV), the state component κ = ln(q_rot) is a pure quaternion (zero real part), meaning its three imaginary components define it. Consequently, dκ/dt and the process noise v_n (representing d²κ/dt²) should also be pure quaternions. However, the paper describes the state evolution noise v_n as a 'zero-mean unit variance quaternion Gaussian variable with all its pseudo-covariances equal to 0.33,' implying v_n is a full 4-component quaternion. Adding full quaternion noise to a state whose components are defined as pure quaternions is inconsistent and would incorrectly cause these components to develop non-zero real parts, violating their physical interpretation."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 11835,
      "output": 862
    }
  },
  {
    "entry_id": 115,
    "retraction_id": "2112.14102v2",
    "paper_id": "2112.14102v1",
    "retraction_comment": "The paper was withdrawn due to a mistake in the proof of Theorem 15, in Section 4. The proposed translation is not equirealizable (the cases for disjunction and Release fail)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect reduction for the Release operator in SafetyLTL to GX0.",
        "Location": "Page 10, Proof of Theorem 15, case φ = φ2 R φ1",
        "Explanation": "The proof claims that if φ1 is equirealizable to a GX formula □χ1 and φ2 is equirealizable to a GX formula □χ2, then φ2 R φ1 is equirealizable to □χ1. This step is stated as: 'Then, φ2Rφ1 is realizable if and only if □χ2R□χ1 is realizable. By the semantics of R, every model that makes □χ1 true will also make □χ2R□χ1 true, and vice versa, so φ2Rφ1 is realizable if and only if □χ1 is realizable, which is a GX ⊆ GX0 formula, as desired.' This claim that (□χ2) R (□χ1) is equirealizable with □χ1 is incorrect for the standard LTL Release operator (defined on page 3 as φ2 R φ1 := ¬(¬φ2 U ¬φ1)). For example, let φ2 be a system proposition 'p' and φ1 be an environment proposition 'q'. Then p R q is realizable by the system setting p to true at the first step. However, □q (which would be the claimed equirealizable □χ1 form) is not realizable if the environment can set q to false. This incorrect reduction step for the Release operator invalidates the proof of membership in EXP for SafetyLTL realizability, and therefore the main claim that SafetyLTL realizability is EXP-complete."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 18590,
      "output": 376
    }
  },
  {
    "entry_id": 116,
    "retraction_id": "1606.07464v6",
    "paper_id": "1606.07464v5",
    "retraction_comment": "The arguments in the Sections 3.2 and 3.3 are not conclusive, and the Markov property is not disproved. Many other statements are though correct, see arXiv:2011.11476v4 (\"Revisiting the stochastic differential equations with multiplicative noise\")",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper's central claim that SDEs with multiplicative noise (specifically Stratonovich, alpha=1/2) are not Markovian is based on a flawed argument regarding the behavior of the propagator's maximum.",
        "Location": "Section 3.2, specifically page 7, the paragraph starting 'By (3.7) it follows that g(x,τ,x̂) must have its maximum at x̂...'",
        "Explanation": "The paper argues that for alpha=1/2, the maximum of the stationary distribution `w_stat` is at `x_hat` where `a(x_hat) = a_sp(x_hat)/2`. It then claims the propagator `g(x, tau, x_hat)` has its maximum at `x_hat - [a_sp(x_hat)/2]tau`. This shift would violate the Chapman-Kolmogorov equation. However, the calculation of the propagator's maximum appears incorrect. The drift term in the Fokker-Planck equation (2.12) is `a_eff = a + (alpha-1)a_sp`. For alpha=1/2, `a_eff = a - a_sp/2`. The maximum of `w_stat` occurs where `a_eff(x_hat) = 0`. The maximum of the short-time propagator `g(x, tau | x_0)` is at `x_0 + a_eff(x_0)tau`. Thus, for `x_0 = x_hat`, the maximum of `g(x, tau | x_hat)` is at `x_hat + a_eff(x_hat)tau = x_hat`. This means the propagator's maximum does not shift, and the condition for Markovian property, as stated by the author, is satisfied for alpha=1/2. This invalidates the disproof for the Stratonovich case and contradicts standard SDE theory."
      },
      {
        "Problem": "Inconsistent application of the Markovian criterion for the alpha=1 (anti-Itô) case.",
        "Location": "Page 7, Section 3.3, and Page 8, first paragraph.",
        "Explanation": "For `alpha=1`, the effective drift in the FPE (2.12) is `a_eff = a`. If a stationary state is peaked at `x_hat` where `a(x_hat)=0`, then `a_eff(x_hat)=0`. According to the paper's own criterion (no shift of the propagator's maximum from `x_hat`), this case should be Markovian. The paper states on page 7 (for `a=0, alpha=1`) that the propagator's maximum is indeed at `x_hat`. However, it then concludes the Markov property is 'only approximate' because the mean `<dX>` is non-zero. This switches the criterion from the propagator's maximum to its mean, which is inconsistent. If the no-shift-of-maximum criterion is key, then `alpha=1` (with `a(x_hat)=0`) should satisfy it, not just be 'approximate'."
      },
      {
        "Problem": "Misleading statements about state-dependent diffusion and the nature of noise-induced drift terms.",
        "Location": "Page 8, 'Comment' section.",
        "Explanation": "The paper claims that 'The Markov property is in fact abolished by the state-dependence of the diffusion.' This is a generally incorrect statement, as standard SDE theory (e.g., Itô or Stratonovich calculus) handles state-dependent diffusion with Markovian solutions. Furthermore, the argument that the noise-generated drift `a_NG` has a 'retarded impact' and is 'absent in the SDE' is confusing and does not align with the standard interpretation where such terms arise from the calculus rules and are part of the instantaneous description of the process evolution."
      },
      {
        "Problem": "Potential misinterpretation of condition (5.9) for the existence of a quiescent steady state.",
        "Location": "Page 11, paragraph starting 'It follows that w(x,t) never reaches...'",
        "Explanation": "The paper suggests that if condition (5.9) (`Div(D Grad phi) = 2 rho`) is not met, the density `w(x,t)` 'moves forever' and never reaches a globally steady state. Condition (5.9) relates to the constancy of the prefactor in the WKB approximation of a stationary distribution and is linked to detailed balance. If not met, non-zero probability currents can exist in a steady state (`w_t = 0`). The conclusion that `w(x,t)` 'moves forever' (implying `w_t != 0`) is too strong if it's meant to exclude any time-independent non-equilibrium steady state. It conflates the existence of currents with the absence of any steady state."
      },
      {
        "Problem": "The 'coarse-graining' argument for alpha=1 yielding an approximate Markov property is unsubstantiated and unconventional.",
        "Location": "Page 8, 'Comment' section and equation (3.8).",
        "Explanation": "The paper argues that on a 'coarse-grained time scale,' the `alpha=1` (anti-Itô) SDE, which has an Itô representation `dX = (a+a_sp)dt + b dW_I`, effectively behaves like `dX = a dt + b dW_I`. This implies the `a_sp` term vanishes under coarse-graining due to a 'retarded impact' of `a_NG`. This justification is hand-wavy and lacks rigorous support. Standard coarse-graining arguments often lead to the Stratonovich interpretation; the proposed transformation from anti-Itô to an Itô-like form by merely dropping a drift term is not conventional."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 16864,
      "output": 1313
    }
  },
  {
    "entry_id": 117,
    "retraction_id": "1806.07478v2",
    "paper_id": "1806.07478v1",
    "retraction_comment": "The results fail to capture the non-simultaneously diagonalizable case",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The primary theoretical justification (Theorem 9) for using scalar test equations z' = λz + μz, with λ being an eigenvalue of N and μ an eigenvalue of S for non-ST (Simultaneously Triangularizable) systems, appears flawed. The theorem's derivation supports using λ_eff = (P_S^{-1} N P_S)_{ii} (diagonal entries of N transformed by P_S, which triangularizes S) instead of eigenvalues of the original N. These λ_eff are equivalent to eigenvalues of N only if N and S are ST.",
        "Location": "Theorem 9 (page 10), and its interpretation in Abstract (page 1), Introduction (page 2, paragraph 2), and Conclusion (page 22, section 6).",
        "Explanation": "Theorem 9 approximates eigenvalues of R(hN, hS/δ) by those of R(hU_N, hU_S/δ). Here, U_S = P_S^{-1} S P_S is triangular (P_S triangularizes S), and U_N is the upper triangular part of P_S^{-1} N P_S. The eigenvalues of the approximating matrix R(hU_N, hU_S/δ) are given by scalar functions R(h(U_N)_{ii}, h(U_S)_{ii}/δ) because U_N and U_S are simultaneously upper triangular (both triangular in the basis defined by P_S). While (U_S)_{ii} are eigenvalues of S, the terms (U_N)_{ii} are the diagonal entries of P_S^{-1} N P_S. These are eigenvalues of N if and only if P_S also triangularizes N (i.e., N and S are ST). For the general non-ST case, (P_S^{-1} N P_S)_{ii} are not, in general, eigenvalues of N. This contradicts the paper's central claim that the scalar analysis uses eigenvalues of the original matrix N."
      },
      {
        "Problem": "The numerical claim in Example 6, which is critical for motivating the analysis of non-ST systems, appears to be incorrect. The example states that for specific parameters (h=2, α=β=γ=1), the stability matrix A(2;1,1,1) for IMEX Euler has an eigenvalue with modulus greater than 1, while scalar test equations predict stability. Re-calculation of eigenvalues for the matrix in Eq. (17) and for the standard IMEX Euler matrix (I-hS)^{-1}(I+hN) suggests stability (modulus < 1).",
        "Location": "Example 6, page 8, specifically the claim 'However, if β = γ = α = 1, then A(2;1,1,1) has an eigenvalue with modulus greater than 1.'",
        "Explanation": "Example 6 illustrates a non-ST system where N and S are individually triangular but not simultaneously triangularizable. It claims the IMEX Euler method is unstable for h=2 and specific parameters, contrary to predictions from scalar test equations. However, eigenvalue calculations for the matrix A(2;1,1,1) as defined in Eq. (17) ( [[-1/7, 2/7], [-2/21, -1/3]] ) yield eigenvalues with modulus approximately 0.27, indicating stability. A similar result is obtained if the standard IMEX Euler amplification matrix (I-hS)^{-1}(I+hN) is used. If this numerical claim of instability is false, a key example motivating the paper's advanced non-ST analysis is undermined."
      },
      {
        "Problem": "The application of Theorem 9 or Remark 11 to the linear shallow water model in the limit K → ∞ (where K is a spatial dimension parameter) lacks a clear mathematical derivation showing how this limit corresponds to the perturbation frameworks (δ → 0 or ε → 0) of the theorems.",
        "Location": "Section 5.2, pages 20-21, particularly the statement: 'Remark 11 and Theorem 9 together with the fact that N_{I,J} and S_{I,J} each have pure imaginary eigenvalues, imply that for fixed height L the hyperbolic-hyperbolic test equations (23) asymptotically approximate the eigenvalues of R(hN_{I,J}, hS_{I,J}) as K → ∞'.",
        "Explanation": "The paper asserts that for the linear shallow water model (a non-ST system), as the horizontal length K becomes very large, the system's stability can be approximated by scalar hyperbolic-hyperbolic test equations, citing Theorem 9 and Remark 11. However, a rigorous connection is not established. It is not explicitly shown how the K → ∞ limit transforms the system matrices N_{I,J} and S_{I,J} into a form where either S_{I,J} becomes 'infinitely stiff' relative to N_{I,J} (for Theorem 9 via S/δ, δ → 0) or N_{I,J} becomes 'negligibly small' (for Remark 11 via εN, ε → 0). Without this derivation, the applicability of the core theorems to this specific limiting case in the shallow water model is unsubstantiated."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 14737,
      "output": 1325
    }
  },
  {
    "entry_id": 118,
    "retraction_id": "2302.13052v2",
    "paper_id": "2302.13052v1",
    "retraction_comment": "There are some errors and inappropriate writings. Thm 4.16 and don't work well for additive invariants",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect argument in the proof of Theorem 6.9.",
        "Location": "Page 36, Proof of Theorem 6.9",
        "Explanation": "The proof states that K_cont^cn(X) is equivalent to tau_>=0 K_cont(X). This is generally false. K_cont^cn(X) is the continuous extension of connective K-theory, while tau_>=0 K_cont(X) is the connective cover of the continuous non-connective K-theory spectrum K_cont(X). These are not equivalent in general, for instance, if K_cont(X) has non-trivial negative homotopy groups."
      },
      {
        "Problem": "Logical circularity or ordering issue in the proof of Theorem 4.16.",
        "Location": "Page 27, Proof of Theorem 4.16",
        "Explanation": "The proof of Theorem 4.16 relies on the property (z_loc)_cont(C tensor D) is equivalent to (z_loc)_cont(C) tensor D. This property is essentially stating that (z_loc)_cont is a symmetric monoidal functor. However, this symmetric monoidal property of (z_loc)_cont is established later in the paper, in Corollary 5.17 (page 32). This creates a circular dependency if Theorem 4.16 is used before or in the derivation of Corollary 5.17, or implies the paper's results should be reordered."
      },
      {
        "Problem": "Unclear or potentially problematic hypothesis in Theorem 4.7 and Lemma 4.6.",
        "Location": "Page 24, Lemma 4.6 and Theorem 4.7",
        "Explanation": "Theorem 4.7 states its hypothesis for D as 'D in Pr_st^{dual,omega}'. Lemma 4.6 refers to 'C in Pr_st^{cg} is compact'. The notation Pr_st^{dual,omega} is not standard or defined in the notation list, and the meaning of a 'compact' object in Pr_st^{cg} is not clarified. If these conditions imply that D^omega (or C^omega) must be a compact object in Cat^perf (e.g., Sp^omega), then Theorem 4.7 is significantly restricted in scope. If D (or C) is merely any compactly generated dualizable stable oo-category, then its associated small category D^omega (or C^omega) is not necessarily compact in Cat^perf, and the proof steps relying on this (e.g., properties of z_add(D^omega)) may not be justified as written."
      },
      {
        "Problem": "Insufficient justification for Lemma 7.13.",
        "Location": "Page 42, Proof of Lemma 7.13",
        "Explanation": "Lemma 7.13 claims that if Delta is a Milnor square of dualizable presentable stable oo-categories, then the square Calk_kappa(Delta) (formed by applying Calk_kappa to each object in Delta) is also a Milnor square. The proof states that 'The three properties [defining a Milnor square] come from the restriction of the previous lemma' (Lemma 7.11, concerning Ind(Delta^kappa)). This justification is too brief and the deduction is not obvious. Establishing that Calk_kappa(Delta) satisfies all conditions of a Milnor square (precartesian, compactness and generation by the functors, and the exchange transformation equivalence) requires a more detailed argument, especially concerning how these properties descend from Ind(Delta^kappa) to Calk_kappa(Delta)."
      }
    ],
    "token_usage": {
      "input": 11734,
      "thinking": 13301,
      "output": 815
    }
  },
  {
    "entry_id": 119,
    "retraction_id": "1511.07171v2",
    "paper_id": "1511.07171v1",
    "retraction_comment": "Error in equation 9",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Omission of a critical convective term in the Boundary Integral Equation (BIE)",
        "Location": "Page 3, derivation of Eq (7) from Eq (4), and subsequent formulation Eq (9) on page 4.",
        "Explanation": "The paper's BIE formulation, as presented in Eq (7) and effectively used in Eq (9), simplifies to a form `c*p = ± ∫ (p dG/dnq - G dp/dnq) dΓq`, where `d/dnq = ∂/∂nq - M∞n (M∞⋅∇q)`. A consistent derivation from the convected Helmholtz equation (Eq 1) and its adjoint operator should yield an additional term, `∫ 4ikM∞n pG dΓq`, in the BIE. The omission of this term, which directly accounts for convection effects involving the normal Mach number `M∞n = M∞⋅n_q`, means that a significant part of the flow physics is not modeled. This would invalidate the method's conclusions for problems involving fluid flow (M∞ ≠ 0)."
      },
      {
        "Problem": "Potentially incorrect definition of the axisymmetric convected Green's function",
        "Location": "Page 2, Equation (2) for Gk and Equation (3) for R*β and r*",
        "Explanation": "The axisymmetric convected Green's function Gk0 is stated to be the integral of Gk given by Eq (2). The definition of Gk involves a convected radius R*β (Eq 3), which in turn depends on r* where `r*² = |mq|² + (mq⋅M*∞)²`. This formulation for the effective distance `r*` in a convected field is non-standard. Typically, Prandtl-Glauert transformations lead to distances scaled by `α = sqrt(1-M∞²)` along the flow direction (e.g., `x_transformed = x/α`). The provided `r*` does not appear to correspond to such standard transformed distances. An incorrect Green's function is a fundamental flaw that would invalidate the entire BEM formulation."
      },
      {
        "Problem": "Unjustified new radiation condition for the axisymmetric cylindrical duct",
        "Location": "Page 5, Equation (10) and its surrounding text.",
        "Explanation": "The paper proposes a new radiation condition for the outlet of the cylindrical duct (Γ+) as `σ_Γ+ = iα² K_z,n p` (Eq 10), where `α² = 1-M∞²` and `K_z,n` is the axial wavenumber. The introduction of the `α²` factor modifying the classical radiation condition is not derived or justified from the physics of wave propagation in a convected medium. Standard radiation conditions for ducts with flow are more complex and depend on the roots of the dispersion relation. An improperly formulated radiation condition will lead to incorrect solutions for the acoustic propagation in the duct."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 13961,
      "output": 662
    }
  },
  {
    "entry_id": 120,
    "retraction_id": "1106.1331v2",
    "paper_id": "1106.1331v1",
    "retraction_comment": "Withdrawn by the authors. Lemma 7.6 is false as stated, and Appendix B is flawed. Corrected and reorganized versions of the material will be posted in papers with different titles",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The assumption that Z is of 'algebraic type' in Theorem 7.1 significantly restricts the generality of the implication 'spherical type implies polar type'.",
        "Location": "Page 22, Assumption (7.2) and Theorem 7.1",
        "Explanation": "Theorem 7.1, which is used to establish that certain spherical spaces are of polar type (a key step for Theorem 8.5 and thus Theorem C/D), requires the homogeneous space Z to be of 'algebraic type'. This assumption is used in Appendix B to employ methods from algebraic geometry over complex numbers. If a 'strongly spherical' space (for which Theorem C is claimed) is not of algebraic type, Theorem 7.1 cannot be invoked to show it is polar. While examples provided might be algebraic, the general applicability of Theorem C hinges on this implication, and the restriction imposed by the 'algebraic type' assumption is not fully explored in terms of its impact on the main conclusions for a general strongly spherical space."
      },
      {
        "Problem": "The condition that the family of balls 'factorizes well' for main term counting in Theorem D and Theorem 10.1 is not rigorously established for all claimed cases.",
        "Location": "Page 5 (Theorem D), Page 32-33 (Section 9.3), Page 35 (Theorem 10.1)",
        "Explanation": "The main term lattice point counting results (Theorem D, Theorem 10.1) rely on the assumption that the relevant family of balls 'factorizes well' (defined in eq. 9.10). While Example 9.3 illustrates this for specific cases, and page 33 suggests it 'appears always to be satisfied' or holds if lim |U_{R+R_0}^F| / |U_R*| = 0, a general proof that this condition holds for all spaces and balls for which Theorems D and 10.1 are claimed (especially for the list in Section 1.5) is not provided. Lack of this verification makes the applicability of these theorems less certain for the full range of spaces discussed."
      },
      {
        "Problem": "The inductive step in the proof of Theorem 8.5 (Property I) assumes that factorizations of strongly spherical spaces are also strongly spherical, which is not proven.",
        "Location": "Page 29, Proof of Theorem 8.5",
        "Explanation": "The proof of Theorem 8.5 (that strongly spherical spaces have Property I) uses induction. If a representation's exponent Λ does not satisfy decay condition (6.4), it argues that Z → G/H_η is a factorization, and the assertion follows from the inductive hypothesis. The proof states: 'Note that any factorization Z* of Z will be strongly spherical, once Z is strongly spherical.' This crucial assertion, that the property of being 'strongly spherical' (Definition 7.7) is inherited by such factorizations Z* = G/H_η, is not justified. For the inductive step to be valid, Z* must satisfy the hypotheses of Theorem 8.5, i.e., Z* must itself be strongly spherical. Without this justification, the induction is incomplete."
      },
      {
        "Problem": "Potential misalignment between the maximal abelian subspace 'A' in the definition of 'strongly spherical' (Def 7.7) and the Cartan subspace 'A_0' used in establishing properties for Corollary 7.9.",
        "Location": "Definition 7.7 (Page 26), Corollary 7.9 (Page 26)",
        "Explanation": "Definition 7.7 ('strongly spherical') requires a specific maximal abelian subspace A ⊂ p for its conditions (1) G=KAH (polar), (2) P_j H open for minimal P_j ⊃ A, and (3) A = U A^+(P_j)(A∩H). Corollary 7.9 states that 'strongly unimodular spherical type implies strongly spherical'. Its proof (page 26) constructs a Cartan subspace A_0 (split part of a minimal parabolic P_0) and argues about conjugates. It is not clear if this A_0 (or its appropriate conjugate) can always serve as the *maximal abelian* A in p required by Def 7.7, simultaneously satisfying all three conditions, particularly condition (1) which refers to a polar decomposition with a maximal abelian A, and condition (3) which links this A to the positive Weyl chambers A^+(P_j) of minimal parabolics whose split parts must align with A."
      },
      {
        "Problem": "The direct application of Theorem 6.4 (Theorem B) decay rates, derived using an Iwasawa decomposition, to integrals over a polar decomposition in the proof of Theorem 8.5 needs clearer justification.",
        "Location": "Page 29 (Proof of Theorem 8.5), Page 20 (Theorem 6.4), Page 26 (Definition 7.7)",
        "Explanation": "Theorem 8.5 (Property I for strongly spherical spaces) uses the decay rate of matrix coefficients from Theorem 6.4. Theorem 6.4 provides this rate for 'a ∈ A^+', where A is from an Iwasawa decomposition G=KAN. However, the proof of Theorem 8.5 integrates over A_{polar}/(A_{polar}∩H), where A_{polar} is the maximal abelian subspace in p from the polar decomposition G=KAH (part of Def 7.7 for 'strongly spherical'). While these A's can be related (e.g., for symmetric spaces A_{Iwasawa} ⊂ A_{polar}), the direct use of decay rates established for an Iwasawa 'A' in an integral over a potentially different polar 'A' (and its subregions A^+(P_j)) requires careful justification to ensure the decay is sufficient in the correct integration domain for general strongly spherical spaces, not just symmetric ones (as discussed in Remark 6.5a)."
      }
    ],
    "token_usage": {
      "input": 17926,
      "thinking": 9396,
      "output": 1323
    }
  },
  {
    "entry_id": 121,
    "retraction_id": "2106.14209v3",
    "paper_id": "2106.14209v2",
    "retraction_comment": "The paper builds on the wrong statement in the paper \"The quantum twistor bundle\" Theorem 4.2. Therefore the C*-algebra investigated in the present paper is not the one for the quantum symplectic sphere",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of the simplified algebraic relations (2.1)-(2.3) for C*(S_q^{4n-1})",
        "Location": "Page 4, Remark 2.2 and equations (2.1)-(2.3)",
        "Explanation": "The paper claims that setting x_i = 0 for i=1,...,n-1 (based on [1]) in the defining relations of C*(S_q^{4n-1}) from Definition 2.1, and letting y_{n+1} = x_n, leads to the system of relations (2.1)-(2.3). However, direct substitution of x_i=0 (i<n) into Definition 2.1 yields different relations for the generators y_1, ..., y_n, y_{n+1}. For instance, the relation for y_i y_i^* (i<n) derived from Definition 2.1 becomes y_i y_i^* = y_i^* y_i + (1-q^2) [ (q^{2(n+1-i)} + 1) y_{n+1} y_{n+1}^* + sum_{k=i+1}^n y_k y_k^* ], which significantly differs from relation (2.2) y_i^* y_i = y_i y_i^* + (1-q^2) sum_{k=i+1}^{n+1} y_k y_k^*. Similarly, the sphere relation derived from Definition 2.1 is y_{n+1}y_{n+1}^* + sum_{i=1}^n y_i y_i^* = 1, which differs from (2.3) sum_{i=1}^{n+1} y_i^* y_i = 1. If this derivation is incorrect, the subsequent analysis and isomorphism proof apply to an algebra different from the C*-algebra of the quantum symplectic sphere C*(S_q^{4n-1}), invalidating the paper's main conclusion about C*(S_q^{4n-1})."
      },
      {
        "Problem": "The algebra defined by relations (2.1)-(2.3) is not the standard Vaksman-Soibelman quantum sphere C(S_q^{2(n+1)-1}) as defined in the paper.",
        "Location": "Page 4, relations (2.1)-(2.3) compared to Page 3, definition of C(S_q^{2n-1})",
        "Explanation": "The paper concludes that C*(S_q^{4n-1}) is isomorphic to the quantum (2(n+1)-1)-sphere by Vaksman and Soibelman. The definition for this Vaksman-Soibelman sphere (let's call its generators z_i) is provided on page 3, and includes relations z_i^* z_j = q z_j z_i^* (for i != j) and the sphere condition sum z_j z_j^* = 1. The algebra that is actually analyzed from Remark 2.2 onwards (let's call it A, with generators y_i) is defined by relations (2.1)-(2.3). These include y_i^* y_j = q^{-1} y_j y_i^* (for i != j, with some specific relations for y_{n+1}, y_n not directly fitting this pattern but also differing) and the sphere condition sum_{i=1}^{n+1} y_i^* y_i = 1. These differences (q vs q^{-1} in commutation relations, and sum y_i^*y_i = 1 vs sum z_j z_j^* = 1) mean that algebra A is not the Vaksman-Soibelman sphere C(S_q^{2(n+1)-1}) as defined on page 3. Therefore, even if C*(S_q^{4n-1}) were shown to be isomorphic to algebra A, the final identification with the specific Vaksman-Soibelman sphere cited would be incorrect."
      },
      {
        "Problem": "Flawed derivation of a key algebraic relation in the proof of Lemma 3.2.",
        "Location": "Page 6, Proof of Lemma 3.2",
        "Explanation": "The proof of Lemma 3.2, which determines the joint spectrum of π(y_i^*y_i), states that the relation y_1y_1^* = (1-q^2) + q^2 y_1^*y_1 'is obtained from (2.2) and (2.3)'. Relation (2.2) for i=1 is y_1^*y_1 = y_1y_1^* + (1-q^2) sum_{k=2}^{n+1} y_k y_k^*. Relation (2.3) is sum_{k=1}^{n+1} y_k^*y_k = 1, which implies sum_{k=2}^{n+1} y_k^*y_k = 1 - y_1^*y_1. To obtain the stated relation for y_1y_1^*, the sum term sum_{k=2}^{n+1} y_k y_k^* from (2.2) needs to be related to 1 - y_1^*y_1. However, y_k y_k^* is generally not equal to y_k^*y_k (indeed, (2.2) shows they differ). The direct substitution or manipulation to arrive at y_1y_1^* = (1-q^2) + q^2 y_1^*y_1 from (2.2) and (2.3) is not evident and appears unjustified. Since Lemma 3.2 and its Corollary 3.3 are used later (e.g., for the well-definedness of the inverse map φ^{-1} in Theorem 3.4), this flaw in derivation potentially undermines the subsequent spectral analysis and the overall proof of the main isomorphism for the algebra defined by (2.1)-(2.3)."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 16886,
      "output": 1373
    }
  },
  {
    "entry_id": 122,
    "retraction_id": "1608.08317v2",
    "paper_id": "1608.08317v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The physical nature and utility of σ-SCF states are questionable as they are not energy extrema.",
        "Location": "Page 5, Sec IV.A; Page 9, Concluding Remarks.",
        "Explanation": "The paper states that σ-SCF solutions are 'not stationary in energy' (p.5) and 'no Hellmann-Feynman theorem holds for the σ-SCF energy because σ-SCF states are not energy extrema' (p.9). This is a fundamental issue. If the states are not stationary points of the energy functional, their energies are not variationally optimized in the usual sense, making their interpretation as well-defined 'mean-field states' problematic. This also severely complicates the calculation of molecular properties like forces, limiting utility for geometry optimization or dynamics. The paper's suggestion to use these states as initial guesses for Δ-SCF (an energy-based method) underscores this limitation, potentially relegating σ-SCF to a sophisticated guess generator rather than a standalone method for final state description."
      },
      {
        "Problem": "High computational cost (N⁵ scaling) for a mean-field level description.",
        "Location": "Page 9, Concluding Remarks.",
        "Explanation": "The method is reported to scale as N⁵ with system size, primarily due to the evaluation of <Ĥ²>. This cost is significantly higher than typical mean-field methods (which scale as N³-N⁴) and is comparable to some lower-order correlated methods like MP2. Such high scaling for what is still a mean-field level description may render the method impractical for many systems of chemical interest, challenging the conclusion that it is an 'effective manner' (p.9) to locate excited states."
      },
      {
        "Problem": "Potential non-smoothness of σ-SCF Potential Energy Surfaces (PES).",
        "Location": "Page 8, Sec V, Eq (21); Page 9, Fig. 11 and discussion.",
        "Explanation": "The paper indicates that the derivative of the σ-SCF energy with respect to a nuclear coordinate X depends on <(Ĥ²)>_x (Eq. 21). Numerical results (Fig. 11) and discussion (p.9) suggest that the continuity of <(Ĥ²)>_x 'is not always guaranteed'. This implies that the σ-SCF PES may exhibit non-smooth behavior or cusps, particularly near Coulson-Fischer-like points. Such roughness is a critical issue for applications requiring smooth energy surfaces, such as molecular dynamics, geometry optimizations, or transition state searches, and was acknowledged as a 'roughness of the σ-SCF PES' (p.9)."
      },
      {
        "Problem": "Severe spin contamination in unrestricted singlet σ-SCF solutions.",
        "Location": "Page 6, Sec IV.A, Eq (18) and surrounding text.",
        "Explanation": "For the H₂ molecule, unrestricted σ-SCF (U-σ-SCF) solutions for nominal singlet states are reported to have approximately 50% triplet character (γT ≈ 0.5, implying <S²> ≈ 1). While the paper suggests these can be spin-adapted, this extreme level of spin contamination in the direct output of the method makes the resulting wavefunction physically questionable as a description of a singlet state. This may indicate significant limitations or problematic behavior of the U-σ-SCF approach for open-shell singlet systems or states with similar characteristics."
      },
      {
        "Problem": "Claim of zero error for Helium triplet states lacks sufficient justification.",
        "Location": "Page 7, Sec IV.C, Table I.",
        "Explanation": "Table I reports zero error for σ-SCF compared to FCI for Helium triplet states in the 6-311G basis. For a mean-field method to achieve exact agreement with FCI, the FCI wavefunction must effectively be a single Slater determinant in that basis, and the method must find it. This condition is not explicitly established or discussed for these specific excited triplet states. Without clear justification that these FCI solutions are indeed single determinants (which would make the problem trivial for a perfect variance minimizer that finds the global minimum of variance), this claim of 'zero error' could be misleading regarding the general accuracy of σ-SCF or might indicate an issue with the benchmark comparison or its interpretation."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 9039,
      "output": 944
    }
  },
  {
    "entry_id": 123,
    "retraction_id": "1805.10733v3",
    "paper_id": "1805.10733v2",
    "retraction_comment": "The result (eq. 3) is not correct; therefore, latter part which is derived from this result is not correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear and potentially problematic derivation of information speed (ds/dt) and cost rate from system entropy change (Δσ_sys).",
        "Location": "Page 2, Equations (6)-(8) and surrounding text.",
        "Explanation": "Equation (6) states `ds^2 = 2(Δσ_sys)`, where `Δσ_sys` is a KL divergence (Eq. 3). The subsequent derivation of `ds/dt` in Eq. (8) as `(1 / sqrt(2 Δσ_sys)) * d(Δσ_sys)/dt` implies a specific relationship, effectively `s(t) = sqrt(2 Δσ_sys(t))`, where `s(t)` is the statistical length and `Δσ_sys(t)` is the KL divergence from a reference. This direct identification is a strong assumption about the system's information geometry and is not rigorously justified. Standard information geometry relates `ds^2` to an infinitesimal change in system entropy (`2 dσ_sys`) or to `2 D_KL(p(θ)||p(θ+dθ))`. The paper's use of a finite `Δσ_sys` in these differential forms and its role in the denominator of Eq. (8) needs clarification and justification, as it is foundational to all subsequent calculations of cost and efficiency."
      },
      {
        "Problem": "Inconsistency in the definition and usage of the thermodynamic cost 'C'.",
        "Location": "Page 3, Equations (12), (13), surrounding text, and Figure 3 (top panel).",
        "Explanation": "The paper defines 'a rate of thermodynamic cost change C' as an integral `C = ∫(ds/dt')^2 dt'` (Eq. 12, if the upper limit is t), which represents a total accumulated cost. However, Figure 3 (top panel) plots 'C' as an instantaneous quantity that varies over time, suggesting `C(t) = (ds/dt)^2` is an instantaneous rate. Furthermore, the text describes `C` as 'a total loss rate', which is contradictory. This ambiguity in whether `C` represents an instantaneous rate or an integrated total cost can lead to misinterpretation of the results and the efficiency calculations (Eq. 16), which typically uses total cost."
      },
      {
        "Problem": "Assumption of linear Langevin equations and persistent Gaussianity for the E. coli model.",
        "Location": "Page 2, 'Numerical simulation' section; Page 5, 'Discussion' section.",
        "Explanation": "The analysis relies on the assumption that the underlying Langevin equations are linear, ensuring that an initial Gaussian distribution of system variables (CheA activity 'a' and MCP methylation level 'm') remains Gaussian over time. This allows the distribution to be fully characterized by its mean and covariance. However, established models of E. coli chemotaxis (e.g., Tu et al. 2008, cited as Ref [3]) are typically non-linear. If a linearization was performed, its justification, validity range, and impact on the conclusions' generality for the actual E. coli system are not adequately discussed. If the original non-linear model is used, the assumption of persistent Gaussianity may be violated, undermining the information geometric calculations."
      },
      {
        "Problem": "Significant quantitative inconsistency between plotted `ds^2/dt^2` and instantaneous cost rate `C(t)`.",
        "Location": "Figure 2 (bottom panel) and Figure 3 (top panel).",
        "Explanation": "The instantaneous rate of thermodynamic cost, `C(t)`, should be equal to `(ds/dt)^2` based on the framework (e.g., if `C` in Eq. 12 is the integrand). Figure 2 (bottom panel) plots `ds^2/dt^2`, and Figure 3 (top panel) plots `C` (interpreted as an instantaneous rate from its time evolution). These two plots should therefore be identical. However, their magnitudes are vastly different: `ds^2/dt^2` in Fig. 2 peaks around 1000, while `C(t)` in Fig. 3 peaks around 0.035. This major discrepancy suggests a fundamental error in the numerical calculations, parameter usage, or the definitions of these quantities, casting doubt on the quantitative results for cost and efficiency."
      },
      {
        "Problem": "Claims regarding noise effects on efficiency are not fully supported by presented data or are potentially misleading.",
        "Location": "Page 4, Results section (discussion of Fig. 4); Page 5, Discussion section.",
        "Explanation": "The text on page 4 claims that 'the efficiency at noise level T_a = 0.0005 is higher than [the] one at noise level T_a = 0.005.' However, Figure 4, intended to show noise effects, does not include data for T_a = 0.0005; it displays results for T_a = 0.005, 0.05, 0.5, and 5. This makes the specific claim unsubstantiated by the provided figures. Additionally, the paper links its findings to stochastic resonance, which implies an optimal non-zero noise level. The claim about T_a = 0.0005 vs. T_a = 0.005 (if true and smaller noise is better) and the general trend in Fig. 4 (efficiency decreasing with increasing noise) do not clearly support typical stochastic resonance. The discussion needs more robust evidence and clarity on the nature of the noise effect."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 8814,
      "output": 1245
    }
  },
  {
    "entry_id": 124,
    "retraction_id": "1912.00541v2",
    "paper_id": "1912.00541v1",
    "retraction_comment": "As several people have pointed out to me, the last sentence of Lemma 5.3 is not justified. This likely counts as a fatal flaw that invalidates the main theorem (Theorem 5.4). I would like to thank those who took the time to read the preprint and send me their feedback. I hereby retract the claimed result",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The injectivity of the constructed endomorphism $f_\\phi$ is not established.",
        "Location": "Page 11, Proof of Theorem 5.4, specifically around the assertion: \"It follows that there exists a self-map $\\phi : \\Delta_q \\to \\Delta_q$ which is not surjective yet which is a full model of an injective endomorphism of $k^G$.\"",
        "Explanation": "In the proof of Theorem 5.4, a map $\\phi: \\Delta_q \\to \\Delta_q$ (denoted $\\alpha_{\\text{new}}$ in the thought process, defined as $\\phi(y) = \\pi_{r,q}(x)$ for $x \\in \\psi^{-1}(y)$) is constructed. This $\\phi$ is an endomorphism of the finite graph $\\Delta_q$ and is shown to be not surjective if $f$ is not surjective. The proof then claims that this $\\phi$ is a 'full model of an injective endomorphism of $k^G$'. Let this endomorphism of $k^G$ be $f_\\phi$, where $f_\\phi(z)_g = \\phi((g^{-1}z)|_{G_q})(e)$. The argument for contradiction relies on $f_\\phi$ being injective. However, the paper does not provide a proof or justification for why $f_\\phi$ must be injective. If $f_\\phi$ is not injective, the subsequent argument that $(\\phi^*)^N = (\\phi^N)^*$ leads to a contradiction (because $(\\phi^*)^N$ would be injective while $(\\phi^N)^*$ would not) fails. The injectivity of $f_\\phi$ depends on properties of $\\phi = \\alpha_{\\text{new}}$ (specifically, if $\\alpha_{\\text{new}}(u_g) = \\alpha_{\\text{new}}(v_g)$ for all $g$ implies $u_g=v_g$ for all $g$), which are not sufficiently established in relation to the initial injective map $f$."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 25370,
      "output": 480
    }
  },
  {
    "entry_id": 125,
    "retraction_id": "2002.11860v4",
    "paper_id": "2002.11860v3",
    "retraction_comment": "Mistake in Lemma 3 changing the announced rate. Withdrawing while fixing the error",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound analysis of the gradient estimator error `H_t`",
        "Location": "Lemma 2 (page 5), its proof, and subsequent use in Lemma 3 and Theorem 1.",
        "Explanation": "The paper defines `H_t = ||\\alpha_t - \\nabla f(Xw_{t-1})||_1` (Eq. 14), where `\\nabla f(Xw) = (1/n)G(w)` with `G(w)_j = f_j'(x_j^T w)`. The algorithm updates `\\alpha_t` (a vector storing historical gradients `f_j'`) in a SAGA-like manner, meaning `\\alpha_t` is an estimator of `G(w)`. The recurrence derived for `H_t` in Lemma 2, `E_t H_t \\leq (1-1/n)(H_{t-1} + \\gamma_{t-1}LD_1)`, relies on `E_t[\\alpha_t^j - (1/n)G_j(w_{t-1})]` contracting appropriately (as shown in Eq. 17-18 for `\\delta_{t-1}`). However, if `E_t[\\alpha_t^j] = (1-1/n)\\alpha_{t-1}^j + (1/n)G_j(w_{t-1})` (SAGA update for `\\alpha_t` estimating `G`), then `E_t[\\alpha_t^j - (1/n)G_j(w_{t-1})] = (1-1/n)\\alpha_{t-1}^j + (1/n^2)G_j(w_{t-1})`. This expression does not lead to the simple contraction claimed for `H_t`. This discrepancy makes the analysis of `H_t` in Lemma 2 and Lemma 3, and consequently the final convergence rates in Theorem 1, unsound."
      },
      {
        "Problem": "Inconsistency in the reported leading term of the convex convergence rate",
        "Location": "Table 1 (page 1) vs. Section 4 (page 7, top left) and Theorem 1 (page 4).",
        "Explanation": "Table 1 claims a convex convergence rate for 'This Work' as `O(n/t + n^{7/2}/t^2)`. However, Theorem 1 states the first term as `(2LD_2^2 + 8LD_1 D_2 n^{1/2}) / t`. If `L, D_1, D_2` are `O(1)` (as implied by Remark 3 for bounded `x_i`), this leading term is `O(n^{1/2}/t)`. This `O(n^{1/2}/t)` rate is also explicitly mentioned in the discussion in Section 4: 'In comparison, the rate given by Theorem 1 has a leading term of O(n^{1/2}/t)...'. This contradicts the `O(n/t)` claim in Table 1, which is critical for comparisons with prior work like Lu & Freund (2018) who achieve `O(n/t)`."
      },
      {
        "Problem": "Potential miscalculation of `n` dependency in the `D_2 H_0` term of Theorem 1",
        "Location": "Theorem 1 (page 4) vs. Appendix C (page 12) and Appendix D (page 13).",
        "Explanation": "Theorem 1 states the `H_0` dependent term in the numerator of the `1/t^2` part of the bound as `2n^{7/2}D_2H_0`. The derivation in Appendix C (page 12) shows this term arising from `2 \\sqrt{n}D_2H_0 C_t`. Appendix D (page 13) bounds `C_t = \\sum (k+1)(1-1/n)^k` by `n^2`. Therefore, this term should be `2 \\sqrt{n}D_2H_0 n^2 = 2n^{2.5}D_2H_0`. There is a discrepancy of `n` in the exponent (`n^{3.5}` vs `n^{2.5}`), which affects the overall rate dependency on `n`."
      },
      {
        "Problem": "Incorrect bound for `max_{u,v \\in C} ||X(u-v)||_2` in Remark 3",
        "Location": "Remark 3, page 4",
        "Explanation": "Remark 3 states `max_{u,v \\in C} ||X(u-v)||_p \\leq n D_p`, where `D_p = max_{i=1...n} max_{u,v \\in C} |x_i^T(u-v)|`. For `p=2`, `||X(u-v)||_2^2 = \\sum_i (x_i^T(u-v))^2 \\leq \\sum_i D_p^2 = n D_p^2`. Thus, `||X(u-v)||_2 \\leq \\sqrt{n} D_p`. The remark incorrectly states `n D_p` for all `p`, including `p=2`. While this specific remark might not be directly used to invalidate a main theorem step (as the analysis in Appendix B for Lemma 1 correctly uses `\\sqrt{n}D_2` related to `||X(u-v)||_2`), it indicates a lack of precision with `n` dependencies."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 22292,
      "output": 1289
    }
  },
  {
    "entry_id": 126,
    "retraction_id": "2109.13007v2",
    "paper_id": "2109.13007v1",
    "retraction_comment": "We found a gap in the claim 1 (we can not solve it)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect premise in boundary tangency argument for Proposition 1",
        "Location": "Page 5, lines 6-12 (equation block and surrounding text)",
        "Explanation": "The proof of Proposition 1, when considering the boundary case (a contact point p on S^n), aims to show that the normals η₁ (to Σ₁) and η₂ (to ρ(θ₀,Σ₂)) must be linearly dependent. It attempts this by deriving a contradiction 1 = -1. This derivation starts from the assertion '1 = (α(η₁,η₁),p)'. However, using standard definitions of the second fundamental form α of S^n (e.g., α(X,Y) = <D_X Y, N_S> where N_S is the normal to S^n, or α_vector(X,Y) = -<X,Y>N_S if N_S is the outward normal position vector p), the term (α(η₁,η₁),p) (interpreted as <α_vector(η₁,η₁), p>) evaluates to -1, assuming η₁ is a unit vector tangent to S^n. If the premise is (α(η₁,η₁),p) = -1, the subsequent calculation leads to -1 = -1, which is not a contradiction. If '1 = (α(η₁,η₁),p)' is indeed incorrect, the argument for the linear dependence of η₁ and η₂ fails. This is critical because the boundary version of the tangency principle is then unproven, and this principle is subsequently used in Claim 1 and thus affects the entire proof of Theorem A."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 18628,
      "output": 370
    }
  },
  {
    "entry_id": 127,
    "retraction_id": "1305.3218v2",
    "paper_id": "1305.3218v1",
    "retraction_comment": "This paper has been withdrawn by the author. Due to the dependence of f(\\sigma) on z, Lemma 5.3 is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound estimation of a crucial sum in the proof of the Extension Generator Theorem.",
        "Location": "Page A:13, Phase I (Section 3.1), step (ii) in the derivation of the upper bound for |D|.",
        "Explanation": "The paper claims that `Sum_j ( (l_0-m)choose(j) ) ( (m)choose(j) ) e^(jr) < (l_0/m) * Sum_j ( (m)choose(j) ) e^(-(j-1)ln j + j + O(1))` which then leads to the sum being `(l_0/m)e^(O(1))`. This inequality and the subsequent approximation of the sum are highly non-trivial and potentially incorrect. My re-estimation of the second sum `Sum_j (m choose j) e^(-(j-1)ln j + j + O(1))` suggests it might be `(1+e)^m e^(O(1))`, which is exponentially larger in `m` than the claimed `(l_0/m)e^(O(1))` (since `l_0` is polynomial in `m`). An error here would invalidate the bound on `|D|`, the conclusion `κ_D > κ(U) - O(1)`, and consequently Lemma 3.2 and the main Extension Generator Theorem (Theorem 3.4), which are foundational for all subsequent results."
      },
      {
        "Problem": "Potentially flawed application of Lemma 4.3 in proving Lemma 4.8, regarding the reduction of the set Q.",
        "Location": "Page A:30, Proof of Lemma 4.8.",
        "Explanation": "Lemma 4.8 states that `|Q(z_j)| << |Q|` after a step in BLOCKEDEDGES. The proof relies on Lemma 4.3, which is about the properties of typical sets. Lemma 4.8 needs to establish the existence of a *specific* small set `z_j` (blocked edges) that is incident to a very small number of active problems `σ` in `Q`. The argument uses an average-case calculation: `M|Q| / (binom(N,L)e^(-o(1)))` to bound the number of incident `σ` for the chosen `z_j`. The validity of this transition from an average-case property (or existence via probabilistic method implied by Lemma 4.3) to a strong worst-case guarantee for the chosen `z_j` needs more rigorous justification. If the reduction `|Q(z_j)| << |Q|` is not as strong as claimed (e.g., not a constant factor reduction independent of other parameters, or if `M` is too large), the inductive argument that `|Q|` becomes empty (or very small) might fail."
      },
      {
        "Problem": "Validity of applying the shift method to the super-polynomially sized flattened circuit in Section 6.",
        "Location": "Page A:44 onwards, Section 6 (Flattening the Shift for General C).",
        "Explanation": "Section 6 aims to prove P ≠ NP by applying the shift method (developed in Sections 4 and 5) to a 'flattened' circuit `Ĉ`. Lemma 6.2 states that `Ĉ` has size `exp(O(ln^3 n))` which is `n^(O(ln^2 n))`, a super-polynomial size. The shift method, including algorithms like CLIQUEGENERATORS and the analysis of `|Q_0|` (e.g., Lemma 4.2(i) where `|Q_0|` depends on the circuit size `|C|`), was developed assuming `|C|` is at most `exp(n^ε)`. If `|C|` is replaced by `size(Ĉ) = n^(O(ln^2 n))`, then `|Q_0|` could become `n^(O(ln^2 n)) * e^(O(n^ε))`, which might be too large for the subsequent arguments about reducing `|Q|` exponentially or finding sparse structures relative to `n` (the input size of CLIQUE). The paper needs to demonstrate that all parameters and complexity bounds of the shift method scale appropriately when applied to `Ĉ`."
      }
    ],
    "token_usage": {
      "input": 14314,
      "thinking": 15195,
      "output": 969
    }
  },
  {
    "entry_id": 128,
    "retraction_id": "1305.3218v2",
    "paper_id": "1305.3218v1",
    "retraction_comment": "This paper has been withdrawn by the author. Due to the dependence of f(\\sigma) on z, Lemma 5.3 is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Sign error in the ordinary differential equation for coefficients `a_{e,k}` and its consequences for the three-annuli property.",
        "Location": "Page 21, top, and subsequent arguments for Lemma 4.2 (Eq. 4.16).",
        "Explanation": "The ODE for the coefficients `a_{e,k}(t)` of the even part `ζ` is stated as `ä_{e,k} - å_{e,k} - s_k a_{e,k} = 0`. Based on the derivation from `ζ_t = ζ/4 + ζ_{φφ} + ζ_{tt}` and `ζ/4 + ζ_{φφ} = -s_k ζ` (for eigenmodes `f_k` with eigenvalue `s_k`), the equation should be `ä_{e,k} - å_{e,k} + s_k a_{e,k} = 0`. \nIf this sign is `+s_k`, the characteristic equation becomes `r^2 - r + s_k = 0`. Since `s_k >= s_1 > 3/4` for `k >= 1`, the discriminant `1-4s_k` is negative. This implies complex roots `1/2 ± i ω_k`, leading to solutions of the form `a_{e,k}(t) = e^{t/2} (C \\cos(ω_k t) + D \\sin(ω_k t))`. \nThe paper's subsequent argument for the three-annuli property of `L^{e,1}` (Eq. 4.16) relies on the assertion `(a_{e,k}^2)'' >= a_{e,k}^2` (page 21, line 6), which is derived from the incorrect ODE form with real exponential solutions. If solutions are oscillatory, this convexity-type argument (and the general lemma on page 18 for `h'' >= h`) does not apply, making the proof of (4.16) for `L^{e,1}` unsound. This potentially invalidates Lemma 4.2, Theorem 4.3, Theorem 2.4, and consequently the main results of the paper."
      },
      {
        "Problem": "Unclear or potentially flawed derivation of the Ventsel boundary condition for `ζ` used in the spectral analysis.",
        "Location": "Page 10-11, specifically the transition from (3.6) to (3.7) and then to the Ventsel BC for `ζ` in (3.8).",
        "Explanation": "The paper derives a Ventsel-type boundary condition (3.6) for `z`. It then states an identity (3.7) `[π/2 (z/4 + z_{φφ}) - z_{φφ}](0,t) = 0`, which appears to be an equation for `z(0,t)` rather than a direct boundary condition for `ζ = z_φ`. The Ventsel boundary condition for `ζ` presented in (3.8), `ζ_φ(0,·) - (π/2)(ζ(0,·)/4 + ζ_{φφ}(0,·)) = 0`, is crucial for the subsequent spectral analysis (Proposition 3.3, 3.5). The logical steps connecting (3.6) (the derived condition for `z`) to the specific form of the Ventsel BC for `ζ` in (3.8) are not clearly presented or seem to involve inconsistencies (e.g., (3.7) being an equation for `z` but used to establish a BC for `z_φ`). If the Ventsel BC in (3.8) is not correctly derived from the original linearized problem, the spectral decomposition and the properties of eigenvalues `s_k` and eigenfunctions `f_k` might be incorrect, impacting the rest of the analysis that relies on this spectral information."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 19928,
      "output": 887
    }
  },
  {
    "entry_id": 129,
    "retraction_id": "1901.07856v7",
    "paper_id": "1901.07856v6",
    "retraction_comment": "The proof of the the second inequality of Lemma 7 is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 2 (Progression Lemma for RECOLOR)",
        "Location": "Page 5, Lemma 2 and its proof.",
        "Explanation": "The proof of Lemma 2 claims that if RECOLOR(e,C) terminates, then not only is 'e' (the triggering edge of the bad cycle C) fixed, but also no other edge 'e'' (that was 'good', i.e., not part of such a bad cycle before the call) becomes 'bad'. The argument attempts to show that if 'e'' becomes bad due to a sub-call RECOLOR(e*,C*), then RECOLOR(e*,C*) could not have terminated. This conclusion is only necessarily true if 'e'' is one of the edges that RECOLOR(e*,C*) is responsible for fixing (i.e., one of the first 2k*-2 edges of C* that are initially recolored and then monitored by RECOLOR(e*,C*)'s recursive loop). If 'e'' is an arbitrary other edge not in this set, RECOLOR(e*,C*) could terminate even if 'e'' becomes part of a 'bad' cycle due to the recoloring of edges in C*. This potential for 'good' edges to become 'bad' without guaranteed correction undermines the progression argument crucial for the algorithm's analysis, particularly for Lemma 3 which bounds the repetitions of EDGECOLOR's main loop."
      },
      {
        "Problem": "Mismatch in conditions between EDGECOLOR's loop and COLORVAL's success criteria, invalidating Lemma 6",
        "Location": "Algorithm 1 (EDGECOLOR, line 4, page 4), Algorithm 3 (COLORVAL, line 3 & lines 5-7, page 7), and Lemma 6 (page 8).",
        "Explanation": "EDGECOLOR's main while-loop (Algorithm 1, line 4) continues if a cycle C has (C⁰(e) monochromatic OR C¹(e) monochromatic). The validation algorithm COLORVAL(F) (Algorithm 3, line 3) continues its processing for a step (eᵢ, Cᵢ) from the trace F if (C⁰(eᵢ) monochromatic AND C¹(eᵢ) monochromatic); otherwise, if this 'AND' condition is not met, COLORVAL(F) declares failure (lines 5-7). This means Pr[V_F] (the probability that COLORVAL(F) 'succeeds' by satisfying the 'AND' condition at every step of the trace F) is the probability of a sequence of events that are much rarer (stricter) than the actual 'OR' condition events causing EDGECOLOR to loop. Consequently, the crucial Lemma 6, which states P_n ≤ P̂_n (where P_n is the probability EDGECOLOR runs for n phases and P̂_n = Σ Pr[V_F]), is not justified. An execution trace F from EDGECOLOR (where the 'OR' condition held at each step) does not guarantee that COLORVAL(F) would 'succeed' (as the 'AND' condition might not have held at each step). This invalidates the bounding of EDGECOLOR's runtime by P̂_n."
      },
      {
        "Problem": "Incorrect derivation and conclusion in the asymptotic analysis of R_n coefficients regarding ρ",
        "Location": "Page 10, paragraph starting 'Now, as it is shown...', specifically the derivation of ρ and the condition for exponential decay.",
        "Explanation": "The paper analyzes the generating function R(z) for the sums of weights of feasible trees. To show that P̂_n (related to the n-th coefficient of R(z)^m) is inverse exponential in n, the radius of convergence ρ of R(z) must be strictly greater than 1 (assuming coefficients R_n decay as (1/ρ)^n, requiring 1/ρ < 1). The paper uses the condition τφ'(τ)/φ(τ) = 1 from Flajolet & Sedgewick. This implies φ(τ) = τφ'(τ). The radius of convergence ρ is defined as τ/φ(τ) for equations of the form W=zφ(W). Thus, ρ = τ/(τφ'(τ)) = 1/φ'(τ). The paper incorrectly states 'ρ = τ/φ(τ) = τφ'(τ)' (middle of page 10). Based on this incorrect formula, it attempts to argue ρ > 1. The correct condition for exponential decay of P̂_n is ρ > 1, which means 1/φ'(τ) > 1, or φ'(τ) < 1. The paper correctly notes that for q=1/2 (a boundary case for their parameter q), φ'(τ) = 1 (implying ρ=1, no exponential decay). It then needs to rigorously show that for their actual q < 1/2, φ'(τ) becomes strictly less than 1. The provided argument is flawed due to the incorrect formula for ρ and does not sufficiently establish this critical condition."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 16736,
      "output": 1116
    }
  },
  {
    "entry_id": 130,
    "retraction_id": "1912.10027v2",
    "paper_id": "1912.10027v1",
    "retraction_comment": "We have found some errors in the methods, in particular two of the methods are not A-stable",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Post-processor construction is ill-defined or ineffective when $T_{p+1}$ is zero or numerically negligible.",
        "Location": "Page 12 (Section 3.2, steps 5-6), Page 13 (step 6), and Page 15 (Table 2, IMEX-EIS+(5,6) results)",
        "Explanation": "The post-processor construction involves forming a matrix $T$ using the truncation error coefficient vectors $T_{p+1}^F$ and $T_{p+1}^G$ (denoted $\\tau^F, \\tau^G$ in the construction). If these coefficient vectors are zero, as implied when a method achieves order $p+2$ or higher *before* post-processing (e.g., IMEX-EIS+(5,6) shows order $p+2 \\approx 6$ before post-processing, suggesting $T_{p+1}=T_5 \\approx 0$), the matrix $T$ would have zero columns and be singular. Consequently, $T^{-1}$ would not exist, and the post-processing filter $\\Phi$ cannot be constructed as described. The paper acknowledges that $T$ might be non-invertible but does not clarify how such cases are handled for methods that are already order $p+2$ before post-processing, yet still have 'after post-processing' results reported. If $T_{p+1}$ is merely very small but non-zero, the post-processor would remove this small $O(\\Delta t^{p+1})$ term, and the observed order might not change significantly if the $O(\\Delta t^{p+2})$ term was already dominant. This makes the benefit of post-processing unclear or the construction problematic for these specific high-performing methods."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 24566,
      "output": 398
    }
  },
  {
    "entry_id": 131,
    "retraction_id": "1502.05353v3",
    "paper_id": "1502.05353v2",
    "retraction_comment": "This paper has been withdrawn due to some errors. The main error is the wrong spin function of Eq. (5), which makes equations (13) and (14) incorrect, and in turn puts doubts on the final conclusions",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Overestimation of overlap integrals by implicitly assuming atomic orbital overlaps are unity.",
        "Location": "Page 12 (Eq. 17-18), Page 15 (Eq. 21), Page 17 (discussion relating S_ij to c^2)",
        "Explanation": "The calculation of the two-particle overlap integral O_12 ≈ c^4 (leading to J_d = -2ε̃_+ c^4) and the single-particle overlap S_ij ≈ c^2 (leading to τ ≈ -ε̃_+ c^2) implicitly assumes that the underlying atomic orbital overlaps (e.g., S_pp between p-orbitals on adjacent oxygen atoms involved in the bond) are equal to 1. In reality, such atomic overlaps are significantly less than unity (e.g., S_pp ≈ 0.2-0.3). This assumption would lead to a substantial overestimation of O_12 and S_ij, and consequently a significant overestimation of the calculated direct exchange J_d and hopping parameter τ. If J_d is overestimated, its claimed dominance over the indirect exchange and the subsequent conclusions about critical doping would be invalid."
      },
      {
        "Problem": "Unconventional definition of the direct exchange integral J_d.",
        "Location": "Page 10, Eq. (13)",
        "Explanation": "The direct exchange integral is defined as J_d = -2ε̃_+ O_12, where 2ε̃_+ is the diagonal energy of the two-particle state (including direct Coulomb repulsion I) and O_12 is the overlap integral <Ψ_i(1)Ψ_j(2)|Ψ_j(1)Ψ_i(2)>. This definition does not correspond to the standard definition of the direct Coulomb exchange integral, K_ex = <Ψ_i(1)Ψ_j(2)|e²/|r1-r2||Ψ_j(1)Ψ_i(2)>, nor to the full off-diagonal Hamiltonian matrix element H_12 = 2ε_+ O_12 + K_ex which determines the exchange splitting in the Heitler-London approach. The paper's J_d appears to be -(Diagonal Energy Element) * Overlap, which is not the conventional exchange term. This potentially misidentifies the physical origin and the mathematical form of the direct exchange energy, which could lead to incorrect quantitative estimates and conceptual interpretations."
      },
      {
        "Problem": "Inconsistent formulation of the direct exchange term in the proposed modified t-J Hamiltonian.",
        "Location": "Page 19, Eq. (27) compared to Page 10, Eq. (14) and Page 18, Conclusion 2",
        "Explanation": "The derivation of J_d (e.g., Eq. 14) indicates an energy splitting of 2J_d between the triplet (parallel spins, energy 2ε̃_+ + J_d) and singlet (anti-parallel spins, energy 2ε̃_+ - J_d) states. This would correspond to an effective Heisenberg interaction term of the form 2J_d S_i·S_j. However, the proposed modified t-J Hamiltonian in Eq. (27) includes a direct exchange term written as 4J_d ΣSᵢ·Sⱼ. This term implies an energy of +J_d for parallel spins (S_i·S_j = 1/4) and -3J_d for anti-parallel spins (S_i·S_j = -3/4), leading to a splitting of 4J_d. This factor of 2 discrepancy in the magnitude of the exchange interaction term is inconsistent with the earlier derivation and undermines the quantitative analysis based on the proposed Hamiltonian, such as the calculation of critical doping."
      },
      {
        "Problem": "Approximations in the evaluation of the overlap integral O_12.",
        "Location": "Page 12, leading to Eq. (17)",
        "Explanation": "The paper simplifies the full expression for O_12 (Eq. 16) by claiming that only the first term, (c² P_1x1 P_2x2)², is dominant and that other terms either vanish due to symmetry or are negligibly small. The argument for vanishing terms (e.g., based on anti-symmetry of P_1x1 P_2x2 integrands) appears flawed, as P_x is an odd function, making P_1x1 P_2x2 an even function if x1 and x2 are coordinates of different particles. Furthermore, the neglecting of terms involving d-orbitals (e.g., (b²D₁D₂)²) as 'negligibly small' requires more rigorous justification than provided. If these neglected or incorrectly dismissed terms are significant, the resulting approximation O_12 ≈ ∫d³r1 d³r2 (c² P_1x1 P_2x2)² and subsequently O_12 ≈ c^4 would be inaccurate, impacting the calculation of J_d."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 15673,
      "output": 1127
    }
  },
  {
    "entry_id": 132,
    "retraction_id": "1808.08722v2",
    "paper_id": "1808.08722v1",
    "retraction_comment": "We find the polarization degrees of freedom of the squeezed light had not been treated properly in our analysis, which would affect our results significantly especially in the case of dissipative quantum walks. A new analysis is currently underway. We thank [REDACTED-NAME] for help in clarifying these issues",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent mathematical justification for dissipative quantum walk amplitudes.",
        "Location": "Page 7, Appendix A2, specifically the text connecting Eq (15) to Eq (A7)-(A8), and Eq (A7) itself.",
        "Explanation": "The paper claims that the dissipative QW amplitudes w_N(n) from Eq (15) can be obtained from u_N(n) and v_N(n) in Eq (A7) (Appendix A2). However, the mathematical relationship implied (w_N(n) being proportional to u_N(n) + v_N(n)) does not hold under standard combinatorial identities (Pascal's identity implies C(N,k) should be C(N-1,k-1) + C(N-1,k), but the sum from A7 leads to 2*C(N-1,k-1) after simplification using C(M,j)=C(M,M-j)). This suggests an unsound mathematical link. Furthermore, Eq (A7) presents u_N(n) and v_N(n) which are generally not equal, contradicting the statement on page 7 that 'H and V polarizations are now symmetric' if u_N and v_N are supposed to be H/V amplitudes of the same state after N steps of the symmetric dissipative QW."
      },
      {
        "Problem": "Distortion of the encoded qubit state in the dissipative scheme requires state-dependent input preparation.",
        "Location": "Page 5, Eq (19) and the discussion thereafter.",
        "Explanation": "The dissipative encoding scheme transforms an input state α|H⟩ + β|V⟩ into an encoded state N(α'|0⟩_dQW + β'|1⟩_dQW), where α'/β' = (α/β)/γ, and γ = sqrt(Z_{N+1}/Z_N) ≠ 1 generally. This means the relative amplitudes of the logical qubit are altered. The paper acknowledges that the input state must be 'prepared properly'. However, this implies that to encode a desired target state A|0⟩_L + B|1⟩_L, the input physical qubit α|H⟩ + β|V⟩ must be specifically pre-compensated (α/β must be γA/B). This complicates the process of encoding 'arbitrary logical states' (as claimed in the abstract) and introduces an additional source of error if the pre-compensation is imperfect or γ is not precisely known."
      },
      {
        "Problem": "The experimental feasibility of the dissipative QW scheme is significantly impacted by undiscussed low success probability.",
        "Location": "Page 5, Section II.B (implicitly through Z_N in Eq 16, 22) and Abstract's claim of 'experimentally feasible schemes'.",
        "Explanation": "The dissipative QW scheme involves projective operations. The normalization constant Z_N for the N-step walk is approximated as Z_N ≈ 1/(2√(πN)) (Eq 22). For N=8, Z_8 ≈ 0.1. This Z_N factor contributes to the overall success probability of generating the desired normalized encoded state. Such low, N-dependent success probabilities are not discussed in the paper. This omission is critical when claiming an 'experimentally feasible scheme', as low efficiency can render a method impractical for generating states for computation or repeated error correction, regardless of the quality of the successfully generated state."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 13673,
      "output": 771
    }
  },
  {
    "entry_id": 133,
    "retraction_id": "2406.11623v4",
    "paper_id": "2406.11623v3",
    "retraction_comment": "Some errors appeared in the article that seem difficult to correct. For example, the Green function $G_R(o,x)$ for the geodesic ball $B(R)$ was misunderstood to satisfy the Dirichlet boundary condition on the geodesic sphere $\\partial B(R)$, however, this is not the case",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and usage of F_R(r)",
        "Location": "Page 6 (definition of F_R(r)), Page 17 (Equation (5))",
        "Explanation": "F_R(r) is defined as E [integral_0^{T_R} (r^2 exp(-r^2/(At))) / (t V(sqrt(t))) dt] on page 6. Let I_0(r) = E [integral_0^{T_R} (exp(-r^2/(At))) / (t V(sqrt(t))) dt], so F_R(r) = r^2 I_0(r) by this definition. However, Equation (5) on page 17 states 'd(pi_r) <= 4rE[...]do_r = 4rF_R(r)do_r'. The first part of this equality implies d(pi_r) <= 4r I_0(r) do_r. The second part then implies F_R(r) = I_0(r). These two definitions/usages of F_R(r) differ by a factor of r^2. This inconsistency is critical as F_R(r) appears in the error terms of the main theorems (e.g., Theorem 4.2, Theorem 5.1)."
      },
      {
        "Problem": "Questionable derivation of a key identity in Calculus Lemma proof",
        "Location": "Page 16, proof of Theorem 4.2",
        "Explanation": "The derivation of the identity 'd/dr integral_{Delta(r)} g_r k dv = 4r F_R(r) integral_{∂Delta(r)} k do_r' seems problematic. This identity is crucial for establishing Theorem 4.2 (Calculus Lemma). The derivation involves differentiating an integral where both the integrand g_r (via its C(r) term) and the upper limit of an inner integral depend on r. The application of Fubini's theorem and the Leibniz rule for differentiation under the integral sign needs careful justification, and the presented steps do not clearly lead to the stated result structure. For example, my own check suggests the LHS derivative might result in a term involving an integral over [0,r] of integrals over ∂Delta(t), rather than a direct term involving an integral over ∂Delta(r) as on the RHS."
      },
      {
        "Problem": "Incorrect exhaustion claim for domains Delta(r)",
        "Location": "Page 9, statement 'lim_{r->R} Delta(r) = B(R)'",
        "Explanation": "The domain Delta(r) is defined (on page 5, consistent with g_r being its Green function) as {x in M : G_R(o,x) > C(r)}, where C(r) = 2AE [integral_0^{T_R} exp(-r^2/At)/V(sqrt(t)) dt]. As r approaches R, C(R) is generally a positive constant (assuming the integral is positive). However, the Green function G_R(o,x) for B(R) is zero on the boundary ∂B(R). Thus, for x in ∂B(R), the condition for being in Delta(R) becomes 0 > C(R), which is false if C(R) > 0. This implies Delta(R) is strictly contained within B(R) and does not include ∂B(R), contradicting the claim that Delta(r) exhausts B(R). This exhaustion property is fundamental for applying the theory developed on Delta(r) to the geodesic ball B(R)."
      },
      {
        "Problem": "Inconsistent handling or omission of Li-Yau constant A",
        "Location": "Theorem 2.2 (page 10), Corollary 2.3 (page 12), and their proofs (pages 11-12)",
        "Explanation": "The constant A from the Li-Yau heat kernel estimate (e.g., exp(-rho(x)^2/(At))) appears to be inconsistently handled or omitted in key estimates. For instance, the derivation of the estimate for the harmonic measure d(pi_r) on page 11, when traced carefully, suggests a factor of 1/A in the coefficient of the main term (assuming lim (r-t)/rho_{t,ν}(x) is of order 1). However, Theorem 2.2 states d(pi_r) <= (2+epsilon_0)r I_0(r) do_r, without this factor A. If A is not equal to 1, this omission or inconsistency affects the accuracy of these estimates, which subsequently propagate to other results, such as Equation (5) on page 17 and potentially the final error terms."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 17879,
      "output": 1081
    }
  },
  {
    "entry_id": 134,
    "retraction_id": "2108.09325v2",
    "paper_id": "2108.09325v1",
    "retraction_comment": "Several sections, particularly Section 5, contain an error interpreting the mutual inclination directly as the obliquity",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Reliance on Pre-existing High Mutual Inclination",
        "Location": "Section 2 (Eq. 4, and discussion of Fig. 2), Section 3 (paragraph discussing efficiency starting 'For example, among planets beginning from 0.1 to 0.4 au...'), Section 5 (first paragraph of Discussion: 'The mutually inclined companion must be near polar...')",
        "Explanation": "The paper proposes that GR-reduced HEM from warm starts explains perpendicular planets (final obliquity `i_f` ~ 90°). However, the underlying dynamics (approximated by Eq. 4, `cos^2 i_min ≈ cos^2 i_0 / (1-e_max^2)`) indicate that the final minimum inclination `i_min` (which becomes `i_f`) is very close to the initial mutual inclination `i_0`, particularly since `e_max` is reduced in the GR-dominated regime. To achieve `i_f` ~ 90°, `i_0` must therefore already be near 90° (e.g., the 70-110° range mentioned in efficiency calculations). This implies the mechanism primarily preserves an existing high mutual inclination during the final tidal migration phase, rather than generating perpendicular configurations from a broad distribution of initial inclinations. This shifts the core challenge to explaining the origin of these initially highly inclined 'warm' systems, limiting the current model's scope as a fundamental explanation for perpendicularity."
      },
      {
        "Problem": "Uncertainty in the Prevalence and Origin of Required 'Warm Start' Conditions",
        "Location": "Section 3 (Parameter space in Fig. 3 and associated discussion, efficiency calculations), Section 5 (Discussion on the origin of warm Jupiters and the initial high inclinations, e.g., paragraph starting 'The observed population of perpendicular close-in planets...')",
        "Explanation": "The proposed scenario critically depends on a specific set of initial conditions: a planet located at a 'warm' semi-major axis (e.g., 0.1-0.6 AU) accompanied by an outer companion that is not only capable of inducing Kozai-Lidov oscillations but is also *already* on a highly inclined (near-polar) orbit relative to the inner planet. The paper does not robustly establish how frequently such specific starting configurations arise through planet formation and migration theories. If these 'warm start' systems with pre-existing high mutual inclinations are rare, or if their formation itself requires other specific and potentially inefficient mechanisms (as alluded to with resonance crossing), the overall contribution of this GR-reduced HEM channel to the observed population of perpendicular planets would be minor, even if the subsequent dynamics operate as described."
      },
      {
        "Problem": "Simplified Treatment of Octupole-Level Effects and Initial Inner Planet Eccentricity",
        "Location": "Section 2 (assumptions stated before Eq. 1: 'limit where the octupole portion of the potential is negligible, both bodies begin on circular orbits...'), Section 4 (bullet points discussing 'The outer planet’s eccentricity' and 'The inner planet’s initial eccentricity')",
        "Explanation": "The primary analytical model (Eq. 1) and much of the subsequent analysis assume negligible octupole-level effects (implying a circular outer perturber orbit) and initially circular orbits for the inner, migrating planet. However, outer companions can possess significant eccentricities (`e_out`), leading to eccentric Kozai-Lidov (eKL) dynamics. These eKL effects can substantially alter eccentricity excitation and inclination evolution, potentially changing the conditions for entering the GR-reduced regime and the final outcomes. Similarly, planets arriving at 'warm' starting positions might already have non-negligible initial eccentricities, which would influence GR precession rates and the Kozai cycle. The paper acknowledges these factors but does not fully explore their impact, leaving uncertainty about the robustness of the predicted parameter space and outcomes if these simplifications are relaxed."
      },
      {
        "Problem": "Inadequate Explanation for the Scarcity of 40°/140° Obliquity Systems from 'Cold Starts'",
        "Location": "Section 1 (Introduction, paragraph starting 'However, the population of warm and cold Jupiters...'), Section 5 (Discussion, paragraph starting 'Another important concern is why HEM would not take place for cold planets as well...')",
        "Explanation": "The paper contrasts its proposed mechanism for perpendicular planets (originating from warm starts) with standard HEM from 'cold starts' (beyond 1 AU), which is canonically predicted to produce obliquities around 40°/140°. If HEM is a significant channel for hot Jupiter formation and 'cold starts' are common, a more prominent population of systems with these 40°/140° obliquities should be observed. The paper acknowledges this discrepancy as a concern but offers only speculative explanations for the apparent lack or suppression of this signature (e.g., most cold Jupiters migrate to warm starts via disk interaction first). The absence of a robust, modeled explanation for the scarcity of these canonical HEM outcomes weakens the overall HEM framework, which provides the broader context for the specific GR-reduced HEM scenario being advocated."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 7706,
      "output": 1133
    }
  },
  {
    "entry_id": 135,
    "retraction_id": "1705.00151v2",
    "paper_id": "1705.00151v1",
    "retraction_comment": "We apologize that in the results and algorithms of Section 4.1, Proposition 4.1 and Lemma 4.2, there are some missing conditions and assumptions on the hypergraphs. Hence we want to withdraw the manuscript. Moreover, we want to work out more results, and merge this manuscript together to write a publishable paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The condition for homotopy equivalence in Proposition 5.4 is non-standard and inadequately justified for the described vertex removal operation.",
        "Location": "Page 12, Proposition 5.4 and its proof.",
        "Explanation": "Proposition 5.4 aims to show H*(H) ≃ H*(Hd(v)) by deleting all hyperedges containing a vertex v. The proof relies on K = St_KH(σ) being homotopy equivalent to K' (related to Hd(v)). The condition given for this is 'Lk_KH(σ) is a simplicial cone', where σ is a hyperedge containing v. This condition on the link of a hyperedge σ is not standard for justifying the homotopy equivalence when removing a vertex v from K (or St_KH(σ)). Standard conditions for such vertex collapsibility typically involve properties of Lk_K(v), the link of the vertex v itself (e.g., Lk_K(v) being contractible). The provided condition Lk_KH(σ) being a cone does not clearly lead to St_KH(σ) being a cone with apex v, which would be needed for St_KH(σ) ~ Lk_{St_KH(σ)}(v)."
      },
      {
        "Problem": "Mismatch between the theoretical basis (Proposition 5.4) and the implementation (Algorithm 5) for collapsing hyperedges.",
        "Location": "Page 12 (Proposition 5.4) and Page 13 (Algorithm 5).",
        "Explanation": "Proposition 5.4 is presented as the theoretical justification for Algorithm 5. However, the conditions differ significantly. Proposition 5.4 uses the condition 'Lk_KH(σ) is a simplicial cone' (where σ is a hyperedge and v ∈ σ). In contrast, Algorithm 5 uses the conditions 'St_KH(v) ⊆ H' and 'Lk_KH(v) is a simplicial cone' (which implies Lk_KH(v) is contractible). The condition in Algorithm 5 (contractible link of a vertex v) is a standard criterion for KH being homotopy equivalent to KH minus the vertex v and its incident open simplices. The condition in Proposition 5.4 is different and, as noted in another problem, seems ill-suited for the conclusion. This discrepancy means Algorithm 5 is either not correctly implementing Proposition 5.4, or Proposition 5.4 is not the correct justification for the (potentially correct) heuristic in Algorithm 5."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 22389,
      "output": 553
    }
  },
  {
    "entry_id": 136,
    "retraction_id": "1701.02653v2",
    "paper_id": "1701.02653v1",
    "retraction_comment": "This paper has been withdrawn to an error in Proposition 8 when moving from the quenched to the annealed measure. Thus, it is not a straightforward adaptation of the theorem cited",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Lemma 10 implies that an occupied root is always occupied by an uncoalesced particle.",
        "Location": "Page 5, Proof of Lemma 10, specifically the combination of the first equality `P(C_t^ρ ≠ ∅) = ...` and the third equality `... = Σ_{n>0} n^{-1}P(|C_t^{(ρ)}|=n)`.",
        "Explanation": "The proof of Lemma 10 starts by equating `P(C_t^ρ ≠ ∅)` (where `C_t^ρ` is the voter model cluster initiated at `ρ`) with a sum involving the size distribution of `|C_t^{(ρ)}|` (the size of the CRW particle at `ρ`). Since `C_t^ρ` is always non-empty (as it's a voter cluster containing its seed `ρ` at time 0, and opinions in a voter model don't spontaneously die), `P(C_t^ρ ≠ ∅) = 1`. The chain of equalities leads to `1 = Σ_{n>0} n^{-1}P(|C_t^{(ρ)}|=n)`. Let `N = |C_t^{(ρ)}|`. This sum is `E[1/N \\cdot 1_{N>0}]`. For this expectation to be 1, given that `N` is an integer and `N > 0` implies `1/N ≤ 1`, it must be that `1/N = 1` almost surely whenever `N > 0`. This means `N=1` almost surely, conditioned on `N>0`. So, `P(N=1 | N>0) = 1`. This implies that if the root `ρ` is occupied by a particle, that particle must be of size 1 (i.e., it consists of only one initial particle and has not coalesced). This is a very strong condition that is not generally true for coalescing random walks, where particles are expected to coalesce and form larger clusters. This assumption would fundamentally alter the nature of the process being studied and undermine conclusions about general CRW."
      },
      {
        "Problem": "The application of Jensen's inequality in the proof of Lemma 10 is flawed.",
        "Location": "Page 5, Proof of Lemma 10, the final inequality step: `E[|C_t^{(ρ)}|^{-1}] ≥ (E[|C_t^{(ρ)}|])^{-1}` (notationally, `E[|C_t^{(ρ)}|^{-1}]` here means `E[|C_t^{(ρ)}|^{-1} \\cdot 1_{|C_t^{(ρ)}|>0}]`).",
        "Explanation": "The proof of Lemma 10 concludes with an application of Jensen's inequality. Let `N = |C_t^{(ρ)}|`. The step is effectively `E[1/N \\cdot 1_{N>0}] ≥ (E[N])^{-1}`. Let `q = P(N>0)` (the probability that the root is occupied, i.e., `p_t`). Let `N'` be the random variable `N` conditioned on `N>0`. The inequality can be written as `E[1/N']q ≥ (E[N']q)^{-1}`. This simplifies to `E[1/N']E[N']q^2 ≥ 1`. By Cauchy-Schwarz (or Jensen's inequality for `1/x` applied to `N'`), `E[1/N']E[N'] ≥ 1`. Thus, the inequality requires `q^2 ≥ 1`, which implies `q=1` (since `q` is a probability). This means the inequality only holds if `P(N>0)=1`, i.e., if the root `ρ` is always occupied (`p_t=1`). If `p_t < 1`, the inequality does not hold in this form. If `p_t=1`, then `∫ p_t dt = ∞` trivially (for infinite time horizon), and the main result would follow directly from Proposition 8 without needing most of the paper's machinery. The assumption `p_t=1` is not justified for CRW on general infinite graphs where the occupation probability at a site is expected to decrease over time."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 21349,
      "output": 969
    }
  },
  {
    "entry_id": 137,
    "retraction_id": "2011.07585v2",
    "paper_id": "2011.07585v1",
    "retraction_comment": "The article contains wrong idea. There was mistake in the H3 assumption",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 2, which is crucial for satisfying Catalyst's condition (H3).",
        "Location": "Page 4, Lemma 2",
        "Explanation": "The proof of Lemma 2 aims to show that the auxiliary function `hk` (defined in Eq. 5) satisfies condition (H3) of the Catalyst framework. However, the derivation relies on an inequality `E[Hk(xk) - H*k + f(xk-1) - f*] <= εk + L/(μ+κ) (H(xk-1) - H*)` which is not justified or derived in the paper. This step is critical for relating the inner-loop accuracy `εk` to the parameter `δk` in (H3). The paper then defines `δk = (1 + L/(μ+κ))εk-1` based on this flawed step. Correctly, (H3) requires `δk >= f(xk-1) - f* + εk` (where `εk` is the actual precision achieved for `Hk`). The current proof does not validly establish (H3) for the chosen `hk` and `δk`."
      },
      {
        "Problem": "Questionable applicability of the generic Catalyst complexity analysis (Eq. 3 and Eq. 7) to Decentralized SGD (DSGD).",
        "Location": "Page 2, Eq. (3); Page 4, Eq. (7); Section 3.3 (application to DSGD)",
        "Explanation": "The Catalyst complexity analysis, leading to Eq. (7), assumes the inner optimization method M satisfies Eq. (3): `E[h(zt) - h*] <= C(1-a)^t (h(z0) - h*) + Bσ²η`. The convergence rate of DSGD, as cited from [2], is more complex, involving terms dependent on `1/ε_k` and `1/sqrt(ε_k)` for the number of iterations to achieve accuracy `ε_k` in the subproblem. It is not demonstrated that DSGD conforms to the specific structure of Eq. (3) with a fixed convergence rate `a` and a simple additive error term `Bσ²η` that can be controlled linearly by a parameter `η`. This potential mismatch makes the direct application of Eq. (7) to DSGD, and the subsequent derivation of overall complexity, potentially unsound without a rigorous mapping of DSGD's convergence behavior to the parameters `a` and `B` of Eq. (3)."
      },
      {
        "Problem": "The final complexity result for accelerated DSGD (Eq. 11) is inconsistent, contains unusual terms, and does not show full acceleration.",
        "Location": "Page 8, Eq. (11); Compare with claim on Page 2; Appendix 4.4 (Page 12)",
        "Explanation": "The final complexity presented in Eq. (11) is `Õ(σ²/(μπε) + L^(3/4)(ζτ+σ sqrt(pτ))^(1/2) / (μ^(5/4) ρ^(3/4) ε^(1/4)) + sqrt(Lτ)/(μρ))`. This result has several critical issues: \n1. It contains an `ε^(-1/4)` term, which is highly atypical for accelerated optimization methods. \n2. It differs from the accelerated complexity claimed earlier on page 2, which featured a more standard `ε^(-1/2)` term. \n3. The leading term `σ²/(μπε)` implies that the variance component is not accelerated (it remains dependent on `1/ε`), contradicting a primary benefit of Catalyst, which typically accelerates variance-dependent terms to `σ/sqrt(ε)` or similar. \n4. The derivation of the network-dependent term (third term in Eq. 11) in Appendix 4.4 seems to incorrectly sum constant terms over K iterations, potentially missing logarithmic factors or factors of `1/sqrt(q)` (where `q` is the conditioning factor `μ/(μ+κ)`)."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 15265,
      "output": 916
    }
  },
  {
    "entry_id": 138,
    "retraction_id": "1803.09392v2",
    "paper_id": "1803.09392v1",
    "retraction_comment": "This paper is withdrawn as the proof of Lemma 2.4 is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified generalization of the Chinburg-Kim formula for Ω(N/F,2)",
        "Location": "Page 6, Proposition 2.6, and its stated proof justification on Page 3 and Page 6.",
        "Explanation": "The central tool for proving Theorem 1.5 is Proposition 2.6, a formula for Chinburg's invariant Ω(N/F,2). This formula uses a ZG-lattice L, which in the context of this paper (for weakly or tamely ramified extensions) is A'_N/F = α*A_N/F (a scaled version of the square root of the inverse different). The paper states (p. 6) that 'The proof of Proposition 2.6 is identical to that of [6, Proposition 2.4]' (S. Kim's paper). Kim's Proposition 2.4 provides a formula for Ω(N/Q,2) where the global lattice term is (O_N) (the ring of integers of N), not a general lattice L like A'_N/F. The assertion that Kim's proof, which is specific to O_N and the base field Q, can be 'identically' applied to establish Proposition 2.6 for a general base field F and with L = A'_N/F, while still yielding the standard Chinburg invariant Ω(N/F,2) targeted by Erez's conjecture, is a very strong claim. This generalization is not explicitly proven or detailed in the note. If this generalized formula (Prop. 2.6) is not valid for the standard Ω(N/F,2), or if its proof is not a straightforward adaptation of Kim's work as asserted, then the main conclusion of the paper (Theorem 1.5) would be unsubstantiated. The validity of Theorem 1.5 hinges critically on this unverified generalization of a complex formula from the theory of Galois module structure."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 15033,
      "output": 433
    }
  },
  {
    "entry_id": 139,
    "retraction_id": "1709.04340v2",
    "paper_id": "1709.04340v1",
    "retraction_comment": "A problem with the proofs of Propositions 2 and 3 (a gap or fault in the reasoning used to claim that the expression in (3.9) is dominated by that in (3.11)); a similar problem with the proof of Proposition $1'$ (it is hard to justify the particular application of the Bourgain-Guth reduction theory implicit in a paragraph above Proposition $1'$). Theorems 1, 2 and 3 lose their status as theorems",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Condition (4.2) of Theorem 3 is not satisfied by the function F(x) used in the proof of Theorem 2.",
        "Location": "Page 18, Section 7 (Application of Theorem 3 for Theorem 2); Page 7, Theorem 3 (Condition (4.2))",
        "Explanation": "Theorem 3 is applied to an exponential sum S(H,M,T;a,b) with F(x) = (x+a/(4M))^{-1} + bM/(4T). Condition (4.2) of Theorem 3 requires F^{(1)}(x)F^{(3)}(x) - 3F^{(2)}(x)^2 \\geq C_4^{-1} > 0 (after ensuring F^{(2)}(x) > 0 by potentially replacing F with -F). For the given F(x), or -F(x), the expression F^{(1)}F^{(3)} - 3(F^{(2)})^2 evaluates to a negative quantity (-6(x+c)^{-6}). This means Theorem 3 is not applicable as stated, potentially invalidating the proof of Theorem 2."
      },
      {
        "Problem": "Condition (4.2) of Theorem 3 (or its analogue in [BW17]) is likely not satisfied for the function F(x) relevant to the proof of Theorem 1.",
        "Location": "Page 21, Section 8 (Proof of Theorem 1 Sketched); Page 7, Theorem 3 (Condition (4.2)); referring to F(x) from [BW17] or similar for S*",
        "Explanation": "The proof of Theorem 1 involves an exponential sum S* and methods from [BW17], which are analogous to the framework leading to Theorem 3. The phase functions typically used for the mean square of the zeta function (e.g., related to log(x) or (1+x)log(1+x) - (1-x)log(1-x)) also result in F^{(1)}F^{(3)} - 3F^{(2)}(x)^2 being negative (after ensuring F^{(2)}(x) > 0). If the Bombieri-Iwaniec method used relies on a condition equivalent to (4.2), its application for Theorem 1 would also be invalid."
      },
      {
        "Problem": "The formulation of Theorem 3(B) includes a remark that undermines its definitiveness.",
        "Location": "Page 8, Remarks on Theorem 3",
        "Explanation": "Theorem 3, Part (B), provides two alternative bounds, (4.9) or (4.10). The remark states: 'one uses the weaker, not the stronger, of the bounds (4.9), (4.10) (for the theorem leaves open the possibility of the stronger one being false)'. A theorem should not assert statements that could be false. This suggests a potential flaw or lack of completeness in the proof or statement of Theorem 3(B), which is a central tool in the paper."
      },
      {
        "Problem": "Unclear justification for the dimensional reduction in the estimation of A_p.",
        "Location": "Page 11, Equations (5.13)-(5.14)",
        "Explanation": "In Section 5, the term A_p, initially related to a 5-dimensional vector y(k,l) and then formulated as an integral involving a 4-dimensional sum in (5.13), is subsequently bounded by A_p' in (5.14), which involves a 3-dimensional sum. The step A_p \\leq A_p' (if this is the meaning of the notation) represents a dimensional reduction that is not standard and lacks clear justification. Since A_p is crucial for the bounds in Theorem 3, this step's validity is critical."
      },
      {
        "Problem": "The identification and properties of the parameter η in Section 6 are insufficiently justified.",
        "Location": "Page 14, Section 6 (Utilisation of New Results on the First Spacing Problem)",
        "Explanation": "The parameter η, defined as (√KLX)^{-1}, is crucial for applying Propositions 2 and 3. The paper claims that 'By (5.8), the above η satisfies both η = (Q/R)^2 (KL)^{-1} and ηK < (3Q)/(4H)'. The derivation of these properties, particularly the specific form η = (Q/R)^2 (KL)^{-1}, from (5.8) is not provided and is not obvious. If these properties of η are incorrect or not properly justified, the subsequent application of Propositions 2 and 3 to bound A_q^{1/q} may be flawed."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 13332,
      "output": 1071
    }
  },
  {
    "entry_id": 140,
    "retraction_id": "1106.5292v3",
    "paper_id": "1106.5292v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect conformal transformation formulas for Ricci tensor and scalar.",
        "Location": "Page 3, Equations (5) and (6).",
        "Explanation": "The formulas presented for the transformation of the Ricci tensor ($R_{ab}$) and Ricci scalar ($R$) under the conformal transformation $g_{ab} = e^\\Phi \\bar{g}_{ab}$ (Eq. 2) are incorrect. Specifically, the signs of all terms involving derivatives of $\\Phi$ in both Eq. (5) for $R_{ab}$ and Eq. (6) for $R$ are opposite to the standard, well-established formulas found in general relativity textbooks. This fundamental error propagates through all subsequent derivations that rely on these transformations."
      },
      {
        "Problem": "The derived Jordan frame action (Eq. 10) is not the standard action obtained from Einstein-Hilbert action via conformal transformation.",
        "Location": "Page 3, Equation (10), and its derivation via Eqs. (7)-(9).",
        "Explanation": "As a direct consequence of using incorrect conformal transformation formulas (Eqs. 5, 6), the derived Jordan frame Lagrangian $L_J$ in Eq. (10) is not the standard scalar-tensor theory Lagrangian that is conformally equivalent (up to a surface term) to the Einstein-Hilbert action (Eq. 1) plus a cosmological constant. The coefficients of the $\\phi^2 \\bar{R}$ term and the kinetic term for $\\phi$ (e.g., $(\\bar{\\nabla}\\phi)^2$) differ significantly in magnitude and/or sign from standard derivations. For example, for $n=4$, the standard derivation yields $\\frac{1}{2}\\phi^2 \\bar{R} + \\frac{3}{4}(\\bar{\\nabla}\\phi)^2$ (for a particular field definition), while Eq. (10) gives $\\frac{1}{12}\\phi^2 \\bar{R} - \\frac{1}{2}(\\bar{\\nabla}\\phi)^2$. This means the paper analyzes a non-standard scalar-tensor theory."
      },
      {
        "Problem": "The paper's main conclusion about the mathematical inequivalence of Einstein and Jordan frames is invalidated.",
        "Location": "Abstract (page 1), Section 3.3 (page 5), and Section 5 (page 8).",
        "Explanation": "The central claim that Einstein and Jordan frames are mathematically inequivalent is based on comparing the standard Einstein equations (transformed using the incorrect rules) with the equations of motion derived from their non-standard Jordan frame action (Eq. 10). Since this Jordan frame action is not the one generally understood to be conformally equivalent to the Einstein-Hilbert action, the demonstrated incompatibility (Eq. 24 vs. Eq. 20) does not prove inequivalence for the standard frames discussed in the literature. The conclusion of inequivalence applies only to the relationship between General Relativity and the specific, non-standard scalar-tensor theory defined by Eq. (10)."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 16312,
      "output": 681
    }
  },
  {
    "entry_id": 141,
    "retraction_id": "1903.00526v2",
    "paper_id": "1903.00526v1",
    "retraction_comment": "An error occurs in Section 5. Post-measurement results in the RTO experiment are improperlystated to directly apply to the entangled measurement state itself. This puts the conclusions stated in the abstract into question",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental Misinterpretation of Product States",
        "Location": "Abstract; Page 1, Introduction (e.g., paragraph 4); Page 5, first paragraph.",
        "Explanation": "The proposed interpretation of a product state |A1>|B1> as 'A has property |A1> if and only if B has property |B1>' is inconsistent with the established definition and role of product states in quantum mechanics. Product states like |A>|B> describe statistically independent (uncorrelated) subsystems, where subsystem A is in state |A> and subsystem B is in state |B> independently. The 'if and only if' (iff) construction imposes a strict, inherent correlation between the properties of A and B, which is characteristic of entangled states, not product states. This redefinition alters the fundamental meaning of how states of composite systems are constructed."
      },
      {
        "Problem": "Flawed Justification for Reinterpreting Product States from Entangled State Behavior",
        "Location": "Page 4, discussion of RTO experiment and Table 1; Page 5, first paragraph.",
        "Explanation": "The paper argues that the behavior of subsystems in entangled states (e.g., in RTO experiments, individual photons are in mixed states while their joint correlations show interference) necessitates a reinterpretation of product state terms like |A1>|B1> as correlations themselves ('A1 iff B1'). This justification is logically flawed. Standard quantum mechanics already explains these phenomena without redefining product states; the entanglement and its observable consequences arise from the superposition of product states (as conventionally understood), not from an inherent correlational meaning within each product state term."
      },
      {
        "Problem": "Failure to Resolve the Measurement Problem Regarding Outcome Selection",
        "Location": "Abstract; Page 1, last paragraph; Page 5, first paragraph; Page 7, Conclusion.",
        "Explanation": "The paper claims its reinterpretation of product states resolves the problem of definite outcomes and the measurement problem. However, it fails to adequately explain the crucial step of how a single, specific measurement outcome is actualized from a superposition. Interpreting an entangled state like (|A1>|B1> + |A2>|B2>)/√2 as a superposition of 'correlations' (e.g., 'A1 iff B1' and 'A2 iff B2') does not inherently make the overall state 'definite' nor does it provide a mechanism for why one specific correlation (and thus one specific pair of outcomes like A1, B1) is realized upon measurement over the other. The core issue of outcome selection remains unaddressed."
      },
      {
        "Problem": "Mischaracterization of the Standard Interpretation of Entangled States",
        "Location": "Page 1, paragraph 3; Page 4, paragraph starting 'The conventional physical interpretation...'.",
        "Explanation": "The paper misrepresents the standard interpretation of entangled states, creating a strawman argument. It claims the conventional interpretation of an entangled state like (|A1>|B1> + |A2>|B2>)/√2 means 'A and B have properties |A1> and |B1> respectively AND they also have properties |A2> and |B2> respectively.' This is incorrect. Standard quantum mechanics describes this as a superposition of possibilities, where subsystems A and B do not possess definite properties corresponding to these terms simultaneously before measurement. This mischaracterization incorrectly motivates the need for the proposed new interpretation of product states."
      },
      {
        "Problem": "The Reinterpretation Does Not Remove the Paradox of Macroscopic Superpositions",
        "Location": "Page 1, paragraph 3; Page 5, paragraph 1; Page 7, Conclusion.",
        "Explanation": "The paper asserts that its reinterpretation renders the entangled measurement state (which can involve macroscopic detectors) 'non-paradoxical.' However, rewriting an entangled state like (|A_micro>|B_macro1> + |A_micro'>|B_macro2>)/√2 as a superposition of correlations (e.g., 'A_micro iff B_macro1' and 'A_micro' iff B_macro2') does not eliminate the core conceptual difficulty of macroscopic superpositions. The detector (B) is still described as being part of a quantum superposition involving its macroscopically distinct states (|B_macro1> and |B_macro2>). The 'iff' linkage does not alter the fact that the detector's state is not a single, definite macroscopic state prior to the selection of one outcome, which is central to the paradox."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 9282,
      "output": 1004
    }
  },
  {
    "entry_id": 142,
    "retraction_id": "1503.07411v2",
    "paper_id": "1503.07411v1",
    "retraction_comment": "This paper has been withdrawn due to a gap in the proof of Proposition 2.19",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Lemma 3.7, asserting that singular points of the constructed varieties X_n are not weak maximal centers, is obscure and contains a questionable calculation.",
        "Location": "Page 16-17, Lemma 3.7, proof.",
        "Explanation": "The proof aims to apply Lemma 2.22 by finding suitable test curves. It introduces a divisor S_λ_bar (denoted S̃_λ in the paper) via the equality S̃_λ = -φ*Kx - (1/2)E without clear derivation from the previously mentioned hyperplane sections S_λ. The crucial intersection calculation, given as '(-φ*Kx - 1/2 E)^2 . (φ*F - 2E) = 2 - 1/2 * 4 = 0', is presented without sufficient derivation of its constituent terms or clear connection to the condition (-K_Y . C_λ) ≤ 0 for the test curves C_λ. The argument is too condensed and its steps are not transparent, making the conclusion that singular points are not weak maximal centers inadequately supported. This lemma is critical for verifying condition (5a) of Theorem 1.1 for the varieties X_n, and thus for the subsequent Theorem 3.8."
      },
      {
        "Problem": "Lemma 2.12 states a strict inequality that appears to be false in one of the cases considered in its proof.",
        "Location": "Page 7, Lemma 2.12, specifically the proof part 'Assume that a(0,x1,x2) = 0'.",
        "Explanation": "In this case, after appropriate substitutions, the proof considers Γ = (y=x₀=0) and Ξ = (y=b=0) on a surface S with K_S = O_S(-1) (so -K_S = O_S(1)). The calculation leads to (Γ·Ξ)_S = 3 and (−K_S·Ξ) = deg_P(Ξ) = 3. Therefore, (Γ·Ξ)_S = (−K_S·Ξ), which contradicts the lemma's claim of a strict inequality (Γ·Ξ)_S > (−K_S·Ξ). While the argument in Proposition 2.13 (which uses Lemma 2.12) might potentially be robust if it only requires a non-strict inequality (≥) from Lemma 2.12, the lemma as stated and proven is inaccurate. This inaccuracy could affect the strength of Proposition 2.13 in excluding certain curves as weak maximal centers."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 16657,
      "output": 578
    }
  },
  {
    "entry_id": 143,
    "retraction_id": "1602.03949v2",
    "paper_id": "1602.03949v1",
    "retraction_comment": "This paper has been withdrawn by the author due to the different description of second-order correlation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially Invalid SNR Metric due to Lack of Output Image Normalization",
        "Location": "Equation (1), Section 2 (page 1), Fig. 2, Fig. 3",
        "Explanation": "The SNR definition (Eq. 1) calculates error between the reconstructed image O(x,y) and the binary object pattern S(x,y). Ghost imaging reconstructions O(x,y) are typically correlation values whose scale, offset, and range (e.g., potentially including negative values) are not inherently matched to the binary [0,1] range of S(x,y). The paper does not specify any normalization or scaling of O(x,y) prior to SNR calculation. This mismatch can lead to arbitrary or misleading SNR values, as the error term (S(x,y) - O(x,y))^2 would be highly dependent on this scaling. This could invalidate all reported quantitative SNR results, comparisons between filter performances, and the primary conclusions drawn from them."
      },
      {
        "Problem": "Unaddressed Background Noise in the Reference Arm",
        "Location": "Fig. 1 (Experimental setup), Section 1 (page 1, rationale for single-arm filtering), Section 2 (page 1, setup description)",
        "Explanation": "The experimental setup indicates that broadband background light is mixed with the signal light before the beamsplitter (BS1) and thus contaminates both the object arm and the reference (idler) arm. While the object arm (leading to the bucket detector) is filtered, the reference arm (providing spatial patterns for correlation) is not. Significant, unfiltered background noise in the reference arm will degrade the quality of the reference patterns I_R(x,y). Since ghost imaging relies on the correlation between the bucket signal and these reference patterns, noise in I_R(x,y) will inherently limit the achievable SNR of the reconstructed image, potentially undermining the claimed effectiveness and upper limit of SNR improvement attributed solely to filtering the object arm."
      },
      {
        "Problem": "Ambiguity and Questionable Validity of Direct Imaging SNR Assessment",
        "Location": "Fig. 3, discussion on page 2",
        "Explanation": "The paper claims that filtering has an 'insignificant and irregular' effect on direct imaging SNR (Fig. 3), which shows consistently high SNR values. Firstly, if Equation (1) is used for direct imaging SNR, it suffers from the same potential normalization flaw as Problem 1. Secondly, the 'irregular' behavior is unexplained and could indicate measurement instability or an inappropriate metric. Thirdly, if direct imaging SNR is indeed very high and largely unaffected by the background that filters target, it might imply that the simulated background conditions are not sufficiently challenging to robustly demonstrate GI's advantages or the benefits of filtering, or that the SNR metric is insensitive to the specific noise characteristics. This makes it difficult to properly contextualize the improvements seen in GI."
      },
      {
        "Problem": "Unclear Control and Impact of Iris in Reference Arm",
        "Location": "Fig. 1 (Experimental setup), Section 2 (page 1, sentence 'Adjusting the iris...')",
        "Explanation": "An iris is shown in the reference arm path in Fig. 1, and the text states it is used for controlling the 'portion of background light getting to the camera'. It is not specified whether the iris setting is kept constant across all experiments (with different filters in the object arm) or if it is adjusted. If adjusted (e.g., to maintain a certain light level or signal-to-background ratio in the reference arm), this introduces a confounding variable that is not discussed and could significantly affect the correlations and thus the GI results. If it is fixed, its specific setting and its effect on the reference arm's signal and background levels are not detailed, making it hard to assess the reference arm's quality and its impact on the overall GI performance, especially in relation to Problem 2."
      }
    ],
    "token_usage": {
      "input": 640,
      "thinking": 7965,
      "output": 860
    }
  },
  {
    "entry_id": 144,
    "retraction_id": "2203.01307v2",
    "paper_id": "2203.01307v1",
    "retraction_comment": "Lemma 2.1 is true for Heisenberg type groups, but in general not for M_tivier groups, cf. Eq. (2.4) of M_ller and Stein [MS94]",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed argument for the 'large eigenvalues' part of the multiplier decomposition (g_>ι)",
        "Location": "Page 14, Section 6, Proof of Proposition 6.1, end of step (3)",
        "Explanation": "The estimation of ||g_>ι||_p involves a sum of terms derived from Proposition 4.2 (a p->2 estimate) and Hölder's inequality. The resulting expression for the norm appears to be C * 2^(ι * (d1+d2)(1/p-1/2)) * ||F^(ι)ψ||_L2 * ||f||_p. Since (d1+d2)(1/p-1/2) is generally positive for p < 2 (d=d1+d2 is the topological dimension), this term grows exponentially with ι. However, the proof requires this term to be bounded by 2^(-ει) * ||F^(ι)||_L2 * ||f||_p, which implies decay. The transition from the derived growing term to the required decaying term is not justified and seems incorrect, potentially invalidating the handling of the l > ι part of the decomposition."
      },
      {
        "Problem": "Potential inconsistency or lack of clarity in the normalization and properties of Laguerre functions φ_k^λ",
        "Location": "Page 7, Eq (2.10); Page 12, Proof of Proposition 5.1 (steps (5.5)-(5.6))",
        "Explanation": "The definition of φ_k^λ in Eq (2.10) involves a sum of normalized Hermite functions Φ_ν,ν'^λ, scaled by (2π)^(n/2)|λ|^(n/2) (the (2π)^(n/2) is likely a typo for (2π)^(-n/2)). If this definition is taken literally, ||φ_k^λ||_L2(R^2n)^2 would not be 1 but would include a factor N_k ~ k^(n-1) (the number of terms in the sum). The proof of Proposition 5.1 appears to rely on the orthogonality of φ_k^|μ| to move from (5.5) to (5.6), effectively treating them as an orthonormal set, which would mean N_k is absorbed or absent. If N_k is present, the exponent in the result of Proposition 5.1 would change from 2l(2α-d2) to 2l(2α+n-1-d2). While this change might not invalidate the subsequent use of Prop 5.1 for kernel support arguments (due to large N choices), it indicates a lack of precision that could affect other parts or the sharpness of constants/exponents if not handled carefully throughout."
      },
      {
        "Problem": "Unclear justification for the inequality R_l^(d1-d2) R_i^(2d2) <= 2^(i(d1+d2)) in the heuristic argument",
        "Location": "Page 4, paragraph before Eq (1.7)",
        "Explanation": "The heuristic argument on page 4 states: 'Since G is a Métivier group, we have d2 < d1. Together with l < ι, we obtain R_l^(d1-d2) R_ι^(2d2) ~ 2^((l-ι)(d1-d2)) 2^(ι(d1+d2)) <= 2^(ι(d1+d2))'. The term R_l^(d1-d2) R_ι^(2d2) seems to be a misstatement of the volume factor (R_l^d1 R_ι^d2)^(1/q) from (1.7) or a related quantity. More importantly, the condition d2 < d1 is asserted as a general property of Métivier groups, but Métivier groups can include Heisenberg-type groups where d1 can be equal to d2. If d1=d2, the factor 2^((l-ι)(d1-d2)) becomes 1, meaning no decay is gained from this specific term. While this is a heuristic argument, relying on d2 < d1 without proper context (e.g., explicitly excluding Heisenberg-type groups or those with d1=d2 for this part of the heuristic) can be misleading. The main proof in Section 6 needs to correctly handle cases where d1=d2 if they are not excluded by the theorem's hypotheses."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 20972,
      "output": 1012
    }
  },
  {
    "entry_id": 145,
    "retraction_id": "2112.10980v2",
    "paper_id": "2112.10980v1",
    "retraction_comment": "There is an error in the proof of the co-primality statement in Proposition 6. The author has constructed examples of knots with integer surgeries so that the orders of the groups generated by these knots and their surgery duals have a non-trivial common factor, so in fact the co-primality statement in Proposition 6 is false",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation of the self-intersection formula |ι(Σ̂K, Σ̂K)| = |K||K*|.",
        "Location": "Page 4, Proof of Proposition 6, first paragraph.",
        "Explanation": "The derivation of the formula |p| = |K||K*| (where p = ι(Σ̂K, Σ̂K)) from the long exact sequence of the pair (W, ∂W) is problematic. The argument states 'it follows that B|Tors(H₂(W,∂W)) is injective' (where B is the map A from H₂(W,∂W) to H₁(∂W) in the paper's notation for sequence (1)) without justification. More critically, the step concluding '|p| = |K||H₁(Y*)|/|H₁(W)| = |K||K*|' does not clearly follow from the preceding homological algebra relating orders of image and kernel of maps in the sequence. The connection between 'p' (the self-intersection number) and the expression |K||H₁(Y*)|/|H₁(W)| is not established by the argument. The derivation appears to contain logical gaps or incorrect deductions from the exact sequence properties."
      },
      {
        "Problem": "Unjustified assertions of specific intersection numbers in the proof of coprimality.",
        "Location": "Page 4, Proof of Proposition 6, second paragraph (regarding coprimality of |K| and |K*|).",
        "Explanation": "The proof that |K| and |K*| are co-prime relies on the assertions 'PD[x, -K][Σ̂K*] = ι(x, Σ̂K*) = |K*|' and 'PD[x*, K*][Σ̂K] = ι(x*, Σ̂K) = |K|' (assuming Σ̂K* is equivalent to Σ̂K in this context). These specific integer values for the intersection numbers of the surfaces x and x* (related to K and K* respectively) with Σ̂K are stated without derivation or reference to a source that would establish them in the given context (surgery on a knot in a rational homology sphere). The validity of these crucial equalities is not substantiated within the paper."
      },
      {
        "Problem": "Confusing and potentially incorrect statements regarding homology maps and identifications preceding Proposition 6.",
        "Location": "Page 3, last paragraph before Proposition 6.",
        "Explanation": "The paragraph aiming to set up the calculation of ι(Σ̂K, Σ̂K) contains confusing statements. For instance, 'In turn, there is an identification H₂(W, ∂W) ≃ Z ⊕ H₁(W) such that the map A is given by [Σ̂K] mapsto (p, α)'. Here, A is the boundary homomorphism H₂(W, ∂W) → H₁(∂W) from exact sequence (1). The element [Σ̂K] is in H₂(W), not H₂(W, ∂W). If the statement refers to the image of [Σ̂K] under the inclusion i: H₂(W) → H₂(W, ∂W), say i([Σ̂K]), then A(i([Σ̂K])) must be 0 by exactness of the sequence. This contradicts the claim that A maps this element to (p, α) if p = ι(Σ̂K, Σ̂K) is non-zero. Such misstatements undermine the clarity and correctness of the setup for Proposition 6."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 14251,
      "output": 780
    }
  },
  {
    "entry_id": 146,
    "retraction_id": "2006.16461v2",
    "paper_id": "2006.16461v1",
    "retraction_comment": "withdrawn due to an error in Lemma 4.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The recurrence relation for N(n,p,q) in Lemma 4.2 is inconsistent with the established base cases for n=1.",
        "Location": "Lemma 4.2 (page 12, Equation 1), its coefficient a_{k,n} (page 13, first line after Equation (1)), and its application to n=1 using N(1,p,q)=r (Theorem 3.4, page 7) and N(0,p,q)=s (Conventions, page 9).",
        "Explanation": "When n=1, Lemma 4.2 simplifies to N(1,p,q) = a_{1,1} * N(0,p,q), where a_{k,n} is the coefficient from page 13 ( (2n-k choose k) + (2n-k-1 choose k-1) ). For n=1, k=1, this coefficient a_{1,1} evaluates to 2. This implies N(1,p,q) = 2 * N(0,p,q), which translates to r = 2s using the paper's definitions of r, s, N(1,p,q), and N(0,p,q) which are based on Honda's work. However, the condition r=2s is not generally true (e.g., for (p,q)=(3,1), Honda's classification gives r=3 and s=2, for which r != 2s). This fundamental inconsistency invalidates Lemma 4.2 and, consequently, the main theorem derived from this recurrence."
      },
      {
        "Problem": "The combinatorial coefficient in the recurrence relation (Lemma 4.2) lacks clear justification for its dependence on '2n total components' instead of a quantity related to np.",
        "Location": "Lemma 4.2 (page 12) and the definition of its coefficient a_{k,n} (page 13, described as 'number of ways to pick k nonadjacent components from the 2n total components').",
        "Explanation": "The recurrence in Lemma 4.2 is derived using an inclusion-exclusion argument based on bypass attachments on the meridian disk D. Bypasses on D are associated with the np arcs of the dividing set Γ_D. The non-adjacency condition for bypasses (Proposition 3.10) is also described in terms of components on D. Therefore, the number of ways to choose k non-adjacent bypass 'slots' would intuitively depend on np (the number of arcs of Γ_D) or 2np (points on ∂D). The paper's coefficient a_{k,n} is for choosing k non-adjacent items from 2n items in a circle. The argument for using 2n (presumably referring to the 2n components of Γ_∂M on the boundary torus) as the relevant parameter for counting non-adjacent bypasses on the disk D is not sufficiently established. This choice likely leads to the inconsistency described in the first problem."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 14088,
      "output": 681
    }
  },
  {
    "entry_id": 147,
    "retraction_id": "1811.02204v3",
    "paper_id": "1811.02204v2",
    "retraction_comment": "Some arguments in the proof of Thm. 2.3.3 are erroneous. One of the faulty arguments lies in the estimate on the first line of page 24. The author mistakenly treats the orthogonal decomposition with respect to the unweighted inner product as the one with respect to the weighted one. Contents which are free from irreparable errors are contained in arXiv:1912.08076",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect positivity assumption for auxiliary metric in higher codimension case",
        "Location": "Page 21-22 (Proof of Theorem 2.3.3, definition of ω_b)",
        "Explanation": "The proof for extending sections from lc centres of codimension σ ≥ 2 (Theorem 2.3.3) introduces an auxiliary Kähler metric ω_b = ω + b(i∂∂(φ_L+ψ) - i∂∂log|ψ|^σ). For ω_b to be Kähler, the (1,1)-form A = i∂∂(φ_L+ψ) - i∂∂log|ψ|^σ must be positive semi-definite. The paper claims this follows from assumption (1) and (2)_σ (page 21, bottom). However, A = i∂∂φ_L + (1 - σ/|ψ|)i∂∂ψ + (σ/|ψ|^2)i∂ψ∧∂ψ. Given assumption (1) (i∂∂φ_L + (1+β)i∂∂ψ ≥ 0), A ≥ (-β - σ/|ψ|)i∂∂ψ + (σ/|ψ|^2)i∂ψ∧∂ψ. Since β ≥ 0 and σ/|ψ| > 0, the coefficient (-β - σ/|ψ|) is negative. If i∂∂ψ is positive, this term is negative and potentially dominant, especially when |ψ| is small (near the singular locus S). Thus, A may not be positive semi-definite, meaning ω_b may not be Kähler, invalidating the subsequent Bochner-Kodaira argument."
      },
      {
        "Problem": "Inconsistent normalization conditions for the potential ψ",
        "Location": "Theorem 2.2.1 (page 10-11), Theorem 2.3.3 (page 20), and main Theorems 1.3.2 (page 6), 1.3.3 (page 7)",
        "Explanation": "The normalization conditions imposed on the potential ψ differ significantly across key theorems. For σ=1, Theorem 2.2.1 requires ψ < -e/l and (2/l)|log(e/|ψ|)| + 1/|ψ| ≤ δ. For σ≥2, Theorem 2.3.3 requires ψ < -eσ/l and (5/l)|log(eσ/|ψ|)| + σ/|ψ| ≤ δ. The main Theorem 1.3.2 uses a condition similar to Theorem 2.3.3 with σ_S (max σ_f). These differing numerical coefficients (e.g., 2/l vs 5/l) and dependencies (1/|ψ| vs σ/|ψ|) are problematic because the proofs (e.g., page 14 for Thm 2.2.1, page 24 footnote 8 for Thm 2.3.3) rely on these specific forms to satisfy crucial inequalities. It's unclear how these distinct conditions are reconciled or if the condition in the main theorem implies the ones used in the intermediate proofs for all relevant σ."
      },
      {
        "Problem": "Restrictive KLT singularity assumption for the definition/properties of lc-measure",
        "Location": "Proposition 3.0.1, condition (†) (Page 31), and its relation to Set-up 1.2 (Page 3)",
        "Explanation": "Proposition 3.0.1, which is crucial for the well-definedness and calculation of the 'lc-measure' (the central new measure in the paper), assumes in condition (†) that the potential φ_L of the line bundle L has only Kawamata log terminal (klt) singularities. This is a very strong restriction. The general set-up of the paper (Section 1.2, item 1) only assumes φ_L has 'neat analytic singularities,' which can be much more singular than klt (e.g., log canonical but not klt). If the definition and properties of the lc-measure fundamentally rely on φ_L being klt, the main theorems of the paper would apply to a much narrower class of line bundles than suggested by the initial setup. Remark 3.0.4 mentions this assumption might be relaxed if the section f has sufficient vanishing orders, but the main theorems do not assume such vanishing for f."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 12520,
      "output": 975
    }
  },
  {
    "entry_id": 148,
    "retraction_id": "1303.6535v2",
    "paper_id": "1303.6535v1",
    "retraction_comment": "Crucial flaw in proof of Theorem 3. The argument only gives a lower bound, not purity as claimed (the latter most likely does not hold except for in small rank)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency in Homogenoeus Group Calculation",
        "Location": "Page 1, formula Ext*(Δv, Δw) = Hc*+l(w)-l(v)(C^v ∩ Cw); Page 2, Proof of Corollary 2",
        "Explanation": "The paper states Ext^k(Δv, Δw) = Hc^(k+l(w)-l(v))(C^v ∩ Cw). For k=0 (Hom groups), and v < w, C^v ∩ Cw is an affine space of dimension d = l(w)-l(v) > 0. Thus, Hom(Δv, Δw) = Hc^d(A^d). Standard results for compactly supported cohomology imply Hc^d(A^d) = 0 for d > 0. This means Hom(Δv, Δw) = 0 if v < w. This contradicts the paper's statement (Proof of Corollary 2) that 'dim Hom(Δx, Δy) = 1 if and only if x ≤ y', which is standard for the chosen Verma module definition. This fundamental contradiction undermines Corollary 2 and subsequent arguments relying on non-zero Hom groups or their Hodge structures derived via this formula."
      },
      {
        "Problem": "Incorrect Isomorphism in Corollary 3(ii)",
        "Location": "Page 2, Corollary 3(ii)",
        "Explanation": "Corollary 3(ii) claims Ext¹(Δv, Δw) ⊕ Q^H(-1) ≅ Ext¹(Δv, Δws) under conditions vs > v and vs ≠ ws. This is derived from Proposition 1(ii), where C^v ∩ Cw ≅ (C^v ∩ Cws) × C*. Applying the Künneth formula for compactly supported cohomology to C^v ∩ Cw, one would expect Ext¹(Δv, Δw) ≅ Ext¹(Δv, Δws) ⊗ Hc¹(C*) (adjusting for cohomology degrees). Hc¹(C*) ≅ Q^H(-1). The stated additive relationship (A ⊕ L ≅ B) is different from the expected multiplicative one (A ≅ B ⊗ L) and is unlikely to hold generally. This error impacts Theorem 4 and Corollary 5, which rely on Corollary 3."
      },
      {
        "Problem": "Potentially Flawed Dimension Formula Derivation in Corollary 5(iii)",
        "Location": "Page 2, Corollary 3(iii) and Corollary 5(iii)",
        "Explanation": "Corollary 5(iii) gives dim Ext¹(Δv, Δw) = dim Ext¹(Δv, Δws) under conditions vs > v and vs ≤ ws. This dimension formula appears to be derived from the exact sequence in Corollary 3(iii). Taking dimensions in that sequence: 0 → Q^H(-1) → Ext¹(Δv, Δw) ⊕ Q^H(-1) → Ext¹(Δv, Δws) → Ext¹(Δvs, Δw)(-1), leads to dim Ext¹(Δv, Δw) + 1 = 1 + dim Ext¹(Δv, Δws) - dim Ext¹(Δvs, Δw) + dim(Im of last map). For Corollary 5(iii) to hold, it seems to require dim Ext¹(Δvs, Δw) = 0 (and the last map to be zero). However, Ext¹(Δvs, Δw) is not generally zero under the given conditions (e.g., if w covers vs). This suggests an issue in the derivation or applicability of the dimension formula."
      },
      {
        "Problem": "Issues in the Proof of Theorem 4",
        "Location": "Page 2, Proof of Theorem 4",
        "Explanation": "The proof of Theorem 4 (Ext¹(Δv, Δw) is pure of weight 2) relies on Corollary 3 and induction. If Corollary 3(iii) is used, the argument involves a long exact sequence. For Ext¹(Δv, Δw) to be pure of weight 2, other terms in the sequence must behave well. Specifically, the term Ext¹(Δvs, Δw)(-1) would be pure of weight 4 if Ext¹(Δvs, Δw) is pure of weight 2. An exact sequence involving Hodge structures of different pure weights (e.g., weight 2 and weight 4) does not generally guarantee that all terms are pure of a single weight. The proof does not adequately address this, making the purity claim for Ext¹(Δv, Δw) not fully substantiated."
      },
      {
        "Problem": "Misstatement Regarding R-polynomials and Hodge-Euler Polynomials",
        "Location": "Page 2, Concluding observation (ii)",
        "Explanation": "Concluding observation (ii) states that 'the Kazhdan-Lusztig R-polynomials are the Hodge-Euler polynomials of the C^v ∩ Cw'. This statement is incorrect. Firstly, R-polynomials are distinct from Kazhdan-Lusztig polynomials (P_{x,y}(q)). Secondly, R-polynomials are generally not the Hodge-Euler polynomials of the intersection of Schubert cells C^v ∩ Cw (which are affine spaces, C^v ∩ Cw ≅ A^(l(w)-l(v))). The Hodge-Euler polynomial of A^d is simple (e.g., q^d under certain conventions) and typically not equal to R_{v,w}(q). This mischaracterization of known mathematical objects is a significant conceptual error."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 18624,
      "output": 1269
    }
  },
  {
    "entry_id": 149,
    "retraction_id": "1204.0036v3",
    "paper_id": "1204.0036v2",
    "retraction_comment": "This paper has been withdrawn by the authors because Lemma 11, for p>1, is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed n-dependency in the main complexity result (Theorem 3)",
        "Location": "Page 28 (derivation from Proposition 4 to the line \"(I) ≤ C'D^(3/2)DN n√N-n+1/2√n+1/2\") and consequently Theorem 3 (page 11).",
        "Explanation": "The derivation of the n^(3/2) term in the complexity bound of Theorem 3 appears to be arithmetically incorrect. Applying the stated Gamma function approximations (Γ(x+a)/Γ(x) ≈ x^a and Γ(x+1/2) ≤ √x Γ(x)) to the formula in Proposition 4, particularly considering the n-dependent terms from Eq. (26) (Γ(n²+n-q)/Γ(n²+n) ≈ (n²)^(-q) and n^(-3q)), leads to an overall n-dependency of approximately n^(-9/2) in the bound for (I), not n^(3/2) as claimed in Theorem 3. This significantly alters the interpretation of how complexity scales with the number of variables 'n'."
      },
      {
        "Problem": "Misleading statement of Theorem 2",
        "Location": "Page 11, Theorem 2.",
        "Explanation": "Theorem 2 states a bound for EH(d)(||θ_h||_Lp), the expected L_p norm. However, its derivation (particularly Lemma 11(ii), which introduces a factor of 1/p) and its subsequent application in Proposition 4 suggest that the bound provided is actually for EH(d)(||θ_h||_Lp^p), the expectation of the p-th power of the L_p norm. If the theorem were for EH(d)(||θ_h||_Lp), the p-th root of the right-hand side expression should have been taken. This lack of clarity is critical as Theorem 2 is a key component in deriving the main complexity result."
      },
      {
        "Problem": "Counter-intuitive implications of the corrected n-dependency in Theorem 3",
        "Location": "Theorem 3 (page 11) and its interpretation, if the n-dependency is corrected from n^(3/2) to n^(-9/2).",
        "Explanation": "If the n-dependency in Theorem 3 is corrected to n^(-9/2) (as suggested by the re-evaluation of the derivation from Proposition 4), the resulting complexity bound implies that the average cost of the algorithm decreases sharply as n (the number of variables/equations) increases. This is highly counter-intuitive for algorithms solving systems of polynomial equations. Such behavior would warrant significant discussion, and could potentially indicate that some bounds used in earlier stages (e.g., Eq. 26, which provides a bound on an average involving condition numbers) are either too loose or their application in this context leads to this unexpected scaling with 'n'."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 15957,
      "output": 666
    }
  },
  {
    "entry_id": 150,
    "retraction_id": "2111.11437v6",
    "paper_id": "2111.11437v5",
    "retraction_comment": "There is an error. In section 3.4, the author identifies $Hom_Q(M, _M)$ with the set $Mat_{r \\times r}$ through the decomposition of M into a direct sum of indecomposable modules, and discusses nilpotent matrices in $Mat_{r \\times r}$. This is misleading because here we do not have a natural ring structure on $Mat_{r \\times r}$",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Over-simplification in main condition via R(λ,κ) and insufficiently justified matrix structure for 'a' and 'b'.",
        "Location": "Theorem 1.2 (page 4), Theorem 3.11 (page 20), Lemma 3.10 (page 20), Remark 3.9 (page 17).",
        "Explanation": "The main theorems (e.g., Thm 1.2) state conditions for Ext¹(Mλ, Mκ)=0 based on R(λ,κ) and R(κ,λ), which are defined using only the first components (λ₁, κ₁) of the τ-orbit Kostant partitions λ and κ. This appears to be an over-simplification for modules like Mλ = ⊕M_{λ_i}. The justification relies on Lemma 3.8 (solutions of af-fb=0 determined by the first row of f), which is applied to specific matrix forms for 'a' (from Mλ*) and 'b' (from Mκ*). These 'a' and 'b' are assumed to be exact Jordan blocks with identities on the superdiagonal. The derivation of this precise structure (Lemma 3.10, supported by Remark 3.9) is brief, and its general validity for all relevant Mλ* (as elements of Hom_Q(Mλ, τMλ)) is critical but not extensively justified, potentially affecting the main conclusions."
      },
      {
        "Problem": "Potentially incorrect derivation of combinatorial terms m(λ,κ) and p(λ,κ).",
        "Location": "Proof of Theorem 3.12 (page 21, equations 3.20-3.23), Proposition 3.5 (page 15).",
        "Explanation": "The derivation of the combinatorial terms m(λ,κ) and p(λ,κ) in equation (3.23) of Theorem 3.12, which is crucial for Theorem 1.2, appears to misapply or inconsistently use Proposition 3.5. Specifically, the connection made in (3.20) between Γ_{λ,κ} \\ Γ_{λ,τκ} (i.e., pairs (i,j) where [λ_i, κ_j]=1 and [λ_i, κ_{j-1}]=0) and the condition λ_i - κ_j ∈ R⁺∪{0} (definition of m(λ,κ)) does not directly follow from Proposition 3.5. Proposition 3.5 case (2) applied to β=λ_i, α=κ_{j-1} (so τα=κ_j) implies λ_i + κ_{j-1} ∈ R⁺. Similar issues may exist for p(λ,κ). This potential mismatch undermines the correctness of the combinatorial conditions presented in the paper's main theorems."
      },
      {
        "Problem": "Ambiguity in the definition and usage of M* and its relation to the map 'a'.",
        "Location": "Definition 2.2 (page 11), page 4 (text below eq. 1.3), Lemma 3.10 (page 20), Theorem 4.4(1) (page 24).",
        "Explanation": "There is an ambiguity in how M* is defined and utilized. Definition 2.2 defines M* for a Q-representation M as a special set or orbit of self-extensions (elements of D Ext¹_Q(M,M)). However, when defining an AQ-module as (M_Q, a), the map 'a' ∈ Hom_Q(M_Q, τM_Q) is identified with M* or referred to as 'the dual of M' (e.g., page 4; Lemma 3.10 refers to Mλ* as 'a'). The precise conceptual link between the set/orbit M* from Definition 2.2 and the specific map 'a' is not clearly established. This is problematic as crucial properties of 'a', such as its specific Jordan block structure asserted in Lemma 3.10, are fundamental to the paper's central arguments about the map r_{a,b}."
      },
      {
        "Problem": "Potential inconsistency or flawed reasoning concerning Corollaries 4.8 and 4.9.",
        "Location": "Corollary 4.8 (page 28) and Corollary 4.9 (page 30).",
        "Explanation": "Corollary 4.8 provides conditions for Ext¹_A(Mλ, Mκ) = 0. Corollary 4.9 states that dim Ext¹_A(Mλ, M_{τλ}) = 1, citing a known result. The proof of Corollary 4.9 claims to use arguments from Corollary 4.8's proof (specifically, that r_{λ,τλ} is surjective, implying one Coker term in Proposition 4.5 is zero). If the pair (λ, τλ) were to fully satisfy all conditions of Corollary 4.8, then Ext¹_A(Mλ, M_{τλ}) should be 0, which contradicts Corollary 4.9. The paper does not adequately clarify whether (λ, τλ) meets all conditions of Corollary 4.8 or robustly explain why only parts of its proof methodology are applicable, leading to a potential inconsistency between these two results or their justifications."
      },
      {
        "Problem": "Questionable steps in the proof of Theorem 4.4(3) regarding module rigidity.",
        "Location": "Theorem 4.4(3) and its proof (pages 24-25).",
        "Explanation": "The proof that an AQ-module T=(T_Q, T*) is rigid (i.e., Ext¹_A(T,T)=0) if Ext¹_Q(T_Q,T_Q) admits an open Aut_Q(T_Q)-orbit contains several steps that appear problematic. For instance, the proof asserts (page 25, line after eq. 4.13) 'dim Aut_A(T) = dim Hom_A(T,T) = (α,α)_Q', where (α,α)_Q is the Euler form for Q. The equality dim Hom_A(T,T) = (α,α)_Q is not generally true. The argument seems to conflate Hom spaces and Euler forms over the quiver algebra Q with those over the preprojective algebra AQ, potentially invalidating the proof of this supporting theorem."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 15063,
      "output": 1458
    }
  },
  {
    "entry_id": 151,
    "retraction_id": "0912.4084v3",
    "paper_id": "0912.4084v2",
    "retraction_comment": "This paper has been withdrawn by the author. Paper is withdrawn. On review the paper contributes nothing of significance. The runtime analysis of the algorithms presented, while correct in terms of number of operations, does not represent the complexity of the algorithms in terms of \"bits input\". A naive mistake in reasoning",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misleading Definition of Polynomial Time and Complexity Metric",
        "Location": "Abstract; Page 2, Paragraph 2; and throughout all complexity analyses (e.g., Page 3, Page 5, Page 6)",
        "Explanation": "The paper claims polynomial time complexity where 'n' is the *magnitude* of the integer to be factored. Standard cryptographic and algorithmic complexity for integer factorization is measured in terms of the *bit length* of 'n' (i.e., log n). An algorithm that is polynomial in the value 'n' is exponential in its bit length, rendering it inefficient for large numbers typically considered in factoring. This fundamental misrepresentation of 'polynomial time' invalidates the significance of the claimed complexity bounds (e.g., O(n^2.5), O(n^1.5 log10n)) as efficient solutions in the accepted sense."
      },
      {
        "Problem": "Incorrect Cost of Arithmetic Operations in Complexity Analyses",
        "Location": "Page 3, Section 2.1.1 (Algorithm 1); Page 5, Section 3.2.2 (Algorithm 2 Sieve); Page 6, Section 3.2.3 (Algorithm 2 Filter)",
        "Explanation": "Throughout the paper, the complexity analyses incorrectly assume that arithmetic operations (like addition or comparison) on numbers of magnitude 'n' take O(n) or O(log10 n) time related to the value 'n' itself, rather than being polynomial in the number of bits (log n). For instance, page 3 states arithmetic operations take 'O(n) in the number of bits of the operands' which is then seemingly interpreted as a factor proportional to 'log10 n' (value) or even 'n' (value) in subsequent derivations (e.g. Loop 3 and Loop 5 of Algorithm 2, Filter Process of Algorithm 2). This consistently inflates and invalidates the derived time complexities."
      },
      {
        "Problem": "Flawed Complexity Analysis of Algorithm 1 (Difference Expression)",
        "Location": "Page 3, Section 2.1.1",
        "Explanation": "The derivation of O(n log10 n) for Algorithm 1 (decomposition) is unsound. The bound for Loop 2 iterations (inner loop) is claimed as O(n^0.5 * (ln n^0.5 + gamma)), which is not clearly justified for the described operations in a worst-case scenario. The algorithm essentially performs trial division. Combined with the incorrect arithmetic cost (see Problem 2), the resulting complexity is not credible. The algorithm is expected to be exponential in the bit length of n."
      },
      {
        "Problem": "Unsound Complexity Analysis for Algorithm 2 (Sieve and Filter Processes)",
        "Location": "Page 5, Section 3.2.2 (Sieve Process); Page 6, Section 3.2.3 (Filter Process)",
        "Explanation": "The O(n^2.5) complexity derived for Algorithm 2's Sieve Process (e.g., Loop 3 and Loop 5 analysis) and Filter Process is based on flawed assumptions. Beyond the incorrect arithmetic cost (Problem 2), the multiplication of loop iteration bounds appears problematic. For example, Loop 3's complexity on page 5 starts with an unjustified 'O(n * ...)' factor, and Loop 5's complexity is claimed as 'O(n * sqrt(n) * sqrt(n) * sqrt(n))'. A standard sieve to sqrt(N) is much faster, and trial division (Filter Process) with these primes would not reach O(N^2.5) if analyzed with correct arithmetic costs and standard loop analyses."
      },
      {
        "Problem": "Incorrect Analysis of Recursive Application for Prime Factoring (Algorithm 1)",
        "Location": "Page 4, Section 2.1.2",
        "Explanation": "The paper claims that prime factoring using recursive application of Algorithm 1 involves a maximum of sqrt(n) executions of the decomposition algorithm. This is incorrect. The number of prime factors of 'n', and thus the number of recursive calls to find all prime factors, is bounded by O(log n), not O(sqrt(n)). This error, combined with the flawed base complexity of Algorithm 1, invalidates the claimed O(n^1.5 log10 n) complexity for prime factoring."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 6820,
      "output": 978
    }
  },
  {
    "entry_id": 152,
    "retraction_id": "2106.04691v2",
    "paper_id": "2106.04691v1",
    "retraction_comment": "Theorem 1.7 is established only under a restrictive hypothesis, not the generality that the authors assert",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Properness of the locally defined map $f$ in the proof of Theorem 1.7.",
        "Location": "Page 8, Section 2.2, item (c); justification linked to Section 3.1 and [GGR21b].",
        "Explanation": "The construction of $\\bar{\\mathcal{F}}^T$ as a compact Hausdorff analytic quotient $\\bar{B}/\\sim$ hinges on the properness of a locally defined map $f: \\mathcal{O} \\to \\mathbb{C}^d$ whose fibres are identified with those of the period mapping $\\Phi$. The paper asserts this properness is key and refers to other work for the detailed argument. If this map $f$ is not proper, or if its fibres do not correctly capture the fibres of $\\Phi$ including at the boundary $Z \\cap \\mathcal{O}$, the foundation of Theorem 1.7 (construction of $\\bar{\\mathcal{F}}^T$ as a well-behaved quotient space) is weakened."
      },
      {
        "Problem": "Validity and derivation of the 'Central Geometric Information' formula (3.23).",
        "Location": "Page 19, equation (3.23); details for related statements cited from [GGR21b, Section 3].",
        "Explanation": "Formula (3.23), $\\mathcal{L}_M|_{A^0} = (\\bar{\\Phi}^1|_{A^0})^*(\\mathcal{L}_M) = \\sum (M,N_i) N_{Z_i/\\bar{B}}|_{A^0}$, establishes a crucial link between Hodge-theoretic line bundles $\\mathcal{L}_M$ (on tori parametrizing level one extension data) and geometric normal bundles $N_{Z_i/\\bar{B}}$ on the compactification $\\bar{B}$. Many subsequent applications concerning ampleness and geometric properties of $\\bar{B}$ (e.g., Corollary 3.26, Conjecture 3.29, Proposition 3.30) depend directly on this formula. Its precise derivation, conditions for validity, and interpretation are critical for these applications."
      },
      {
        "Problem": "Geometric interpretation of $\\bar{\\Phi}^T$ for I-surfaces and resolution of moduli singularities.",
        "Location": "Page 32, Remark 5.4.",
        "Explanation": "Remark 5.4 states that for the KSBA moduli space $\\bar{M}_I$ of I-surfaces (surfaces with $K_X^2=1, p_g=2$), the map $\\bar{\\Phi}^T$ is locally 1-1 on the data $(X, C, \\{q_i\\})$ and its image is locally isomorphic to the blowup of the boundary stratum $N_2 \\subset \\bar{M}_I$. This is a strong and specific claim about $\\bar{\\Phi}^T$ resolving singularities of a moduli space. The justification 'One may check' suggests it's considered established or straightforward, but it's a significant geometric conclusion whose underpinnings are critical for understanding the geometric role of the constructed completion."
      },
      {
        "Problem": "Conditions for negative definiteness of intersection matrix in Proposition 3.34.",
        "Location": "Page 21, Proof of Proposition 3.34.",
        "Explanation": "The proof that $\\bar{\\Phi}^1$ is non-constant on some boundary component $Z_i$ (when $\\dim B=2$ and generic local Torelli holds) relies on the intersection matrix $||Z_i \\cdot Z_j||$ being negative definite, citing [GGLR20, Lemma 3.1.1]. The argument assumes that the conditions for this negative definiteness (e.g., related to the contractibility of $Z = \\bigcup Z_i$ to a point by $\\Phi^0$) are met. If these conditions are not satisfied under the hypotheses of Proposition 3.34 or are overly restrictive, the scope or validity of the proposition could be affected."
      }
    ],
    "token_usage": {
      "input": 11734,
      "thinking": 15241,
      "output": 930
    }
  },
  {
    "entry_id": 153,
    "retraction_id": "1308.2817v2",
    "paper_id": "1308.2817v1",
    "retraction_comment": "The paper has been withdrawn because Eq.(4) is incorrect (isospin CG coefficients have been omitted). The corrected results change some of the discussion for 48Ca while the conclusions for 208Pb are hardly effected. A revised manuscript is under preparation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Questionable formulation and justification of Eq. (4) for the ratio of unit cross sections.",
        "Location": "Page 3, Eq. (4) and surrounding text, including the reference to the 12C case [37].",
        "Explanation": "Equation (4) provides the ratio σ_M1στ / σ_GT = (1/2) * (2T_i - 1) / (2T_i + 1). This equation is fundamental to the entire method. However, its derivation is not detailed. More critically, for a target with T_i=0 (like 12C, which is mentioned as an experimental verification via [37]), the term (2T_i - 1) / (2T_i + 1) evaluates to -1, leading to a negative ratio, which is unphysical for cross sections. Reference [37] (Dozono et al.) for 12C actually states a ratio of (p,p')/(p,n) cross sections of 0.5, which is not reproduced by Eq. (4) with T_i=0. This discrepancy for T_i=0 casts serious doubt on the general validity or the stated form of Eq. (4), or at least on its applicability to all T_i values without further clarification or modification. Since this equation is used for 48Ca (T_i=4) and implicitly for 208Pb (T_i=22), any flaw in its derivation or general applicability is a critical issue."
      },
      {
        "Problem": "Strong assumption of identical nuclear structure matrix elements for analog M1 and GT transitions.",
        "Location": "Page 3, assumption (ii) and the interpretation of Fig. 3.",
        "Explanation": "The method assumes (assumption ii) 'identical matrix elements for the excitation of analog GT and spin-flip M1 transitions.' This implies that the reduced nuclear structure matrix elements |<f|| Σσκτκ ||i>|^2 in Eq. (3) are the same for the M1_στ transition and its analog GT transition. While Fig. 3 is presented as supporting evidence for 48Ca (showing that (dσ_pp') scaled by a factor derived from Eq. (4) matches dσ_pn), this agreement itself relies on the correctness of Eq. (4). If Eq. (4) is flawed, the conclusion drawn from Fig. 3 about the matrix elements may be incorrect. The assumption that these complex nuclear structure elements are 'identical' for different (though analog) transitions is very strong and its general validity, crucial for a broadly applicable method, is not independently established beyond the consistency check shown for 48Ca."
      },
      {
        "Problem": "Reliance on global systematics for the absolute scale of the unit GT cross section (σ_GT).",
        "Location": "Page 3, Eq. (5) and its application.",
        "Explanation": "The absolute value of B(M1_στ) is determined using σ_M1στ, which is derived from σ_GT (Eq. 4), where σ_GT is obtained from a mass-dependent parameterization (Eq. 5) based on (p,n) reaction systematics [40]. While uncertainties in this parameterization are propagated, the accuracy of such global systematics for any specific nucleus (like 48Ca or 208Pb) can be a limitation. If the actual σ_GT for the nucleus under study deviates systematically from the value predicted by Eq. (5), it will introduce a systematic error in the extracted B(M1_στ) and consequently B(M1) values. This is particularly important when comparing the results to high-precision data from other methods like (e,e')."
      },
      {
        "Problem": "Uncertainty in neglecting Coulomb distortion differences and other reaction mechanism effects.",
        "Location": "Page 3, assumption (i) 'isospin symmetry between the (p,p') and the analogous (p,n) reaction'.",
        "Explanation": "The method assumes that isospin symmetry holds for the reaction dynamics, and that distortion effects which could break this symmetry are 'negligible at a beam energy of about 300 MeV'. However, (p,p') and (p,n) reactions involve different outgoing particles (proton vs. neutron), leading to different final state Coulomb interactions. While high energies mitigate Coulomb effects, they may not be entirely negligible, especially for heavy nuclei like 208Pb. The paper relies on the consistency shown in Fig. 3 for 48Ca as evidence, but this is intertwined with other assumptions (Eq. 4, identical matrix elements). A more quantitative assessment of the potential impact of differential distortion effects on the ratio of unit cross sections would be necessary to firmly establish the method's precision, particularly for heavier systems."
      },
      {
        "Problem": "Approximations in relating extracted B(M1_στ) to the electromagnetic B(M1) value.",
        "Location": "Page 4, Eq. (7) and discussion.",
        "Explanation": "Equation (7) is used to convert the extracted hadronic quantity B(M1_στ) (isovector spin M1 strength) to the electromagnetic B(M1)↑ value. This conversion assumes that orbital M1 contributions are negligible and that isoscalar spin M1 contributions are also negligible. For 48Ca, a doubly magic nucleus, the orbital M1 strength is argued to be zero for pure configurations, and the isoscalar spin part is small due to g-factors. However, configuration mixing could introduce non-zero orbital components, and the complete neglect of these terms is an approximation. The paper mentions theoretical estimates for meson-exchange currents (MEC) differing between hadronic and electromagnetic probes are small ('a few per cent'), but the overall accuracy of Eq. (7) limits the precision of the final B(M1)↑ value intended for comparison with electromagnetic measurements."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 10510,
      "output": 1311
    }
  },
  {
    "entry_id": 154,
    "retraction_id": "1412.0982v2",
    "paper_id": "1412.0982v1",
    "retraction_comment": "This paper has been withdrawn by the authors. As pointed out to us by [REDACTED-NAME], [REDACTED-NAME] and [REDACTED-NAME], Theorem 3.1 is incorrect, namely, the zero locus should be larger than that in Theorem 3.1. We are sincerely grateful to them for their valuable comments. Nevertheless, the metrics we constructed have positive sectional curvature almost everywhere on the Gromoll-Meyer sphere and on the homotopy (not diffeomorphic) RP^7",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect representation of sp(2) elements and its implications",
        "Location": "Page 3, definition of T_I Sp(2) and Eq (2.1)",
        "Explanation": "Elements of the Lie algebra sp(2) at the identity, denoted T_I Sp(2), are given in matrix form as `xi = (x y; -y z)` where `x, z` are pure imaginary quaternions (Re(x)=Re(z)=0). For this matrix `xi` to satisfy the sp(2) condition `xi + xi^* = 0` (where `xi^*` is the conjugate transpose), the entry `-y` in the (2,1) position must be equal to `-(y^*)`, where `y^*` is the conjugate of the `y` in the (1,2) position. This implies `y = y^*`, meaning `y` must be a real quaternion (a scalar). This restricts `y` to be 1-dimensional. However, for the 10-dimensional Lie algebra sp(2), the off-diagonal block `y` can be any 4-dimensional quaternion. If `y` is restricted to be real, the algebra described is 7-dimensional (isomorphic to u(2)). If `y` in the formula (2.1) for the metric `g_r` is intended to be a general quaternion, the matrix representation `(x y; -y z)` is incorrect; it should be `(x y; -y^* z)`. This fundamental error in representing sp(2) elements potentially affects all subsequent calculations involving these matrices, including the metric definition, connection (Lemma 2.1), curvature formulas (Prop 2.2, Prop 2.3), and the analysis of zero-curvature planes (Section 3)."
      },
      {
        "Problem": "Unclear identification of the quotient space with the Gromoll-Meyer exotic sphere",
        "Location": "Page 9, Section 3, definition of Sigma^7 and action (3.1)",
        "Explanation": "The paper defines the Gromoll-Meyer sphere `Sigma^7` as the quotient `Sp(2)/S^3` resulting from the `S^3` action given in Eq (3.1): `u*A = diag(u,1) A diag(u_bar, u)`. It is critical for the main claim that this specific quotient manifold is diffeomorphic to *the* Gromoll-Meyer exotic 7-sphere (typically the generator of bP_8). Standard constructions of this specific exotic sphere often utilize different `S^3` (or `Sp(1)`) actions, for example, `A -> diag(u,u) A diag(u_bar,1)`. The paper cites Gromoll-Meyer [5] but does not explicitly show that the action (3.1) produces the intended exotic sphere or one diffeomorphic to it. If the action (3.1) yields a different manifold, the central claim of constructing a metric with positive sectional curvature on the Gromoll-Meyer exotic sphere would not be substantiated for that specific, well-known exotic sphere."
      },
      {
        "Problem": "Discrepancy in the derivation of the general curvature formula (Proposition 2.2)",
        "Location": "Proposition 2.2 (Page 4, statement) and its proof (Page 5, formula for alpha)",
        "Explanation": "Proposition 2.2 presents a key formula for the sectional curvature. The statement of the proposition includes a term `(3/4) * sum a_i(1-a_i)^3 ||[X_i, Y_i]||_Q^2`. However, in the proof on page 5, the derived expression for `alpha` (which contributes to the final curvature formula `K = alpha + 3/4 beta`) contains a similar term `(1/4) * sum a_i(1-a_i)^2 ||[X_i,Y_i]||_Q^2`. The power of `(1-a_i)` is different (3 in the statement vs. 2 in the derivation of `alpha`). The `beta` term (also on page 5) is `sum (1-a_i) ||[A,B]_{k_i} + a_i[X_i,Y_i]_k||_Q^2`. Combining the relevant parts from the derived `alpha` and `3/4 beta` does not straightforwardly yield the `a_i(1-a_i)^3` term as stated in Proposition 2.2. This discrepancy in the powers of `(1-a_i)` is significant as it affects the conditions under which terms are non-negative and, consequently, the overall conditions derived for non-negative sectional curvature (e.g., `0 < a_i <= 1`). The soundness of this central technical proposition is critical for the rest of the paper's arguments."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 19661,
      "output": 1098
    }
  },
  {
    "entry_id": 155,
    "retraction_id": "1402.3490v2",
    "paper_id": "1402.3490v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error of the combination rule",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Combination rule potentially undefined due to normalization factor K_D",
        "Location": "Page 8, Equations (12) and (13)",
        "Explanation": "The D-numbers combination rule in Eq. (12) uses a normalization factor (1-K_D). K_D is defined in Eq. (13) as (1/(Q1*Q2)) * sum(D1(B1)D2(B2)) for B1 ∩ B2 = ∅. If the sum of conflicting products, C_mass = sum(D1(B1)D2(B2)) for B1 ∩ B2 = ∅, is equal to Q1*Q2, then K_D = 1. This leads to division by zero in Eq. (12), making the combination rule undefined. This is analogous to K=1 in Dempster-Shafer theory. The paper does not explicitly state the condition K_D < 1 for the rule's applicability or discuss how to handle K_D = 1, which is a critical omission for a general combination rule."
      },
      {
        "Problem": "Ambiguity in handling non-exclusive elements of the set Θ",
        "Location": "Page 7, Definition 1 and explanation; Page 9-10, Example 1",
        "Explanation": "Definition 1 states that elements F_i in the set Θ are not required to be mutually exclusive. However, D-numbers are formally defined as a mapping D: 2^Θ → [0,1], and the combination rule (Eq. 12) uses standard set intersection (∩) on subsets of Θ (i.e., B1, B2 ⊆ Θ). If F_i are distinct elements of Θ, then singleton subsets like {F_i} and {F_j} (for i ≠ j) are always disjoint. This appears inconsistent with Example 1, where D(High ∩ Medium) = 1 is derived, implying 'High' and 'Medium' are treated as overlapping sets that are directly assigned D-values, and their intersection is non-empty. The paper does not clearly explain how the non-exclusivity of elements F_i ∈ Θ is operationalized within the 2^Θ framework and the standard set intersection used in the combination rule, leading to a potential disconnect between the stated motivation and the formal mechanics."
      },
      {
        "Problem": "Unjustified multiplicative decrease in the degree of completeness",
        "Location": "Page 8, Definition 3 (Equations 12-15)",
        "Explanation": "The proposed D-numbers combination rule implies that the degree of completeness of the combined D-number, Q_combined, is the product of the degrees of completeness of the individual D-numbers, i.e., Q_combined = Q1 * Q2. This can be derived from the definitions: sum_B D(B) = Q1*Q2. This multiplicative decrease means that if any source is significantly incomplete, the combined evidence will also be highly incomplete, potentially more so than either source if one is nearly complete (e.g., Q1=0.2, Q2=0.9 results in Q_combined=0.18). The paper does not provide a theoretical justification for this specific behavior or argue why this multiplicative reduction in completeness is a desirable or universally appropriate property for combining uncertain and incomplete information. This characteristic could lead to counter-intuitive results where information seems to be unduly lost or diminished."
      }
    ],
    "token_usage": {
      "input": 9670,
      "thinking": 9117,
      "output": 855
    }
  },
  {
    "entry_id": 156,
    "retraction_id": "1504.06694v3",
    "paper_id": "1504.06694v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a logical fallacy was made in transition from equation (46) to equations (47)-(50)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect coefficient comparison in the main proof.",
        "Location": "Page 5, Eq 45 (Section 3.1) and Page 6, Eq 50 (Section 3.2)",
        "Explanation": "The paper's central argument for impossibility relies on equations like `6 * S^N(N) = 25 * a_{(N-2)/2}^2`. Here, `S^N(N)` (coefficient of `x^N` on LHS, which is 1) is multiplied by 6. The term `a_{(N-2)/2}` is the leading coefficient of `r_poly(x)`, which has degree `(N-2)/2`. Thus, `(a_{(N-2)/2})^2` is related to the coefficient of `x^(N-2)` on the RHS. The paper incorrectly equates a term derived from the `x^N` coefficient on the LHS with a term derived from the `x^(N-2)` coefficient on the RHS. This invalidates the conclusion that `a_{(N-2)/2}` must be irrational based on this specific equation."
      },
      {
        "Problem": "Failure to correctly analyze the degree mismatch in polynomial identities.",
        "Location": "Page 5, Eq 41 (Section 3.1) and Page 6, Eq 46 (Section 3.2)",
        "Explanation": "The polynomial identities (e.g., Eq 41: `sum_{k=0}^{N} 6 * |S^(k)(N)| x^k = 5 r_poly(x) + 25 (r_poly(x))^2`) have a degree mismatch. The LHS, `6 * (x)^N`, has degree `N` (where `N=n-4`). The polynomial `r_poly(x)` is defined such that its degree is `(N-2)/2`. Consequently, the RHS has degree `N-2`. For these polynomials to be identical, the coefficients of `x^k` for `k > N-2` on the LHS must be zero. Specifically, the coefficient of `x^N` on the LHS is `6 * S^N(N) = 6`. On the RHS, the coefficient of `x^N` is 0 (since `N > N-2` for `N>2`). This implies `6 = 0`, a contradiction. This contradiction, which would prove impossibility, is not identified or used by the paper."
      },
      {
        "Problem": "The proof in Section 3 is restricted to even values of n.",
        "Location": "Page 5, line 5 of Section 3.1 (definition of r_poly) and corresponding part in Section 3.2",
        "Explanation": "The polynomial `r` (denoted `r_poly(x)` here) is defined as a sum `sum a_k x^k` where the summation for `k` goes up to `(n-4-2)/2 = (n-6)/2`. For `(n-6)/2` to be a non-negative integer representing the degree of the polynomial, `n-6` must be an even non-negative integer, meaning `n` must be an even integer `n >= 6`. The paper claims to prove no solutions for `n >= 8` but its argument structure in Section 3 is only applicable if `n` is even. The case for odd `n >= 9` (e.g., n=9, 11, ...) is not addressed by this method, leaving the proof incomplete."
      },
      {
        "Problem": "Incorrect rational solution stated for an equation in the 'intuitive approach'.",
        "Location": "Page 2, discussion of Eq 11",
        "Explanation": "The paper states that `t0 = 5/2` is the positive rational solution to the equation `(1+2t)(1+3t) = 5` (Eq 11). However, solving `6t^2 + 5t - 4 = 0` yields `t = (-5 +/- 11)/12`, so the positive rational solution is `t0 = 6/12 = 1/2`. The value `t0 = 5/2` is incorrect. While Section 2's 'intuitive approach' is later abandoned, this fundamental error in solving a simple quadratic equation in an illustrative part of the paper undermines confidence in its overall mathematical rigor."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 14540,
      "output": 1004
    }
  },
  {
    "entry_id": 157,
    "retraction_id": "1502.02090v5",
    "paper_id": "1502.02090v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 3.15",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Proof of Proposition 3.2 uses inconsistent forms for projection",
        "Location": "Page 5, Proof of Proposition 3.2",
        "Explanation": "The proof aims to show that the projector `Π_7^2(·) = 1/3 *(* (· ∧ *φ) ∧ *φ)` annihilates forms in `Λ_{14}^2`. It states it will show `*(* (β ∧ φ) ∧ φ) = 0` for `β ∈ Λ_{14}^2`. However, the projector formula explicitly involves `*φ` (the Hodge dual of the 3-form `φ`), while the calculation shown for the `Λ_{14}^2` component uses `φ`. These are different expressions (`φ` vs `*φ` inside the innermost wedge product), and the validity of this step in proving the projector property is therefore questionable."
      },
      {
        "Problem": "Inconsistent formulas used for the G2 projector `Π_7^2`",
        "Location": "Proposition 3.2 (page 5) and unnumbered equation on page 6 (before 'Hence')",
        "Explanation": "Proposition 3.2 defines the projector onto `Λ_7^2` as `Π_7^2(f) = 1/3 *(* (f ∧ *φ) ∧ *φ)`. However, an unnumbered equation on page 6 (used to express `F_A^7`) states `F_A^7 = 1/3 (F_A + *(F_A ∧ φ))`. These two formulas for the projection onto `Λ_7^2` are generally not equivalent. The latter is a standard formula for this projector. This inconsistency is problematic as subsequent derivations, such as equation (3.4) which relies on Prop 3.2, may be based on a non-standard or incorrect projector formula if Prop 3.2 is indeed flawed or different from the standard one used elsewhere."
      },
      {
        "Problem": "Questionable proof of Lemma 3.5 regarding projection of `d_A F_A^{14}`",
        "Location": "Page 8, Proof of Lemma 3.5",
        "Explanation": "Lemma 3.5 states `Π_1^3(d_A F_A^7) = 0`. Its proof relies on showing `Π_1^3(d_A F_A^{14}) = 0`. The argument for `Π_1^3([A, F_A^{14}]) = 0` (a component of `Π_1^3(d_A F_A^{14})`) uses an unclear identity `*([A, F_A^{14}] ∧ *φ) ⋅ φ = 1/7 * ([A \\wedge *φ, F_A^{14}]) ⋅ φ` and subsequent reasoning about `*(A \\wedge *φ)` that is not well-justified. Furthermore, the application of equation (3.7) (which describes the decomposition of `d` on scalar forms) to the `ad(E)`-valued form `dF_A^{14}` (or `d F_A^{14}`) to show `Π_1^3(dF_A^{14})=0` is not adequately explained or justified."
      },
      {
        "Problem": "Unclear derivation and potentially incorrect coefficient in Yang-Mills energy decomposition",
        "Location": "Page 8, derivation leading to equation (3.9)",
        "Explanation": "The paper derives an expression for the Yang-Mills energy as `||F_A||^2 = 3||F_A^7||^2 - \\int_M tr(F_A^{14}) \\wedge \\phi`. This decomposition leads to equation (3.9): `||F_{A+tψ_A}||_{L^2}^2 = 3||F_{A+tψ_A}^7||_{L^2}^2 + \text{topological constant}`. The derivation steps for this energy decomposition are not standard, and the coefficient 3 for `||F_A^7||^2` is unusual compared to typical Bogomolny-type decompositions found in G2 geometry, which usually yield factors of 1 or 2. This potentially flawed decomposition significantly impacts subsequent equations (3.10) and (3.12) derived from it."
      },
      {
        "Problem": "Critical gap in the final argument of Theorem 3.6 proof",
        "Location": "Page 10, proof of Theorem 3.6 (which is Theorem 1.1)",
        "Explanation": "The conclusion of Theorem 3.6, that `F_A^7 = 0`, hinges on establishing the equality `||ψ_A||^2 = ||F_A^7||^2`. The paper justifies this equality by stating 'Since `C(ψ_A) = F_A^7` and `*d_A * F_A^7 = ψ_A`, then we have `||ψ_A||^2 = ||F_A^7||^2`'. However, the identity `*d_A * F_A^7 = ψ_A` is not proven, does not appear to be standard, and contradicts the earlier derivation of `d_A^* F_A^7 = 0` (which implies `*d_A*F_A^7 = 0` if `F_A^7` is a 2-form in 7D, up to sign). Without a valid derivation for `||ψ_A||^2 = ||F_A^7||^2`, the subsequent step `2||ψ_A||^2 = 0` (obtained by combining it with the known relation `||F_A^7||^2 = 3||ψ_A||^2`) and thus the theorem's main conclusion (`F_A^7 = 0`) are unsupported by the provided argument."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 17109,
      "output": 1346
    }
  },
  {
    "entry_id": 158,
    "retraction_id": "1611.05964v2",
    "paper_id": "1611.05964v1",
    "retraction_comment": "Algorithm 1 is inefficient since line 2 is processed n 3 times need to be changed There are inconsistent notations throughout the manuscript [REDACTED-NAME] are not defined",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between L-subproblem and its proposed solution in ADMM",
        "Location": "Algorithm 2, steps 6-9 (Page 5); Eq. 28 (Page 5); Sections III.B & III.C (Page 6).",
        "Explanation": "The update rule for the tensor L in Algorithm 2 (specifically steps 6-9, detailed in Sections III.B and III.C) does not correctly solve the stated L-subproblem (Eq. 28) of the ADMM framework. Eq. 28 is a weighted tensor nuclear norm proximal problem. The standard solution involves soft-thresholding the singular values of the input tensor with thresholds scaled by the weights. However, the paper's method first multiplies the singular values by the weights (Eq. 33, Section III.B) and then applies a standard soft-thresholding operator D_tau (Section III.C, Eq. 34-35) to this weight-scaled tensor. This sequence of operations is mathematically different from the correct solution of the proximal operator for Eq. 28. This discrepancy means the algorithm may not be minimizing the stated objective function L_rho in Eq. 27."
      },
      {
        "Problem": "Insufficient iterations and unclear conditions for comparative evaluation",
        "Location": "Section IV, paragraph 2, page 6 ('ten iterations are performed').",
        "Explanation": "The proposed algorithm is run for a fixed 10 iterations. This is a small number for ADMM-based methods, especially those involving reweighting which changes the optimization landscape at each outer loop. No convergence plots or justification for this low number are provided. Furthermore, the paper does not specify the stopping criteria or iteration counts used for the baseline methods (GTNN, TMAC, TC). If baselines were also arbitrarily limited or run under different convergence conditions, the comparison's fairness and validity are questionable, as the reported performance might be from a premature stage of optimization."
      },
      {
        "Problem": "Empirical and insufficiently justified formula for regularization parameter epsilon",
        "Location": "Section III.D, Eq. 36 and subsequent paragraph, page 6.",
        "Explanation": "The weight update rule (Eq. 36) uses a parameter epsilon, which is critical for stability and performance in reweighted schemes. The paper proposes a specific, complex formula for epsilon: 'epsilon = exp(-alpha * P_missing / 0.02)', where P_missing is the percentage of missing entries and 0.02 is a constant. The derivation or justification for this specific functional form and the constant 0.02 is absent. Additionally, no sensitivity analysis regarding the parameter 'alpha' or the constant '0.02' is provided. This lack of analysis makes the method appear heuristic and potentially difficult to generalize or tune for new datasets/scenarios, despite the paper's claim that this choice improves recovery."
      },
      {
        "Problem": "Unspecified threshold parameter `tau` in L-update step of Algorithm 2",
        "Location": "Algorithm 2, step 9 (Page 5); Eq. 34-35 (Page 6).",
        "Explanation": "Algorithm 2, step 9, specifies the L-update as L(k+1) = D_tau[L_tilde(k+1)], where D_tau is the singular value soft-thresholding operator with threshold `tau` (defined in Eq. 34-35). However, the value or method for determining `tau` at this specific step is not specified in Algorithm 2 or its accompanying description. While Eq. 31 suggests a threshold of 1/rho for a related update, it's not explicitly linked to `tau` in step 9 of Algorithm 2. This omission makes a key step of the algorithm incompletely defined and not fully reproducible without assumptions."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 9751,
      "output": 863
    }
  },
  {
    "entry_id": 159,
    "retraction_id": "2206.04913v2",
    "paper_id": "2206.04913v1",
    "retraction_comment": "I really apologize the audience for this withdrawal. The last section has some errors, because the proof of Lemma 4.2 is not true. Also other sections should be improved",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Theorem 3.5 (and consequently Corollary 3.6) relies on an assumption about the structure of faces in the simplicial complex L^2(I) that appears inconsistent with the definition of L^2(I) from cited works [8,9], particularly for homological degree i > 1. The proof assumes that a cycle contributing to β_{i,2di}(R/I^2) corresponds to a face τ = {S_{l1}S_{l'1}, ..., S_{li}S_{l'i}} where the sets (S_{lk} ∪ S_{l'k}) are pairwise disjoint. However, faces of L^2(I) for i > 1 must be subsets of 'star-like' structures (F_j^* or G_j^* in [8,9]), implying common edges among the constituent monomials S_xS_y if i > 1. This contradicts the pairwise disjoint union assumption crucial for the degree calculation and the combinatorial interpretation in Corollary 3.6.",
        "Location": "Pages 10-12, Theorem 3.5, Corollary 3.6, and their proofs.",
        "Explanation": "If the assumed face structure is not possible within L^2(I) for i > 1, then the argument connecting the non-vanishing Betti number to the existence of 2^i matchings of size i (derived from this specific structure) is invalid. This particularly affects Corollary 3.6 which is stated for i > 1."
      },
      {
        "Problem": "In Theorem 3.7, Part 2, the claim that β_{i,d(t-1)+j}(R/(I(H)^t)) ≥ si (where s is the number of self semi-induced matchings of type (i,j) and H is d-uniform, t>1) is not sufficiently justified. The proof of Part 1 constructs cycle candidates e_{τ_l} for each self semi-induced matching S and each edge S_l within S. This suggests s · i potential cycles if |S|=i. However, the proof does not establish that these s · i cycles are distinct in homology or linearly independent, which is necessary to claim the Betti number is at least s · i.",
        "Location": "Page 12, Theorem 3.7, Part 2. Proof implicitly relies on Part 1 (page 12-13).",
        "Explanation": "The jump from constructing individual cycles to a lower bound of 's · i' for the Betti number requires a proof of linear independence of these cycles in homology, which is missing. Without it, the bound might only be 's' (if, for example, all i cycles derived from one matching S are homologous or only one is chosen per matching)."
      },
      {
        "Problem": "Lemma 4.2, which presents a short exact sequence crucial for the inductive bounds on regularity in Section 4, appears to have inconsistencies in its formulation for t > 1. Specifically, the map φ sends elements (v_1,...,v_s) from (I_{m-s}(-d))^s to a target where the first s components are in ⊕_{j=1..s} I_{m-s+j}^{t-1}(-d). This requires that v_j ∈ I_{m-s}(-d) implies v_j ∈ I_{m-s+j}^{t-1}(-d), meaning I_{m-s} ⊆ I_{m-s+j}^{t-1}. This inclusion does not hold generally for t > 1. The proof of the lemma also contains an incorrect assertion: 'I_{m-s}^t ⊆ I_k^{t-1}' for m-s+1 ≤ k ≤ m, which is false for t > 1.",
        "Location": "Page 15, Lemma 4.2 and its proof.",
        "Explanation": "If the short exact sequence in Lemma 4.2 is not exact as stated, then Proposition 4.3, Proposition 4.4, and Corollary 4.5, which are derived using this sequence, lack a valid foundation. This would invalidate the main upper bound for regularity of powers of edge ideals presented in Corollary 4.5."
      }
    ],
    "token_usage": {
      "input": 4768,
      "thinking": 17349,
      "output": 1032
    }
  },
  {
    "entry_id": 160,
    "retraction_id": "1705.06716v2",
    "paper_id": "1705.06716v1",
    "retraction_comment": "This study needs many major modifications. Majority of the study includes mistakes. For example, all the plots and the numbers that are generated using ALPGEN MC generator in the tables are not correct. In addition, the selected factorization and renormalization scales do not define the correct form of the interaction. Even the title of the study must be changed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Severe mismodeling by Alpgen for W+jets (>=2 jets) in validation",
        "Location": "Section 3, Table 8 (p. 8), Figure 3b (p. 9)",
        "Explanation": "Alpgen (LO) predictions for W+jets with 2 or more jets deviate from ATLAS 7 TeV data by 50-70% (e.g., W+2jets Alpgen: 134.58 pb vs ATLAS: 89.63 pb; W+3jets Alpgen: 30.32 pb vs ATLAS: 17.55 pb). This poor agreement in the validation phase severely undermines the reliability of Alpgen for predicting W+jets with multiple jets at 14 TeV (Table 10), which is a key result of the paper. The paper's claim that these results 'match well when the systematical errors (5-10%) along with the statistical errors on the experimental results' are considered is not supported by the data, as the discrepancies far exceed typical systematic uncertainties for these bins."
      },
      {
        "Problem": "Absence of theoretical uncertainties for Alpgen W/Z+jets predictions",
        "Location": "Section 3, Tables 9 & 10 (p. 11), and throughout the W/Z+jets discussion",
        "Explanation": "The Alpgen predictions for W/Z+jets at 14 TeV (and other energies) are provided with only Monte Carlo statistical uncertainties. For Leading Order (LO) calculations, especially for multi-jet final states, uncertainties from scale variations and Parton Distribution Functions (PDFs) are expected to be significant and often dominate the error budget. Without quantifying and including these theoretical uncertainties, the predictive power of the results in Tables 9 and 10 is severely limited, and their precision is implicitly overstated, making them unsuitable for robust comparison or use in further studies."
      },
      {
        "Problem": "Arbitrary scale tuning for Alpgen generator without systematic uncertainty assessment",
        "Location": "Section 3, p. 5-6 (description of Alpgen scale choices: 'The renormalization and factorization scales are modified by a factor of 4 to be consistent with ATLAS Z+jets results. For W+jets...modified...by a factor of 2 to be consistent with ATLAS W+jets results.')",
        "Explanation": "The factorization and renormalization scales in Alpgen were multiplied by ad-hoc factors (2 for W+jets, 4 for Z+jets) with the stated purpose of achieving consistency with specific ATLAS data. This data-driven tuning of fundamental parameters in an LO calculation, without a systematic study of these choices or their impact on scale uncertainties across different energies and jet multiplicities, compromises the predictive integrity of the generator. It is unclear if these tuned scales are optimal or appropriate for the 14 TeV predictions, and this tuning makes a proper scale uncertainty evaluation even more critical, yet it is absent."
      },
      {
        "Problem": "Underestimation of issues with LO predictions for high jet multiplicities",
        "Location": "Conclusion, p. 12 (paragraph discussing Alpgen's limitations: 'the cross section predictions for W+jets (Z+jets) up to 4 jets (2 jets) are increasing...in an orderly manner but for W+5 jets (Z+3-6 jets) the fluctuations on the results begin...')",
        "Explanation": "The paper acknowledges that for higher jet multiplicities, LO Alpgen predictions exhibit 'fluctuations' and do not behave in an 'orderly manner'. This known instability of LO matrix element generators for high jet multiplicities is a critical limitation. However, the paper then claims these predictions are 'totally acceptable' when statistical errors are considered. This dismisses the significant theoretical uncertainties and potential unphysical behavior inherent in such LO predictions for high jet counts, rendering the predictions for W+jets with >=5 jets and Z+jets with >=3 jets particularly unsound."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 8497,
      "output": 867
    }
  },
  {
    "entry_id": 161,
    "retraction_id": "1604.05964v2",
    "paper_id": "1604.05964v1",
    "retraction_comment": "equation no. 16 17 and 18 have flaws, result of which final outage derivation is not converging",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Simplification of Post-CoMP Desired Signal Gain",
        "Location": "Page 3, Eq (3) and its use in SINR Eq. (6) numerator; and analogous assumptions for secondary user analysis (e.g., Eq. 19).",
        "Explanation": "The paper approximates the desired signal's effective channel power gain after CoMP (ZF-DPC) as `|h_ii|^2`, which represents the raw channel power gain between the user and its serving base station *before* CoMP. The actual post-CoMP gain, often denoted `|l_ii|^2` (derived from a matrix decomposition like H=LQ or H=QR), depends on the overall channel matrix and the specifics of the ZF-DPC processing, and is generally not equal to `|h_ii|^2`. This simplification likely overestimates the desired signal strength, leading to optimistic SINR and rate predictions, and thus potentially inflates the reported performance gains of the cloud model. For instance, reference [2] cited by the paper suggests post-processing gains follow a Chi-squared distribution with different degrees of freedom."
      },
      {
        "Problem": "Optimistic Assumption of a Single Secondary Interferer to a Primary User",
        "Location": "Page 2, Section II.A ('Distribution of Resource Blocks among Secondary', first bullet point under benefit); Page 3, Eq (6) (term `I_one,Si`).",
        "Explanation": "The primary user's SINR model assumes interference from at most one secondary base station (`I_one,Si`) in the event of a misdetection. This relies on a central secondary cluster cloud perfectly coordinating unique resource block (RB) allocation to all secondary base stations across an entire 'defined cluster' from a pool of RBs deemed unoccupied. The feasibility, scalability, and robustness of such perfect, wide-area coordination (e.g., against latency, synchronization errors, or practical cluster sizes and definitions) are not established. If this coordination is imperfect or the assumption too strong, multiple secondary interferers could exist, leading to an underestimation of the actual interference at the primary user and consequently an overestimation of the primary network's performance."
      },
      {
        "Problem": "Optimistic Assumption of a Single Primary Interferer to a Secondary User",
        "Location": "Page 2, top-left ('Each primary within a cluster is allocated with M ... unique Resource Blocks'); Page 5, Eq (19) (term `I_one,Pi`).",
        "Explanation": "The secondary user's SINR model assumes interference from only one primary base station (`I_one,Pi`) if the secondary mistakenly transmits on a resource block (RB) that is actually in use by a primary. This is justified by the statement that RBs are allocated uniquely to primary base stations within a primary 'cluster'. However, the definition of these primary clusters, inter-cluster frequency reuse patterns, and the potential for a secondary user to be located at the confluence of multiple primary coverage areas using the same frequency are not fully addressed. This could lead to an underestimation of the interference from the primary network to secondary users, thereby overstating the secondary user performance."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 10332,
      "output": 699
    }
  },
  {
    "entry_id": 162,
    "retraction_id": "1010.6286v5",
    "paper_id": "1010.6286v4",
    "retraction_comment": "This paper has been withdrawn by the author due to the map described in Thorem 2.4 is not injective",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The main construction in Theorem 2.4 does not yield an embedding for a non-abelian right-angled Artin group (RAAG) $A_\\Gamma$. The constructed map takes free pairs of generators $(u,v)$ in $A_\\Gamma$ (corresponding to an edge in $\\Gamma$) to elements $(X_u, X_v)$ in $B'_n$ that satisfy the relation $[X_u, X_v] = c_{uv}$, where $c_{uv}$ is a specific non-identity commutator derived from braid group generators. This means the image group is a quotient of $A_\\Gamma$ (with added relations), not isomorphic to $A_\\Gamma$.",
        "Location": "Page 5, Proof of Theorem 2.4",
        "Explanation": "The proof aims to make generators $X_u = \\Psi(u)\\psi_1$ and $X_v = \\Psi(v)\\psi_2$ free if $u,v$ are free in $A_\\Gamma$. It ensures they don't commute by having $[X_u,X_v] = [\\psi_1, \\psi_2] \\neq 1$. However, for an embedding, $X_u, X_v$ must satisfy *no* relations other than those inherited from $A_\\Gamma$. Introducing the relation $[X_u, X_v] = c_{uv}$ (where $c_{uv}= [\\psi_1, \\psi_2]$) means the map is not an embedding unless $c_{uv}$ is trivial or $A_\\Gamma$ already had this relation, neither of which is the case."
      },
      {
        "Problem": "The assumption that squares of non-commuting braid generators, specifically $\\sigma_{k+2}^2$ and $\\sigma_{k+3}^2$, generate a free group $F_2$ is incorrect.",
        "Location": "Page 5, Proof of Theorem 2.4 (lines 6-9) and Page 3 (paragraph starting 'Just using this...')",
        "Explanation": "The proof of Theorem 2.4 relies on modifying the map $\\Psi$ using pairs of elements $\\psi_{k+2}, \\psi_{k+3}$ (which are $\\sigma_{k+2}^2, \\sigma_{k+3}^2$) that are assumed to behave like generators of $F_2$. However, if $\\sigma_a$ and $\\sigma_b$ are standard braid generators, the subgroup $\\langle \\sigma_a^2, \\sigma_b^2 \\rangle$ is not $F_2$ if $\\sigma_a, \\sigma_b$ do not commute (e.g., $b=a+1$). These elements satisfy relations within the braid group, and their commutator $[\\sigma_{k+2}^2, \\sigma_{k+3}^2]$ is a specific element, not a generic commutator in an $F_2$ subgroup."
      },
      {
        "Problem": "Proposition 2.3(5) is incorrect: the couple product $G \\Join F_k$ (where $G$ is a RAAG) is not generally isomorphic to $G$ if $F_k$ is non-abelian and its generators are coupled with generators of $G$.",
        "Location": "Page 4, Proposition 2.3(5); Page 5, its application in proof of Theorem 2.4",
        "Explanation": "If $g_i, g_j$ are generators of $G$ such that $[g_i, g_j]=1$, and they are coupled with $f_i, f_j$ (generators of $F_k$) respectively, then the relation in $G \\Join F_k$ becomes $[g_if_i, g_jf_j] = [g_i,g_j][f_i,f_j] = [f_i,f_j]$ (assuming $g$'s commute with $f$'s, and $f_i,f_j$ commute with $g_j,g_i$ respectively). If $F_k$ is non-abelian (e.g. $F_2$), then $[f_i,f_j] \\neq 1$. Thus, a commuting pair in $G$ can become a non-commuting pair in $G \\Join F_k$, meaning $G \\Join F_k$ is not isomorphic to $G$. The proof of Theorem 2.4 iteratively applies this proposition, claiming isomorphism at each step, which is unsound."
      },
      {
        "Problem": "The initial homomorphism $\\Psi: A_\\Gamma \\to B'_l$ in the proof of Theorem 2.4 is not an embedding for a general non-abelian $A_\\Gamma$.",
        "Location": "Page 5, Proof of Theorem 2.4 (lines 1-3)",
        "Explanation": "The initial map is defined by $\\Psi(g_i) = \\sigma_{2i-1}^2$. Since the indices $2i-1$ and $2j-1$ (for $i \\neq j$) differ by at least 2, the braid generators $\\sigma_{2i-1}$ and $\\sigma_{2j-1}$ commute. Consequently, their squares $\\sigma_{2i-1}^2$ and $\\sigma_{2j-1}^2$ also commute. This means the image $\\Psi(A_\\Gamma)$ is an abelian group (specifically, $Z^{|\\Gamma|}$). If $A_\\Gamma$ is not abelian, this map $\\Psi$ is not an embedding because it maps non-commuting pairs of generators (those forming an edge in $\\Gamma$, by the paper's convention) to commuting elements. The subsequent inductive modification attempts to fix this but fails due to other issues (Problems 1-3)."
      },
      {
        "Problem": "Proposition 2.3(4) is incorrect without strong, unstated assumptions: the subgroup $\\langle g_1f_1, \\dots, g_kf_k \\rangle$ of $G \\times F_k$ (denoted $G \\Join F_k$ coupled part) is not generally isomorphic to $F_k$.",
        "Location": "Page 4, Proposition 2.3(4)",
        "Explanation": "The proof of this proposition implicitly requires that any relation $W(f_1, \\dots, f_k)=1$ in $F_k$ implies the corresponding relation $W(g_1, \\dots, g_k)=1$ in $G$. Since $F_k$ is a free group, this means the map $f_i \\mapsto g_i$ must extend to an injective homomorphism from $F_k$ to $G$; i.e., $g_1, \\dots, g_k$ must themselves freely generate a subgroup isomorphic to $F_k$ within $G$. This is a very strong condition on the choice of $g_i$ in $G$ and is not stated as a prerequisite for the proposition."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 18580,
      "output": 1589
    }
  },
  {
    "entry_id": 163,
    "retraction_id": "0811.2430v4",
    "paper_id": "0811.2430v3",
    "retraction_comment": "The author revised the article and considers that the proof is not rigorous. The main counter-argument is that one should not draw conclusions from a truncated wave-function",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Symmetrization Procedure and Definition of Particle Interchange",
        "Location": "Page 2, discussion of particle interchange below Eq. (6); Page 3, Equations (8) and (9).",
        "Explanation": "The paper defines particle interchange inadequately (e.g., swapping detector outcomes for source-labeled particles like replacing `|D1>L |D2>R` with `|D2>L |D1>R`) rather than swapping particle labels in the quantum state `ψ(x1, x2)` to `ψ(x2, x1)`. Consequently, the construction of symmetric and antisymmetric states in Equations (8) and (9) is flawed. For example, a term like `|D1>L|D'1>R + |D'1>L|D1>R` represents a superposition of two distinct states of the source-labeled particle pair (L,R) – specifically, (particle L in D1 and particle R in D'1) and (particle L in D'1 and particle R in D1) – rather than the correct symmetrization of a single state with respect to the exchange of indistinguishable particles. This fundamentally undermines the derivation of the probabilities in Eqs. (10) and (11)."
      },
      {
        "Problem": "Problematic Initial State Formulation for Indistinguishable Particles",
        "Location": "Page 2, Equation (1).",
        "Explanation": "Equation (1), `|ψ> = 1/2 ( |A> − |A'>)( |B> – e^(iφ)|B'>)`, is presented as the initial state. This represents a product state `|ψ_L>|ψ_R>` where L and R act as distinguishable labels for particles from the two sources. If the particles are truly identical and indistinguishable from the outset, the symmetrization postulate requires the initial state to be explicitly (anti)symmetrized with respect to abstract particle labels (e.g., `N[|ψ_L(1)>|ψ_R(2)> ± |ψ_L(2)>|ψ_R(1)>]`). Starting with an effectively distinguishable product state and then attempting to derive symmetrized components later based on measurement outcomes is a conceptual error that conflates distinguishability by source with fundamental particle identity."
      },
      {
        "Problem": "Assumption of Coherence Between Independent Sources",
        "Location": "Page 2, Equation (1); Page 3, Equations (10), (11).",
        "Explanation": "The derivation, starting from Equation (1) which includes a relative phase `φ` between terms associated with source L and source R, implicitly assumes a stable phase relationship between the two independent particle sources. For truly independent sources, such a phase relationship does not generally exist; their relative phase would be random. This would typically lead to the washing out of the interference fringes predicted in Equations (10) and (11) unless specific measures (e.g., phase-locking the sources, or stringent temporal post-selection as in Hong-Ou-Mandel experiments with independent sources, as discussed in the cited Yurke and Stoler paper) are implemented. The paper does not discuss how such coherence is achieved or maintained."
      },
      {
        "Problem": "Misleading Conception of Symmetrization as a Dynamically Induced Effect",
        "Location": "Abstract (lines 6-9); Page 1, Introduction (last paragraph); Page 4, Section 3 (Discussion, paragraph 1).",
        "Explanation": "The paper repeatedly suggests that the wavefunction *becomes* non-factorizable and (anti)symmetrical 'at-a-distance' as a result of creating a configuration where 'one cannot tell anymore which particle came from which source,' even if the particles never meet. Quantum statistics (symmetrization/antisymmetrization) is a fundamental postulate for identical particles, meaning their joint wavefunction *must* possess the appropriate symmetry if they are indistinguishable. It is not an effect that is dynamically 'produced' or 'agreed upon' by particles due to the experimental setup or their (non-)interaction. The indistinguishability dictates the use of an (anti)symmetrized state from the start, and non-local correlations are then consequences of measurements on such a state."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 9305,
      "output": 941
    }
  },
  {
    "entry_id": 164,
    "retraction_id": "2201.05255v2",
    "paper_id": "2201.05255v1",
    "retraction_comment": "Our definition of the higher Toda brackets is not effective, i.e. not well defined, in the category of pointed spaces",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition of the unstable Toda bracket `{f}'_m` for `n >= 4` appears to be identical to that of `{f}_m`, as both are defined using a union `U_A` over \"admissible sequences A\". This contradicts the statement that `{f}_m ⊂ {f}'_m` is a proper inclusion in general (page 2) and the paper's aim to define three distinct systems. If `{f}'_m` is intended to be different (e.g., using weakly admissible sequences as suggested by comparison with [OO4]), its definition is incorrectly stated or insufficiently clarified.",
        "Location": "Page 1 (definition of `{f}_m`), Page 2 (definition of `{f}'_m` and description of `U_A`), Page 2 (statement `{f}_m ⊂ {f}'_m ⊂ {f}''_m`).",
        "Explanation": "This ambiguity or error in the definition of one of the three central objects of study undermines the clarity regarding the distinctness of the systems being investigated for `n >= 4`. If `{f}_m = {f}'_m`, then there are only two distinct systems for `n >= 4`, and claims about their relationship or separate properties might be affected."
      },
      {
        "Problem": "The inductive proof of Theorem 1.2 (a main result) on page 16 relies on the algebraic identity `Σ^{n-2}(1_{Σ^{m[3,1]}X_1} ^ τ(S^1, S^{m[n+1,4]})) o (1_{X_1} ^ h_m') = 1_{X_1} ^ h_m`. This identity involves specific homeomorphisms `h_m` (defined on page 2) and twist maps `τ`, and is stated without proof or reference.",
        "Location": "Page 16, proof of Theorem 1.2, the line starting \"(since Σ^{n-2}(1_{Σ^{m[3,1]}X_1} ...)\".",
        "Explanation": "This identity represents a crucial coordinate transformation step in the induction. If this identity is incorrect, the inductive step for Theorem 1.2 would be invalid for `n > 4`, potentially invalidating this part of the theorem."
      },
      {
        "Problem": "The proof of Theorem 1.3 (suspension property) relies on Lemma 7.2, which details complex homotopy manipulations for 3-fold terms. The inductive step for Theorem 1.3 (page 23) asserts that \"the proof of Lemma 7.2 is valid for the assertion which is obtained from Lemma 7.2 by replacing B2, B1 with Bk+1, Bk, respectively, for n > k > 1.\"",
        "Location": "Page 23, paragraph starting \"Then the proof of Lemma 7.2 is valid...\".",
        "Explanation": "This generalization is critical for the inductive argument of Theorem 1.3. However, the complexity of indices and terms increases significantly for higher `k`. A detailed justification or proof of this generalizability is missing. If this generalization is flawed or not straightforward, Theorem 1.3 may not hold for `n > 3`."
      },
      {
        "Problem": "The formula for `Σ^l[f_3, A_2, Σ^{m_3}f_2]` derived in the proof of Lemma 7.2 (leading to equation (7.5)) is highly complex. It involves multiple compositions with specific homotopical constructions like `(ψ_{Σ^{m_3}f_2})^{-1}` and terms such as `(1_{X_3} \\wedge \\tau(S^{m_3}, S^l) \\cup C(1_{X_2} \\wedge \\tau(S^{m[3,2]}, S^l)))`.",
        "Location": "Page 21, proof of Lemma 7.2, derivation of (7.5).",
        "Explanation": "Lemma 7.2 is foundational for Theorem 1.3. An error in this intricate formula, which involves non-trivial homotopical constructions and coordinate changes, would invalidate Lemma 7.2 and, consequently, Theorem 1.3. The sheer complexity of the formula makes it susceptible to errors without extremely careful derivation and verification."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 22578,
      "output": 977
    }
  },
  {
    "entry_id": 165,
    "retraction_id": "1601.01217v3",
    "paper_id": "1601.01217v2",
    "retraction_comment": "There is an important mistake in the definition of the global smoothing operator preserving the presymplectic form",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 10702,
      "thinking": 15837,
      "output": 1
    }
  },
  {
    "entry_id": 166,
    "retraction_id": "1412.3838v2",
    "paper_id": "1412.3838v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the statement according to which the volume element does not depend on the choice of the time orientation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated claim of t-independence of the integration domain B_n(x)",
        "Location": "Page 7, point 2) & \"Remark\"; Page 11, point 2) & Remark 1 (page 12)",
        "Explanation": "The paper's construction of the volume element relies on integrating over a Euclidean unit ball B_n(x) in each tangent space. This B_n(x) is identified as the unit ball of an auxiliary Riemannian metric g^t (in the positive definite case) or g^{t,+} (in the Lorentzian case), which is constructed using an auxiliary time-orientation vector field t(x). The paper asserts that this ball B_n(x) (and its volume) is independent of the choice of t(x). However, g^t and g^{t,+} explicitly depend on t(x). Generally, different choices of t(x) will lead to different metrics g^t (or g^{t,+}) and consequently different unit balls. The paper provides no proof or valid justification for why these unit balls would be identical or otherwise independent of t(x), which is a critical step for the overall argument."
      },
      {
        "Problem": "Flawed justification for the t-independence of the unit ball B_n(x)",
        "Location": "Page 7, point 2); Page 11, point 2)",
        "Explanation": "The paper attempts to justify the t-independence of B_n(x) by stating, for instance, 'since g^t is Riemannian, according to Remark 1, 3), the unit ball of g^t is the Euclidean unit ball B_n' (page 7). Remark 1.3, however, discusses the indicatrix of a Finsler function F that is itself Riemannian (i.e., F^2 is a quadratic form in y). The fact that an osculating metric g^t (or g^{t,+}) is Riemannian merely implies its unit ball is an ellipsoid (a 'Euclidean ball' in a general sense). It does not imply that this ellipsoid is a fixed, t-independent entity called 'the' Euclidean unit ball B_n, nor that the unit balls derived from different choices of t are identical. The reasoning conflates the existence of 'a' Euclidean unit ball for each g^t with all these balls being 'the same' fixed ball B_n."
      },
      {
        "Problem": "The main conclusion of a t-independent volume element is unsupported, invalidating its proposed utility",
        "Location": "Abstract; Page 2, first remark; Page 7, Definition 2 & Remark 3; Page 11, Definition 5 & Remark 1 (page 12); Equations (14), (20), (21)",
        "Explanation": "The central claim of the paper is the construction of a volume element for Finsler spacetimes that, despite requiring a time orientation for its construction, 'does not depend on its choice' (Abstract). This claimed t-independence is crucial for the volume element to be a canonical geometric object of the Finsler spacetime itself and for its applications in field theory (Eq. 21). However, if the integration domain B_n(x) is t-dependent (as indicated by the flaws in Problems 1 and 2), the resulting volume density σ(x) = (1/vol(B_n)) ∫_{B_n(x)} |g(x,y)| dy will generally depend on t. This would invalidate the main conclusion and render the proposed volume element dependent on an arbitrary auxiliary choice, undermining its fundamental significance."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 13499,
      "output": 804
    }
  },
  {
    "entry_id": 167,
    "retraction_id": "1301.0396v3",
    "paper_id": "1301.0396v2",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in Lemma 2.9",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear justification for the existence of X and {r_k} in step (Oplus)",
        "Location": "Page 8, Proof of Lemma 2.9, step (Oplus)",
        "Explanation": "The proof of Lemma 2.9 states: 'Since X is a countably block-splitting family there is X in X and there is an infinite set {r_k : k in w} of stages r such that (Oplus) (forall k in w)(X supseteq g_{r_k} AND X intersect g_{r_{k+1}} = emptyset).' The sets g_r are constructed within the proof as unions of blocks derived from names. Definition 2.8 defines a countably block-splitting family X with respect to given block sequences. It is not immediately clear how Definition 2.8 implies the existence of an X in X and an infinite sequence {r_k} satisfying the strong oscillatory property (Oplus) with respect to the constructed sequence of sets (g_r)_r. This step is critical for the sealing argument. While this might be a standard technique in such proofs, its direct derivation from the provided definition of countably block-splitting is not explicit."
      },
      {
        "Problem": "Argument for the semifilter S being 'not comeagre' is potentially flawed or unclear",
        "Location": "Page 12, Proof of Lemma 4.2 (last paragraph of proof)",
        "Explanation": "To show that the constructed semifilter S is not comeagre, the proof argues that for a finite-to-one function f (in V_a), the set f(S) is not C*-dense below s_a. The argument states: 'However, ([s_a]^omega, subseteq*) has 2^aleph_0 = aleph_2 pairwise almost disjoint subsets, and hence {f\"s_beta : beta < a}, being of size at most aleph_1, is not dense in ([s_a]^omega, subseteq*). So the whole set f(S) = {f\"s_beta : beta in omega_2} is not C*-dense below s_a.' There are issues here: \n1. The set {f\"s_beta : beta < a} has size at most |a| (if a is a cardinal, or aleph_1 if a < omega_2 and cf(a) > omega_0), not necessarily aleph_1. More importantly, the argument should concern the whole f(S) = {f\"s_beta : beta in omega_2}, which has size omega_2 (assuming 2^aleph_1 = aleph_2 from CH and Diamond(S^2_1) giving 2^aleph_1 = aleph_2, and the iteration preserves cardinals).\n2. Even if f(S) has size aleph_2 and there are aleph_2 p.a.d. subsets of s_a, it's not directly shown how this implies f(S) is not C*-dense below s_a (i.e., that there exists Z_0 subseteq* s_a such that for all beta, f(s_beta) is not subseteq* Z_0). The connection is not clearly established. An alternative argument using the <*-unboundedness property from (I4) and Larson's characterization of comeagre semifilters might be more direct and robust."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 16409,
      "output": 760
    }
  },
  {
    "entry_id": 168,
    "retraction_id": "1808.04792v3",
    "paper_id": "1808.04792v2",
    "retraction_comment": "The velocities in the radiative transfer analysis for each snapshot of the simulated collapsing core are a factor of 1.732 (the square root of 3) smaller along each of the three dimensions. This error is currently being rectified",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Overly Idealized Simulation Conditions",
        "Location": "Abstract, Section 2.1 (The numerical simulation, p. 4)",
        "Explanation": "The simulation assumes spherical symmetry and, critically, no turbulent component. Prestellar cores are known to be turbulent and often non-spherical. The absence of turbulence, a key factor in core structure and evolution, may lead to an unrepresentative 'outside-in' velocity profile (e.g., location and magnitude of peak infall speed relative to density distribution) and an oversimplified collapse dynamic. This makes it uncertain if the derived ~3-4 fold underestimation of infall speeds is broadly applicable to real cores, potentially limiting the universality of the conclusions."
      },
      {
        "Problem": "Assumption of Constant Molecular Abundances",
        "Location": "Section 2.3 (Considerations for the synthetic spectral data, p. 6)",
        "Explanation": "The study uses constant relative molecular abundances for HCO+ and N2H+. However, species like HCO+ are known to deplete significantly in the dense, cold centers of prestellar cores due to CO freeze-out, while N2H+ is more resilient. This chemical differentiation can alter the optical depth profiles of lines, changing which parts of the core are traced and affecting the shape of self-absorbed profiles (e.g., the depth and position of the central dip). Ignoring this could lead to inaccurate synthetic line profiles and thus flaw the quantitative comparison between 'actual' and 'inferred' infall speeds, impacting the main conclusion about the degree of underestimation."
      },
      {
        "Problem": "Dependence on a Specific 'Outside-In' Collapse Scenario",
        "Location": "Abstract, Section 2.1 (p. 4), Section 5.2.1 (Discussion of spherical collapse models, p. 16)",
        "Explanation": "The central conclusion that infall speeds are systematically and significantly underestimated (by factors of ~3-4) relies heavily on the specific 'outside-in' collapse profile generated in their simulation, where peak infall occurs at large radii in a lower-density envelope. This profile is a direct consequence of their initial conditions (a minor perturbation in a globally Jeans-unstable, uniform medium). If real prestellar cores form and evolve through a wider variety of mechanisms or initial conditions that do not consistently lead to this particular velocity and density structure, the claimed systematic and large underestimation of infall speeds may not be a universal characteristic, thereby limiting the general applicability of the main quantitative conclusion."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 6067,
      "output": 550
    }
  },
  {
    "entry_id": 169,
    "retraction_id": "1306.2988v2",
    "paper_id": "1306.2988v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The result claiming a factor 0.56 algorithm is invalid because of a crucial bug in Claim 2 which was brought to our attention by [REDACTED-NAME], [REDACTED-NAME], and [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Missing proof for Claim 1 (Stability Property)",
        "Location": "Claim 1 is stated on page 5. Its proof is referenced as by induction but is not provided in the appendix (page 15 only contains proofs for Claim 2 and Claim 3 of Lemma 7). Claim 1 is subsequently used in the proof of Lemma 1 (page 15, Appendix) and the proof of Claim 2 for Lemma 7 (page 15, Appendix).",
        "Explanation": "Claim 1 states that altering a single vertex's position in the permutation changes the matching by at most one component (path or cycle). This is a strong structural property. Its correctness is crucial as it's used to justify Lemma 1 (assuming worst-case graphs have a perfect matching) and in the proof of Claim 2 (part of Lemma 7, which is called a 'pivotal technical lemma'). Without a proof for Claim 1, the foundation for these subsequent results, and thus the main 0.56 lower bound, is weakened."
      },
      {
        "Problem": "Potentially incorrect probability calculations in the proof of the general upper bound (Theorem 13)",
        "Location": "Page 20, Appendix, 'Proof of Theorem 13'.",
        "Explanation": "The proof derives an upper bound of 19/24 (approx 0.7916) using Yao's Lemma on a specific 4-vertex graph. The derivation involves several conditional probabilities, for instance, 'given that the first edge that is scanned is found to be present, we find the optimal matching (of size 2) with probability 1/2'. A re-evaluation of this probability based on the graph structure {ab, bc, ca, da} (triangle with a pendant) suggests this might be 1/4 instead of 1/2, leading to a different expected value. If these intermediate probability calculations are incorrect, the claimed upper bound of 0.7916 for general randomized algorithms is not substantiated."
      },
      {
        "Problem": "Insufficient justification for Lemma 16, which claims deterministic 'revealing algorithms' are no worse than optimal deterministic Vertex-Iterative (VI) algorithms on a specific graph distribution",
        "Location": "Lemma 16 is stated on page 12, with its proof sketch on page 20 (Appendix).",
        "Explanation": "Lemma 16 is a critical step in deriving the 0.75 upper bound for VI algorithms. It bridges the gap between general VI algorithms and a more restricted class of 'revealing algorithms'. The proof sketch is very brief, especially concerning the case where a VI algorithm queries an edge involving a vertex that the simulating revealing algorithm considers 'inactive'. The argument that the revealing algorithm 'immediately gives up' for its current vertex without underperforming the VI algorithm needs more rigorous justification to ensure the class of revealing algorithms accurately captures the power of VI algorithms in this context."
      },
      {
        "Problem": "Use of a non-standard and un-derived mathematical formula in the analysis of the Random-Reveal algorithm's performance",
        "Location": "Page 21, Appendix, 'Proof of Claim 13' (which is part of the proof for Lemma 19).",
        "Explanation": "Claim 13 analyzes the behavior of the Random-Reveal (RR) algorithm when the chosen vertex 'v' is from the clique part 'C'. To establish that 4 vertices get matched in expectation, it relies on the statement: 'the average number of vertices in P that get probed by v is given by Sum_{i=1}^{k/2} i * (1/k) * (1/(k-i+1)) = 1'. This formula for the sum equaling 1 is not standard and its derivation is not provided. While a simpler probabilistic argument might yield a similar result (average of 1 P-vertex probed), relying on an un-derived, complex formula as a fact is a weakness. The correctness of this step is essential for Lemma 19 (E[RR(Γ)] = 0.75), which directly leads to the 0.75 upper bound for VI algorithms."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 9818,
      "output": 923
    }
  },
  {
    "entry_id": 170,
    "retraction_id": "1901.07086v3",
    "paper_id": "1901.07086v2",
    "retraction_comment": "The claim of Main Theorem 1 is wrong. The prime counting function on the complex plan does not satisfy the inequality. The prime number Theorem contradicts the claim",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of Gaussian Primes.",
        "Location": "Page 2, Definition 2, part (2)",
        "Explanation": "Part (2) of Definition 2 incorrectly states that for a Gaussian integer z = bi (where a=0), z is a Gaussian prime if |b| is an ordinary prime and |b| ≡ 1 (mod 4). The correct condition for |b| (an ordinary prime) is |b| ≡ 3 (mod 4). Primes p ≡ 1 (mod 4) are not prime in Z[i] but split as a sum of two squares. This fundamental error affects the criteria for identifying Gaussian primes lying on the imaginary (or real) axis, which is used in Case (II) of the main theorem."
      },
      {
        "Problem": "Flawed argument for existence of Gaussian primes on a line segment in Case I of the Main Theorem.",
        "Location": "Page 6, Proof of Main Theorem 1, Case (I)",
        "Explanation": "The proof for Case (I) (z1, z2 ≠ 0) claims to find (k-1)/2 Gaussian primes on the line segment [(z1,z2), (kz1,kz2)]. Given the condition gcd(z1,z2)=f(k)=d, the Gaussian integers on this segment are of the form (d+j)(a+ib), where z1=da, z2=db for integers a,b and j ranges from 0 to (k-1)d. If a+ib is not a unit (which is true if z1,z2 ≠ 0 and a+ib is not ±1, ±i, or ±1±i) and d+j > 1 (true since d=f(k)≥2 for k≥2), then (d+j)(a+ib) is a composite Gaussian integer. Thus, such a segment would not contain multiple Gaussian primes as claimed. The argument also erroneously tries to map ordinary primes (from Proposition 2) to norms of points specifically on this segment."
      },
      {
        "Problem": "Reliance on an overly strong and potentially misattributed version of the Generalized Bertrand's Postulate (Proposition 2).",
        "Location": "Page 4, Proposition 2; Page 6, Proof of Main Theorem 1",
        "Explanation": "Proposition 2 states that there are at least (k-1) primes between n and kn for n ≥ f(k) = ceil(1.1 ln(2.5k)), attributing this to Das et al. [3]. The cited paper [3] (Das and Paul, arXiv:1710.09891) appears to state a conjecture for π(kn) - π(n) ≥ 1, not a proof for a lower bound of (k-1) primes. If Proposition 2, in this strong form, is not a proven result, the main theorem's quantitative conclusion, which directly depends on this (k-1) factor, lacks a valid foundation."
      },
      {
        "Problem": "Misapplication of Chebyshev Bias for guaranteed counts in short intervals.",
        "Location": "Page 6, Proof of Main Theorem 1, Case (I) and Case (II)",
        "Explanation": "The proof uses Chebyshev Bias (which describes the asymptotic equidistribution of primes in arithmetic progressions) to assert that at least half of an alleged (k-1) primes in an interval (f(k), kf(k)) will be of a specific congruence class (e.g., p ≡ 1 mod 4 or p ≡ 3 mod 4). Asymptotic results generally do not provide such guaranteed lower bounds or exact proportions for specific, potentially small, intervals without invoking more powerful effective theorems or detailed error term analysis, which are not provided."
      },
      {
        "Problem": "Fundamentally problematic problem formulation: seeking multiple primes on a single line segment.",
        "Location": "Page 5, Definition 6 and Main Theorem 1; Page 6, Proof",
        "Explanation": "The paper defines its central problem as finding multiple Gaussian primes *on* a specific line segment [(z1,z2), (kz1,kz2)]. This formulation is highly restrictive and atypical for generalizations of Bertrand's Postulate to Gaussian primes, which usually concern the existence of primes within 2D regions (e.g., annuli). As argued in Problem 2, for Case I (z1,z2 ≠ 0), such line segments are generally populated by composite numbers (multiples of a base Gaussian integer), making the search for multiple primes on them inherently flawed."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 10149,
      "output": 1034
    }
  },
  {
    "entry_id": 171,
    "retraction_id": "2204.01118v2",
    "paper_id": "2204.01118v1",
    "retraction_comment": "In the proof of Theorem 5, page 10, line 1O, a term was missing in the r.h.s, that is \\|f''\\|_p^p",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of the finite difference operator Δ_h.",
        "Location": "Page 1, definitions of τ_h, Δ_h, and formula (1)",
        "Explanation": "The paper defines the translation operator as (τ_h f)(x) := f(x+h) - f(x). Then, the finite difference operator is defined as Δ_h f := τ_{-h} f - f. Substituting the definition of τ_{-h}f gives (Δ_h f)(x) = (f(x-h) - f(x)) - f(x) = f(x-h) - 2f(x). However, formula (1) for the m-th power of Δ_h, (Δ_h^m f)(x) = Σ_{k=0 to m} (m choose k) (-1)^{m-k} f(x+kh), implies that for m=1, (Δ_h f)(x) = f(x+h) - f(x). These two definitions of Δ_h f are contradictory and this inconsistency appears at the beginning of the paper."
      },
      {
        "Problem": "Gap in the proof of Proposition 3 regarding the condition f(0)=0.",
        "Location": "Page 4, Proof of Proposition 3",
        "Explanation": "The proof of Proposition 3 (characterizing functions f acting on L_p(Ω) for |Ω|<+∞) applies Proposition 2. However, Proposition 2 explicitly requires f(0)=0. For Proposition 3, where |Ω|<+∞, a function f can act on L_p(Ω) even if f(0) ≠ 0 (e.g., f(t)=c). The proof does not address how Proposition 2 can be applied if f(0) ≠ 0 (e.g., by considering f_0(t) = f(t)-f(0)). This is a logical gap in the argument."
      },
      {
        "Problem": "Unsound argument in the proof of Theorem 4 for p>1 involving U_j and inequality (18).",
        "Location": "Page 9, Proof of Theorem 4, definition of U_j and equation (18)",
        "Explanation": "In the proof of Theorem 4 (m=2 case), U_j is defined as U_j := ∫ |(f'' o g)(x)| |∂_j g(x)|^{2p} dx. Inequality (18) states ||(f'' o g)∂_j g ∂_k g||_p ≤ U_j^{1/(2p)} U_k^{1/(2p)}. For p=1, this inequality is correct by Cauchy-Schwarz. However, for p>1, this inequality, (∫|A|^p |B|^p |C|^p dx)^{1/p} ≤ (∫|A| |B|^{2p} dx)^{1/(2p)} (∫|A| |C|^{2p} dx)^{1/(2p)} (where A=|f''o g|, B=|∂_j g|, C=|∂_k g|), is not generally valid. The subsequent integration by parts argument for U_j also appears to implicitly use different definitions of the related function h(s) for p=1 (based on ∫|f''|) versus p>1 (based on ∫|f''|^p), suggesting an inconsistency with the single definition of U_j provided. This makes the argument for p>1 unsound as written."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 19572,
      "output": 794
    }
  },
  {
    "entry_id": 172,
    "retraction_id": "2001.10956v2",
    "paper_id": "2001.10956v1",
    "retraction_comment": "The second equation (2.22) is incorrect. The follow-up of the correct equation demands new developments, which I shall provide in a new version soon. wh",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Proposition 2.1",
        "Location": "Page 8, Equations (2.20)-(2.23)",
        "Explanation": "The proof provided for Proposition 2.1 contains significant flaws. Equation (2.20), which relates the coefficients $\\phi(k)$, appears to be inconsistent with the known action of the operator $\\mathcal{E}^\\flat$ unless the spectral parameter $i\\lambda=1$, which is not general. Additionally, equation (2.22) incorrectly identifies the Fourier coefficients of the distribution $\\mathfrak{N}_{\\chi,i\\lambda}$ when its arguments are scaled. While Proposition 2.1 itself is cited from previous work [15] and may be correct, its derivation within this paper is unsound."
      },
      {
        "Problem": "Incorrect application of Proposition 3.1 in the proof of Proposition 5.1",
        "Location": "Page 18, Equation (5.2) and subsequent application of Prop 3.1/Eq (3.27)",
        "Explanation": "In the proof of Proposition 5.1, the adjoint of the operator $p^{(N-k)(2i\\pi\\mathcal{E}^\\flat-1)}$ is incorrectly calculated in equation (5.2). This leads to an incorrect form for the test function against which $\\mathfrak{B}^1$ is paired. Proposition 3.1 (and its re-expression (3.27)) provides a bound for $\\langle \\mathfrak{B}^1, h_q \\rangle$ where $h_q(x,\\xi) = h(qx, q^{-1}\\xi)$. The test function derived in (5.2) is not of this specific form. Therefore, the direct application of the bound from Proposition 3.1 is unjustified, breaking a critical step in estimating the norm of $(T_p^{\\text{dist}})^{2N}\\mathfrak{B}^1$."
      },
      {
        "Problem": "Unexplained factor of $\\pi$ in an exponential decay term and its impact on the main theorem's final argument",
        "Location": "Page 22, Eq. (5.17) and Page 23, Eq. (5.20)",
        "Explanation": "Equation (5.17) presents an error term estimate involving $e^{-\\pi N\\beta \\eta^2}$. However, based on the definition of the localizing function $\\Phi_N(i\\lambda) = \\exp(-N\\beta(\\lambda-\\lambda_0)^2)$ in (5.11), this decay factor should likely be $e^{-N\\beta \\eta^2}$. The presence of this unexplained $\\pi$ makes the estimated decay stronger. If it is a typo, the condition on $\\beta$ required to control this error term (used in deriving (5.20)) would be more stringent (i.e., $\\beta$ would need to be larger by a factor of $\\pi$). This change could potentially make it impossible to satisfy the simultaneous inequalities in (5.20) needed to achieve the final contradiction in the proof of Theorem 5.4."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 18022,
      "output": 712
    }
  },
  {
    "entry_id": 173,
    "retraction_id": "1407.6492v2",
    "paper_id": "1407.6492v1",
    "retraction_comment": "This paper has been withdrawn by the main author due to the Table 1 and equation 2 errors",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Critical Ambiguity and Inconsistency in Feature Definitions",
        "Location": "Section 2 (Feature Extraction), specifically Sections 2.1 (Angle Features), 2.2 (Distance Feature), and 2.3 (Transit Feature)",
        "Explanation": "The definitions of the three core features (angle, distance, transit) are critically ambiguous, inconsistent, and lack sufficient detail for replication. \n1. Angle Feature (Sec 2.1): The term 'angle of white pixel to block horizontal level' is undefined; it's unclear how θk is calculated, what the reference points are, or whether it pertains to contour pixels (mentioned in Sec 2 intro), 'white pixels' (Sec 2.1), or foreground pixels. \n2. Distance Feature (Sec 2.2): The description is contradictory, referring to 'distance of white pixel' and then 'Euclidean distances from foreground pixel'. The 'agent point of block' is undefined, and the reference for distance measurement (e.g., 'left and bottom coroner of block') is vague. \n3. Transit Feature (Sec 2.3): The feature is described as a 'ratio' of Run Length Counts, but the specific ratio (e.g., horizontal RLC / vertical RLC, or sum of RLCs normalized by some factor) is not defined. \nThis lack of clarity and consistency in defining the fundamental features makes the proposed method irreproducible and its soundness difficult to assess."
      },
      {
        "Problem": "Major Inconsistency in Reported Test Dataset Size",
        "Location": "Abstract (page 1), Section 3 (page 4, paragraph 1), and Table 1 (page 4)",
        "Explanation": "There is a significant and unexplained discrepancy in the reported size of the test dataset. The abstract and the main text (page 4, first paragraph of Section 3) state that for one experiment, 15,000 samples were used for training and 5,000 samples for testing, achieving 99.82% accuracy. The text also mentions a total dataset of 20,000 samples for cross-validation. However, Table 1 (page 4) lists the test set size for 'Our proposed method' (achieving 99.82%) and 'Our proposed method With 4 subset' (achieving 99.90%) as 50,000 samples. This is a tenfold increase from the 5,000 test samples mentioned elsewhere and exceeds the stated total dataset size of 20,000 used for experiments. This major inconsistency makes it impossible to ascertain the true scale of the evaluation and casts serious doubt on the reliability and comparability of the reported performance figures."
      },
      {
        "Problem": "Misleading Presentation of Performance on Training Data",
        "Location": "Section 3 (page 4, paragraph 1) and Table 1 (page 4)",
        "Explanation": "The paper presents accuracy on the training data in a potentially misleading manner. It states, 'From the experiment, we got an accuracy of 100% when the 20,000 data were used as training and the same data set was used for testing.' While testing on training data can be a sanity check, reporting this 100% accuracy as a key experimental result is misleading because it does not reflect the model's generalization performance on unseen data. Furthermore, Table 1 includes a 'Train Acc' column where 'Our proposed method' and 'Our proposed method With 4 subset' are listed with 100% accuracy. Presenting this training set accuracy alongside test accuracies for other methods, without strong caveats, can inflate the perceived performance of the proposed method, as it's not a standard measure of generalization capability."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 4960,
      "output": 834
    }
  },
  {
    "entry_id": 174,
    "retraction_id": "1802.06370v4",
    "paper_id": "1802.06370v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial explanation error of redundancy",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formulation of the limit to recover the standard Hamiltonian H0 from the Cabbatonian Hj.",
        "Location": "Page 7, Equation (2.27)",
        "Explanation": "Equation (2.27) presents a limit process to recover H0 from Hj involving a sum of terms mλk². If Hj is a nested exponential structure like Hj = -mλj² exp(-Hj-1/mλj²), then recovering Hj-1 from Hj involves (Hj + mλj²). A sequential limit process, lim_{λ1}(...(lim_{λj}(Hj + mλj²))... + mλ1²), would be needed. The simultaneous limit Π lim_{λk→∞} applied to (Hj + Σ mλk²) is incorrect because terms like mλ_{k<j}² would remain when they shouldn't, or the sum itself is not the correct term to add for a nested structure where only the outermost λ parameter is dealt with at each step of the limit."
      },
      {
        "Problem": "Unsound derivation of the Lagrangian hierarchy Lj, particularly for j ≥ 2.",
        "Location": "Page 9, Section 2.4, specifically equations (2.35)-(2.37).",
        "Explanation": "The derivation of the Lagrangian L2 (and by extension, Lj for j≥2) appears flawed. Equation (2.35) defines p2 as being proportional to ṗ0 (the time derivative of the standard momentum), derived from p2 = -∂H2/∂x. However, equation (2.36) then presents a different p2, defined by an integral, which is then used in the Legendre transformation to obtain L2 in (2.37). The canonical momentum p that appears in H2(p,x) and in the term pẋ of the Legendre transform L2 = pẋ - H2(p,x) must be consistently defined, typically by inverting ẋ = ∂H2/∂p. Using two different definitions or sources for 'p2' in the same derivation process is inconsistent and invalidates the resulting L2."
      },
      {
        "Problem": "Incorrect claim of infinite distinct equations of motion arising from individual terms of an expanded Lagrangian.",
        "Location": "Page 13, Equation (3.15) and surrounding text.",
        "Explanation": "The paper states that for the harmonic oscillator, the Lagrangian Lλ can be expanded as Lλ = Σ c_k L_k, and that the least action principle (δS=0) 'gives infinite copies of the Euler-Lagrangian equation d²x/dtk² = -(k/m)x, k=1,2,3,...'. This is a misinterpretation. A single Lagrangian Lλ for a given physical system yields one equation of motion (possibly in a rescaled time). The individual terms Lk in its expansion do not each satisfy their own distinct equations of motion where a physical parameter (like the effective spring constant implied by 'k/m', if 'k' is the index) changes with the term index. This would imply the system simultaneously obeys an infinite set of different physical laws."
      },
      {
        "Problem": "Misleading or incorrect summary equation for the existence of infinite Hamiltonians.",
        "Location": "Page 15, Equation (4.1).",
        "Explanation": "The concluding summary presents equation (4.1): 'F' - ṗ = ṗ ∂H/∂p + (p/m) ∂H/∂x' as the equation for which infinite Hamiltonians exist, where F' = -dV(x)/dx. This equation is not the primary PDE (e.g., eq. 2.2: (1/m)∂H/∂x + ṗ ∂²H/∂p² + (p/m)∂²H/∂p∂x = 0) that was used throughout the paper to derive the families of Hamiltonians. Equation (4.1) is obscure, its derivation is not provided in this context, and it does not accurately represent the conditions (like (2.2) combined with (2.7) for the function F) that the new Hamiltonians were shown to satisfy. This misrepresents the core mathematical basis of the paper's findings."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 17802,
      "output": 951
    }
  },
  {
    "entry_id": 175,
    "retraction_id": "1403.0340v2",
    "paper_id": "1403.0340v1",
    "retraction_comment": "This paper has been withdrawn by the author because of Projection measurement tacit usage (while generalized one should have been used)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated claim of teleportation impossibility for general stochastic qudits.",
        "Location": "Page 11, statement before Eq. (66)",
        "Explanation": "The paper claims that teleportation of a general stochastic qudit (a qubit entangled with a two-state detector, as defined in Eq. 61) is 'impossible' except for special initial states (Eq. 66). This is a critical limitation of their proposed system. However, no proof or detailed explanation for this impossibility is provided. Standard teleportation principles suggest that an arbitrary state of a d-level system can be teleported using a shared maximally entangled state of two d-level systems and appropriate local measurements and corrections. The stochastic qudit in Section 6 is a 4-level system. The claim of impossibility, without justification, undermines the generality and utility of the proposed teleportation scheme for these states."
      },
      {
        "Problem": "Incorrect expansion of l=1 stochastic Bell states.",
        "Location": "Page 7, Eqs. (29)-(32)",
        "Explanation": "The expansion of the l=1 stochastic Bell states (defined in Eqs. 25-26) into ordinary qubit Bell states and detector states appears to be incorrect. A direct calculation of the coefficients and detector state combinations (e.g., for the detector part |ψ^{++}⟩ associated with the |Ψ⁺⟩ qubit Bell state in the expansion of |Ψ⁺_{stochastic}⟩) yields results that differ significantly from those presented in Eqs. (29)-(32). Since these expansions describe the entanglement structure, errors here would invalidate conclusions drawn about the nature of these states and their use in protocols like teleportation discussed in Section 5."
      },
      {
        "Problem": "Flawed recovery operations in Section 6.2 teleportation.",
        "Location": "Page 12, description of Bob's operations after Eq. (69)",
        "Explanation": "For the teleportation protocol in Section 6.2 (for stochastic qubits with a two-state detector), the local unitary corrections Bob needs to perform to recover the original state (of special form Eq. 66) are not all correctly identified or justified. For instance, if Alice's measurement outcome corresponds to a Φ-type Bell state (implying Bob's state is, e.g., μ|D₀0⟩ - λ|D₁1⟩ when the target is μ|D₀0⟩ + λ|D₁1⟩), the paper suggests Bob performs an X or Y operation on the micro-detector. Applying such an operation (e.g., swapping detector states |ξ⁺⟩ ↔ |ξ⁻⟩) does not appear to recover the target state. A Z-like operation on the detector or qubit might be needed for certain outcomes, which is not what is stated. This indicates the protocol description for recovery is flawed."
      },
      {
        "Problem": "Mischaracterization of stochastic Bell states in Section 6.1.",
        "Location": "Page 10, statement after Eq. (60)",
        "Explanation": "The paper claims that the stochastic Bell states defined in Eqs. (44)-(47) for a qubit and a two-state detector 'are maximally entangled states of the ordinary qubits Bell states and the micro-detectors Bell states.' This implies a product structure like |Bell_{Qubit}⟩ ⊗ |Bell_{Detector}⟩. However, the defined states (e.g., Φ^{(α)(β)}) are GHZ-like states of the four involved two-level systems (two qubits and two detectors, e.g., (1/√2) [ |ξ⁺_A ξ⁺_B⟩|0_A 0_B⟩ + |ξ⁻_A ξ⁻_B⟩|1_A 1_B⟩ ] for Φ^{(+)(+)}). They are not separable into a qubit Bell state part and a detector Bell state part, nor does tracing out one pair leave the other in a Bell state. This represents a fundamental misunderstanding or misstatement of the entanglement structure of these key states."
      },
      {
        "Problem": "Formulation of inner product in Eq. (18) is unclear and likely incorrect.",
        "Location": "Page 6, Eq. (18)",
        "Explanation": "Equation (18), which defines the inner product (or overlap) of two stochastic qubit states |η^{jlJM}⟩, appears to be incorrectly formulated. The use of a single index 'm' for the detector's angular momentum projection in both Clebsch-Gordan coefficients and the detector state overlap ⟨ξ^{lm}_{q,p}|ξ^{lm}_{q',p'}⟩ is inconsistent with the definition of these states where 'm' (the detector's angular momentum projection) depends on M (total projection) and j_z (qubit projection), specifically m = M-j_z. Thus, the 'm' values associated with different j_z components within a single η state are different, and this is not properly reflected in the structure of Eq. (18). The factor 1/(2J+1) is also unusual for a simple overlap between two specific states. While not directly used in the main teleportation arguments later, it indicates a lack of rigor in fundamental definitions."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 16494,
      "output": 1165
    }
  },
  {
    "entry_id": 176,
    "retraction_id": "2106.01585v2",
    "paper_id": "2106.01585v1",
    "retraction_comment": "The proof of Lemma 3.1 has a gap. While there is exponential mixing for Holder functions, the rate of the mixing depends on the Holder exponent of the function. This leads to a vicious circle",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated control of higher norms for the new error term R^(1)",
        "Location": "Page 15, Lemma 3.12 and its proof",
        "Explanation": "The proof of Lemma 3.12, which estimates the C^(k+k_bar) norm of the new error term R^(1), crucially relies on citing '[DK10b, Section 5.2]'. However, [DK10b] deals with Z^k actions on tori and its methods are heavily based on Fourier analysis. The current paper explicitly states that Fourier analysis is 'not available' or 'not easily used' for nilmanifolds (page 2). Estimating derivatives of R^(1) (which involves compositions and Baker-Campbell-Hausdorff terms) in the nilmanifold setting requires a dedicated proof that is not provided. This omission represents a significant gap, as controlling higher norms of the error term is essential for the KAM scheme to yield a smooth conjugacy."
      },
      {
        "Problem": "Inconsistent inductive hypothesis and derivation for higher norms in KAM iteration",
        "Location": "Page 15, Equations (4.1), (4.2), and Page 16, derivation of ||R^(n+1)||_Ckn+1",
        "Explanation": "The KAM iteration scheme appears to use an inductive hypothesis (4.2) ||R^(n)||_Ckn << epsilon_n^(-1), where epsilon_n = ||R^(n)||_C0. This implies that higher norms of the error R^(n) grow very rapidly as its C0 norm decreases. This is atypical and problematic for KAM convergence. Furthermore, the derivation on page 16 to show that ||R^(n+1)||_Ckn+1 satisfies this hypothesis for the next step (i.e., ||R^(n+1)||_Ckn+1 << epsilon_(n+1)^(-1)) seems flawed. The paper shows ||R^(n+1)||_Ckn+1 << epsilon_n^(1/2). For this to be compatible with epsilon_(n+1)^(-1) = (epsilon_n^(3/2))^(-1) = epsilon_n^(-3/2), it would require epsilon_n^(1/2) << epsilon_n^(-3/2) (for small epsilon_n < 1), which is false. This inconsistency undermines the convergence of the KAM scheme for higher norms."
      },
      {
        "Problem": "Contradictory argument for achieving C-infinity regularity",
        "Location": "Page 8, Remark on smoothness; Page 16, final paragraph detailing C-infinity argument",
        "Explanation": "The paper claims C-infinity conjugacy by arguing that the KAM scheme can be run for arbitrarily high target regularity C^L (by choosing a parameter k' large enough), and then uses uniqueness of conjugacies. However, a remark on page 8 states: 'We note that the implied constants may explode uncontrollably as k' increases. Therefore, we work with a fixed smoothness k+k'...'. This statement directly contradicts the strategy for obtaining C-infinity regularity. If the implicit constants in the KAM estimates explode with the target regularity k', the initial smallness condition on the perturbation would necessarily depend on k'. This would mean that a single, fixed C^k-small perturbation cannot be shown to be C^L-conjugate for arbitrarily high L by this method, making the final step to C-infinity unsound."
      },
      {
        "Problem": "Insufficient justification for Hölder regularity of the solution w_lambda",
        "Location": "Page 8, paragraph preceding Lemma 3.1, and proof of Lemma 3.1",
        "Explanation": "The construction of the approximate solution w to the linearized conjugacy equation involves series defining w_lambda. The paper asserts 'each w_lambda defines a Hölder function' and subsequently uses this assertion (e.g., 'since w_lambda^+ is Hölder' in the proof of Lemma 3.1). While the series for w_lambda might converge in some distributional sense due to exponential mixing properties, a rigorous proof establishing Hölder regularity with appropriate quantitative bounds (e.g., for ||w||_C1, which is used in Lemma 3.6) is not adequately provided. This step is crucial, as the regularity of w and its norm estimates directly impact the validity of subsequent estimates within the KAM scheme."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 12478,
      "output": 965
    }
  },
  {
    "entry_id": 177,
    "retraction_id": "1509.00106v3",
    "paper_id": "1509.00106v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (21)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency in the derivation of optimal γ₀ and final complexity bound (Eq. 26)",
        "Location": "Page 11, Eq. (25) to Eq. (26) and choice of γ₀",
        "Explanation": "Lemma 1 (page 6) states that L_f_bar = 1 for the Lipschitz constant of the smoothed function's gradient (L_f_γ = γ⁻¹ L_f_bar). This L_f_bar = 1 is used in Eq. (22) and subsequently in Eq. (25). However, the formula for the initial γ₀ chosen on page 11 to derive Eq. (26) introduces an explicit ||A|| factor. Correspondingly, Eq. (26) also contains an explicit ||A|| factor. If L_f_bar = 1 is correct (which it appears to be for the specific smoothing form), this introduction of ||A|| into γ₀ and Eq. (26) is not justified by the preceding Eq. (25) (where L_f_bar=1). The dependence on A should primarily come through the D_UA term. This discrepancy makes the claimed optimal γ₀ and the precise form of the complexity in Eq. (26) unsound."
      },
      {
        "Problem": "Incorrect application of theoretical results in Section 4.3 (Over-complete linear operator)",
        "Location": "Page 13-14, Section 4.3, specifically around Eq. (28)-(31) and Rk estimation",
        "Explanation": "Section 4.3 introduces a smoothed function f_γ(x) (Eq. 28) that is different from the paper's main proposed smoothing (Eq. 7). Eq. (28) corresponds to standard Nesterov smoothing, for which L_f_bar would typically be ||A||²/μ_b_U. The section then attempts to apply results and definitions (e.g., the structure of Rk from Eq. 16, leading to conditions for c̄₁) that were derived for the novel smoothing structure of Eq. (7). For example, the Rk estimation at the bottom of page 13 refers to terms like b_U(u*(x̃ᵏ)) and A(u*(xᵏ) - u*(x̃ᵏ)), which are appropriate for standard smoothing, but the conditions derived for c̄₁ (Eq. 30) and the claim that Theorem 1's convergence guarantee (Eq. 31) applies are based on the framework developed for Eq. (7). This mixing of frameworks makes the analysis in Section 4.3 unsound."
      },
      {
        "Problem": "Numerical experiments may not validate the main proposed algorithm",
        "Location": "Page 18, Section 6 (Numerical Experiments)",
        "Explanation": "The numerical experiments in Section 6 appear to use settings and refer to results from Section 4.3. For instance, on page 18, for the square-root LASSO problem, it mentions choosing 'the constant c̄₁ := max{1+k₀⁻¹, cond(BBᵀ)} as suggested by (30)'. Equation (30) defines c̄₁ for the over-complete operator case (Section 4.3), which uses standard smoothing (Eq. 28). The experiments also refer to Eq. (31) for the theoretical upper bound, which is also from Section 4.3. If the experiments are indeed based on the (potentially flawed) Section 4.3 analysis and its associated standard smoothing function, they do not directly validate the performance or theoretical benefits (e.g., the L_f_bar=1 property) of the main novel smoothing algorithm proposed in Eq. (7) and analyzed in Sections 2-3 and Theorem 1."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 20300,
      "output": 849
    }
  },
  {
    "entry_id": 178,
    "retraction_id": "1905.01749v2",
    "paper_id": "1905.01749v1",
    "retraction_comment": "There is a serious flaw with Theorems 2-4 which makes their results incorrect. We are working on fixing the issue and uploading a new version of this paper. This flaw, however, does not in any way affect the correctness of evaluations and the gains obtained using the proposed approach",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Greedy construction of partition hierarchy limiting solution space.",
        "Location": "Page 7, Algorithm 4, Section V-D",
        "Explanation": "The hierarchical partitioning (Algorithm 4) builds its layers by greedily merging the two current \"fastest\" partitions based on ranks derived from individual estimations. This strategy, while inspired by a simplified model (Section IV), might not generate a hierarchy that includes the globally optimal or near-optimal partitioning for a general network topology with complex shared bottlenecks. The best overall solution might lie outside the set of partitions explored by this specific greedy construction method, potentially leading to suboptimal performance despite selecting the best layer from this limited hierarchy."
      },
      {
        "Problem": "Potential looseness of the evaluation's lower bound may overstate relative performance.",
        "Location": "Page 8, Section VI-A (description of aggregate topology and lower bound); Page 11, Figure 7 (comparison against lower bound)",
        "Explanation": "The lower bound on completion times used for evaluation is derived from a highly simplified \"aggregate topology\" that assumes no internal network bottlenecks and is acknowledged by the authors as likely unachievable. If this lower bound is significantly loose (i.e., far below the true optimal performance on the actual topology), then Iris appearing \"close\" to it, especially under high load (as suggested in Fig. 7), does not provide strong evidence of its near-optimality relative to what is actually achievable on the test topologies."
      },
      {
        "Problem": "Impact of capacity scaling in Mininet emulations on result validity.",
        "Location": "Page 10, Section VI-C (\"Mininet Emulations\")",
        "Explanation": "Emulations were conducted with significantly scaled-down link capacities (e.g., maximum 500 Mbps for downlinks) compared to typical inter-datacenter WANs (which often have multi-Gbps links). This scaling, performed to manage CPU overhead in Mininet, can alter the network's bottleneck locations and characteristics, as well as the relative impact of different links on overall transfer performance. Consequently, the quantitative results and observed behaviors in the scaled emulation environment may not accurately translate to real-world, full-scale deployments."
      },
      {
        "Problem": "Optimistic assumption in initial completion time estimation may lead to suboptimal decisions.",
        "Location": "Page 7, Algorithm 2 description (\"MinimumCompletionTimes\"), and its use in Algorithm 3 & 4",
        "Explanation": "The initial estimation of partition completion times (Algorithm 2), which is critical for ranking receivers (Algorithm 3) and subsequent partitioning decisions (Algorithm 4), assumes that a new transfer request gets exclusive access to all the available bandwidth on its path. In realistic scenarios with concurrent transfer arrivals or dynamically fluctuating available bandwidth due to other traffic, this optimistic assumption can lead to inaccurate completion time estimates. These flawed estimates can result in incorrect receiver rankings and, ultimately, suboptimal partitioning choices made by the Iris system."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 4465,
      "output": 653
    }
  },
  {
    "entry_id": 179,
    "retraction_id": "1312.6644v4",
    "paper_id": "1312.6644v3",
    "retraction_comment": "This paper has been withdrawn by the author because Eqs. (7) and (8) are not correct. An update with corrected expressions and plots will follow soon",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous or potentially incorrect definition of local temperature for coupled systems.",
        "Location": "Page 2, paragraph after Eq (2), definition of T_i; potentially affecting Fig 4a.",
        "Explanation": "The paper defines local temperature T_i using the formula `coth(ħV_R^(1/2)/(2k_B T_i)) = 2(PPT)_ii / (mħV_R^(1/2))`. Here, V_R is the renormalized potential matrix for the entire system. It is unclear how V_R^(1/2) (a matrix square root) is used to obtain a scalar frequency or quantity corresponding to the i-th degree of freedom for this formula. While the high-temperature limit T_i = (PPT)_ii/(mk_B) is standard, if the temperature profiles in Fig 4a are based on the more general but ambiguous coth form, their accuracy and the subsequent conclusions about deviations from Fourier's law could be compromised."
      },
      {
        "Problem": "The claim of 'heat superconductor' behavior (κ ~ L) in 2D and 3D ordered crystals relies heavily on an unpublished theorem from the authors' own work.",
        "Location": "Page 4, first paragraph; Abstract; Page 1, first paragraph.",
        "Explanation": "The paper asserts that 1D, 2D, and 3D ordered ion crystals all exhibit thermal conductivity κ proportional to system length L (behaving as 'heat superconductors'). This crucial claim for 2D and 3D systems is primarily justified by citing a general theorem from the authors' own recent preprint [7], which states that any system symmetric with respect to reservoir interchange shows this κ ~ L scaling in the weak coupling limit. Relying on such a strong and broad theorem from an unpublished source for a central conclusion, especially for 2D/3D systems where transport is complex, makes the conclusion less independently verifiable. More direct evidence or detailed reasoning for ballistic transport in their specific 2D/3D crystal models would strengthen this claim."
      },
      {
        "Problem": "Insufficient physical explanation for the 'hyper sensitivity' of 2D/3D crystals to disorder and the insulating behavior of disordered 2D crystals.",
        "Location": "Page 4, discussion of Fig 2 and Fig 3a; Abstract.",
        "Explanation": "The paper reports a striking 'hyper sensitivity' of 2D (zig-zag) and 3D (helicoidal) crystals to on-site disorder, leading to a rapid decrease in thermal conductivity, with disordered 2D crystals becoming 'heat insulators'. In contrast, 1D crystals are much less sensitive. However, the paper does not provide a detailed physical mechanism to explain *why* these higher-dimensional structures exhibit such pronounced sensitivity or why disordered 2D systems specifically become insulators (e.g., through detailed analysis of mode localization, phonon scattering mechanisms, or density of states arguments specific to these ion crystal structures). This lack of mechanistic explanation for a key finding is a significant gap."
      },
      {
        "Problem": "The justification for high-frequency modes dominating heat transport is weak and potentially counterintuitive.",
        "Location": "Page 5, discussion of Eq (9) and Fig 3b.",
        "Explanation": "The paper claims that 'the largest contributions [to heat current] come from the modes with higher frequencies' because 'those are the normal modes with greater amplitude in the ends of the crystals, and therefore are the ones most coupled to the reservoirs.' This explanation is not well-substantiated. High-frequency modes are often more susceptible to scattering and localization, and their larger amplitude at the ends is not an obvious general property. The argument needs stronger physical backing or reference to specific mode characteristics within their model. Additionally, the x-axis label ω/ω_c in Fig 3b is undefined, obscuring the interpretation of the presented mode contributions."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 6079,
      "output": 862
    }
  },
  {
    "entry_id": 180,
    "retraction_id": "2103.11473v2",
    "paper_id": "2103.11473v1",
    "retraction_comment": "The proof of the cluster property (E4) for the superposition is wrong. [REDACTED-NAME] and [REDACTED-NAME] gave a counterexample s.t. the statement of cluster property can't hold in its full generality",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of the cluster property (OS axiom E4) is flawed, and the claim that E4 holds for the constructed Schwinger functions $S_{n,\\rho}$ is likely incorrect if the measure $\\rho$ is not a Dirac delta measure.",
        "Location": "Page 7, Proof of Theorem 2.7, argument for property (2.17) / (E4)",
        "Explanation": "The proof of the cluster property (E4) relies on showing that any time-translationally invariant state $\\Psi \\in H_\\rho$ must be proportional to the vacuum state $[\\Omega]_\\rho$ (property (2.17), equivalent to (2.16) which is E4). The argument proceeds by mapping $\\Psi$ via an isometry $U$ to the direct integral Hilbert space $\\mathcal{H} = \\int_{[m_0, \\infty)}^{\\oplus} H_m \\rho(dm)$. It correctly deduces that if $T_t^\\rho \\Psi = \\Psi$, then $(U\\Psi)(m) = c(m)[\\Omega]_m$ for $\\rho$-almost all $m$, where $c(m)$ is a measurable function and $[\\Omega]_m$ is the vacuum in $H_m$. However, the proof then states: 'Eventually, we obtain $\\Psi = [\\Omega]_\\rho$ since $U$ is injective which finishes the proof.' This inference is incorrect. For $\\Psi$ to be proportional to $[\\Omega]_\\rho$ (i.e., $\\Psi = c_0 [\\Omega]_\\rho$ for some constant $c_0$), the function $c(m)$ must be constant $\\rho$-a.e. The injectivity of $U$ only implies that if $U\\Psi = U(c_0[\\Omega]_\\rho)$, then $\\Psi = c_0[\\Omega]_\\rho$. The crucial step of proving $c(m)$ is constant is missing. For a superposition of distinct free fields (i.e., when $\\rho$ is not a Dirac delta measure), the space of invariant vectors $(c(m)[\\Omega]_m)_m$ that are in the image of $U$ (or its closure) is generally not restricted to those where $c(m)$ is constant. Such mixtures are known to lead to reducible theories with non-unique vacua (the center of the associated von Neumann algebra is non-trivial, isomorphic to $L^\\infty(\\text{supp}(\\rho))$), for which the cluster property (E4) in its strong form (implying a unique vacuum) does not hold. This flaw is critical as satisfying all OS axioms, including (E4), is the main claim of the paper (Theorem 2.7 and Abstract)."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 15383,
      "output": 622
    }
  },
  {
    "entry_id": 181,
    "retraction_id": "1303.6851v2",
    "paper_id": "1303.6851v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a loophole in the argument of the classical bound",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misleading 'Classical' Derivation of the Tsirelson Bound",
        "Location": "Section III.A, specifically the reasoning leading to and interpretation of Eq. (19) on page 4.",
        "Explanation": "The paper claims to derive the Tsirelson bound of 2√2 for a 'classical' system using Eqs. (17)-(19). While the mathematical steps to arrive at the inequality |E[CHSH]| ≤ √(2+2E[BαBβ]) + √(2-2E[BαBβ]) ≤ 2√2 are valid for general classical random variables (with outcomes ±1 and appropriate mean values), calling this model 'classical' in the context of Bell's theorem is misleading. The standard classical bound of 2 in the CHSH inequality arises from the assumption of local realism (Local Hidden Variable models). The paper's 'classical' derivation does not impose these local realism constraints. Therefore, achieving 2√2 in this less constrained model does not imply that 'nonlocality can also exist classically' in the sense relevant to Bell's theorem, nor does it trivialize the quantum-classical distinction that Bell tests highlight. The conclusion that 'the notion of nonlocality becomes trivial' based on this derivation is unsound."
      },
      {
        "Problem": "Flawed Argument Regarding the Physicality and Comparability of Nonlocal Boxes (PR Boxes)",
        "Location": "Section III.B, page 4, particularly the paragraph discussing the inconsistency of local probabilities for the nonlocal box and the conclusions drawn.",
        "Explanation": "The paper argues that the nonlocal box (PR box), which maximally violates the CHSH inequality up to 4, is 'not physically comparable with the quantum one' (page 1) or 'not physical' (page 5) because its definition leads to inconsistencies in assigning local probabilities (e.g., deducing B=B' and B=-B' simultaneously). These inconsistencies are, in fact, a manifestation of the PR box's extreme non-classical nature and its violation of local realism. Dismissing the PR box as 'counterfactual' or 'not physical' on this basis is a philosophical stance that sidesteps its theoretical importance in exploring the boundaries of correlations. The argument does not 'falsify the physical foundation for the existence of nonlocality' as claimed; rather, it uses the very properties that define strong nonlocality as a reason to dismiss the concept."
      },
      {
        "Problem": "Unsupported Reinterpretation of 'Nonlocality' based on its Connection to the Uncertainty Principle",
        "Location": "Throughout the paper, e.g., Abstract; Introduction (p. 1, col. 2, para 1); Section II conclusion (p. 3, col. 1, last para); Section IV (p. 5, 'Local, global, and relational' and 'To conclude...').",
        "Explanation": "The paper repeatedly argues that because the quantum (Tsirelson) bound for CHSH correlations can be derived from the uncertainty principle, the phenomenon observed in Bell tests is not 'nonlocality' but merely a consequence of uncertainty. While the mathematical link between the uncertainty principle and the Tsirelson bound is established (and cited), concluding that this invalidates 'nonlocality' as a 'physically valid concept' is an unsupported reinterpretation. In the context of Bell's theorem, 'nonlocality' refers to correlations that cannot be explained by local hidden variable (LHV) theories. Quantum mechanics, with its inherent uncertainty relations, produces such correlations. Attributing these correlations solely to 'uncertainty' and thereby dismissing 'nonlocality' does not address the fundamental conflict between quantum predictions and the worldview of local realism. The paper redefines nonlocality rather than providing a sound argument against its standard understanding and implications."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 10046,
      "output": 825
    }
  },
  {
    "entry_id": 182,
    "retraction_id": "1208.2556v2",
    "paper_id": "1208.2556v1",
    "retraction_comment": "This paper has been withdrawn by the author due to some nodes in the graph have not been taken into account",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradiction in parity of d(i-2) in Lemma 2.1 proof.",
        "Location": "Page 2, Proof of Lemma 2.1, paragraph starting 'Let di-2 be even...' and paragraph starting 'It follows d2 = C^(6)(di-3)...'",
        "Explanation": "The proof first deduces that d(i-2) must be odd (for cycles ≠ {4,2,1}). However, the subsequent formula for d2, given as C^(6)(di-3) = (3( (3( (di-3/2)/2 )+1 )/2)+1)/2, implies a sequence of operations where d(i-2) (which is di-3/2) must be even, because the next operation applied to it is division by 2 (i.e., (di-3/2)/2). This is a fundamental contradiction regarding the parity of d(i-2), which undermines the derivation of the formula for d2 and consequently the structure of the cycle asserted in Lemma 2.1."
      },
      {
        "Problem": "Miscalculated formula for d2 in Lemma 2.1.",
        "Location": "Page 2, Proof of Lemma 2.1, formula 'd2 = C^(6)(di-3) = (9di-3+10)/16'",
        "Explanation": "Assuming the sequence of Collatz operations implied by the structure (3((3((di-3/2)/2)+1)/2)+1)/2 (despite the parity contradiction mentioned in Problem 1), a careful expansion yields (9di-3+20)/16, not (9di-3+10)/16. This calculation error in the constant term (20 vs 10) is significant. If the constant were 20, the derived forms of di-3 (from 16k+6 to 16k+12) and d2 (from 9k+4 to 9k+8) would change, invalidating the specific structure asserted in Lemma 2.1 (e.g., d0=36k+16) which is crucial for the main proof."
      },
      {
        "Problem": "Systematic misclassification of m0 type in the main proof.",
        "Location": "Page 4, paragraph starting 'Let k = 9q for mo = max(M)...', and similar statements for other cases of k on pages 4, 5, and 6.",
        "Explanation": "The main proof assumes that m0 = 36k+16 (the maximum element of a cycle from Lemma 2.1) corresponds to 'Node A' which is of type 9a+7 (or 9a+16, implying the coefficient 'a' of 9 is even). However, 36k+16 can be written as 9(4k+1)+7. Since 4k+1 is always odd for any integer k, m0 is always of the form 9b+7 (where 'b' is the odd coefficient 4k+1). This systematic misidentification of m0's type (as a '9a+...' type instead of '9b+...' type) invalidates the starting node for the backward trace analysis in all cases considered in the main proof (pages 4-6)."
      },
      {
        "Problem": "Erroneous contradiction claim in the main proof for the case k=9q.",
        "Location": "Page 4, paragraph 'Let k = 9q...'",
        "Explanation": "In the main proof, when analyzing the case k=9q, the argument traces m0 backwards. It reaches mi-1 (representing d(i-1) in the cycle) which is of type 9b+1 (Node H). The paper then claims 'There is no mi-2 = κ^(-1)(n) for H as required from Lemma 2.1.' This claim is false. For Node H (9b+1, where b=24q+1 is odd), the inverse operation κ^(-1)(n)=(n-1)/3 is applicable because (n-1)/3 = 3b results in an odd number (72q+3). This resulting mi-2 (representing d(i-2)) is odd and matches the form 8k+3 (specifically, 8(9q)+3) as predicted by Lemma 2.1. Therefore, the claimed contradiction does not exist; the calculation is consistent with Lemma 2.1."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 16869,
      "output": 1024
    }
  },
  {
    "entry_id": 183,
    "retraction_id": "1804.05635v2",
    "paper_id": "1804.05635v1",
    "retraction_comment": "Theorem 1 is questionable and needs revision. Others parts should also be modified accorrdingly. Before the new version is ready, this version should not be referred",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Theorem 4 (consistency of winners with centralized greedy algorithm) is incomplete. It does not address the scenario where an agent is a loser in the centralized algorithm due to its valuation being less than its critical value, while still fitting resource constraints. In the decentralized algorithm, if other agents bid less than their true valuations, this agent's critical value might decrease, potentially allowing it to become a winner, which would contradict the claim of an identical set of winners.",
        "Location": "Page 8, Proof of Theorem 4",
        "Explanation": "The proof for the case where a centralized loser (`xk''=0`) is also a decentralized loser (`xk'=0`) primarily argues based on resource infeasibility (referencing Equation 21). It fails to explicitly cover the situation where an agent `ak'` loses in the centralized scheme because its valuation `vk'` is less than its centralized critical value `ck''` (i.e., `vk' < ck''`), even if `ak'` fits resource-wise. In the decentralized scheme, other agents `aj` bid `bj <= vj`. This could lead to a lower critical value `ck'` for agent `ak'`. If `ck'` drops below `vk'`, agent `ak'` might decide to bid and win in the decentralized scheme (`xk'=1`), thus violating the theorem's claim that `xi = xi'` for all `i`."
      },
      {
        "Problem": "The proof of convergence (Theorem 1: \"Any transition path of any agent is finite\") relies on the assertion that \"agents can only raise their bids.\" However, Algorithm 2 (Line 9) allows an agent to set its bid `bi'` to any value in the interval `[ci + ε, vi]`. Since the critical value `ci` (calculated based on other agents' bids) can decrease, an agent's new bid `bi'` could be lower than its previous bid.",
        "Location": "Page 6, Proof of Theorem 1 (first paragraph) and Algorithm 2, Line 9",
        "Explanation": "The proof of Theorem 1 states: \"Clearly, agents can only raise their bids...\". This premise is used to argue that bids are non-decreasing and bounded, hence converge. However, Algorithm 2, Line 9, specifies `bi' <- b ∈ [ci + ε, vi]`. If `ci` (the critical value for agent `i` to outrank its key predecessor or satisfy resource constraints) decreases due to changes in other agents' bids or statuses, agent `i` might select a new bid `b` that is lower than its previous bid for `bi`. If bids are not monotonically non-decreasing, the convergence proof provided is invalid. While the system might still converge, a different argument would be required."
      },
      {
        "Problem": "There is a potential mismatch between the textual definition of a Key Predecessor (Definition 2) and its implementation in Algorithm 3. This could lead to agents making incorrect local decisions about whether they can win and what bid to place.",
        "Location": "Page 6, Definition 2 (\"Key Predecessor\") and Algorithm 3 (\"Procedure key_predecessor\")",
        "Explanation": "Definition 2 states: \"ai's key predecessor is ak if (sk, bk) is the request that ranks the lowest among all winning requests whose absence alone would make (si, bi) granted.\" Algorithm 3, however, iterates through `C`, which is defined as the set of winning neighbors `aj` such that `(sj, bj)` ranks *higher* than `(si, bi)` (using the paper's notation `(sj, bj) < (si, bi)` means `sj` ranks higher). Algorithm 3 then returns `j` from this set `C` if `si` cannot be allocated resources due to `j` and other agents in `C` that rank higher than `j`. This seems to identify the highest-ranking conflicting agent among those that outrank `i`, rather than the lowest-ranking winner overall whose single absence enables `i` to win. An incorrectly identified key predecessor would lead to an incorrect critical value `ci` in Algorithm 2, potentially causing agent `i` to make a suboptimal or incorrect decision about winning and bidding."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 14037,
      "output": 932
    }
  },
  {
    "entry_id": 184,
    "retraction_id": "1503.01380v2",
    "paper_id": "1503.01380v1",
    "retraction_comment": "incomplete and inaccurate, requesting withdrawal immediately. the ranking method is not correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory Final Model Specification",
        "Location": "Page 2 (Section 2, last paragraph), Page 3 (NOTE), Page 6 (SUMMARY OUTPUT, ANOVA table), Page 7 (Regression equation)",
        "Explanation": "The paper states that a Principal Component based Multiple Linear Regression (PCMLR) model is developed, where PCA is applied to a reduced set of variables and MLR is performed on the retained principal components (Page 2, Page 3 NOTE). However, the final 'SUMMARY OUTPUT' (Page 6) and the 'Regression equation' (Page 7) are presented in terms of the original predictor variables (Quarter, H-index, etc.), not principal components. The ANOVA table (Page 6) shows 5 degrees of freedom for regression, corresponding to the 5 original variables in the equation. This contradicts the claim of using an MLR model on principal components, making the actual final model structure and the role of PCA in deriving it fundamentally unclear and inconsistent."
      },
      {
        "Problem": "Flawed Variable Selection and Misapplication of PCA",
        "Location": "Page 4 (Analysis Phase-I), Page 5 (Analysis Phase-II, III, Principal Component Analysis), Page 6 (Table: Principal Component Analysis and its Inference)",
        "Explanation": "The variable selection process is multi-staged and contains flaws. Initially, variables are removed iteratively based on p-values (>0.05) and correlation coefficients (<0.4 with SJR score) (Pages 4-5). Then, PCA is supposedly used. The 'Table: Principal Component Analysis' (Page 6) incorrectly attributes 'Percentage of Variation Explained' to individual *original variables* within a PCA context. Based on this misinterpretation, original variables like 'Total Cites(3years)' and 'Citable Docs. (3years)' are removed because they 'explain only 2.5%'. Using PCA output in this manner to filter original variables for a subsequent direct MLR (as implied by the final equation) is a misapplication of the technique. This flawed process makes the final set of chosen predictors lack robust justification."
      },
      {
        "Problem": "Arbitrary and Poorly Justified 'Quarter' Predictor Variable",
        "Location": "Page 2 (Section 2, paragraph on 'Quarter'), Page 6 (Regression Output for 'Quarter'), Page 7 (Regression equation)",
        "Explanation": "The inclusion of 'Quarter' as a predictor variable for journal influence is inadequately justified. The paper posits an intuition that journals evaluated in the first quarter have greater influence (Page 2), but this is unsubstantiated and lacks a theoretical basis in bibliometrics. Furthermore, the final regression equation (Page 7) shows a negative coefficient for 'Quarter' (-0.14076). If 'Quarter' is coded 1, 2, 3, 4, this implies journals in later quarters have higher predicted influence, contradicting the initial stated intuition. This variable likely introduces noise or captures spurious correlations rather than genuine influence factors."
      },
      {
        "Problem": "Unsubstantiated K-Means Clustering for 'National' vs. 'International' Journal Classification",
        "Location": "Page 3 (NOTE), Page 8 ('Classification Process'), Page 9 ('K-Means Clustering' section)",
        "Explanation": "The paper proposes using K-Means clustering (K=2) on the derived Journal Influence Score (JIS) to classify journals into 'National' and 'International' categories. This approach is problematic because K-Means is an unsupervised algorithm that will partition data regardless of underlying truth. There is no ground truth or external validation provided to support that the resulting clusters meaningfully correspond to an objective or recognized distinction of 'National' versus 'International' journal status or scope. The labeling of clusters is arbitrary, and the practical utility of this classification beyond the JIS ranking itself is not demonstrated, making the claim of a useful classification scheme unsound."
      },
      {
        "Problem": "Ambiguity of the Target Variable in Regression Analysis",
        "Location": "Abstract, Page 1 (last paragraph), Page 2 (Section 2.2), Page 4 ('Analysis Phase-I')",
        "Explanation": "The paper is not explicit about the precise nature of the dependent variable 'y' (referred to as Journal Influence Score or benchmarked against SJR) used in the regression model. While it's stated that the model is validated against SCImago Journal Rank (SJR) and variable selection uses correlation with 'SJR Score', it's unclear if the regression predicts the raw SJR values, their ranks, a logarithmic transformation, or some other metric. This ambiguity is critical because the choice of target variable affects the interpretation of model performance metrics like R-squared, the appropriateness of linear regression assumptions, and the overall meaning of the generated 'Journal Influence Score'."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 5690,
      "output": 1060
    }
  },
  {
    "entry_id": 185,
    "retraction_id": "1711.11197v4",
    "paper_id": "1711.11197v3",
    "retraction_comment": "Theorem 4.3 is false as states and it requires a completely different approach. Section 5 is completely correct but it will developed separately",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect K-theory argument in the proof of Corollary 5.3.",
        "Location": "Page 26, Proof of Corollary 5.3",
        "Explanation": "The proof of Corollary 5.3, which states that every elliptic operator P in the family case satisfies the Homotopic Stable Fredholm Perturbation property (HSFPP), relies on the claim that `K_0(Gamma_phi(M)|_V) = 0`. However, the relevant K-group for the vanishing of the boundary topological index (as per Definition 4.5 and Corollary 4.6, which links it to HSFPP) is `K_1(H_V) = K_1(Gamma_phi(M)|_V)`. The groupoid `Gamma_phi(M)|_V` is `(V x_B V) x R`. Its K-theory is `K_1(C^*( (V x_B V) x R )) \\cong K_0(C^*(V x_B V)) \\cong K_0^{top}(B)`. This group `K_0^{top}(B)` is generally not zero, contradicting the proof's assertion and undermining its argument for why HSFPP holds in this context (though the conclusion itself is known from other works)."
      },
      {
        "Problem": "Potential ambiguity and inconsistency in the definition and decomposition of the b-holonomy groupoid and related boundary terms.",
        "Location": "Page 14, Definition 3.1, Equation (3.2); Page 15, definition of full symbol sigma_F and Diagram (3.12)",
        "Explanation": "The b-holonomy groupoid `bH(M,F)` is defined via `Blupr,s(H(M,F), H(V,Fv))`. The subsequent decomposition (3.2) `bH(M,F) = H(M,F) U H(V,Fv) x R` is potentially misleading. A standard Blup construction `Blup(G,G_Y)` typically yields `(G \\setminus G_Y) \\cup (N_{G_Y}^G / R_+^*)`. The first term `H(M,F)` in (3.2) should likely refer to the restriction of `H(M,F)` to the interior `M \\setminus V`. Furthermore, the definition of the full symbol `sigma_F` (page 15) uses `C(bS*F) x_V Psi^0(H(M,F)|_V)`, while diagram (3.12) uses `Psi^0(V,Fv)` (implicitly `H(V,Fv)`). The terms `H(M,F)|_V` and `H(V,Fv)` are not generally identical. The condition `F|_V \\approx F_V x R` (page 2) implies `H(M,F)|_V` is related to `H(V,Fv) x PairGroupoid(R)`, not directly `H(V,Fv)`. This lack of precise alignment could affect the well-definedness of the full symbol and subsequent arguments."
      },
      {
        "Problem": "Crucial Morita equivalence (4.20) asserted without justification.",
        "Location": "Page 21, Equation (4.20) and proof of Theorem 4.4",
        "Explanation": "The proof of Theorem 4.4 (b-Connes-Skandalis longitudinal index theorem) relies on the commutativity of diagram (4.21). This commutativity, in turn, depends on the Morita equivalence stated in (4.20): `bH(M,F)^tan x_{h_T} R^N ~_M D(bH(M,F) x R^N, (bH(M,F) x_h R^N)|_U)`. This equivalence relates a twisted deformation groupoid (LHS) to a normal groupoid construction (RHS). It is a highly technical statement presented without proof or a specific citation that directly supports this form. The validity of this equivalence is essential for the entire proof strategy of Theorem 4.4."
      },
      {
        "Problem": "Insufficient justification and missing definitions in the proof of Corollary 4.6.",
        "Location": "Page 21-22, Proof of Corollary 4.6, Diagrams (4.24) and (4.25)",
        "Explanation": "The proof of Corollary 4.6 (Topological obstruction for Fredholm boundary conditions) is difficult to follow. The groupoid `bH^{Fred}` appearing in diagram (4.24) is not defined, and its relation to previously defined objects like `(bH(M,F))^{FE}` or `bF_{nc}` is unclear. The argument that the 'top face' of diagram (4.25) contains the APS and Connes-Skandalis indices is not clearly substantiated. The diagram chase procedure linking the vanishing of `bInd_{top}([sigma_P])` to the HSFPP via the six-term sequence of (4.24) is not explicitly detailed, making the proof's logic opaque and hard to verify."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 12801,
      "output": 1171
    }
  },
  {
    "entry_id": 186,
    "retraction_id": "2301.09693v2",
    "paper_id": "2301.09693v1",
    "retraction_comment": "An important technical mistake in the set-up of this variant of generalization to Seiberg-Witten equations was pointed out to the author. In particular, the equations are not elliptic as claimed. As a result, any statement about (or uses) regularity and transversality of the moduli space has to be disregarded. However, the moduli space is still compact",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of a key equation in the Kähler case, invalidating subsequent arguments.",
        "Location": "Page 25, derivation of eq (5.4) from (5.1).",
        "Explanation": "The paper derives equation (5.4), $i\\Lambda F_A = -\\frac{1}{4n}(|\\alpha|^2 - |\\beta|^2) + |\\phi|^2$, by taking the trace of the second equation in system (5.1). However, a direct trace calculation of eq (5.1) (page 23), using $\\eta = -i|\\phi|^2\\omega + F_{A_{can}}$ and $Tr(F_B)=0$, yields $i\\Lambda F_A = \\frac{1}{2n}(|\\alpha|^2 - |\\beta|^2) - 2|\\phi|^2$. The coefficients for all terms (the $(|\\alpha|^2 - |\\beta|^2)$ term and the $|\\phi|^2$ term) are different in magnitude and/or sign. This incorrect equation (5.4) is critical for Proposition 5.2, which claims that if $L \\cong \\mathcal{O}_X$, then $\\phi=0$. The paper's argument for this relies on all terms in the integrated version of (5.4) having positive coefficients, which is not true with the corrected derivation. This error undermines Proposition 5.2 and consequently the main application Theorem 5.4."
      },
      {
        "Problem": "Discrepancy in the index formula for the Dirac operator, affecting the dimension of the moduli space.",
        "Location": "Page 17, calculation of $\\chi(\\mathcal{E})$ and implicit formula for $index_C D_A^{E,+}$.",
        "Explanation": "The calculation of the Euler characteristic $\\chi(\\mathcal{E})$ of the deformation complex, which determines the dimension $d = -\\chi(\\mathcal{E})$ of the moduli space, appears to use an inconsistent or incorrect index for the Dirac operator $D_A^{E,+}$. On page 17, the paper states $\\chi(\\mathcal{E}) = \\chi(\\mathcal{A}) + \\chi(\\mathcal{B}) = 1-b_1(X)+b_2^+(X) + \\frac{n}{4}c_1(det(s))^2 - 2c_2(E)$. This implies that $\\chi(\\mathcal{B}) = \\frac{n}{4}c_1(det(s))^2 - 2c_2(E)$, and thus $index_C D_A^{E,+} = -\\frac{1}{2}\\chi(\\mathcal{B}) = c_2(E) - \\frac{n}{8}c_1(det(s))^2$. This formula for $index_C D_A^{E,+}$ differs from the standard Atiyah-Singer index theorem result, which is typically $index_C D_A^{E,+} = \\frac{1}{2}(c_2(E) - \\frac{n}{4}c_1(s)^2) - \\frac{n}{8}\\sigma(X)$. Notably, the paper's implicit formula for the index of $D_A^{E,+}$ is missing the term involving the signature $\\sigma(X)$ and has different coefficients for $c_2(E)$. While the final formula for $\\chi(\\mathcal{E})$ (e.g., Lemma 3.5) does incorporate $\\sigma(X)$ and $\\chi(X)$ terms (presumably from substituting $b_1, b_2^+$), the discrepancy in the underlying component $index_C D_A^{E,+}$ suggests a potential error in the derivation of the overall dimension formula. An incorrect dimension formula could impact the definition, properties (e.g., parity for $SW_E(s)$), and integrality of the invariant."
      }
    ],
    "token_usage": {
      "input": 11992,
      "thinking": 17329,
      "output": 887
    }
  },
  {
    "entry_id": 187,
    "retraction_id": "1609.01275v2",
    "paper_id": "1609.01275v1",
    "retraction_comment": "There is a serious error 3 lines below \"Step (II)\". It is not true that \"It follows that the set C' of all oriented colourings for ... is equal to the set of extension colourings.. .\" (In fact they only account for half of the extension colourings.)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory claims about the base origami polynomial and its implication for the main conjecture.",
        "Location": "Page 4 (Example 1.1), Page 1 (Abstract and Introduction)",
        "Explanation": "The paper states in Example 1.1 (page 4) that for a base origami, 'the origami polynomial vanishes identically', and claims 'This is true also for general base origami'. If the polynomial is identically zero, the RUM spectrum is the entire 2-torus (a 2-dimensional set). This directly contradicts the paper's main claim (e.g., Abstract, page 1) of resolving a conjecture that the dimension of mechanical modes is 'typically equal to 1'. If general base origami (the starting point for constructing other origamis via Lemma 3.1) have a 2D spectrum, it undermines the 'dimension 1 phenomenon' unless 'generic' surfaces in the conjecture exclude base origami, or unless all such base origami are non-generic. A non-degenerate base origami (e.g., with non-coplanar motif bar vectors) would generally yield a non-zero antipalindromic polynomial, leading to a 1D spectrum. The paper's assertion that the polynomial for general base origami is identically zero creates a foundational conflict with its central conclusion."
      },
      {
        "Problem": "Proof mechanism for palindrome property preservation does not adequately cover transitions from zero to non-zero polynomials.",
        "Location": "Page 13-14 (Lemma 5.3), Page 12 (Example 4.2)",
        "Explanation": "Lemma 5.3 aims to show that the (strong) palindrome property is preserved under joint-splitting moves. The proof outline (e.g., X_μ' = d_i X_μ or pol(μ') = d_i pol(μ)) suggests that terms in the new polynomial (X_μ' or pol(μ')) are obtained by multiplying original terms (X_μ or pol(μ)) by some factor d_i. If an original term X_μ (or polynomial p_O(z)) is zero, this multiplicative relationship implies the new term X_μ' (or polynomial p_O'(z)) would also be zero. However, Example 4.2 (page 12) describes a scenario where a base origami with an identically zero polynomial is split, resulting in a new origami whose polynomial p_O'(z) is claimed to be (non-zero and) palindromic. The transition from an identically zero polynomial to a non-zero polynomial is not compatible with a strictly multiplicative transformation of its terms as implied by the general mechanism of Lemma 5.3. This suggests a gap or inconsistency in the proof structure when dealing with cases where the initial polynomial is zero."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 18435,
      "output": 612
    }
  },
  {
    "entry_id": 188,
    "retraction_id": "2106.14795v2",
    "paper_id": "2106.14795v1",
    "retraction_comment": "Proof of Threorem 17, part 2 not correct as displayed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The argument that Assumption 15 (properties of continuous adjoint state p) implies Assumption 10 (discrete adjoint state p_h is non-zero on each element) is flawed.",
        "Location": "Page 18, Section 3.1, paragraph starting 'In fact we can now argue...'",
        "Explanation": "Assumption 15 states that the continuous adjoint p has simple, isolated zeros. The paper claims this implies Assumption 10 (p_h(x) != 0 for all x, meaning p_h is non-zero on each mesh interval I_k). The argument on page 18, based on p_{j+1}-p_j > 0 (derived from q_h > 0), shows that the discrete values p_j are strictly increasing. A strictly increasing sequence can pass through zero, meaning some p_k could be zero (e.g., p_{k-1} < 0, p_k = 0, p_{k+1} > 0). If p_k (the constant value of p_h on interval I_k) is zero, this contradicts Assumption 10. Assumption 10 is crucial for the subsequent derivation of the sparsity structure (39) and the error analysis of the control."
      },
      {
        "Problem": "The matrix form of the discrete state equation (45), specifically the equation B^T z = u, appears inconsistent with the underlying PDE and discretization choices.",
        "Location": "Page 22, Equation (45), and Page 23, definition of vector u.",
        "Explanation": "The continuous problem has z' = u (where z = -y'). The discrete version (23b) is int_Omega w_h z_h' dx = - int_Omega w_h u_orig dx, implying z_h' = -P_0(u_orig), where P_0(u_orig) is the L2-projection of the original control u_orig onto piecewise constants. Let u_j be the constant value of this projected control on interval I_j = (x_{j-1}, x_j). Then z_h'|_I_j = -u_j. The matrix B is defined on page 22 such that (B^T z)_j = z_j - z_{j-1} (if z_j are nodal values of z_h, and (B^T z)_j corresponds to interval I_j). Thus, z_h'|_I_j = (z_j - z_{j-1})/h_j. The equation B^T z = u from (45) would then mean (z_j - z_{j-1}) = u_j (if u is the vector of control values u_j). This implies z_h'|_I_j = u_j/h_j. Comparing z_h'|_I_j = -u_j with z_h'|_I_j = u_j/h_j leads to u_j/h_j = -u_j. If u_j is non-zero, this means 1/h_j = -1, which is impossible. This suggests an error in the formulation B^T z = u, likely missing a scaling factor diag(h_j) and a negative sign. This inconsistency affects the derivation of the reduced cost functional (P_h) and the subsequent numerical method."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 25842,
      "output": 768
    }
  },
  {
    "entry_id": 189,
    "retraction_id": "2108.05981v2",
    "paper_id": "2108.05981v1",
    "retraction_comment": "The article has been withdrawn due to incorrect model formulation. Particularly, introducing the so-called \"field with two elements\" was a mistake that made the main equation (observation) of the paper incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified derivation of boson mass from Klein-Gordon equation.",
        "Location": "Page 3, Eq. (2) to Eq. (3)",
        "Explanation": "Assuming a time-independent field (ω=0) in the Klein-Gordon dispersion relation Eq. (2) (ω² - (2π/q)² = mq²) implies mq² = -(2π/q)², representing a tachyonic mass or instability. However, Eq. (3) states (2π/qc)² = mqc², which is equivalent to mq² = (2π/q)², arbitrarily changing the sign or misinterpreting the static condition. This invalidates the fundamental mass relation |mqc| = 2π/qc (Eq. 4) used throughout the paper."
      },
      {
        "Problem": "Incorrect formula for the order of the symmetry group SU₂(q²).",
        "Location": "Page 2, Table 1 and text; Page 4, Eq. (7); Page 5, Eq. (9)",
        "Explanation": "The paper states the order of SU₂(q²) is q³-q, where q is the order of the underlying finite field Fq. This formula is not standard for special unitary groups (e.g., the order of SU(2,Q) is Q(Q²-1) if Q is the field order). This incorrect order is used to estimate the group size based on qc (Eq. 7) and subsequently to derive q* from the Monster group's order (Eq. 9), making q* and dependent calculations unreliable."
      },
      {
        "Problem": "Flawed derivation of mass dependence on spatial dimensions D.",
        "Location": "Page 6, derivation leading to Eq. (13)",
        "Explanation": "When generalizing the mass formula to D spatial dimensions for a static solution, the paper states mqc² = -D(2π/qc)² (if wavenumbers are equal). This implies an imaginary mass. The paper then effectively uses a linear factor of D in its final mass formula (Eq. 13, where MH/Mp = D * mq*/m2), rather than √D which would arise if mqc² were Dk₀², or properly addressing the negative sign. This step is crucial for obtaining the numerical result for the Higgs mass."
      },
      {
        "Problem": "Ad-hoc introduction and interpretation of m₂ = π.",
        "Location": "Page 5, paragraph after Eq. (11), leading to Eq. (12)",
        "Explanation": "The mass m₂ = π, attributed to a 'field with 2 elements', is obtained by extrapolating the already problematic Eq. (3) (mqc = 2π/qc) to qc=2. The physical basis for this extrapolation, the specific value π, and its role as a fundamental mass scale (m₂) used in the final formula (Eq. 12 and 13) are unsubstantiated and appear chosen to simplify mq*/m₂ to 2/q*, facilitating the numerical outcome."
      },
      {
        "Problem": "Unsupported central conjecture equating finite group order with Monster group order.",
        "Location": "Page 5, Eq. (8) and surrounding text",
        "Explanation": "The paper's 'main observation' hinges on the conjecture that the critical order of the proposed SU₂(q*²) group is exactly equal to the order of the Monster group. This assumption is primarily justified by a rough numerical similarity (10⁵¹ vs 10⁵³) derived from initial calculations that themselves rely on problematic formulae (the boson mass formula Eq. 4 and the group order formula). This leap from approximate similarity to exact equality is a significant, unsubstantiated assumption driving the paper's main numerical result."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 6622,
      "output": 842
    }
  },
  {
    "entry_id": 190,
    "retraction_id": "2209.07447v2",
    "paper_id": "2209.07447v1",
    "retraction_comment": "Theorem 11.1 is false : the kernel is not trivial as stated",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Gap in proving equality of Brauer classes [D1] and [D2]",
        "Location": "Page 30, Proof of Proposition 12.2",
        "Explanation": "The proof of Proposition 12.2 aims to show that two central simple algebras D1 and D2 (derived from cocycles ξ1 and ξ2) generate the same subgroup of the Brauer group. The argument proceeds by considering L = K(D1), so [D1]_L = 1. This implies ψ_0_L([ξ1_M0]_L) = 1. The proof then incorrectly concludes that '[ξ1_M0]_L = [1]' (first line after the H^1 diagram). In fact, ψ_0_L([ξ1_M0]_L) = 1 only implies that [ξ1_M0]_L is in the image of H^1(L, S_L) (where S is the central torus of M0). Let [ζ]_L be the common image of [ξ1_M0]_L and [ξ2_M0]_L in H^1(L, H0). The proof then asserts '[ζ]_L = [1]' without justification. If [ξ1_M0]_L comes from H^1(L, S_L), its image [ζ]_L in H^1(L, H0) also comes from H^1(L, S_L) (as S is a subgroup of H0), which is not necessarily trivial. This invalidates the subsequent step that uses Theorem 11.1 to deduce [ξ2_M0]_L = [1] and hence [D2]_L = 1. This step is crucial for eventually showing D1 = D2 (Corollary 12.3), which is a cornerstone for the final proof."
      },
      {
        "Problem": "The main conclusion about G0 is not reached from the proven result about M0",
        "Location": "Page 19 (Strategy discussion), Page 31-32 (End of Proof)",
        "Explanation": "The paper's main theorem (Theorem 3.7 / Theorem 8.5) states that the g3 invariant classifies Albert K-algebras arising from the first Tits construction, which translates to showing that if two cocycles [ξ1_G0], [ξ2_G0] in H^1(K, G0) (derived from a special torus T) have f3=0 and the same g3, then [ξ1_G0] = [ξ2_G0]. The paper's strategy, as outlined on page 19 and executed in subsequent sections, focuses on proving a stronger result: Theorem 8.6, which states that under the same conditions, the classes coincide in H^1(K, M0), where M0 is a smaller reductive subgroup of G0 (M0 = S . SL3). The final arguments in §12 (pages 31-32) indeed establish that a relevant twisted cocycle [ξ_M] becomes trivial in H^1(K,M) (equivalent to [ξ1_M0] = [ξ2_M0] in the original notation). However, the paper does not provide an argument for why equality in H^1(K, M0) implies equality in H^1(K, G0). The map H^1(K, M0) → H^1(K, G0) induced by inclusion is not necessarily injective. Without this implication, the main theorem concerning G0 (and thus Albert algebra isomorphism) is not proven, even if the results about M0 are correct."
      }
    ],
    "token_usage": {
      "input": 8896,
      "thinking": 17656,
      "output": 811
    }
  },
  {
    "entry_id": 191,
    "retraction_id": "1305.2623v2",
    "paper_id": "1305.2623v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in the calculation of Equation (28)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory scaling of cluster member group sizes.",
        "Location": "Page 3, Section 2.2.1, paragraph starting 'For both velocity models...'",
        "Explanation": "The paper states that for u groups of cluster members, the size of group G_y is M_y, with M_y ~ c_y * n^(a_y) and sum_{y=1 to u} M_y = n. It also states that a_y < 1 for all y (y=1,...,u), where u is a positive constant. If all a_y < 1, then sum_{y=1 to u} M_y would be O(n^alpha_max) where alpha_max = max(a_y) < 1. This implies sum_{y=1 to u} M_y = o(n), which contradicts the condition sum_{y=1 to u} M_y = n. For the sum to be n, at least one a_y must be equal to 1."
      },
      {
        "Problem": "Incorrect condition for Proposition 1.",
        "Location": "Page 6, Proposition 1 (statement and proof)",
        "Explanation": "Proposition 1 states its results hold if 'S_i, S_i*n^d and e^(-S_i*n^d) all go to 0 as n -> +inf'. The condition e^(-S_i*n^d) -> 0 implies S_i*n^d -> +inf. However, the condition also lists S_i*n^d -> 0. These are contradictory. The derivation of P(E_i) in the proof relies on p_i = (1-S_i)^(n^d) -> 0, which means S_i*n^d -> +inf. Thus, the stated condition 'S_i*n^d all go to 0' is incorrect."
      },
      {
        "Problem": "Inconsistent derivation of covered area S_i or resulting probability P(E_i, v_i) in Proposition 2 for random walk.",
        "Location": "Page 6, Proposition 2 (especially eq. (6) and its use in the proof of Prop. 2(a))",
        "Explanation": "The proof of Proposition 2(a) states S_i ~ (log n + w)v_i / ((m-k+1)v*n^d) (from eq. 6). This S_i is then used to derive P(E_i,v_i) by ensuring the exponent S_i*n^d*(m-k+1) becomes (log n + w)v_i/v*. However, this expression for S_i is not derived from the geometric area S_i = pi*r^2 + 2rv_iT using the transmission range r given in Proposition 2(a), which is r = sqrt((log n+w) / (2(m-k+1)v_i T n^d)). Substituting this r into pi*r^2 + 2rv_iT does not yield the S_i claimed in eq. (6). This suggests an inconsistency or an unsubstantiated assumption about S_i."
      },
      {
        "Problem": "Derivation of critical transmission range for random walk mobility appears unsound.",
        "Location": "Page 4, Main Results (1); Page 9, Section 7.1",
        "Explanation": "The critical transmission range for random walk is given as r_crit_RW = sqrt(log n / (2(m-k+1)v*T n^d)). This form implies that the effective area S_eff used in the condition S_eff * n^d * (m-k+1) ~ log n scales as r^2, specifically S_eff = (2v*T)r^2. However, the actual covered area is S_i = pi*r^2 + 2rvT. For S_i to be equivalent to (2v*T)r^2, it would require pi*r^2 + 2rvT = (2v*T)r^2. This equality only holds under specific conditions on parameters (e.g., pi = 2v*T if the r^2 terms dominate and r=1 if linear terms dominate, or specific relations if one term is negligible). If the 2rvT term dominates S_i (common for small r), r_crit should be O(log n), not O(sqrt(log n)). The derivation is not generally valid."
      },
      {
        "Problem": "Contradictory conditions on velocity scaling under strong parameters for random walk mobility.",
        "Location": "Page 4, 'Strong parameters condition' for random walk mobility model",
        "Explanation": "The strong parameters condition states that all velocities are o(n^(d-1)) and requires d > 2. Simultaneously, page 4 also states that 'all velocities are less than 1/T' (to keep movement within the unit square), where T is a positive constant (defined on page 3). If d > 2, then d-1 > 1, so n^(d-1) grows with n. The condition v = o(n^(d-1)) < 1/T implies n^(d-1) must be bounded by a constant (or decrease if T increases, but T is constant). This requires d-1 <= 0, meaning d <= 1. This contradicts the requirement d > 2."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 15271,
      "output": 1246
    }
  },
  {
    "entry_id": 192,
    "retraction_id": "0909.5521v3",
    "paper_id": "0909.5521v2",
    "retraction_comment": "Manuscript withdrawn, because results are incorrect. If phi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be expressed as a universal Horn sentence in ESO (NOT even when the structure is ordered)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsoundness of Assumption 4 and its justification.",
        "Location": "Page 2, Assumption 4; Page 4, Section 2.1.1; Page 6, Section 3.1.",
        "Explanation": "Assumption 4 posits that if a conjunction of clauses is equivalent to a Horn formula, then each individual clause (or component formula) must itself be Horn. This is generally false; for example, (p∨q) ∧ ¬q is equivalent to the Horn formula p∧¬q, yet p∨q is not Horn. The paper's justification in Section 3.1, based on the purported 'unrelatedness' or 'independence' of Basic Feasibility Constraints (BFC) and Objective Function Constraints (OFC), is informal, lacks rigor, and does not logically establish the assumption. This assumption is critical to the paper's argument that the OFC part of a P-time problem must be Horn, which is then used to argue for NP-complete problems."
      },
      {
        "Problem": "Unjustified claim that the Objective Function Constraint (OFC) for NP-complete problems is ESO-ord-Π₁-Horn.",
        "Location": "Page 3, Remarks 8 & 9; Page 4, Remark 11; Page 5, Sections 2.2 & 2.3.",
        "Explanation": "The paper argues that an OFC expression (φ₂), if expressible as ESO-ord-Π₁-Horn for a P-time problem, can be 're-used' for an NP-complete problem (like Clique or Vertex Cover) and will remain ESO-ord-Π₁-Horn. This re-usability and the general claim that OFCs (e.g., cardinality constraints like |S| ≥ K) for NP-complete problems can be expressed in ESO-ord-Π₁-Horn logic are not substantiated. The paper itself cites Dawar [Da09] in Section 3.1, which reportedly proves that 'ESO universal Horn logic cannot express the objective function constraint,' directly contradicting this central premise needed for the paper's main result."
      },
      {
        "Problem": "Failure to provide a concrete ESO-ord-Π₁-Horn expression for the Objective Function Constraint for Clique or Vertex Cover.",
        "Location": "Page 4, Remark 11; Page 5, Sections 2.2 (Vertex Cover) and 2.3 (Clique).",
        "Explanation": "While the paper attempts to formulate the Basic Feasibility Constraints (BFC) for Clique and (transformed) Vertex Cover in Horn form, it never explicitly demonstrates how the corresponding Objective Function Constraint (OFC) (e.g., |S| ≥ K or |T| ≥ K₁) can be written as an ESO-ord-Π₁-Horn formula. It relies on an indirect argument that Grädel's Theorem 'guarantees' this for P-time problems and that this formulation can be 're-used' (Remark 11). This is insufficient for proving that an NP-complete problem's OFC *is* ESO-ord-Π₁-Horn. A direct construction or a more rigorous proof of existence for the OFC part is needed, especially as this is the most contentious aspect of expressing NP-complete problems in this logic and is challenged by cited work [Da09]."
      },
      {
        "Problem": "Misinterpretation of the relationship between Dawar's [Da09] result and Grädel's Theorem.",
        "Location": "Page 6, Section 3.1.",
        "Explanation": "The paper suggests that if Dawar's result (stating that the OFC for optimization problems is not expressible in ESO-ord-Π₁-Horn) is true, then Grädel's Theorem (P = ESO-ord-Π₁-Horn) would be incorrect. This indicates a misunderstanding. Grädel's theorem characterizes the complexity class P. Dawar's result, if it pertains to NP-hard optimization problems, would imply that these problems (or specifically their OFCs) do not meet Grädel's criteria for being in P. This is consistent with P ≠ NP and does not invalidate Grädel's characterization of P. This misinterpretation points to a foundational confusion about the scope and implications of these descriptive complexity results."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 7130,
      "output": 959
    }
  },
  {
    "entry_id": 193,
    "retraction_id": "1810.09527v2",
    "paper_id": "1810.09527v1",
    "retraction_comment": "Appears that the three transitions interpreted as blueshifted molecular emission from methanol and methanimine are recombination line transitions with similar rest frequencies Paper being withdrawn while this is confirmed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Critical Error in Reported Isotropic Luminosity Value",
        "Location": "Page 6, Section 4.1, 3rd paragraph",
        "Explanation": "The paper states the isotropic luminosity of the integrated 6.7 GHz methanol emission is '4.5 × 10^0 Jy km s¯¹ kpc²'. However, using the paper's own values for integrated intensity (2.62 Jy km/s from Table 1) and distance (3.7 Mpc = 3700 kpc), the calculated luminosity should be approximately 3.58 × 10^7 Jy km s¯¹ kpc². This is a discrepancy of about seven orders of magnitude. The stated value of 4.5 Jy km s¯¹ kpc² would imply the source is less luminous than typical Galactic masers, directly contradicting the paper's main conclusions about it being a 'kilomaser' and ~10,000 times more luminous than typical Galactic masers. While other comparisons in the text (e.g., to G9.62+0.20 and the L_sun value of 0.25 L☉) suggest the authors intended the much higher luminosity, the explicitly stated numerical value in these units is critically incorrect and undermines the significance of the finding if taken at face value."
      },
      {
        "Problem": "Misleading Phrasing Regarding Spatial Scale of Emission in Abstract",
        "Location": "Abstract",
        "Explanation": "The abstract states: 'The methanol emission is resolved on scales smaller than 40 pc'. This phrasing is ambiguous and potentially misleading. The argument developed in the main text (page 6, end of Section 4.1) is that the emission is 'resolved out on angular scales of around 2\" (corresponding to linear scales of 40 pc)'. 'Resolved out' means that the emission lacks compact structures at this resolution and is instead diffuse over larger scales. The abstract's phrasing could be misinterpreted as the emission being constrained to structures *smaller* than 40 pc, which is contrary to the paper's argument for a diffuse, extended source."
      },
      {
        "Problem": "Uncertainty in Coexistence and Pumping of 5.0 GHz and 6.7 GHz Methanol Emission",
        "Location": "Page 9, first full paragraph; related to Page 7, statement on similar morphology",
        "Explanation": "The paper reports detection of 5.0 GHz methanol emission, considered a Class I maser candidate, apparently co-spatial with the 6.7 GHz Class II maser ('Images of the integrated 5.0 GHz methanol... all look very similar', page 7). Class I (collisionally pumped) and Class II (radiatively pumped) masers generally require different physical conditions, making their simultaneous strong emission from the same gas volume challenging to explain. While the paper cites a special case (Voronkov et al. 2005) and acknowledges, 'It is not clear whether the 5.0 GHz methanol transition will be inverted in these conditions', it does not sufficiently demonstrate that the proposed diffuse outflow model can simultaneously satisfy the pumping requirements for both types of transitions if the 5.0 GHz emission is also a maser. This unresolved issue adds significant uncertainty to the physical characterization of the emitting region and the completeness of the proposed model."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 10947,
      "output": 736
    }
  },
  {
    "entry_id": 194,
    "retraction_id": "1603.01872v4",
    "paper_id": "1603.01872v3",
    "retraction_comment": "This paper contains an error: the diagram (13) in the proof of Proposition 6.5 does not strictly commute as claimed. See this https URL for more details. The authors would like to thank [REDACTED-NAME] and [REDACTED-NAME] for finding this error and bringing it to their attention",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated claim of strict commutativity for a complex diagram central to the 1-connected fibration case.",
        "Location": "Page 20, proof of Proposition 6.5 (specifically diagram (13) and its justification).",
        "Explanation": "The proof of Proposition 6.5, which is crucial for establishing functoriality when q is a 1-connected fibration, relies on the commutativity of diagram (13). The paper asserts: 'One checks that both routes from the top of the diagram to the bottom commute as strict maps of spectra, and so the parallelogram in (13) commutes in the homotopy category.' Verifying the equality of compositions of strict maps of spectra in such a complex diagram (involving derived homotopy fixed points D_H, norm maps η, evaluation maps e, and maps μ and /H from Definition 6.2) is highly non-trivial. The paper does not provide a detailed breakdown of this check, nor does it reference a general lemma or technique that would make this specific claim evident. Without this detailed verification, the commutativity of diagram (13) – and thus the conclusion of Proposition 6.5 – is not fully established for the reader."
      },
      {
        "Problem": "Unsubstantiated claim about a composition of spectral maps being a strict identity map.",
        "Location": "Page 15, proof of Proposition 6.4 (specifically diagram (8) and its justification).",
        "Explanation": "Proposition 6.4 aims to show that the maps /H and μ (from Definition 6.2) coincide with Δ_{BH} and ∇_{BH} in a specific case. The proof involves demonstrating the commutativity of diagram (8). For the left-hand triangle in (8), the paper claims it 'commutes because all maps are isomorphisms in the homotopy category, and the composition that starts and ends in the lower-left corner is the identity as a strict map of spectra.' The assertion that this specific composition of spectral maps (involving F^H(EG_+, EG_+), maps induced by diagonals on EG, and projections) is strictly the identity map requires careful justification, which is not provided in the text. This claim is critical for establishing the properties of /H and μ, which are fundamental to the arguments in Section 6."
      }
    ],
    "token_usage": {
      "input": 7090,
      "thinking": 13391,
      "output": 511
    }
  },
  {
    "entry_id": 195,
    "retraction_id": "2404.01980v6",
    "paper_id": "2404.01980v5",
    "retraction_comment": "There is a flaw in the proof of Theorem 3.3 that the A at t=0 and A at t=T cannot be guaranteed to be identical, thus the key inequality fails",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified inequality and mishandling of error terms in the proof of Theorem 3.2",
        "Location": "Page 3, Proof of Theorem 3.2, specifically the step leading to inequality (3.3) and the subsequent limit A -> 0.",
        "Explanation": "The proof of Theorem 3.2 relies on establishing an inequality (stated on page 3, leading to (3.3)): `(4πA - κ(T)A^2) / (4πA - A^2) >= 1/(1+e^(-BT-C))`. This inequality is derived from two facts: (1) `I_A^2(T) >= 1/(1+e^(-BT-C))` (from Proposition 3.1), and (2) `I_A^2(T)` is 'tightly' approximated by `(4πA - κ(T)A^2) / (4πA - A^2)` for small `A` (from eq. 2.4). The 'tightness' means `I_A^2(T) = ((4πA - κ(T)A^2) / (4πA - A^2)) * (1 + δ_A)` where `δ_A >= 0` and `δ_A -> 0` as `A -> 0`. The paper's stated inequality implicitly assumes `δ_A` can be ignored or is zero for sufficiently small `A`. However, one must use `((4πA - κ(T)A^2) / (4πA - A^2)) * (1 + δ_A) >= 1/(1+e^(-BT-C))`. When this corrected inequality is carried through the algebraic steps to derive an equivalent of (3.3), additional terms involving `δ_A` appear. Specifically, the derivation leads to an inequality of the form `e^{-B(A)T} * Factor_LHS(A, δ_A) >= RHS_Factor_1(κ) - Term_Error(A, δ_A)`. The paper's argument implicitly assumes `Term_Error(A, δ_A)` vanishes as `A -> 0`. Standard estimates for geodesic disks suggest `δ_A = O(A)`. If `δ_A = O(A)`, the `Term_Error` (which is of the form `(Something) * δ_A/A^2 * A`) behaves like `O(1/A)` and blows up as `A -> 0`, invalidating the final contradiction. For the proof to hold, `δ_A` must vanish faster (e.g., `δ_A = o(A)` or ideally `O(A^2)`), or the error term must be handled differently. The paper does not provide an analysis of the order of `δ_A` or justify why this error term can be neglected."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 21800,
      "output": 649
    }
  },
  {
    "entry_id": 196,
    "retraction_id": "1105.1572v2",
    "paper_id": "1105.1572v1",
    "retraction_comment": "This was withdrawn because the key distribution figures Figure 1 and 3 in the paper are technically incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated and misleading claim about data decryption security linked to QKD.",
        "Location": "Page 2, Section II, paragraph 1",
        "Explanation": "The paper states, 'It has been proved that the chances of decrypting the data by an eavesdropper without the key is reduced to zero in such a situation [4],' citing a popular science article [4] as proof. This claim is an overstatement of QKD's direct role (which is key distribution) and the nature of 'proof' for such absolute security. QKD aims to secure the key; data security then depends on the encryption algorithm used. Attributing 'zero chance' of data decryption based on a non-rigorous source for a commercial system's claim is unsound and misrepresents the security guarantees."
      },
      {
        "Problem": "Incorrect statement regarding information leakage during error reconciliation in QKD.",
        "Location": "Page 5, 'Privacy Amplification (extension of BB84)' section, first sentence of the second paragraph of this subsection",
        "Explanation": "The paper claims, 'During the reconciliation phase, Oscar did not gain any information, since the last bit of each parity-check block was discarded.' This is false. Public discussion of parities during error reconciliation inherently leaks information to an eavesdropper (Oscar) about the remaining bits in the block, even if one bit per block is discarded. This leakage is precisely why privacy amplification is a necessary subsequent step. The statement demonstrates a misunderstanding of a fundamental aspect of QKD post-processing."
      },
      {
        "Problem": "The description of the quantum Byzantine Agreement protocol is critically unclear and appears to contain inconsistencies.",
        "Location": "Page 8-9, Section VI.A, 'Byzantine Agreement Problem,' particularly steps 1-6 of the protocol description and the subsequent explanatory paragraph.",
        "Explanation": "The paper attempts to describe a quantum protocol for a modified Byzantine Agreement using qutrits. However, the description is muddled, appears to conflate the binary message to be agreed upon with qutrit measurement outcomes (e.g., S's role in Step 1), and the logic for consistency checks and detection of dishonesty (e.g., Step 6 with vague conditions like 'almost all') is not coherently or correctly explained. This makes it impossible to assess the soundness of the claimed solution from the provided text, undermining the paper's discussion of this application."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 5471,
      "output": 539
    }
  },
  {
    "entry_id": 197,
    "retraction_id": "2003.05595v3",
    "paper_id": "2003.05595v2",
    "retraction_comment": "Equation (24) was wrong: algebraic cancellations of this type are invalid in general",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "False algebraic claim regarding the trace of a product of three skew-symmetric matrices.",
        "Location": "Page 5, discussion of Equation (12) and (14)",
        "Explanation": "The paper argues that the right-hand side of Eq. (12), which is -(ξ, d*ξ ∧ d*ξ), vanishes. The justification given is that the matrix factor of the integrand takes the form trace(M₁M₂M₃) where M₁, M₂, M₃ ∈ so(m), and that this trace is zero. This algebraic claim, that the trace of a product of three arbitrary skew-symmetric matrices is zero, is false for m ≥ 3. For example, in so(3), if L₁₂, L₂₃, L₃₁ are standard basis elements, tr(L₁₂L₂₃L₃₁) = 1. Since this trace is not generally zero, the argument that the term -(ξ, d*ξ ∧ d*ξ) vanishes is invalid. This step is crucial for concluding ||Ξ||_{L²} = 0, which is central to proving Theorem 1.1."
      },
      {
        "Problem": "Inconsistent or problematic definition/usage of the wedge product notation '∧' for matrix-valued forms (e.g., Ω∧Ω).",
        "Location": "Page 2 (Nomenclature), Page 4 (Proof of Theorem 1.1), Page 5 (Eq. 14 justification)",
        "Explanation": "There's a contradiction or ambiguity in how Ω∧Ω (and Ξ∧Ξ) is defined and used: \n1. On page 2, it's textually defined as 'matrix multiplication on the matrix factor'. If this interpretation is used for Eq. (1) (dΩ + Ω∧Ω = 0) where Ω is so(m)-valued, then Ω∧Ω (meaning Ω²) must be so(m)-valued. However, Ω² is symmetric. For Ω² to be both symmetric and skew-symmetric, Ω² must be 0. For Ω ∈ so(m,R), Ω²=0 implies Ω=0. This would render Theorem 1.1 trivial (applying only to Ω=0).\n2. The local coordinate expression for Eq. (1) on page 2 suggests Ω∧Ω means [Ω,Ω] (commutator of matrix coefficients, wedge of forms), which is standard in gauge theory. If this is the case, then [Ω,Ω] is so(m)-valued, which is consistent. However, the argument on page 5 that -(ξ, d*ξ ∧ d*ξ) = 0 relies on the structure tr(M₁M₂M₃) (implying matrix product interpretation of ∧), not tr(M₁[M₂,M₂]) (which would arise from a commutator interpretation of ∧). If ∧ means commutator, the trace argument as presented is misapplied, and tr(M₁[M₂,M₂]) for M₁,M₂ ∈ so(m) is not generally zero. This inconsistency undermines the proof of Ξ=0."
      },
      {
        "Problem": "Mismatch between the stated generality of the domain U in Theorem 1.1 and the assumptions used in its proof.",
        "Location": "Theorem 1.1 (page 1), Lemma 3.1 (page 3), Proof of Theorem 1.1 (page 4, Eq. 11)",
        "Explanation": "Theorem 1.1 states that U is a 'simply-connected domain'. However, the proof relies on Lemma 3.1, which is stated for a 'smooth bounded domain U'. Furthermore, the proof of Theorem 1.1 involves solving a PDE for ξ (Eq. 11) with the boundary condition ξ=0 on ∂U, and uses integral identities (like (ξ, dd*ξ) = ||d*ξ||²) that typically require such boundary conditions on a bounded domain. The arguments presented may not directly apply or may require significant modification (e.g., using weighted Sobolev spaces, different Hodge decomposition theory) for general unbounded simply-connected domains like Rⁿ. The paper does not address these adaptations, potentially limiting the proven scope of Theorem 1.1 compared to its statement."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 18926,
      "output": 937
    }
  },
  {
    "entry_id": 198,
    "retraction_id": "1609.00445v2",
    "paper_id": "1609.00445v1",
    "retraction_comment": "Withdrawn due to an error in the numerical code, used to obtain the numerical results",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of exchange parameters (Jo, J1, Do, D1) with respect to their stated origin from t3 sign change.",
        "Location": "Equations (2) and (3) (page 2), and related explanatory text (e.g., page 2, \"Multiorbital effects\" section; page 3, first paragraph of left column).",
        "Explanation": "The paper posits that new exchange terms J1 and D1 arise from a sign change of the interorbital hopping integral t3 between two distinct classes of bonds in the pyrochlore lattice. This implies that J1 and D1 should represent the parts of the Heisenberg and Dzyaloshinsky-Moriya (DM) interactions, respectively, that are 'odd' with respect to the sign of t3, while Jo and Do should represent the 'even' parts. However, the explicit formulas provided for these parameters in Eqs. (2) and (3) contradict this fundamental premise:\n1. Jo (Heisenberg 'even' part) in Eq. (2) contains terms linear in t3 (e.g., terms proportional to t2*t3 and t3*todd), which are 'odd' if t3 changes sign.\n2. Do (DM 'even' part) in Eq. (3) contains a term linear in t3 (proportional to (2*t3)/(U+2J')), which is 'odd'.\n3. D1 (DM 'odd' part) in Eq. (3) contains a term independent of t3 (proportional to -(t1-3t2)/(U'+JH)), which is 'even'.\nThis mischaracterization means that Jo and Do are not purely 'even', and D1 (and potentially J1, though its formula appears consistent with being 'odd') is not purely 'odd' under the t3 sign change. Consequently, the subsequent construction of the effective Hamiltonian using Jij = Jo +/- J1 and specific forms for Dij vectors (e.g., components like -Do-D1) does not correctly represent the interactions for the two bond types. This fundamental flaw likely invalidates the quantitative results derived from this Hamiltonian, including the phase diagrams, energies of chiral states, and conditions for dimensionality reduction and spin liquid stability."
      },
      {
        "Problem": "Potentially overstated claims about Spin Liquid (SL) stabilization based on Mean-Field Approximation (MFA).",
        "Location": "Page 3, sections \"Mean-field approximation\" and \"Numerical results\" (e.g., \"Since this macroscopic degeneracy can be used to stabilize the SL...\").",
        "Explanation": "The paper employs Mean-Field Approximation (MFA) to analyze the model and argues that the observation of macroscopic degeneracy in MFA results indicates the stabilization of a Spin Liquid (SL) phase. While macroscopic degeneracy in the classical ground state manifold is often considered a prerequisite for certain types of SLs (e.g., classical spin ice, Heisenberg model on kagome/pyrochlore lattices), MFA is an approximate method that neglects quantum fluctuations by linearizing interactions. Degeneracy within MFA might not directly or sufficiently translate to the stabilization of a true quantum SL, which is governed by strong quantum fluctuations. Confirming a quantum SL typically requires more sophisticated theoretical tools (e.g., exact diagonalization on small clusters, DMRG, quantum Monte Carlo, variational methods). Attributing SL stabilization primarily based on MFA degeneracy, especially in a complex model potentially including DM interactions which tend to lift degeneracies and select ordered states, is a strong claim that may not be fully substantiated by the methodology used. The evidence for SL is indirect and relies on an interpretation of MFA results rather than a direct calculation of SL properties or stability against quantum effects."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 15139,
      "output": 805
    }
  },
  {
    "entry_id": 199,
    "retraction_id": "1810.09697v2",
    "paper_id": "1810.09697v1",
    "retraction_comment": "We get more general results in Theorem 1.1. Corollary 5.27 and Theorem 1.3 are false",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch in definition of bi-unitary divisor compared to cited work [1]",
        "Location": "Page 2, Introduction (especially the claim 'We then complete, in this manner, a list given in [1]') and definitions of `gcd_u` and bi-unitary divisor.",
        "Explanation": "The paper defines a bi-unitary divisor D of S using a `gcd_u(D, S/D) = 1` condition, where `gcd_u(A,B)` is interpreted from Lemma 2.2 as the largest polynomial C that is a unitary divisor of both A and B. This leads to σ**(P^a) = σ(P^a) if 'a' is odd, and σ**(P^a) = σ(P^a) - P^(a/2) if 'a' is even. The cited work [1] by Beard (1987), whose list of bi-unitary perfect polynomials this paper claims to complete, defines D as a bi-unitary divisor of S if gcd(D, S/D) is square-free (for k=2 in Beard's k-unitary definition). These definitions are not equivalent (e.g., for P^5, this paper's σ**(P^5) = σ(P^5), while Beard's is 1+P+P^4+P^5). Therefore, the claim of completing Beard's list is questionable without explicit discussion of the differing definitions."
      },
      {
        "Problem": "Internal contradiction regarding the number of distinct Mersenne factors",
        "Location": "Page 5, Corollary 3.3 and Page 3, definition of C15 (in Theorem 1.1).",
        "Explanation": "Corollary 3.3 states that for a bi-unitary perfect polynomial A = x^a (x+1)^b P_1^{h_1} ... P_r^{h_r}, the number of distinct Mersenne factors 'r' must be less than 5 (i.e., r <= 4). However, polynomial C15, listed as a bi-unitary perfect polynomial in Theorem 1.1, is defined as x^13(x+1)^13 M1^2 M2^4 M3^4 M4 M5. This polynomial C15 involves 5 distinct Mersenne factors (M1, M2, M3, M4, M5), so r=5 for C15. This directly contradicts Corollary 3.3. Since Theorem 1.1 is stated to follow from Lemma 3.4 (and computations), and Corollary 3.3 is presented as part of the theoretical framework, this contradiction is a significant flaw."
      },
      {
        "Problem": "Inconsistent definition of Mersenne Polynomials",
        "Location": "Page 2, Introduction (definition of Mersenne polynomial) and Page 3 (list of polynomials M_i).",
        "Explanation": "A Mersenne polynomial is defined on page 2 as 'a polynomial of the form 1 + x^a(x+1)^b, with gcd(a,b) = 1'. While M1 = 1+x+x^2 (which is 1+x(x+1) with a=1, b=1) fits this definition, the polynomials M2 = 1+x+x^3, M3 = 1+x^2+x^3, M4 = 1+x+x^2+x^3+x^4, and M5 = 1+x^3+x^4, all stated to be Mersenne and irreducible on page 3, do not conform to this structural definition. For example, M2 = 1+x+x^3 cannot be written in the form 1+x^a(x+1)^b. Typically, in this research area, Mersenne polynomials over F2 are often defined as irreducible polynomials P for which σ(P) factors completely into powers of x and x+1. If this latter definition is implicitly used for M2-M5, the explicitly stated definition is incorrect and misleading."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 23604,
      "output": 916
    }
  },
  {
    "entry_id": 200,
    "retraction_id": "1309.2621v7",
    "paper_id": "1309.2621v6",
    "retraction_comment": "This paper was withdrawn because the author did not prove that the function lambda_0(t) = gamma(t) on page 14 is strictly increasing. This is why we cannot make the crucial time change that proves the main theorem about infinite dimensional SRBM",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The claimed equivalence of two different skew-symmetry conditions in Lemma 3.3 is not proven and potentially incorrect.",
        "Location": "Page 20, Lemma 3.3 and its proof. Also impacts Theorem 1.1.",
        "Explanation": "Theorem 1.1 relies on a skew-symmetry condition for the Competing Brownian Particles (CBP) system (Equation 2). Its proof uses a connection to an infinite-dimensional Reflected Brownian Motion (SRBM, Theorem 2.2), which has its own skew-symmetry condition (`RD+DR^T=2A`). Lemma 3.3 claims these two conditions are equivalent. However, the provided proof of Lemma 3.3 is incomplete: it states the components of the SRBM skew-symmetry condition and then asserts Equation (2) without showing the mathematical derivation of their equivalence. The derived SRBM skew-symmetry condition (LHS: `q_k^+ \\sigma_{k-1}^2 + (q_k^+ + q_k^-)\\sigma_k^2 + q_k^- \\sigma_{k+1}^2`, RHS: `2\\sigma_k^2`) and Equation (2) (LHS: `q_k^- \\sigma_{k-1}^2 + q_{k+1}^+ \\sigma_{k+1}^2`, RHS: `(q_{k+1}^+ + q_{k-1}^-)\\sigma_k^2`) are not evidently equivalent. If they are not equivalent, the main conclusion of Theorem 1.1 is not soundly established by the provided arguments, as the SRBM result (Theorem 2.2) would be applied under a condition different from or not implied by Equation (2)."
      },
      {
        "Problem": "Inconsistent definition of the SDE for ranked particle dynamics at the beginning of the paper.",
        "Location": "Page 1, Equation (1) compared to Page 2, Definition 1 (iv).",
        "Explanation": "Equation (1) on page 1 presents the SDE for the n-th ranked particle `Y_n(t)` as `Y_n(t) = g_n t + \\sigma_n W_n(t) + q^+_n L_{n-1}(t) - q^-_{n-1}L_n(t)`. The coefficient `q^-_{n-1}` for the local time `L_n(t)` (collision between `Y_n` and `Y_{n+1}`) appears incorrect; it should likely involve an index `n` (e.g., `q^-_n`). This is later clarified in Definition 1 (iv) on page 2, which gives the SDE for `Y_k(t)` as `Y_k(t) = g_k t + \\sigma_k W_k(t) + q_k^+ L_{k-1}(t) – q_k^- L_k(t)`. While Definition 1 likely states the intended model, the initial, prominent Equation (1) is inconsistent and could mislead the reader regarding the fundamental model dynamics."
      },
      {
        "Problem": "Typographical error in a key term within the proof of Lemma 3.3.",
        "Location": "Page 20, Proof of Lemma 3.3.",
        "Explanation": "In the proof of Lemma 3.3, when analyzing the skew-symmetry condition `RD+DR^T=2A` for the case `i=j+1`, the paper states that `(2A)_{ij} = -2\\sigma_j^2`. Given the definition of the covariance matrix `A` for the gap process, where `A_{ij} = A_{j+1,j} = -\\sigma_{j+1}^2` (using particle index `j+1` for the variance), this term should be `(2A)_{ij} = -2\\sigma_{j+1}^2`. While this might be a typo, it occurs during the justification of a critical lemma (Lemma 3.3), whose overall soundness is already questioned in Problem 1."
      }
    ],
    "token_usage": {
      "input": 7348,
      "thinking": 17709,
      "output": 919
    }
  },
  {
    "entry_id": 201,
    "retraction_id": "0811.0505v2",
    "paper_id": "0811.0505v1",
    "retraction_comment": "This paper has been withdrawn by the author since there were errors in the calculus of the defect coefficient in Page 11. The corrected calculus gives actually zero which do not lead to a contradiction on the continuity of the flow-map of the Benjamin-Ono equation. The author warmly thank [REDACTED-NAME] G_rard for having pointing out this error to him",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect quantity calculated in Lemma 4.2, affecting a critical defect term.",
        "Location": "Page 11, Lemma 4.2 (proof) and its use for a(0) on page 10.",
        "Explanation": "Lemma 4.2 aims to compute lim_{n->inf} integral_T |w_{0,n}|^2 dx, where w_{0,n} = dx P_+(e^{-iF_{0,n}/2}). This limit, a(0) - ||w_0||_{L^2}^2, is claimed to be pi/2. However, the proof on page 11 calculates lim_{n->inf} integral_T |P_+(u_{0,n} e^{-iF_{0,n}/2})|^2 dx. If W_{0,n} = P_+(u_{0,n} e^{-iF_{0,n}/2}), this is lim ||W_{0,n}||_{L^2}^2. The quantity w_{0,n} is related to dx W_{0,n} (if W_{0,n} were P_+(e^{-iF_{0,n}/2})). The L2-norm of w_{0,n} involves a spatial derivative (multiplication by k in Fourier space) which is not accounted for in the provided calculation. Since the value pi/2 is crucial for the magnitude of the defect term leading to the paper's main contradiction, this miscalculation is critical."
      },
      {
        "Problem": "The constant delta and the precise form of the defect term in Eq. (23) are not rigorously derived or justified.",
        "Location": "Page 10, Eq. (23).",
        "Explanation": "Equation (23) introduces a crucial defect term distinguishing it from the standard gauge-transformed equation (13). This term is given as (i/8pi) ((a^2 - ||u_0||_{L^2}^2) - delta(a(t) - ||w(t)||_{L^2}^2)) w. The constant 'delta' is not defined, nor is its value (implicitly taken as 8 in the calculation on page 11) derived. The origin of this specific structure for the defect term is not made explicit prior to its statement. The later derived equation (55) on page 30, which describes the limit of the gauge transform, appears to have a structurally different defect term. Since the contradiction hinges on the non-zero nature and specific form of this term in (23), its unsubstantiated form is a critical issue."
      },
      {
        "Problem": "Numerical inconsistency in the calculation of the defect term's coefficient at t=0.",
        "Location": "Page 11, the paragraph concluding the proof of Theorem 1.1 before Lemma 4.3.",
        "Explanation": "The paper calculates the coefficient of the defect term at t=0. Using a^2 - ||u_0||_{L^2(T)}^2 = pi (from corrected Eq. (24) where integral_T |cos(nx)|^2 dx = pi) and assuming the result from Lemma 4.2 that a(0) - ||w(0)||_{L^2(T)}^2 = pi/2 (despite the issues with Lemma 4.2's proof), the coefficient becomes (i/8pi)(pi) - (i/pi)(pi/2) = i/8 - i/2 = -3i/8. The paper then equates this resulting coefficient (implicitly -3i/8 times w_0) to '-i/(4pi)' (implicitly meaning the coefficient is -i/(4pi)). The equality -3i/8 = -i/(4pi) would imply pi = 2/3, which is false. This numerical error in a key step of the contradiction argument is critical. Even if the defect term is non-zero, the specific value claimed is incorrect based on the preceding steps."
      }
    ],
    "token_usage": {
      "input": 8380,
      "thinking": 15289,
      "output": 895
    }
  },
  {
    "entry_id": 202,
    "retraction_id": "1404.7350v2",
    "paper_id": "1404.7350v1",
    "retraction_comment": "The paper has been withdrawn by the author since Lemma 3.27 is wrong. The author thanks [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between the definition of Rudin-Blass ordering and its use in cited theorems.",
        "Location": "Page 10, Definition 2.11; Page 22, Theorems 3.4 and 3.5.",
        "Explanation": "Definition 2.11 states: 'Let F <_{RB} G iff there is a finite-to-one f such that f(F) ⊆ f(G).' If f(F) denotes the standard filter lifting {X : f⁻¹[X] ∈ F}, this definition implies F ⊆ G, which is not the standard Rudin-Blass ordering. The standard definition (e.g., F ≤_RB G if ∃f finite-to-one, f(F) = f(G) with f(F) being the standard lifting) is used in cited works like Eisworth [15]. Theorems 3.4 and 3.5, which are crucial for P-point preservation in the main forcing construction (e.g., property (P1) and (P2) for the iteration, page 40), are cited from Eisworth [15]. Applying these theorems using the paper's potentially non-standard or misstated Definition 2.11 of <_{RB} could lead to unsound arguments regarding the preservation of the P-point E, which is critical for the paper's main conclusions."
      },
      {
        "Problem": "Flawed reasoning in the proof of Proposition 6.2 concerning the Rudin-Blass relation.",
        "Location": "Page 43, Proof of Proposition 6.2.",
        "Explanation": "In the proof of Proposition 6.2, it is argued that a Milliken-Taylor ultrafilter U would lead to a contradiction. Part of the argument involves Eisworth's Theorem 3.5 for the preservation of a P-point E by the forcing M(U). The proof states: 'If we force with it [M(U)] we preserve E according to Eisworth' Theorem 3.5.' This preservation requires E not<_{RB} Φ(U) (using the standard definition of Rudin-Blass ordering from Eisworth). The paper then claims 'Φ(U) not<_{RB} E since Φ(U) has character ℵ₂.' This justification is problematic because: (1) It refers to Φ(U) not<_{RB} E, but the condition for Eisworth's theorem to preserve E is E not<_{RB} Φ(U). (2) Justifying an RB-relation (or non-relation) based solely on the characters of the filters (character of Φ(U) being ℵ₂ and character of E being ℵ₁) is generally insufficient. This flawed step weakens the argument that M(U) would preserve E, which is part of the contradiction aimed for in Proposition 6.2."
      }
    ],
    "token_usage": {
      "input": 11734,
      "thinking": 13900,
      "output": 644
    }
  },
  {
    "entry_id": 203,
    "retraction_id": "1612.01576v2",
    "paper_id": "1612.01576v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error in the inductive proof of Theorem 3.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The combinatorial proof for Glauber dynamics (Theorem 3.1) appears to establish a coupling time T_ID = O(n (log n)^2), leading to a mixing time of O(n (log n)^2). However, the paper claims an O(n log n) mixing time, stating this is achieved via a 'standard boosting argument' that is not detailed for removing the extra log factor. If the presented proof method inherently yields O(n (log n)^2), it does not achieve the claimed optimal O(n log n) mixing time for Glauber dynamics.",
        "Location": "Page 8, Proof of Theorem 3.1, and statement of Theorem 1.1 on page 2.",
        "Explanation": "The inductive proof for Theorem 3.1 concludes that the identity coupling time T_ID is at most cn(log n)^2. This directly implies a mixing time bound of O(n (log n)^2). The paper then states that 'a standard boosting argument' (referencing, e.g., Theorem 5.2 from [14] which is a recursive construction) is used to obtain the O(n log n) bound. However, the proof provided *is* the recursive construction and it yields O(n (log n)^2). It is not explained how the presented method shaves off the additional log factor. The classical O(n log n) result is known via other techniques, but this specific proof, as detailed, seems to lead to O(n (log n)^2)."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 19536,
      "output": 341
    }
  },
  {
    "entry_id": 204,
    "retraction_id": "1501.05036v2",
    "paper_id": "1501.05036v1",
    "retraction_comment": "Eq. (9) only implies correlation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Over-application of Theorem 1's explanation to general strainlines.",
        "Location": "Page 15, paragraph 2, and discussion of Fig 6(a).",
        "Explanation": "The paper claims that the strong alignment observed numerically between contours of the path-averaged scalar (f_bar) and general strainlines (not necessarily LCSs) is explained by Proposition 1 and Theorem 1. However, Theorem 1, which demonstrates that f_bar becomes uniform along a material line, critically relies on Assumption (H) (exponential decay of the line's length). Assumption (H) is motivated and stated for hyperbolic LCSs (page 8), which are special strainlines characterized by strong repulsion (large lambda_2 values). It is not established that general strainlines satisfy Assumption (H); their length shrinkage (guaranteed by Proposition 1) might be slow if their associated lambda_2 values are close to 1. If Assumption (H) does not hold for general strainlines, then Theorem 1 cannot be invoked to explain their alignment with f_bar contours. The existing framework (Proposition 1 with Proposition 2) might not be sufficient to ensure f_bar becomes nearly uniform along all strainlines, especially for finite integration times T."
      },
      {
        "Problem": "The explanation for LCSs aligning specifically with zero-level contours of the path-averaged scalar is not rigorously established.",
        "Location": "Page 17, paragraphs 2-3; Page 19, lines 6-9; Figure 7(b) and Figure 8.",
        "Explanation": "Theorem 1 explains why the path-averaged scalar (f_bar) should be approximately constant along an LCS, but it does not determine the value of this constant. The paper argues (and claims to 'show' on page 19) that this constant tends to the spatial mean of the scalar field f (which is zero in the numerical example), attributing this to longer trajectories on LCSs sampling the domain more effectively, akin to ergodic behavior. However, the paper acknowledges that Birkhoff's ergodic theorem 'does not immediately apply' because the flow is not strictly ergodic and the scalar field f is time-dependent. The provided explanation is therefore heuristic and not rigorously proven. Numerical results (e.g., Fig 8b) show a trend with considerable scatter, rather than a precise convergence for all relevant trajectories, making the strong assertion of f_bar on LCSs tending to the spatial mean of f potentially overstated."
      },
      {
        "Problem": "Assumption (H) imposes a strong condition on the uniform exponential shrinkage of LCS segments.",
        "Location": "Assumption (H) on page 8, and its application in the proof of Theorem 1 on page 10.",
        "Explanation": "Assumption (H) states that the length l(t) of a hyperbolic LCS follows an exponentially decaying upper envelope, l(t) <= l(t_0)e^(-lambda|t-t_0|). In the proof of Theorem 1, this assumption is effectively applied to arbitrary segments of an LCS, implying that any segment of initial length l_0 shrinks as l_segment(t) <= l_0 * e^(-lambda(t-t_0)) with the same characteristic constant lambda. This assumes a rather uniform exponential shrinkage rate across the entire LCS and all its sub-segments. While LCSs are regions of strong deformation, the stretching (and thus shrinking) rates (related to lambda_2) can vary along the LCS. If lambda_2 is not sufficiently uniform, different segments might shrink at different effective rates, and a single lambda might not characterize all segments appropriately. This strong form of the assumption, crucial for Theorem 1's quantitative result (Eq. 9), might not universally hold for all structures defined as LCSs by conditions (A)-(D) on page 6."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 10494,
      "output": 840
    }
  },
  {
    "entry_id": 205,
    "retraction_id": "1208.6493v2",
    "paper_id": "1208.6493v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in a claim about singular supports in the proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of Paley-Wiener-Schwartz theorem and flawed reasoning for S'(R) convergence.",
        "Location": "Page 4, Proof of Theorem 1.2, paragraph starting 'Also, by the Payley-Wiener-Schwartz theorem...'",
        "Explanation": "The paper states that for F in E'(R) with support in (-π, π), its inverse Fourier transform f(z) satisfies |f(z)| ≤ C(1+|z|)^(-N)e^(π|Im(z)|). The correct estimate from Paley-Wiener-Schwartz theorem is |f(z)| ≤ C(1+|z|)^N e^(π|Im(z)|) for some N ≥ 0. This implies f(n) can have polynomial growth, not necessarily the decay suggested by the paper's exponent -N. Consequently, the paper's argument that 'the series Σf(n)e^(-inω) converges in S'(R)' because |f(n)| ≤ C(1+|n|)^(-N) (implying decay) is flawed. While the series does converge in S'(R) for polynomially bounded f(n) (a standard result for Fourier series of distributions), the justification provided in the paper is based on an incorrect premise about the behavior of f(n)."
      },
      {
        "Problem": "Erroneous derivation in Example 3.1.",
        "Location": "Page 4, bottom, and Page 5, top (Example 3.1).",
        "Explanation": "The derivation in Example 3.1, which aims to show that Σf(n)sin(π(t-n))/(π(t-n)) does not converge in D'(R) for F=δ', contains significant errors. Specifically, in the estimation of |<f(n)sin(π(·-n))/(π(·-n)), φ>|, the paper states it equals (1/|2πn|) times an integral term. Given f(n) = -in/(2π) for F=δ', |f(n)| = n/(2π), so the expression should be (n/(2π)) times the integral term. This is an error of a factor of n^2. Subsequently, the paper derives a lower bound for this term as m/(2π^2 n^2) ∫φ(t)dt (adjusting for the paper's expression) and then incorrectly claims this 'does not converge to 0 as n → ∞'. In fact, a term proportional to 1/n^2 does converge to 0. If f(n) were used correctly, the terms would be O(1), leading to divergence. The provided argument is unsound and internally inconsistent."
      },
      {
        "Problem": "Incorrect statement regarding the singular support of F_tilde.",
        "Location": "Page 4, Proof of Theorem 1.2, paragraph starting 'We have that the singular support of F_tilde...'",
        "Explanation": "The paper claims: 'We have that the singular support of F_tilde is contained in its support, which is furthermore included in the set U_{n∈Z} (nπ, (n+1)π).' This statement is incorrect. F_tilde is a 2π-periodic distribution; for instance, if F=δ_0, then F_tilde = Σ_k δ(ω-2πk), whose singular support is {2πk | k∈Z}. The set U_{n∈Z} (nπ, (n+1)π) is R \\ {mπ | m∈Z}. The set {2πk | k∈Z} is not a subset of R \\ {mπ | m∈Z} (e.g., 0, 2π are in the former but not the latter). This mischaracterization of F_tilde's singular support makes this part of the proof confusing, even if the product 1_[-π,π]F_tilde is well-defined for other reasons."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 15487,
      "output": 896
    }
  },
  {
    "entry_id": 206,
    "retraction_id": "1909.06350v2",
    "paper_id": "1909.06350v1",
    "retraction_comment": "The proof contained an error in the definition of the coupling in (4.8) that the authors currently cannot fix. The authors thank [REDACTED-NAME] for pointing this error out to them",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The error bound in equation (4.9) for E|I_3^(j)(t_1) - Ĩ_3^(j)(t_1)| appears to lead to terms with positive powers of n.",
        "Location": "Page 11, Equation (4.9) and subsequent discussion.",
        "Explanation": "The right-hand side of the inequality in (4.9) is stated as '≲ n^(1+ξ) / (n^ω η_0) + n^(1+ξ) / (n^(1+w_u) η_0) + n η_1^ξ'. Substituting η_0 = n^(-1-δ_0), the first term becomes n^(1+ξ) / (n^ω n^(-1-δ_0)) = n^(2+ξ-ω+δ_0). For this term to be O(n^-c) with c > 0, it would require ω > 2+ξ+δ_0. However, n^ω represents the number of smallest singular values considered (typically ω is a small positive constant, e.g., ω < 1). If ω is small, 2+ξ-ω+δ_0 is positive, meaning this term grows with n. The paper's subsequent claim that 'the r.h.s. in (4.9) is bounded by n^(-c(k))' by choosing exponents seems incorrect if this term is present and behaves as calculated. This potentially invalidates the proof of Lemma 4.3."
      },
      {
        "Problem": "Questionable scale η_0 in the denominator of the GFT error estimate in (4.5).",
        "Location": "Page 10, Equation (4.5) and its explanation.",
        "Explanation": "Equation (4.5) presents an error term for a Green's Function Comparison Theorem (GFT) result as O(t_1 / sqrt(n η_0)). Given t_1 = n^(-1+ω_1) and η_0 = n^(-1-δ_0), this error is n^(-1+ω_1+δ_0/2). This term can be O(n^-c) if ω_1+δ_0/2 < 1. However, (4.5) is used to compare I_3 terms, where I_3 involves an integral over η ∈ [η_1, η_2], with η_1 = n^(-1+δ_1) being significantly larger than η_0. Typically, GFT error estimates depend on the spectral scale being probed (here, related to η_1 or η within the integral for I_3). Using the much smaller scale η_0 (related to I_2 or the smallest singular values) in the denominator makes the error bound significantly worse. If η_0 is indeed the correct limiting scale for the GFT's applicability to H^z due to its spectrum near zero, this requires careful justification not fully provided. If η_1 were the appropriate scale, the error would be n^(-1+ω_1-δ_1/2), which is a much better bound. The use of η_0 without clear justification for this specific GFT application makes the argument's soundness at this step unclear or reliant on unstated conditions on ω_1 and δ_0."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 17589,
      "output": 738
    }
  },
  {
    "entry_id": 207,
    "retraction_id": "0904.3281v2",
    "paper_id": "0904.3281v1",
    "retraction_comment": "The integrality statement is false. See the publication \"A norm compatible system of Galois cohomology classes for GSp(4)\" of the author for a correct statement and proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The identification of H^4 classes with H^1 Galois cohomology classes is not fully justified for all cases.",
        "Location": "Page 12, Corollary 3.3 and the preceding argument involving the Hochschild-Serre spectral sequence.",
        "Explanation": "The paper constructs Eisenstein classes E_N^{k,k'} in H^4(S(N), W^{k,k'}). Corollary 3.3 claims these classes can be identified with elements in H^1(G_N, H^3(S(N)_\\bar{Q}, W^{k,k'})), where G_N is Gal(\\bar{Q}/Q(\\zeta_N)). This identification relies on an isomorphism H^4(S(N), W^{k,k'}) \\cong H^1(G_N, H^3(S(N)_\\bar{Q}, W^{k,k'})). Such an isomorphism, derived from the Hochschild-Serre spectral sequence, requires the vanishing of H^0(G_N, H^4(S(N)_\\bar{Q}, W^{k,k'})) and potentially other terms. While the paper argues for H^0(G_N, H^3(...)) = 0, it does not provide a justification for H^0(G_N, H^4(...)) = 0. For a Siegel threefold S(N) (dimension 3), H^4(S(N)_\\bar{Q}, W) vanishes if W is a 'sufficiently regular' coefficient system. However, the paper allows k \\ge k' \\ge 0. If k=k'=0, W^{0,0} is related to the constant sheaf (possibly twisted), for which H^4(S(N)_\\bar{Q}, W^{0,0}) is generally non-zero, and H^0(G_N, H^4(S(N)_\\bar{Q}, W^{0,0})) is also not necessarily zero. If this term is non-zero, the H^4 classes E_N^{k,k'} may not correspond to classes in H^1(G_N, H^3(...)), which could affect their interpretation as Galois cohomology classes in the context of Perrin-Riou's conjectures for the full range of k, k'."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 14861,
      "output": 518
    }
  },
  {
    "entry_id": 208,
    "retraction_id": "1705.03737v2",
    "paper_id": "1705.03737v1",
    "retraction_comment": "This paper contains a flaw that the proposed methods were overfitted thus the experimental results were not suitable. At this point, we do not want to update this article bu are developing a quite new approache where the authors are different from this paper,, and the title of our paper will be changed. 8 pages, 6 figures",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially Flawed Deep3D Baseline Implementation and Reporting",
        "Location": "Table 3 (page 6), Table 5 (page 8), Section 6.1 (page 6), Section 6.3 (page 8)",
        "Explanation": "The reported number of parameters for the baseline method Deep3D (33.52M in Table 5) appears significantly underestimated compared to its published VGG-16-based architecture (typically >100M parameters). This discrepancy would invalidate the claimed memory efficiency gains. Furthermore, as Deep3D's accuracy results (Table 3) were obtained by the authors on their new dataset (implying re-implementation or re-training), any inaccuracies in this re-implementation would also make the accuracy comparisons unsound. The paper lacks sufficient detail about this re-implementation to verify its faithfulness."
      },
      {
        "Problem": "Ambiguity and Lack of Demonstrated Spatial Scalability for the Best Performing Model (DeepView_dec)",
        "Location": "Abstract (page 1), Novelty point 3 (page 2), Section 5.1 (page 5), Section 5.3 (page 5), Table 3 (page 6)",
        "Explanation": "The paper claims spatial scalability (handling various input image sizes) as a key advantage. However, this is experimentally demonstrated in Section 5.3 only for the DeepView_ren model (referred to as 'DeepView_rec'). The superior DeepView_dec model, which achieves the highest accuracy (Table 3), lacks explicit experimental validation of its spatial scalability. It's unclear if its reported main results are tied to a single training resolution (384x160 per Section 5.1), which would limit the scope of this claimed advantage for the best model."
      },
      {
        "Problem": "Persistent Use of Undefined Term 'DeepView_rec' Obscuring Model Identification",
        "Location": "Section 5.3 (page 5), Table 2 (page 5), Table 5 (page 8)",
        "Explanation": "The term 'DeepView_rec' is used consistently in sections and tables detailing spatial scalability and computational efficiency results. This term is not defined alongside the two proposed architectures (DeepView_ren and DeepView_dec). While context suggests it refers to DeepView_ren, this persistent ambiguity makes it difficult to confidently attribute specific experimental results to the correct model, hindering clarity and potentially leading to misinterpretation."
      },
      {
        "Problem": "Unclear Training Protocol Regarding Input Resolution for Main Comparative Evaluation",
        "Location": "Section 5.1 (page 5), Section 6.1 (Table 3, page 6), Section 6.2 (page 6)",
        "Explanation": "Section 5.1 states that training/testing frames are downscaled to a fixed 384x160 resolution. However, Section 5.3 explores scalability with varied resolutions. It is not explicitly stated whether the models used for the main comparative evaluation against Deep3D (Table 3) and for the subjective study (Section 6.2) were trained exclusively on this single 384x160 resolution or if they were multi-scale trained models. This ambiguity affects the interpretation of the main results in the context of the broader spatial scalability claims."
      },
      {
        "Problem": "Lack of Statistical Significance Testing for Subjective Evaluation Results",
        "Location": "Section 6.2 (page 7)",
        "Explanation": "The subjective evaluation concludes that DeepView_dec produces 'better visual quality' than Deep3D based on Mean Opinion Scores (MOS) of -0.37 and -0.48, respectively. The paper does not report whether this relatively small difference (0.11 on a 7-point scale) is statistically significant. Without such analysis, the claim of superior subjective quality is not robustly supported, as the observed difference could be due to chance."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 11237,
      "output": 884
    }
  },
  {
    "entry_id": 209,
    "retraction_id": "2307.01627v2",
    "paper_id": "2307.01627v1",
    "retraction_comment": "The proof of Theorem 2.6 is incorrect. Without this theorem the main claim of the paper becomes unproven",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified deduction in the proof of Theorem 2.1 regarding the subgroup A_r.",
        "Location": "Page 4, lines 3-5, proof of Theorem 2.1. Specifically, the claim 'In particular A_r \\leq \\bar{G}' and the subsequent deduction 'A_r \\leq C_{\\bar{G}}(\\overline{GA}) = 1'.",
        "Explanation": "In the context of the proof, \\bar{G} = O_r(\\overline{GA}) and A_r is the r-part of the acting group A (more precisely, its image \\bar{A_r} in \\overline{GA} = GA/L). There is no clear justification provided why \\bar{A_r} must be a subgroup of \\bar{G}. If A_r is not a subgroup of \\bar{G}, or if C_{\\bar{G}}(\\overline{GA}) \\neq 1, then the argument that A_r \\leq L (and thus A_r stabilizes W_1) fails. This potentially undermines Theorem 2.1, which is a foundational result for Theorem 2.2 and subsequently Theorem 2.6."
      },
      {
        "Problem": "Unjustified conclusion about the structure of P' (the derived subgroup of P) in the proof of Theorem 2.6.",
        "Location": "Page 8, in the proof of Theorem 2.6, the passage starting 'Notice that \\Phi(P) \\leq Z(GA) by an argument above and hence \\Phi(P) = P' is cyclic of prime order.'",
        "Explanation": "The hypotheses on the p-group P are: P/Z(P) is elementary abelian, \\Phi(P)=P', exp(P)=p if p is odd, and P' \\leq Z(GA) (derived from an earlier argument). These conditions, even with G being of odd order (so p is odd), do not force P' to be cyclic of prime order. For instance, P could be a direct product of two extraspecial p-groups, in which case P' would be elementary abelian of order p^2, satisfying the other conditions. If P' is not cyclic of prime order, the argument that the subgroup E is extraspecial, and therefore the reduction to Theorem 2.5, is invalid. This is a critical step in the proof of Theorem 2.6."
      },
      {
        "Problem": "Unjustified 'cascading centralization' argument in step (2) of the main theorem's proof.",
        "Location": "Page 10, proof of step (2) for the main theorem. Specifically, the deduction: 'Hence [Q,B] \\leq \\Phi(Q)Q_0, that is [P_{h-2}/\\Phi(P_{h-2}), B] = 1. It follows that [P_i, B] = 1 for each i < h-2.'",
        "Explanation": "The argument asserts that if a subgroup B of A centralizes the section P_{h-2}/\\Phi(P_{h-2}), then B must also centralize all preceding sections P_i (for i < h-2) in the A-tower. The paper states this leads to 'an A-chain of length h-2 centralized by B'. The A-tower structure (defined in Remark 3.2) does not inherently guarantee such a strong downward propagation of centralization by B. Without this cascading centralization, the inductive argument used to establish that P (=P_{h-1}) and Q (=S_{h-2}) satisfy the hypotheses (i) and (ii) of Theorem 2.6 (related to P = [P,B]^X and Q = [Q,B]Y Q_0) is unsound. This would invalidate the application of Theorem 2.6 in the proof of the main theorem."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 13219,
      "output": 872
    }
  },
  {
    "entry_id": 210,
    "retraction_id": "1907.08721v2",
    "paper_id": "1907.08721v1",
    "retraction_comment": "A wrong fact on Hochschild homology was used in the proof of the main result (section 2, Theorem 2.0.4)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear and potentially flawed justification for the injectivity of the map I_{X,v} -> H*(Xtilde, omega_{Xtilde}) in the proof of Theorem 2.0.4.",
        "Location": "Page 7, Proof of Theorem 2.0.4, specifically the paragraph starting 'Since R(pi)_*O_{Xtilde} = O_X...' and culminating in '...is injective.'",
        "Explanation": "The proof of Theorem 2.0.4 asserts the existence of an injective graded vector space morphism from the dual homological unit I_{X,v} to H*(Xtilde, omega_{Xtilde}). The argument involves several complex steps: pulling back morphisms from X to Xtilde, using a semi-orthogonal decomposition of HH_*(Xtilde), and then an action on a specific line bundle L in Pic(Xtilde). The critical deduction that the composite map I_{X,v} -> H*(Xtilde, omega_{Xtilde}) is injective is not sufficiently justified. Specifically, why the non-zero map L(pi)^*(i_{R(pi)_*(L)}(a)) (related to an object on X) leads to a non-zero element in H*(Xtilde, omega_{Xtilde}) (related to L on Xtilde and its canonical bundle omega_{Xtilde}) via the described HH machinery and action is not evident. The transition from pi^*omega_X to omega_{Xtilde} and the change of objects from L(pi)^*R(pi)_*L to L are not clearly bridged while preserving injectivity."
      },
      {
        "Problem": "Potential issue with the grading in the asserted embedding of I_X into HH_*(X)[dim X] in Remark 2.0.3.3.",
        "Location": "Page 5, Remark 2.0.3.3",
        "Explanation": "Remark 2.0.3.3 states that the existence of morphisms i_E and their functoriality is equivalent to an injective map I_X -> HH_*(X)[dim X]. If I_X is identified with H*(X, omega_X), its k-th graded piece H^k(X, omega_X) is a summand of HH_{n-k}(X) (where n=dim X) via the HKR isomorphism. The target HH_*(X)[dim X] has its k-th graded piece as HH_{k-dimX}(X) = HH_{k-n}(X). For a graded map, H^k(X, omega_X) would map to HH_{k-n}(X). This requires n-k = k-n, implying k=n. This suggests that only H^n(X, omega_X) might embed in this specific shifted Hochschild homology in a degree-preserving way via the standard HKR inclusion, which contradicts the idea that the entire H*(X, omega_X) embeds. While the main proof of Theorem 2.0.4 might not directly rely on this specific formulation of embedding into HH_*, this remark provides context and alternative reasoning that could be misleading or problematic if unsound."
      },
      {
        "Problem": "The identification of the dual homological unit I_{X1, rk2} with H*(X2, omega_{X2}) in the proof of Theorem 3.0.2.",
        "Location": "Page 8, Proof of Theorem 3.0.2",
        "Explanation": "The proof states: 'Furthermore, since rk2 is the natural rank function on D^b(X2) ~ D^b(X1), the homological unit associated to rk2 is H*(X2, omega_{X2}) (see remark 2.0.3)'. While it's plausible that an equivalence Phi_E: D^b(X1) -> D^b(X2) would relate I_{X1, rk_A} to I_{X2, rk_B} if rk_A and rk_B correspond (here rk2 on D^b(X1) is rk_{O_X2} o Phi_E), this identification is asserted rather than proven. Remark 2.0.3.2 states that for the specific rank function rk_{O_X} on D^b(X), the dual homological unit I_X is H*(X, omega_X). The argument needs to clearly establish that I_{X1, rk2} (an algebraic structure defined relative to D^b(X1)) is indeed isomorphic to H*(X2, omega_{X2}), not just that H*(X2, omega_{X2}) is the unit for D^b(X2) with its own point rank."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 17075,
      "output": 1047
    }
  },
  {
    "entry_id": 211,
    "retraction_id": "1608.07104v2",
    "paper_id": "1608.07104v1",
    "retraction_comment": "This paper has been withdrawn due to errors in the crucial estimates in Lemma 1 and Theorem 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of an essential estimate in Lemma 1 for the operator symbol.",
        "Location": "Page 5, Proof of Lemma 1 (estimate for $S_k$).",
        "Explanation": "Lemma 1 aims to prove $S_k = |k+(1/2)e^2|^2/|p_k| \\le 4$. The proof for the case $\\kappa < 4s$ (where $\\kappa = |k+(1/2)e^2|$) states $S_k \\le \\frac{4s}{2s|k_2+1/2|} \\le 4$. A careful analysis shows $S_k \\le \\frac{\\kappa^2}{s|2k_2+1|}$. With $\\kappa < 4s$, this becomes $S_k \\le \\frac{16s^2}{s|2k_2+1|} = \\frac{16s}{|2k_2+1|}$. This bound is not uniform in $s$ (it can grow linearly with $s$, e.g., if $k_2=0$ and $s$ is large). The uniform boundedness of $S_k$ (i.e., $|k+e^2/2|^2 \\lesssim |p_k|$) is critical for the continuity of the embedding $X_s^{1/2} \\hookrightarrow H^1$ (Lemma 2) and for the crucial estimate in Lemma 4 that allows controlling the operator $qG_s$. If $S_k$ is not uniformly bounded, the construction of Complex Geometrical Optics (CGO) solutions as presented is invalidated."
      },
      {
        "Problem": "Incomplete proof for the convergence of the remainder term of CGO solutions.",
        "Location": "Page 9, Proof of Theorem 5, specifically the argument for $||r_n||_{1/2,s_n} \\to 0$.",
        "Explanation": "Theorem 5 asserts that CGO solutions $u_n = \\chi_{s_n z}(1+r_n)$ can be constructed such that $||r_n||_{1/2,s_n} \\to 0$ as $s_n \\to \\infty$. The proof derives $||r_n||_{1/2,s_n} \\le \\frac{1}{1-n^{-1}} ||q||_{-1/2,s_n}$ by choosing $s_n > R(n^{-1})$. For $||r_n||_{1/2,s_n}$ to converge to 0, it is necessary that $||q||_{-1/2,s_n} \\to 0$. The paper mentions that $q \\in H^{-1}(Q)$ (page 8), but it does not provide a proof that this regularity, combined with the definition of the norm $||q||_{-1/2,s}^2 = \\sum |p_k|^{-1} |\\tilde{q}_k|^2$, ensures $||q||_{-1/2,s_n} \\to 0$. This convergence is essential for the CGO solutions to approximate plane waves."
      },
      {
        "Problem": "Inconsistent definition of complex vectors $z^1, z^2$ in the final step of the uniqueness proof.",
        "Location": "Page 13, Step 5.",
        "Explanation": "In Step 5 of the uniqueness proof, complex vectors $z^1$ and $z^2$ are defined as $z^1 = -k/2 + t\\eta^1 + is\\eta^2$ and $z^2 = k/2 + t\\eta^1 - is\\eta^2$. It is claimed that these are chosen to ensure $z^j \\cdot z^j = 0$ and $z^2-z^1=k$. However, a direct calculation shows $z^2-z^1 = (k/2+t\\eta^1-is\\eta^2) - (-k/2+t\\eta^1+is\\eta^2) = k - 2is\\eta^2$. This expression equals $k$ only if $s=0$ or $\\eta^2=0$. Neither of these conditions is suitable for constructing the required CGO solutions (if $s=0$, $z^j$ are real, and $z^j \\cdot z^j=0$ implies $z^j=0$; if $\\eta^2=0$, the construction of $z^j$ such that $z^j \\cdot z^j=0$ might be problematic or not serve the intended purpose). The condition $z^2-z^1=k$ (or a similar one involving conjugates) is fundamental for using the product of CGO solutions $u^1 u^2$ (or $u^1 \\overline{u^2}$) to approximate the Fourier mode $\\chi_k$ and subsequently show that $q_1-q_2=0$."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 23852,
      "output": 1129
    }
  },
  {
    "entry_id": 212,
    "retraction_id": "2401.17112v2",
    "paper_id": "2401.17112v1",
    "retraction_comment": "Bug. Lemma 1 is incorrect. The lemma needs the sets to be closed under subtraction which they are not",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed statement of Theorem 4 (Diagonal Criterion)",
        "Location": "Page 3, Section 4, Theorem 4",
        "Explanation": "Theorem 4, presented as summarizing a 'key concept', has a flawed definition for the sets S_i, which are crucial for the H-independence method. The flaws are: \n1. Exclusion of Zero: S_i is defined as R \\ {r : r . (v_i . v_i) = 0}, meaning S_i = {x in R | x . (v_i . v_i) != 0}. This definition excludes 0 from S_i whenever v_i . v_i is not zero and not a zero-divisor itself (which is true for the set sizes considered). However, the definition of H-independence (sum alpha_k v_k = 0 => alpha_k = 0 for all k, with alpha_k in S_k) and Theorem 2 implicitly require S_k to contain 0, so that alpha_k = 0 is a possibility. The specific sets S_u and S_v used in the proof of Theorem 3 correctly include 0. \n2. Missing Symmetry Requirement: Theorem 4 fails to state that the sets S_i must be symmetric (i.e., if r is in S_i, then -r must also be in S_i). This symmetry property is explicitly required by the method described in Section 2 (page 2, first paragraph) and is generally necessary for the underlying theory (e.g., Lemma 1 and Theorem 2). The specific sets S_u and S_v used in the proof of Theorem 3 do satisfy this symmetry. \nWhile the main result, Theorem 3, appears sound as its proof uses correctly defined coefficient sets S_u and S_v that satisfy these conditions, the misstatement of Theorem 4 is a significant flaw as it inaccurately represents the 'key concept' of the method."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 17063,
      "output": 442
    }
  },
  {
    "entry_id": 213,
    "retraction_id": "1710.01525v2",
    "paper_id": "1710.01525v1",
    "retraction_comment": "We can not prove Lemma 1 in Sect 2.4, and Terras did not prove it either, we misunderstood Terras's result here. Thus our proof about Theorem 2 is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Theorem 2 is false for O(n)=0",
        "Location": "Theorem 2 (Page 3, Eq. 2) and its proof conclusion (Page 7)",
        "Explanation": "The main theorem's statement is `2^(E(n)-1) < 3^(O(n)) < 2^(E(n))`. This fails for cases where `O(n)=0` (e.g., for `n=2^k, k>=1`). For `n=2`, `O(2)=0` (no odd steps before `s_G(n) < n`) and `E(2)=1` (one even step: 2 -> 1). The theorem would require `2^(1-1) < 3^0 < 2^1`, which simplifies to `1 < 1 < 2`. The first part, `1 < 1`, is false. This contradicts the theorem's claim of holding for any integer `n > 1`."
      },
      {
        "Problem": "Unproven assertion for the bound on Res(n) in Lemma 3",
        "Location": "Page 6, Proof of Lemma 3, the lines leading to the conclusion `3^(O(n)-1-i) / 2^(lambda(i)) < 1/3`",
        "Explanation": "The proof of the inequality `Res(n) < O(n)/3` relies on the assertion that each term `T_i = 3^(O(n)-1-i) / 2^(lambda(i))` in the sum for `Res(n)` is less than `1/3`. This assertion is stated with insufficient justification ('s_u[i] > n and K < n imply that ... < 1, thus we can conclude that ... < 1/3'). This step is a non-sequitur. The condition `3^(O(n)-i) < 2^(lambda(i))` (equivalent to `T_i < 1/3`) is a strong claim about the Collatz sequence's structure and requires a rigorous proof. Since the main proof of Theorem 2 depends on `Res(n) < O(n)/3`, this gap makes the overall proof unsound."
      },
      {
        "Problem": "Incorrect logical step in Theorem 2 proof conclusion",
        "Location": "Page 7, last sentence of the proof of Theorem 2: 'So there must be 2^(E(n)-1) < 3^(O(n)), which implies Eq.(2).'",
        "Explanation": "The proof on page 7 aims to show `2^(E(n)-1) < 3^(O(n))` by contradiction. Assuming the argument leading to this is correct (despite reliance on the unproven bound for `Res(n)`), this inequality is only the first part of Eq. (2). Eq. (2) is `2^(E(n)-1) < 3^(O(n)) AND 3^(O(n)) < 2^(E(n))`. The proof does not establish how `2^(E(n)-1) < 3^(O(n))` alone implies the full compound inequality of Eq. (2). While the second part `3^(O(n)) < 2^(E(n))` can be derived from `K < n` and the formula for `K` (assuming `Res(n) >= 0`), the paper does not explicitly make this argument and connect it. More importantly, as highlighted in Problem 1, the strict inequality `2^(E(n)-1) < 3^(O(n))` does not hold when `O(n)=0` and `E(n)=1` (where it's an equality), making the direct implication to Eq. (2) false for such cases."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 18519,
      "output": 859
    }
  },
  {
    "entry_id": 214,
    "retraction_id": "2011.05544v2",
    "paper_id": "2011.05544v1",
    "retraction_comment": "Comments are welcome. There is a problem with the Theorem 4.7. Which could be fixed by taking double duals (category of reflexive sheaves) but it ruins the double deformation construction",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified Cancellation Assumption in K_0^⊕",
        "Location": "Page 8, Remark 4.6, and its use in Proposition 4.15",
        "Explanation": "The argument in Remark 4.6 states: 'Note that there is also an isomorphism α|_{T=1} ≃ β|_{T=1} (This is because the image of [α] and [β] under ∂_is are isomorphic for i = 0,1.)'. This implies that equality of classes in K_0^⊕((B^q)^n Vect(X)) (i.e., ∂_i([α]) = ∂_i([β])) means isomorphism of the objects themselves (α|_{T=i} ≃ β|_{T=i}). This is a strong cancellation property that does not generally hold for K_0 of exact categories like Vect(X) for a projective variety X, especially when K_0 may have torsion or lack unique factorization analogs. This assumption is critical for the subsequent devissage argument in Proposition 4.15."
      },
      {
        "Problem": "Incorrect Long Exact Sequence of Homotopy Groups",
        "Location": "Page 5, sequence (3.4)",
        "Explanation": "The long exact sequence of homotopy groups (3.4) derived from the fibration (3.3) appears incorrect. For a fibration F → E → B, the sequence is ... → π_n(F) → π_n(E) → π_n(B) → π_{n-1}(F) → ... The paper's sequence (3.4) is π_0(Fiber) → K_1(Total Space) → π_1(Base) → 0. Given K_1(Total Space) = π_1(E), π_0(Fiber) = π_0(F), and π_1(Base) = π_1(B), the standard sequence would be ... → π_1(B) → π_0(F) → π_1(E) → π_0(B) → ... The presented sequence (3.4) omits terms and has an incorrect structure (e.g., ending in '→ 0' at that point), which invalidates the strategy of proving K_1((B^q)^n Vect(X)) is torsion by showing the left group is torsion and the right group is trivial."
      },
      {
        "Problem": "Unsubstantiated Relations for Homology Calculation",
        "Location": "Page 7, relations (4.1)",
        "Explanation": "To prove that π_1(|d → K^⊕((B^q)^n Vect(X × A^d))|) is trivial, the paper introduces relations (4.1) for elements in (B^q)^n Vect(X × A^2). These relations are stated as 'relations that come from the homology' without derivation or reference to a standard source in this specific context (H_1 of K_0^⊕ of a simplicial exact category). The validity and applicability of these specific triangular and square relations are crucial for Lemma 4.4 and the overall argument in Proposition 4.15, and their absence of justification makes this part of the proof unsound."
      },
      {
        "Problem": "Unclear Justification and Structure of Sequence (2.1)",
        "Location": "Page 3, sequence (2.1)",
        "Explanation": "The exact sequence (2.1), ⊕_{t=1}^{n-i} K_i((B^q)^{n-i-1}N) → K_i((B^q)^{n-i}N) → K_n(N) → 0, is crucial for relating different K-groups and is used in the proof of A^1-invariance (Proposition 2.5). However, the derivation of this sequence, the precise nature of the first term (a direct sum), and its role as the kernel of K_i((B^q)^{n-i}N) → K_n(N) are not clearly explained or referenced from standard K-theory literature (e.g., [Gra12]). The preceding discussion attempting to justify the kernel via K_i((B^q)^{n-i-1}C^qN) and a surjection K_i((B^q)^{n-i-1}N) → K_i((B^q)^{n-i-1}C^qN) is also unclear and potentially flawed."
      },
      {
        "Problem": "Assumption of Finiteness of Automorphism Groups of Complexes",
        "Location": "Page 6, Corollary 3.5",
        "Explanation": "Corollary 3.5 claims that π_0(|d→ K((B^q)^n Vect(X × A^d), G_m^1)|) is torsion. The proof relies on generators [(b, Θ)] being torsion, which means Θ (an automorphism of b ∈ (B^q)^n Vect(X)) must have finite order. This is justified by citing Proposition 3.4, which states Aut(E) is finite for a single coherent sheaf E. While Aut(E)(k) is finite for E over a finite field k, it's not explicitly shown that Aut(b) for an n-dimensional binary acyclic complex b (consisting of multiple vector bundles and differentials) is finite. This step is essential for proving the left-hand term in (3.4) is torsion."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 11593,
      "output": 1223
    }
  },
  {
    "entry_id": 215,
    "retraction_id": "1301.3486v2",
    "paper_id": "1301.3486v1",
    "retraction_comment": "Withdrawn because certain correction terms that arise in the Lace expansion of Section 3 were not identified and taken into account in the subsequent derivation. A new version with these correction terms included is in preparation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch in dimensional requirements for main scaling limit (Theorem 1.1) versus Hausdorff convergence of the backbone (Theorem 1.3, Proposition 1.4) for long-range models.",
        "Location": "Page 5 (Hypothesis H, Proposition 1.2), Page 4 (Theorem 1.1), Page 6 (Theorem 1.3, Proposition 1.4)",
        "Explanation": "Theorem 1.1 states scaling limits for the backbone pivotal points under certain dimensional conditions (e.g., d > 3(2^a) for long-range models). Theorems 1.3 and Proposition 1.4, which describe the Hausdorff convergence of the entire IIC backbone (not just pivotal points), additionally assume Hypothesis H. Proposition 1.2 provides conditions for Hypothesis H to hold. For long-range models, Proposition 1.2(ii) requires d > 4(2^a). This dimensional requirement is stronger than that of Theorem 1.1 (d > 3(2^a)). Therefore, for long-range models where 3(2^a) < d <= 4(2^a), Theorem 1.1 applies, but the proof for Hypothesis H (and consequently for Theorems 1.3 and Proposition 1.4) is not provided. This means the conclusions about Hausdorff convergence of the backbone (Theorems 1.3, Proposition 1.4) are effectively restricted to d > 4(2^a) for long-range models, a stronger condition than stated for Theorem 1.1. While the paper correctly states Hypothesis H as an assumption for Thm 1.3/Prop 1.4, the implication that this imposes a stronger dimensional restriction for long-range models than Thm 1.1 might not be immediately apparent."
      }
    ],
    "token_usage": {
      "input": 15346,
      "thinking": 17032,
      "output": 402
    }
  },
  {
    "entry_id": 216,
    "retraction_id": "2101.07819v3",
    "paper_id": "2101.07819v2",
    "retraction_comment": "We are withdrawing because of a significant error. The category Weil used to define tangent structures is too strict for the construction of our main example. In particular the map alpha in 7.19 is not well-defined. To resolve this we will replace Weil with a suitable $\\infty$-category and post a new version when possible. We are grateful to [REDACTED-NAME] and [REDACTED-NAME] for pointing out this error",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Lemma 7.18(2), establishing $T^A(GF) \\simeq T^A(G)T^A(F)$ for the Goodwillie tangent structure components, is highly technical and pivotal for the monoidal property of the overall tangent functor $T$. Specifically, the argument for equation (7.29) ($P_{A''}(H\\tilde{\\phi}) \\simeq *$) relies on intricate properties of $m$-homogeneous functors and their interaction with the induced map $\\tilde{\\phi}$ from a Weil algebra homomorphism $\\phi$. An error in this multi-stage reduction (pages 86-88) would compromise the claim that $T$ is a (strict) monoidal functor from Weil to endofunctors on $\\text{Cat}_{\\infty}^{\\text{diff}}$.",
        "Location": "Pages 83-88, primarily proof of Lemma 7.18(2), focusing on equation (7.29) and its justification.",
        "Explanation": "Lemma 7.18(2) is crucial for showing that the defined tangent structure $T$ respects composition of Weil algebra morphisms, which is a key part of $T$ being a monoidal functor (as required by Definition 2.1/2.11). The proof involves reducing to the case where $A'$ is $W^{n'}$ and then showing $P_{A''}(H\\tilde{\\phi}) \\simeq *$ for an $m$-homogeneous functor $H$ ($m \\ge 2$). This relies on analyzing the structure of $H\\tilde{\\phi}$ (equation 7.32) and arguing that its $A''$-excisive approximation is trivial. The complexity of this argument, involving Lemma 7.33 and properties of smash products under $\\tilde{\\phi}$, makes it a critical point where an oversight could invalidate the monoidal property of $T$."
      },
      {
        "Problem": "The proof of Proposition 7.38, which establishes the vertical lift axiom for the Goodwillie tangent structure on a differentiable $\\infty$-category $\\mathcal{C}$, is extremely technical. It involves constructing an explicit homotopy inverse $g$ (equation 7.39) for a map $f$ between $\\infty$-categories of excisive functors. The argument relies on detailed calculations with pullbacks and properties of multilinear functors, including a citation to Lurie [Lur17, 1.4.2.22] for a key equivalence ($D(X,Y) \\simeq D(X \\wedge Y, S^0)$).",
        "Location": "Pages 92-95, proof of Proposition 7.38.",
        "Explanation": "The universality of the vertical lift (diagram on page 92 being a pullback) is a fundamental axiom for a tangent structure (Definition 1.14, via Remark 1.17 and page 22). If this proposition is incorrect, the Goodwillie structure defined in the paper would not satisfy all axioms of a tangent $\\infty$-category. The proof's reliance on intricate homotopy arguments and specific classifications of multilinear functors makes it a potential point of failure if any step in the construction of the inverse or the application of cited results is flawed."
      },
      {
        "Problem": "The well-definedness of the action map $T : \\text{Weil} \\times \\text{RelCat}_{\\infty}^{\\text{diff}} \\to \\text{RelCat}_{\\infty}^{\\text{diff}}$ as a strict action of the simplicial monoid Weil (Proposition 8.20). While the paper details the construction for 0-simplexes and 2-simplexes (Definition 8.11, 8.13, 8.15, 8.18), the proof that this extends to a full simplicial monoid action (respecting identities and composition strictly for all $n$-simplexes of Weil) is condensed.",
        "Location": "Pages 101-109, particularly Definition 8.18 and Proposition 8.20.",
        "Explanation": "For $T$ to define a tangent structure as per Definition 2.11 (a strict monoidal functor $T : \\text{Weil}^{\\otimes} \\to \\text{End}(\\mathcal{X})^{\\circ}$), the underlying map $T : \\text{Weil} \\times \\mathcal{X} \\to \\mathcal{X}$ must be a strict action of the simplicial monoid Weil on the simplicial set $\\mathcal{X}$. Proposition 8.20 claims this for $\\mathcal{X} = \\text{RelCat}_{\\infty}^{\\text{diff}}$. The proof (page 109) shows $T^{A'}T^A(\\mathcal{C},W) = T^{A'\\otimes A}(\\mathcal{C},W)$ for 0-simplexes. For higher simplexes, it refers to a 'large diagram-chase' and a key commuting diagram (page 110). Ensuring this construction correctly respects all simplicial identities and compositions in Weil for arbitrary $n$-simplexes is critical. Any failure here would mean $T$ is not a well-defined strict monoidal functor."
      }
    ],
    "token_usage": {
      "input": 35212,
      "thinking": 9247,
      "output": 1160
    }
  },
  {
    "entry_id": 217,
    "retraction_id": "1711.07883v3",
    "paper_id": "1711.07883v2",
    "retraction_comment": "The paper has some problems on the Poisson homomorphism from the motivic Hall algebra to the motivic quantum torus",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect justification for vanishing Poisson brackets in the proof of the motivic flop formula.",
        "Location": "Page 22, Section 3.4.2, paragraph starting \"Applying the motivic integration map...\"",
        "Explanation": "The paper argues that certain Poisson brackets vanish because \"Ext(E,F) = 0 since dim(supp E) <= 1, dim(supp F) <= 1\". This condition on Ext groups is generally false for 1-dimensional sheaves (e.g., Ext^1(O_C, O_C) for a curve C is non-zero) and thus an insufficient justification. If the Poisson brackets do not vanish as claimed, the simplification I_Λ(P_H_≤1) = I_Λ(D'(H_exc)) * I_Λ(H_≤1) from the preceding Hall algebra identity involving an adjoint action (equivalent to P_H_≤1 = D'(H_exc) * exp({η,-})(H_≤1) after applying the integration map) does not hold. This would invalidate a key step in proving Theorem 1.4, the motivic flop formula."
      },
      {
        "Problem": "Incorrect claim about vanishing Ext groups for 0-dimensional sheaves, affecting higher rank DT/PT correspondence.",
        "Location": "Page 27, proof of Proposition 4.5, specifically the justification for \"the Poisson brackets in ε(C_μ) vanish\".",
        "Explanation": "The proof of Proposition 4.5, which states I_#(ε(C_I)) = Σ I_#(ε(C_μ)), relies on the vanishing of certain Poisson brackets. The justification provided is \"For any v_i, v_j in Γ_#, Ext^s(v_i, v_j) = 0 for all s by dimensional reasons.\" Γ_# consists of K-theory classes of 0-dimensional sheaves. This claim about universal vanishing of Ext groups is false (e.g., Ext^i(k(p), k(p)) for a skyscraper sheaf k(p) at a point p can be non-zero for i=0,1,2,3 on a CY3). If these Poisson brackets do not vanish, Proposition 4.5 is incorrect. This proposition is subsequently used in deriving results for the higher rank DT/PT correspondence (Theorem 4.6), potentially invalidating its conclusions or requiring a different argument."
      },
      {
        "Problem": "Questionable identity in Proposition 4.7 relating an exponential sum to S_A0^r,0(-q).",
        "Location": "Page 28, Proposition 4.7.",
        "Explanation": "Proposition 4.7 states the identity: exp ( Σ_{n>0} ([N_n] (L^(nr)-1)/(L-1)) x^n ) = S_A0^r,0(-q). The factor (L^(nr)-1)/(L-1) in the exponent, where L is the Lefschetz motive, is unusual in standard expressions for motivic Donaldson-Thomas type generating series for 0-dimensional sheaves or their r-rank generalizations (S_A0^r,0). The paper does not provide a clear derivation or reference to an established identity of this specific form. If this proposition is incorrect, the interpretation of the prefactor appearing in Theorem 4.6 (the higher rank DT/PT correspondence) as S_A0^r,0(-q) would be invalid. This affects the final stated form and interpretation of Theorem 4.6."
      }
    ],
    "token_usage": {
      "input": 8122,
      "thinking": 11267,
      "output": 789
    }
  },
  {
    "entry_id": 218,
    "retraction_id": "1603.02912v3",
    "paper_id": "1603.02912v2",
    "retraction_comment": "The calculation of the apparent charge density in this paper was wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The central claim that a 'complete' Lorentz transformation results in zero induced charge density (ρ'(r',t') = 0, Eq. 5) for a moving neutral current loop is incorrect.",
        "Location": "Page 3, Eq. (5) and surrounding text; Abstract; Page 2, first paragraph.",
        "Explanation": "The charge density ρ' (which, in its correct form, is ρ' = -γ(V·j)/c² for an initially neutral system with ρ=0) is a well-established physical consequence of special relativity, arising from the relativity of simultaneity. It is not an artifact to be eliminated by a further transformation step. The Lorentz transformation of the four-current J<sup>μ</sup> = (ρ, j) into J'<sup>μ</sup> = (ρ', j') already fully accounts for the transformation of spacetime coordinates, as J'<sup>μ</sup> is a function of x' and J<sup>μ</sup> is a function of x, where x and x' are related by Lorentz transformation. There is no subsequent step that would make ρ' vanish if j is non-zero and V·j is non-zero."
      },
      {
        "Problem": "The formula for the transformed charge density in Eq. (1) has a sign error.",
        "Location": "Page 1, Eq. (1).",
        "Explanation": "The standard Lorentz transformation for the charge density, when transforming from a frame S where charge density ρ=0 and current density is j, to a frame S' (where the system from S is observed to move with velocity V, or S' moves with V relative to S), is ρ' = -γ(V·j)/c². With c=1, this is ρ' = -γV·j. Equation (1) states ρ'(r,t) = γV·j(r,t), which has the opposite sign. This error is also reflected in the derivation in Footnote 2. While the paper's main argument is that ρ' should be zero, this initial error in stating the quantity it aims to refute is significant."
      },
      {
        "Problem": "Misinterpretation of the Lorentz transformation process for fields.",
        "Location": "Page 2, first paragraph beginning 'We used the word spurious...'.",
        "Explanation": "The paper incorrectly posits a two-step process for transforming charge-current density. It claims the first step (transforming components, e.g., Eq. 1) is incomplete and that a second step (transforming spacetime coordinates (t,r) to (t',r')) modifies the result of the first step to yield ρ'=0. In reality, the standard Lorentz transformation of a four-vector field, J'<sup>μ</sup>(x') = Λ<sup>μ</sup><sub>ν</sub>J<sup>ν</sup>(x(x')), is a single, complete operation. This operation defines the field components in the new frame (x') based on their values in the old frame (x), where x(x') is the inverse Lorentz transformation of coordinates. There is no subsequent, separate coordinate transformation step that alters or nullifies the already transformed field components."
      },
      {
        "Problem": "The paper misinterprets the physical origin of the induced charge density as an 'artifact of counting' rather than a real physical effect.",
        "Location": "Page 2, last paragraph starting 'To see what happens...'; Page 3, first two paragraphs before Eq. (5).",
        "Explanation": "The paper correctly identifies that the non-zero ρ' arises because observers in the moving frame S' define simultaneity differently than observers in the rest frame S. This leads to an apparent imbalance in the density of positive and negative charges in S' if the wire is neutral and carries a current in S. The paper calls this a 'miscounting' and an 'artifact'. However, this is precisely the physical mechanism underlying the Lorentz transformation of charge and current densities. The resulting ρ' is the charge density that would be measured by an observer in frame S'. It is a real physical effect, not an artifact to be corrected or eliminated."
      },
      {
        "Problem": "The transformation of the current density j in Eq. (2) is generally incorrect.",
        "Location": "Page 1, Eq. (2).",
        "Explanation": "Equation (2) states j'(r,t) = γj(r,t). This implies that the current density vector j is simply scaled by γ. The correct Lorentz transformation for the current density components (assuming ρ=0 in the initial frame S) is that the component parallel to the relative velocity V is scaled by γ (j'<sub>||</sub> = γj<sub>||</sub>), while components perpendicular to V remain unchanged (j'<sub>⊥</sub> = j<sub>⊥</sub>). Therefore, j' = γj is only true if the current density j is entirely parallel to V. If j has components perpendicular to V, Eq. (2) is incorrect. While the paper's main focus is on ρ', this error in stating the basic transformation equations for the four-current is notable."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 7840,
      "output": 1111
    }
  },
  {
    "entry_id": 219,
    "retraction_id": "2205.10165v2",
    "paper_id": "2205.10165v1",
    "retraction_comment": "It is not proved that the function $S$ is in fact an inner function",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental error in the definition of S_n and S",
        "Location": "Page 1, definition of S1; Page 2, recursive definition of S_{n+1} and fixed-point equation for S.",
        "Explanation": "The recursive definition S_{n+1} = exp((1+zS_n)/(1-zS_n)) and the corresponding fixed-point equation S = exp((1+zS)/(1-zS)) are claimed to produce singular inner functions (S_n, S ∈ SInn). However, if S_n (or S) were an inner function, then for z in the unit disk U, w = zS_n(z) (or w = zS(z)) would satisfy |w| < 1. The term (1+w)/(1-w) then has a strictly positive real part. Consequently, |S_{n+1}(z)| = exp(Re((1+zS_n(z))/(1-zS_n(z)))) > 1 (and similarly |S(z)| > 1). This contradicts the requirement for inner functions to have modulus less than or equal to 1 in U. Thus, the constructed functions S_n and S cannot be inner functions as claimed."
      },
      {
        "Problem": "Ill-defined recursion and flawed normality argument",
        "Location": "Page 2, paragraph starting \"{S_n}_n=0 (as a set of functions) is a normal family\".",
        "Explanation": "Stemming from the definitional error of S_n, S_1 = exp((1+zS_0)/(1-zS_0)) (with S_0 ∈ SInn) will have |S_1(z)| > 1 for z ∈ U. In the next step, for S_2 = exp((1+zS_1)/(1-zS_1)), the argument w_1(z) = zS_1(z) is not guaranteed to be in the unit disk U, as |S_1(z)| > 1. If |w_1(z)| ≥ 1, the term (1+w_1(z))/(1-w_1(z)) is not guaranteed to have positive real part, and its properties are uncontrolled. This breaks the recursive construction of functions with the necessary properties for S_n to converge to an S ∈ SInn. The argument for {S_n} being a normal family (e.g., via Montel's theorem) is unsound as local uniform boundedness is not established."
      },
      {
        "Problem": "Unsubstantiated claim of contraction mapping for existence of S",
        "Location": "Page 2, Remark 1.1 and the subsequent claim about Banach's fixed-point theorem; Page 4, Remark 1.4.",
        "Explanation": "The paper asserts that the operator T(t) = exp((1+zt)/(1-zt)) is a contraction map with respect to t (where t is a complex variable in U, or a function), ensuring a unique fixed-point S. The derivative calculation for h(t) = exp((1+zt)/(1-zt)) on page 4 (Remark 1.4) contains a sign error: the derivative of (1+zt)/(1-zt) with respect to t is 2z/(1-zt)², not -2z/(1-zt)². Even if the intended function was exp(-(1+zt)/(1-zt)) to ensure |T(t)|<1, its derivative's modulus |exp(-(1+zt)/(1-zt)) * (-2z/(1-zt)²)| is not generally less than 1 for all z, t in the unit disk. The specific bound of 4e⁻² mentioned on page 2 is not derived or justified. Thus, the existence and uniqueness of the fixed-point S via Banach's theorem is not established."
      },
      {
        "Problem": "Flawed proof of injectivity for zS",
        "Location": "Page 2, Proof of Theorem 1.2, the step \"f(z·S(z)) = z\" based on the definition of f(w) and the fixed-point equation for S.",
        "Explanation": "The proof that w(z) = zS(z) is injective relies on f(w(z)) = z, where f(u) = u·exp((1+u)/(1-u)). The condition f(zS(z)) = z translates to (zS(z))·exp((1+zS(z))/(1-zS(z))) = z, which simplifies to S(z)·exp((1+zS(z))/(1-zS(z))) = 1. Given the paper's fixed-point equation S(z) = exp((1+zS(z))/(1-zS(z))), this implies S(z)·S(z) = 1, so S(z) = ±1. However, on page 3, the paper argues that S(z) satisfying the fixed-point equation cannot be a constant e^(iθ) (which includes ±1). This creates a contradiction, meaning that the premise f(zS(z))=z is false for the S constructed by the paper (unless S=±1, which is ruled out). Therefore, the proof of injectivity for zS is unsound."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 11961,
      "output": 1208
    }
  },
  {
    "entry_id": 220,
    "retraction_id": "1511.00570v2",
    "paper_id": "1511.00570v1",
    "retraction_comment": "This paper has been withdrawn because the analysis therein completely oversimplified the physics during primordial nucleosynthesis",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent formalism for the parameter α and its evolution equation.",
        "Location": "Eq (3), the text paragraph following Eq (4) (specifically the definitions of α for the two epochs), and Eq (13).",
        "Explanation": "The definitions of the parameter α provided explicitly in the text below Eq (4) for the two considered epochs (TF > T > TB, and T <= TB) are inconsistent with the evolution equations for α presented in Eq (13), if the relation X4 = 2/(1+α) from Eq (3) is assumed to hold universally. For example, for TF > T > TB, the text defines α = Np/(2Nn), but Eq (13) requires α = Np/Nn to be consistent with X4 = 2/(1+α). Similarly, for T <= TB, the text defines α = (1/2)Np,f/N4, but Eq (13) requires α = 1 + Np,f/(2N4) for consistency with X4 = 2/(1+α). This fundamental inconsistency in the definition and evolution of α undermines the derivation of ΔX4Macro (Eq 14) and therefore all subsequent quantitative constraints on Macro dark matter presented in the paper."
      },
      {
        "Problem": "Questionable validity of the perturbative calculation for ΔX4Macro (Eq 14) in the 'vanishing constraint' region.",
        "Location": "Eq (14), and the discussion of Figure 2 on page 4 (specifically the third paragraph describing the vanishing constraint near V(Rx) ~ 0.01 MeV).",
        "Explanation": "The calculation of ΔX4Macro is based on a perturbative expansion (Eq 14) that assumes the parameter α remains close to its standard model value, αstd. In the 'vanishing constraint' region (e.g., V(Rx) ~ 0.01 MeV), the argument is that two opposing effects on X4 (one decreasing X4, one increasing it) cancel out. If these individual effects are large before cancellation, α could deviate significantly from αstd during the early or late phases of BBN. This would potentially invalidate the linearization of X4(α) around αstd (i.e., the use of (1+αstd)² in the denominator of Eq 14 and αstd as a prefactor for some terms). This makes the prediction of a specific 'vanishing constraint' location and its robustness questionable without a more detailed non-perturbative analysis or justification of the approximation in this regime."
      },
      {
        "Problem": "Potential neglect of Macro-induced shift in the deuterium bottleneck temperature (TB) in the 'vanishing constraint' region.",
        "Location": "Footnote 1 on page 3, Figure 2 (including caption), and the discussion of the vanishing constraint on page 4.",
        "Explanation": "The analysis assumes that the deuterium bottleneck temperature TB is not shifted by Macro interactions by more than 10% (Footnote 1). While the authors mark regions of high overall absorption where this assumption might fail (dashed lines in figures), the 'vanishing constraint' feature is presented as occurring in a 'robust' region. However, if the cancellation of effects on X4 (as discussed in Problem 2) involves significant prior absorption or alteration of nucleon abundances, these alterations could themselves shift TB by more than the assumed 10%. The paper's check that 'variations of TB by 10% do not affect ... constraints by more than 5%' might not cover scenarios where TB is significantly shifted *due to* the Macro interactions themselves, especially if the individual (pre-cancellation) effects are large. This could undermine the validity of the calculations specifically in the 'vanishing constraint' region."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 12567,
      "output": 825
    }
  },
  {
    "entry_id": 221,
    "retraction_id": "1911.02706v2",
    "paper_id": "1911.02706v1",
    "retraction_comment": "A missing sign in the argument to prove Lemma 2 renders the proof incorrect. The note is withdrawn since we are unable to provide a corrected proof that works with the stated generality",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Lemma 2, which claims that the scalar curvature s_g is constant for a critical metric, is unsound.",
        "Location": "Page 5, Proof of Lemma 2",
        "Explanation": "The proof relies on a sequence of highly non-trivial (and potentially incorrect for the general Riemannian setting) identities and steps that are not derived or properly cited. Specifically: \n1. The stated Bochner formula for δ(h_φ) where h_φ = Hess_g φ (∇g dφ) appears non-standard. The standard identity for δ(Hess φ) is d(Δφ) + Ric(dφ).\n2. The subsequent identity for -δδ(h_φ) (also written as -δ∇*(h_φ)) = Δ_g^2 φ + (Ric_g, Hess_g φ)_g + (1/2)(ds_g, dφ)_g is crucial but not derived or cited for the general Riemannian case. Such fourth-order operator identities are subtle and context-dependent (e.g., Kähler vs. Riemannian).\n3. The derivation of the variational expression d/dt S(g+th_φ)|_{t=0} = -4 ∫ s_g (Δ_g^2 φ + (Ric_g, Hess_g φ)_g + (1/2)(ds_g, dφ)_g) dμ_g is opaque and not shown. It's unclear how this specific form with the factor -4 and the operator Q(φ) arises from the general variation of S(g).\n4. The final conclusion that if φ = s_g, then 'the squared L2-norm of the ∇_g ds_g vanishes, so ∇_g ds_g = 0' (i.e., Hess_g s_g = 0) from the vanishing of the integral ∫ s_g Q(s_g) dμ_g is a significant leap that requires a specific structure of Q(s_g) (e.g., being a square of Hess_g s_g or similar, as in certain Kähler geometry arguments) which is not established here. \nCollectively, these points render the proof of s_g being constant invalid, which is a cornerstone for Theorem 3."
      },
      {
        "Problem": "The derivation of Equation (10), the trace of the Euler-Lagrange equation (8), appears to have an incorrect coefficient for the Laplacian term.",
        "Location": "Page 3, Equation (10) and its derivation from (8) and (9)",
        "Explanation": "Tracing the Euler-Lagrange equation (8): (2Δ_g s_g + s_g^2/2) g + 2 Hess_g(s_g) - 2s_g Ric_g = λ_g g, yields (2n+2)Δ_g s_g + (n-4)/2 s_g^2 = n λ_g. Using the definition of λ_g from (9) (λ_g = (n-4)/(2n) π_g(s_g^2), assuming μ_0(M)=1 and λ_g is constant), this leads to (2n+2)Δ_g s_g + (n-4)/2 (s_g^2 - π_g(s_g^2)) = 0. However, Equation (10) in the paper states this as (2n-2)Δ_g s_g + (n-4)/2 (s_g^2 - π_g(s_g^2)) = 0. The coefficient of Δ_g s_g differs ((2n+2) vs (2n-2)). This discrepancy affects subsequent arguments that use Equation (10), notably the n=2 case."
      },
      {
        "Problem": "The argument for constancy of scalar curvature s_g in dimension n=2 relies on the potentially incorrect Equation (10).",
        "Location": "Page 4, discussion of n=2 case",
        "Explanation": "The proof that s_g is constant for n=2 (leading to ∂#s_g being holomorphic) starts from Equation (10). For n=2, the paper's Equation (10) becomes 2Δs_g - (s_g^2 - π_g(s_g^2)) = 0. If the coefficient of Δs_g is (2n+2) as derived from (8) (see Problem 2), then for n=2, it would be (2*2+2) = 6, leading to 6Δs_g - (s_g^2 - π_g(s_g^2)) = 0. While the overall argument structure for n=2 might still hold with a different constant factor, the specific derivation of Equation (11) and the conclusion that ∂#s_g is holomorphic needs to be re-verified with the corrected starting equation. The validity of this specific dimensional argument is thus questionable."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 18923,
      "output": 1129
    }
  },
  {
    "entry_id": 222,
    "retraction_id": "1806.06939v2",
    "paper_id": "1806.06939v1",
    "retraction_comment": "The objective in (8) allows for trivial solutions e.g. the prior",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation and unclear final form of the training objective function.",
        "Location": "Page 4, Eq (8); Appendix A, Eq (S1)-(S4), Page 11.",
        "Explanation": "The derivation of the proposed training objective (Eq 8) as an upper bound on the KL divergence KL(q(w) || p(w|Sp,Sf)) appears unsound. The inequality step in Appendix A (Eq S1), `integral q(w) log p(Sf|Sp,w) dw >= integral q_tilde(w) log(q(w)p(Sf|Sp,w)) dw`, is not generally true and lacks justification. Furthermore, the derivation in Appendix A leads to an objective `KL(q||p_prior) + KL(q_tilde||q) - E_{q_tilde}[log p(Sf|Sp,w)] - H(q_tilde)`, which differs from the implied final objective in the main text's Eq (8) (last line, if interpreted as an expectation `E_{q_tilde}[log p(Sf|Sp,w)]` for the likelihood term). This inconsistency and flawed derivation undermine the theoretical grounding of the method."
      },
      {
        "Problem": "Potential high variance in gradient estimation due to single sample usage for the expectation involving the proposal network.",
        "Location": "Page 4, Eq (8) (last term); Page 5, Section 4 (Experiments).",
        "Explanation": "The paper states that one sample is used during training (Page 5). If the expectation term `E_{w ~ q_tilde(w|Sp, Sf)} [log p(Sf|Sp, w)]` in their objective (Eq 8) is estimated using a single sample from the proposal network `q_tilde`, this can lead to high variance in the gradients. This is particularly concerning as a key motivation for introducing `q_tilde` was to mitigate high variance estimates from sampling `q(w)`. Using a single sample for this new expectation might counteract the intended benefits."
      },
      {
        "Problem": "Misleading terminology of \"Importance Sampling\" in the objective function and method title.",
        "Location": "Title; Abstract; Page 1 (Fig 1 caption); Page 4 (Section 3.3).",
        "Explanation": "The method is titled \"Importance Sampling based Optimization\" and repeatedly refers to importance sampling. However, the final training objective, as implied by Eq (8) (e.g., `KL(q||p_prior) + KL(q_tilde||q) - E_{w ~ q_tilde} [log p(Sf|Sp, w)]`), does not use the standard importance weights `q(w)/q_tilde(w)` to correct the expectation term. Instead, `q_tilde` acts as a learned proposal distribution in a scheme more akin to amortized variational inference or a doubly reparameterized model. This terminology can be misleading regarding the actual mechanism and its theoretical properties (e.g., unbiasedness with respect to the original ELBO)."
      },
      {
        "Problem": "Limited flexibility of the variational distribution q(w) potentially conflicting with the \"full Bayesian treatment\" claim.",
        "Location": "Page 3, Section 3.1, Eq (4).",
        "Explanation": "The paper claims a \"full Bayesian treatment\". However, the variational distribution `q(W_k)` (Eq 4) uses Bernoulli variables where the probability `p_k` is \"chosen manually\" (e.g., a fixed dropout rate). If `p_k` is a fixed scalar hyperparameter, the model's ability to learn the variance of the posterior distribution for different weights or layers is restricted, as only the means `M_k` are tuned. This is a common simplification (MC dropout) but limits the flexibility of the posterior approximation compared to approaches where variance-related parameters are also learned adaptively. This makes the \"full Bayesian treatment\" claim strong for the adopted `q(w)`."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 10616,
      "output": 890
    }
  },
  {
    "entry_id": 223,
    "retraction_id": "1310.8031v2",
    "paper_id": "1310.8031v1",
    "retraction_comment": "The solution for the NS equations provided can only be constant or very small magnitude",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Error in the derivation of the crucial estimate for the nonlinear term.",
        "Location": "Page 7, equations (34)-(36), leading to (27)",
        "Explanation": "The derivation of the bound for the nonlinear term `b(u,u,A^r u)` involves Sobolev embeddings and interpolation inequalities. In equation (34), the interpolation exponents for `||u(t)||_{k+1/2}` and `||u(t)||_{r+2-k}` are used to bound these terms. When these are substituted into (33) to get (35), the resulting exponent for `||u(t)||_{r+1}` appears to be `1/(2r)`. However, a recalculation suggests the exponent should be `1+1/(2r)`. Specifically, if `||u||_{k+1/2} \\le C ||u||_1^{1-\theta_1} ||u||_{r+1}^{\theta_1}` and `||u||_{r+2-k} \\le C ||u||_1^{1-\theta_2} ||u||_{r+1}^{\theta_2}`, where `\theta_1 = (k-1/2)/r` and `\theta_2 = (r+1-k)/r`, then the combined power of `||u||_{r+1}` in (33) becomes `\theta_1 + \theta_2 = (r+1/2)/r = 1 + 1/(2r)`. This error in the exponent of `||u||_{r+1}` in (35) would significantly alter the subsequent application of Young's inequality in (36) and the final form of the differential inequality (27), which is fundamental to the paper's main argument."
      },
      {
        "Problem": "The assumption (38) on initial data is overly restrictive and likely implies the trivial solution.",
        "Location": "Page 7, equation (38), and its use in Page 8, equation (43)",
        "Explanation": "Assumption (38) states `sup_{k<∞} ||u_0||_k = K_3 < ∞`. The norms `||u||_k` are defined (e.g., page 3, implicitly by (7)) as `||u||_k^2 = \\sum_j \\lambda_j^k |\\hat{u}_j|^2`, where `\\lambda_j` are eigenvalues of the Stokes operator and `\\lambda_j \to \\infty`. If `u_0` has any non-zero Fourier coefficient `\\hat{(u_0)}_j` for an eigenvalue `\\lambda_j > 1` (which is true for any non-zero function as `\\lambda_1 = 4\\pi^2 > 1`), then `\\lambda_j^k |\\hat{(u_0)}_j|^2` would grow unboundedly with `k`. Thus, for `sup_k ||u_0||_k` to be finite, `u_0` must be zero. If `u_0=0`, the global existence of a smooth solution `u(t)=0` is trivial and does not address the Navier-Stokes problem. The paper's core argument that the blow-up time `T` in (43) tends to infinity as `r \to \\infty` relies critically on `K_3` (representing `||u_0||_r`) being uniformly bounded, which is a consequence of this assumption."
      },
      {
        "Problem": "Inconsistent forms of the key differential inequality for H^r norms.",
        "Location": "Page 6, Eq. (27); Page 8, Eq. (39); Page 8, Eq. (40) first line",
        "Explanation": "The fundamental differential inequality governing `d/dt ||u(t)||_r^2` is presented in several different forms throughout the paper, which is problematic for a rigorous proof. \n1. Equation (27) states: `d/dt ||u(t)||_r^2 + \nu ||u(t)||_{r+1}^2 \\le \\dots + c ||u(t)||_r ||u(t)||_1^{4r/(2r-1)}`. \n2. Equation (39) (for `f=0`) states: `d/dt ||u(t)||_r^2 + \nu ||u(t)||_{r+1}^2 \\le c ||u(t)||_1 ||u(t)||_r^{4r/(2r-1)}`. \n3. The first line of equation (40) implies (by dropping the `\nu ||u||_{r+1}^2` term from (39)): `d/dt ||u(t)||_r^2 \\le c ||u(t)||_1^2 ||u(t)||_r^{4r/(2r-1)}` (note the `||u||_1^2` here vs `||u||_1` in (39)). \nThese expressions differ in how norms `||u||_1` and `||u||_r` appear and their powers. Such inconsistencies in the starting point of the Gronwall-type argument (40)-(43) undermine the validity of the subsequent steps and conclusions."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 18246,
      "output": 1204
    }
  },
  {
    "entry_id": 224,
    "retraction_id": "0904.3516v4",
    "paper_id": "0904.3516v3",
    "retraction_comment": "This paper has been withdrawn by the authors. The present version has several results that are correct, but, there is a problem in the use of sections 7 and 8 to derive generic properties for the set of analytic potentials g. All sections before this are OK",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 10186,
      "thinking": 65536,
      "output": 0
    }
  },
  {
    "entry_id": 225,
    "retraction_id": "1509.01802v3",
    "paper_id": "1509.01802v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equations 22 and 23",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Treatment of p_i^2 for massless gluons",
        "Location": "Page 8, Equations (22), (23), (24)",
        "Explanation": "The derivation of the limiting behavior of amplitude A_c (Eq. 25) relies on expressions (Eq. 22, 23) that include terms like 'p2^2' or 'sqrt(p2^2)', where p2 is the momentum of an external massless gluon. For a massless gluon, p2^2 = p_mu p^mu = 0. If p2^2 is strictly zero, then the numerator in Eq. (22) and the terms in Eq. (23) would be zero. This would lead to an indeterminate 0/0 form in Eq. (24) when calculating A_c, invalidating the derivation of Eq. (25) where p2^2 supposedly cancels. The paper does not clarify if 'p2^2' is a symbolic scale or how this issue is handled, which is critical for the validity of the result."
      },
      {
        "Problem": "Unjustified kinematic assumption for intermediate propagators",
        "Location": "Page 8, Section 2.3.1 (around Eq. 22) and Page 9, second paragraph",
        "Explanation": "The analysis of term (c) assumes a specific limiting configuration where the intermediate momenta P_345 and P_671 become collinear with one specific incoming gluon p2 (i.e., P_345 = z p2, P_671 = (1-z) p2). This assumption is crucial as it implies p1+p3=0, leading to <31>=0 and thus A_c=0 via Eq. (25). The paper claims this is 'forced by kinematics' when s_345 and s_671 are small and final state transverse momenta balance pairwise. However, the justification for why P_345 and P_671 must align specifically with p2 (rather than another incoming momentum or a combination) is insufficient. This specific alignment is a strong condition that significantly restricts the phase space and may not be representative of all DPI-like configurations."
      },
      {
        "Problem": "Questionable approximation of spinor products in Eq. (23)",
        "Location": "Page 8, Equation (23)",
        "Explanation": "Equation (23) provides approximations for spinor products like <6|7+1|2] and <5|4+3|2] under the assumption that P_671 = (1-z)p2 and P_345 = z p2. The derivation of these approximations is not shown and appears non-trivial. For example, <6|7+1|2] = <6|P_71+p2|2], where P_671 = p6+P_71. A direct expansion using standard spinor identities like Eq. (14) under the given conditions (e.g., P_671 = (1-z)p2) does not straightforwardly yield the expressions in Eq. (23) (e.g., the (1-z) prefactor for the first term, or the appearance of sqrt(p2^2) if p2^2=0). If these approximations are incorrect, the cancellation of p2^2 terms in Eq. (24) and the final form in Eq. (25) would be invalid."
      },
      {
        "Problem": "Potential inconsistency between different forms of amplitude A_c",
        "Location": "Page 8, Equation (17) vs Equation (19)",
        "Explanation": "Equation (19) is presented as a graphical representation (and presumably an equivalent algebraic form) of term (c) from Equation (17). The central vertex factor in Eq. (19) involves ([P_671 P_345])^3. If P_671 and P_345 are collinear (e.g., both proportional to p2, as assumed in Sec 2.3.1), then [P_671 P_345] = 0, which would make A_c from Eq. (19) vanish directly. However, the derivation from Eq. (17) leads to Eq. (25), which is generally non-zero (proportional to <31>^3) unless <31>=0. This discrepancy suggests a potential inconsistency in how A_c behaves under the assumed kinematic limit, or between the two presented forms of the amplitude, which could affect the conclusions drawn."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 17298,
      "output": 1039
    }
  },
  {
    "entry_id": 226,
    "retraction_id": "2312.05804v3",
    "paper_id": "2312.05804v2",
    "retraction_comment": "Error in the derivation of equation 11 in section 4.3.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Limited Generality of Clothing Prior",
        "Location": "Section 4.2, 'Layered Geometric Prior'",
        "Explanation": "The clothing prior is defined as an SMPL model excluding head, hands, and feet. This body-centric prior may overly constrain the generation of diverse clothing types (e.g., very loose, flowing, or structured garments that deviate significantly from a body silhouette), potentially limiting the variety and realism of 'non-skin tight' clothing the system can produce. This could impact the claim of generating 'more diverse 3D content without being constrained by specific templates' if the initial density guidance is too restrictive."
      },
      {
        "Problem": "Constrained Clothing Reusability due to Unidirectional Body-to-Clothing Deformation",
        "Location": "Section 4.3.2 ('SMPL-driven Implicit Field Deformation Network'), Equation 13, and acknowledged in Section 6 ('Limitations')",
        "Explanation": "The method primarily deforms the body to fit a pre-generated clothing item. The clothing's overall shape, generated in Stage 1, remains relatively fixed during this matching process. If the clothing's implicit shape is not well-suited for the target body's topology or proportions (e.g., large differences in body mass or structure), deforming the body to fit can lead to unnatural body shapes, as acknowledged in the limitations. This significantly constrains the 'free transfer and reuse' capability, especially between bodies with substantial shape differences, as true bidirectional adaptation or robust clothing deformation to a new body is not part of the described method."
      },
      {
        "Problem": "Potential for Error Propagation in Semantic Confidence Network Supervision",
        "Location": "Section 4.3.1, 'Confidence Prediction for Clothing', Equation 12",
        "Explanation": "The 3D Semantic Confidence Network is supervised by 'f_s', the clothing feature perceived by the pre-trained semantic awareness network F_sa from the initial clothing generation (Stage 1). If this initial clothing generation already contains significant non-clothing artifacts or misinterpretations of the text prompt, then 'f_s' will also be flawed. Using these potentially unreliable features as a supervisory signal for the confidence score 's_c' could lead to ineffective refinement or even reinforce initial generation errors, rather than robustly eliminating non-clothing content as intended. The robustness of this stage to varying quality of the initial clothing generation is not demonstrated."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 4580,
      "output": 535
    }
  },
  {
    "entry_id": 227,
    "retraction_id": "1401.1766v5",
    "paper_id": "1401.1766v4",
    "retraction_comment": "This paper has been withdrawn by the author due to errors in figure 1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated Ontology Coverage Claim and Incorrect Citation",
        "Location": "Page 5, Section 'Ontology-graph construction', last paragraph",
        "Explanation": "The paper claims that four specific UMLS ontologies (MeSH, SNOMEDCT, CSP, AOD) 'cover all senses of the target words in NLM database [18]'. However, reference [18] ('Chvatal V: A greedy heuristic for the set-coving problem') is entirely unrelated to ontology coverage or the NLM database. This critical claim about the comprehensiveness of the constructed ontology graph, which is foundational to the system's query expansion capabilities, is therefore unsubstantiated by the provided citation and potentially incorrect. The actual extent of coverage is not justified."
      },
      {
        "Problem": "Weak Evaluation Methodology Relying on Subjective Judgments with Potentially Problematic Criteria",
        "Location": "Page 16, Section 'Results', bullet points defining categories of comparison",
        "Explanation": "The performance comparison between G-Bean and PubMed relies exclusively on subjective judgments from 20 graduate students. The criteria for categorizing outcomes (e.g., 'G-Bean is definitely better than PubMed') use thresholds like '(n_a - n_b)/n_a >= 25%'. Using n_a (votes for G-Bean) as the denominator can make the 'definitely better' classification sensitive to small absolute numbers of votes. More importantly, the primary condition for results being 'similar' (n_c >= 10, i.e., at least half the students find them similar) can overshadow actual differences, potentially masking scenarios where one system is moderately preferred by a plurality but not overwhelmingly so. This methodology may not robustly support the strength of the conclusions drawn."
      },
      {
        "Problem": "Absence of Objective Evaluation Metrics Using Standard Test Collection",
        "Location": "Page 15-17, Section 'Results'",
        "Explanation": "The paper uses the OHSUMED benchmark queries, a dataset that typically includes relevance judgments for documents. However, the evaluation does not employ any standard, objective Information Retrieval (IR) metrics such as Precision, Recall, Mean Average Precision (MAP), or Normalized Discounted Cumulative Gain (NDCG). Relying solely on subjective student opinions when objective measures could have been calculated makes the performance claims less rigorous, harder to compare with other systems, and potentially less reliable. This is a significant omission for an IR system evaluation."
      },
      {
        "Problem": "Insufficient Detail on User Intention Discovery Mechanism",
        "Location": "Page 11, Section 'Document retrieval', paragraph 2; and Page 2, Abstract, Methods point (3)",
        "Explanation": "One of G-Bean's three claimed innovations is 'Retrieval and re-ranking of documents based on user's search intention'. The paper states G-Bean 'can form a new query using the key concepts automatically obtained from all articles that are interested by the user'. However, the methodology for how these 'key concepts' are extracted from user-selected articles and how they are subsequently used to 'form a new query' is not adequately described. This lack of detail makes it difficult to assess the soundness, novelty, or effectiveness of this core component, thereby weakening the claims about its advantages."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 6534,
      "output": 729
    }
  },
  {
    "entry_id": 228,
    "retraction_id": "2011.03931v2",
    "paper_id": "2011.03931v1",
    "retraction_comment": "There is a error in the experimental EBSD map of albite due to pseudosymmetry. The two parts A and B are actually linked by a 180_ rotation around b-axis. The theory remains valid to my point of view, but the EBSD map of albite cannot be used as an \"experimental proof\". I would like to apologize to the readers of the first versions deposited on Arxiv",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Oversimplified correspondence matrices for 180° axial heterotwins in triclinic/monoclinic systems.",
        "Location": "Page 25, Table 3 (and related calculations in Section 5.1.2)",
        "Explanation": "The correspondence matrices C^(2->1) (representing the twin operation) for 180° axial heterotwins in feldspars (e.g., albite, which is triclinic) are presented in Table 3 as simple diagonal matrices like diag(1,-1,-1). Such matrix forms are generally valid only if the crystal axis of rotation is orthogonal to the other two basis vectors and these vectors themselves form an orthogonal set, or if the matrix represents the operation in a basis aligned with Cartesian axes where the crystal axis of rotation is also aligned. For a triclinic system like albite, these conditions are not met. The actual matrix C^(2->1), as defined by Eq. (1) (C^(2->1) = B_super2 * (B_super1)^-1, where B_super are matrices of supercell vectors in a common Cartesian frame), would be more complex and dependent on the actual triclinic cell parameters and the specific supercell vectors (e.g., from Table 2). This simplification would lead to incorrect distortion matrices F^1 (Eq. 4) and generalized strain values sg, which are central to the paper's predictions."
      },
      {
        "Problem": "Inconsistent or inadequately justified misorientation and its geometric interpretation for the non-180° b-axial heterotwin in albite.",
        "Location": "Page 26, Section 5.1.3 (description of Table 4 results)",
        "Explanation": "For the predicted non-180° b-axial heterotwin in albite ((101) || (001) interface), the paper states that the misorientation matrix T found by the software is a 'rotoinversion of 180° around the axis ~[201]'. The subsequent geometric interpretation of this [201] axis as being 'normal to axis b' (the common invariant direction u) is generally not true for a triclinic crystal unless specific, restrictive metric conditions (2ab*cos(gamma) + bc*cos(alpha) = 0) are met, which is not stated. Furthermore, the term 'rotoinversion of 180°' is ambiguous; if it implies a standard S2 operation (inversion), it's a simple inversion. If it means a 180° rotation followed by inversion, the relationship of this complex operation (around an axis ~[201] that is not u=b) to the general theory of non-180° axial heteroplanes (which describes a rotation around the common axis u by the inter-planar angle alpha, as per page 15) is unclear and not justified. This makes the nature of the predicted 'unconventional twin' and its formation mechanism obscure."
      }
    ],
    "token_usage": {
      "input": 12766,
      "thinking": 16517,
      "output": 667
    }
  },
  {
    "entry_id": 229,
    "retraction_id": "1501.02643v7",
    "paper_id": "1501.02643v6",
    "retraction_comment": "This article has been withdrawn due to error in Eq. 8",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of Ising-type interaction for Quantized Spin Hall Effect (QSHE)",
        "Location": "Page 2, Eq. (8) and preceding text; Section 'Spin Hall Effect' (Eq. 9-19)",
        "Explanation": "The paper simplifies the general s-d interaction between the Single Molecule Magnet (SMM) spin (S) and topological insulator (TI) electron spin (σ), which is typically of Heisenberg form (S·σ), to an Ising-type interaction (-λS_zσ_z, later -λτ_zσ_z in the two-level model as per Eq. 8). This simplification is stated as being 'for simplicity' (page 2, text leading to Eq. 8) and 'interaction in the z-direction' (page 2, text below Eq. 8). This assumption is critical for the derivation of the Quantized Spin Hall Effect (QSHE, Eq. 19), as it allows the system to be decoupled into two sectors where the SMM's z-spin component (S_z or τ_z) is conserved by the interaction. Without strong physical justification for neglecting the S_xσ_x and S_yσ_y terms (e.g., due to extreme SMM anisotropy projecting the interaction onto the z-axis), the QSHE conclusion is not robustly supported, as these terms would generally break the S_z conservation essential for the argument."
      },
      {
        "Problem": "Unclear derivation and generality of eigenvalues in the presence of SMM tunneling",
        "Location": "Page 3, Eq. (20); Section 'Effects of Tunneling'",
        "Explanation": "The eigenvalues E_sη = (-1)^η √((v_F k + sΔ_x)^2 + λ^2) (Eq. 20) for the system including SMM tunneling (Δ_x ≠ 0) are presented without derivation. The full Hamiltonian (Eq. 8) that includes TI surface states, SMM tunneling (Δ_xτ_x), and SMM-TI interaction (-λτ_zσ_z) is a 4x4 matrix (2 dimensions for electron spin, 2 for SMM pseudo-spin). The simple analytical form of Eq. (20) suggests it might be valid only under specific, unstated approximations (e.g., for a particular momentum k direction, or after neglecting certain terms from the 4x4 matrix diagonalization) rather than being a general solution. Since the subsequent calculation of the pseudo-spin Chern number (C°, Eq. 21-26) directly relies on these eigenvalues and the derived eigenspinors (Eq. 21-22), any lack of generality or correctness in Eq. (20) would undermine the conclusions for the SMM tunneling regime."
      },
      {
        "Problem": "Misleading framing of the model as a co-tunneling transport problem",
        "Location": "Abstract; Page 1, last paragraph of Introduction; Page 2, text below Eq. (6)",
        "Explanation": "The paper repeatedly frames its analysis as a 'simplified model of a co-tunneling problem which involves a molecular quantum dot sandwiched between a source and a drain made of two topological insulator surfaces' (Abstract) or similar wording (Page 2). However, the actual Hamiltonian solved (Eq. 4: H = H_TI + H_SMM + H_int) and depicted (Fig. 1) describes an SMM coupled to a single 2D TI surface. The derived results are equilibrium topological properties of this SMM-TI interface (quantized spin Hall conductivity and pseudo-spin Chern number), not a calculation of transport current or conductance in a source-SMM-drain setup. This framing is misleading because the study does not analyze the co-tunneling transport phenomena it claims to model. The conclusions drawn are about the intrinsic properties of the interface, which would influence transport, but the transport itself is not calculated."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 13571,
      "output": 874
    }
  },
  {
    "entry_id": 230,
    "retraction_id": "1903.02670v2",
    "paper_id": "1903.02670v1",
    "retraction_comment": "We can not use fixed-point theorem in the spaces defined in section 4.",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Divergent integral in bilinear estimate for IVP (1.2)",
        "Location": "Page 6-7, Proposition 2.3, specifically equation (2.17) and (2.18)",
        "Explanation": "The proof of the bilinear estimate for the nonlinearity in equation (1.2) (derivative equation) involves an integral of the form `∫ (t-τ)^A τ^(-1) dτ` (from estimating `||v(τ)||_{L^2} ||w(τ)||_{L^2}` using the `X_T^s` norm definition (2.11), which gives `τ^(-1/2)` for each term). This integral diverges logarithmically at `τ=0`. This invalidates Proposition 2.3, which is crucial for proving local well-posedness (Theorem 1.1) for equation (1.2) in the `X_T^s` space for `s > -1/2`."
      },
      {
        "Problem": "Function space `Y_T^s` definition is problematic for `s > 1/2`",
        "Location": "Page 10, Definition of `Y_T^s`, equations (3.29)-(3.30)",
        "Explanation": "The norm for `Y_T^s` includes the term `t^(1/2-s) ||∂_x u(t)||_{L^2}`. If `s > 1/2`, the exponent `1/2-s` is negative. For this term to be bounded as `t → 0`, `||∂_x u(t)||_{L^2}` must decay to zero at a specific rate if `∂_x u(0) = ∂_x φ ≠ 0`. This implies that the space `Y_T^s` is effectively restricted to initial data `φ` such that `∂_x φ = 0`, or the norm is infinite for general `φ ∈ H^s(R)`. This makes the space unsuitable for proving Theorem 1.2 (local well-posedness for (1.1) for `s > 1/2`) for general initial data. The linear estimate in Lemma 3.3 also shows this issue, as `t^(-s/2)` (which blows up if `s>0`) appears in the estimate if the norm is applied directly."
      },
      {
        "Problem": "Function space `Z_T^s` definition is problematic for `0 < s < 1`",
        "Location": "Page 15, Definition of `Z_T^s`, equations (4.51)-(4.52)",
        "Explanation": "The norm for `Z_T^s` includes the term `t^((1-s)/2) ||u(t)||_{H^s}`. If `0 < s < 1`, the exponent `(1-s)/2` is positive. For this term to be bounded as `t → 0` where `u(t) → φ`, it requires `φ = 0`. If `φ ≠ 0`, `t^((1-s)/2) ||u(t)||_{H^s}` would approach `0 * ||φ||_{H^s} = 0` if `||φ||_{H^s}` is finite, but the issue is that the definition implies `u(t)` must decay. More critically, if `u(t) → φ ≠ 0`, then `t^((1-s)/2) ||u(t)||_{H^s}` approaches zero, but the linear solution `E_μ(t)φ` would have this term as `t^((1-s)/2) ||E_μ(t)φ||_{H^s} ≈ t^((1-s)/2) ||φ||_{H^s}` which blows up if `(1-s)/2 < 0` or is not well-behaved for `φ ≠ 0` if `(1-s)/2 > 0` (as seen in Lemma 4.1 proof attempt). The problem is that for `φ ≠ 0`, `t^((1-s)/2) ||E_μ(t)φ||_{H^s}` blows up as `t → 0` if `(1-s)/2 < 0` (i.e. `s>1`) or is not well defined for `t=0` if `(1-s)/2 > 0`. The space seems suitable only for `φ=0`, making Theorem 1.3 (local well-posedness for (1.1) for `s > 0`, which relies on this space for `0 < s < 1`) problematic for general non-zero initial data."
      },
      {
        "Problem": "A priori estimate for global well-posedness (Theorem 1.5) assumes higher regularity of initial data",
        "Location": "Page 17, Proof of Theorem 1.5, equations (5.64)-(5.65)",
        "Explanation": "The proof of global well-posedness for equation (1.1) in `H^s (s > 0)` relies on an a priori estimate in `H^1`. The derivation of this estimate involves considering an equation for `w = ∂_x u` (5.64) with initial data `w(x,0) = φ'(x)`. This step, and the subsequent estimate (5.65) for `||∂_x u||^2`, implicitly assume that `φ' ∈ L^2`, i.e., `φ ∈ H^1`. However, Theorem 1.5 is stated for initial data `φ ∈ H^s` where `s` can be in `(0,1)`. For such `s`, `φ ∈ H^s` does not imply `φ ∈ H^1`, so `φ'` may not be in `L^2`. This makes the basis of the a priori estimate unsound for the full claimed range of `s`."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 16524,
      "output": 1354
    }
  },
  {
    "entry_id": 231,
    "retraction_id": "1408.0367v2",
    "paper_id": "1408.0367v1",
    "retraction_comment": "This paper has been withdrawn by the author. The paper only considers the omega>k regime, but the undamped modes have omega<k",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and application of damping rates p1, p2 for electromagnetic modes.",
        "Location": "Eq (20), (21), (22), and page 4, first paragraph.",
        "Explanation": "The mode equation (20) for 'u' is u'' + (aσ)u' + Y u = 0 (with Y = k² + (am_A)²). If aσ > 0 and Y > 0, the characteristic equation λ² + (aσ)λ + Y = 0 has negative real roots (λ1, λ2) for overdamped solutions, leading to decaying modes e^(λ1 η), e^(λ2 η). Eq (22) defines p1, p2 as these roots: p² + (aσ)p + Y = 0. Thus, p1, p2 should be negative. However, Eq (21) gives solutions as u1 = exp(-p1(η-ηr)), u2 = exp(-p2(η-ηr)). If p1, p2 are the negative roots from (22), then -p1 and -p2 are positive, making u1 and u2 *growing* modes. This contradicts the claim of damping. The approximations for p1 and p2 on page 4 (e.g., p1 ≈ am_A²/σ) are positive, suggesting that p1 and p2 were intended to be positive decay rates, which would satisfy p² - (aσ)p + Y = 0, not Eq (22). This inconsistency undermines the core argument for the exponential decay of free electromagnetic fluctuations."
      },
      {
        "Problem": "Approximation of the source term integral in the Schwinger-Dyson equation.",
        "Location": "Eq (28), (30), and (31).",
        "Explanation": "Eq (30) presents an approximation for the sourced part of the correlator, (G_R Π_S G_A)(η,η) ≈ π_ij α⁴ Π_S^T / (k² + a²m_A²)². This result appears to be derived by treating the Green's functions G_R as 1/Y (where Y = k² + a²m_A²), which implies neglecting derivative terms (damping and inertia) in the Green's function equation. However, the paper argues for strong damping (large aσ). A simple estimate including damping (G_R ~ 1/(aσ) exp(-p1 Δη)) suggests the integral (28) would yield a result proportional to Π_S / (aσ Y) rather than Π_S / Y². If aσ is large, this difference is significant and would alter the predicted power spectrum P_B in Eq (31) for sourced fluctuations."
      },
      {
        "Problem": "Approximation of the retarded Green function G_R.",
        "Location": "Eq (29).",
        "Explanation": "The retarded Green function G_R in Eq (29) is given with a denominator of (aσ). The correct denominator, derived from the Wronskian of the solutions u1 and u2 (assuming p1, p2 are positive decay rates from p² - (aσ)p + Y = 0), should be (p2-p1) = sqrt((aσ)² - 4(k²+(am_A)²)). Using (aσ) as the denominator is an approximation valid only if (aσ)² >> 4(k²+(am_A)²), i.e., if the damping term dominates heavily. This approximation may not hold generally, for instance, for large k or large effective photon mass (am_A), potentially leading to inaccuracies in the calculated sourced fluctuations which depend on G_R."
      },
      {
        "Problem": "Conclusion of universal exponential decay of sourced magnetic fields relies on strong assumptions about the source properties.",
        "Location": "Section IV.C (especially Eq (43) and subsequent text) and Section V (Conclusion).",
        "Explanation": "The paper concludes that magnetic fields, including those sourced by de Sitter fluctuations, decay exponentially. This relies on the assumption that the source current correlator (Π_S) itself decays exponentially. As shown in Section IV.C for a scalar field source, this exponential decay of Π_S is contingent upon the scalar field having its own significant damping term (σ_φ in Eq (43)). If the fundamental fields sourcing the currents do not possess such intrinsic damping mechanisms (i.e., σ_φ = 0), their correlators would typically decay as a power law due to cosmic expansion. This, in turn, would lead to a power-law decay for the sourced magnetic fields, not an exponential one. The paper's strong conclusion about exponential decay for all primordial fields is therefore not universally supported without specifying and justifying such damping for all possible source mechanisms."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 14843,
      "output": 1081
    }
  },
  {
    "entry_id": 232,
    "retraction_id": "1809.01643v2",
    "paper_id": "1809.01643v1",
    "retraction_comment": "Error in proof for efficiency bound. Variation of time variable is not taken into account",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unrealistic conditions in Assumption 2.8 on true model residuals.",
        "Location": "Page 7, Assumption 2.8",
        "Explanation": "Assumption 2.8 states that `||ε||_1 = o(N^(1/2))` and `||δ||_1 = o(N^(1/2))`, where `ε = D - p(x)` and `δ = Y - E[Y|X]` are true model residuals. These conditions imply `(1/N)sum_i|D_i - p(x_i)| = o(N^(-1/2))` and `(1/N)sum_i|Y_i - E[Y_i|X_i]| = o(N^(-1/2))`. These are exceptionally strong requirements on the data generating process, suggesting that the average absolute residuals vanish at a rate faster than `N^(-1/2)`, which is unlikely to hold for typical DGPs (e.g., if D is Bernoulli(0.5) and p(x)=0.5, the first term is 0.5, not `o(N^(-1/2))`). If these conditions are crucial for the proofs of Theorem 1 and Theorem 2, their validity is compromised."
      },
      {
        "Problem": "Inconsistency in the definition of the outcome variable and time-weighting factor in the estimator versus the theoretical derivations.",
        "Location": "Page 7, Estimator (2.3); Page 8, expression for sigma^2; Page 23, definition of A(W_i, p, γ₀)",
        "Explanation": "The estimator in equation (2.3) uses `(Y_{i,k}(1) - Y_{i,k}(0))` (i.e., `ΔY`) and `E_{k-1}[Y_{i,k}(1) – Y_{i,k}(0)|X_{i,k}, D_{i,k}=0]` (i.e., `E[ΔY|X,D=0]`) as the outcome component. However, the theoretical influence function `A(W_i, p, γ₀)` (page 23) and the variance `σ²` (page 8) appear to be defined for `Y_i` (outcome at time `T_i`) and `γ₀(x_i) = E[Y_i|X_i, D_i=0, T_i]`, along with a time-weighting factor `W_T = (T - P(T=1))/(P(T=1)(1-P(T=1)))`. If `ΔY` is used in the estimator, the `W_T` factor (or the version used in (2.3)) is likely inappropriate. Furthermore, the specific time-weighting factor implemented in estimator (2.3) does not algebraically match the `W_T` factor used in the theoretical influence function `A` and variance `σ²`, meaning the estimator analyzed in the proofs may not be the one presented in (2.3)."
      },
      {
        "Problem": "Potential flaw in the proof of Lemma 2.1 for identification.",
        "Location": "Page 17, Appendix A.1 (Proof of Lemma 2.1)",
        "Explanation": "The proof of Lemma 2.1, which establishes the identification of ATET(1) using the proposed augmented IPW form, contains a critical step where an expression `E[ W_T * ((D-p(x))/(p(x)(1-p(x)))) * (Y - E[Y|X,D=0]) | X ]` is asserted to be equal to `E[Y(1)-Y(0)|X,D=1] - E[Y(1)-Y(0)|X,D=0]` (the conditional DiD parameter). This equality is not clearly derived or verified within the proof. If this step is incorrect, the fundamental identification result underpinning the proposed estimator may be invalid, and the estimator might not target the intended ATET(1)."
      },
      {
        "Problem": "The estimator `θ̂` in (2.3) likely estimates `P(D=1)ATET(1)` rather than `ATET(1)` as claimed for `θ₀`.",
        "Location": "Page 7, Estimator (2.3) and Theorem 1; Page 18, Moment condition for θ₀",
        "Explanation": "The moment condition defining `θ₀` in the proof of Theorem 1 (page 18) is `E[(1/λ_D) * ψ_core - θ₀] = 0`, implying `θ₀ = E[(1/λ_D) * ψ_core] = ATET(1)`. The estimator `θ̂_k` in (2.3) is an empirical average of `hat_ψ_core` terms, so `θ̂ = (1/K)Σθ̂_k` would estimate `E[ψ_core]`. This suggests `θ̂` estimates `λ_D * θ₀ = P(D=1)ATET(1)`. However, Theorem 1 states that `θ₀ = ATET(1)`. This implies that the estimator (2.3) is missing a scaling factor of `1/P̂(D=1)` to consistently estimate ATET(1), or `θ₀` is misidentified in the theorem statement."
      }
    ],
    "token_usage": {
      "input": 7090,
      "thinking": 15516,
      "output": 1220
    }
  },
  {
    "entry_id": 233,
    "retraction_id": "1203.2581v2",
    "paper_id": "1203.2581v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 2",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The effective model for pairing calculations uses 2D band dispersions, neglecting k_z dispersion.",
        "Location": "Page 2, description of effective model Hamiltonian H and dispersions ε_k,α below Eq. (1); also impacts discussion of k_z dependent pairing on page 3.",
        "Explanation": "The effective model's band dispersions (ε_k,α) are defined solely in terms of k_x and k_y, fitted to the k_z=0 Fermi surface. This ignores the significant k_z dispersion shown in the first-principles calculations (Fig. 1a) and the 3D nature of Fermi surface pockets (e.g., near the Z point). This simplification is problematic for a study aiming to determine the stability and nodal structure of k_z-dependent pairing states (e.g., S_{z^2} or S_{x^2+y^2} + S_{z^2}), as the underlying electronic structure lacks k_z dependence, potentially leading to inaccurate conclusions about 3D pairing phenomena."
      },
      {
        "Problem": "Inconsistent definition of the in-plane s-wave component for the k_z-dependent pairing state.",
        "Location": "Page 3, discrepancy between the phase diagram in Fig. 4 (showing 'S_{x^2+y^2} + S_{z^2}') and Eq. (3) (using Δ_α(k) = Δ^0_α [cos k_x cos k_y + δ^α_z cos k_z]).",
        "Explanation": "The phase diagram (Fig. 4) identifies a region with 'S_{x^2+y^2} + S_{z^2}' pairing. S_{x^2+y^2} is defined earlier as Φ^3_k = (cos k_x + cos k_y)/2. However, Eq. (3), used to analyze this k_z-dependent state and its nodes, employs an in-plane component of cos k_x cos k_y (Φ^1_k). These two s-wave forms have different symmetries and nodal structures. This inconsistency invalidates the subsequent analysis of horizontal line nodes based on Eq. (3) if the phase diagram correctly identifies (cos k_x + cos k_y)/2 as the dominant in-plane component, or vice-versa."
      },
      {
        "Problem": "Persistent misidentification of the nodal lines for the S_{x^2+y^2} pairing symmetry.",
        "Location": "Page 3, Fig. 3 caption; Page 3, discussion of FS pocket-2 behavior; Page 4, discussion of S_{x^2+y^2} pairing from magnetic exchange interactions.",
        "Explanation": "The paper defines S_{x^2+y^2} pairing as being proportional to (cos k_x + cos k_y). However, it repeatedly claims or implies that its nodal lines are at k_x = ±π/2 or k_y = ±π/2 (e.g., as depicted by dashed lines in Fig. 3b). These are the nodal lines for an s-wave form like cos k_x cos k_y. The actual nodal lines for (cos k_x + cos k_y) are k_x + k_y = (2n+1)π. This fundamental confusion undermines the paper's assessment of whether the S_{x^2+y^2} state (one of the main candidates) would be nodal or nodeless on the calculated Fermi surfaces of KFe2As2."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 7285,
      "output": 799
    }
  },
  {
    "entry_id": 234,
    "retraction_id": "1912.11842v3",
    "paper_id": "1912.11842v2",
    "retraction_comment": "There is a serious mistake in the section 4 in this paper. The paper concludes that there is new particle production in the system due to the plasma oscillation. However, the fact that the imaginary part of the self-energy will always be zero in the nonrelativistic limit indicates no new particle created",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Questionable Interpretation of Particle Production",
        "Location": "Page 16, Eq. (167) and surrounding discussion; Abstract; Introduction",
        "Explanation": "The paper interprets a correction term (ωp²/4m²) to the plasma frequency as evidence for actual on-shell particle production, leading to an increase in the background particle density (δη). This interpretation is highly unconventional. Such terms typically represent medium modifications to wave propagation or effective parameters. If the background density n₀ genuinely changes to n₀+δη, this would alter the background fermion field ψ₀, necessitating a self-consistent recalculation of the polarization tensor. The mechanism by which plasma oscillations would create stable, additional background particles that modify n₀ is not clearly established or justified within the framework."
      },
      {
        "Problem": "Contradictory Statements and Limitations Regarding Strong Field Effects",
        "Location": "Abstract (pg 1), Introduction (pg 1-2), Page 4 (\"Nonlinear QED effects is excluded\"), Page 8 (\"electromagnetic field is not too strong... eA⁰/m << 1\"), Page 18 (Remark 1, \"Schwinger pair ... cannot be treated in our perturbative scheme\")",
        "Explanation": "The paper is motivated by the need to study strong field QED plasmas, mentioning phenomena like 'QED cascade'. However, it later explicitly states that 'The nonlinear QED effects is excluded,' restricts analyses to weak background fields (eA⁰/m << 1), and admits the scheme cannot handle Schwinger pair production (a key strong field effect) if eA⁰/m ≥ 1. This creates a significant disconnect between the stated goals of addressing non-perturbative strong field phenomena and the actual capabilities and limitations of the presented framework."
      },
      {
        "Problem": "Unsound Justification and Self-Contradiction in the 'Classical Limit Method'",
        "Location": "Page 9, Section III.1, particularly the paragraph starting \"The term of 'classical limit' is meaningless...\"",
        "Explanation": "The core 'classical limit method' involves replacing quantum expectation values with products of classical background fields (e.g., <ΨΨ> ~ Ψ₀Ψ₀). However, the paper itself states on page 9: \"The term of 'classical limit' is meaningless. Further, it invalids the perturbation calculations. In fact, one can not ignore the higher order terms... if ψ and Aμ are macroscopic quantities.\" This statement, if taken at face value, fundamentally undermines the entire approach, as the paper then proceeds to use this 'meaningless' limit and perturbation calculations. This suggests a severe internal contradiction or a profoundly problematic justification for the central method used to evaluate background field contributions."
      },
      {
        "Problem": "Weak and Potentially Ad-hoc Justification for Phase Choices in Background Fermion Coefficients",
        "Location": "Page 12 (Eq. 133-136 and surrounding text) and Page 13 (explanation for setting phases φ₁, φ₂, χ₁, χ₂ to zero)",
        "Explanation": "The coefficients cˢ(t,p) and dˢ(t,p) in the background fermion field expansion initially include phase factors. The paper states these phases can be set to zero, justifying this choice by claiming: \"They are just being chosen for ensuring the appearance of (2π)⁴δ⁴(0) in the background polarization tensor.\" This justification is physically unsound. The (2π)⁴δ⁴(0) factor arises naturally from spacetime integration due to translation invariance. The phases in cˢ and dˢ describe the quantum state of the background fermions and should be determined by physical conditions, not by a mathematical convenience to obtain a factor that would appear regardless. This arbitrary setting of phases could improperly constrain the background state and affect derived results."
      },
      {
        "Problem": "Contradictory Assumptions Regarding Static vs. Dynamic Background Plasma",
        "Location": "Page 12 (Assumption 2: \"plasma is assumed in static state\") and Page 18 (Remark 1: \"one can not just replace N₀(t,p)... by the static approximate average values... The strong variation... must be taken into account.\")",
        "Explanation": "The derivation of the polarization tensor and subsequent dispersion relations explicitly assumes a static plasma (N(t,q) = N(q), j(t,q) = 0) on page 12. However, in the concluding remarks on page 18, the authors state that for strong radiation cases (a key interest of the paper), one *cannot* use static average values for background quantities like N₀(t,p), and that their \"strong variation ... must be taken into account.\" This is a direct contradiction. If strong variations are essential for the relevant physical scenarios, then the calculations based on the static assumption are not applicable to those very situations, rendering the applicability of the derived results to strongly interacting systems unclear."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 6046,
      "output": 1079
    }
  },
  {
    "entry_id": 235,
    "retraction_id": "2212.07368v2",
    "paper_id": "2212.07368v1",
    "retraction_comment": "There is an error in the use of Corollary 1 in our Paper, which does not apply in our case",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Critical dependence on accurate estimation of K_sum (number of distinct spectral components)",
        "Location": "Section II.B, Theorem 1 (Page 3), Section IV Step 1 (Page 4), Algorithm 1 (Page 5)",
        "Explanation": "The theoretical framework for unique recovery (Theorem 1) and the practical algorithm (Algorithm 1) fundamentally rely on the true number of distinct frequency components K_sum in the summed signal to construct the correct regression matrix A. The paper does not adequately address the challenge of robustly estimating K_sum (a difficult model order selection problem for line spectral estimation methods like Prony's) from noisy data, nor does it analyze the severe consequences of K_sum misestimation. An incorrect K_sum leads to a structurally incorrect A_hat (wrong number of columns), which undermines the subsequent unlabeled sensing step and can invalidate recovery claims, regardless of N satisfying N >= 2K_sum_hat."
      },
      {
        "Problem": "Algorithmic limitation due to fixed, potentially inaccurate, regression matrix A_hat during iterative refinement",
        "Location": "Algorithm 1, lines 2-4 versus lines 5-9 (Page 5)",
        "Explanation": "In Algorithm 1, the regression matrix A_hat (derived from the estimated signal support U_hat) is computed once at the beginning and then held fixed throughout the iterative updates of the permutation vector q and signal coefficients beta. If this initial A_hat is inaccurate (due to noise in support estimation, or an incorrect K_sum), all subsequent iterations operate with this flawed matrix. The algorithm lacks a mechanism to refine A_hat based on improved estimates of q or beta, making it highly sensitive to the quality of the initial support estimation and potentially leading to suboptimal solutions."
      },
      {
        "Problem": "Fragility of support estimation from summed signals when individual signals have disparate strengths or noise levels",
        "Location": "Section IV, Step 1 (Page 4, paragraph 'Step 1 - Estimating Support')",
        "Explanation": "Step 1 of the proposed method estimates the common signal support (parameters for U_hat, which forms A_hat) from the sum of all observed channels (y_sum_tilde). If the original signals (x_m) have significantly different strengths, or if some channels are much noisier than others, the spectral components of weaker or relatively noisier signals can be masked or lost in the sum y_sum_tilde. Consequently, the estimated U_hat might not adequately represent the basis for these obscured signals, making their correct reconstruction and the correct permutation assignment for their samples impossible in Step 2."
      },
      {
        "Problem": "Overstatement of robustness to errors from estimated support in experimental results",
        "Location": "Page 7, 'Known versus Estimated Support' section, discussion of Figure 5",
        "Explanation": "The paper claims that the performance degradation due to using estimated support (A_hat) instead of known support (A) is 'in fact very small' (Page 7), attributing this to the robustness of the MM-estimator. However, the experimental results presented in Figure 5 show a noticeable drop in Weighted Accuracy (WA) and a significant increase (e.g., by one or more orders of magnitude in nMSE for some scenarios) when support is estimated. This discrepancy suggests an overstatement of the MM-estimator's ability to fully compensate for errors in A_hat from Step 1, potentially misleading readers about the practical impact of these estimation errors."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 9897,
      "output": 772
    }
  },
  {
    "entry_id": 236,
    "retraction_id": "1104.1920v2",
    "paper_id": "1104.1920v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 42, 50, 51",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent handling of initial source correlation (α²) between Reverse Reconciliation (RR) and Direct Reconciliation (DR) bounds.",
        "Location": "Comparison of Page 15 (RR bounds independence of α²) and formulas in Section III (e.g. Eq 34, 40, 41 lacking α²) with Page 23 (DR bounds dependence on α²) and formulas in Appendix (e.g. Eq 47, 49-51 containing α²). Also, concluding remarks on Page 19.",
        "Explanation": "The paper claims that its new bounds for Reverse Reconciliation (RR) in Section III are independent of the initial source correlation/mixedness parameter α² (effectively assuming a pure source with α²=1). This is justified by stating these bounds are identical to those for a maximally entangled case. However, the bounds derived in the Appendix for Direct Reconciliation (DR), using ostensibly the same formalism, explicitly depend on the actual α² of the source. This is a critical inconsistency. The physical source and Eve's interaction are the same for both RR and DR. If the security principle for RR allows assuming α²=1 (attributing source mixedness to Eve) to obtain the tightest secure key rate, the same principle should apply to DR. Conversely, if DR correctly accounts for actual source mixedness (α² > 1), then RR bounds should also reflect this, and the Section III RR bounds would not be general for any α² but specific to α²=1, potentially overestimating security if the actual source has α² > 1 and this mixedness is exploitable beyond the α²=1 case."
      },
      {
        "Problem": "Restriction to phase-insensitive Gaussian attacks while claiming generality.",
        "Location": "Page 10, Eq (21) and its justification (C=Y=0 from Iwasawa decomposition); Page 13, assumption 'Tx=Tp=T and χx=χp=χline'.",
        "Explanation": "The derivation of the 'optimal bounds' in Section III (and the Appendix) relies on the assumption that Eve's symplectic transformation S is phase-insensitive. This is explicitly stated by setting S=diag(Sx,Sp) (Eq 21), which implies that the off-diagonal blocks C and Y in the general Iwasawa decomposition (Eq 20) are zero, and further by assuming identical transmission and noise for X and P quadratures (Tx=Tp, χx=χp). While this is characteristic of some channels like fiber optics, it restricts the generality of Eve's attack. A security proof against 'all possible collective Gaussian attacks' (as claimed on page 9) should consider general Gaussian unitaries, including phase-sensitive ones, unless it is rigorously proven that these reduce to the phase-insensitive case for the Holevo bound under all relevant conditions. The paper does not provide sufficient justification for this restriction covering all general Gaussian attacks."
      },
      {
        "Problem": "Flawed reasoning for the 'non-tightness' of previous bounds, which motivates the new bounds.",
        "Location": "Page 9, paragraph starting 'It is clear that the Holevo bound...'.",
        "Explanation": "The paper argues on page 9 that the bounds from Section II (based on Eve purifying ρ_AB) are 'not tight'. The reasoning is that Eve's Holevo information (XBE) is non-zero if the source is imperfect (e.g., characterized by α² > 1, indicating mixedness or non-maximal entanglement) even with a perfect channel (T=1, no channel-induced noise). The paper states this 'disagree[s] with our initial assumption... any attempt of intercepting the quantum channel by Eve will obviously induce some noises into the channel.' This reasoning is flawed. If the source itself is imperfect, Eve can legitimately gain information from this source imperfection without interacting with or inducing noise in the quantum channel. A non-zero XBE in such a scenario reflects actual information available to Eve due to the source characteristics, not necessarily a flaw in the bound formalism making it 'not tight'. While the new bounds presented in Section III might indeed be tighter due to established extremality arguments in CVQKD security (e.g., assuming an effective α²=1 for RR), the specific motivation provided on page 9 for the 'non-tightness' of prior bounds is based on a misunderstanding of how information leakage from imperfect sources is accounted for."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 14402,
      "output": 967
    }
  },
  {
    "entry_id": 237,
    "retraction_id": "1406.6450v2",
    "paper_id": "1406.6450v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a gap in the inequality of (2.7)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of Wa and its claimed Berger measure ξa.",
        "Location": "Page 4, Eq (1.5) and Figure 1(ii); Page 7, Proof of Theorem 1.1 (i), statement regarding ξa and Eq (2.4).",
        "Explanation": "The weights an for the operator Wa defined in Eq (1.5) (a0=1/2, an=sqrt((2n+1)/(2n+2)) for n>=1) are inconsistent with the weights αn0 shown in Figure 1(ii) (α00=1/2, α10=sqrt(5/4), α20=sqrt(7/6)) for n>=1. Furthermore, the Wa defined by (1.5) is claimed on page 7 to be subnormal with Berger measure ξa = (1/3)δ0 + (1/6)δ1/2 + (1/2)δ1. However, the moments γk(Wa) calculated from weights (1.5) (e.g., γ1=1/4, γ2=3/16) do not match the moments calculated from ξa (e.g., m1=7/12, m2=13/24). The formula for γℓ(Wa) in Eq (2.4) is also inconsistent with both. This foundational inconsistency undermines all subsequent results that rely on Wa, ξa, or γℓ(Wa)."
      },
      {
        "Problem": "Incorrect hyponormality condition for the pair (T1,T2).",
        "Location": "Page 8, statement before (ii); Page 7, M(k1,0) definition.",
        "Explanation": "The paper claims (T1,T2) is hyponormal if and only if 0 < ε ≤ 1/2. Hyponormality requires the matrix M(k1,0) (defined in Lemma 2.1 and implicitly on page 7) to be positive semi-definite for all k1 ≥ 0. A direct calculation of det(M(0,0)) using the paper's definitions for T1 (Eq 1.5 for αn0=an), T2 (0th vertical slice Wb with weights sqrt(ε), a1, a2,...), and commutativity to determine other necessary weights (e.g., α01=a1, β10=sqrt(3ε), β01=a1), yields det(M(0,0)) = (3/32)ε(1-4ε). For this to be non-negative (with ε>0), it implies ε ≤ 1/4. This contradicts the paper's claimed range ε ≤ 1/2. If hyponormality only holds for ε ≤ 1/4, the main counterexample (e.g., for ε=5/12) would involve a non-hyponormal pair, invalidating the paper's conclusion regarding Lubin's question for hyponormal pairs."
      },
      {
        "Problem": "Unsound derivation of the subnormality condition for T1+T2.",
        "Location": "Page 9, Eq (2.9), (2.10), (2.12) and the condition ε ≤ 5/12.",
        "Explanation": "The derivation of the condition 0 < ε ≤ 5/12 for the subnormality of T1+T2 relies on Agler's criterion and specifically on the calculation of Pn. The formula for ||((T1+T2)/2)^ℓ e(0,0)||^2 in Eq (2.9), and consequently Pn in Eq (2.10) and (2.12), explicitly uses the expression γℓ(Wa) = (1/3)(1/2)^ℓ + 2/3. As established in Problem 1, this expression for γℓ(Wa) is incorrect for the defined Wa. Therefore, the entire calculation of Pn and the resulting condition ε ≤ 5/12 are based on an erroneous premise, making the conclusion unsound."
      },
      {
        "Problem": "Inconsistent Berger measure claimed for the restricted shift Wa|L1.",
        "Location": "Page 10, statement before eq (2.17) regarding (ξa)L1.",
        "Explanation": "In proving Theorem 1.1(iii), the paper states that the Berger measure of Wa|L1 (i.e., shift(a1, a2, ...)) is (ξa)L1 = (1/3)δ0 + (2/3)δ1. However, if Wa has the Berger measure ξa = (1/3)δ0 + (1/6)δ1/2 + (1/2)δ1 (as claimed on p. 7), its first moment is m1(Wa) = 7/12 and its second moment is m2(Wa) = 13/24. According to standard theory (e.g., Eq 1.3, normalized), the Berger measure of Wa|L1 should be (s/m1(Wa))dξa(s). The first moment of this measure for Wa|L1 would be m1(Wa|L1) = m2(Wa)/m1(Wa) = (13/24)/(7/12) = 13/14. The first moment of the claimed (ξa)L1 = (1/3)δ0 + (2/3)δ1 is 2/3. Since 13/14 ≠ 2/3, the claimed Berger measure for Wa|L1 is inconsistent with the primary claimed measure ξa for Wa. This invalidates the subsequent calculations for (μM)^Y_ext and the derivation of the condition ε ≤ 3/8 for (T1,T2) subnormality."
      },
      {
        "Problem": "Questionable derivation of T2 subnormality condition.",
        "Location": "Page 7, derivation of 'T2 is subnormal ... <=> 0 < ε ≤ 1/2'.",
        "Explanation": "The paper concludes that T2 is subnormal if and only if 0 < ε ≤ 1/2. The 0th vertical slice of T2 is Wb = shift(sqrt(ε), a1, a2, ...). For Wb to be subnormal, sqrt(ε)^2 must be less than or equal to (||1/s||_L1(ξ_Wa|L1))^-1, where ξ_Wa|L1 is the Berger measure of shift(a1, a2, ...). Using the paper's claimed ξa for Wa (from page 7) and the formula for the measure of Wa|L1 (normalized version of (1.3) or (2.5)), this leads to ε ≤ 7/12, not ε ≤ 1/2. The paper's justification for ε ≤ 1/2 relies on a 'Note' with formulas for β(i,0) and ||1/t||_L1((ξa)Li) that are not clearly derived from the primary definitions of T1, T2, and ξa, and seem inconsistent with the definition of Wb."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 13412,
      "output": 1631
    }
  },
  {
    "entry_id": 238,
    "retraction_id": "1510.05979v4",
    "paper_id": "1510.05979v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (39)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Force Law Between Discrete and Continuous Systems",
        "Location": "Eq (1) on page 3, and Eq (37) on page 11",
        "Explanation": "The N-body problem defined in Section 1.1 (Eq (1)) uses a force law of the form  m_i q̈_i = sum_{j!=i} σ m_i m_j (q_i - q_j) / ||q_i - q_j||^(2+σ), which is repulsive. The paper claims (page 3) that for σ=1, this yields the Newtonian n-body problem, which is incorrect as Newtonian gravity is attractive. In contrast, Section 3 introduces a specific force φ(u) = -σ u / ||u||^(2+σ) (Eq 37) for the continuous system, which is attractive. The continuous equation of motion (39) and subsequent analysis are based on this attractive force. This fundamental inconsistency in the force law (repulsive for discrete, attractive for continuous) is unacknowledged and undermines the paper's goal of studying continuous choreographies as limits of the initially defined n-body problem."
      },
      {
        "Problem": "Incorrect Action Functional Leading to Euler-Lagrange Mismatch",
        "Location": "Eq (39) and Eq (40) on page 11",
        "Explanation": "The paper states that Eq (39) (v^2 y''(s) = -σ ∫ (y(s)-y(s')) / ||y(s)-y(s')||^(2+σ) ds') is the Euler-Lagrange equation for the action functional A^σ(y) given in Eq (40) (A^σ(y) = ∫_0^1 [ (v^2/2) ||y'(s)||^2 + ∫_0^1 ds' / ||y(s)-y(s')||^σ ] ds). However, the potential energy term in an action functional derived from pairwise interactions Φ(y(s)-y(s')) typically includes a factor of 1/2 (i.e., (1/2)∫∫ Φ ds'ds) to avoid double counting. The potential Φ corresponding to the force in Eq (39) is -1/||y(s)-y(s')||^σ. Thus, the potential energy part of the action should be (1/2)∫∫ (-1/||y(s)-y(s')||^σ) ds'ds if φ = -DΦ. The functional S(y) in Eq (30) has this 1/2 factor. The functional A^σ(y) in Eq (40) uses +∫∫ 1/||y(s)-y(s')||^σ ds'ds (without the 1/2 factor). If Φ(w) = 1/||w||^σ, then -DΦ(w) = σ w/||w||^(σ+2). The Euler-Lagrange equation for A^σ(y) as written in (40) would be v^2 y''(s) = 2σ ∫ (y(s)-y(s'))/||y(s)-y(s')||^(σ+2) ds', which differs from Eq (39) by a factor of -2. This inconsistency means that A^σ(y) in (40) is not the correct action functional for Eq (39)."
      },
      {
        "Problem": "Invalid Simplification of the Action Functional",
        "Location": "Eq (40) to Eq (43) on page 11",
        "Explanation": "The paper simplifies the action functional A^σ(y). The potential energy term in Eq (40) is V(y) = ∫_0^1 [ ∫_0^1 ds' / ||y(s)-y(s')||^σ ] ds. This is simplified in Eq (43) to V_simplified(y) = ∫_0^1 ds / ||y(s)-y(0)||^σ. This simplification, which effectively replaces the sum of interactions between all pairs of points on the curve with an interaction of each point y(s) with a fixed point y(0), is generally incorrect for an arbitrary periodic function y(s) in the space Λ. The derivation steps (41) and (42) do not justify this reduction. Consequently, the existence proof (Theorem 3.1) and the stability analysis of the circular solution (Proposition 3.3), which are based on minimizing or analyzing this simplified (and incorrect) functional (43), are unsound."
      }
    ],
    "token_usage": {
      "input": 4768,
      "thinking": 13907,
      "output": 1038
    }
  },
  {
    "entry_id": 239,
    "retraction_id": "1202.0569v2",
    "paper_id": "1202.0569v1",
    "retraction_comment": "Due to a flaw in Lemma 9, the paper has been withdrawn",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lemma 5 is false, and its proof is flawed.",
        "Location": "Page 5, Lemma 5",
        "Explanation": "Lemma 5 states: 'We have that |U| ≥ 2 for all non-empty U ∈ U.' (U is a class of vertices from V(C) belonging to the same connected component of G - E(C)). This lemma is false. Consider a graph G formed by a 4-cycle C = (v1, v2, v3, v4, v1) where vertex v1 is also part of a K3 (triangle) {v1, v5, v6, v1}, and the K3's edges are not in E(C). This graph G is bridge-free. The circulation is C. The components of G - E(C) are H_v1 = ({v1,v5,v6}, {(v1,v5),(v5,v6),(v6,v1)}) and H_v2={v2}, H_v3={v3}, H_v4={v4}. The class U corresponding to H_v1 is {v1}, so |U|=1. This contradicts the lemma. The proof of Lemma 5 assumes that if |U|=1 for a class U containing vertex u, then there is 'exactly one edge e=uv with v ∈ H(u)'. This premise is not generally true (in the counterexample, u=v1 has two edges (v1,v5) and (v1,v6) in H(v1)). The subsequent deduction that 'e is a bridge in G' relies on this flawed premise or an incomplete case analysis."
      },
      {
        "Problem": "The algorithm in Lemma 6 is not guaranteed to execute correctly due to its reliance on the false Lemma 5.",
        "Location": "Page 7, Lemma 6, Step 3 and its justification",
        "Explanation": "Step 3 of the algorithm in Lemma 6 requires finding an alternating path starting from a vertex v1 ∈ U1 with type(v1)=0 (i.e., v1 is unmatched in M). The paper argues (page 7, paragraph after Step 6): 'In Step 3, U1 and Ul+1, having degree 1 with respect to M, contain at least one vertex of type 0, respectively, by Lemma 5.' If Lemma 5 is false, it is possible that |U1|=1. If U1={u1} and deg_M(U1)=1, then u1 must be matched by M, meaning type(u1) is +1 or -1, not 0. Thus, a starting vertex of type 0 as required by Step 3 may not exist in U1 (or Ul+1). This makes Step 3, and consequently the entire algorithm of Lemma 6, potentially unexecutable."
      },
      {
        "Problem": "The proof of Lemma 9, specifically the argument that the constructed set A' is C-augmenting for the original graph G and circulation C, is unsound.",
        "Location": "Page 11, Proof of Lemma 9, paragraph starting 'Now, the set A' = ...'",
        "Explanation": "Lemma 9 aims to construct a C-augmenting set A' such that G-A' is bridge-free. The proof involves an iterative algorithm. The argument that the final set A' = (A_0 ∪ ... ∪ A_i) ∩ E(C) is C-augmenting for the original G and C relies on a series of equations at the end of the proof. This derivation, particularly the step ((E(G) \\ (A_0 ∪ ... ∪ A_i)) ∩ E(C)) \\ (E(C_i') ∪ A_i) and its subsequent simplification to E(C) \\ (A_0 ∪ ... ∪ A_i ∪ E(C_i')) = ∅, appears to conflate different graphs and circulations (e.g., G with G_i, C with C_i) or make unjustified assumptions about the relationships between these sets. The final condition E(C) ⊆ (A_0 ∪ ... ∪ A_i) ∪ E(C_i') does not directly imply that A' is C-augmenting (i.e., E(C) \\ A' ⊆ E(C_i')) without further, clearer justification. The provided argument is insufficient to establish that A' is C-augmenting for the original C."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 14728,
      "output": 1013
    }
  },
  {
    "entry_id": 240,
    "retraction_id": "2111.02352v2",
    "paper_id": "2111.02352v1",
    "retraction_comment": "The previous to the last sentence of Section 4, namely that \"This means that $\\hat{Q}$ and, by Lemma 6, $\\hat{Q}$ too, is less than 1.\" is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent coefficients in the Ordinary Generating Function (OGF) analysis.",
        "Location": "Equation (11) versus Equations (12) and (13) (Page 10).",
        "Explanation": "The recurrence relation for Rn given in Equation (11) implies coefficients for the OGF R(z) that are different from those used to define φ(x) in Equation (13) (which is based on Equation (12)). Specifically, the coefficient for the R(z)^2 term derived from (11) would be (∆^(8/3)/(8α))q^2, while Eq. (12) implies it is 1/(8αq^3) (as used in φ(x)). Similarly, for the R(z)^4 term, (11) implies ∆^5q^4, while (12) implies 1/(∆^(1/3)q^4). These sets of coefficients are not equivalent. Since the subsequent singularity analysis (Eq. 14-16) relies on φ(x) from Eq. (13), this discrepancy invalidates that analysis if Eq. (11) correctly represents the combinatorial sum."
      },
      {
        "Problem": "Incorrect algebraic step in deriving the condition on α.",
        "Location": "Page 11, derivation of inequality (16) from φ'(τ) < 1.",
        "Explanation": "When evaluating the condition φ'(τ) < 1 for ∆ → +∞, the paper arrives at an intermediate inequality equivalent to 1/sqrt(2αq^3) < 1 (using the paper's φ(x) from Eq. 13 and its τ_limit = sqrt(8αq^3)). The paper then incorrectly transforms this into '1 / (2^(1/2) α^(3/2)) < 1'. This step implicitly and incorrectly assumes q^3 = α^(-2). The actual substitution q ≈ 1/(α∆^(4/3)) into 1/sqrt(2αq^3) < 1 would lead to 1 < 2α / (α^3 ∆^4), which simplifies to α^2 ∆^4 < 2. This is a contradiction for large ∆, meaning the claimed range α > 2^(-1/3) is not supported by this derivation path."
      },
      {
        "Problem": "Insufficient proof for Lemma 2 regarding α-specially proper coloring.",
        "Location": "Page 4 (Lemma 2) and Page 5 (Proof of Lemma 2).",
        "Explanation": "Lemma 2 states that a random coloring with K = [α∆^(4/3)]+∆+1 colors is α-specially proper with positive probability. The provided proof only argues that for a single vertex u, there is a positive probability of finding a suitable color given the colors of its neighbors and special pairs. It does not provide a rigorous argument (e.g., using the Lovász Local Lemma or a union bound over all constraints) that *all* such conditions for *all* vertices are simultaneously satisfied with positive probability. This lemma is crucial for Fact 2 (page 7), which states that the probability Q (MOSERALG halts but coloring is not α-specially proper) is bounded away from 1, a key component for the MAINALGORITHM's success."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 16415,
      "output": 746
    }
  },
  {
    "entry_id": 241,
    "retraction_id": "2207.08480v2",
    "paper_id": "2207.08480v1",
    "retraction_comment": "Errors in the method to determine the S-transformation coefficients, because the characters for the surfaces are not simply the product of characters for cylinders. Errors in the linear spaces assigned to surfaces in string vertices this http URL concrete definition for open sector linear spaces also required",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Highly restrictive condition for applicability (η = N)",
        "Location": "Page 3 (initial statement), Page 15 (Eq. 38)",
        "Explanation": "The framework's applicability hinges on the condition that open sector representation coefficients (η) are identical to closed sector fusion coefficients (N), as stated in Eq. (38): η_μ3μ1^w(P2) = N_P1P2^P3. This condition is crucial for establishing the isomorphism between closed and open sector linear spaces (Eq. 43), which is foundational for the entire S-transformation definition. While noted for diagonal RCFTs, the general validity of this strong condition for other CFT classes (like Liouville theory, which the paper hopes to apply to) is not established, potentially severely limiting the proposed framework's scope."
      },
      {
        "Problem": "Insufficient justification for curvature localization",
        "Location": "Page 9 (Eq. 20, surrounding text), Page 11 (Eq. 26)",
        "Explanation": "The paper claims that Gaussian curvature (K) becomes localized as delta functions at the singularities (zeros/poles/branch points) of the time-evolution generating vector fields f(z) or v(z) (Eqs. 20, 26). The justification provided – 'We expect the index theorem to be equivalent to the Gauss-Bonnet theorem, which means that the curvature on the surfaces are localized...' – is insufficient and lacks rigor. A clear derivation of how these specific vector fields induce such localized delta-function curvature on an initially (presumably) smooth manifold is missing."
      },
      {
        "Problem": "Schematic and insufficiently rigorous reduction to conventional S-matrix",
        "Location": "Section 3.3.2 (Pages 20-22, Eqs. 69-72)",
        "Explanation": "The derivation attempting to connect the paper's S-transformation coefficients (C_Pμ) to the conventional modular S-matrix (S_PP') is schematic. Equation (69) introduces fitting coefficients A_μ1(1) and A_μ1μ2(2) without a clear first-principles derivation from the paper's core definitions. The subsequent claim that S_PP' and C_Pμ can be 'read off' (Eqs. 70-72) is not adequately substantiated, making the crucial link between this new formalism and established CFT results tenuous."
      },
      {
        "Problem": "Reliance on unproven statements in sewing formalism",
        "Location": "Page 27 (Eqs. 96, 97 and their use for Eq. 95)",
        "Explanation": "Key conclusions in the discussion of separating sewing for open sectors, particularly those leading to Eq. (95) and the subsequent assertion that open sector representation coefficients form a matrix representation of fusion algebra, rely on relations (Eqs. 96 and 97) that are explicitly stated in the paper as 'unproven'. Deriving significant results from unproven assumptions constitutes a critical gap in the argument's soundness."
      },
      {
        "Problem": "Assumption of S-transformation factorization in sewing",
        "Location": "Page 24 (Eq. 83, and its use in Eq. 84 to derive Eq. 86)",
        "Explanation": "The derivation of the composition rule for S-transformation coefficients under sewing (Eq. 86) relies on an assumed factorization property of the S-transformation acting on tensor products of linear spaces: S[A_i tensor_P A_j] = S[A_i] tensor_P S[A_j] (Eq. 83, used in Eq. 84). This type of factorization is not generally true for linear maps on tensor product spaces and is presented as an assumption without justification within the paper's framework, weakening the derivation of Eq. (86)."
      }
    ],
    "token_usage": {
      "input": 11476,
      "thinking": 5758,
      "output": 878
    }
  },
  {
    "entry_id": 242,
    "retraction_id": "2302.04323v3",
    "paper_id": "2302.04323v2",
    "retraction_comment": "The first statement on page 9 is not necessarily true. Roughly speaking, the problem is that the indices \"i_s\" and \"r\" are competing with each other and therefore what I believed to be immediate, as happens naturally in the case of a single index, and as can be seen in the proof of Theorem 6.7 of the FHHMZ reference, is in fact not immediate in the situation where double indices are involved",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Major overstatement of novelty for Corollary 3.10 / Theorem 3.10 regarding the Fixed Point Property (FPP) for super-reflexive spaces.",
        "Location": "Abstract; Page 12, Theorem 3.10 and its discussion.",
        "Explanation": "The paper claims in the abstract that 'we deduce that every super-reflexive space has the fixed point property thus solving a long-standing open question in metric fixed point theory.' Theorem 3.10 states this result. However, this problem appears to have been solved by P. N. Dowling, C. J. Lennard, and B. Turett in their 2000 paper 'The fixed point property for superreflexive Banach spaces' (J. Math. Anal. Appl. 251(2), 690-696). If this prior work is indeed correct and established, the current paper's claim of solving this long-standing question would be inaccurate, significantly affecting the perceived impact and novelty of this specific corollary."
      },
      {
        "Problem": "The proof that the set M is empty, crucial for the Main Theorem (Theorem 3.7), is flawed, particularly for the case when the EAB constant lambda = 1.",
        "Location": "Page 7, derivation of sup ||[vi]|| for [vi] in M.",
        "Explanation": "The proof aims to show M is empty by deriving sup_{[vi] in M} ||[vi]|| < 1, which contradicts Lemma 2.2 (assuming 0 in K and diam K = 1). The paper's derivation yields sup ||[vi]|| <= (1+lambda)d + 1/2. Using the condition (3.2) for d, i.e., d < (2-lambda)/(2(1+lambda)), this leads to sup ||[vi]|| < (1+lambda) * (2-lambda)/(2(1+lambda)) + 1/2 = (2-lambda)/2 + 1/2 = 3/2 - lambda/2. For this to be strictly less than 1 (needed for the contradiction), it requires 3/2 - lambda/2 < 1, which implies lambda > 1. However, if lambda = 1 (a key case, as Z=C[0,1] with lambda=1 is used in Theorem 3.9), the derivation only yields sup ||[vi]|| <= 1. This is not a strict inequality and thus does not ensure M is empty by contradiction with Lemma 2.2 (which would give sup ||[vi]|| = 1). This flaw makes the proof of the Main Theorem, and consequently Theorem 3.9, unsound for lambda=1."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 20875,
      "output": 617
    }
  },
  {
    "entry_id": 243,
    "retraction_id": "1911.03748v2",
    "paper_id": "1911.03748v1",
    "retraction_comment": "Unfortunately, our proof contains a serious flaw. Specifically, Lemma 5.3 does not prove the assertion it claims to prove and this collapses the entire argument. We thank [REDACTED-NAME] for pointing out the flaw, and apologize to the community for posting an eventually incorrect proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect epsilon handling in the proof of Theorem 6.2 (restatement of Theorem 1.6(2))",
        "Location": "Page 15, Proof of Theorem 6.2",
        "Explanation": "Theorem 6.2 states an approximation in L2-squared norm: ||f-g||_2^2 <= eps. The proof combines Proposition 4.5 and Lemma 6.1. These propositions provide approximations in L2 norm (e.g., ||f-f'||_2 <= eps_intermediate). To achieve a final L2-squared error of `eps_final`, one needs an L2-norm error of sqrt(eps_final). Thus, Prop 4.5 and Lemma 6.1 should be invoked with L2-norm error budgets related to sqrt(eps) (where `eps` is the L2-squared error from Thm 6.2's statement), for example, sqrt(eps)/2 for each. However, the proof on page 15 states that Prop 4.5 is used to find f' with ||f-f'||_2 <= eps/4, and Lemma 6.1 for g with ||f'-g||_2 <= eps/4. This incorrectly uses `eps` (the L2-squared budget) as an L2-norm budget. This error affects the derivation of the decision tree depth. If correctly handled, the depth dependency on `eps` (the L2-squared error) would be poly(d, 1/sqrt(eps)), not poly(d, 1/eps) as claimed by the text interpreting the result of Lemma 6.1 with log(|T|) term where |T| depends on 1/eps_L2_norm^p. The final claimed depth poly(d, 1/eps) in Theorem 6.2 (where eps is L2-squared error) is not rigorously supported by this erroneous epsilon management."
      },
      {
        "Problem": "Flawed proof of Proposition 4.5 (Approximation by a low-degree junta)",
        "Location": "Page 10, Proof of Proposition 4.5",
        "Explanation": "The provided proof sketch for Proposition 4.5, which asserts that a degree-d function f can be approximated in L2 norm by a junta f' depending on 2^{O(d)}/eps^2 variables, contains unsound steps. Specifically, the inequality `||T_{1/sqrt(3)} f''||_2 <= sum_{i not in T} ||D_i T_{1/sqrt(3)} f''||_2` is incorrect; a norm is generally not bounded by the sum of norms of its derivatives in this manner. A correct approach would typically involve Poincare's inequality (||g||_2^2 <= E[g]^2 + sum_i ||D_i g||_2^2). Applying Poincare and Lemma 4.4 correctly would lead to ||T_{1/sqrt(3)}f''||_2^2 <= (d^2/sqrt(3)) * sqrt(max_{i not in T} I_i(f'')). This, combined with ||f''||_2^2 <= K^2 ||T_{1/sqrt(3}}f''||_2^2 (where K is likely 3^{d/2}), results in a junta size |T| depending on eps_L2_norm^(-4), rather than eps_L2_norm^(-2) as implied by the proposition's statement (2^{O(d)}/eps^2, where eps is L2 norm error). While the proposition itself is a known type of result (the paper cites [16]), the given proof is flawed and does not correctly establish the stated parameters."
      },
      {
        "Problem": "Inconsistent definition of error 'eps' between Theorem 1.6(2) and its restatement Theorem 6.2",
        "Location": "Page 4 (Theorem 1.6(2)) and Page 14 (Theorem 6.2)",
        "Explanation": "Theorem 1.6(2) states that for any eps > 0, there exists a decision tree g such that `||f - g|| <= eps`. This typically denotes the L2 norm: (E[(f-g)^2])^{1/2} <= eps. However, Theorem 6.2, explicitly called a 'Restatement of Theorem 1.6(2)', states `||f - g||_2^2 <= eps`. This is the L2-squared norm. These represent different error magnitudes: an L2 error of `eps` corresponds to an L2-squared error of `eps^2`. This inconsistency affects how the polynomial depth `poly(d,1/eps)` should be interpreted and derived. If `eps` in Theorem 1.6(2) is L2-norm error, then the depth is `poly(d, 1/eps_L2)`. If `eps` in Theorem 6.2 is L2-squared error, then the depth should be `poly(d, 1/sqrt(eps_L2_sq))`. The proof of Theorem 6.2 attempts to establish depth `poly(d, 1/eps_L2_sq)`, which is a stronger claim if `eps_L2_sq` is small, but as noted in Problem 1, this derivation has flaws."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 21391,
      "output": 1201
    }
  },
  {
    "entry_id": 244,
    "retraction_id": "2212.12846v2",
    "paper_id": "2212.12846v1",
    "retraction_comment": "We found an error in Lemma 3.5.--which is used in the subsequent analysis to establish the rate of convergence. Since the error is not fixable, we would like to withdraw the article",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Discrepancy and error in claimed convergence rate.",
        "Location": "Abstract (page 1), Introduction (page 1, section 1), Theorem 2.4 (page 6), and Proof of Main Theorem (page 29-31, particularly equation (4.24), the parameter choice on page 31, and the subsequent conclusion).",
        "Explanation": "The paper's main conclusion about the convergence rate of the finite difference scheme is not sound due to issues in the parameter optimization at the end of the proof. Specifically:\n1. The abstract, introduction, and Main Theorem (Theorem 2.4) claim a convergence rate of O((∆x)^(1/2)).\n2. The derived error estimate before parameter optimization (e.g., equation (4.24) on page 29, or (4.27) on page 30) contains several terms dependent on auxiliary parameters ε, ξ, and δ.\n3. The specific choice of parameters on page 31 (ε = (∆y)^(1/2), ξ = (∆y)^(1/4), δ = (∆y)^(1/4)) leads to at least one error term being O(1). For example, the term Cξ/δ becomes C((∆y)^(1/4))/((∆y)^(1/4)) = C, which does not vanish as ∆y → 0. This O(1) term means that no convergence rate is established with this choice.\n4. Consequently, the statement on page 31 that this parameter choice yields a convergence rate of O((∆y)^(1/4)) is incorrect.\n5. Even if a rate of O((∆y)^(1/4)) were correctly established for E[||u_∆y - u_ε||], when combined with the error E[||u_ε - u||] ≤ C√ε = C((∆y)^(1/2))^(1/2) = C(∆y)^(1/4), the final convergence rate for E[||u_∆y - u||] would be O((∆y)^(1/4)), which still contradicts the claimed O((∆y)^(1/2)) rate.\nThis fundamental inconsistency invalidates the paper's main quantitative result on the rate of convergence."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 17085,
      "output": 510
    }
  }
]