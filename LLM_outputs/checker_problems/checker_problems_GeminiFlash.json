[
  {
    "entry_id": 0,
    "retraction_id": "2303.17613v10",
    "paper_id": "2303.17613v9",
    "retraction_comment": "The theoretical structure, in particular the existence of the Riemannian metric, was flawed and will be resubmitted after reconsideration",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of Log map and gradient of squared distance in signature space.",
        "Location": "Appendix A.6, Eq (A.40), Eq (A.42), Section 2.4, Section 2.7, Section 3.3",
        "Explanation": "The derivation of the Log map for signature space in Appendix A.6 appears incorrect, specifically the step dL_a v = av. This invalidates the subsequent formula for the gradient of the squared distance (A.42) and the Karcher mean condition (Eq 8), which are central to the algorithms for computing the group mean and PGA modes."
      },
      {
        "Problem": "Unjustified gradient descent update rule for PGA modes.",
        "Location": "Section 3.3, Eq (23)",
        "Explanation": "The iterative update rule for the principal geodesic direction v (Eq 23) is complex and its derivation or justification is not provided. It deviates from standard gradient descent forms and its correctness in minimizing the objective function (Eq 19) is not established, potentially leading to an unreliable optimization process."
      },
      {
        "Problem": "Non-standard and potentially inappropriate norm for reconstruction error.",
        "Location": "Section 4.2, Eq (32)",
        "Explanation": "The 'homogenous norm' used to define the reconstruction error is non-standard for signature space or tensor algebra. Its properties and relevance to the geometric problem or the comparison of different methods (PCA vs. PGA) are not explained, making the conclusions drawn from the reconstruction error comparison (Figure 14) potentially misleading."
      },
      {
        "Problem": "Algorithms for mean and PGA rely on flawed gradient calculations.",
        "Location": "Section 2.4, Section 2.6, Section 3.3",
        "Explanation": "The algorithms for computing the group mean (Section 2.4) and the Principal Geodesic Analysis modes (Section 2.6, 3.3) are based on finding stationary points using gradients of the squared distance or related quantities. As the derivation of these gradients appears flawed (Problem 1), the algorithms themselves are likely unsound and may not correctly compute the intended mean and modes."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 4077,
      "output": 501
    }
  },
  {
    "entry_id": 1,
    "retraction_id": "2103.13332v3",
    "paper_id": "2103.13332v1",
    "retraction_comment": "The notion of stabilizing ordinal is not well-defined, i.e., Definition 14 is flawed. As a consequence the results presented in the paper are either incorrect or remain unproved",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "False claim regarding sentences with undefined stabilizing ordinals.",
        "Location": "Page 14, Lemma 31.",
        "Explanation": "Lemma 31 claims that if the stabilizing ordinal pg(φ) is undefined for the minimal evaluation function g (g(w)=Ø), then φ is not in the interpretation of the truth predicate at any stage α ([Kα(g)](w)) for any world w. However, sentences with undefined stabilizing ordinals, such as the Liar sentence ¬Tλ or K¬Tλ, are in [K(g)](w) (the first stage of the construction), directly contradicting this lemma for α=1."
      },
      {
        "Problem": "Invalid claim that the minimal evaluation function is a prefixed point.",
        "Location": "Page 15, Lemma 19.",
        "Explanation": "Lemma 19 claims that the minimal evaluation function g (g(w)=Ø) is a prefixed point (Definition 17). Definition 17(i) requires that if pf(φ) is undefined, then φ ∉ [Kα(f)](w) for all α, w. Since pg(φ) is undefined for sentences like ¬Tλ, g being a prefixed point would require ¬Tλ ∉ [Kα(g)](w) for all α, w. As shown by evaluating ¬Tλ at stage 1, ¬Tλ ∈ [K(g)](w). Therefore, g is not a prefixed point, and Lemma 19 is false."
      },
      {
        "Problem": "Invalid proof for the existence of fixed points via KSF(g).",
        "Location": "Page 15, Proposition 20(i).",
        "Explanation": "The proof of Proposition 20(i) (existence of fixed points) relies directly on Lemma 18 (prefixed points are fixed points) and Lemma 19 (the minimal function g is a prefixed point). Since Lemma 19 is false (as it relies on the false Lemma 31), the argument that KSF(g) is a fixed point is invalid. This undermines the paper's main positive result regarding the existence of fixed points for K."
      },
      {
        "Problem": "Unsound proof for non-existence of fixed points for subjunctive conditional jump C.",
        "Location": "Page 10-11, Lemma 12.",
        "Explanation": "The proof relies on an incorrect equivalence in the interpretation of the subjunctive conditional semantics (Definition 10, clause 16, second disjunct). Specifically, the step claiming equivalence between '∃z ∈ Ww[M, z |=f λ & ∀u(u ≤w z & M, u |=f λ ⇒ M, u |=f ⊥)]' and '∃z ∈ Ww[M, z |=f λ & ∀u(u ≤w z ⇒ M, u |≠f λ)]' is false under standard assumptions about ⊥. While the conclusion that C has no fixed points might still hold, the provided proof is invalid."
      },
      {
        "Problem": "Flawed proof of non-monotonicity of K.",
        "Location": "Page 8, Lemma 9(ii).",
        "Explanation": "The proof of Lemma 9(ii) attempts to show that iterative applications of K over the minimal function g do not form an increasing sequence by demonstrating that σ ∈ [K(g)](w) but σ ∉ [K(K(g))](w) for a specific sentence σ and model M. The evaluation of σ ∉ [K(K(g))](w) appears to contain an error in applying the semantics of the K operator, specifically regarding the safety condition. Based on the semantics, it seems M, w |=K(g) Kσ is true, contradicting the claim that σ ∉ [K(K(g))](w)."
      }
    ],
    "token_usage": {
      "input": 6832,
      "thinking": 16294,
      "output": 864
    }
  },
  {
    "entry_id": 2,
    "retraction_id": "1602.07129v2",
    "paper_id": "1602.07129v1",
    "retraction_comment": "this paper has been withdrawn due to minor error in the calculation of dielectric constant",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of TEM-ED data regarding structural disorder",
        "Location": "Page 4, Results and Discussion, Figure 2(b)",
        "Explanation": "The text states that the 'Absence of the superlattice reflection at [1/2,1/2,1/2] in the SAD confirms the antisite disorder'. However, Figure 2(b) clearly shows a spot at the [1/2,1/2,1/2] position (encircled), which is indicative of ordering, not disorder. This contradicts the conclusion about the disordered Pm-3m structure based on TEM."
      },
      {
        "Problem": "Incorrect interpretation of AC magnetic susceptibility data regarding spin-glass behavior",
        "Location": "Page 5, Results and Discussion, Figure 3(b)",
        "Explanation": "The authors claim a 'clear absence of frequency dispersion' in the AC susceptibility data (Fig 3b) to discard spin-glass behavior. However, the peak position appears to shift slightly to higher temperatures with increasing frequency (e.g., comparing 0.3Hz and 966Hz curves), which is a characteristic signature of spin-glass or cluster-glass systems."
      },
      {
        "Problem": "Flawed or inconsistently described specific heat analysis and magnetic entropy calculation",
        "Location": "Page 5, Results and Discussion, Figure 4(a), Figure 4(b), Equations (1), (2), (3)",
        "Explanation": "The method for separating the magnetic contribution (Cmag) from the lattice contribution (Clatt) by fitting a polynomial (Eq 1) to Cp/T vs T² data in the 20-40K range is non-standard and likely inaccurate for determining Clatt up to 40K. The resulting magnetic entropy change (Smag = 0.5 J/mole-K) is significantly lower than the theoretical value (11.5 J/mole-K), leading to interpretations about suppressed moments. While a Debye fit is mentioned yielding a value closer to theoretical, the text states this fit is unphysical above 50K, creating confusion about which analysis supports the conclusions. The overall specific heat analysis and Smag calculation are questionable and impact the interpretation of the magnetic transition."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 3812,
      "output": 507
    }
  },
  {
    "entry_id": 3,
    "retraction_id": "2006.00175v4",
    "paper_id": "2006.00175v3",
    "retraction_comment": "In eq 38, misses a d^2 phi term, breaking down the results of the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Condition for Quantum Symmetry",
        "Location": "Section I, Eq. 21, 22",
        "Explanation": "The paper claims that a field transformation is a quantum symmetry if the action changes as S -> S + ∫ d⁴x ε f + ∫ d⁴x ∂μ ε Jμ. This is incorrect. For a transformation generated by a conserved charge to be a quantum symmetry, the action change under a local transformation (with ε(x)) must be a total derivative, i.e., S -> S + ∫ d⁴x ∂μ ε Jμ. The presence of the non-total derivative term ∫ d⁴x ε f generally breaks quantum symmetry unless f=0."
      },
      {
        "Problem": "Flawed Derivation of Conditions on W1 and W2",
        "Location": "Section II (Eq. 40, 41), Section IV (Eq. 59, 62), Section VI (Eq. 71, 73, 74)",
        "Explanation": "The conditions derived for the functions W1 and W2 are based on calculating the change in the action under a *global* transformation (constant ε) and equating it to a form related to quantum symmetry. However, the criterion for quantum symmetry (even the paper's own criterion) requires analyzing the action change under a *local* transformation (ε(x)). The derivation is incorrect, and the resulting conditions on W1 and W2 are not valid for establishing the claimed quantum symmetry."
      },
      {
        "Problem": "Inconsistent Application of Quantum Symmetry Criterion",
        "Location": "Section II (Eq. 39, 40), Section IV (Eq. 59), Section VI (Eq. 71)",
        "Explanation": "The paper calculates the action changes under the proposed transformations (e.g., Eq. 39, 59, 71) and claims they imply quantum symmetry based on the criterion from Section I (S -> S + ∫ d⁴x ε f + ∫ d⁴x ∂μ ε Jμ). However, the calculated changes do not clearly match this specific form, particularly the factor dL/d(∂μφ) in the first term of the claimed form (S -> S + ∫ d⁴x ε f dL/d(∂μφ) + ...). The paper does not explicitly show how the calculated changes map to the required form, making the application of its own criterion inconsistent or unclear."
      },
      {
        "Problem": "Unjustified Claim about Generator Representation",
        "Location": "Page 2, Introduction section",
        "Explanation": "The paper claims that the generators of the proposed symmetry (Eq. 4) do not belong to the (1/2, 0) representation of the Lorentz group. While the transformation is not standard supersymmetry, the transformation δφ = εψ (with ε a spinor parameter) typically implies a spinor generator. The paper does not provide a clear derivation of the generator's Lorentz representation or its algebra, beyond stating it doesn't satisfy the standard SUSY anticommutators. The claim about the representation lacks sufficient justification."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 4217,
      "output": 693
    }
  },
  {
    "entry_id": 4,
    "retraction_id": "2108.05829v5",
    "paper_id": "2108.05829v4",
    "retraction_comment": "There is a mistake in the proof. The second term of the last equation in Lemma 2.2 does not have the desired asymptotic behavior. I am grateful with [REDACTED-NAME] for pointing out this mistake",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified Non-negativity of <v, nabla_v V>",
        "Location": "Proof of the conjecture (Page 5), Lemma 2.2 (Page 4)",
        "Explanation": "The proof relies on the inequality <dot{gamma}, nabla_{dot{gamma}}V> >= 0 along the trajectory. This property is assumed to hold on the set W - V(U). However, the construction of V in Lemma 2.2 only proves the asymptotic property <v, nabla_v V> = (1+o(1))||v||^2 as x approaches x_0. This asymptotic property does not guarantee non-negativity on the entire set W - V(U), and the trajectory is not guaranteed to approach x_0."
      },
      {
        "Problem": "Reliance on Unpublished Lemma",
        "Location": "Lemma 2.1 (Page 3), References (Page 7)",
        "Explanation": "A key lemma (Lemma 2.1), crucial for the construction of the vector field V using Hironaka's monomialization, is attributed to an unpublished communication ([Sp]). This makes the proof unverifiable and unsound for a formal mathematical publication aiming to prove a major conjecture."
      },
      {
        "Problem": "Flawed Calculation in Lemma 2.2",
        "Location": "Proof of Lemma 2.2 (Page 4)",
        "Explanation": "The calculation deriving the asymptotic property of <v, nabla_v V_p> contains a step that appears mathematically incorrect (specifically, the term involving g_{ai,j}). While the final asymptotic result might potentially be true, the presented derivation is flawed, raising concerns about the rigor and correctness of the vector field construction details."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 11460,
      "output": 398
    }
  },
  {
    "entry_id": 5,
    "retraction_id": "2403.19848v2",
    "paper_id": "2403.19848v1",
    "retraction_comment": "We're withdrawing our paper from arXiv due to a critical error in our review methodology, which excluded key studies on sustainable road freight transport. This oversight could mislead the scientific community. We plan to correct this, ensuring comprehensive study inclusion, and will resubmit our paper for a more accurate review",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of a clearly defined systematic review methodology",
        "Location": "Section 2. Methodology",
        "Explanation": "The paper states it uses a 'systematic review methodology' but fails to provide essential details such as the search strategy, databases used, inclusion/exclusion criteria for selecting studies, or the process for screening and selecting relevant literature. This lack of methodological rigor makes the review's findings potentially incomplete and subject to selection bias."
      },
      {
        "Problem": "Insufficient analysis and synthesis of the reviewed literature",
        "Location": "Section 2. Methodology, Section 3. Results and discussion, Table 1",
        "Explanation": "The paper does not adequately describe how the selected studies were analyzed or synthesized to arrive at the conclusions. Table 1 provides a basic summary, but the discussion section primarily lists examples without explaining the analytical process used to identify key themes, compare findings across studies, or assess the collective evidence base."
      },
      {
        "Problem": "Unclear description of data handling and analysis from literature",
        "Location": "Page 1 (Abstract), Page 3 (Introduction), Page 4 (Methodology)",
        "Explanation": "The paper contains vague and confusing statements about using 'the same data presented by the literature' and attempting to 'visualize the study of the available data.' This suggests a potential misunderstanding of how to analyze and synthesize findings from existing research papers in a literature review context."
      },
      {
        "Problem": "Potential for selection bias due to undefined scope and criteria",
        "Location": "Section 2. Methodology, Table 1",
        "Explanation": "Without clear inclusion/exclusion criteria and a defined search scope (beyond 'indifferent dates'), it is impossible to determine if the studies included in the review, particularly those listed in Table 1, represent the breadth of relevant literature on sustainable road freight transport. This raises concerns about potential selection bias influencing the findings."
      },
      {
        "Problem": "Weak link between presented literature and broad conclusions",
        "Location": "Section 3. Results and discussion, Section 4. Conclusion",
        "Explanation": "Due to the lack of detailed analysis and synthesis, the broad conclusions drawn about the state of research, the relative development of different sustainability dimensions, and future research directions appear not to be strongly supported by a rigorous examination of the specific findings, methodologies, or limitations of the individual studies reviewed."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 2183,
      "output": 534
    }
  },
  {
    "entry_id": 6,
    "retraction_id": "2210.14117v3",
    "paper_id": "2210.14117v2",
    "retraction_comment": "Error in formulation of Bronold-Fehske model. The plots shown are actually in terms of E' + chi, shifted incorrectly by a factor of the electron affinity. The apparent perfect reflection region is therefore nonphysical",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Simulations do not reach a steady state.",
        "Location": "Page 5, Section III; Fig 9",
        "Explanation": "The paper states that the simulations do not reach a steady state due to collision-driven cooling, causing the electron flux gain (γ) to increase over time (Fig 9). The presented sheath profiles (Fig 7) and distribution functions (Fig 8) are snapshots of a transient state, not the equilibrium the system would eventually reach. This makes conclusions about the 'resulting' sheath structure and gain potentially invalid as representative of a stable physical system."
      },
      {
        "Problem": "Neglect of True Secondary Electron Emission (TSEE) and Ion-Induced Secondary Electron Emission (IISEE).",
        "Location": "Page 6, Section III (Limitations); Page 7, Section IV (Conclusion)",
        "Explanation": "The paper focuses only on low-energy elastic reflection (backscattering). However, in the high-affinity (Boron Nitride) case, the simulation shows electrons are accelerated to higher energies (Fig 8). These higher-energy electrons (and potentially ions) would cause TSEE and IISEE, which are neglected. The paper acknowledges this could lead to a feedback loop and drive emission towards γ > 1. Ignoring these mechanisms, which become relevant due to the simulated acceleration, means the results for the SCL sheath might be incomplete or inaccurate, potentially altering the high-energy tail, total emission yield, and the sheath structure itself."
      },
      {
        "Problem": "Use of an artificial, spatially-varying collision frequency.",
        "Location": "Page 4, Section II C; Eq. 15; Fig 6",
        "Explanation": "The physical collision frequency is artificially inflated and given a non-physical sigmoid spatial profile to achieve a collisional presheath and collisionless sheath within the limited simulation domain. While the goal is physically motivated, the artificial nature of the model and its potential sensitivity (as shown in Fig 5 for uniform collisions) raise concerns that it might distort the distribution functions and transport properties in the presheath and transition region in ways that are not physically accurate, potentially affecting the resulting sheath structure and gain."
      },
      {
        "Problem": "Assumption of the same wall roughness parameter (C=2) for different dielectric materials.",
        "Location": "Page 2, Section II A; Eq. 7",
        "Explanation": "The Bronold-Fehske reflection model includes a fitting parameter C representing wall roughness. The paper uses C=2 for both Magnesium Oxide and Boron Nitride due to a lack of experimental data, stating it 'remains sufficiently applicable'. However, C is a material property that likely differs between materials. Using a potentially incorrect value for C could affect the calculated reflection probability (Eq. 7, 8) and thus the gain γ, potentially altering the quantitative or even qualitative nature of the resulting sheath (classical vs. SCL) compared to a simulation with material-specific C values."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 2869,
      "output": 655
    }
  },
  {
    "entry_id": 7,
    "retraction_id": "1902.09447v2",
    "paper_id": "1902.09447v1",
    "retraction_comment": "We have to change the simulations section since the authors of the RANA method do not agree that we did fair comparisons with their method",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent mathematical formulation in the initialization algorithm derivation.",
        "Location": "Section IV-A, equations (14), (15), (21), (24), (25), and Algorithm 2 Lines 6-9.",
        "Explanation": "The definitions and indexing of matrices G_l and vectors y_l used to derive the alternating minimization steps for the initialization algorithm appear inconsistent with standard matrix operations and the dimensions of the FROG data Y[p, l]. For instance, equation (14) ye = Gexe is presented as a linear system, but the provided definitions for ye, xe, and Ge do not form a standard matrix-vector product with consistent dimensions or indexing based on the R x N FROG data Y[p, l]. This lack of clarity and apparent inconsistency in the mathematical setup casts doubt on the validity of the derived alternating updates and the initialization method itself."
      },
      {
        "Problem": "Gap in the convergence proof regarding the smoothing parameter approaching zero.",
        "Location": "Theorem 1, Lemma 1, Appendix A, Appendix B, equations (28), (29), (53), (57).",
        "Explanation": "The convergence proof relies on standard stochastic gradient descent theory which typically assumes bounded Lipschitz constant and variance. However, the bounds derived in Lemma 1 for the Lipschitz constant (U) and the expected squared stochastic gradient (ζ²) appear to depend inversely on the smoothing parameter μ. Since the algorithm decreases μ towards zero (lim μ(t) = 0), these bounds may diverge. The proof does not demonstrate that these bounds remain finite along the algorithm's trajectory as μ -> 0, leaving a gap in the formal convergence guarantee."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 7914,
      "output": 379
    }
  },
  {
    "entry_id": 8,
    "retraction_id": "1610.03889v2",
    "paper_id": "1610.03889v1",
    "retraction_comment": "There is a serious gap about the tangent space of the dimension 2 foliations induced by a linear pull-back. I do not know if the scheme is reduced and so it is possible that the dimension of the tangent space of this scheme is bigger than his topological dimension",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption on the form of tangent vectors.",
        "Location": "Lemma 2.1, Page 3",
        "Explanation": "The lemma assumes that any tangent vector \\u03be in T\\u03a0Pois(Pn) can be written in a specific polynomial form in the coordinate xn. This assumption is not justified for a general bivector field on Pn (or in an affine chart) and is likely incorrect for sections of \\u039b\\u00b2 TPn. This assumption is fundamental to the subsequent calculations and conclusions."
      },
      {
        "Problem": "Incorrect domain for applying Proposition 3.4.",
        "Location": "Proof of Theorem 1, Page 6 (relies on Proposition 3.4, Page 5)",
        "Explanation": "Proposition 3.4 is a result about bivector fields on Pn-1 (or Cn-1). The proof applies this proposition to the component \\u03b1\\u2080 of the tangent vector \\u03be, which is defined as the part independent of xn in an affine chart of Pn (or Cn). This \\u03b1\\u2080 is a bivector field on Cn, not necessarily Pn-1, making the application of Proposition 3.4 invalid without a clear and justified mapping or isomorphism."
      },
      {
        "Problem": "Flawed argument for equality of tangent spaces.",
        "Location": "Proof of Theorem 1, Page 6 (relies on Lemma 2.1, Page 3)",
        "Explanation": "The proof concludes that deforming the Poisson structure \\u03a0 is equivalent to deforming the foliation F by arguing that their tangent spaces T\\u03a0Pois(Pn) and TF(Fol(Pn)) are equal. This equality is derived directly from Lemma 2.1, which is based on the unjustified assumption about the form of \\u03be and the incorrect application of Proposition 3.4. Therefore, the equality of tangent spaces is not correctly established, breaking the link between the stability of the foliation and the stability of the Poisson structure."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 3375,
      "output": 499
    }
  },
  {
    "entry_id": 9,
    "retraction_id": "1208.1540v2",
    "paper_id": "1208.1540v1",
    "retraction_comment": "This paper has been withdrawn because there is a gap in the construction of the canonical quadratic refinement on a mapping torus",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Independence of quadratic refinement Q on the choice of bordism trivialization",
        "Location": "Proposition 4.2 (page 19), Proposition 5.2 (page 22)",
        "Explanation": "The proofs for the independence of Q on the choice of bordism trivialization rely on terms involving cup products of cocycles and lifts vanishing modulo 1 or 2. The arguments provided, particularly in Proposition 4.2 relating Q1-Q2 to <z ∪ (λ2-λ1), [W, ∂W]> mod 1 and in Proposition 5.2 relating Q1-Q2 to <z132 ∪ (z132-λ132), [W132]>, do not rigorously demonstrate that these terms are always zero modulo 1 based on the properties of λ as a lift of the Wu class or λ as a form lift satisfying (3.5)."
      },
      {
        "Problem": "Proof that Q is a quadratic refinement",
        "Location": "Proposition 5.4 (page 23)",
        "Explanation": "The proof that Q is a quadratic refinement of LM uses a specific form z = dx∪u + dy∪v on M × P. It is not clear that this form correctly restricts to the required boundary classes on M × ∂P. Additionally, the argument for dropping the λ term modulo 1 seems incorrect, as the de Rham class of the relative lift λ is not necessarily twice an integral class, only twice a de Rham class."
      },
      {
        "Problem": "Canonicity of the relative lift and canonical quadratic refinement",
        "Location": "Section 4.3 (page 20), Section 4.4 (page 20)",
        "Explanation": "The construction of the canonical reduced differential cohomology class μc relies on choosing a non-canonical μ such that a(μ) has no component on T²⁺¹(Mφ). While a(μ) is fixed up to a 2-torsion class, the initial choice of μ is not unique. The procedure for making it canonical by adding u₁ and u₂ seems to depend on this initial non-canonical choice of μ, which affects the canonicity of λc and Qc."
      },
      {
        "Problem": "Proof of vanishing of canonical quadratic refinement Qc on torsion subgroups",
        "Location": "Proposition 4.5 (page 21), Proposition 5.5 (page 24)",
        "Explanation": "The proofs that Qc vanishes on H²⁺¹(M, Z)tors and H²⁺²(Mφ, Z)tors appear to mix the definitions of the non-canonical Q (defined in 4.1) and the canonical Qc (defined in 4.7 or 5.7). They rely on equalities derived from earlier propositions (like 4.2 and 5.4) whose proofs contain potential flaws, making the vanishing property of Qc on torsion subgroups questionable."
      },
      {
        "Problem": "Obstruction to extending the reduced differential cohomology class",
        "Location": "Section 3.3 (page 18), Appendix A (page 32-36)",
        "Explanation": "The construction of the relative lift λ = ν - 2μw requires extending the reduced differential cohomology class μ from the boundary manifold E to the bounded manifold W. While Appendix A shows that integral cohomology classes can be extended in certain dimensions (l=0, 2, l odd), it does not provide a proof or argument that the reduced differential cohomology class μ can always be extended under the same conditions. If this extension is not always possible, the construction of the canonical relative lift and the subsequent canonical quadratic refinements is not guaranteed, despite the vanishing of cobordism obstructions for integral classes."
      }
    ],
    "token_usage": {
      "input": 9928,
      "thinking": 5713,
      "output": 838
    }
  },
  {
    "entry_id": 10,
    "retraction_id": "1708.09822v3",
    "paper_id": "1708.09822v2",
    "retraction_comment": "incorrect example (Example 5)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect multiplication table for the basis of the matrix component of Hλ,4.",
        "Location": "Page 17, Proposition 4.8",
        "Explanation": "The multiplication table provided for the Q-basis {1, X, Y, Z} of the Mat_r(R) component of Hλ,4 contains errors. Specifically, the calculation for Y^2 is shown as 2β²e, but the table lists 4β². The calculation for Z^2 also appears incorrect. These errors invalidate subsequent derivations based on this table."
      },
      {
        "Problem": "Theorem 4.9 is unsound due to reliance on an incorrect multiplication table.",
        "Location": "Page 17, Theorem 4.9",
        "Explanation": "Theorem 4.9 provides a necessary and sufficient condition for Hλ,4 to be isomorphic to QD4 as Q-algebras. The proof of this theorem relies on the multiplication table given in Proposition 4.8 to derive the equation b²α² = c²β² + d²α²β². Since the multiplication table is incorrect, the derived condition and thus the theorem's conclusion are likely incorrect."
      },
      {
        "Problem": "Examples 5 and 6 are based on a condition derived from an incorrect multiplication table.",
        "Location": "Pages 18-19, Examples 5 and 6",
        "Explanation": "Examples 5 and 6 are presented to illustrate Theorem 4.9 by constructing fields L/Q with Galois group D4 and checking the condition b²α² = c²β² + d²α²β². As this condition is derived from the erroneous multiplication table in Proposition 4.8, the examples do not reliably support the theorem's statement."
      },
      {
        "Problem": "Potential error in the calculation of basis elements for the center in Proposition 4.11.",
        "Location": "Page 20, Proposition 4.11",
        "Explanation": "In the proof for the n=5 case, the calculation of the basis elements for the center of the matrix component involves multiplying the idempotent e3 by group elements. While the calculation for e3(σ+σ²) seems plausible, the calculation for e3(σ²+σ³) is complex and a minor typo (3σ² instead of 3σ³ in the intermediate step) was noted during verification, although the final result matches a re-calculation. Given the complexity and potential for error, this step warrants careful re-verification as it is crucial for determining the center and thus the structure of the algebra."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 7476,
      "output": 581
    }
  },
  {
    "entry_id": 11,
    "retraction_id": "2011.04373v3",
    "paper_id": "2011.04373v2",
    "retraction_comment": "paper withdrawn since dimension reduction might not hold in the parabolic setting",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Invalid application of Lemma 2.6 due to non-constant coefficient.",
        "Location": "Page 11, application of Lemma 2.6",
        "Explanation": "The iterative inequality for the sequence Mi is of the form Mi+1 <= C_i * Mi^(1+alpha), where the coefficient C_i = b^(2i) * (A/k) * (1 + C_terms) grows exponentially with the iteration index i (since b > 1). Lemma 2.6, which is used to conclude convergence to zero, requires a constant coefficient (Y_{n+1} <= C * b * Y_n^(1+alpha)). The convergence condition derived from Lemma 2.6 is therefore not applicable to this iteration, invalidating the conclusion that Mi converges to zero and thus the boundedness result."
      },
      {
        "Problem": "Essential condition for positive constants in iterative estimates not guaranteed by hypotheses.",
        "Location": "Page 10, definition of tau and beta; Page 9, definition of beta; Page 6, condition (3.3)",
        "Explanation": "The iterative estimates and the definition of the exponent alpha used in Lemma 2.6 rely on the constant tau being positive. The definition of tau includes the term p + epsilon_0 - 2. With the choice epsilon_0 = 4/(N+2), tau > 0 requires p > 2 - 4/(N+2) = 2N/(N+2). While Hypothesis (H1) states p > 2N/(N+2), the strict inequality in H1 does not guarantee p + 4/(N+2) > 2 (it only guarantees p + 4/(N+2) >= 2). If p + epsilon_0 <= 2, then tau <= 0, which makes the definition of beta (beta = q/(N+1) + epsilon_0/tau) problematic (undefined or non-positive), breaking the requirement alpha > 0 for Lemma 2.6. This invalidates the iterative scheme."
      },
      {
        "Problem": "Condition for applying Lemma 2.4 (Sobolev embedding on the sphere) not guaranteed by hypotheses.",
        "Location": "Page 7, application of Lemma 2.4; Page 4, Lemma 2.4 statement",
        "Explanation": "Lemma 2.4, the Sobolev embedding on the sphere, is applied with s = q* = q(N-1)/(N+1). The lemma requires s to be in the range [1, N-1). Hypothesis (H1) on q (q > p > 2N/(N+2) and q < p(N+1)/(N-1)) does not guarantee that q* is in this range for all N >= 2. Specifically, q* >= 1 requires q >= (N+1)/(N-1), which is not guaranteed by q > 2N/(N+2) for N=2, 3, 4. Also, q* < N-1 requires q < N+1, which is not guaranteed by q < p(N+1)/(N-1) if p is large. The invalid application of Lemma 2.4 undermines the estimates in Section 3.1, particularly (3.10) and subsequent steps."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 8171,
      "output": 738
    }
  },
  {
    "entry_id": 12,
    "retraction_id": "2401.02488v3",
    "paper_id": "2401.02488v2",
    "retraction_comment": "Lemma 3.4 on page 7 is incorrect. This is crucial to the argument. The problem that could not be fixed is if there are parts of hilden subgroup elements that contain parts of powers of the garside element",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of the Hilden subgroup and the double coset problem.",
        "Location": "Abstract, Section 1, Definition 2.2, Theorem 2.5",
        "Explanation": "The paper defines the Hilden subgroup $H_n$ as a subgroup of $B_{2n}$ (Definition 2.2) but states the Hilden double coset problem for the braid group $B_n$ modulo $H_n$ (Abstract, Section 1, Theorem 2.5). A double coset $H_n \\beta H_n$ is only well-defined if $\\beta$ is an element of a group $G$ that contains $H_n$ as a subgroup, or if $H_n$ is a subgroup of $G$ and $\\beta \\in G$. Here, $\\beta \\in B_n$ and $H_n \\subset B_{2n}$. This fundamental inconsistency makes the problem statement ill-posed as written for $B_n$ unless a specific embedding into $B_{2n}$ is defined and used consistently."
      },
      {
        "Problem": "Incorrect claim that the Garside element $\\Delta$ is in the Hilden subgroup $H_n$.",
        "Location": "Lemma 3.1 Proof, Figure 6 caption",
        "Explanation": "The proof of Lemma 3.1 relies crucially on the claim that the Garside element $\\Delta$ (defined in $B_n$) is in the Hilden subgroup $H_n$ (defined as a subgroup of $B_{2n}$). This claim is used to argue that if $\\beta = \\Delta^m P_0$, then $P_0$ is in the same Hilden double coset as $\\beta$. However, the generators of $H_n \\subset B_{2n}$ (Definition 2.2) do not appear to generate the Garside element $\\Delta_{2n}$ of $B_{2n}$, let alone $\\Delta_n$ of $B_n$. This invalidates the proof of Lemma 3.1 and the subsequent procedure which relies on $P_0$ being in the double coset."
      },
      {
        "Problem": "Flawed procedure for finding the minimal positive element in a double coset.",
        "Location": "Section 3.1",
        "Explanation": "The procedure to find the minimal positive element $\\gamma_0$ in the double coset $[\beta]^+$ searches a 'candidate set' $C$ of positive words with length less than $P$ (where $\\beta = \\Delta^m P$) and no $\\Delta$ in their Garside form. It claims the first word in $C$ found to be in the double coset of $P$ is $\\gamma_0$. This is flawed because the minimal positive element $\\gamma_0$ might have length greater than $P$, might have $\\Delta$ in its Garside form, and the procedure does not guarantee finding the lexicographically smallest positive word in the entire double coset."
      },
      {
        "Problem": "Flawed proof of Lemma 3.4 regarding double coset membership check.",
        "Location": "Lemma 3.4 Proof",
        "Explanation": "Lemma 3.4 attempts to provide a method to check if $A a B = P$ for $A, B \\in H_n$. The proof uses Garside decompositions $A = \\Delta^m P_A$ and $B = P_B \\Delta^k$ and incorrectly claims $AaB = P_A a P_B = P$. Braid multiplication is not commutative, and this simplification is invalid. Furthermore, the claim about word lengths $\\text{Len}(AaB) = \\text{Len}(A) + \\text{Len}(a) + \\text{Len}(B) = \\text{Len}(P)$ is generally false for braid words, especially since $A, B \\in H_n$ are not necessarily positive. This invalidates the proposed finite-time check for double coset membership (Problem 3.3), which is essential for the overall procedure and theorem."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 4307,
      "output": 931
    }
  },
  {
    "entry_id": 13,
    "retraction_id": "1208.2556v8",
    "paper_id": "1208.2556v7",
    "retraction_comment": "This paper has been withdrawn by the author because (k+1)n<k(n+2) is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of property (iv) stating that m₂ is odd.",
        "Location": "Page 2, Section 2, property iv)",
        "Explanation": "The reasoning provided for property (iv) is that if m₂ were even, then m₃ = C(m₂) = m₂/2 would contradict m₀ being the smallest element. This is flawed because m₃ being smaller than m₂ does not imply m₃ is smaller than m₀. The cycle {1, 4, 2} is a counterexample: m₀=1, m₁=4, m₂=2. Here m₂ is even, and m₃=C(2)=1=m₀, which does not contradict m₀=1 being the smallest element."
      },
      {
        "Problem": "Proof of Theorem 3.1 relies on a false property.",
        "Location": "Page 3, Theorem 3.1 Proof",
        "Explanation": "The proof of the main theorem (Theorem 3.1) relies on properties (i) through (iv) of a min-normal cycle. Specifically, it uses the property that m₂ is odd (property iv) in its derivation involving m₂ = 3k+2. Since property (iv) is false, as shown by the {1, 4, 2} cycle, the entire proof is unsound and its conclusion cannot be accepted based on this argument."
      },
      {
        "Problem": "Misinterpretation and misuse of the equation involving 2ʸ - 3ˣ.",
        "Location": "Page 3, Theorem 3.1 Proof",
        "Explanation": "The proof states \"there is only one solution for 2ʸ - 3ˣ ∈ N\". This statement is nonsensical in context. For a specific Collatz cycle, the number of odd steps (x) and the total number of division steps (y) are fixed values, making 2ʸ - 3ˣ a single fixed value determined by the cycle. The equality z₀/(2k+1) = z₁/(3k+2) derived in the proof is a trivial consequence of the definitions zⱼ = mⱼ(2ʸ - 3ˣ) and the properties m₀=2k+1, m₂=3k+2. It does not imply uniqueness for 2ʸ - 3ˣ or lead to a contradiction on its own."
      },
      {
        "Problem": "Unclear and potentially incorrect derivation in Lemma 2.1.",
        "Location": "Page 2, Lemma 2.1 Proof",
        "Explanation": "The derivation of the formula mⱼ = (3ˣ mⱼ + z) / 2ʸ is confusing. The definition of y as \"the sum of even elements and also the sum of 2-operations for each step\" is unclear and likely incorrect. While the final form mⱼ(2ʸ - 3ˣ) = z is a standard result for Collatz cycles (where y is the total number of divisions), the intermediate steps and definitions in the proof are difficult to follow and may contain errors, undermining confidence in the derived formula and the subsequent value of z."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 8356,
      "output": 696
    }
  },
  {
    "entry_id": 14,
    "retraction_id": "1905.08897v3",
    "paper_id": "1905.08897v2",
    "retraction_comment": "Although the quasi-nodal surface has been identified in our preprint, there is a tiny band gap (millivolt-level) in the non high symmetry k-line (e.g.,K1-K5). In this regard, the proposed bct-C40 should be a nodal net semimetal based on the strict definition of topological semimetal. We would like to withdraw this work to avoid misleading the readers from Arxiv",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect topological classification of bct-C40.",
        "Location": "Abstract, Introduction, and Conclusion of Ref [1] (as discussed throughout the Comment).",
        "Explanation": "The original paper [1] claims bct-C40 is a nodal-net semimetal. The comment demonstrates through re-calculations that the nodal structure forms surfaces in the Brillouin zone, classifying it as a nodal surface semimetal instead."
      },
      {
        "Problem": "Misrepresentation of the geometry of nodal lines.",
        "Location": "Fig. 3(c) in Ref [1], discussed on Page 1-2 of the Comment (Fig. 1b, 1c).",
        "Explanation": "The original paper [1] depicts straight lines connecting nodal points to form a 'boxed-asterisk' net. The comment shows that the actual nodal lines between key points (e.g., 0-1, 0-2) are wavy, not straight, invalidating the claimed geometry."
      },
      {
        "Problem": "Failure to identify all existing nodal points.",
        "Location": "Fig. 3(c) in Ref [1], discussed on Page 2-3 of the Comment (Fig. 1d, 1e).",
        "Explanation": "The original paper [1] only identified nodal points belonging to their proposed nodal net. The comment found additional Dirac nodal points (like Dg and others in Fig. 1e) that lie outside this proposed structure, indicating the nodal structure is more extensive or different than described."
      },
      {
        "Problem": "Incorrect description of the overall nodal structure in 3D momentum space.",
        "Location": "Fig. 3(c) in Ref [1], discussed on Page 3 of the Comment (Fig. 2).",
        "Explanation": "The original paper [1] concluded the nodal points form a network of lines. The comment's calculations in the full 3D BZ reveal that the nodal points actually form extended surfaces, which is the defining characteristic of a nodal surface semimetal."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 2235,
      "output": 476
    }
  },
  {
    "entry_id": 15,
    "retraction_id": "1712.07752v2",
    "paper_id": "1712.07752v1",
    "retraction_comment": "Based on the numerous reviews I have received, the figures illustrated in the paper are highly incorrect and vague. This might guide a novice reader towards a wrong direction and lead to improper understanding of the subject. Also, the paper covers a diverse range of topics but doesn't get into the details of any and hence the proposals remain pragmatically irrelevant",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of a feasible mechanism for empowering the UN to host and enforce the proposed body.",
        "Location": "Page 3, Page 4, Page 5",
        "Explanation": "The paper acknowledges that the UN currently lacks the economic and political power to enforce strong regulations against sovereign nations. It suggests 'major reforms' are needed for the UN to become powerful enough to host the UIRB-AI, but fails to provide a concrete or realistic plan for how these fundamental reforms, particularly economic empowerment over individual nations, would be achieved in the face of the nationalistic competition the paper describes."
      },
      {
        "Problem": "Unrealistic assumption of achieving and maintaining 'unanimity' and cooperation among nations.",
        "Location": "Abstract, Page 3, Page 4, Page 6 (Conclusion)",
        "Explanation": "The paper proposes an 'Unanimous International Regulatory Body' and emphasizes the need for cooperation and unity among nations. However, it simultaneously highlights the strong nationalistic competition and self-interest driving AI development globally. The paper does not convincingly explain how the required level of unanimity and willingness to sacrifice national interests for a global body would be achieved and sustained in this adversarial environment."
      },
      {
        "Problem": "Unsound and unaddressed practical hurdles for the proposed 'AI Tax' revenue generation mechanism.",
        "Location": "Page 5",
        "Explanation": "The paper proposes an 'AI tax' as a novel revenue source crucial for the UIRB-AI's economic superiority. However, it immediately identifies two major, unaddressed hurdles: the difficulty in distinguishing AI replacing vs. complementing human workers for taxation purposes, and securing the participation of national governments. Without viable solutions to these challenges, the proposed economic foundation for the UIRB-AI appears speculative."
      },
      {
        "Problem": "Absence of a credible enforcement mechanism for the regulatory body.",
        "Location": "Page 4, Page 5",
        "Explanation": "The paper suggests registration and reporting requirements for AI labs and companies. However, it does not detail how the UIRB-AI would effectively enforce compliance with its regulations, particularly against powerful multinational corporations or sovereign states that might resist or ignore the body's authority, especially given the acknowledged current weakness of the UN."
      },
      {
        "Problem": "Overly broad and potentially unmanageable scope of regulation.",
        "Location": "Abstract, Page 2, Page 5",
        "Explanation": "The paper proposes a regulatory body for 'all applications of AI'. Given the vast, diverse, and rapidly evolving nature of AI technology across numerous sectors and applications, defining, monitoring, and effectively regulating this entire scope presents immense technical, legal, and logistical challenges that are not adequately addressed, making the task of the UIRB-AI seem potentially overwhelming."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 1824,
      "output": 621
    }
  },
  {
    "entry_id": 16,
    "retraction_id": "2110.09901v3",
    "paper_id": "2110.09901v2",
    "retraction_comment": "It relies on maximizing the distance over an intersection of balls to a given point. The used algorithm for this however, is not able to solve the class of problem the SSP generates",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Proof Linking Maximizer over Qp to RSSP Solution",
        "Location": "Page 12, Proof of Lemma 3.4, point (4)",
        "Explanation": "The proof attempts to show that if an RSSP solution x1 exists, the maximizer x* of ||x-C||^2 over Qp satisfies the RSSP conditions. The proof contains a critical error where the inequality ||x* - C|| <= ||x1 - C|| is claimed, which is the opposite of the property of a maximizer (||x* - C|| >= ||x - C|| for all x in Qp). This invalidates the core argument linking the optimization problem solution to the RSSP solution."
      },
      {
        "Problem": "Unsound Claim about Polytope Inclusion Complexity",
        "Location": "Page 16, Section 3.5, Complexity analysis",
        "Explanation": "The paper claims that asserting the inclusion of polytope Pp,R²,C in Qp can be done in P time by solving linear programs. Both Pp,R²,C and Qp are defined by inequalities involving the maximum of quadratic functions (hp(x) and hp(x) - ||x-C||^2). Asserting inclusion between sets defined by quadratic inequalities is generally a non-convex problem or requires solving problems that are not solvable by linear programming in polynomial time. This invalidates the complexity claim and the FPTAS nature of the proposed algorithm."
      },
      {
        "Problem": "Insufficient Proof for P ⊆ Qp",
        "Location": "Page 9, Lemma 2.1 and Proof sketch; Page 19, Lemma B.1 Proof",
        "Explanation": "The claim that Qp is an outer approximation of P relies on P ⊆ Qp for sufficiently large p. The proof sketch and the proof of Lemma B.1 are inadequate. They rely on a 2D analogy (Figure 1) and a lemma (A.1) about inclusions related to a single hyperplane, failing to rigorously demonstrate that the intersection of the constructed balls (Qp) contains the entire polytope P, which is defined by the intersection of the unit hypercube and multiple half-spaces."
      },
      {
        "Problem": "Unjustified Single-Point Assumption for Argmin",
        "Location": "Page 13, Remark 5",
        "Explanation": "The paper assumes that the argmin of the function hp(x) - ||x-C||^2 over the set {x|hp(x) <= 1} contains a single point {x*c}. This is a strong assumption about the nature of the optimization problem's solution set and is not justified for general inputs S and the constructed point C. This limits the applicability of the proposed algorithm to a specific, potentially small, subset of RSSP instances without proving this property holds generally."
      },
      {
        "Problem": "Incorrect Equivalence Claim for Objective Function Maximum",
        "Location": "Page 3, below equation (4)",
        "Explanation": "The paper claims that the maximum value of the objective function in (4) over the feasible set P is zero if and only if the maximizer x* is a {0,1} vector and S^T x* = 0. While the objective function is indeed zero for {0,1} vectors satisfying S^T x = 0, the feasible set P is a continuous polytope. The claim that the *maximizer* over this continuous set must be a {0,1} vector if the maximum is zero is not guaranteed by the formulation alone and requires further justification that is not provided."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 3248,
      "output": 801
    }
  },
  {
    "entry_id": 17,
    "retraction_id": "2001.09967v3",
    "paper_id": "2001.09967v2",
    "retraction_comment": "This paper is withdrawn because there is an error in the last section: the algebraic identities, in the limit n-> \\infty, all collapse to the first conservation law. One could wonder whether this can be fixed via a suitable renormalization scheme but at present, the argument is incomplete",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of rigorous proof for the existence of the limiting root density u(t,x).",
        "Location": "Abstract, Section 1.1, Section 2.1, Section 3",
        "Explanation": "The paper derives conservation laws for a density u(t,x) which is assumed to be the limit of root distributions under iterated differentiation. The existence of this limit density for general initial distributions is a fundamental unproven assumption underlying the interpretation of the conservation laws in the continuous setting."
      },
      {
        "Problem": "Unjustified limit process for deriving integral conservation laws.",
        "Location": "Section 3",
        "Explanation": "The derivation of the conservation laws involves taking limits of discrete sums over polynomial roots and replacing them with integrals over the hypothesized density u(t,x). The rigorous mathematical justification for this convergence, which is essential for the conservation laws to hold for u(t,x), is not provided."
      },
      {
        "Problem": "Proposed PDE lacks rigorous derivation from the root evolution process.",
        "Location": "Section 1.2, Section 2.1, Section 2.2",
        "Explanation": "The paper strongly links the conservation laws to a specific nonlocal PDE, but acknowledges that a rigorous derivation of this PDE from the underlying process of iterated polynomial differentiation is outstanding. This weakens the claim that this specific PDE governs the evolution."
      },
      {
        "Problem": "PDE derivation is limited to initial distributions with single-interval support.",
        "Location": "Section 5 ('A Word of Warning')",
        "Explanation": "The PDE, which is presented as governing the root density evolution, is only known to be rigorously derived for initial distributions whose support is a single compact interval, limiting its applicability to more general cases (e.g., disjoint support)."
      },
      {
        "Problem": "Smoothing property of the proposed PDE is conjectured, not proven.",
        "Location": "Section 1.2",
        "Explanation": "The paper conjectures that the PDE has smoothing properties, which would align with the observed behavior of polynomial roots under differentiation. However, this key property of the PDE itself remains unproven, leaving a fundamental aspect of the model's behavior unverified."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 5747,
      "output": 498
    }
  },
  {
    "entry_id": 18,
    "retraction_id": "2003.01493v2",
    "paper_id": "2003.01493v1",
    "retraction_comment": "Theorem 3.3 is not true in general. If it holds, for example, when n=2, we infer that all 2-cluster tilting subcategories are 2Z-cluster tilting, but it can't hold in general",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 3.2 regarding contractibility of composite extensions.",
        "Location": "Page 12-13, Lemma 3.2 and its proof.",
        "Explanation": "The proof of Lemma 3.2, which is essential for establishing the exactness of the long sequence, appears to contain logical gaps and potentially misapply previous results (such as Proposition 2.15, Lemma 2.12, Proposition 2.8, and Lemma 2.4). The arguments showing the equivalence of the conditions for a composite extension to be contractible are difficult to follow and seem unsound, particularly in the base case (r=s=1) and the subsequent inductive steps."
      },
      {
        "Problem": "Flawed proof of exactness at nE^1(A, X^i) in Theorem 3.3.",
        "Location": "Page 14-15, Proof of Theorem 3.3, Steps 2, 3, 4, 5.",
        "Explanation": "In Steps 2 through 5, the proof attempts to demonstrate exactness at the terms nE^1(A, X^i) for i=0, 1, ..., n. The arguments presented, involving commutative diagrams and factorization, do not clearly show that an element in the kernel of the outgoing map is in the image of the incoming connecting morphism X*,i. Instead, the arguments seem to relate the element to images under maps induced by alpha^j (e.g., (alpha^0)*,1), which are not the required connecting morphisms in the sequence."
      },
      {
        "Problem": "Flawed proof of exactness at nE^i(A, X^j) for i > 1 in Theorem 3.3.",
        "Location": "Page 16, Proof of Theorem 3.3, Steps 6, 7, 8.",
        "Explanation": "The proof of exactness for the higher nE^i groups (i > 1) in Steps 6, 7, and 8 relies on Lemma 3.2, whose proof is questionable. Furthermore, the arguments within these steps, especially Steps 7 and 8, involve manipulations of composed extensions and equivalence relations (using notation like '=i') that are not clearly justified by the definitions or properties established in the paper. The reasoning appears logically unsound and difficult to verify."
      },
      {
        "Problem": "Unsoundness of Theorem 4.2 (Wakamatsu's Lemma) due to reliance on Theorem 3.3.",
        "Location": "Page 17-18, Theorem 4.2 and its proof.",
        "Explanation": "The proof of Theorem 4.2, the n-abelian version of Wakamatsu's Lemma, directly depends on the long n-exact sequence theorem (Theorem 3.3). Since the proof of Theorem 3.3 contains significant flaws (as detailed in the problems above concerning Lemma 3.2 and the exactness steps), the proof of Theorem 4.2 is consequently unsound."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 6746,
      "output": 688
    }
  },
  {
    "entry_id": 19,
    "retraction_id": "2005.08379v2",
    "paper_id": "2005.08379v1",
    "retraction_comment": "Figure 1 is incorrect. Will be updated in the revision",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Country Selection and Grouping",
        "Location": "Section 2, Section 3.1, Table 1, Figure 3",
        "Explanation": "The study selects countries based on their COVID-19 case count *after* the data collection period ends (April 19 vs April 5). The subsequent grouping of countries into S1 (high spread) and S2 (lower spread) is based on an arbitrary selection of 3 countries each from the top 20 list, which is a small, non-representative sample. This makes the generalization of findings to all \"countries with lower/higher pandemic spread\" unsound and potentially subject to selection bias."
      },
      {
        "Problem": "Unjustified Causal Claims",
        "Location": "Abstract, Section 3.1, Section 4",
        "Explanation": "The paper strongly implies or concludes that higher Twitter activity and focus on preventive measures in S2 countries *influenced* or *contributed* to their lower pandemic spread. This is a strong causal claim derived from observed correlations between Twitter data and case counts. The study does not account for numerous confounding factors (e.g., government interventions, public health infrastructure, population density, cultural factors) that are critical determinants of pandemic spread, rendering the causal conclusion unsound."
      },
      {
        "Problem": "Bias in Tweet Data Analysis",
        "Location": "Section 2, Section 3.1, Figure 3, Figure 4, Figure 6",
        "Explanation": "Although the paper mentions collecting tweets matching COVID-19 terms regardless of trend, the primary analysis (temporal volume, topic modeling, bigrams) appears heavily focused on tweets *within* trending topics. This approach biases the analysis towards topics popular enough to trend, potentially missing significant discussions, sentiments, or information propagation occurring outside of trending hashtags or topics, thus providing an incomplete picture of public awareness and discussion."
      },
      {
        "Problem": "Overstated Sentiment Findings",
        "Location": "Section 3.3, Figure 5",
        "Explanation": "The conclusion that users in lower-spread countries (S2) had a positive sentiment towards preventive measures is not consistently supported by the sentiment analysis results. Figure 5 shows sentiment for social distancing and quarantine is largely neutral across all countries (S1 and S2). While Austria and Belgium (S2) show a positive spike for lockdown sentiment, Sweden (S2) does not, and the overall claim of positive sentiment towards *preventive measures* in general for S2 countries is an overgeneralization based on the presented data."
      },
      {
        "Problem": "Reliance on Potentially Inaccurate Historical Trend Data",
        "Location": "Section 2",
        "Explanation": "The study relies on scraping historical trend data from third-party services (Trendogate, Wayback Machine) because the Twitter API does not provide this data. While necessary, this introduces a potential source of error or inaccuracy in the fundamental trend data used for analysis. The paper mentions cross-examination for validation but does not provide details on the extent or results of this validation, making it difficult to assess the reliability of the historical trend dataset."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 3478,
      "output": 695
    }
  },
  {
    "entry_id": 20,
    "retraction_id": "2408.09172v3",
    "paper_id": "2408.09172v2",
    "retraction_comment": "The model diagram in Figure 1 on page 3 of the paper has significant ambiguities. It may lead readers to mistakenly believe that the experiments were conducted in a multi-turn dialogue format. Therefore, we request the withdrawal of this submission",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound definition of LLM uncertainty",
        "Location": "Section 3.2, Figure 1",
        "Explanation": "The method defines uncertainty based purely on output consistency across specific label-injection prompts. This operational definition may capture prompt sensitivity or sycophancy rather than the model's true internal uncertainty or knowledge boundary."
      },
      {
        "Problem": "Insufficient mitigation of sycophancy",
        "Location": "Section 3.1, Figure 2",
        "Explanation": "Despite including instructions to maintain stance, LLMs show significant shifts in accuracy based on provided labels (Figure 2), suggesting they are still heavily influenced. This confounds the measurement of uncertainty with susceptibility to external guidance."
      },
      {
        "Problem": "Unjustified and potentially unstable selection of 'informative' categories",
        "Location": "Section 4.2 (Uncertainty Category Distribution), Section 5.1 (Example Selection Details), Figure 4",
        "Explanation": "The claim that certain categories (e.g., 011, 010, 110) are 'most informative' is based on intuition. Selecting the best category based on validation performance is susceptible to overfitting, especially given the uneven distribution and small sample sizes in some categories (Figure 4), making the selection of a single example potentially unstable."
      },
      {
        "Problem": "Strong assumption in the 'one-example-for-all' ICL strategy",
        "Location": "Section 5.1 (Example Selection Details)",
        "Explanation": "Using a single example from one uncertainty category for all test instances assumes universal informativeness, which may not hold. This simplification, while efficient, might not fully leverage the potential benefits of uncertainty-guided selection compared to per-instance methods."
      },
      {
        "Problem": "Mischaracterization of the comparison with sampling-based methods",
        "Location": "Section 4.2 (Uncertainty Properties of LLMs), Section 6 (Conclusion)",
        "Explanation": "Framing Unc-TTP as a 'stricter classification' of the same uncertainty concept as sampling is questionable. Unc-TTP probes sensitivity to external labels, while sampling probes internal variability. They measure different aspects of model behavior, and Unc-TTP showing more 'wavering' might just reflect a stronger perturbation method."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 3141,
      "output": 533
    }
  },
  {
    "entry_id": 21,
    "retraction_id": "1207.2800v2",
    "paper_id": "1207.2800v1",
    "retraction_comment": "This paper has been withdrawn by the authors because the proof of Lemma 3.3 has a gap. More precisely, the claim \"If R has a pylonic vertex, v, incident with at least two cables, the pylonicity of v is destroyed by the splitting of any corner\", as stated, is unjustified and looks false in whole generality; the authors overlooked some cases",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 3.4 regarding the structure of irreducible triangulations of punctured surfaces.",
        "Location": "Section 3, Lemma 3.4 Proof",
        "Explanation": "The proof relies on an undefined operation of 'closing the triangular hole' to obtain a triangulation Î of the closed surface S from an irreducible triangulation T of S-D when the boundary length is 3. The argument that this Î belongs to Ξ₁ or Ξ₂ based on the number of cables in the boundary is unclear and lacks formal justification, undermining the classification of irreducible triangulations of S-D and the subsequent finiteness theorem (Theorem 3.5)."
      },
      {
        "Problem": "Misapplication of results about the projective plane to the Möbius band.",
        "Location": "Section 5",
        "Explanation": "The justification for restricting the analysis of irreducible Möbius band (N₁-D) triangulations to cases (i) and (ii) of Lemma 3.4 is based on Corollaries 4.4 and 4.5, which describe properties of triangulations of the projective plane (N₁), a different surface. This misapplication means the argument for excluding cases (iii) and (iv) of Lemma 3.4 for N₁-D is unsound, potentially leading to an incomplete list of irreducible triangulations in Theorem 5.1."
      },
      {
        "Problem": "Unsound proofs of key lemmas for the pinched torus.",
        "Location": "Section 6, Lemma 6.1 and Lemma 6.2 Proofs",
        "Explanation": "The proofs of Lemma 6.1 and Lemma 6.2, which aim to characterize the vertex set and edge properties of irreducible triangulations of the pinched torus S₀[2], contain significant logical gaps and unclear steps. For example, the proof of Lemma 6.2 is difficult to follow and makes unsubstantiated claims about edges becoming cables, rendering the proofs unreliable and undermining Theorem 6.3."
      },
      {
        "Problem": "Fundamentally flawed representation and interpretation of pinched torus triangulations.",
        "Location": "Section 6, Fig. 4 and Theorem 6.3 Proof",
        "Explanation": "The paper uses a spherical model with two vertices s₁ and s₂ to represent the singular point s of the pinched torus S₀[2], stating that s₁ and s₂ are identified. The figures and description imply that edges incident to s₁ and s₂ in the spherical model become loops at the identified vertex s in S₀[2]. This results in a graph that is not simple (contains loops), contradicting the standard definition of a triangulation as a 2-cell embedding of a simple graph, which is used elsewhere in the paper. This invalidates the analysis and the list of irreducible triangulations provided in Theorem 6.3."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 7561,
      "output": 625
    }
  },
  {
    "entry_id": 22,
    "retraction_id": "2212.04565v2",
    "paper_id": "2212.04565v1",
    "retraction_comment": "There is an error. Some cases were not considered in the proof of Theorem 1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect set equality in the proof of Lemma 2.1",
        "Location": "Page 2-3, Proof of Lemma 2.1",
        "Explanation": "The proof defines sets D and E based on conditions on individual components (c and d) and claims that their union D \\cup E represents the set of pairs (c, d) not in N[(g_2, h_2)]. This is incorrect. The condition (c, d) \\notin N[(g_2, h_2)] is a more complex condition involving the adjacency rules in the strong product, not simply a disjunction of conditions on individual components relative to N[g_2] and N[h_2]. This fundamental error invalidates the subsequent set manipulations in the proof of Lemma 2.1."
      },
      {
        "Problem": "Incorrect formula for the difference of a closed neighborhood and a union of closed neighborhoods",
        "Location": "Page 3, Corollary 2.2",
        "Explanation": "Corollary 2.2 provides a formula for the set difference N[(gk, hk)] \\setminus \\bigcup_{i=1}^{k-1} N[(gi, hi)]. This formula is stated as an immediate consequence of Lemma 2.1, which is incorrect as Lemma 2.1 only addresses the difference of two closed neighborhoods. More importantly, the formula itself is incorrect; the set difference is not equal to the union of Cartesian products as stated. This incorrect formula is a central component used in the subsequent corollary and the main proof."
      },
      {
        "Problem": "Incorrect derivation of the inequality in Corollary 2.3",
        "Location": "Page 3-4, Corollary 2.3",
        "Explanation": "Corollary 2.3 provides an upper bound on the size of the set from Corollary 2.2. The proof relies on the set equality claimed in Corollary 2.2 and the triangle inequality for set sizes. Since the set equality in Corollary 2.2 is false, applying the triangle inequality to the right-hand side of that false equality does not yield a valid upper bound for the size of the set on the left-hand side, N[(gk, hk)] \\setminus \\bigcup_{i=1}^{k-1} N[(gi, hi)]."
      },
      {
        "Problem": "Unfounded claim about the number of unique components in the proof of Conjecture 1.1",
        "Location": "Page 4, Proof of Conjecture 1.1",
        "Explanation": "The proof claims that in a Grundy dominating sequence S = ((g_1, h_1), ..., (g_k, h_k)) in G \\boxtimes H, there are at most \\gamma_{gr}(G) unique vertices of G in the first position and at most \\gamma_{gr}(H) unique vertices of H in the second position, leading to the conclusion that |S| \\le \\gamma_{gr}(G)\\gamma_{gr}(H) implies the failure condition. This claim is false. There is no such general restriction on the number of unique first or second components in a Grundy dominating sequence of the strong product graph. This invalidates the core argument used to prove the conjecture."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 14560,
      "output": 714
    }
  },
  {
    "entry_id": 23,
    "retraction_id": "2209.08741v2",
    "paper_id": "2209.08741v1",
    "retraction_comment": "This manuscript has been withdrawn by the authors. Condition (B) needs to be modified for the proofs to work",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper claims that a bounded domain with Bergman metric of constant negative holomorphic sectional curvature is a Lu Qi-Keng domain (zero-free Bergman kernel).",
        "Location": "Page 7, Page 10, used implicitly in proofs of Proposition 2.1, Theorem 1.4, 2.5, 1.6.",
        "Explanation": "This is a critical step used throughout the paper to justify the form of the Bergman-Calabi diastasis (2.5) and the conclusion that the Bergman representative coordinate T maps the domain to a ball (minus a polar set). The justification provided (referencing [28] and the diastasis formula) appears potentially circular, as the derivation and properties of the diastasis formula in [28] seem to rely on the domain being Lu Qi-Keng. If this implication (constant curvature => Lu Qi-Keng) is not rigorously proven or requires additional unstated assumptions, it undermines the foundation of many subsequent results."
      },
      {
        "Problem": "The proofs of several key results, including Proposition 2.1, Theorem 2.5, and Theorem 1.6, appear to rely on the conclusion that the Bergman representative coordinate T maps the domain to a ball (possibly minus a polar set).",
        "Location": "Proofs of Proposition 2.1 (Page 7), Theorem 2.5 (Page 12), Theorem 1.6 (Page 17).",
        "Explanation": "This conclusion is derived from the assumption of constant curvature and the claim that this implies the domain is Lu Qi-Keng (Problem 1). Using results (like the bounds on derivatives in Proposition 2.1) that depend on T mapping to a ball within the proofs of theorems that are meant to establish properties of domains with constant curvature (such as boundedness of derivatives or local kernel estimates) constitutes a logical dependency issue or a circular argument. For instance, the proof of Proposition 2.1 starts by stating that T maps Ω to a ball, which is a consequence derived later in the paper based on constant curvature implying Lu Qi-Keng."
      },
      {
        "Problem": "The deduction of the Lipschitz continuity of the Bergman representative coordinate T (and its inverse S in some cases) relies on the boundedness of the partial derivatives of the coordinate functions w_alpha.",
        "Location": "Proofs of Theorem 1.4 Part 1 (Page 9), Theorem 2.5 Part 1 (Page 12).",
        "Explanation": "This boundedness is shown using Condition (B) and Lemma 2.2 (for Theorem 1.4) or (2.15) and Proposition 2.1 (for Theorem 2.5). However, Lemma 2.2 requires the Bergman kernel K(z,p) to be zero-free for all z, which is not an explicit assumption of Theorem 1.4 Part 1. Similarly, Proposition 2.1 relies on T mapping to a ball, which depends on the zero-free property. The paper relies on the potentially unproven implication that constant curvature implies the zero-free property (Problem 1) to satisfy this requirement, making the deduction of Lipschitz continuity dependent on this weak link."
      },
      {
        "Problem": "The conclusion that the Bergman representative coordinate T extends to a homeomorphism of the closures relies on the inverse map S extending continuously across the pluripolar set E.",
        "Location": "Proofs of Theorem 1.1 Part 2 (Page 14), Theorem 1.4 Part 2 (Page 11), Theorem 2.5 Part 2 (Page 12).",
        "Explanation": "While S is shown to be Lipschitz on the domain minus E (the image of the set removed from the domain), the continuous extension of a Lipschitz function from a domain minus a pluripolar set to the closure of the full domain across the pluripolar set requires rigorous justification, especially in the multidimensional case. This step is critical for establishing the homeomorphism property up to the boundary."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 7891,
      "output": 881
    }
  },
  {
    "entry_id": 24,
    "retraction_id": "1603.02871v2",
    "paper_id": "1603.02871v1",
    "retraction_comment": "Problems in the proof....specifically maximal pivotality. The estimates on the number of pivotal edges is fine",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof of P_p(N >= 3) = 0 (Proposition 1)",
        "Location": "Page 6, Proof of Proposition 1",
        "Explanation": "The proof relies on an incorrect independence assumption between the event Fm (at least three infinite clusters intersect the boundary of Bm) and Vm (all bonds in Bm are closed). It also includes an unjustified step claiming that modifying the configuration inside a finite box can guarantee a trifurcation at the origin with positive probability, which is not a standard or justified technique in percolation theory."
      },
      {
        "Problem": "Unsound proof of Lemma 2 (existence of pivotal edges)",
        "Location": "Page 6, Proof of Lemma 2",
        "Explanation": "The proof is stated to be analogous to the proof of Proposition 1 and suffers from the same fundamental flaws. It implicitly relies on incorrect independence assumptions and an unjustified step claiming that modifying the configuration inside a finite box can guarantee that a specific edge (e0) is pivotal for the event {N=1} with positive probability. This lemma is crucial for the subsequent pivotal edge argument."
      },
      {
        "Problem": "Incorrect independence assumption in Lemma 4(ii)",
        "Location": "Page 4, Lemma 4(ii)",
        "Explanation": "Lemma 4(ii) claims that the event that the maximally pivotal set containing e0 is a fixed set {e1, ..., ek} is independent of the state of the edges in {e1, ..., ek}. This is highly unlikely to be true, as the definition and structure of pivotal sets depend directly on the configuration of open/closed edges. This invalidates the variance calculation (Proof of Lemma 3) which relies on this lemma."
      },
      {
        "Problem": "Questionable claim in Lemma 4(i)",
        "Location": "Page 4, Lemma 4(i)",
        "Explanation": "Lemma 4(i) claims that if the configuration omega is in the event {N=2}, the maximally pivotal set Pe(omega) containing edge e is either empty or exactly the set of all pivotal edges En(omega) in the box Bn. This seems incorrect; a maximally jointly pivotal set containing e should be a subset of pivotal edges containing e with a specific maximality property, not necessarily the entire set of pivotal edges in the box."
      },
      {
        "Problem": "Unjustified step in variance calculation (inequality 15)",
        "Location": "Page 8, inequality (15) and surrounding text",
        "Explanation": "The inequality Pp(TM(e1)) <= Pp(He1) + epsilon is derived from the claimed downward convergence TM(e1) intersect A12 -> He1 as M -> infinity. The definition of TM(e1) and its relation to He1 (the event that e1 is pivotal for {N=1}) are not clearly established, and the claimed downward convergence lacks rigorous justification. This step is used in the estimation of I2,2 within the variance calculation."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 5650,
      "output": 680
    }
  },
  {
    "entry_id": 25,
    "retraction_id": "1110.2623v5",
    "paper_id": "1110.2623v4",
    "retraction_comment": "This paper has been withdrawn since a necessary condition for the existence of an asymptotically cylindrical Calabi-Yau metric on W_1 is in fact not satisified",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The original construction of admissible pairs (W, D) for non-symplectic automorphisms of prime order p > 2 is based on an incorrect claim about the divisor D being anti-canonical.",
        "Location": "Section 6, Appendix A",
        "Explanation": "Theorem 2.3 requires the divisor D to be in the anti-canonical class |-Kw| for (W, D) to be an admissible pair. Appendix A explicitly states that the claim D ∈ |-Kw| made for the construction in Section 6 when p > 2 is false, invalidating this construction method for the cases the paper aims to address."
      },
      {
        "Problem": "The specific examples of G2-manifolds and their Betti numbers calculated in Section 7 rely on the flawed construction of W1 from Section 6 for p=3.",
        "Location": "Section 7, Example 7.6, Theorem 7.9, Appendix D",
        "Explanation": "The examples in Section 7 use W1 constructed via the method described in Section 6 with p=3. Appendix A clarifies that the Section 6 construction is only valid for p=2. Therefore, the specific calculations of Betti numbers for the new G2-manifolds presented in Section 7 are based on an invalid construction of one of the building blocks (W1)."
      },
      {
        "Problem": "The new construction of admissible pairs in Appendix B relies on unproven assumptions about the fixed locus and Hodge numbers of the resulting threefold W'.",
        "Location": "Appendix B, Step 3",
        "Explanation": "The proof that the pair (W', D') constructed in Appendix B is admissible and that π1(W') is finite depends on assumptions about the fixed locus of the automorphism ρ' (containing at least one rational curve) and the Hodge numbers of W' ((h1,1(W'), h1,2(W')) ≠ (11,0)). While the authors state these are 'in general satisfied', the paper does not provide a proof that these conditions hold for the specific K3 surfaces and automorphisms required for the construction, leaving the general validity of the new construction uncertain."
      },
      {
        "Problem": "The application of the matching theorem (Theorem 7.7) to the specific examples using the new construction requires further detailed analysis not provided in the paper.",
        "Location": "Appendix D",
        "Explanation": "Appendix D discusses how to adapt the examples from Section 7 using the new construction. It notes that the original choice for W1's fixed lattice complement (A2) leads to a situation where the ranks of Lρ' and Lρ'² differ (19 vs 20), suggesting the original matching argument might not apply directly. While an alternative choice for W1's fixed lattice complement (2H) is proposed to satisfy a condition of Theorem 7.7, the detailed steps for constructing this W1 via Appendix B and rigorously proving the matching condition are not fully presented, indicating a gap in the argument for the existence of the claimed G2-manifolds."
      }
    ],
    "token_usage": {
      "input": 10444,
      "thinking": 2119,
      "output": 675
    }
  },
  {
    "entry_id": 26,
    "retraction_id": "1307.5957v4",
    "paper_id": "1307.5957v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of the Nonlinear Schrödinger Equation and its associated potential energy.",
        "Location": "Page 1, Equation (1.1); Page 2, Section 2 (Energy definition); Page 3, Equation (2.7)",
        "Explanation": "Equation (1.1) defines the NLS with a cubic nonlinearity |u|^2 u (p=2). However, the text in Section 2 states p=3 for the nonlinear term, and the potential energy formula V(t) is incorrect for both p=2 and p=3. Equation (2.7) gives the energy for the cubic NLS |u|^3 u (p=3, λ=1), contradicting the equation stated in (1.1)."
      },
      {
        "Problem": "Incorrect definitions of momentum density and stress tensor components.",
        "Location": "Page 2, Equations (2.2) and (2.3)",
        "Explanation": "The definitions provided for F_j0 (momentum density) and F_jk (stress tensor) are non-standard and appear incorrect for the NLS equation. This invalidates the conservation laws (2.4) which are stated to be derived from these definitions."
      },
      {
        "Problem": "Incorrect definition of the Lagrangian density for the NLS equation.",
        "Location": "Page 3, Equation (3.1) and Page 4, Equation (3.5)",
        "Explanation": "The Lagrangian density defined includes a term proportional to |∂_t u|^2, which is incorrect for the standard NLS equation. The correct Lagrangian density involves terms like (i/2)(u* ∂_t u - u ∂_t u*). This fundamental error invalidates the subsequent Lagrangian mechanics formulation and the action principle."
      },
      {
        "Problem": "Fundamental confusion between field theory and particle mechanics.",
        "Location": "Page 3, Section 3, Proposition 3.1, Equations (3.2), (3.3), (3.4)",
        "Explanation": "The paper incorrectly applies the Euler-Lagrange equation for a particle (3.3) to a field theory context. This leads to mathematically nonsensical equations like (3.2) and an irrelevant derivation of Newton's second law for a particle (3.4) in the context of the NLS field equation."
      },
      {
        "Problem": "Incorrect statement and application of the Poincaré inequality.",
        "Location": "Page 3, Section 2.1, Proof sketch of Theorem 2.2",
        "Explanation": "The proof sketch relies on the inequality ||u(x)||_{L^2(R)} <= C ||∇u(x)||_{L^2(R)}, which is generally false for functions in L^2(R) or H^1(R). This invalidates the argument presented for the main theorem."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 4351,
      "output": 646
    }
  },
  {
    "entry_id": 27,
    "retraction_id": "2211.05302v2",
    "paper_id": "2211.05302v1",
    "retraction_comment": "We just noted the explanation on phase retardation was incorrect and accordingly, the inhibition mechanism of zeroth-order light was not properly elucidated. We will submit a revised version soon",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and likely incorrect theoretical model for the SLM.",
        "Location": "Page 1-2, Equations (1) and (3), and surrounding text",
        "Explanation": "The paper uses Equation (1) which describes the tilting angle for a twisted nematic liquid crystal cell. However, it then uses Equation (3) for phase retardation, which is applicable to parallel-aligned liquid crystal cells, and mentions 'parallel aligned LC cells' in the text. The specific experimental SLM (LETO PLUTO) is a Liquid Crystal on Silicon (LCoS) device, typically used as a phase-only SLM, which is often parallel-aligned or has a small twist optimized for specific polarization. This inconsistency and likely misapplication of the theoretical model invalidate the theoretical analysis and simulations based on it."
      },
      {
        "Problem": "Unsound theoretical basis for voltage optimization.",
        "Location": "Page 2-3, Figure 1 and associated text",
        "Explanation": "The paper determines optimal Bright (Vo) and Dark (Vc) voltages based on theoretical curves derived from Equations (1)-(4). Since the underlying theoretical model (specifically the phase retardation formula in Eq. 3 and potentially the application of Eq. 4) is likely incorrect for the SLM type used, the theoretical justification for the chosen optimal voltages is flawed. While experimental results show practical improvement, the paper's explanation for the optimality is based on an unsound theoretical foundation."
      },
      {
        "Problem": "Insufficient theoretical explanation for the reduction of pixelation-induced zeroth-order light.",
        "Location": "Page 1-2, Theoretical background section",
        "Explanation": "The paper claims to eliminate zeroth-order light caused by pixelation by adjusting Vc and Vo. However, the provided theoretical model (Equations 1-5) primarily describes the voltage-dependent phase/amplitude modulation of the liquid crystal cells. It does not explicitly model how these voltage adjustments specifically reduce the diffraction effects caused by the pixelated structure (e.g., fill factor, grid diffraction), which is the stated origin of the zeroth order. The link between the voltage-controlled LC behavior and the reduction of the pixelation-induced zeroth order is not theoretically derived or explained within the provided framework."
      },
      {
        "Problem": "Unjustified application of the intensity formula (Eq. 4) without full polarization details.",
        "Location": "Page 2, Equation (4) and surrounding text, Figure 3(g)",
        "Explanation": "Equation (4) relates intensity to phase retardation and incident polarization angle $\\psi$. The paper states $\\psi$ is slightly larger than zero in practice, implying the SLM is not in a pure phase-only mode according to this equation. For a twisted nematic SLM (if applicable) or a parallel-aligned SLM used for phase-only modulation, the intensity modulation depends heavily on the input and output polarization states relative to the LC director. The paper does not fully describe the polarization optics used in the theoretical model or simulation, nor does it justify the applicability of Equation (4) to the specific SLM and experimental setup (Fig 3g shows a polarizer before the SLM, but the output analysis is not detailed in relation to the theory). This lack of detail makes the application of Eq. 4 questionable and potentially inaccurate for modeling the SLM's intensity response."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 3573,
      "output": 736
    }
  },
  {
    "entry_id": 28,
    "retraction_id": "1910.05809v3",
    "paper_id": "1910.05809v2",
    "retraction_comment": "Need to fix some error in the paper. In the last step of the proof, the hypersurface of the minimal principle curvature equal to zero may be tangent to the boundary of the domain",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed argument in Claim 1 regarding the location of the maximum of the gradient.",
        "Location": "Page 5, Proof of Theorem 3.1, Claim 1",
        "Explanation": "Claim 1 asserts that the maximum of $|\nabla u^T|$ on the boundary $\\Gamma^T$ is achieved at a point $Q$ where $\\det(u^T_{ij}(Q)) > 0$. The proof identifies $Q$ as a point where $\\min_{\\Gamma^T} (1/W^T)$ is achieved, which corresponds to a minimum of $|\nabla u^T|$, not a maximum. The subsequent argument that $\\det(u^T_{ij}(Q)) > 0$ relies on $u^T_{kk}(Q) > 0$ for $k<n$, which is only guaranteed if $u^T$ is strictly convex at $Q$, assuming the frame aligns with principal directions. This is circular reasoning, as strict convexity is the property being proved up to $T$. This invalidates the application of the constant rank theorem based on this point."
      },
      {
        "Problem": "Inconsistent assumption or division by zero in the derivation following the determinant formula.",
        "Location": "Page 6, Proof of Theorem 3.1, after the determinant formula",
        "Explanation": "The formula for $u^T_{nn}(P)$ derived from $\\det u^T_{ij}(P) = 0$ involves division by $u^T_{kk}(P)$ for $k<n$. If the rank of $u^T_{ij}(P)$ is $n-1$ (since the determinant is zero), at least one eigenvalue is zero. If this zero eigenvalue corresponds to a tangent direction ($k<n$), then $u^T_{kk}(P)=0$ for that $k$, leading to a division by zero. This contradicts the assumption that the formula holds and invalidates the subsequent arguments, including the proof of Claim 2."
      },
      {
        "Problem": "Proof of Claim 2 (multiplicity one) relies on an inconsistent assumption.",
        "Location": "Page 6, Proof of Theorem 3.1, Claim 2",
        "Explanation": "The proof of Claim 2, which asserts that the smallest eigenvalue has multiplicity one at the boundary point $P$ where the rank drops, relies on the formula derived from the determinant being zero. As explained in Problem 2, this derivation is invalid if the rank drops in a tangent direction. If the multiplicity is not one, the subsequent use of the approximation $\\mu$ for $\\kappa_1^T$ in Lemma 3.2 might not be justified, as smooth convergence of $\\mu$ to $\\kappa_1^T$ typically requires $\\kappa_1^T < \\kappa_2^T$."
      },
      {
        "Problem": "Proof of Lemma 3.2 relies on the multiplicity of the smallest principal curvature being one.",
        "Location": "Page 7, Proof of Lemma 3.2",
        "Explanation": "The proof of Lemma 3.2, which establishes an inequality for the Laplacian of the smallest principal curvature $\\kappa_1^T$, relies on using an approximation $\\mu$ that converges smoothly to $\\kappa_1^T$. This smooth convergence and the subsequent derivation typically require that $\\kappa_1^T$ is strictly separated from the other principal curvatures, i.e., its multiplicity is one. If Claim 2 is false and the multiplicity can be greater than one at the boundary point $P$, the validity of Lemma 3.2 is questionable."
      },
      {
        "Problem": "Unclear and potentially incorrect argument for transversality in the final step.",
        "Location": "Page 9, Proof of Theorem 3.1, final paragraph",
        "Explanation": "The argument that the set $\\{\\kappa_1^T=0\\}$ is a smooth hypersurface transversal to the boundary $\\Gamma^T$ at $P$ is not clearly justified. The claim that $u^T_n(P) > 0$ implies this transversality is unclear. This step is crucial for concluding that $T=1$ by contradiction, and its lack of rigor weakens the entire proof."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 5169,
      "output": 931
    }
  },
  {
    "entry_id": 29,
    "retraction_id": "1108.1348v2",
    "paper_id": "1108.1348v1",
    "retraction_comment": "Withdrawn because of a crucial error in eq.(15)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect comparison baseline due to different metric ansätze.",
        "Location": "Page 5 (metric ansatz), Page 6 (Section 3.1), Page 3 (Introduction), Page 10 (Conclusions).",
        "Explanation": "The paper claims that the spherically symmetric solutions with zero shift function (n=0) and nonzero B are independent of λ and identical to the λ=1 solutions found in Ref. [10]. However, the metric ansatz used in this paper (Eq. 6) has grr = 1/f(r), while the metric ansatz used in Ref. [10] has grr = f(r). Consequently, the n=0, B ≠ 0 solutions derived in this paper (ds² = -c² dt² + dr²/(1-2B/r) + r² dΩ²) are different from the λ=1, n=0, B ≠ 0 solutions found in Ref. [10] (ds² = -c² dt² + (1-2M/r) dr² + r² dΩ²). This invalidates the comparison between the λ ≠ 1 solutions and the λ=1 solutions, which is central to the paper's argument about the recovery of Newton's Law in the IR limit."
      },
      {
        "Problem": "Unverified satisfaction of Hamiltonian constraint for asymptotic solutions.",
        "Location": "Page 8, Section 3.3.",
        "Explanation": "In the analysis of the most general case (nonzero B and nonzero n), the authors derive asymptotic solutions for the shift function n(r) but explicitly state that they have not checked if these solutions satisfy the Hamiltonian constraint (Eq. 14). The Hamiltonian constraint is a fundamental equation of motion derived from varying the action with respect to the lapse function N. If the derived asymptotic solutions do not satisfy this constraint, they are not valid solutions of the theory, and the conclusions drawn from their form (specifically, the oscillating Newtonian potential) may be unfounded."
      },
      {
        "Problem": "Breakdown of asymptotic expansion validity in the λ → 1 limit.",
        "Location": "Page 9, Section 3.3.",
        "Explanation": "The asymptotic expansion used to analyze the solutions for nonzero B and nonzero n is stated to be valid for r ≫ rc, where rc ~ B/|λ-1|. As the IR limit λ → 1 is approached, the critical distance rc goes to infinity. This means the asymptotic analysis is only valid at increasingly large distances, and the region where Newton's Law is expected to be recovered (e.g., solar system scales) might fall outside the regime of validity of the derived solutions as λ gets close to 1. This makes drawing conclusions about the precise λ → 1 limit based on this expansion problematic."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 7782,
      "output": 619
    }
  },
  {
    "entry_id": 30,
    "retraction_id": "1505.02494v2",
    "paper_id": "1505.02494v1",
    "retraction_comment": "This paper has been withdrawn by the author due to crucial sign errors in Theorem 5 and equation (10)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Proposition 1 is flawed.",
        "Location": "Page 5, Proof of Proposition 1",
        "Explanation": "The proof incorrectly assumes that the summation in the definition of w_i for i in the set I can be restricted to indices in I. This step is only valid if x_j = 0 for all j not in I, which is not guaranteed by the definition of I or the problem conditions. This invalidates the conclusion that (lambda, x_I) is a generalized eigenpair of (A_I, B_I)."
      },
      {
        "Problem": "The proof of Lemma 3 is flawed.",
        "Location": "Page 8, Proof of Lemma 3",
        "Explanation": "The proof starts with the incorrect assumption that J_0 is a subset of J and J is a subset of J_1. J_0 and J_1 are defined based on the solution (lambda, x), while J is a fixed index set defining the problem (GEiCP-T)_J. There is no general requirement for this subset relationship to hold."
      },
      {
        "Problem": "The proof of Theorem 1 is invalid.",
        "Location": "Page 6, Proof of Theorem 1",
        "Explanation": "The proof relies directly on Proposition 1, which has a flawed proof. Therefore, the bound on the number of lambda-solutions derived in Theorem 1 cannot be considered proven by the arguments presented."
      },
      {
        "Problem": "The proof of Theorem 3 is invalid.",
        "Location": "Page 9, Proof of Theorem 3",
        "Explanation": "The proof relies directly on Lemma 3, which has a flawed proof. Therefore, the existence result for (GEiCP-T)_J with irreducible nonnegative tensors cannot be considered proven by the arguments presented."
      },
      {
        "Problem": "The proof of Theorem 9 (monotonic convergence) is incomplete.",
        "Location": "Page 15, Proof of Theorem 9",
        "Explanation": "The proof relies on the assumption that the new iterate x^(k+1) generated by the algorithm lies within an open neighborhood Sigma(x^k) where the objective function f(x) is convex. The algorithm uses a fixed step size (normalization), and there is no guarantee that this step size is small enough to keep the iterate within the region of local convexity. This gap invalidates the proof of monotonic increase of f(x^k) (and thus lambda(x^k))."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 15236,
      "output": 570
    }
  },
  {
    "entry_id": 31,
    "retraction_id": "1504.07542v2",
    "paper_id": "1504.07542v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial sign error in equation 9",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The self-consistency equation for the order parameter (Eq. 3) is presented without derivation and appears incorrect for the given Hamiltonian.",
        "Location": "Page 1, Eq. 3",
        "Explanation": "The paper states that Eq. 3 is derived from Eq. 2, which is merely a definition of the order parameter. The form of Eq. 3, particularly the terms involving 'v/|Δ|' inside the tanh argument and the denominator, is highly non-standard for a gap equation derived from the BCS Hamiltonian with an added linear external pair potential term (Eq. 1). The derivation of this fundamental equation is missing, and its unusual form suggests it may be incorrect, invalidating subsequent results based on it."
      },
      {
        "Problem": "The free energy functional (Eq. 21) is introduced without a valid derivation from the microscopic Hamiltonian.",
        "Location": "Page 4, Eq. 21",
        "Explanation": "The paper describes obtaining the free energy by adding a term related to the external potential (H_ext) to a known free energy. However, the form of the added term (stated as 2v/Uph |Δ|^2, later modified near T*c) does not correctly correspond to the contribution of the linear external potential term in the Hamiltonian (-v * sum(pair operators)) to the free energy in a mean-field or GL approximation. The free energy functional is the basis for all subsequent Ginzburg-Landau analysis and derived parameters (ξ, λ, χ, Hc1, Hc2), making its lack of rigorous derivation and apparent incorrect form a critical flaw."
      },
      {
        "Problem": "Inconsistent and confusing definition and role of critical temperatures.",
        "Location": "Pages 1, 3",
        "Explanation": "The paper introduces Tc as the critical temperature for the v=0 case (Eq. 12). It then introduces T*c (Eq. 17) as the temperature where the Δph component of the gap vanishes for v<0. However, on page 1, it is stated that for v<0, the gap Δ does not vanish at any temperature. This creates a contradiction and confusion regarding the true critical temperature and the behavior of the order parameter when the external potential is present."
      },
      {
        "Problem": "Derived Ginzburg-Landau parameters exhibit unusual and likely incorrect temperature dependencies.",
        "Location": "Page 5, Eqs. 28, 30",
        "Explanation": "Based on the questionable free energy functional, the derived correlation length ξ (Eq. 28) shows an unusual dependence on v and T (proportional to 1/sqrt(vT)), which is not typical for standard GL theory near a critical point. The Ginzburg-Landau parameter χ (Eq. 30) is found to diverge at T*c with a T^(3/2) prefactor. While a diverging χ indicates Type II behavior, the specific temperature dependence and the divergence itself are consequences of the potentially flawed free energy and derived parameters, casting doubt on this key conclusion."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 3897,
      "output": 688
    }
  },
  {
    "entry_id": 32,
    "retraction_id": "2012.10766v4",
    "paper_id": "2012.10766v3",
    "retraction_comment": "Propositions 3 and 4 are incorrect, and so is their proof. The proof requires the shifted convolution problem for the coefficients of the cusp forms, which is not presented here. The definition of the mollifier M(f,s) is wrong. It needs to be defined as a convolution inverse of the Fourier coefficients of the automorphic forms",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Algebraic error in the expansion of the squared difference in the proof of Proposition 4.",
        "Location": "Page 14, Proof of Proposition 4",
        "Explanation": "The identity |1 - z|^2 = |z|^2 - 1 - 1 + 1 is used in the form ∫ |1 - LM|^2 dt = ∫ |LM|^2 dt - T + O(T^{1/2+ε}). The correct expansion is ∫ |1 - LM|^2 dt = ∫ (1 - LM)(1 - LM) dt = ∫ (1 - LM - LM + |LM|^2) dt = T - ∫ LM dt - ∫ LM dt + ∫ |LM|^2 dt. Since ∫ LM dt = T + O(T^{1/2+ε}), the correct relation is ∫ |1 - LM|^2 dt = T - 2(T + O(T^{1/2+ε})) + ∫ |LM|^2 dt = -T + ∫ |LM|^2 dt + O(T^{1/2+ε}). The stated identity is incorrect and invalidates the subsequent argument that ∫ |1 - LM|^2 dt = o(1) requires ∫ |LM|^2 dt = T + o(1)."
      },
      {
        "Problem": "Missing core calculation for the mean square of the mollified L-function.",
        "Location": "Page 14-22, Proof of Proposition 4",
        "Explanation": "The proof of Proposition 4 requires showing that ∫ |L(f, σ0 + it)M(f, σ0 + it)|² dt = T + o(1). However, the paper presents a calculation (pages 17-22) for the twisted mean square ∫ L(f, 1/2+α+it) L(f, 1/2+β-it) w(t) dt, which is a different quantity. The calculation for the mean square of L(f,s)M(f,s) involving the mollifier M(f,s) is not provided, leaving a critical gap in the proof of Proposition 4 and consequently Theorem 1."
      },
      {
        "Problem": "Incomplete demonstration of zero covariance for the independence proof.",
        "Location": "Page 23-28, Proofs of Theorem 4, Lemma 10, Theorem 5, Lemma 11, Theorem 3",
        "Explanation": "The proof of independence (Theorem 3 and 4) relies on Lemma 1, which states that uncorrelated normal variables are independent. Joint normality is established via the moment method for linear combinations (Theorem 5, Lemma 11). For independence, the covariance between log|L(f_i, s)| and log|L(f_j, s)| for i≠j must be zero. While the moment calculation for the linear combination implicitly suggests zero covariance, the presented calculations (Lemma 10, Lemma 11) primarily focus on the diagonal terms contributing to the variance. The vanishing of cross-terms in the moment calculation that would explicitly demonstrate zero covariance between different L-functions is not clearly or completely shown."
      },
      {
        "Problem": "Unclear or potentially incorrect bound for the off-diagonal sum in the twisted mean square calculation.",
        "Location": "Page 22",
        "Explanation": "In the calculation related to the twisted mean square (part of the missing proof for Proposition 4), the sum Σ_{h,k<T^ε} (I_D^{(1)}(h,k) + I_D^{(2)}(h,k)) is bounded by T^{1/2+θ+ε} Σ_{h,k<T^ε} (hk)^{(1+θ)/2}. The paper then states this is << T^{1-ε} = o(T). Based on standard summation estimates, the sum Σ_{h,k<T^ε} (hk)^{(1+θ)/2} is approximately (T^ε)^2 (T^ε)^{(1+θ)/2} = T^{ε(2 + (1+θ)/2)}. The total bound would then be T^{1/2+θ+ε} T^{ε(2 + (1+θ)/2)} = T^{1/2+θ+ε(3 + θ/2)}. With θ=7/64, this exponent is 39/64 + ε(199/64), which is greater than 1/2. The claim that this bound is << T^{1-ε} appears inconsistent with the preceding terms, suggesting an error in the bound or its presentation."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 10613,
      "output": 1024
    }
  },
  {
    "entry_id": 33,
    "retraction_id": "1703.02535v2",
    "paper_id": "1703.02535v1",
    "retraction_comment": "Error in the diffusion constant of Theorem 2.2, equation (2.4) due to a delicate issue in the method of the proof which is not trivial to correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Key lemma for disordered system relies on numerical verification",
        "Location": "Lemma 4.9 (Page 26), Appendix B.2 (Page 30)",
        "Explanation": "The lower bound of Lemma 4.9, which is a crucial inequality used in the proofs of the main theorems for the disordered system (Theorems 2.7 and 2.8), is stated as being verified numerically rather than proven rigorously. This makes the proofs of Theorems 2.7 and 2.8 mathematically unsound as presented."
      },
      {
        "Problem": "Proofs for non-disordered system properties may rely on unproven conjectures",
        "Location": "Lemmas 4.2, 4.3 (Page 22), Theorems 2.3, 2.4 (Page 12), Remark 4.1 (Page 22)",
        "Explanation": "The proofs of Lemmas 4.2 and 4.3, which establish properties of the renormalization map essential for the non-disordered system theorems (2.3 and 2.4), rely on conditions (e.g., 2KRV'(2KR) < 1) that appear to stem from the conjecture about the strict concavity of Vμ(λ) (Remark 4.1). This conjecture is stated as only proven for 'narrow' disorder, potentially leaving the proofs incomplete for general interaction parameters."
      },
      {
        "Problem": "Proof of strict monotonicity in disorder spread is incomplete",
        "Location": "Theorem 2.9 (Page 14), Lemma A.1 (Page 27)",
        "Explanation": "Theorem 2.9 claims that synchronization level is strictly smaller for strictly more spread-out disorder. The proof of the supporting Lemma A.1 shows a key quantity Δ is less than or equal to zero (Δ ≤ 0), which implies non-increasing behavior. However, establishing the *strictly* smaller claim requires proving Δ < 0, which is not rigorously shown in the provided proof."
      },
      {
        "Problem": "Main theorems for disordered system are stated under a potentially limiting assumption",
        "Location": "Section 2 introduction (Page 10), Theorems 2.6, 2.7, 2.8 (Pages 13-14)",
        "Explanation": "The main results for the disordered system (Theorems 2.6, 2.7, 2.8) are stated under the assumption that the disorder is small. While the authors suggest this assumption might be redundant, its necessity for the proofs is not explicitly disproven, limiting the proven generality of these theorems to the small disorder regime."
      },
      {
        "Problem": "Criteria for universality classes are not sharp",
        "Location": "Theorem 2.3 (Page 12), Theorem 2.7 (Page 14), Figure 5 (Page 12)",
        "Explanation": "Theorems 2.3 and 2.7 provide only sufficient conditions for universality classes (1) and (3). The paper explicitly states these criteria are not sharp, and the critical surface separating universality class (2) is not fully characterized, indicating that the provided conditions do not precisely delineate the boundaries between all universality classes."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 5848,
      "output": 725
    }
  },
  {
    "entry_id": 34,
    "retraction_id": "1611.01102v3",
    "paper_id": "1611.01102v2",
    "retraction_comment": "The paper fails to appreciate that the necessitation rule is tacitly presupposed in the formulation of the Girle-Priest tableau rules. If those presuppositions were made explicit, the proofs of this paper would depend on a use of necessitation, contra what was claimed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Formal error in applying the Box-Elimination rule.",
        "Location": "Page 3-4, 'Argument that q is false', Step (11)",
        "Explanation": "The step infers `q = ~□q` in world `k` from `(Def) (q = ~□q) (n)` and `nAk` using the □-Elim rule. However, the □-Elim rule, as stated on page 2, applies to formulas of the form `□p`. The formula `q = ~□q` is not of this form. The application of the rule here is formally incorrect based on the rules provided."
      },
      {
        "Problem": "Implicit and unjustified assumption of the necessity of the definition.",
        "Location": "Page 3-4, 'Argument that q is false', Step (11)",
        "Explanation": "The derivation of the contradiction in world `k` requires the equivalence `q = ~□q` to hold in world `k`. The proof attempts to derive this from the definition holding in world `n` and `nAk`. This step is only valid if the definition `q = ~□q` is assumed to be a necessary truth (or true in all worlds accessible from `n`), allowing `□(q = ~□q)` to be inferred and then □-Elim applied. This crucial assumption is not explicitly stated or justified in the proof steps, and the formal step used is incorrect."
      },
      {
        "Problem": "Questionable admissibility of the self-referential definition within standard modal logic.",
        "Location": "Page 1, Section 2; Page 4, Section 3",
        "Explanation": "The paradox is constructed using a proposition `q` defined by the self-referential equivalence `q = ~□q`. Standard propositional modal logic does not typically provide mechanisms for introducing propositions defined in this self-referential manner within the object language. While the author claims such a definition is admissible, its introduction as a standard premise `q = ~□q` into the system is the source of the inconsistency, suggesting that the standard framework is not equipped to handle such definitions without extension or modification (e.g., using fixed-point semantics)."
      },
      {
        "Problem": "Mischaracterization of the impact on soundness proofs.",
        "Location": "Page 4, Section 3 'Whither Soundness?'",
        "Explanation": "The author concludes that the paradox implies soundness proofs for systems T and stronger depend on inconsistent premises. However, the paradox arises from adding the specific, self-referential premise `q = ~□q` to the system. This shows that the system *plus* this premise is inconsistent. It does not necessarily invalidate the soundness proof for the system *without* this premise, which demonstrates soundness for standard formulas and propositions. The issue lies with the premise `q = ~□q` itself, not necessarily with the standard axioms and rules of T."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 5784,
      "output": 652
    }
  },
  {
    "entry_id": 35,
    "retraction_id": "2205.15802v2",
    "paper_id": "2205.15802v1",
    "retraction_comment": "The proof of Theorem 3 is wrong: in the display equation below Equation (22), bottom of page 15, the gradient of $\\phi_{t+1}$ is missing a factor $1/(\\alpha\\eta_t)$",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Discrepancy between claimed regret bound and derived bound for arbitrary comparators.",
        "Location": "Page 4, Theorem 5 (Eq 14)",
        "Explanation": "The paper claims that AdaTask achieves the target regret bound L||U||_S(1) √T/N up to logarithmic factors in T and ||U||_S(1) for any comparator U ∈ R^{N×d}. However, the derived bound in Theorem 5 includes an additional term L/√N. This term is not a logarithmic factor and can dominate the target bound, especially when ||U||_S(1) is small, thus weakening the theoretical guarantee compared to the stated claim."
      },
      {
        "Problem": "High computational cost per step not fully justified empirically.",
        "Location": "Algorithm 1, Proposition 7, page 9",
        "Explanation": "The algorithm requires computing the Singular Value Decomposition (SVD) of an N x d matrix H_{t-1} at each time step. While the paper mentions faster updates for rank-one changes, the cost is still potentially O(Nd) or higher per step. This is significantly more expensive than the O(Nd) cost of updating N vectors in baselines like independent learning. The paper does not provide empirical runtime comparisons to demonstrate practical feasibility or justify this overhead relative to the observed performance gains."
      }
    ],
    "token_usage": {
      "input": 6832,
      "thinking": 18918,
      "output": 308
    }
  },
  {
    "entry_id": 36,
    "retraction_id": "2006.05804v2",
    "paper_id": "2006.05804v1",
    "retraction_comment": "Lemma 2.2 is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The method for summing angular regularity contributions in bilinear estimates appears unsound.",
        "Location": "Page 6, Section 1.7; Page 12, Section 4",
        "Explanation": "The paper attempts to handle the summation over angular frequencies (l_0, l_1, l_2) in bilinear estimates using an inequality like sum l_0^{sigma_0} ||H_{l_0} (H_{l_1} u_1 * H_{l_2} u_2)||_{L^2} <= ||<Omega>^{sigma_0} u_1|| ||<Omega>^{sigma_0} u_2||. This inequality is not standard and lacks justification. Standard estimates for products of spherical harmonics do not typically yield such a gain in angular regularity norms of the factors. This issue is critical as the paper relies on angular regularity to achieve scaling critical well-posedness for terms lacking null structure."
      },
      {
        "Problem": "Lemma 2.2, central to the angular regularity argument, is stated incorrectly or refers to an undefined space.",
        "Location": "Page 10, Lemma 2.2",
        "Explanation": "Lemma 2.2 is stated as ||P_{K_{N,L}} H_l u||_{L^2} <= N^{-1/2} L^{-1/2} l^{-1/2} ||P_{K_{N,L}} H_l u||_{H^{1/2,1/2}_{1/2}}. The space H^{1/2,1/2}_{1/2} is not defined in the paper. Assuming it refers to the Besov space B^{1/2,1/2}_{1/2}, the inequality seems to be a misstatement of the norm definition or a non-standard embedding/interpolation result without proof or reference. The application of this lemma in the bilinear estimates (Section 4) also appears inconsistent with the definition of the Besov norm used."
      },
      {
        "Problem": "The formulation of the sums representing bilinear estimates in Section 4 is incorrect or incomplete.",
        "Location": "Page 12, Definition of I^1(N, L); Page 14, Definition of I^2(N, L); Page 15, Definition of I^3(N, L)",
        "Explanation": "The expressions defined as I^1(N, L), I^2(N, L), and I^3(N, L) (e.g., I^1(N, L) := sum_{N_0, L_0} N_0^{-1/2} L_0^{-1/2} C_{N_0, L_0}^{012} ||phi_1||_{N_1, L_1, l_1} ||phi_2||_{N_2, L_2, l_2}) are missing crucial components. They do not include the L^2 norm of the projected product of the functions (with derivatives where applicable) and are missing summations over all relevant dyadic variables (N_j, L_j, l_j for j=0, 1, 2). This makes it impossible to verify the subsequent steps in the proofs of the bilinear estimates."
      },
      {
        "Problem": "The claim of achieving scaling critical regularity for terms without null structure relies on potentially flawed angular regularity arguments.",
        "Location": "Page 1, Abstract; Page 6, Section 1.7; Page 13, Remark 4.1; Page 14, Remark 4.2",
        "Explanation": "The paper explicitly states that terms like [phi, d_nu phi] in YMH have no null structure and that the Dirac bilinear term psi-bar gamma_nu psi is treated without exploiting its null structure. The strategy to overcome the resulting loss of regularity and reach scaling critical spaces is based on imposing extra weighted angular regularity and using Lemma 2.2. Given the issues identified with the angular summation technique and the statement of Lemma 2.2, the mechanism proposed to achieve the claimed regularity is not convincingly demonstrated."
      },
      {
        "Problem": "Errors in the formulation of higher-order estimates.",
        "Location": "Page 15, Estimates (5.1), (5.2), (5.3)",
        "Explanation": "The statement of the trilinear estimate (5.2), ||[d_mu phi, [A_nu, phi]]||_{B^{-1/2, -1/2}_{sigma_0}} <= C ||A|| ||phi|| ||phi||, contains apparent errors. The left side involves a trilinear term, while the right side is presented as a product of only two norms. Furthermore, the indices and the specific norms on the right side do not match the structure of the term on the left. While the paper claims higher-order terms are easier, this specific error raises concerns about the correctness of the detailed estimates for these terms."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 13482,
      "output": 1104
    }
  },
  {
    "entry_id": 37,
    "retraction_id": "1708.02698v3",
    "paper_id": "1708.02698v2",
    "retraction_comment": "It turns out that there is an error in the argument for the curve case in Lemma 2.5 which makes the main result (Theorem 2.4) partially incorrect. We will post a modified version of the paper in which this is fixed. Meanwhile we withdraw the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The base case of the induction in the proof of Theorem 2.4 is not justified.",
        "Location": "Page 16, Proof of Theorem 2.4, first paragraph of the inductive step.",
        "Explanation": "The proof assumes that the initial algebra R (denoted as A in the first step of the induction) has a G_m action such that the origin is in the interior of the moment polytope, which is equivalent to the stable locus being non-empty. This property is not guaranteed for an arbitrary finitely generated positively graded algebra R, and it is not part of the theorem's assumptions on R. The inductive step relies on this property to apply Lemma 2.5."
      },
      {
        "Problem": "The proof of Theorem 1.6 contains an incorrect derivation of a key inclusion.",
        "Location": "Page 9, Proof of Theorem 1.6, claim (4) and subsequent argument.",
        "Explanation": "The proof attempts to show p^(mn) \\subset x^n R. From uy \\in x^mn R for u \\in R \\setminus p, the proof correctly deduces y \\in x^m R. This shows p^(mn) \\subset x^m R, not p^(mn) \\subset x^n R as required for the inclusion A[m] \\subset B. While the required inclusion p^(n) \\subset x^n R (when m=v(x)=1) might be true under the given conditions, its proof is missing or incorrect in the text."
      },
      {
        "Problem": "The argument for twisting the torus action in the inductive step of Theorem 2.4 appears confused.",
        "Location": "Page 16-17, Proof of Theorem 2.4, argument starting with 'Now let us consider the associated graded algebra B = gr_v(R(i))...'",
        "Explanation": "The algebra B = gr_v(R(i)) has a Z-grading from the filtration and a G_m^i-action (corresponding to the original grading of R(i)). This gives B a (Z x Z^i)-grading and a G_m^{i+1} action. The moment polytope is in R^{i+1}. The proof introduces a subalgebra B' defined using the 'original grading' of B, which is ambiguous. The subsequent definition of the twisted action pi' on B' and the calculation of its moment polytope Delta(B', pi') = n Delta(B, pi_beta) - alpha seem inconsistent with the structure of B and B'. This step is crucial for the induction to proceed by guaranteeing a non-empty stable locus."
      },
      {
        "Problem": "Example 2.6, intended to illustrate the proof of Theorem 2.4, contains significant errors.",
        "Location": "Page 17, Example 2.6.",
        "Explanation": "For R=k[x,y,z] and p=(x), the associated graded ring gr_p(R) is isomorphic to k[y,z][t], not S/(y^2z - x^3). The example incorrectly identifies this with the associated graded ring from Example 1.4 (cuspidal cubic). The example's calculations and conclusions based on this incorrect identification are invalid, suggesting a potential misunderstanding of the construction steps being illustrated."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 19720,
      "output": 747
    }
  },
  {
    "entry_id": 38,
    "retraction_id": "1201.3873v3",
    "paper_id": "1201.3873v2",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial gap in the estimates for m>=4",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula used for the Bohnenblust-Hille norm",
        "Location": "Section 2, formula for f2 numerator; Section 3, formula for g4 numerator; Section 4, formula for g6 numerator",
        "Explanation": "The paper attempts to calculate the Bohnenblust-Hille norm ||P||_BH = (sum |alpha_a|^p)^(1/p) with p = 2m/(m+1). For m=2, the correct power is p=4/3. The formula used in f2 is based on (|a|^2 + |b|^2 + |c|^2)^(3/2), which is incorrect. Similar errors in the power or the sum of coefficients are present in the formulas for g4 (m=4, p=8/5) and g6 (m=6, p=12/7), invalidating the calculation of the BH norm and thus the lower bounds."
      },
      {
        "Problem": "Incorrect identification of polynomial coefficients for BH norm calculation",
        "Location": "Section 3 (Case m=4), formula for g4 numerator; Section 4 (Case m>=6), formula for g6 numerator",
        "Explanation": "For polynomials constructed as powers P_m = (P2)^n, the Bohnenblust-Hille inequality applies to the coefficients of the expanded polynomial P_m in the standard basis z^a. The paper calculates the BH norm using terms related to the coefficients of P2 (a, b, c) and the power n directly in the BH norm formula, rather than first finding the actual coefficients of P_m and applying the BH norm definition to them. This is a misapplication of the inequality."
      },
      {
        "Problem": "Lower bounds and derived constant C are based on incorrect calculations",
        "Location": "Section 2, 3, 4, 5",
        "Explanation": "The numerical lower bounds presented for Dm (e.g., D2 >= 1.1066, D4 >= 1.131) and the derived lower bound for the hypercontractivity constant C (C > 1.0845) are calculated using the incorrect formulas for the Bohnenblust-Hille norm and its application to the constructed polynomials. Therefore, these quantitative results and any conclusions drawn from them (like the suggested exponential growth) are not rigorously established."
      },
      {
        "Problem": "Flawed proof of the norm formula for P2",
        "Location": "Section 2, Proof of Proposition 1",
        "Explanation": "The proof attempts to calculate the norm ||P2|| = sup{|az1^2 + bz2^2 + cz1z2| : max{|z1|, |z2|} = 1} by reducing the supremum over θ1, θ2 (where z1=e^(iθ1), z2=e^(iθ2)) to a supremum over a single variable θ = θ1 - θ2. This reduction is not generally valid for arbitrary a, b, c and does not cover the entire boundary set where the supremum is attained, making the provided proof unsound."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 4886,
      "output": 713
    }
  },
  {
    "entry_id": 39,
    "retraction_id": "1006.2189v2",
    "paper_id": "1006.2189v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The proof of the verification of axiom 1 for the smoothing functor that is given in the paper is false, since it would violate what is known in dimension 4. If U is a subset of V and both are diffeomorphic to R^4, then the restriction map of smoothing spaces sm(V) -> sm(U) need not be one-to-one on path components. Thus axiom 1 is violated in dimension 4. The verification of axiom 1 in higher dimensions is probably a consequence of the product structure theorem",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed deduction of Theorem 5.3 on smoothings of N x S^1.",
        "Location": "Page 13, Deduction of Theorem 5.3",
        "Explanation": "The deduction relies on a claimed homotopy fiber sequence Sm(N x I) -> Sm(N x S^1) -> Sm(N x R) and a claimed section for the second map. While Sm(N x I) is the fiber of this sequence, the existence of a section implies Sm(N x S^1) is homotopy equivalent to the product Sm(N x I) x Sm(N x R). This contradicts the conclusion of Theorem 5.3, Sm(N x S^1) ~ Sm(N x I) x Omega Sm(N x I), when combined with Corollary 4.8 (Sm(N x I) ~ Omega Sm(N x R)), unless the spaces involved are trivial. The logical steps connecting the fiber sequence, the section, Corollary 4.8, and Theorem 5.3 appear inconsistent."
      },
      {
        "Problem": "Incorrect construction in the proof sketch for Lemma 2.1.",
        "Location": "Page 4, Proof of Lemma 2.1",
        "Explanation": "The proof attempts to construct a k-simplex of Sm(U) from a k-simplex (tau, sigma) of Sm(U) x Delta[1]. A k-simplex of Sm(U) is a smooth bundle W' -> Delta^k and a fiber-preserving homeomorphism h': W' -> U x Delta^k. The proposed construction V = tau^{-1} H_sigma(U x Delta^k) results in a subset of the original smooth bundle W (where tau: W -> U x Delta^k is the fiber-preserving homeomorphism h), not a smooth bundle over Delta^k with a map to U x Delta^k. The construction does not yield a valid k-simplex in Sm(U)."
      },
      {
        "Problem": "Insufficient justification for the homotopy pullback step in the proof of Proposition 3.5.",
        "Location": "Page 8, Proof of Proposition 3.5",
        "Explanation": "The proof claims that the excision property for open sets (the square involving Sm(V1 U V2), Sm(V1), Sm(V2), Sm(V1 intersect V2) being a homotopy pullback) follows from the corresponding property for compact subsets (Sm(K1 U K2), Sm(K1), Sm(K2), Sm(K1 intersect K2) forming a homotopy pullback). This step relies on Sm(V) being the homotopy colimit of Sm(K) over compact K in V. Passing a homotopy pullback property from a system over compact sets to its homotopy colimit over open sets requires careful justification regarding the interaction of homotopy colimits and pullbacks, which is not provided and is generally non-trivial."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 9320,
      "output": 643
    }
  },
  {
    "entry_id": 40,
    "retraction_id": "1207.1467v2",
    "paper_id": "1207.1467v1",
    "retraction_comment": "This paper has been withdrawn due to a logica error in equation 1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of Bird et al. model and 'enhanced diffusion'",
        "Location": "Section 3.1, Conclusions",
        "Explanation": "The paper claims that the Bird, Lightfoot, and Stewart model (specifically equation 3.10, derived under the assumption of stagnant inert gas) 'falsely reports enhanced diffusion'. This is a misinterpretation. Equation (3.10) correctly describes diffusion in the frame of reference where the inert species is stagnant. The 'enhancement' observed is the Stefan flow, a real physical phenomenon arising from unequal molar fluxes, which is captured by the advective term in the bulk-velocity frame (equation 2.6) or by the non-linear term in the stagnant-inert frame (equation 3.10). The paper's own derivation from (3.12) to (3.13) correctly shows the mathematical equivalence between the two formulations when all terms are included, but the conclusion that (3.10) is 'false' or that the enhancement is 'falsely reported' is incorrect. The issue is one of interpreting results in different frames of reference, not a fundamental error in the Bird model itself."
      },
      {
        "Problem": "Flawed Order of Magnitude Analysis for Advection-Dominated Case",
        "Location": "Section 4, equations (4.14) and (4.15)",
        "Explanation": "In Section 4, which considers situations where the Péclet number Pe > 1 (advection-dominated), the order of magnitude analysis for the momentum equation terms (4.14, 4.15) uses a characteristic velocity scale appropriate for Pe ~ 1 (vc ~ D/L). This leads to the conclusion that velocity and gravity terms are negligible in the momentum equation for relevant scales. This contradicts the premise of significant advection (Pe > 1), which implies a characteristic velocity vc much larger than D/L. The analysis is inconsistent with the scenario being considered in Section 4 and invalidates the conclusion that natural convection effects are negligible when Pe > 1."
      },
      {
        "Problem": "Unsound Dismissal of Chemical Potential as a Natural Descriptor",
        "Location": "Abstract, Section 2.2, Conclusions",
        "Explanation": "The paper states that chemical potential 'does not yield a more mathematically natural set of transport equations for diffusion dominated systems' and that this is 'contrary to the typically accepted thermodynamic definition'. This dismisses the fundamental thermodynamic basis of diffusion, which is driven by gradients in chemical potential. While the resulting transport equations might take similar forms depending on the chosen dependent variable (density, humidity, chemical potential), the statement that chemical potential is not a 'more mathematically natural' descriptor or that the result contradicts thermodynamic definitions is poorly justified and unsound. The derivation in Section 2.2 correctly shows Fick's law can be expressed in terms of chemical potential gradient (2.11), consistent with thermodynamics."
      },
      {
        "Problem": "Inconsistent Explanation of Bird Model Derivation and Advective Term",
        "Location": "Section 3.1, equation (3.4)",
        "Explanation": "The paper states that the Bird model (3.10) is derived from (3.4) by setting the advective term to zero, referring to ∇ · (ρ⁹v⁹ᵃ). While setting v⁹ᵃ ≈ 0 (stagnant inert gas) is the standard assumption leading to the non-linear term in the stagnant-inert frame, the paper's phrasing is confusing. It then correctly shows that *not* setting ∇ · (ρ⁹v⁹ᵃ) = 0, but using the relationship (3.12) derived from mass conservation and Fick's law, leads back to the linear advection-diffusion equation (2.6) in the bulk-velocity frame. This inconsistency in explaining the derivation of (3.10) from (3.4) contributes to the overall confusion regarding the Bird model and its relationship to the linear diffusion equation."
      },
      {
        "Problem": "Lack of Clear Distinction and Consistent Use of Frames of Reference",
        "Location": "Sections 2, 3, 4",
        "Explanation": "The paper discusses different velocities (species velocity v⁹ʲ, diffusive velocity v⁹ʲ,⁹, bulk velocity v⁹, inert species velocity v⁹ᵃ) and implicitly uses different frames of reference (fixed frame, stagnant inert frame, bulk velocity frame). However, it does not clearly define which equations are valid in which frame or consistently apply them. This lack of clarity, particularly in the comparison between the Bird model (derived in the stagnant-inert frame) and the linear diffusion model (typically applied in the bulk-velocity frame), leads to confusion and supports the paper's incorrect claim that the Bird model 'falsely reports' enhancement."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 3225,
      "output": 1057
    }
  },
  {
    "entry_id": 41,
    "retraction_id": "1503.03121v2",
    "paper_id": "1503.03121v1",
    "retraction_comment": "This paper has been withdrawn by the author because the duality is indefensible speculation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of mechanism for jettisoning matter and black holes to the extroverse.",
        "Location": "Abstract, Section 1, Section 4",
        "Explanation": "The core mechanism for entropy reduction in the introverse, crucial for infinite cyclicity, relies on the assumption that all matter, including black holes, is jettisoned to the extroverse at turnaround. The paper states this assumption but provides no physical mechanism or justification for how this process occurs, especially for black holes which contain the vast majority of the universe's entropy. This leaves the central premise of the CBE model's entropy argument unsupported."
      },
      {
        "Problem": "Inconsistent definition of the contracting scale factor.",
        "Location": "Section 2, Eq (14)",
        "Explanation": "The contracting scale factor is defined as directly proportional to the expanding scale factor, `a_hat(t) = f(t_r) a(t)`. This implies their rates of change are proportional. However, the paper later describes the contraction rate as 'far more gradual' than the expansion rate, which contradicts this proportional relationship. This inconsistent definition is fundamental to the scale factor matching calculation used to determine the cyclic period."
      },
      {
        "Problem": "Unjustified assumption of radiation-dominated contraction throughout the relevant period.",
        "Location": "Section 2, Eq (20)",
        "Explanation": "The calculation of the turnaround time and cyclic period assumes that the contracting universe's scale factor follows a radiation-dominated power law (t^(1/2)) throughout the phase relevant for matching (from t_r down to t_m). If the contraction is the time-reverse of the expansion, it should include phases corresponding to dark energy and matter domination before becoming radiation-dominated near the bounce. Assuming radiation domination throughout this period is inconsistent with the time-reversal idea and is essential for the calculated period of 2.6Ty."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 2990,
      "output": 428
    }
  },
  {
    "entry_id": 42,
    "retraction_id": "2405.12710v3",
    "paper_id": "2405.12710v2",
    "retraction_comment": "The author has withdrawn this paper due to a critical definitional error in concept learning for global/local-interaction learning during training. This error led to an alignment issue with the definition of the text-video retrieval task, causing an unfair comparison with state-of-the-art (SOTA) methods. Consequently, this hindered the accurate evaluation of the paper's contributions",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misleading Efficiency Claim based on Partial FLOPS",
        "Location": "Abstract, Introduction (Page 1), Table I (Page 5), Table V (Page 8), Performance Comparisons (Page 6)",
        "Explanation": "The paper claims the method is 'nearly 220 times faster' than SOTA methods based on FLOPS reported in Table I. However, these FLOPS are only for the 'similarity calculation head' (Table I). The total computational cost for retrieval includes encoding all videos and the query, which is a significant part of the process. Table V shows the total inference time, where GLSCL is faster than some SOTA methods but not by a factor of 220, and is even slower than some baselines like DiCoSA. Basing the primary efficiency claim on partial FLOPS is misleading regarding the overall retrieval speed."
      },
      {
        "Problem": "Potentially Unsound or Confusing Inter-Consistency Loss (ICL) Formulation",
        "Location": "Section III-D (Page 4), Equations 6, 7, 8",
        "Explanation": "The Inter-Consistency Loss (ICL) aims to align corresponding visual and textual concepts (c^v_i, c^t_i). It combines minimizing the Euclidean distance (Eq 6) and forcing the dot product similarity to a target value λ (Eq 7) for the *same* positive pairs. Forcing a specific dot product value (Eq 7) is different from minimizing Euclidean distance (Eq 6), which for normalized vectors is equivalent to maximizing dot product. The combination of these two objectives for positive pairs, especially without explicitly stating vector normalization, seems potentially conflicting or redundant. Furthermore, the explanation of Eq 7 as a 'semantic regularization by constraining the positive video-text concepts in a suitable margin' is confusing, as margin losses typically involve negative samples, which are absent in this formulation. This loss design is either flawed or poorly justified."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 4643,
      "output": 430
    }
  },
  {
    "entry_id": 43,
    "retraction_id": "1305.5284v3",
    "paper_id": "1305.5284v2",
    "retraction_comment": "This paper has been withdrawn by the author due to missing phase-space factor in eq(1)/(2), thus the whole structure is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The argument for Glasma being a pure gluon plasma at high temperature relies on thermal distribution functions.",
        "Location": "Page 2, Equations (1) and (2) and surrounding text.",
        "Explanation": "Glasma is described as a pre-equilibrium phase, existing before thermal equilibrium is reached. Applying thermal statistics (like Bose-Einstein and Fermi-Dirac distributions) to a non-thermal state is fundamentally unsound and contradicts the paper's own premise about Glasma."
      },
      {
        "Problem": "The paper claims that Glasma has zero photon and dilepton emission.",
        "Location": "Page 2, text below equations (1) and (2), and the table.",
        "Explanation": "The claim is based on the absence of quarks and listing only thermal production processes. However, non-equilibrium states with strong color fields and highly occupied gluons (like Glasma) can have non-thermal emission mechanisms (e.g., bremsstrahlung, production from fields) which are not considered, making the claim of zero emission likely incorrect."
      },
      {
        "Problem": "The explanations for heavy ion puzzles depend on the assumption of zero electromagnetic emission from Glasma.",
        "Location": "Page 2, text below the table.",
        "Explanation": "The proposed solutions to the puzzles (e.g., enhanced photon/dilepton v2) critically rely on the Glasma phase having no EM emission. Since the claim of zero emission is likely unsound (as per Problem 2), the explanations based on this property are also undermined."
      },
      {
        "Problem": "Glasma is proposed as a candidate for dark matter and dark energy based on properties derived from heavy ion collisions.",
        "Location": "Page 2-3, sections on astrophysics and cosmology.",
        "Explanation": "Extrapolating the properties of a transient, microscopic, strongly interacting plasma from heavy ion collisions to explain cosmological phenomena over vast scales and timescales is highly speculative. Glasma's properties (hot, dense, relativistic) do not align well with standard models of dark matter (typically non-relativistic/weakly interacting) or dark energy (associated with negative pressure/cosmological constant)."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 2300,
      "output": 484
    }
  },
  {
    "entry_id": 44,
    "retraction_id": "2307.11176v2",
    "paper_id": "2307.11176v1",
    "retraction_comment": "There is an irrecoverable error in Lemma 2.5. There are counterexamples even in case R=Q[x]. The lemma is crucial for the rest of the paper and it does not work unless strong assumptions are made (like: the modules are graded)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of filtration on M in Lemma 6.1",
        "Location": "Lemma 6.1, page 8",
        "Explanation": "The filtration on M = R[w,w-1] tensor_{R[w]} Mo is defined as FiM = U_{j>=0} w^{i-j} FjMo. For M to be a regularly Z-filtered module, FiM must be a left R[w,w-1]-submodule of M for all i, and satisfy wFiM = Fi+1M. The defined FiM is a union of R[w]-submodules, but not necessarily an R[w,w-1]-submodule. Furthermore, the condition wFiM = Fi+1M does not hold in general for a stably Z>0-filtered Mo where wFjMo = F_{j+1}Mo only for j >= j0."
      },
      {
        "Problem": "Flawed proof of Lemma 4.2 in the non-commutative case",
        "Location": "Lemma 4.2, page 6",
        "Explanation": "The proof relies on the existence of an element p in R[w,w-1] such that p(1-w)yn = yn, derived from the condition (1-w)Mn = Mn where Mn is a cyclic left R[w,w-1]-module generated by yn. In a non-commutative ring, (1-w)Mn = Mn implies (1-w) has a left inverse modulo the left annihilator of yn, not necessarily a right inverse acting on yn. This step is crucial for the subsequent argument using the associated graded module and its annihilator."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 16449,
      "output": 383
    }
  },
  {
    "entry_id": 45,
    "retraction_id": "0804.4876v3",
    "paper_id": "0804.4876v2",
    "retraction_comment": "A counterexample to Theorem 1.2 has been pointed out to the author (x^2+3 reduced modulo 2). The mistake cannot be corrected at this time",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect statement of the Generalized Kummer-Dedekind Theorem",
        "Location": "Theorem 1.2 (Page 2)",
        "Explanation": "Theorem 1.2 claims that for any prime ideal p, the factorization exponents (e_i) and degrees (f_i) of a polynomial c(x) modulo p are equal to the ramification indices (e(Pi|p)) and residual degrees (f(Pi|p)) of the prime ideals Pi above p in the number field extension K. The equality e_i = e(Pi|p) is generally false. The standard Kummer-Dedekind theorem relates f_i to f(Pi|p) and the number of factors to the number of primes, typically under conditions where p is unramified in K and does not divide the index [O_K : O_k[alpha]]. The theorem's claim to lift 'all constraints' is not supported by standard results."
      },
      {
        "Problem": "Fundamental error in the proof setup for Theorem 1.2",
        "Location": "Proof of Theorem 1.2, Notation section (Page 10)",
        "Explanation": "In the notation section for the proof of Theorem 1.2, the set R_i is defined as the set of roots of the polynomial factor c_i, which has degree f_i. However, the size of this set is incorrectly stated as |R_i| = e_i f_i. The number of roots of a polynomial of degree f_i is f_i, not e_i f_i. This fundamental error in defining the size of the set of roots invalidates the subsequent steps of the proof that rely on this size to establish relationships with prime splitting properties."
      },
      {
        "Problem": "Incorrect statement of the Generalized Lagarias Theorem",
        "Location": "Theorem 1.1 (Page 1)",
        "Explanation": "Theorem 1.1 claims that two unramified primes p1 and p2 have the same splitting types throughout intermediate fields if and only if their associated Frobenius automorphisms phi1 and phi2 have cyclic decomposition groups <phi1> and <phi2> that are conjugate in the Galois group G. The correct condition for two unramified primes to have the same splitting type in any intermediate field is that their Frobenius elements phi1 and phi2 are conjugate in G, not that their cyclic subgroups <phi1> and <phi2> are conjugate. Conjugacy of cyclic subgroups is a stronger condition than conjugacy of elements."
      },
      {
        "Problem": "Misapplication of Proposition 3.7 in the proof of Theorem 1.2",
        "Location": "Proof of Theorem 1.2, Step 2 (Page 11)",
        "Explanation": "The proof attempts to establish a D-isomorphism between the set of roots R_i (claimed size e_i f_i) and a D-orbit on H\\G corresponding to a prime P_i (size e(P_i|p)f(P_i|p) by Proposition 3.7). This leads to the incorrect conclusion e_i f_i = e(P_i|p)f(P_i|p). The step misapplies Proposition 3.7 and incorrectly relates the size of the set of roots of a polynomial factor modulo p to the size of a D-orbit on H\\G."
      },
      {
        "Problem": "Misapplication of Proposition 3.8 in the proof of Theorem 1.2",
        "Location": "Proof of Theorem 1.2, Step 3 (Page 11)",
        "Explanation": "The proof attempts to establish an E-isomorphism between a single root R_ij (size 1) and an E-orbit on H\\G (claimed size |E\\E_i|). This step, combined with the incorrect notation for R_ij (claimed size e_i), leads to the incorrect conclusion e_i = |E\\E_i|. The step does not correctly relate the action of the inertia group E to the ramification index e(P_i|p) or the polynomial exponent e_i."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 12899,
      "output": 928
    }
  },
  {
    "entry_id": 46,
    "retraction_id": "2105.09970v2",
    "paper_id": "2105.09970v1",
    "retraction_comment": "The proof of the main Lemma (3.11, section 3.4) is incomplete: in the middle of page 22, the fact that $\\gamma$ is weakly distributive is not sufficient to justify the chain of two inclusions used to invoke Proposition 2.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flaw in the proof of the fixed-point lemma (Lemma 3.13)",
        "Location": "Section 3.5, Lemma 3.13 (Page 26-27)",
        "Explanation": "The proof claims that the sequence of algebras Dⁿ has a fixed point because the sequence of pairs (Nⁿ⁻¹, vⁿ⁻¹) has a fixed point, where Nᵏ⁻¹ is the horizontal monoid of Mᵏ⁻¹ and vᵏ⁻¹ is the homomorphism A∆ → Nᵏ⁻¹. However, the construction of Mⁿ (and thus Dⁿ) depends on the entire sequence of previous algebras/homomorphisms (μ₁, ..., μⁿ⁻¹), not just the last one. The repetition of (Nᵏ⁻¹, vᵏ⁻¹) only implies that μᵏ⁻¹(A∆) and the homomorphism from A∆ repeat, not that the sequence (μ₁, ..., μᵏ⁻²) repeats in a way that guarantees μᵏ = μᵏ⁻ʲ. This breaks the argument for the termination of the algorithm."
      },
      {
        "Problem": "Ambiguity/potential inconsistency in the definition of the threshold congruence for vectors",
        "Location": "Section 2.4 (Page 8), Section 3.3.1 (Page 19)",
        "Explanation": "The threshold-τ integer congruence ≡τ is defined for integers. It is then used for vectors in [τ]ᴾ (an additive semigroup) in the definition of the relations ≈ⁿ and <ⁿ. The text states \"m ≡τ n are used indifferently, while m ≤ n is a shorthand for ∀p: mₚ ≤ nₚ\". This suggests m ≡τ n means m=n for vectors. If this is the case, the threshold τ plays no role in the relations ≈ⁿ and <ⁿ beyond bounding the size of the counter set P, which seems incorrect for threshold counters. If ≡τ for vectors means component-wise ≡τ for integers, then using it \"indifferently\" with equality is wrong, and proofs relying on this might be flawed. This ambiguity makes it difficult to verify the correctness of the relations and subsequent proofs."
      }
    ],
    "token_usage": {
      "input": 9154,
      "thinking": 7000,
      "output": 478
    }
  },
  {
    "entry_id": 47,
    "retraction_id": "1508.06018v3",
    "paper_id": "1508.06018v2",
    "retraction_comment": "This paper has been withdrawn by the authors due the fact that the main results Proposition 4.1 and Theorem 4.8 are not correct. Anonymous reviewers notice, that In the former the set B\\A is not necessarily nonempty while, in the latter, the formulation and proof are unclear",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation of inequality (6.3) in the proof of Proposition 4.1",
        "Location": "Section 6.1, Proof of Proposition 4.1",
        "Explanation": "The derivation of inequality (6.3), V_1(x_1) > Γ_{η,1}(σ(r), φ(r)), relies on applying the D-path condition (Assumption 3.1 (ii)) which is defined for zero external input (Γη(σ(r)) < σ(r)) to the case with non-zero external input φ(r), assuming Γη(σ(r), φ(r)) < σ(r). Furthermore, it assumes that this vector inequality implies the strict inequality holds for a specific component (corresponding to the maximum transformed state), which is not guaranteed by the definition of the vector inequality. This invalidates the derivation of the dissipation inequality (6.6) and the proof of Proposition 4.1."
      },
      {
        "Problem": "Mismatch between the proven convergence set and the definition of aISS/aISpS",
        "Location": "Theorem 4.6, Definition 4.4, Proof of Theorem 4.6 (3rd part)",
        "Explanation": "The definition of aISS/aISpS requires solutions to converge to a neighborhood of the origin in RN whose size is proportional to the input magnitude. The proof of Theorem 4.6 shows convergence to the set B0 = ∩ {x ∈ RN : V_i(x_i) < m0}. B0 is a sublevel set of the candidate Lyapunov functions V_i, not necessarily a ball centered at the origin in RN. The proof does not explicitly establish that convergence to B0 implies convergence to a ball around the origin in RN with the required size proportionality, creating a gap between the proven result and the stated conclusion."
      },
      {
        "Problem": "Ill-defined function Ig in the example",
        "Location": "Section 5, Example, definition of Ig on page 15-16",
        "Explanation": "The function Ig is defined component-wise based on the level sets of the multi-variable function g(V,0). Defining (Ig)_i(r) as the largest V_i such that g(V,0) = r is ill-posed as g(V,0) depends on all components of V, not just V_i. This definition is crucial for Claim 5.2 and undermines the example's analysis."
      },
      {
        "Problem": "Flawed proof of Claim 5.2 in the example",
        "Location": "Section 5, Proof of Claim 5.2",
        "Explanation": "The proof attempts to show that a vector inequality V ≥ Ig(ū/0.95) implies div(pf)(V,u) ≥ Q(V) > 0. It incorrectly applies the scalar function g(V,0) to the vector inequality and makes an unsubstantiated claim about the monotonicity of g(V,0), which appears to be contradicted by Figure 5.4. This invalidates the example's demonstration that Assumption 4.5 holds."
      },
      {
        "Problem": "Lack of a constructive method or verifiable conditions for the sets D_j",
        "Location": "Theorem 4.8, Assumption 4.5",
        "Explanation": "Theorem 4.8 relies on Assumption 4.5 holding on open sets D_j such that S_j ⊆ cl{D_j}. The paper does not provide a method for constructing these sets D_j or verifying the inclusion condition S_j ⊆ cl{D_j} for a given system. This represents a significant gap in the practical applicability of the theorem."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 11809,
      "output": 840
    }
  },
  {
    "entry_id": 48,
    "retraction_id": "1310.8403v3",
    "paper_id": "1310.8403v2",
    "retraction_comment": "This paper has been withdrawn as a bug has been discovered in the proof of Claim 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof technique for comparing maximum packing areas.",
        "Location": "Page 3-5, Lemma 2, Lemma 4, Claim 3, Claim 5",
        "Explanation": "The proofs of Lemma 2 and Lemma 4, which are central to characterizing the MIN-MAX point set, rely on constructing a new point set Qn and arguing that its maximum packing area A(Qn) is less than A(Pn). This argument is based on comparing specific packing configurations (C(Qn) vs R(Pn)) or parts of packings (Claims 3 and 5), which does not prove that the *maximum* possible area for Qn is strictly less than the maximum for Pn. The logic of transferring packings between different point sets is also flawed."
      },
      {
        "Problem": "Lack of rigorous derivation for area calculation and minimization on the diagonal.",
        "Location": "Page 3, Lemma 1",
        "Explanation": "The proof of Lemma 1 presents an expression for the total area of rectangles anchored at points on the principal diagonal and claims a minimum value is achieved when points are spaced according to '2x1 = x2 = ... = xn-1'. Neither the area expression itself nor the condition for minimization and the resulting minimum area (1/2 + 1/(2n)) are rigorously derived or justified using standard optimization techniques (e.g., calculus)."
      },
      {
        "Problem": "Crucial theorem about point locations is unproven.",
        "Location": "Page 6, Theorem 6",
        "Explanation": "Theorem 6 states that all points in a MIN-MAX point set must lie on the principal diagonal. This is a necessary step to connect the result from the restricted diagonal case (Lemma 1) to the general case (Theorem 7). However, the proof provided for Theorem 6 is insufficient, stating it follows by extending the idea from Lemma 4, which only addresses the bounding points of rectangles anchored at the origin (p1)."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 3857,
      "output": 449
    }
  },
  {
    "entry_id": 49,
    "retraction_id": "2003.05237v3",
    "paper_id": "2003.05237v2",
    "retraction_comment": "There is an issue in the proof of Lemma 3.7: evaluation of the involved classes gives back the same values for the coinvariants and not necessarily for the coefficients themselves. At the moment I do not see how to fix it. The lemma is needed in the proof of the main Theorem",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential error in the equivariance proof of the cochain map C*(F)",
        "Location": "Lemma 3.2, page 16",
        "Explanation": "The proof claims that the map C*(F) is Γe x Γr-equivariant. However, the stated actions of Γe x Γr on the domain and codomain cochain complexes appear unusual, and the provided calculation for equivariance seems inconsistent with standard definitions of group actions on cochain complexes and the stated actions themselves. If C*(F) is not a Γe x Γr-equivariant cochain map, then Proposition 3.3, which states that C*(F) induces a map in cohomology of Γe x Γr-invariants, is invalid. This would break the chain of argument leading to the main theorems."
      },
      {
        "Problem": "Heavy reliance on results from an external preprint for crucial properties of the natural map",
        "Location": "Section 2.4, Section 3 (Lemmas 3.1, 3.2, 3.6, Proposition 3.3, Theorem 3.9)",
        "Explanation": "The proof of the main theorem relies fundamentally on the existence and key properties of the natural map F, such as its differentiability, the Jacobian bound (Jaca Fs <= 1), and the equality case (Jacobian=1 iff isometric embedding). These results are stated as proven in the author's preprint [Savd]. Without independent verification of the results in this external preprint, the soundness of the arguments presented in the paper cannot be fully established based solely on the attached document. This affects the verifiability of the paper's conclusions."
      }
    ],
    "token_usage": {
      "input": 7348,
      "thinking": 12558,
      "output": 375
    }
  },
  {
    "entry_id": 50,
    "retraction_id": "2203.03600v2",
    "paper_id": "2203.03600v1",
    "retraction_comment": "The main technical result, Lemma 4, has a major error in the proof: The claim in the proof \"... we could decompose $y^i$, and therefore $y$ into at least two sign-compatible, non-zero cycles of $\\mc A$ ...\" is NOT true. This claim is based on our claim in Lemma 3 that the decomposition of cycles $y^i$ into bricks $y^{i^j}$ yields cycles $y^{i^j}$ of the N-fold matrix $\\mc A$. This is not true",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The N-fold IP structure assumed by Theorem 1 is not the structure of the IP formulations used for the applications.",
        "Location": "Section 2 (Eq 2), Section 5 (Applications)",
        "Explanation": "Theorem 1 provides an algorithm for N-fold IPs with a specific block structure (horizontal A blocks, diagonal B blocks). The IP formulations presented for scheduling and coloring problems in Section 5 (e.g., Q||Cmax, R||Cmax, Minimum Sum Coloring) have different matrix structures (e.g., horizontal Identity blocks and diagonal processing time blocks for Q||Cmax, or constraints involving variables from two different blocks for Minimum Sum Coloring). Applying Theorem 1, which is designed for the structure in Eq 2, to these formulations is incorrect."
      },
      {
        "Problem": "The parameters derived for the applications in Tables 2, 3, and 4 are incorrect.",
        "Location": "Section 5, Tables 2, 3, 4",
        "Explanation": "The derivation of parameters like r, s, pA, SA, pB in Tables 2, 3, and 4 does not correctly map the constraint matrices of the applications to the N-fold structure in Eq 2. For example, the Q||Cmax matrix does not have a column-independent row partition with small pA as claimed in Table 2. This invalidates the parameter values used in the complexity analysis for the applications."
      },
      {
        "Problem": "The proof of Lemma 3 contains inconsistent notation and mixes concepts, making it logically unsound.",
        "Location": "Section 4, Proof of Lemma 3",
        "Explanation": "Lemma 3 is stated in the context of decomposing a vector y^i (from Lemma 4, based on a row partition of A). However, its proof refers to a Graver basis element g of B(i) and a vector y^(i) which is a cycle of B(i). These elements are not defined in the context of y^i from Lemma 4, creating a disconnect and making the proof invalid."
      },
      {
        "Problem": "The proof of Lemma 4 relies on the flawed Lemma 3, and the derived Graver basis bound is inconsistent with the bound claimed later.",
        "Location": "Section 4, Proof of Lemma 4, text after Lemma 4",
        "Explanation": "The proof of Lemma 4 directly uses the result of Lemma 3, which is flawed. Furthermore, the bound derived in the proof of Lemma 4 (||y||_1 <= SA LB (2 pA Delta LB + 1)^pA) does not match the simpler bound g'(A) = SA (pA pB Delta)^(pA pB) stated immediately after the proof. The derivation of g'(A) is not shown, undermining the theoretical contribution."
      },
      {
        "Problem": "The structure of the run time in Theorem 1 does not align with the general run time formula from Proposition 1 using the claimed Graver basis bound.",
        "Location": "Section 2 (Proposition 1), Section 4 (Theorem 1 statement and text after Lemma 4)",
        "Explanation": "Proposition 1 gives a run time structure (Delta g1(A))^O(r+s). Theorem 1 gives a run time structure (SA)^O(r+s) (pA pB Delta)^O(rpApB + spApB). Substituting the claimed bound g'(A) = SA (pA pB Delta)^(pA pB) into the Proposition 1 formula does not yield the structure of the Theorem 1 run time. This suggests an error in applying Proposition 1 or an error in the stated run time of Theorem 1."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 16235,
      "output": 834
    }
  },
  {
    "entry_id": 51,
    "retraction_id": "2001.10983v3",
    "paper_id": "2001.10983v2",
    "retraction_comment": "A case in the proof of Proposition 2.8 was overlooked (thanks to [REDACTED-NAME] for pointing out this) and I withdraw the paper until that gap is filled",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof of Proposition 1.17",
        "Location": "Page 10-11, Proposition 1.17 and its proof",
        "Explanation": "The proof of Proposition 1.17 assumes that the set of vectors {vi} is the full set of roots R, which is not stated in the proposition. The proposition only requires {vi} to be a set of vectors of minimal nontrivial norm that spans the lattice. Reflections associated with such a set do not necessarily generate the full Weyl group in general. The argument relies on this incorrect assumption, making the proof logically flawed."
      },
      {
        "Problem": "Incorrect Hodge number calculation/comparison",
        "Location": "Page 17, Section 2.3, equation (2.5) and subsequent text",
        "Explanation": "The equation (2.5) relating H^0(Omega^p_{T x X}|XT) to Hodge numbers of T and X is incorrect. The space of p-forms on T x X restricted to XT is not simply the sum of p-forms from T and X restricted to XT as implied. The subsequent claims about the vanishing or non-vanishing of H^0(Omega^1_XT) and H^0(Omega^{n-1}_XT) based on this incorrect equation are also false. This invalidates the proof of Theorem 2.13 which relies on deriving a contradiction from this comparison."
      }
    ],
    "token_usage": {
      "input": 4768,
      "thinking": 11267,
      "output": 324
    }
  },
  {
    "entry_id": 52,
    "retraction_id": "2307.05226v3",
    "paper_id": "2307.05226v2",
    "retraction_comment": "The paper has been withdrawn because of the basic mistake: the map $f$ has in general rank q, not p < q (Section 3)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear definition and use of differential forms and derivation of key equations.",
        "Location": "Page 13",
        "Explanation": "The definitions of the differential forms $\\eta$ and $\\tau_J$ and the subsequent derivation of the equation $0 = \\tau_J \\wedge d\\tilde{f}_L$ from the vanishing of coefficients $b_J(y)$ of $\\phi^*(\\omega_X)$ for $J \\neq J_0$ are not mathematically clear or justified. The notation used for partial derivatives of differential forms is non-standard, and the connection between these forms and the coefficients of the pullback form is obscure."
      },
      {
        "Problem": "Incorrect application of Saito's Theorem 1.7.",
        "Location": "Page 13",
        "Explanation": "Saito's Theorem 1.7 concerns the cohomology of the Koszul complex associated with elements in a module and an ideal generated by coefficients of their wedge product. The application of this theorem to the ideal $a_L$ generated by coefficients of the p-form $df_L$ and the form $\\tau_J$ in the stated manner appears incorrect or lacks sufficient explanation to be verifiable."
      },
      {
        "Problem": "Unjustified key inclusion relation.",
        "Location": "Page 13",
        "Explanation": "The inclusion relation $y_s^N \\cdot \\tau_J \\in \\sum_{i=1}^q d\\tilde{f}_i \\wedge \\Omega^{n-p-1}$ for $J \\neq J_0$ and the subsequent relation $y_s^N \\cdot \\tau_J \\in \\sum_{j=1}^n \\phi_j \\cdot \\Omega^{n-p}$ used for the final contradiction are stated without clear derivation from the preceding steps or theorems. These relations are crucial for the proof in the isolated singularity case."
      },
      {
        "Problem": "Ambiguous statement regarding the singular locus of the pullback foliation.",
        "Location": "Page 9, Proof of Proposition 3.3",
        "Explanation": "The statement $Y = Y_0 \\setminus \\text{Sing}(G)$ is confusing. If $Y$ is smooth, $Y_0$ (with reduced structure) is smooth and $Y=Y_0$. Sing(G) is the set where the rank of the differentials defining G drops, which is typically a subset of $Y_0$. The statement seems to imply $Y$ is the complement of Sing(G) within $Y_0$, which is not standard terminology and could indicate a misunderstanding of the relationship between the smooth variety $Y$ and the singular locus of the induced foliation $G$."
      },
      {
        "Problem": "Potential gap in concluding non-singularity of G near the origin.",
        "Location": "Page 10, Proof of Proposition 3.3",
        "Explanation": "The proof shows that the p-form $\\omega$ associated with $G$ is proportional to $dy_1 \\wedge ... \\wedge dy_p$ in a neighborhood of $Y_0$. While this implies $G$ is non-singular in this neighborhood, the conclusion that $G$ is non-singular in a full neighborhood of the origin in $\\mathbb{C}^n$ might require further justification, such as showing that the leaves of $G$ foliate a neighborhood of the origin."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 7098,
      "output": 772
    }
  },
  {
    "entry_id": 53,
    "retraction_id": "1702.07688v4",
    "paper_id": "1702.07688v3",
    "retraction_comment": "I no longer believe that the conclusions are supported by the calculations done in this manuscript. The paper tried to determine what will limit the precision in practice. I incorrectly pointed to small 1 qubit (precision) errors happening everywhere in the circuits",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper claims that fault-tolerant measurement circuits do not mitigate the issue of finite measurement direction precision.",
        "Location": "Page 4, 'However the fault tolerant circuits, such as the one shown in Fig.1b) do not help here...'",
        "Explanation": "Standard fault-tolerant measurement protocols are designed to ensure reliable syndrome extraction despite noise in the measurement apparatus. The paper asserts that these do not help against continuous measurement direction errors without fully demonstrating why standard fault-tolerant techniques for measurement circuits fail in this specific scenario, which is crucial for the paper's conclusion."
      },
      {
        "Problem": "The argument that continuous measurement direction errors are fundamentally uncorrectable because syndrome information is discrete.",
        "Location": "Page 3, 'since we do not know the exact direction of m_i, we cannot correct for our error. We simply do not have access to the information (this information is encoded in the directions m_i, i.e. in continuous variables, while we only measure the syndromes g_i = +/- 1, i.e. discrete values).'",
        "Explanation": "This is the core mechanism proposed for the failure of QEC. It assumes that the continuous error in the measurement direction cannot be reliably inferred or corrected using the discrete syndrome outcomes. A more rigorous argument is needed to show why this specific type of continuous error cannot be handled by fault-tolerant encoding and decoding, as fault tolerance typically maps errors to detectable syndromes."
      },
      {
        "Problem": "The conclusion that QEC is fundamentally limited by measurement precision based on simulations showing linear scaling.",
        "Location": "Page 4, Fig. 2 (lower panel), Fig. 3 (upper curves), Page 4, 'Worse, the logical qubit is actually less precise than the physical ones.', Page 4, 'We conclude that quantum error correction can help... but cannot lead to improvements beyond the precision pe on the direction of the measurement.'",
        "Explanation": "The simulations show linear scaling for specific codes and protocols under a specific model of measurement noise. While this is strong evidence for the simulated scenarios, concluding a fundamental limit to *all* QEC schemes requires demonstrating that this linear scaling is an unavoidable consequence of measurement precision errors, regardless of the fault-tolerant strategy employed."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 2250,
      "output": 501
    }
  },
  {
    "entry_id": 54,
    "retraction_id": "1408.2493v2",
    "paper_id": "1408.2493v1",
    "retraction_comment": "This paper has been withdrawn by the author. The proof of Theorem 6.2 is incorrect and the Theorem probably fails to be true",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ill-defined function definition",
        "Location": "Page 11, Definition of zeta(p)",
        "Explanation": "The function zeta(p) for a dyadic rational p=m/2^n is defined as 'the least s in S such that s' < m/2^n < s'''. Constructively, there is no unique 'least' rational segment containing a given rational number. This definition is unsound and is used in proofs of Theorem 3.3 and Theorem 4.2."
      },
      {
        "Problem": "Undecidable condition in inductive definition",
        "Location": "Page 13, Proof of Theorem 4.1 (EBI => OI([0,1]))",
        "Explanation": "The inductive definition of delta(s) relies on deciding whether 'Da(n') covers delta(n'')'. Da(n') is a decidable subset of S, not necessarily finite. Deciding if a decidable (potentially infinite) set of rational segments covers a given segment is not constructively decidable in general, as it involves universal quantification over real numbers and existential quantification over the covering set."
      },
      {
        "Problem": "Undecidable condition in definition",
        "Location": "Page 23, Proof of Theorem 7.2 (CBW(N) => OI(C))",
        "Explanation": "The definition of beta relies on deciding whether 'Da(n) 01-secures <>'. Da(n) is a decidable subset of Bin. 01-securing is defined via membership in Sec01(Da(n)), which is the infinite union of Sec01_m(Da(n)). Deciding membership in an infinite union is generally not constructively possible."
      },
      {
        "Problem": "Type error and undecidable condition in set definition",
        "Location": "Page 40, Proof of Theorem 11.2 (AFT <=> EnDec?!), proof (i) => (ii)",
        "Explanation": "The definition of the set B includes the condition 'exists s meeting D_beta such that D(s)=t'. Meeting D_beta is defined for elements of N (infinite sequences), but s is stated to be in Bin (finite sequences), which is a type mismatch. Furthermore, deciding membership in B involves existential quantifiers over infinite sets (meeting D_beta) and checking properties of D(s) and dead ends, making the claim that B is a decidable subset questionable."
      }
    ],
    "token_usage": {
      "input": 13540,
      "thinking": 6701,
      "output": 559
    }
  },
  {
    "entry_id": 55,
    "retraction_id": "2112.06228v2",
    "paper_id": "2112.06228v1",
    "retraction_comment": "Theorem 4.3 is missing the terms corresponding to the linear pentagon equation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivative calculation in Proposition 4.8",
        "Location": "Page 19, Proof of Proposition 4.8",
        "Explanation": "The proof attempts to show the two associator paths are different by comparing the derivatives of their coefficients at the origin (s=0). This requires calculating the derivative of σˢ(ζ(k₁, ..., kr)) at s=0, where σˢ is defined based on truncated sums (Eq. 3.4). The calculation method or the resulting values used in the proof (e.g., -5/4 ζ(4) and -3 ζ(4)) appear incorrect and inconsistent with the definition of σˢ and related derivative formulas for sums or integrals. This invalidates the comparison of the derivatives and the conclusion that the paths are different."
      },
      {
        "Problem": "Misapplication of the map κ in comparing associator paths",
        "Location": "Page 19, Proof of Proposition 4.8",
        "Explanation": "The proof compares the first path (coefficients σˢ(I(w))) with the second path (coefficients σˢ'(I(w)) = σˢ(κ(I(w)))). The map κ is defined on words, but it is applied in the context of multiple zeta values or associator coefficients. The proof seems to incorrectly assume a direct correspondence between specific ζ(w) values (like ζ(A²B) and ζ(AB²)) and the coefficients of the associator in the commutator basis, and how κ acts on these. This leads to an incorrect calculation of the derivative of the second path's coefficients, undermining the proof that the paths are distinct."
      },
      {
        "Problem": "Insufficient justification for the shuffle algebra property for complex parameters",
        "Location": "Page 15-16, Section 4.2 and Theorem 4.5",
        "Explanation": "The construction of a 'disk of associators' φKZ,z for complex z (Re(z)>0) relies on the map σ̃ᶻ being a shuffle algebra morphism. While this property is shown for real integer parameters n (Theorem 3.4) by relating it to iterated integrals, the generalization to complex z, where z modifies the integral kernels or limits derived from the summation definition (3.4), requires a more rigorous proof that the shuffle product property for iterated integrals holds in this complex setting. Without this, the claim that φKZ,z satisfies the pentagon equation for complex z is not fully justified."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 9511,
      "output": 553
    }
  },
  {
    "entry_id": 56,
    "retraction_id": "1311.7114v2",
    "paper_id": "1311.7114v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the derivation of equation 24 and 25",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent density matrix used for population calculation.",
        "Location": "Section II.B, Eq. (18)",
        "Explanation": "The paper states that relaxed one-electron CI densities (PD) obtained from solving coupled-perturbed Hartree-Fock (CP-HF) equations are used for calculating local populations (Eq. 18). However, the excitation energies (Eq. 16) are calculated using standard CIS, which is based on the CIS density matrix derived from HF orbitals and CIS coefficients. Using a density matrix derived from CP-HF (which includes orbital relaxation effects not present in standard CIS) for populations while using standard CIS for energies introduces an inconsistency between the calculated subsystem energies and populations for the same electronic state."
      },
      {
        "Problem": "Arbitrary and unjustified definition of the partitioning surface.",
        "Location": "Section IV, Eq. (29)",
        "Explanation": "The partitioning of the molecule into subsystems is defined by an arbitrary mathematical surface (Eq. 29) with several parameters (a, b, c, d, b', xo, yo, zo). The specific values chosen for these parameters are not justified, nor is the sensitivity of the calculated subsystem energies and populations to the choice of these parameters analyzed. This lack of justification and sensitivity analysis means the quantitative results obtained for energy partitioning and population distribution are dependent on an arbitrary choice, potentially undermining the claim of providing a \"rigorously quantitative assessment\"."
      },
      {
        "Problem": "Reliance on Configuration Interaction Singles (CIS) for states where it is known to be inadequate.",
        "Location": "Throughout the results section (III) and discussion (IV)",
        "Explanation": "The method is applied using CIS wave functions. While CIS is acknowledged as a low-level method, it is known to be qualitatively inaccurate for describing certain types of excited states relevant to EET, such as charge transfer states or states with significant double excitation character. The paper applies the method to \"nonlocalized\" states (e.g., states 6-9, 12 in Table I) which may have significant charge transfer character. Using unreliable input wave functions for these states means the resulting partitioning analysis for these states is also unreliable, weakening the demonstration of the method's utility for the full range of states involved in EET."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 2640,
      "output": 502
    }
  },
  {
    "entry_id": 57,
    "retraction_id": "1206.3652v3",
    "paper_id": "1206.3652v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in Theorem 2.6 under the metric of Grassmannian manifolds induced from the riemannian submersion",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Holonomy Formula for Hopf Fibration",
        "Location": "Abstract, Introduction (p. 1), Theorem 1.1 (p. 4), Proof of Theorem 1.1 (p. 5), Theorem 2.6 (p. 10), Remark 2.7 (p. 10)",
        "Explanation": "The paper states multiple different formulas for the holonomy displacement in the case of the Hopf fibration S¹ -> SU(2) -> CP¹ (or its generalizations). The introduction and Theorem 1.1 state V(γ) = e^(A(γ)i), while the calculation in the proof of Theorem 1.1 yields V(γ) = e^(A(γ)i/2). The abstract and Theorem 2.6 introduce a factor λ, but the statements are inconsistent with each other and the derived result. The correct formula for the standard connection on the Hopf bundle over CP¹ (radius 1/2) is V(γ) = e^(A(γ)i/2)."
      },
      {
        "Problem": "Confusion Regarding Base Space and Bundle Type",
        "Location": "Section 1 (p. 2), Section 2 (p. 6), Proof of Theorem 2.5 (p. 9)",
        "Explanation": "In Section 1, the paper initially identifies the base space of the U(1) bundle as SU(2)/U(1), which is S³, but then correctly uses CP¹=S² as the base space later. More critically, in Section 2, the paper claims to study the principal U(n) bundle U(n) -> U(n+m)/U(m) -> Gn,m but proceeds to analyze the bundle U(n)xU(m) -> U(n+m) -> Gn,m using the corresponding Lie algebra decomposition and horizontal space. These are distinct bundles, and the analysis performed is not for the principal U(n) bundle stated as the subject of the paper."
      },
      {
        "Problem": "Flawed Construction in Proof of Theorem 2.5",
        "Location": "Proof of Theorem 2.5 (p. 9)",
        "Explanation": "In the proof for the case Imµ ≠ 0, the paper attempts to construct a Lie algebra monomorphism f: su(1+1) -> u(n+m) using the matrix K = [-I_n 0; 0 O_m]. This matrix K is not an element of the horizontal space m = {[0 -X*; X 0]} defined earlier in the paper for the U(n)xU(m) bundle, nor is it generally in the horizontal space for the principal U(n) bundle U(n) -> U(n+m)/U(m) -> Gn,m. This invalidates the construction and the subsequent argument that the bundle contains a subbundle isomorphic to the Hopf bundle."
      },
      {
        "Problem": "Incorrect Definition/Use of Horizontal Space",
        "Location": "Section 2 (p. 6), Theorem 2.2 (p. 7), Proof of Theorem 2.2 (p. 7), Theorem 2.5 (p. 9)",
        "Explanation": "The paper defines the Lie algebra decomposition u(n+m) = h + m where h = u(n) + u(m) and m = {[0 -X*; X 0]}. This decomposition corresponds to the bundle U(n)xU(m) -> U(n+m) -> Gn,m. However, the paper states its subject is the principal U(n) bundle U(n) -> U(n+m)/U(m) -> Gn,m. The horizontal space for this principal bundle is different. The analysis, including Theorem 2.2 and the use of m', is based on the incorrect horizontal space for the stated principal bundle."
      },
      {
        "Problem": "Unclear or Incorrect Statement of Main Result Conditions",
        "Location": "Abstract (p. 1), Theorem 2.6 (p. 10)",
        "Explanation": "The abstract and Theorem 2.6 state that the factor λ in the holonomy formula depends on whether the surface S is a complex submanifold or not, with λ=1/2 or 0. However, the conditions in Theorem 2.2 for S to be totally geodesic relate to properties of the horizontal space m' (Imµ=0 or Imµ≠0, J-invariance). The connection between 'S being a complex submanifold' and these conditions (Imµ=0 vs Imµ≠0, J-invariance) is not clearly established or justified. Furthermore, the value λ=0 for the non-complex case (Imµ=0) would imply the holonomy is always 1, meaning no displacement, which seems unlikely for a non-flat connection."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 4719,
      "output": 1086
    }
  },
  {
    "entry_id": 58,
    "retraction_id": "1511.00057v2",
    "paper_id": "1511.00057v1",
    "retraction_comment": "Several proofs were found to be incomplete or in error including the proof that quantum rotations can induce arbitrary noise weights. A fully corrected version of this paper is published as: A. Paris, G. Atia, A. Vosoughi, and S. Berman, \"Hidden quantum processes, quantum ion channels, and 1/f-type noise\", [REDACTED-NAME], vol. 30, num. 7, pp. 1830-1929 (2018), doi:https://doi.org/10.1162/neco_a_01067",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and derivation of the multi-time quantum stochastic process Ψ(t1, ..., tn).",
        "Location": "Definition 2.2.1.1, Definition 2.2.2.3, Corollary 2.2.2.1, Page 18",
        "Explanation": "The paper defines a formal quantum stochastic process as a family of operators on the multi-time tensor product space H⊗n (Def 2.2.1.1). However, the activated measurement process (Def 2.2.2.3) appears to define the evolution of a single-time state on H via differential equations. The crucial link showing how this single-time evolution generates the multi-time operator Ψ(t1, ..., tn) required for the framework is missing or unclear, particularly with the missing equation in Cor. 2.2.2.1 and the statement on Page 18 that Ψ(t1, ..., tn) is a tensor product of single-time states, which seems inconsistent with the differential equation definition."
      },
      {
        "Problem": "Direct contradiction between the claim of HMM equivalence and the claim of explaining 1/f noise.",
        "Location": "Page 5, Page 6, Theorem 2.2.4.1, Lemma 3.2.0.1",
        "Explanation": "The paper claims that Hidden Quantum Models (HQMs) can produce 1/f noise, unlike Hidden Markov Models (HMMs). However, Theorem 2.2.4.1 states that diagonalizable HQMs have posterior distributions that are formally equivalent to HMMs. If the observable's distribution is an HMM, its autocovariance function must be that of an HMM (Lemma 3.2.0.1), which is known not to be 1/f noise over a wide frequency range. This creates a fundamental contradiction that undermines the paper's central claim about the explanatory power of HQMs for 1/f noise."
      },
      {
        "Problem": "Unclear justification and definition of the multi-time expectation value (Generalized Born Axiom).",
        "Location": "Definition 2.2.1.2, Equation 5, Remark 2.2.1.5, Section 1.2.1",
        "Explanation": "Standard quantum mechanics provides expectation values for observables at a single time. The paper introduces a 'Generalized Born Axiom' (Eq. 5) for multi-time expectation values using an operator Ψ(t1, ..., tn) on H⊗n. While acknowledging the difficulties with time-dependent measurements and the measurement problem, the paper does not rigorously derive or justify this specific multi-time expectation definition from fundamental quantum principles under the proposed activated measurement protocol. Its physical interpretation in terms of actual measurement outcomes is left ambiguous."
      },
      {
        "Problem": "Disconnect between the proof of HMM equivalence and the definition of the HQM posterior distribution.",
        "Location": "Theorem 2.2.4.1, Page 17 (Proof), Equation 7",
        "Explanation": "The proof of Theorem 2.2.4.1 shows that the coefficients of a single-time state evolving under repeated activated measurements follow a discrete-time Markov process. However, the theorem claims that the posterior distribution of the HQM (defined using the multi-time operator Ψ(t1, ..., tn) in Eq. 7) is a formal HMM. The proof does not clearly demonstrate how the discrete-time Markov evolution of single-time state coefficients translates into the continuous-time HMM structure for the multi-time posterior distribution of the observable A, which is required to support the theorem's claim."
      },
      {
        "Problem": "The definition of the activated measurement operator MQ,A lacks a clear derivation from fundamental quantum operations.",
        "Location": "Definition 2.2.2.2, Equation 6",
        "Explanation": "The activated measurement operator MQ,A[Ψ] is defined as a specific operation on a state Ψ (Eq. 6). While it involves elements related to measurement (projection operators) and an 'activator' Q, its derivation from more fundamental quantum postulates (like unitary evolution and the standard projection postulate) is not provided. It is introduced as a definition, but its physical plausibility as a fundamental quantum process underlying the model is not established, weakening the claim that the framework is based on a 'biophysically plausible quantum mechanical formalism'."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 4447,
      "output": 979
    }
  },
  {
    "entry_id": 59,
    "retraction_id": "1704.08680v2",
    "paper_id": "1704.08680v1",
    "retraction_comment": "Withdrawn by the author. In particular, Lemma 4 and hence Lemma 5 are incorrect invalidating the claimed result",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fatal error in the induction step of the approximation ratio proof.",
        "Location": "Page 16, Proof of Theorem 7",
        "Explanation": "The proof attempts to show that the increase in the weighted sum of duals (Σ_S |δ1(S)| y_S^2) is at least 6/5 times the increase in the standard dual objective (Σ_S y_S^2) during each iteration of Phase II. This requires showing |C| <= (6/5) Σ_{C∈C} 1/|δ1(C)| for the set C of minimally violated sets in the current iteration. However, Lemma 6 proves the opposite inequality: Σ_{C∈C} 1/|δ1(C)| <= (6/5) |C|. This contradiction invalidates the induction and the claimed approximation ratio."
      },
      {
        "Problem": "Unsound proof of Lemma 3.",
        "Location": "Page 11, Proof of Lemma 3",
        "Explanation": "Lemma 3 claims that if a minimally violated set C has degree > 1 in T1 (|δ1(C)| > 1), then its frontier in T1 (Δ1(C)) contains only Steiner nodes. The proof's reasoning involving the reverse-delete step of Phase I and paths connecting terminals to the root is confusing and appears logically inconsistent. It suggests that if a terminal is in the frontier, the edge incident to it in δ1(C) must have been deleted in reverse-delete, which contradicts the assumption that this edge is in δ1(C) ∩ T1 (i.e., not deleted). This lemma is foundational for subsequent lemmas and the main proof."
      },
      {
        "Problem": "Unsound proof of Lemma 4.",
        "Location": "Page 12, Proof of Lemma 4",
        "Explanation": "Lemma 4 claims that for any minimally violated set C with |δ1(C)| = d > 1 in Phase II, there exist d separate degree 1 duals growing together with C. This lemma is crucial for the bound derived in Lemma 6. Its proof relies on the potentially unsound Lemma 3 and a convoluted argument about the reverse-delete process in Phase I. The justification for the existence and properties of these separate degree 1 duals is not clearly established and contains gaps or errors in reasoning."
      },
      {
        "Problem": "Unjustified inequality relating primal cost to weighted dual sum.",
        "Location": "Page 16, Proof of Theorem 7",
        "Explanation": "The proof of Theorem 7 begins by stating c(T) <= Σ_S |δ1(S)| y_S^2. This inequality relates the cost of the final tree T to a non-standard weighted sum of the final dual values from Phase II, where the weights are the degrees in Phase I. Standard primal-dual analysis relates the primal cost to the total increase in dual variables (Σ_S y_S^2) or a sum involving edge coverage by dual sets. The paper provides no derivation or justification for this specific inequality, which is a critical step in the overall proof structure."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 7396,
      "output": 704
    }
  },
  {
    "entry_id": 60,
    "retraction_id": "2406.04846v2",
    "paper_id": "2406.04846v1",
    "retraction_comment": "The claim in this manuscript is incorrect due to a mistake in Eq. (6). The reason is that expression in Eq. (6) is derived in real arithmetic. It is incompatible with the modulo 2 arithmetic in the state ket",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Transversal Logical Gate Implementation",
        "Location": "Page 2, Equation (4) and surrounding text",
        "Explanation": "The paper claims that the logical phase gate P(α)_L can be implemented transversally as a tensor product of physical P(αν_j) gates. This is fundamentally incorrect for general α on CSS codes. Transversal gates on CSS codes are highly restricted (e.g., Clifford gates like Z, X, H), and a general P(α) is not transversal. This invalidates any argument relying on this specific implementation method for P(α)_L."
      },
      {
        "Problem": "Unjustified Gate Count Complexity",
        "Location": "Abstract, Introduction, Conclusions",
        "Explanation": "The paper claims an O(log(1/ε) log log(1/ε) log log log(1/ε)...) gate count for approximating a single-qubit gate to accuracy ε. The described recursive method (using Figure 2) implements P(πl/2^m) in O(m) gates. To approximate P(α) to accuracy ε, one needs m such that |α - πl/2^m| < ε, which requires m to be at least O(log₂(1/ε)). This implies an O(log(1/ε)) gate count, not the claimed bound with extra logarithmic factors. The origin or derivation of the claimed gate count complexity is not provided or justified by the method presented."
      },
      {
        "Problem": "Gate Set Size Depends on Accuracy",
        "Location": "Abstract, Introduction, Conclusions",
        "Explanation": "The method relies on approximating P(α) using gates of the form P(πl/2^m) where m depends on the required accuracy ε (specifically, m needs to be at least O(log₂(1/ε))). The set of gates used is {H} ∪ {P(πl/2^m) | m ≤ M, 0 ≤ l < 2^m} for M ≈ log₂(1/ε). This is not a fixed finite gate set, but a set whose size grows with 1/ε. While the paper mentions the set depends on ε, this is a significant difference from the standard context of universal approximation theorems (like Solovay-Kitaev or the Nielsen & Chuang challenge) which typically assume approximation using a fixed finite universal gate set. The size of the gate set used is O(1/ε), which is very large."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 4075,
      "output": 554
    }
  },
  {
    "entry_id": 61,
    "retraction_id": "2306.09163v2",
    "paper_id": "2306.09163v1",
    "retraction_comment": "Theorem 1 is false for A = F_2[x]/(x^3): (A, +) \\cong C_2 x C_2; (A, \\circ) \\cong C_4",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of the central claim that the number of subgroups of the adjoint group (A,o) is equal to the number of subgroups of the additive group (A,+) is unsound.",
        "Location": "Section 2, Proof of Theorem 1",
        "Explanation": "The proof attempts to use matrix methods (RREF) developed for vector spaces to count subgroups of the group (A,o). This relies on treating the group operations in (A,o) (a o b = a+b+ab, and s o a = sa + (s choose 2)a^2 + ... for integer s) as equivalent to vector space operations (addition and scalar multiplication) for the purpose of RREF and subgroup counting. This equivalence is not generally true, and the argument modulo A^2 is insufficient to justify it for the entire group structure. Subgroups of (A,o) are not generally subspaces of (A,+)."
      },
      {
        "Problem": "The calculation of the Galois Correspondence Ratio (GCR) for 4-dimensional algebras relies on the unproven equality s(A,o) = s(A,+).",
        "Location": "Section 3, specifically the GCR calculation for A24",
        "Explanation": "The GCR is defined as i(A)/s(A,o). The paper calculates s(A,+) (the number of subspaces of A as a vector space) and uses this value for s(A,o) based on Theorem 1. Since the proof of Theorem 1 is unsound, the denominator used in the GCR calculation is likely incorrect, invalidating the calculated GCR values for A24 and implicitly for other 4-dimensional algebras discussed."
      },
      {
        "Problem": "The asymptotic result for the GCR (Theorem 3) depends on the equality s(A,o) = s(A,+).",
        "Location": "Section 4, Theorem 3",
        "Explanation": "Theorem 3 provides an upper bound for the GCR, which is calculated as i(A)/s(A,o). The calculation uses s(A,+) for s(A,o). If s(A,o) is not equal to s(A,+), the derived bound and the conclusion that GCR approaches 0 for large parameters are not necessarily correct."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 3480,
      "output": 520
    }
  },
  {
    "entry_id": 62,
    "retraction_id": "1607.07976v3",
    "paper_id": "1607.07976v2",
    "retraction_comment": "The statement about approximate equality of phase and group velocities is incorrect. Therefore, all arguments based on this statement are unfounded",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound justification and circularity in the adiabatic assumption and its condition.",
        "Location": "Section IV.A, Page 24-25, Eq. (12)",
        "Explanation": "The core assumption that the plasma evolves very slowly in the Pulse Co-Moving (PCM) frame due to ignorable radiation back-reactions is justified intuitively but not rigorously quantified *before* applying the assumption. The derived necessary condition for adiabaticity (Eq. 12) is obtained *from* the adiabatic model itself, creating a circular argument for its validity. The simulations presented show that this assumption breaks down in the studied regimes, particularly for longer pulses or at higher densities."
      },
      {
        "Problem": "Questionable derivation of the global momentum evolution equation (Eq. 9a).",
        "Location": "Page 27, Eq. (9a)",
        "Explanation": "The step of directly equating the time derivative of the global electromagnetic momentum KF in the laboratory frame to the source term -1/2 ε0 Ew^2, which is related to the rate of change of KF in the PCM frame (Eq. 7b), lacks rigorous justification via Lorentz transformation. This is particularly problematic when the PCM frame velocity (vg) is changing, as described by the subsequent Eq. (9b)."
      },
      {
        "Problem": "Unjustified claim of 'proven equality' of local phase velocities and the concept of 'pure radiation'.",
        "Location": "Abstract, Page 7, Page 21, Section IV.C",
        "Explanation": "The claim of a 'proven equality' between the local phase velocities of the laser pulse and the plasma wave is stated as an observation from simulations, not a theoretical derivation, yet it is used as a fundamental basis for the theoretical approach. Furthermore, the explanation that the laser pulse is 'pure radiation' with equal local phase and group velocities contradicts standard wave physics concepts and is not justified within the paper's framework."
      },
      {
        "Problem": "Inconsistency in the spectral analysis derivation (Eqs. 11a, 11b).",
        "Location": "Page 40, Eqs. (11a), (11b)",
        "Explanation": "The derivation of frequency and wavenumber shifts assumes that the original pump frequency and wavenumber are preserved in the PCM frame (ωPCM = ω0|PCM, kPCM = [k0 + Δk]|PCM). This assumption appears inconsistent with the paper's own Eq. (10), which shows that the carrier frequency and wavenumber (ω0, k0) are evolving in the laboratory frame due to pulse depletion. The spectral shifts should likely be related to the *instantaneous* carrier frequency/wavenumber, not the initial ones."
      },
      {
        "Problem": "Reliance on the relativistic particle analogy for pulse evolution.",
        "Location": "Page 27-28, Eqs. (8), (9b)",
        "Explanation": "The derivation of the group velocity evolution (Eq. 9b) relies heavily on treating the entire pulse as a single relativistic particle with a constant 'rest mass' H0 = HFT|PCM. The constancy of H0 is derived under the adiabatic assumption. Applying this analogy to describe the pulse's evolution, especially in regimes where the adiabatic assumption is shown to break down, is a significant simplification that may not accurately capture the complex dynamics of an evolving wave packet in a nonlinear medium."
      }
    ],
    "token_usage": {
      "input": 13282,
      "thinking": 4166,
      "output": 761
    }
  },
  {
    "entry_id": 63,
    "retraction_id": "2006.15984v5",
    "paper_id": "2006.15984v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial definition error of Canonical Huffman Table",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formulation of the estimated file size of entropy-coded data (Fvlc)",
        "Location": "Section 4.1, Equations 6 and 7",
        "Explanation": "The calculation of the estimated file size of the VLCs after replacement (Fvlc) in the objective function F(x) appears mathematically incorrect based on standard information theory and Huffman coding principles. Specifically, the formula for self-information I_i in Equation 6 and the summation in Equation 7 do not correctly represent the expected size of the entropy-coded data given the estimated frequencies. This fundamental error in the objective function means the optimization process is not guaranteed to find the mapping sequence that truly minimizes the file size increment as intended."
      },
      {
        "Problem": "Loss of original optimized Huffman table information",
        "Location": "Section 4.2, Section 5.2, Section 4.1.1 (page 11)",
        "Explanation": "The proposed method replaces the original BITS and HUFFVAL lists in the DHT segment with lists defining the customized Huffman table. This results in the loss of the definition of the original Huffman table in the marked bitstream. While the standard Huffman table is fixed and known, the optimized Huffman table (used for opt-bitstream) is image-specific and cannot be reconstructed without its original BITS and HUFFVAL lists or the original RS frequencies, which are lost. The data extraction process requires replacing the customized table with the original one for bitstream restoration. Since the original optimized table information is lost, restoring the original bitstream is impossible for images originally encoded with an optimized Huffman table, invalidating the claim of applicability to opt-bitstream and the reversibility for such images."
      },
      {
        "Problem": "Potential ineffectiveness of the genetic algorithm due to limited search space and flawed objective function",
        "Location": "Section 4.1, Section 5.1.1 (page 15), Section 5.1.2 (page 16)",
        "Explanation": "The genetic algorithm used to solve the optimization problem operates within a severely restricted search space by considering only 10 consecutive RSs for mapping and limiting the number of mapped VLCs per RS (xi) to only {1, 2, 4, 8}. Combined with the likely incorrect formulation of the objective function's Fvlc term, the GA may not effectively explore the solution space or converge to a truly optimal or near-optimal solution that minimizes the actual file size increment. While experimental results show good performance, the optimization process itself appears unsound, raising questions about the method's reliability and performance guarantees across different images and capacities."
      }
    ],
    "token_usage": {
      "input": 8896,
      "thinking": 16879,
      "output": 582
    }
  },
  {
    "entry_id": 64,
    "retraction_id": "1512.06616v5",
    "paper_id": "1512.06616v4",
    "retraction_comment": "Withdrawn after detection of a major error in the C-E expansion",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect assumption for leading-order boundary condition.",
        "Location": "Section 5.1, Eq. (37)",
        "Explanation": "The assumption B(w_s^eq)=0 implies that the bulk equilibrium distribution satisfies the quantum transmission conditions exactly. This is generally not true for non-trivial scattering and invalidates the subsequent derivation of leading-order relations for chemical potentials (38, 39)."
      },
      {
        "Problem": "Flawed derivation of leading-order chemical potential relations.",
        "Location": "Section 5.1, derivation of (38) and (39) from (37)",
        "Explanation": "The derivation of simple algebraic relations (38) and (39) for the chemical potentials from the system of integral equations B(w_s^eq)=0 is not mathematically justified and appears incorrect."
      },
      {
        "Problem": "Incorrect formulation of the boundary layer correction effect on transmission conditions.",
        "Location": "Section 5.2, equation B(w_s^eq + tau*theta_s^inf) = 0",
        "Explanation": "The equation B(w_s^eq + tau*theta_s^inf) = 0 is used to derive the order tau transmission conditions. This implies B(w_s^eq) + tau*B(theta_s^inf) = 0. Since B(w_s^eq) is generally non-zero, this equation cannot hold for small tau unless B(w_s^eq) is of order tau, which is not shown. The boundary layer corrector should ensure the full distribution satisfies the boundary condition, not just a sum of terms in this manner."
      },
      {
        "Problem": "Unjustified derivation of the order tau diffusive transmission condition (51).",
        "Location": "Section 5.2, derivation of (51)",
        "Explanation": "The derivation of the momentum-dependent equation (51) from the system B(w_s^eq + tau*theta_s^inf) = 0 is not explicitly provided and relies on the incorrect formulation discussed in Problem 3. The validity of (51) is therefore not established."
      },
      {
        "Problem": "Final model relies on unverified diffusive transmission conditions.",
        "Location": "Section 6, model (54) with DTC (53)",
        "Explanation": "The proposed hybrid diffusive-quantum model (54) uses the diffusive transmission conditions (53), which are derived from (51) using the Maxwell-Boltzmann approximation. Since the derivation of (51) is based on questionable assumptions and steps (Problems 1-4), the validity of the final DTC (53) and the entire model is compromised."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 6434,
      "output": 624
    }
  },
  {
    "entry_id": 65,
    "retraction_id": "2309.14057v2",
    "paper_id": "2309.14057v1",
    "retraction_comment": "Our description in Chapter 3, Section 3.2 of the paper is too repetitive with the paper \"Object detection meets knowledge graphs\". There is an error in the description of formula (5) in Section 3.3. And a detailed reasoning process is required for formula (5). Therefore, we wish to request a retraction of the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Dimensionality and Operation Inconsistencies in GRM Module",
        "Location": "Page 15, Figure 5, Equation 8",
        "Explanation": "The description and diagram of the Graph Reasoning Mapping (GRM) module's operations and dimensions appear inconsistent and dimensionally incorrect. Specifically, the matrix multiplication between the compatibility matrix H_v (C x HW) and the evolved semantic representation V^{l+1} (C x D), and the subsequent addition with the visual feature map X (D x H x W), do not align with standard matrix operations or the depicted reshapes, making the proposed architecture unclear and potentially unimplementable as described."
      },
      {
        "Problem": "Overstated State-of-the-Art Claims",
        "Location": "Abstract, Introduction (Page 1, 5), Section 5.1 (Page 18), Table 2 (Page 21), Table 3 (Page 23)",
        "Explanation": "The paper claims achieving new state-of-the-art performance on PASCAL VOC 2012 and MS-COCO 2014 validation sets. However, the results presented in Table 2 and Table 3 show that the proposed method (Ours+GRM) is outperformed by several other methods (e.g., L2G on VOC, CSE on MS-COCO) on these validation sets, contradicting the state-of-the-art claim."
      },
      {
        "Problem": "Non-standard Pseudo-label Evaluation Metric",
        "Location": "Section 4.2 (Page 17), Table 1 (Page 19)",
        "Explanation": "The quality of the generated pseudo-labels is evaluated by computing mIoU against ground truth on the *training* set. While pseudo-labels are used to train the segmentation network, evaluating their quality on the training set against ground truth is not a standard practice and does not directly demonstrate their effectiveness for training or the final segmentation performance on unseen validation/test data."
      },
      {
        "Problem": "Static Nature of Semantic Relationships",
        "Location": "Section 3.1, 3.2 (Page 10-13), Section 3.4 (Page 15)",
        "Explanation": "The core semantic relationship matrix E and word embeddings V are derived offline from a general knowledge graph (ConceptNet) and remain static during the training process. This limits the model's ability to dynamically learn and adapt semantic relationships based on the specific visual context of individual images, potentially hindering its ability to capture sample-specific nuances, despite claims of dynamic learning."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 3305,
      "output": 588
    }
  },
  {
    "entry_id": 66,
    "retraction_id": "1206.0667v2",
    "paper_id": "1206.0667v1",
    "retraction_comment": "This paper is withdrawn by the author because the paper did not prove the second inequality of (4.3), which is unlikely to hold in general",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Dimensional mismatch in integrals over Lagrangian submanifolds",
        "Location": "Page 6, Section 3",
        "Explanation": "Integrals such as $\\int_{\\phi_G(O_\\Delta)} h_G \\Omega_1^n$ and $\\int_{\\phi_G(O_\\Delta)} \\Omega_1^n$ are performed over the 2-dimensional Lagrangian submanifold $\\phi_G(O_\\Delta) \\subset T^*\\Delta$. Since $\\dim M = 2$, $n=2$, and $\\Omega_1^n = \\Omega_1^2$ is a 4-form on $T^*\\Delta$. Integrating a 4-form over a 2-dimensional manifold yields zero, contradicting the non-zero values claimed (e.g., $\\text{vol}_\\omega(M)$). This fundamental dimensional error invalidates the calculations in Section 3."
      },
      {
        "Problem": "Dimensional mismatch in integrals over trace manifold",
        "Location": "Page 7, Section 3",
        "Explanation": "Integrals such as $\\int_{\\text{Tr}_G(\\phi_G(O_\\Delta))} dh_G \\wedge \\Omega_1^n$ are performed over the 3-dimensional manifold $\\text{Tr}_G(\\phi_G(O_\\Delta))$. Since $n=2$, $dh_G \\wedge \\Omega_1^n = dh_G \\wedge \\Omega_1^2$ is a 1-form wedge a 4-form, resulting in a 5-form. Integrating a 5-form over a 3-dimensional manifold yields zero. This dimensional error invalidates the calculations in Lemma 3.3."
      },
      {
        "Problem": "Incorrect application of Stokes' theorem in Lemma 4.3",
        "Location": "Page 11, Lemma 4.3",
        "Explanation": "The formula $\\eta(\\bar{x}) - \\eta(x) = \\int_{[x, \\bar{x}]} \\Theta + \\int_{C_{x_0x}} d\\Theta$ is derived using Stokes' theorem. The boundary of $C_{x_0x}$ is given as $l_{[x_0,x]} + [x,x] - l_{[x_0,\\bar{x}]}$. Applying Stokes' theorem $\\int_{\\partial C_{x_0x}} \\Theta = \\int_{C_{x_0x}} d\\Theta$ and assuming $dh' = \\Theta$ on the relevant chains, the correct relation should be $\\eta(\\bar{x}) - \\eta(x) = \\int_{[x,x]} \\Theta - \\int_{C_{x_0x}} d\\Theta$. The formula in the lemma has a sign error for the second term and uses the undefined segment $[x, \\bar{x}]$ instead of $[x,x]$. This error affects the proof of Theorem 4.5."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 10763,
      "output": 679
    }
  },
  {
    "entry_id": 67,
    "retraction_id": "1503.03000v3",
    "paper_id": "1503.03000v2",
    "retraction_comment": "This paper has been withdrawn by the author because the renormalization constructed in it is not compatible with renormalization in perturbative quantum field theory. Main Theorem of \\S5 is not true",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of rigorous mathematical foundation for infinite-dimensional setting.",
        "Location": "Sections 1, 2",
        "Explanation": "The paper operates in infinite-dimensional spaces (Schwartz space, phase space, Weyl-Moyal algebra) and uses concepts like functional derivatives, integrals, and convergence of series (time-ordered exponential, graph sums) without providing the necessary rigorous definitions or proofs of convergence in this setting. This undermines the claim of mathematical rigor."
      },
      {
        "Problem": "Unjustified crucial assumption on the structure of divergences.",
        "Location": "Page 5",
        "Explanation": "The renormalization procedure relies on the assumption that the divergent part T(Uε(Γ)) for any graph Γ is a polynomial in ε⁻¹ and log ε without a constant term. This assumption is stated without justification for arbitrary Hamiltonians and the unspecified 'Hamiltonian regularization', which is essential for applying the Connes-Kreimer framework."
      },
      {
        "Problem": "Inconsistency or lack of clarity regarding the mathematical space of operators.",
        "Location": "Sections 1, 2, Definition on Page 7",
        "Explanation": "Hamiltonians are introduced as elements of SV' (irregular), but the regularized evolution operator Uε is defined using Hε(t) ∈ SV (regular), implying Uε is in SV⊗A. The final renormalized operator Ũ is stated to be in SV'. The precise mathematical spaces and the action of the Moyal product, time evolution, and renormalization maps on these spaces are not clearly defined or consistently used, especially concerning the transition between SV and SV'."
      },
      {
        "Problem": "The defined renormalization scheme differs from the standard one, requiring additional steps.",
        "Location": "Theorem on Page 9/10, Comment on Page 10",
        "Explanation": "The paper defines renormalization using the Hopf algebra of *all* graphs. However, the comment explicitly states that recovering standard perturbative QFT results requires transforming this renormalization over all graphs into one over one-particle irreducible (1PI) graphs and performing an 'additional renormalization'. This implies the defined mathematical S-matrix Ũ is not the standard renormalized S-matrix, and the core renormalization procedure presented is different from the standard one, requiring further, undefined steps to match known results, contradicting the claim of yielding standard results directly."
      },
      {
        "Problem": "Claim of non-perturbative nature is contradicted by the construction.",
        "Location": "Abstract, Introduction, Eq. 5, Eq. 6, Eq. 15",
        "Explanation": "The construction of the evolution operator Ũ is based on a sum over Feynman graphs, which arises from the expansion of the time-ordered exponential (Eq. 5, 6, 15). This is inherently a perturbative expansion in the interaction Hamiltonian. While the renormalization is applied term-by-term in this expansion, the final result is still presented as this sum, which contradicts the claim of providing a 'mathematical non-perturbative renormalization'."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 2978,
      "output": 668
    }
  },
  {
    "entry_id": 68,
    "retraction_id": "2010.16005v2",
    "paper_id": "2010.16005v1",
    "retraction_comment": "There is a potential issue with trilinear estimates and the indices needs to be adjusted",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect algebraic expansion and change of variables in the trilinear estimate proof.",
        "Location": "Page 10, Proof of Theorem 2",
        "Explanation": "The expression for the change of variables μ = τ - γ(ξ - ξ₁) - τ₂ - γ(ξ₁ - ξ₂) is incorrectly expanded as a linear function of ξ₁. This error invalidates the subsequent calculation of dξ₁/dμ and the resulting polynomial terms, which are central to the integral estimates that follow."
      },
      {
        "Problem": "Misapplication of Lemma 4.",
        "Location": "Page 11, Proof of Theorem 2",
        "Explanation": "Lemma 4 provides a 1D integral estimate for a specific form ∫ dx / ⟨x - α⟩²ˡ ⟨x - β⟩²ˡ. The integral being estimated on page 11 after the change of variables, ∫ dμ / ⟨μ⟩²ᵇ' |...|^{1/2}, does not match the required form of Lemma 4. Applying Lemma 4 in this context is mathematically unsound."
      },
      {
        "Problem": "Unjustified final inequality in the trilinear estimate proof.",
        "Location": "Page 12, Proof of Theorem 2",
        "Explanation": "The inequality |ξ| / [⟨τ - γ(ξ)⟩¹⁻ᵇ' ⟨4τ - γ(ξ)⟩¹/⁴] ≤ 1 is presented as the conclusion of the trilinear estimate proof for the Riesz derivative term. However, the derivation leading to this inequality relies on the previously identified incorrect algebraic manipulations and misapplications of lemmas, rendering the final inequality's validity in this context unproven and the proof unsound."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 4772,
      "output": 391
    }
  },
  {
    "entry_id": 69,
    "retraction_id": "2305.08639v2",
    "paper_id": "2305.08639v1",
    "retraction_comment": "Proof of Theorem 5.4 is wrong. In particular, the map that is claimed to be a homomorphism, it is not a homomorphism. Also, some of the main results of the paper rely on that Theorem",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental issues with the definition and properties of the group N/[π,N] and related constructions.",
        "Location": "Section 4, particularly Lemma 4.1, Lemma 4.3, Proposition 4.4, Lemma 4.5, Proposition 4.8, Page 15 calculations.",
        "Explanation": "The definition of generators for N/[π,N] in Lemma 4.3 seems incorrect. The proof of Proposition 4.4 uses an element not in the generating set. The relations in Lemma 4.5 and the generators of K' in Lemma 4.1 are not rigorously derived. The use of linear algebra on group elements in the proof of Proposition 4.8 is mathematically unsound. These issues undermine the foundation for constructing the abelian quotients and related homomorphisms."
      },
      {
        "Problem": "Incorrect calculation in the proof of Lemma 4.6 regarding the action of braid group generators.",
        "Location": "Page 13, Proof of Lemma 4.6.",
        "Explanation": "The explicit calculation of the action of σ₁ on the generator (x₁, x₂) of A₃ is incorrect based on the defined action of σᵢ on π. This invalidates the claim that Bₙ normalizes Aₙ, which is used in subsequent Sₙ-equivariance arguments."
      },
      {
        "Problem": "Unproven and likely incorrect claim about the trivial action of Gₙ³ on π/N.",
        "Location": "Proposition 5.1, Page 16.",
        "Explanation": "The proof relies on the claim that Gₙ³ acts trivially on π/N. This is not proven in the paper and appears unlikely to be true for the defined action and subgroup N. This invalidates proofs that depend on Proposition 5.1 (e.g., Theorem 5.4, Proposition 5.7)."
      },
      {
        "Problem": "Missing proof connecting the image of the homomorphism τ̃ to the abelianization.",
        "Location": "Section 6, connecting Lemmas 6.1 and 6.2 to Theorem B.",
        "Explanation": "Lemmas 6.1 and 6.2 compute the rank of the image of the homomorphism τ̃: Bₙ[3] → Aₙ ⊗ H*. Theorem B states the rank of the abelianization H₁(Gₙ³; Z). The paper claims Theorem B follows, but does not provide a proof that the image of τ̃ is isomorphic to the abelianization, which is necessary to draw this conclusion."
      },
      {
        "Problem": "Flawed proof for the generating set of B₄[3].",
        "Location": "Proposition 2.2, Pages 6-8.",
        "Explanation": "The proof attempts to show that a specific set of 12 elements generates B₄[3]. However, the proof seems to only show that other elements are contained within the subgroup generated by this set, without establishing that this subgroup is equal to B₄[3]. This makes the proof incomplete and undermines Lemma 6.2 and Theorem B."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 5294,
      "output": 700
    }
  },
  {
    "entry_id": 70,
    "retraction_id": "1706.06242v2",
    "paper_id": "1706.06242v1",
    "retraction_comment": "An error has occurred: The classical Kolmogorov result about characterization of compactness is usually applied with linear operators. Unfortunately, commutator of Hardy-Littlewood maximal operator is a sublinear one",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Undefined notation M_alpha",
        "Location": "Page 4, Proof of Theorem 1.1, (a) => (b)",
        "Explanation": "The proof uses the inequality [b_1, M]_1(f_1, f_2)(x) <= ||b_1||_Lipa M_alpha(f_1, f_2)(x). The notation M_alpha is not defined anywhere in the paper. The definition of the bilinear maximal function is M(f), and M_s(f) is defined later, but M_alpha is not. This makes the initial step of the proof impossible to verify."
      },
      {
        "Problem": "Flawed proof of Claim 1",
        "Location": "Pages 5-6, Proof of Claim 1",
        "Explanation": "The proof of Claim 1, which provides a key estimate for the difference of the commutator values, contains several unjustified steps. Specifically, bounding integrals over cubes by global maximal functions (e.g., integral_{B_2 x B_2} ... <= C M(f_1)(x) M(f_2)(x)) without proper scaling by the cube size, and the introduction of the factor |x-x'|^alpha/|B_2|^(alpha/n) and the function M_s in the final bounds are not clearly derived from the preceding steps."
      },
      {
        "Problem": "Incorrect application of function space properties in Theorem 1.1 (b) => (a)",
        "Location": "Page 8, Proof of Theorem 1.1, (b) => (a)",
        "Explanation": "The proof attempts to show b_i in Lip_alpha from the F_p^(alpha, infinity) boundedness of the commutator. It uses an inequality involving the L^q norm of the oscillation of b_i over a cube Q, which is a characterization of Lip_alpha. However, the connection between this inequality and the F_p^(alpha, infinity) norm of the commutator is not correctly established. The definition of the F_p^(alpha, infinity) norm is misapplied or confused with an L^q norm estimate."
      },
      {
        "Problem": "Incorrect bound for uniform boundedness in Theorem 1.2",
        "Location": "Page 8, Proof of Theorem 1.2, verification of condition (2.1)",
        "Explanation": "To show uniform boundedness, the proof uses the inequality [b, M](f_1, f_2)(x) <= 2(||b_1||_L_infinity + ||b_2||_L_infinity)M(f_1, f_2)(x). This inequality is incorrect as the commutator involves differences b_i(x) - b_i(y_i), not the L_infinity norm of b_i. Furthermore, CMO functions are not necessarily in L_infinity, making the use of L_infinity norms inappropriate for the general case."
      },
      {
        "Problem": "Critical error in the proof of uniform translation continuity in Theorem 1.2",
        "Location": "Page 11, Proof of Theorem 1.2, verification of condition (2.2)",
        "Explanation": "The bound derived for the difference ||[b, M](f_1, f_2)(.) - [b, M](f_1, f_2)(. + t))||_Lp includes the term |t| ||[b, M](f_1, f_2))||_Lp. This term does not go to zero as |t| -> 0 unless the commutator is the zero operator. A correct bound for translation continuity should be of the form C|t|^delta ||f|| for some delta > 0, which tends to zero as |t| -> 0. The presence of the original operator norm multiplied by |t| indicates a fundamental error in the estimation of the difference."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 7823,
      "output": 880
    }
  },
  {
    "entry_id": 71,
    "retraction_id": "1510.01988v2",
    "paper_id": "1510.01988v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to an error in Lemma 2; terms involving the normal derivative of $\\rho$ are missing",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of the divergence of the tangential part of the vector field U.",
        "Location": "Page 3, Lemma 2 (1) proof",
        "Explanation": "The algebraic simplification in the calculation of div_Σ,ρ²g Uᵀ is incorrect. The final expression '1 + k/(ρᵏ(|x|)|x|ᵏ⁺²) * |xᵀ|²/|x|²' does not follow from the preceding steps. This fundamental calculation error invalidates subsequent results that rely on this formula."
      },
      {
        "Problem": "Incorrect inequality used for the divergence of Uᵀ.",
        "Location": "Page 3, Lemma 2 (1) proof; Page 5, Lemma 4 proof",
        "Explanation": "The inequality div_Σ,ρ²g Uᵀ ≤ 1 is used in the proof of Lemma 2 (1) and Lemma 4. However, based on the paper's own (incorrect) formula for div_Σ,ρ²g Uᵀ, this divergence is '1 + k/(ρᵏ(|x|)|x|ᵏ⁺²) * |xᵀ|²/|x|²', which is clearly greater than or equal to 1 (since k > 0, ρ > 0, |x| > 0, and |xᵀ|² ≥ 0). This incorrect inequality undermines Lemma 4 and the main proof."
      },
      {
        "Problem": "Incorrect calculation of the inner product of V with the position vector on the boundary.",
        "Location": "Page 4, Lemma 2 (4) proof",
        "Explanation": "The calculation of (V(x),x)_ρ²g when |x|=|y|=r contains an error in the evaluation of the integral term. The derivative d/dt (1/|tx-y|ᵏ⁻²) is incorrectly calculated, leading to an incorrect final expression for (V(x),x)_ρ²g on the boundary."
      },
      {
        "Problem": "Claim that the vector field W is tangential on the boundary is likely incorrect.",
        "Location": "Page 5, Lemma 3",
        "Explanation": "Lemma 3 states that W is tangential along the boundary ∂Bⁿ(r), which means (W, x)_ρ²g = 0 when |x|=r. This relies on the calculation (U,x)_ρ²g - (V,x)_ρ²g = 0 on the boundary. Since the calculation for (V,x)_ρ²g on the boundary in Lemma 2 (4) appears incorrect, the conclusion that W is tangential is likely false. If W is not tangential, the boundary integral in the Divergence Theorem application does not vanish as assumed in the proof of Theorem 1."
      },
      {
        "Problem": "Incorrect bound for the divergence of Wᵀ.",
        "Location": "Page 5, Lemma 4",
        "Explanation": "Lemma 4 states that div_Σ,ρ²g Wᵀ ≤ 1/(2I(r)). This bound is derived using the incorrect formula and inequality for div_Σ,ρ²g Uᵀ from Lemma 2 (1). This invalidates the key integral inequality ∫_Σ\\D_ε(y) div_Σ,ρ²g Wᵀ ≤ ∫_Σ\\D_ε(y) 1/(2I(r)) used in the proof of Theorem 1 to establish the area bound."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 9322,
      "output": 764
    }
  },
  {
    "entry_id": 72,
    "retraction_id": "1212.5552v2",
    "paper_id": "1212.5552v1",
    "retraction_comment": "There are signal errors in eqs. (17) to (25)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Calculation of Boltzmann Factors",
        "Location": "Section IV, Eqs. 41-43",
        "Explanation": "The Boltzmann factors w(nd,i, nd,i+1) obtained by tracing out the a,b,c sites (Eqs. 41-43) do not appear to be correctly calculated from the listed eigenvalues (Eqs. 16-21) of the Hamiltonian Hi,i+1 for the corresponding configurations of nd,i and nd,i+1. This indicates a fundamental error in applying the decoration transformation method."
      },
      {
        "Problem": "Incorrect Partition Function",
        "Location": "Section IV, Eq. 48",
        "Explanation": "The partition function per elementary cell (Eq. 48) is derived directly from the calculated Boltzmann factors w0, w1, and w2. Since the calculation of these Boltzmann factors is flawed (Problem 1), the resulting partition function is incorrect."
      },
      {
        "Problem": "Unsound Thermodynamic Results and Conclusions",
        "Location": "Section V and VI, Figs. 3-11",
        "Explanation": "All thermodynamic quantities (particle density, entropy, specific heat, internal energy, compressibility) and the phase diagram at finite temperature are calculated based on the incorrect partition function (Problem 2). Therefore, the presented results, plots (Figs. 3-11), and the conclusions drawn from them regarding the thermodynamic properties and phase transitions of the model are unsound and unreliable."
      },
      {
        "Problem": "Incorrect Residual Entropy Calculation and Interpretation",
        "Location": "Section V, discussion of residual entropy, Fig. 5, Fig. 6, Fig. 7",
        "Explanation": "The calculation and interpretation of the residual entropy, including the specific values claimed for trivial and non-trivial frustration, rely on the partition function at zero temperature. As the partition function is incorrect (Problem 2), the residual entropy values and the conclusions about frustration based on them are likely incorrect."
      },
      {
        "Problem": "Inconsistent Eigenvalue Table and State Description",
        "Location": "Section III, page 3, table of eigenvalues and description of states S0-S4",
        "Explanation": "There is an apparent inconsistency between the listed eigenvalues E_k, their associated particle densities ρ, and the number of particles on nodal sites nd = nd,i + nd,i+1, when compared with the description of the ground states S0-S4 and a consistent definition of particle density per unit cell. This inconsistency undermines the clarity and correctness of the intermediate steps used to determine ground states and potentially calculate Boltzmann factors."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 16596,
      "output": 598
    }
  },
  {
    "entry_id": 73,
    "retraction_id": "1612.09148v2",
    "paper_id": "1612.09148v1",
    "retraction_comment": "The second equality in eq. 11 does not hold for the general case. Thus, the conclusion does not follow from the premises and the claim of the paper is not proven",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of the proposed alternative dynamical matrix form.",
        "Location": "Page 1-2, derivation from Eq. 1 to Eq. 12 and Eq. 13.",
        "Explanation": "The rearrangement of the sum in Eq. 1 to obtain Eq. 12 and subsequently Eq. 13 is mathematically incorrect. The property of force constants relating terms at R_n and -R_n (Eq. 11) is misapplied in the summation pairing, leading to a matrix that is not equivalent to the standard dynamical matrix."
      },
      {
        "Problem": "The proposed alternative matrix is not the dynamical matrix.",
        "Location": "Page 2, Eq. 13 and subsequent discussion.",
        "Explanation": "The matrix defined in Eq. 13 is shown to be the real part of the standard dynamical matrix (Eq. 1), not an equivalent alternative form. The imaginary part of the standard dynamical matrix is generally non-zero for arbitrary wave vector q."
      },
      {
        "Problem": "The eigenvalues of the proposed matrix are not the phonon frequencies.",
        "Location": "Page 2, discussion following Eq. 13.",
        "Explanation": "The squares of the phonon frequencies are the eigenvalues of the standard dynamical matrix (Eq. 1). Since the matrix in Eq. 13 is only the real part of the standard dynamical matrix, its eigenvalues are generally not the phonon frequencies, invalidating its use for calculating phonon dispersion relations."
      },
      {
        "Problem": "Misleading characterization of the standard dynamical matrix.",
        "Location": "Page 1, discussion following Eq. 1.",
        "Explanation": "The paper states that the standard form (Eq. 1) is 'not explicitly Hermitian'. While the Hermitian property might not be immediately obvious from the formula structure, the matrix *is* Hermitian under the standard assumptions (real symmetric force constants, lattice inversion symmetry), which is the fundamental reason its eigenvalues (phonon frequencies squared) are real. The paper implies this is a deficiency of the standard form that their proposed form fixes, but the proposed form is incorrect."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 9765,
      "output": 478
    }
  },
  {
    "entry_id": 74,
    "retraction_id": "1205.5450v3",
    "paper_id": "1205.5450v2",
    "retraction_comment": "The paper has been withdrawn due to an error in the maximal norm estimate that we haven't been able to overcome",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incomplete Global Existence Proof",
        "Location": "Page 17, Section 3",
        "Explanation": "The proof attempts to establish global well-posedness in Zs,p by combining the local result with known global results in H^s from [30] and [22]. It relies on showing that the solution u3 in Zs,p agrees with a solution u2 from [30] (which is extended in H^s) and that the Zs,p norm of u3 remains bounded. While the agreement in H^s is plausible, the argument for the boundedness of the weighted L^2 norm |||x|^p u3(t)||_2 for all time t in [0, T1] appears incomplete. The estimate (3.97) bounds the weighted norm of the integral term in the Duhamel formula, but its use in closing the global bound for the weighted norm of the solution itself seems circular based on the provided text."
      },
      {
        "Problem": "Unjustified Key Linear Estimate",
        "Location": "Page 8, Lemma 2.4",
        "Explanation": "Lemma 2.4 provides a crucial estimate (2.42) for the L^{1+a}_x L^inf_t norm of the linear group Wa(t)f, involving weighted Sobolev norms on the right-hand side. The proof is extremely brief and refers to an inequality (2.43) whose connection to the main estimate (2.42) is not clear, and the norms/exponents in (2.43) appear different from those in (2.42). This lack of a clear and verifiable proof for a key linear estimate undermines the foundation of the nonlinear estimates and the contraction principle argument."
      },
      {
        "Problem": "Lack of Detail and Justification for Key Nonlinear Estimates",
        "Location": "Pages 15-16, Section 3 (Estimates (3.87), (3.88), (3.89), (3.90))",
        "Explanation": "The local well-posedness proof relies on the contraction principle, which requires bounding the norm of the nonlinear map Psi(u). This involves bounding several components of the norm |||Psi(u)|||, including weighted L^2, L^2 maximal function, and weighted L^{1+a} L^inf norms. The derivations of these key nonlinear estimates are not provided in sufficient detail, making it difficult to verify their correctness, especially given the complexity of the weighted and mixed space-time norms involved and the nonlinear term u dx u."
      },
      {
        "Problem": "Potential Issues with the Proof of the Pointwise Estimate for Fractional Weights (Lemma 1.2)",
        "Location": "Pages 4, 9-14, Lemma 1.2 and its proof",
        "Explanation": "Lemma 1.2, presented as a 'new main idea', provides a pointwise formula and estimates for the linear group acting on weighted functions. This lemma is fundamental for the weighted estimates in the contraction principle argument. Its proof relies on a fractional Leibniz-type rule (Lemma 2.7) and complex integral estimates involving fractional calculus and weighted spaces. The derivations are dense, and potential subtle errors in these technical steps could invalidate the lemma and consequently the weighted estimates in the main proof."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 14093,
      "output": 743
    }
  },
  {
    "entry_id": 75,
    "retraction_id": "1806.09512v2",
    "paper_id": "1806.09512v1",
    "retraction_comment": "The calculations are not strictly correct because the Fermi momenta for protons and neutrons were not scaled correctly",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of constant effective mass M* per nucleus across all kinematics.",
        "Location": "Section II, Section IV.L, Figure 18",
        "Explanation": "The model assumes a single effective mass M* for each nucleus, independent of energy and momentum transfer. However, the paper's own analysis shows that the 'optimal' effective mass extracted from the experimental quasielastic peak position varies significantly with energy transfer (omega), contradicting this core assumption."
      },
      {
        "Problem": "Reliance on factorization and scaling assumptions which are known to be broken by significant nuclear effects.",
        "Location": "Section I, Section II, Section V, Figures 6-17",
        "Explanation": "The model assumes the nuclear response factorizes into a single-nucleon part and a universal scaling function. The paper acknowledges that effects like meson-exchange currents (MEC), final-state interactions (FSI), and short-range correlations (SRC) break these assumptions. The fact that a large amount of data falls outside the model's uncertainty band, particularly in kinematic regions sensitive to these effects (e.g., the left tail corresponding to high momentum components, and for heavy nuclei), indicates that the underlying assumptions are not universally valid, limiting the model's applicability and predictive power outside the core quasielastic peak region."
      },
      {
        "Problem": "Bias introduced by the data selection procedure used for fitting.",
        "Location": "Section III.A, Section III.B, Section III.C",
        "Explanation": "The procedure for extracting the scaling function and fitting parameters involves selecting data points that fall within a certain band or satisfy a density criterion around the expected quasielastic peak. This process inherently biases the fit towards the kinematic region where scaling holds best, potentially leading to parameters and a scaling function that do not accurately represent the nuclear response in regions dominated by non-scaling effects."
      },
      {
        "Problem": "Degraded performance for heavy nuclei.",
        "Location": "Section IV.J, Section IV.K, Table II (chi-squared values)",
        "Explanation": "The model's description of experimental data is significantly worse for heavy nuclei like 208Pb and 238U compared to lighter nuclei, as indicated by higher chi-squared per quasielastic point values. This suggests that the model's core assumptions, such as factorization and a constant effective mass, are less valid in heavy nuclei where effects like FSI and MEC are expected to be more prominent and complex."
      },
      {
        "Problem": "Unclear or potentially less rigorous method for estimating theoretical uncertainty bands.",
        "Location": "Section III.C, Section IV, Section IV.L",
        "Explanation": "The theoretical uncertainty bands are derived by parameterizing the width of the data cloud that falls within a band during the fitting process, or through separate analyses (e.g., for effective mass uncertainty). It is not clear if this method fully captures and propagates the uncertainties from all fitted parameters (scaling function parameters, kF, and M* for all nuclei) in a statistically rigorous way, potentially affecting the reliability of the predicted error bands."
      }
    ],
    "token_usage": {
      "input": 6832,
      "thinking": 4556,
      "output": 689
    }
  },
  {
    "entry_id": 76,
    "retraction_id": "2102.11234v2",
    "paper_id": "2102.11234v1",
    "retraction_comment": "In step (3) of the proof of Theorem 1.3. it is claimed that $\\delta^2_{N,N} = 2\\delta$. This is not the only case that can occur and therefore there is a gap in the proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Confusion between the number of distinct nearest neighbor distances (g) and the number of distinct nearest and second nearest neighbor distances (g²).",
        "Location": "Page 3 (Theorem 1.2), Page 7 (Numerical experiments section)",
        "Explanation": "The paper claims to prove g(3,2) ≥ 9 and refute the conjecture g(3,2) ≤ 7 based on a numerical example where g²(a, L, ||.||2) = 9. However, g is defined as the number of distinct nearest neighbor distances, while g² is the number of distinct nearest *and* second nearest neighbor distances. The example shows gN=6 and g²N=9 for a specific N. g² ≥ 9 does not imply g ≥ 9. This fundamental confusion invalidates the main claim (Theorem 1.2) and the conclusion regarding the HM20 conjecture."
      },
      {
        "Problem": "Numerical example contradicts Theorem 1.3.",
        "Location": "Page 7 (Numerical experiments section), Page 3 (Theorem 1.3)",
        "Explanation": "The numerical example for d=3, N=39 presents gN=6 and g²N=9. Theorem 1.3 states that g²(d,q) ≤ g(d,q) + 1 (where g and g² are maximal values over N). If interpreted as g²N ≤ gN + 1 for this specific N, the example (9 ≤ 6+1=7) presents a clear contradiction. This indicates either the numerical calculation/interpretation is incorrect or Theorem 1.3 is false, pointing to a critical error in the paper's core results."
      },
      {
        "Problem": "Proof of Theorem 1.3 is flawed.",
        "Location": "Pages 6-7 (Proof of Theorem 1.3)",
        "Explanation": "The proof attempts to show g²N ≤ g_{N-1} + 1. Step 1 relies on an unclear connection between the new distance δN,N and distances in SN-1, potentially misusing Lemma 2.1. Step 3's analysis of the case δN,N ∉ BN-1 seems logically inconsistent, making unsupported claims about the second nearest neighbors of 'a' and 'Na' and their distances. The proof does not rigorously establish the claimed inequality."
      },
      {
        "Problem": "Proof of Lemma 2.2 for Lq metric is incorrect.",
        "Location": "Page 6 (Proof of Lemma 2.2)",
        "Explanation": "The proof for the Lq metric claims that if the Lq norms of two vectors x and y are equal (||x||q = ||y||q), where components are related to algebraic independent numbers, then the magnitudes of their components must be equal (|x_i| = |y_i|) for all i. This is generally false for q > 0. This lemma is used to argue that there are at most two points with minimum distance, which is foundational for defining the second nearest neighbor and analyzing g², potentially undermining subsequent arguments."
      },
      {
        "Problem": "Insufficient proofs for supporting lemmas.",
        "Location": "Page 5 (Proof of Lemma 2.1), Page 8 (Proof of Lemma 3.1)",
        "Explanation": "Lemmas 2.1 and 3.1, which are used in the proofs of main theorems (Theorem 1.3 and Theorem 1.4/3.4), are given only one-sentence proofs. These brief justifications are insufficient, especially for claims involving multi-dimensional Kronecker sequences and their distance properties. This lack of rigor weakens the arguments that rely on these lemmas."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 7590,
      "output": 832
    }
  },
  {
    "entry_id": 77,
    "retraction_id": "1303.3756v2",
    "paper_id": "1303.3756v1",
    "retraction_comment": "This paper has been withdrawn by the author because Jarzynski's equality takes also processes into consideration which do not satisfy the 2nd law. Consequently, a modified non-equilibrium thermodynamics has to be developped taking into account the \"anti-irreversible admixtures\"",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misunderstanding the scope of Jarzynski's equality.",
        "Location": "Section 5, Eq. 31, and surrounding text.",
        "Explanation": "The paper claims that Jarzynski's equality, \\overline{\\exp(-\\beta W)} = \\exp(-\\beta\\Delta F), is only valid in the reversible limit (Eq. 31). This is incorrect according to the established understanding in statistical mechanics, where the equality holds for any process starting from canonical equilibrium, including irreversible ones."
      },
      {
        "Problem": "Incorrectly rejecting the standard derivation of the Second Law inequality from Jarzynski's equality.",
        "Location": "Section 5, discussion below Eq. 41.",
        "Explanation": "The author states that deriving the Second Law inequality, \\overline{W} \\ge \\Delta F, from Jarzynski's equality using Jensen's inequality is 'not true' and requires presupposing reversibility. This is incorrect. Applying Jensen's inequality to the convex function \\exp(-x) directly to the equality \\overline{\\exp(-\\beta W)} = \\exp(-\\beta\\Delta F) yields \\exp(-\\beta\\overline{W}) \\le \\overline{\\exp(-\\beta W)} = \\exp(-\\beta\\Delta F), which implies \\overline{W} \\ge \\Delta F. This derivation is valid for any process for which Jarzynski's equality holds, regardless of reversibility."
      },
      {
        "Problem": "Misinterpretation of the temperature parameter in Jarzynski's work.",
        "Location": "Page 4, below Eq. 16; Page 5, Section 3.",
        "Explanation": "The paper suggests that Jarzynski replaces the contact temperature with the system's thermostatic temperature T=1/k\\beta in non-equilibrium and that this implies equilibrium or vanishing heat exchange. In Jarzynski's statistical mechanical framework, \\beta is the temperature of the initial canonical ensemble and the heat reservoir controlling the process. The equality holds for non-equilibrium processes starting from this equilibrium state, and does not require the system to be in equilibrium or have a well-defined instantaneous temperature T equal to the reservoir temperature during the process."
      },
      {
        "Problem": "The paper's derivation from phenomenological thermodynamics leads to Jensen's inequality, but this is incorrectly presented as Jarzynski's result before claiming the equality is only reversible.",
        "Location": "Section 3.2, Eq. 30 and 31.",
        "Explanation": "The derivation in Eq. 30 correctly yields \\exp(-\\beta\\Delta F) \\ge \\overline{\\exp(-\\beta W_k)}, which is Jensen's inequality applied to the work distribution, a consequence of the Second Law. However, the author implies this inequality is what Jarzynski obtained before stating that the equality (Eq. 31) is only valid for reversible processes. Jarzynski's actual result is the equality \\overline{\\exp(-\\beta W)} = \\exp(-\\beta\\Delta F), which holds for non-equilibrium processes starting from canonical equilibrium."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 2618,
      "output": 705
    }
  },
  {
    "entry_id": 78,
    "retraction_id": "2002.03104v2",
    "paper_id": "2002.03104v1",
    "retraction_comment": "As pointed out by [REDACTED-NAME] via MO: \"This only shows that there is no trivial, i.e. purely analytic, argument proving that this expression is unbounded. But there might be only finitely many odd perfect numbers, or there might be some relation between n and q, which implies that the ratio is bounded.\"",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Invalid use of contradiction based on an 'unbounded expectation'.",
        "Location": "Section 3 (proofs of a, b, c), Theorem 4.4 proof, Theorem 4.6 proof",
        "Explanation": "The paper repeatedly claims a contradiction arises from an expression being bounded, based on an initial statement (1) and the 'expectation' that the expression is unbounded. Statement (1) is an inequality that appears to be true, not a claim of unboundedness. The 'unbounded expectation' is not a valid mathematical premise for contradiction. This invalidates multiple proofs."
      },
      {
        "Problem": "Incorrect logical equivalences stated in Lemmas 4.1 and 4.2.",
        "Location": "Lemma 4.1, Lemma 4.2",
        "Explanation": "The paper claims that certain inequalities are true if and only if specific biconditionals hold. The logical derivations show that the stated equivalences are incorrect. This error propagates to Corollary 4.4.1."
      },
      {
        "Problem": "Unfounded step in the proof of Theorem 4.5.",
        "Location": "Theorem 4.5 proof",
        "Explanation": "The proof assumes n < σ(q²) and q² < σ(n) and claims that this 'follows that both σ(n)/q² < σ(q²)/n and σ(q²)/n < σ(n)/q² hold'. These two resulting inequalities are contradictory, but the deduction from the premise to these inequalities is not justified and appears incorrect, invalidating the proof."
      },
      {
        "Problem": "Unjustified inequalities and invalid contradiction in Theorem 4.6 proof.",
        "Location": "Theorem 4.6 proof",
        "Explanation": "The proof of the main theorem relies on bounding the expression q²/n + n/q² in different cases. The inequalities used for bounding (e.g., q²/n + n/q² < 1 + C¹/²/25) are not justified by the preceding steps or known results. Furthermore, the conclusion of the proof relies on claiming this bound contradicts statement (1), which is an invalid use of contradiction as described in Problem 1."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 8197,
      "output": 502
    }
  },
  {
    "entry_id": 79,
    "retraction_id": "1401.5295v2",
    "paper_id": "1401.5295v1",
    "retraction_comment": "This paper has been withdrawn due to non-inclusion of some terms in equation 16",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect description of current pattern in PH1 phase",
        "Location": "Section IV B",
        "Explanation": "The paper states that phase PH1 has a 'ferromagnetic current wave' while simultaneously stating and showing that the current on all bonds (Jij) is zero in this phase (Fig 6b). Zero current cannot be described as a current wave, which is a factual error in describing the properties of the phase."
      },
      {
        "Problem": "Inconsistency regarding particle-hole symmetry and filling",
        "Location": "Section II.C and Section III",
        "Explanation": "The paper states that particle-hole symmetry exists for half-filling and the Hamiltonian is invariant under it for 'the same case' (Sec II.C). However, the study focuses on filling 1/2q (lowest band filled, Sec III), which is generally not half-filling (1/2) for the range of q studied (3-8). This is a contradiction in describing the system's symmetries at the studied filling."
      },
      {
        "Problem": "Reliance on Mean-Field Theory for First-Order Transition and Gap Closing",
        "Location": "Section I, Section IV A, Section V",
        "Explanation": "The central claim of a first-order topological phase transition without gap closing is based on mean-field theory. While MFT predicts gapped competing phases, it often overestimates the stability of broken symmetry phases and the sharpness of first-order transitions in 2D. Fluctuations could potentially alter the nature of the transition, affect the gap at the transition point (e.g., via domain wall excitations), and smear out the first-order nature, raising questions about the robustness of the claimed TPT without gap closing in a real system, despite the mean-field result."
      },
      {
        "Problem": "Potential numerical issues in finding the true ground state",
        "Location": "Section IV A",
        "Explanation": "The paper mentions finding 'many mean field solutions' and selecting the lowest energy one. For complex systems with multiple competing orders, ensuring that the iterative method consistently converges to the true global minimum energy solution across the entire parameter space can be numerically challenging. If a lower energy solution was missed, the determined phase diagram and transition points would be incorrect."
      },
      {
        "Problem": "Limited scope of interactions",
        "Location": "Section II, Section V",
        "Explanation": "The study is limited to nearest-neighbor repulsive interactions. In real materials, long-range Coulomb interactions are often present and can significantly influence the phase diagram and the nature of electronic phases and transitions. Neglecting these potentially important interactions limits the direct applicability of the conclusions to real physical systems."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 8358,
      "output": 601
    }
  },
  {
    "entry_id": 80,
    "retraction_id": "1402.6435v2",
    "paper_id": "1402.6435v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in page 20",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of height for the adelic divisor (0, 2t[inf]).",
        "Location": "Page 21, Proof of Corollary 5.7, (a) <= (b)",
        "Explanation": "The height h_{(0,2t[inf])}(x) for a rational point x in X(K) is calculated as t, but the correct value is t * |Sigma| / [K:Q]. This error invalidates the inequality h_D(x) >= t derived in the proof, which is essential for showing (a) <= (b)."
      },
      {
        "Problem": "Flawed proof of the equivalence between infimum of concave transform and supremum of volume thresholds.",
        "Location": "Page 21, Proof of Corollary 5.7, (c) = (d)",
        "Explanation": "The proof relies on the equality vol^{lambda1}(D) = vol(D), where lambda1 = inf G_D(u). This equality is not generally true for a big divisor D unless G_D(u) >= 0 on Delta(D) and the volume formula simplifies appropriately. This step is crucial for proving (c) = (d)."
      },
      {
        "Problem": "Logical gap in the proof of Theorem 5.6 regarding the numerical base locus.",
        "Location": "Page 21, Proof of Theorem 5.6, (b) => (c) and (b)' => (c)",
        "Explanation": "The proof claims that vol^a(D)=vol(D) (in the big case) or vol^a(D+eps A)>0 (in the general case) implies NBs(D)=0 by citing Theorem 4.8. However, Theorem 4.8 does not provide this implication. Theorem 4.8 (1) only states vol^a(D)=vol(D) implies NBs(D)=NBs(D), and Theorem 4.8 (2) states if D is *nef* and vol^a(D)=vol(D), then NBs(D)=0. The condition D is nef is missing in Theorem 5.6 (b) and (b)'. This gap invalidates the implication (b) => (c) and (b)' => (c)."
      },
      {
        "Problem": "Flawed proof of Corollary 5.5, which is used to prove Theorem 5.6 (c) => (a).",
        "Location": "Page 20, Proof of Corollary 5.5",
        "Explanation": "This proof, used in Theorem 5.6 (c) => (a), appears flawed. It uses the definition of sigma_xi(D) for pseudo-effective divisors to construct an effective divisor E with small multiplicity at xi, then applies Proposition 5.1 to E. However, Proposition 5.1 is for effective divisors, and the application requires h_E(x) >= 0, which relies on x not being in the geometric support of E. This is not guaranteed for all rational points x, especially those in the support of D."
      },
      {
        "Problem": "Missing proof that vol^a(D)=vol(D) implies D is pseudo-effective.",
        "Location": "Page 19, Proof of Theorem 4.8 (1)",
        "Explanation": "The proof of Theorem 4.8 (1) only shows that vol^a(D)=vol(D) implies sigma_xi(D)=sigma_xi(D) and NBs(D)=NBs(D). The statement that D is pseudo-effective is not proven here but is used in subsequent results (e.g., Lemma 3.9, Theorem 5.6, Corollary 5.5), making this a critical missing piece in the logical flow."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 21254,
      "output": 861
    }
  },
  {
    "entry_id": 81,
    "retraction_id": "2210.17003v2",
    "paper_id": "2210.17003v1",
    "retraction_comment": "The main theorems of the paper (Theorem 13 and 17) are wrong. The statements are only valid in R^2",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed reasoning for CT(x)=0 when {x,y,z} are distinct.",
        "Location": "Page 4, Proof of Theorem 13, Case |{x,y,z}|=3",
        "Explanation": "The proof claims that if x, y=RA(x), and z=RB(y) are distinct, then CT(x)=0. While Corollary 12 shows ||x||=||y||=||z||, the circumcenter of three distinct points on a sphere centered at the origin is the origin only if the origin lies in their affine hull (i.e., they are linearly dependent). This linear dependence is not generally guaranteed for arbitrary x and cones A, B."
      },
      {
        "Problem": "Incorrect identification of CT(x1) in Theorem 13, Case (i)(c) y1=z1.",
        "Location": "Page 4, Proof of Theorem 13, Case (i)(c), subcase y1=z1",
        "Explanation": "In this case, {x1, y1, z1} = {x1, y1, y1} = {x1, y1}. The circumcenter of two points x1 and y1 is their midpoint (x1+y1)/2. The proof claims this is equal to PA(x1). This is incorrect; the midpoint of x1 and y1 is not generally equal to the projection of x1 onto A."
      },
      {
        "Problem": "Flawed reasoning and unproven claims in Theorem 13, Case (i)(c) x1=z1.",
        "Location": "Page 4, Proof of Theorem 13, Case (i)(c), subcase x1=z1",
        "Explanation": "The reasoning claims that RA and RB o RA reflect x1 through the same point q=PA(x1)=PB(y1). This claim is not justified and appears incorrect. RA reflects x1 to y1, and RB o RA reflects x1 to z1=x1. If they reflect through the same point q, q must be the midpoint of (x1, y1) and (x1, x1). The latter implies q=x1, which means x1 is the midpoint of (x1, y1), so y1=x1. But the case is x1=z1 ≠ y1, leading to a contradiction. The conclusion CT(x1)=q is based on this flawed premise."
      },
      {
        "Problem": "Incorrect identification of CT(x) in Theorem 13, Case (iii).",
        "Location": "Page 5, Proof of Theorem 13, Case (iii)",
        "Explanation": "In this case, {x, y, z} = {x, RA(x), x} = {x, RA(x)}. The circumcenter of two points x and RA(x) is their midpoint (x+RA(x))/2. The proof claims this is equal to PB(RA(x)). This is incorrect; the midpoint of x and RA(x) is not generally equal to the projection of RA(x) onto B."
      },
      {
        "Problem": "Incorrect application of Theorem 13 in the proof of Theorem 17.",
        "Location": "Page 6, Proof of Theorem 17",
        "Explanation": "The proof attempts to show finite convergence of the sequence {xn} generated by CRM on A and B by applying Theorem 13 to the shifted sets A'=(A ∩ Br(x*)) - x* and B'=(B ∩ Br(x*)) - x*. However, the sequence {xn} is generated by applying the CRM operator for A and B, not the CRM operator for A' and B'. The algorithm applied to A, B is not equivalent to the algorithm applied to A', B', so the finite convergence of one does not imply the finite convergence of the other."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 5630,
      "output": 888
    }
  },
  {
    "entry_id": 82,
    "retraction_id": "1503.00700v2",
    "paper_id": "1503.00700v1",
    "retraction_comment": "This preprint was withdrawn because the theoretical discussion of the inferred temperature of qubit couplers assumes an equilibrium distribution, which is not the case during the annealing cycles",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The method for correcting J_ij bias relies on fitting data to a Boltzmann-like model (Eq 9) that the author states is not physically valid for coupled spins.",
        "Location": "Page 6, Equation (9) and surrounding text",
        "Explanation": "The theoretical basis for deriving J_ij corrections from this fitting is unsound, as acknowledged by the author. While empirical improvement is observed for the null problem, the method's foundation for J_ij correction is questionable."
      },
      {
        "Problem": "The method assumes residual biases are simple additive offsets independent of the programmed h_i and J_ij values.",
        "Location": "Page 5, Equation (6); Page 7, Equation (10); Page 4, h-sweep values near zero",
        "Explanation": "The experimental design hints at potential non-linear or sign-dependent biases (e.g., using near-zero h values to avoid anomalies), which would not be correctly addressed by a simple additive offset correction. This assumption is critical for applying the correction to non-null problems, but its validity is not demonstrated."
      },
      {
        "Problem": "The conclusion claims the method is validated for operational use on 'subsequent applications of interest,' but the validation experiments are limited to the null problem (h_i=0, J_ij=0).",
        "Location": "Page 9, Section VI Conclusions and Recommendations",
        "Explanation": "It is not demonstrated that the biases measured and corrected in the null problem generalize or remain consistent when non-zero h_i and J_ij values are programmed for actual optimization problems. The bias might be problem-dependent, limiting the applicability of the null-problem-derived corrections."
      },
      {
        "Problem": "The interpretation of the effective temperature derived from the J_ij fitting (Eq 9) as a measure of quantum annealing improvement over a classical device is based on a model acknowledged as not physically valid.",
        "Location": "Page 7, text discussing the temperature fitting parameter for J_ij",
        "Explanation": "Since the model used to derive this temperature is theoretically unsound for coupled spins, the physical interpretation of the resulting parameter is unreliable and does not provide a valid measure of quantum advantage."
      },
      {
        "Problem": "The paper does not provide standard metrics (e.g., R-squared, residuals) or visualizations (fitted curves overlaid on data) to demonstrate the quality of the fits for the Boltzmann models (Eq 5 and 9).",
        "Location": "Page 4, Figure 4; Page 6, Figure 7; text describing fitting process",
        "Explanation": "Without evidence of good fit quality, the reliability of the derived h_i and J_ij offsets and effective temperatures, which are central to the correction method, cannot be properly assessed."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 2662,
      "output": 631
    }
  },
  {
    "entry_id": 83,
    "retraction_id": "1202.1896v2",
    "paper_id": "1202.1896v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical mistake in the circle graph algorithm",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed decomposition strategy for permutation graphs.",
        "Location": "Page 3, Lemma 1 and Theorem 1 Proof",
        "Explanation": "Lemma 1 claims that in an optimal coloring, uncolored vertices are precisely those crossing scanlines separating colored components. This assumption is not justified and seems incorrect. The subsequent dynamic programming approach in Theorem 1 relies on decomposing the graph based on scanlines, assuming vertices crossing the intermediate scanline are uncolored. This decomposition is likely invalid for finding a general black-and-white coloring."
      },
      {
        "Problem": "Incorrect dynamic programming combination for permutation graphs.",
        "Location": "Page 3, Theorem 1 Proof",
        "Explanation": "The dynamic programming combines colorings of two pieces P1 and P2 (separated by a scanline s) by simply adding the counts of black and white vertices (b1+b2, w1+w2). This is only valid if there are no adjacencies between vertices in P1 and P2. However, vertices in P1 (segments between s1 and s) can intersect vertices in P2 (segments between s and s2). The DP state (b', w') does not capture the necessary boundary information (e.g., which vertices crossing s are colored) to ensure a valid combined coloring."
      },
      {
        "Problem": "Unclear and potentially incorrect dynamic programming structure for circle graphs.",
        "Location": "Pages 4-5, Theorem 2 Proof",
        "Explanation": "The proof describes a dynamic programming approach on a subgraph G' induced by chords with endpoints on an arc C'. It then introduces a complex DP state involving chains of scanlines (Δ) and a set R of vertices colored black. The definition of the state, the transitions, and how this relates to solving the problem on the entire graph G are very difficult to follow and appear incomplete or based on unjustified assumptions. The final sentence mentions combining colorings of two pieces incident with a scanline s, which seems to refer to a different decomposition strategy than the one described earlier in the proof."
      },
      {
        "Problem": "Unjustified key observation in circle graph proof.",
        "Location": "Page 5, Theorem 2 Proof",
        "Explanation": "The proof states as an 'important observation' that 'each chord that crosses s' crosses at most one other scanline of Δ'. This observation seems crucial for the definition of the DP state (specifically, item (d) in the table contents), but it is not proven or justified. If this observation is false, the described DP state is insufficient to capture the necessary information for valid transitions."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 2947,
      "output": 580
    }
  },
  {
    "entry_id": 84,
    "retraction_id": "1304.5962v2",
    "paper_id": "1304.5962v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound Assumption of Fixed Cancellation Boundary",
        "Location": "Page 3, Lemma 2.1; Page 4, Problem formulation (7)-(10)",
        "Explanation": "The paper assumes that the seller's optimal cancellation boundary is fixed at the strike price K for all times τ > τ*. This is an unsound assumption for an optimal stopping problem in continuous time, where optimal boundaries are typically free boundaries that depend on time and other parameters, not fixed constants. The structure of the cancellation payoff Y(S) = (S-K)+ + δ suggests the seller would prefer to cancel when S is low (below K), making the cancellation region likely of the form S <= S*(τ), not just S=K."
      },
      {
        "Problem": "Flawed Proof of the Fixed Boundary",
        "Location": "Page 4, Proof of Lemma 2.1",
        "Explanation": "The proof provided to justify the fixed cancellation boundary at K contains a critical error. In the comparison argument using the maximum principle, the initial condition for the difference function Ṽ(S, τ*) is stated as positive, but based on the problem setup where V(S, τ*) = vE(S, τ*) and V(S, τ*; K) = vE(S, τ*) for S > K (for c1) and S < K (for c2), this initial condition should be zero. This error invalidates the subsequent application of the maximum principle and the conclusion that the boundary is fixed at K."
      },
      {
        "Problem": "Incorrect Problem Formulation (Fixed vs. Free Boundary)",
        "Location": "Page 4, Problem formulation (7)-(10); Page 5, Section 3",
        "Explanation": "Based on the unsound assumption of a fixed boundary, the paper formulates the option valuation problem for τ > τ* as solving the Black-Scholes equation with a fixed boundary condition at S=K. However, the seller's right to cancel optimally constitutes a free boundary problem. The optimal cancellation boundary is unknown a priori and must be determined as part of the solution, typically through additional conditions like smooth pasting and high contact, which are not considered in this fixed boundary formulation."
      },
      {
        "Problem": "Likely Incorrect Pricing Formula",
        "Location": "Page 6, Theorem 3.2, formula (13)",
        "Explanation": "The explicit pricing formula for the cancellable European option (Theorem 3.2) is derived directly from the formulation as a fixed boundary problem at S=K. Since the underlying assumption that the optimal boundary is fixed at K is unsound and its attempted justification is flawed, the resulting pricing formula (13) is likely incorrect. The true pricing formula would need to be derived from the solution of the corresponding free boundary problem."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 5248,
      "output": 621
    }
  },
  {
    "entry_id": 85,
    "retraction_id": "1908.07349v3",
    "paper_id": "1908.07349v2",
    "retraction_comment": "the results of theorem 2 is not correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the expansion of $\\varphi(u(z))$ and $\\varphi(v(w))$",
        "Location": "Equations (3.6) and (3.7), Page 6",
        "Explanation": "The formulas provided for the expansion of $\\varphi(u(z))$ and $\\varphi(v(w))$ in terms of the coefficients of $\\varphi$ ($B_i$) and the coefficients of $u$ ($c_j$) or $v$ ($d_j$) appear to be incorrect. The coefficients of a composite function $\\varphi(u(z))$ are typically expressed using Bell polynomials or related formulas, not the Faber polynomials $K_n^1$ as defined in the paper, which are related to the inverse function expansion. This fundamental error affects the coefficient comparison method used throughout the proof."
      },
      {
        "Problem": "Incorrect derivation of equation for $a_2^2$",
        "Location": "Equation (3.22), Page 8",
        "Explanation": "Equation (3.22), which provides an expression for $a_2^2$, is stated to be obtained by adding equations (3.20) and (3.21). However, adding equations (3.20) and (3.21) algebraically results in an expression for $2a_3 - 2a_2^2$, not $a_2^2$. This algebraic error invalidates the subsequent steps in the proof of Theorem 3.6 that rely on this equation to derive bounds for $|a_2|$."
      },
      {
        "Problem": "Incorrect application of Lemma 2.3 to bound $|a_3 - 2a_2^2|$",
        "Location": "Equation (3.17) and the preceding text in the proof of Theorem 3.6, Page 8",
        "Explanation": "The proof states that applying Lemma 2.3 to the coefficients $d_1, d_2$ in equation (3.22) yields the bound for $|a_3 - 2a_2^2|$ in (3.17). Equation (3.22) is an expression for $a_2^2$, not $a_3 - 2a_2^2$. Furthermore, Lemma 2.3 provides bounds for the coefficients $c_n$ and $d_n$ themselves ($|c_n| \\le 1, |d_n| \\le 1$), not directly for combinations of the function coefficients $a_k$ based on expressions involving $c_n, d_n$. This step is logically unsound."
      },
      {
        "Problem": "Unsound derivation of bounds for $|a_2|$ and $|a_3|$",
        "Location": "Equations (3.15) and (3.16), Theorem 3.6, Page 8",
        "Explanation": "The derivation of the bounds for $|a_2|$ and $|a_3|$ in Theorem 3.6 appears unsound. The intermediate steps, particularly the derivation of equation (3.22) and the subsequent application of Lemma 2.3, contain significant errors. Consequently, the resulting bounds presented in equations (3.15) and (3.16) do not appear to be correctly derived from a standard and correct application of the coefficient comparison method for bi-univalent functions. The structure of the bounds (sums within a minimum) is also unusual and suggests potential issues in the final formulas."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 15120,
      "output": 786
    }
  },
  {
    "entry_id": 86,
    "retraction_id": "1310.0331v4",
    "paper_id": "1310.0331v3",
    "retraction_comment": "this paper has been withdrawn by the author due to a crucial error in equation 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect structure for N-fermion wave functions",
        "Location": "Section II, Eq. (5) and (7)",
        "Explanation": "The proposed wave function structures for N=3 and N=4 fermions are presented as sums of terms that are not fully antisymmetric under the exchange of all particles. Fermionic wave functions must be fully antisymmetric. This invalidates the claim that Laughlin wave functions can be represented in this form."
      },
      {
        "Problem": "Unjustified core assumption in Section III",
        "Location": "Section III",
        "Explanation": "The derivation of modified Bose-Einstein and Fermi-Dirac statistics relies on the assumption that pairwise entanglement between particles in specific energy levels (ε_i and ε_{i+1}) leads to equal mean occupation numbers (n_i = n_{i+1}). This crucial assumption is stated without derivation or justification from a physical principle of entanglement, rendering the subsequent statistical modifications based on it unsound."
      },
      {
        "Problem": "Circular reasoning in Section II's main claim",
        "Location": "Section II",
        "Explanation": "The paper claims that pairwise entanglement leads to fractional statistics. However, the argument proceeds by showing that the known Laughlin wave function (which exhibits fractional statistics) can be expressed in a specific entangled form. This demonstrates that the Laughlin state *is* entangled in a certain way, but does not prove that this type of entanglement generally *causes* or *implies* fractional statistics."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 5973,
      "output": 332
    }
  },
  {
    "entry_id": 87,
    "retraction_id": "2308.02854v2",
    "paper_id": "2308.02854v1",
    "retraction_comment": "The assumption that the convex hull of d+2 points in R^d is either a d-simplex or a bi d-simplex is true only in d<4. In higher dimensions, there are more simplical polytopes, among which the cyclic polytope maximalizes the number of facets. As a consequence, there is no simple linear relation between the number of vertices and facets in d>3, from which one could connect the expected values",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect linear relation between face numbers used in the proof.",
        "Location": "Page 4, Proof of Theorem 1",
        "Explanation": "The proof relies on the linear relation (d − 1)f₀(H_{d+2}) - f_{d-1}(H_{d+2}) = (d – 2)(d + 1) holding almost surely for the face numbers of the convex hull of d+2 points. However, for d ≥ 3, the convex hull of d+2 points in general position can have different combinatorial types, and this relation does not hold for all of them (e.g., for d=3, it fails for the triangular prism; for d=4, it fails for the cyclic polytope C(6,4)). This invalidates a key step in the proof."
      },
      {
        "Problem": "Severe algebraic error in deriving the main formula.",
        "Location": "Page 4, Proof of Theorem 1, rearrangement from equation (4) to equation (5)",
        "Explanation": "The algebraic manipulation used to solve for E[vol_d(H_{d+1})] from equation (4) is incorrect. Performing the rearrangement correctly leads to E[vol_d(H_{d+1})] = - (d+1)/(2(d-1)) * Integral(...), which implies a negative expected volume, a physical impossibility. This error invalidates the derived formula in Theorem 1."
      },
      {
        "Problem": "Inconsistency with known result for d=3.",
        "Location": "Theorem 1 (Equation 5) and Equation (1) on page 1",
        "Explanation": "The paper claims that Theorem 1 gives Equation (1) as a special case by setting d=3. However, substituting d=3 into the formula in Theorem 1 yields E[vol₃(H₄)] = 3/5 - Integral(...), which does not match Efron's formula (Equation 1) E[vol₃(H₄)] = 3/5 * Integral(...). This inconsistency confirms that the formula in Theorem 1 is incorrect."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 10234,
      "output": 479
    }
  },
  {
    "entry_id": 88,
    "retraction_id": "1501.01153v3",
    "paper_id": "1501.01153v2",
    "retraction_comment": "Submission withdrawn due to the error in equation 35 on dimensional grounds",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified choice of effective potential for magnetic condensation",
        "Location": "Section 2, Equation (11) and surrounding text",
        "Explanation": "The paper switches from the derived one-loop effective potential (Eq. 10) to a simple quadratic potential (Eq. 11) for inducing magnetic condensation without clear physical justification. This choice is crucial as it determines the relationship between the dual QCD parameters (like glueball masses) and the bag constant, which are central to the subsequent bag model calculations and critical temperature estimations."
      },
      {
        "Problem": "Incorrect determination of critical temperature for baryonic matter",
        "Location": "Section 5, text around Equations (67) and (68), Figure 2, Section 6 text discussing Figure 2",
        "Explanation": "The paper incorrectly assumes that the critical temperature for the nucleon-QGP phase transition is found at the point where the quark chemical potential (and thus nucleon chemical potential) vanishes. The phase transition boundary for baryonic matter is a line in the temperature-chemical potential plane determined by the equality of pressures, and it does not generally occur at zero chemical potential."
      },
      {
        "Problem": "Using massless approximation for nucleon pressure",
        "Location": "Section 5, Equation (65) and derivation from Equation (36)",
        "Explanation": "The pressure for the hadronic phase consisting of nucleons is calculated using the formula for massless fermions (Eq. 36). Nucleons are massive particles (approx. 940 MeV), and using a massless approximation is inaccurate, especially at temperatures around the critical temperature (100-200 MeV), which are comparable to or smaller than the nucleon mass. This significantly affects the calculated hadronic pressure and the phase boundary for baryonic matter."
      },
      {
        "Problem": "Inconsistent application of Gibbs criteria for baryonic matter",
        "Location": "Section 5, text around Equations (66) and (67)",
        "Explanation": "While stating the Gibbs criteria correctly (equality of pressure, temperature, and chemical potential), the paper imposes an additional, incorrect condition (vanishing chemical potential) to find the critical temperature for baryonic matter. The critical temperature for a system with finite baryon density should be found from the intersection of the pressure curves for the hadronic and QGP phases at the given chemical potential, or by finding the phase boundary in the T-mu plane, not by forcing the chemical potential to zero at the transition point."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 3682,
      "output": 551
    }
  },
  {
    "entry_id": 89,
    "retraction_id": "1910.10153v2",
    "paper_id": "1910.10153v1",
    "retraction_comment": "The function \\phi(x) which we define above Eq.8 is infinitely peaked in the thermodynamic limit; the long-time-tail behavior enters through higher derivatives of the entropy",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of internal thermalization timescale vs. driving frequency",
        "Location": "Page 1, Introduction; Page 6, Supplementary Information, Eq. 16",
        "Explanation": "The framework assumes that blocks of size $\\xi(\\omega) \\sim \\sqrt{D/\\omega}$ are internally thermalized on the timescale of the driving frequency $\\omega$. However, the thermalization time for a block of size $L$ is related to its Thouless energy $E_{Th} \\sim D/L^2$. For $L = \\xi(\\omega)$, $E_{Th} \\sim \\omega$, implying a thermalization time $\\sim 1/\\omega$. This is the same timescale as the driving, not much faster, which questions the assumption of internal equilibrium on the relevant timescale."
      },
      {
        "Problem": "Approximation of matrix elements within thermal blocks",
        "Location": "Page 3, Eq. 7; Page 8, Eq. 30; Page 9, Eq. 31",
        "Explanation": "The matrix elements of the electron operator within a thermal block are approximated as constant for energy differences up to the single-particle bandwidth $U$. This is based on RMT predictions, which are typically valid for energy differences below the Thouless energy $E_{Th}$ of the block. For a block of size $\\xi(\\omega)$, $E_{Th} \\sim \\omega$. If $\\omega \\ll U$, energy differences within the block can be much larger than $E_{Th}$, making the RMT-based constant matrix element approximation potentially invalid for these large energy differences contributing to the Kubo formula."
      },
      {
        "Problem": "Justification for incoherent summation at low temperatures",
        "Location": "Page 10, Section C, Eq. 38, 39",
        "Explanation": "At low temperatures, the electron coherence length $\\xi_\\tau$ can be large. The paper sums contributions from coherent volumes $\\xi_\\tau$ within thermal blocks $\\xi(\\omega)$ incoherently, claiming it's due to the probing wavevector $q = \\xi_\\tau^{-1}$. This justification for incoherent summation at scales $\\xi_\\tau$ needs more rigorous support. Incoherent transport usually arises from dephasing or scattering processes, not solely from the probing wavevector. If the summation should be coherent, the calculation based on incoherent summation over coherent volumes is flawed."
      },
      {
        "Problem": "Inconsistency in explaining the distinction between integrable and non-integrable systems at lowest order",
        "Location": "Page 4, Discussion; Page 11, Section 3",
        "Explanation": "The paper claims the framework is relevant for non-integrable systems and fails for integrable ones, supported by numerical results. However, the derivation of the lowest-order transport coefficients (Eq. 32, 36, 39) does not explicitly use properties specific to non-integrable systems (like RMT level repulsion, which appears only in higher-order corrections). This creates a discrepancy: if the lowest-order calculation doesn't use non-integrable properties, the theoretical explanation for why it would fail for integrable systems at lowest order is not clearly established within the derivation."
      },
      {
        "Problem": "Relation between restricted current matrix element and zero-temperature conductivity",
        "Location": "Page 10, Eq. 40, 41, 42, 43",
        "Explanation": "The paper relates the average magnitude of the matrix element of the restricted current operator $J_{\\xi_\\tau}$ between a ground state and an excited state at energy $\\sim T$ to the non-local zero-temperature conductivity $\\sigma(q=\\xi_\\tau^{-1}, \\omega=T, T=0)$. This connection, particularly claiming independence from the initial state energy below $T$ (Eq. 40) and relating a matrix element magnitude to a conductivity, seems non-trivial and requires more detailed justification or derivation."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 2969,
      "output": 902
    }
  },
  {
    "entry_id": 90,
    "retraction_id": "1306.5006v3",
    "paper_id": "1306.5006v2",
    "retraction_comment": "We have decided to withdraw the paper due to a crucial error in equation (9), that is in the definition of the p-value. This invalidates the results reported into the manuscript",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential size distortion for non-i.i.d. models",
        "Location": "Section 3.3, Section 6, Table 1, Figures 5-7",
        "Explanation": "The permutation test used to compute p-values assumes the data is i.i.d. under the null hypothesis of serial independence. However, models M8-M12 (ARCH/GARCH family) generate data that is serially independent but not i.i.d. due to conditional heteroskedasticity. Applying this standard permutation test to raw data from these models may lead to an inflated Type I error rate (size distortion) under the null of serial independence. The simulation study does not show or discuss the size of the KL-ADF (or ADF) for these models under the null, making the power comparison for M8-M12 potentially misleading."
      },
      {
        "Problem": "Insufficient number of permutations in simulation study",
        "Location": "Section 3.3, Section 6.1",
        "Explanation": "The simulation study uses B=99 permutations to compute p-values. This number is relatively low for estimating small p-values accurately, especially around the significance level (alpha=0.05). A low number of permutations can lead to high variability in the estimated p-values and rejection rates, affecting the reliability and precision of the simulation results and power comparisons."
      },
      {
        "Problem": "Fixed grid size for numerical integration",
        "Location": "Section 3.2, Section 5",
        "Explanation": "The integral for the KL divergence estimator is approximated using a fixed 100x100 grid. The accuracy of this approximation depends on the characteristics of the estimated densities. A fixed grid size might not be sufficient for accurately estimating the integral for all sample sizes or data generating processes, potentially introducing significant approximation errors in the test statistic."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 3365,
      "output": 427
    }
  },
  {
    "entry_id": 91,
    "retraction_id": "1704.08680v6",
    "paper_id": "1704.08680v5",
    "retraction_comment": "Algorithm does not terminate. Even if fixed, Claim 9 is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof for Type 2 events in Theorem 6",
        "Location": "Page 8, Proof of Theorem 6",
        "Explanation": "In the analysis of a Type 2 event (Steiner node hitting the simplex), the proof requires that the sum of costs of the linking edges added to the solution is at most (7/6) times (l-1) times the hitting time, where l is the number of components the Steiner node links to. The algorithm guarantees that each linking edge cost is at most the hitting time, so their sum is at most l times the hitting time. The required inequality l * tau''(v) <= (7/6) * (l-1) * tau''(v) simplifies to l <= (7/6)(l-1), which only holds if l >= 7. However, the number of links l can be smaller than 7, invalidating this step of the proof and the derived 7/6 bound."
      },
      {
        "Problem": "Inconsistent growth rate assumption in Proposition 7",
        "Location": "Page 14, Proof of Proposition 7",
        "Explanation": "The proof of Proposition 7, which relates the hitting time of a Steiner node to its linking times, relies on the sum of coordinate increments within a time interval [ti, ti+1] being i(ti+1 - ti). This seems to assume a simple growth rate proportional to the number of links i. However, Algorithm 3 (Page 11, lines 19-20) specifies a more complex modified growth rate for partial Steiner nodes with degree >= 2, which is |Delta^1(v) intersect Lt| / |Lt| * 1/|C intersect R|. The proof does not show that this complex rate leads to the simple i(ti+1 - ti) increment used in the derivation, rendering the proof of Proposition 7 unsound for partial Steiner nodes."
      },
      {
        "Problem": "Flawed proof strategy and definition of c2 in Theorem 8",
        "Location": "Page 15, Theorem 8 and its proof",
        "Explanation": "Theorem 8 introduces an alternative instance I2 with costs c2 to facilitate the proof of the 7/6 approximation ratio. For edges (u,v) in L (the set of links from phase 1), c2(u,v) is defined as (6/7)d(u,v). The simplex-embedding LP requires c(u,v) >= d(u,v) for all edges (u,v) in the graph for gamma(z) to be a lower bound on the optimal cost. By setting c2(u,v) = (6/7)d(u,v) for edges in L, the distance constraint c2(u,v) >= d(u,v) is violated for these edges (since 6/7 < 1). This breaks the fundamental relationship between the LP value gamma(z') and the optimal cost in I2, invalidating the proof strategy that relies on comparing costs in I1 and I2 via the LP."
      },
      {
        "Problem": "Unsoundness in Claim 9 and its proof",
        "Location": "Page 15, Claim 9 and its proof",
        "Explanation": "Claim 9 asserts the existence of an optimal solution T in I1 with a specific structure regarding Steiner components (E(T) intersect Lv is either Lv or empty). This claim is used in the proof of Theorem 8. The proof of Claim 9 is not rigorous; it involves replacing edges incident to a Steiner node u with links from L, arguing about cost changes based on Proposition 7 and t_max. The argument is hand-wavy and does not convincingly demonstrate that optimality and connectivity are preserved after these edge replacements. The illustration in Figure 5 also appears inconsistent with the text regarding edge costs."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 4812,
      "output": 861
    }
  },
  {
    "entry_id": 92,
    "retraction_id": "0710.2117v5",
    "paper_id": "0710.2117v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical error in the geometric formulation of the principle of inertial motion",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect geometric properties of Lorentz transformations in Euclidean space.",
        "Location": "Section 2.2, Eq. (5), Page 2",
        "Explanation": "The paper claims that Lorentz transformations preserve ratios of lengths, areas, and volumes in 4D Euclidean space (x, y, z, ct). This is fundamentally incorrect. Lorentz transformations preserve the Minkowski interval (c²t² - x² - y² - z²) and do not preserve Euclidean distances or volumes in this space. This undermines the geometric foundation claimed for the Euclidean interpretation of special relativity."
      },
      {
        "Problem": "Apparent mathematical error or misinterpretation in connecting derived motion law to Broekaert's model.",
        "Location": "Section 5.2, Eq. (13) and Eq. (28), Page 8 and 9",
        "Explanation": "The paper claims that the derived equation for radial acceleration in Model 2 (Eq. 28, dv₂(r)/dt) is Broekaert's result from Eq. (13) (Ÿ = rφ² - ...). Eq. (13) is an equation for the second derivative of the radial coordinate (Ÿ or r̈), which includes an angular momentum term (rφ²). Eq. (28) is an equation for the derivative of the radial speed (v̇), which includes a radial speed squared term (v₂(r)²). These equations have different forms and terms and do not appear to be equivalent, suggesting an error in the derivation or comparison that is central to the paper's claim of resolving the incompatibility."
      },
      {
        "Problem": "Unjustified relation between speeds in different models.",
        "Location": "Section 5.2, Eq. (19), Page 9",
        "Explanation": "The relation v₂(r) = v₁(r)e⁻³ᵏ/ʳ between the radial speeds in Model 1 and Model 2 is introduced without clear derivation or justification from the proposed Euclidean geometric framework or the motion law. This relation is crucial for connecting Broekaert's model (Model 2) to the model compatible with the motion law (Model 1) and makes the proposed 'solution' appear ad-hoc rather than a consequence of the framework."
      },
      {
        "Problem": "Lack of clear derivation and justification for the energy conservation equation within the Euclidean framework.",
        "Location": "Section 4, Eq. (9) and (10), Page 7",
        "Explanation": "The energy conservation equation (Eq. 9) is presented, and its transformation to a 'familiar form' (Eq. 10) involving a position-dependent mass m₀(r) is mentioned. However, the specific form of Eq. (9) and its derivation from the Euclidean geometric principles are not clearly shown. The reliance on Broekaert's work, which uses a different interpretation (Lorentz-Poincaré), raises questions about the internal consistency of the derivation within the proposed Euclidean framework."
      },
      {
        "Problem": "Problematic formulation and application of the Euclidean principle of general covariance.",
        "Location": "Section 3.1, Page 6",
        "Explanation": "The principle states that laws are covariant if geometric relations are conserved under coordinate transformations. However, the paper previously claimed that Lorentz transformations (a specific type of coordinate transformation) preserve Euclidean ratios, which is incorrect. If the principle applies to general coordinate transformations in a curved Euclidean space, these transformations would not generally preserve Euclidean ratios, making the condition for covariance difficult to satisfy or apply meaningfully in the way suggested. This inconsistency weakens the foundation of the proposed covariance principle."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 4513,
      "output": 804
    }
  },
  {
    "entry_id": 93,
    "retraction_id": "1111.3825v3",
    "paper_id": "1111.3825v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in lemma 3.7",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption of 'trivial parabolic structure'",
        "Location": "Abstract, page 2, Theorem 3.1, Definition 2.4",
        "Explanation": "The paper assumes the harmonic bundle has a 'trivial parabolic structure' as defined in Definition 2.4, which implies the metric is bounded by uniform powers of |z| near the divisor. However, the harmonic bundles arising from reductive representations with unipotent local monodromy via Jost-Zuo's theorem [3] are generally only tame and nilpotent. The metric for such bundles typically exhibits more complex asymptotic behavior related to the weight filtration of the nilpotent monodromy (as described in Mochizuki [5] and Lemma 3.8), not a uniform power bound. This strong condition is not guaranteed by the initial setup or the cited result [3] and likely invalidates the L2 cohomology calculations."
      },
      {
        "Problem": "Inconsistency between Definition 2.4 and Lemma 3.8",
        "Location": "Definition 2.4, Lemma 3.8",
        "Explanation": "Definition 2.4 defines 'trivial parabolic structure' using a uniform power bound for the metric of multiple-flat sections near the divisor. In contrast, Lemma 3.8 provides an estimate for the metric of any section involving the endomorphism K, which is related to the weight filtration of the nilpotent monodromy. This estimate shows that the asymptotic behavior depends on the section, contradicting the uniform bound implied by Definition 2.4. This internal inconsistency suggests a fundamental issue with the understanding or application of the properties of these bundles."
      },
      {
        "Problem": "Unjustified assumption of 'real structure'",
        "Location": "Page 2, Theorem 3.1, Definition 2.5",
        "Explanation": "The paper assumes the harmonic bundle possesses a 'real structure' as defined in Definition 2.5. While harmonic bundles corresponding to polarized variations of Hodge structure (PVHS) have such a structure, the paper starts from a general reductive representation with unipotent local monodromy. Such representations do not automatically guarantee the existence of a real structure on the associated harmonic bundle. This is a strong additional condition not justified by the initial setup or the cited result [3]."
      },
      {
        "Problem": "Claim that the proof is 'exactly the same' as Kashiwara-Kawai [4], §5.12",
        "Location": "Page 9",
        "Explanation": "The paper claims the rest of the proof is 'exactly the same' as Kashiwara-Kawai [4], §5.12. However, [4] deals with PVHS, which have specific properties (polarization, weight filtration) crucial for their L2 analysis. The harmonic bundles here, while related, do not automatically possess these properties in the same way unless explicitly linked via Simpson's correspondence for PVHS. Given the likely incorrect assumption about the 'trivial parabolic structure' (Problems 1 & 2), the L2 analysis and subsequent steps cannot be directly identical or applicable without significant justification based on the specific properties of the harmonic bundle in question."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 4169,
      "output": 687
    }
  },
  {
    "entry_id": 94,
    "retraction_id": "1711.04838v3",
    "paper_id": "1711.04838v2",
    "retraction_comment": "Lemma 9.1 is incorrect and so the main result is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 8.2",
        "Location": "Page 9, Lemma 8.2 Proof",
        "Explanation": "The proof attempts to rule out the case where one triple point is degenerate and the other is non-degenerate. Case (i) incorrectly claims that two m/t-edges at T2 must coincide and form a double point circle with a single triple point, contradicting Lemma 2.1. Case (ii) does not provide a clear contradiction based on the number of degenerate edges, and the argument about edge connections between triple points of different degeneracy types is unclear."
      },
      {
        "Problem": "Flawed proof of Lemma 8.5",
        "Location": "Page 10, Lemma 8.5 Proof",
        "Explanation": "The proof relies on an unjustified inequality (#d(T1) + #d(T2) ≥ 4) presented as Equation (1). The subsequent deduction 'But this arises from Equation 1' is not a valid logical step. The argument attempting to rule out cases where T1 or T2 are non-degenerate also appears incomplete or flawed regarding the connectivity of degenerate/non-degenerate edges between triple points."
      },
      {
        "Problem": "Theorem 8.6 Proof relies on flawed lemmas",
        "Location": "Page 10, Theorem 8.6 Proof",
        "Explanation": "The proof states that the theorem follows from Lemmas 8.2, 8.4, and 8.5. As the proofs of Lemma 8.2 and Lemma 8.5 appear unsound, the proof of Theorem 8.6, which concludes that the cocycle invariant is an integer for diagrams with at most three triple points, is also unsound."
      },
      {
        "Problem": "Flawed proof of Lemma 9.1",
        "Location": "Page 11, Lemma 9.1 Proof",
        "Explanation": "The proof attempts to derive a contradiction by considering the intersection of double decker curves in the first homology group of the surface-knot. The argument that a curve (CU) intersects the union of itself and another curve (CU UCL) at a single crossing point is geometrically and topologically incorrect, invalidating the subsequent homology deduction."
      },
      {
        "Problem": "Flawed proof of Theorem 9.2",
        "Location": "Pages 11-12, Theorem 9.2 Proof",
        "Explanation": "The proof enumerates several cases for double point circle configurations and attempts to rule them out using arguments about intersections and homology of double decker curves. These arguments suffer from the same fundamental flaw as identified in the proof of Lemma 9.1 regarding the intersection of double decker curves, rendering the entire proof unsound. This directly impacts the conclusion of Theorem 9.3 that the triple point number for genus-one surface-knots is at least four."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 7652,
      "output": 646
    }
  },
  {
    "entry_id": 95,
    "retraction_id": "2010.13204v2",
    "paper_id": "2010.13204v1",
    "retraction_comment": "The conclusion of the paper is likely wrong. The second necessary integration step which is barely mentioned at the end of section B introduces another correlation between the vacuum fluctuations which will negate any gain of the here proposed method. I overlooked this. Thanks to [REDACTED-NAME] for figuring it out",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The fundamental equation describing the feedback loop is dimensionally inconsistent.",
        "Location": "Page 2, Section II.A, Equation Psig^int = r Psig^int e^(i(Ω(t-2τ)+ΦRF)) + E0 Esig e^(i(ω0+Ω)(t-τ))",
        "Explanation": "This equation attempts to describe the system's dynamics but mixes quantities that appear to represent power or amplitude (Psig^int, r) with quantities representing field amplitudes (E0, Esig). This dimensional inconsistency makes the equation physically unsound and invalidates subsequent derivations based on it."
      },
      {
        "Problem": "The application of the geometric series summation for gain calculation is based on a likely incorrect recurrence relation.",
        "Location": "Page 2, Section II.A, Equation Psig^int = EoEsig / (1 - r e^(-iΦRT))",
        "Explanation": "The derivation of the signal gain relies on the preceding inconsistent equation. The mechanism of gain in this active electronic feedback system, based on detected signal amplitude modulating an injected field, is fundamentally different from coherent field superposition in a passive optical cavity. Applying the geometric series sum derived from the flawed recurrence relation is not justified and likely incorrect."
      },
      {
        "Problem": "The calculation of the integrated signal energy/power (S) appears incorrect.",
        "Location": "Page 3, Section II.B, Equation S = N_S T / (1-r)",
        "Explanation": "If N_S represents the signal power without feedback (photon rate), and the amplitude gain of the system is proportional to 1/(1-r), the power gain should be proportional to 1/(1-r)^2. The integrated signal energy should therefore be proportional to N_S T / (1-r)^2, not N_S T / (1-r)."
      },
      {
        "Problem": "The claim that the signal-to-noise ratio (SNR) is identical to the regeneration cavity is based on the incorrect signal calculation.",
        "Location": "Page 3, Section II.B, SNR formula and subsequent text",
        "Explanation": "The SNR formula uses the incorrect signal term S = N_S T / (1-r). When comparing this SNR to the known SNR for a passive cavity (where signal power gain is proportional to 1/(1-ρ1ρ2)^2), the signal terms do not match when equating r with ρ1ρ2, leading to the conclusion that the SNRs are not identical, contrary to the paper's claim."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 17436,
      "output": 580
    }
  },
  {
    "entry_id": 96,
    "retraction_id": "2208.11892v3",
    "paper_id": "2208.11892v2",
    "retraction_comment": "Lemma 3.2 does not hold. A counter example is $f \\equiv 1$",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradiction in the condition on p for absorbing a term in the proof of (2.21) for p > 2, Case 1.",
        "Location": "Page 19, Proof of (2.21) for p > 2, Case 1, Step 4",
        "Explanation": "In Step 4 of the proof for the case |λ| ≤ O(h⁻²), the paper states that the desired estimate (8.1) is established provided that p > 2 satisfies N/p - 1 < 0, which is p > N. This condition is used to absorb the term CK hᴺ/ᵖ⁻¹ ||e||Lᵖ(Ωh) into the left-hand side. However, for this absorption to work for small h, the coefficient hᴺ/ᵖ⁻¹ must be small, which requires N/p - 1 > 0, i.e., p < N. This is a direct contradiction to the stated condition p > N, indicating a fundamental error in the argument for this case."
      },
      {
        "Problem": "Unproven error estimate for the dual problem solution used in the proof of (2.22) for p < 2.",
        "Location": "Page 20, Proof of (2.22) for p < 2",
        "Explanation": "The proof of the Lᵖ error estimate for the velocity ||e||Lᵖ(Ωh) when p < 2 relies on a duality argument. A key step involves bounding the error of the finite element solution to the dual problem, U - Uh. The paper uses the estimate ||U - Uh||Lᵖ'(Ωh) ≤ C a(h, λ) ||φ||Lᵖ'(Ω), where a(h, λ) = min{h², h|λ|⁻¹/², |λ|⁻¹}. This is an error estimate of the same type as the main results (Theorem 2.2) that the paper aims to prove for the primal problem. Assuming this estimate for the dual problem without providing a proof or a reference where it is established using the paper's framework makes the argument incomplete and potentially circular."
      },
      {
        "Problem": "Flawed derivation of the main resolvent estimate (1.4) from the error estimates.",
        "Location": "Page 22, Section 9, Proof of Theorem 2.1",
        "Explanation": "The proof of the main resolvent estimate (1.4) for the finite element solution (uh, φh) relies on combining the known resolvent estimate for the exact solution (1.2) and the error estimates (2.21) and (2.24). The combination shown in the text, particularly for the velocity estimate, does not appear to correctly yield the desired form (|λ|+1)||uh||Lᵖ(Ωh) + |λ|¹/²||∇uh||Lᵖ(Ωh) ≤ C||f||Lᵖ(Ω). The terms involving |λ| and the error norms do not seem to combine in a way that is uniformly bounded by ||f||Lᵖ(Ω) for all λ ∈ Σδ. This suggests an issue in the final step connecting the error estimates to the resolvent estimate for the finite element solution."
      },
      {
        "Problem": "Unverified claim about the half-space regularity estimate for N=2.",
        "Location": "Page 7, Lemma 3.2 Proof",
        "Explanation": "The proof of the higher regularity estimate for the Stokes resolvent problem on bounded domains relies on a known result for the half-space from [27]. The paper states that the result from [27, Theorem 8.1] holds for N=3 and can be proved for N=2 by modifying the argument in [27]. However, [27] is specifically titled and focused on N=3. Without a detailed explanation or a reference confirming this modification is straightforward and correct, this step in the proof of Lemma 3.2 is not fully justified, potentially impacting the subsequent use of W³,ᵖ × W²,ᵖ regularity."
      }
    ],
    "token_usage": {
      "input": 8380,
      "thinking": 15616,
      "output": 906
    }
  },
  {
    "entry_id": 97,
    "retraction_id": "1507.00282v2",
    "paper_id": "1507.00282v1",
    "retraction_comment": "This paper has been withdrawn due to a crucial error in the proof of Proposition 14. The authors are very thankful to [REDACTED-NAME] for kindly pointing it out",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 2704,
      "thinking": 22237,
      "output": 1
    }
  },
  {
    "entry_id": 98,
    "retraction_id": "1707.00947v2",
    "paper_id": "1707.00947v1",
    "retraction_comment": "I am so sorry, the hypothesis proposed by this paper would be not appropriate because there is no mechanism on which can be based between money and output value in this paper. The equation maybe more empty",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Arbitrary and Unjustified Core Dynamic Equation",
        "Location": "Page 4-5, Equation (2)",
        "Explanation": "The fundamental dynamic equation M(t) - P(t)Y(t) = k * d[P(t)Y(t)]/dt is introduced as a 'speculated' equation without theoretical derivation or justification from economic principles. This lack of foundation for the core dynamic relationship makes the subsequent derivations and conclusions questionable."
      },
      {
        "Problem": "Inconsistent Long-Run Velocity Behavior",
        "Location": "Page 7, 8, 9-10",
        "Explanation": "The model predicts different long-run behaviors for the velocity of money (PY/M) depending on the assumed functional form of money supply M(t). It approaches 1 for constant or linear M, but approaches 1/(1+kq) for exponential M. This inconsistency undermines the generality and theoretical coherence of the model's long-run predictions."
      },
      {
        "Problem": "Contradiction Between Model Predictions and Empirical Evidence",
        "Location": "Page 7, 8, 10, 12, Figure 1",
        "Explanation": "The paper presents empirical evidence (Figure 1) supporting the standard quantity theory result c ≈ q - g in the long run. However, the paper's dynamic model only predicts c = q - g for the specific case of exponential money growth (M(t)=M0*e^(qt)) under a condition (q > -1/k). For other cases analyzed (constant M, linear M), the model predicts c = -g. The empirical evidence contradicts the model's predictions for these other cases, suggesting the model is not generally consistent with the data presented."
      },
      {
        "Problem": "Unjustified Hypothesis of Economic Cycles",
        "Location": "Page 13-19, Figures 2, 3, 4, 5, Tables 2, 3",
        "Explanation": "The hypothesis of 'natural cycle' assumes the economy cycles along the long-run equilibrium line c = q - g for a fixed money growth rate q. This cyclical movement is not derived from the core dynamic model (Eq 2), which describes the path towards equilibrium, not cycles along it. The entire framework of natural and driving cycles is built upon this unproven assumption."
      },
      {
        "Problem": "Misinterpretation of Model Results and Causation",
        "Location": "Page 12, 25, 27",
        "Explanation": "The paper misinterprets the derived relationship between price and output (Eq 16) as both a demand and supply function, which is not supported by the model's structure. It also makes strong claims about causation, such as inflation being 'only' caused by accelerated money growth or decelerated output growth, which are not fully or accurately supported by the model's derived long-run relationships."
      }
    ],
    "token_usage": {
      "input": 7606,
      "thinking": 6451,
      "output": 663
    }
  },
  {
    "entry_id": 99,
    "retraction_id": "2212.04536v2",
    "paper_id": "2212.04536v1",
    "retraction_comment": "Thm. A, Cor. B, are incorrect as stated and would require additional assumptions on q (a result of a missing assumption in another paper). Withdrawn until I obtain a working solution",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 3.2 regarding the restriction of the character Îu,2.",
        "Location": "Page 3, Lemma 3.2 proof",
        "Explanation": "The proof claims that Res_G+(Îu,2) = Γu holds because the unipotent element u is conjugate to u^τ by an element of G, which implies τg^-1 is in CG+(u). However, the cited source ([SFT22, Lem. 6.4 and Rem. 6.5]) states that this equality holds if CG+(u) is contained in G. The condition that u is conjugate to u^τ by an element of G implies CG+(u) is *not* contained in G (as it contains elements like gτ), directly contradicting the requirement from the cited source and invalidating the deduction."
      },
      {
        "Problem": "Flawed proof of Theorem A due to incorrect statements about character properties under Galois action.",
        "Location": "Page 3, Proof of Theorem A",
        "Explanation": "The proof contains the statement \"But since ŷ^σ ∈ {x, xβ} must be an extension of x\". This is incorrect; ŷ^σ is a character of G+, while x and xβ are characters of G. Furthermore, if ŷ is an extension of x, then ŷ^σ is an extension of x^σ, not necessarily x, even when σ stabilizes Q(x). The subsequent deductions based on this incorrect statement are invalid, undermining the proof that Q(ŷ) = Q(x)."
      },
      {
        "Problem": "Flawed proof of Corollary B due to misapplication of previous results and incorrect deductions.",
        "Location": "Page 4, Proof of Corollary B",
        "Explanation": "The proof attempts to apply Theorem A, which is stated for G = GLn(q), to the group S<τ> where S = PSLn(q). This is an incorrect application of Theorem A. Additionally, the proof applies Lemma 3.4, which is stated for extending characters of G=GF to G(Fo), to extending characters of S=PSLn(q) to S<Fo>. The notation G(Fo) in Lemma 3.4 is also confusing and likely intended to be G<Fo>, but applying it to S=PSLn(q) (a quotient group) is not justified by the lemma's statement. The deduction that the extension X2 is τ-invariant is also not directly supported by Lemma 3.4."
      },
      {
        "Problem": "Flawed proof of Theorem 4.1 for Lie type cases due to reliance on flawed results and incorrect arguments.",
        "Location": "Pages 5-6, Proof of Theorem 4.1 (discussion of Lie type groups with q odd)",
        "Explanation": "The proof relies on Corollary B and Lemma 3.4, whose proofs appear flawed (see Problems 3 and 1/3). The arguments for specific cases like PSU3(q) and PSL2(q) also contain errors, such as mixing the action of the transpose-inverse automorphism (τ) with the Galois automorphism (σ), confusing characters of G and G* in the duality context, and making unclear or incorrect deductions about character properties and conjugacy."
      },
      {
        "Problem": "Flawed proof of Theorem C due to misapplication of Theorem 4.1 and confusion of groups.",
        "Location": "Page 6, Proof of Theorem C",
        "Explanation": "The proof attempts to use Theorem 4.1 and the argument structure from [DNT08, Thm. A]. However, it misapplies Theorem 4.1 (which provides a character of an almost simple group H = NG(S1)/CG(S1)) in the context of constructing a character of G from a character of its minimal normal subgroup N = S1 x ... x Sk. The statement \"Taking η ∈ Irr(N) to be the character θ × 1_{S_2} × ... × 1_{S_k}, we have G_η ⊆ H\" is incorrect; G_η is a subgroup of G, while H is a quotient group related to S1. This fundamental confusion of groups invalidates the lifting argument."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 13183,
      "output": 942
    }
  },
  {
    "entry_id": 100,
    "retraction_id": "1405.2435v10",
    "paper_id": "1405.2435v9",
    "retraction_comment": "lemmas 11 is wrong. The conjecture is not proved.",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 11 regarding path extension spaces.",
        "Location": "Page 13, Proof of Lemma 11 and subsequent text before Lemma 12.",
        "Explanation": "The proof introduces an unstated and unjustified assumption that the minimality of |N(u)| is preserved under path extension (|N(uβ)| = |N(u)|). This assumption is not supported by Corollary 10 and leads to circular reasoning or a non-sequitur in the argument that path extensions stay within the set of spaces Vp."
      },
      {
        "Problem": "Unjustified matrix equalities and relations in Lemma 11 proof continuation.",
        "Location": "Page 14, Continuation of the proof of Lemma 11 (between Lemma 11 and 12).",
        "Explanation": "The proof makes critical claims such as Lx = Lβy and Lβy = MβLy without rigorous derivation from the definitions and previous lemmas. The relationship between matrices of type Lu (defined in Section 5) and minimal solutions Ly of MuLx=Ms (defined in Section 6) is not clearly established, making these equalities appear unfounded."
      },
      {
        "Problem": "Unsound deduction in Lemma 12.",
        "Location": "Page 15, Proof of Lemma 12.",
        "Explanation": "The proof relies on the flawed Lemma 11 and makes unsubstantiated claims about the relationship between the length of a path, the dimension of the generated space Vp, and the condition |N(u)| > 1. The argument that a new space appears until |N(u)|=1 is reached is not logically derived from Lemma 11."
      },
      {
        "Problem": "Theorem 1's proof is invalid due to reliance on flawed lemmas.",
        "Location": "Page 16, Theorem 1.",
        "Explanation": "The proof of Theorem 1 directly depends on the conclusion of Lemma 12. Since the proof of Lemma 12 is unsound due to its reliance on the flawed proof of Lemma 11 and unjustified matrix relations, the proof of Theorem 1 (claiming the Černy conjecture) is invalid."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 4523,
      "output": 497
    }
  },
  {
    "entry_id": 101,
    "retraction_id": "1705.07013v2",
    "paper_id": "1705.07013v1",
    "retraction_comment": "The proofs involve use of structured input states which could not be generalized",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of Fidelity of Deletion",
        "Location": "Section II, Eq. 7",
        "Explanation": "The paper defines the fidelity of deletion as Fd = (1+η₂)/2. However, the correct definition is the overlap between the output state ρ₂ and the blank state ρ(Σ), which is Fd(m) = Tr(ρ(Σ) ρ₂) = (1 + η₂ m⋅b)/2, where b is the Bloch vector of the blank state Σ. This fidelity depends on the input state m and the blank state b, unless η₂=0 or b=0. For a universal state-independent machine, the fidelity should typically be the minimum over all input states, Fd = min_m Fd(m) = (1 - |η₂|)/2 (assuming |b|=1). The paper's definition is incorrect and affects the optimization problem."
      },
      {
        "Problem": "Unjustified derivation of No-Signaling constraints",
        "Location": "Section II, Eq. 10 and Eq. 12",
        "Explanation": "The paper derives crucial constraints on the machine parameters (Eq. 12) from the no-signaling principle applied to specific input mixtures (Eq. 10). However, the derivation is not provided, and the method of applying the no-signaling principle to identical input mixtures (both representing the maximally mixed state) is highly unconventional and lacks clear justification in the context of preventing superluminal communication via the deletion machine. The standard application of no-signaling for a process acting on ρ⊗ρ would imply the reduced output states are independent of ρ, leading to different constraints (η₁=0, η₂=0). The validity of the constraints and thus the resulting bound is questionable."
      },
      {
        "Problem": "Inconsistency regarding the blank state",
        "Location": "Section II, Eq. 5, Eq. 7, and optimal parameters",
        "Explanation": "The blank state |Σ> is a fixed state of the deletion machine, represented by a fixed Bloch vector b (Eq. 5). The fidelity of deletion Fd depends on this blank state (Fd(m) = (1 + η₂ m⋅b)/2). However, the paper's definition Fd = (1+η₂)/2 (Eq. 7) does not depend on b. While the optimal solution found has η₂=0 (making Fd=1/2 regardless of b), the general formulation and definition of Fd are inconsistent with the concept of a fixed blank state when η₂ is non-zero."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 9024,
      "output": 582
    }
  },
  {
    "entry_id": 102,
    "retraction_id": "1801.01544v2",
    "paper_id": "1801.01544v1",
    "retraction_comment": "We withdraw the manuscript because Lemma 2.3 is false",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect scaling in the blow-up argument for a priori estimates.",
        "Location": "Proof of Theorem 3.1 (Page 9-11), Proof of Theorem 1.2 (Page 11), Proof of Theorem A.1 (Page 25), Equation (3.9).",
        "Explanation": "The blow-up argument relies on scaling the equation $(-\\Delta)^s u_k = f(u_k)$ to obtain a limit equation in $\\mathbb{R}^N$. The scaled equation for $v_k(y) = \\lambda_k^{-1} u_k(x_k + \\lambda_k y)$ should be $(-\\Delta)^s v_k(y) = \\lambda_k^{2s-1} f(\\lambda_k v_k(y))$. For $f(u)=u^p$, this is $\\lambda_k^{2s-1+p} v_k(y)^p$. Equation (3.9) incorrectly states $(-\\Delta)^s v_k(y) = v_k(y)^p$. Since $\\lambda_k \\to 0$, this equality requires $2s-1+p=0$, which contradicts the assumption $p>1$. This fundamental error invalidates the blow-up arguments used to prove the a priori estimates in Theorems 3.1, 1.2, and A.1."
      },
      {
        "Problem": "Incorrect inequality used in Lemma 4.1.",
        "Location": "Proof of Lemma 4.1 (Page 14), inequality (4.6).",
        "Explanation": "The inequality (4.6), $\\int_\\Omega u \\phi_1 dx \\le (2\\lambda_1)^{-1} \\int_\\Omega u^p \\phi_1 dx + (2\\lambda_1)^{-1} \\int_\\Omega \\phi_1 dx$, is used to derive crucial $L^1$ and $L^p(\\Omega, \\delta^s)$ estimates for weak solutions in Lemma 4.1. This inequality appears to be incorrectly derived from Young's inequality or other standard estimates. Lemma 4.1 is a foundational result for the existence theorems (Theorem 1.7, 1.8, 1.10) and the regularity result (Proposition 1.6). Its unsoundness undermines the validity of these subsequent theorems."
      },
      {
        "Problem": "Flawed bootstrap argument for regularity of weak solutions.",
        "Location": "Proof of Proposition 1.6 (Page 12-14).",
        "Explanation": "The proof attempts to show that a weak solution is locally $C^{2s+\\alpha}$ by an iterative bootstrap argument on $L^q$ norms on shrinking balls, using Lemma 2.8(ii). This lemma requires the $L^t$ exponent of the source term to be less than $N/2s$. The argument defines a sequence of exponents $t_k$ and claims $t_{k+1} > t_k$. The conditions required for applying Lemma 2.8(ii) and for the exponent to increase are not rigorously shown to hold for $p$ in the assumed range $(1, p_s)$, making the regularity result questionable."
      },
      {
        "Problem": "Potential issue with integrability assumption in the Mountain Pass argument.",
        "Location": "Proof of Theorem 1.10 (Page 22-23), Claim 2.",
        "Explanation": "The proof of Claim 2, essential for establishing the Palais-Smale condition for the Mountain Pass functional, requires the term $\\int_\\Omega u_\\rho^{p-1} v_n (v_n - v) dx$ to converge to zero. This relies on $u_\\rho^{p-1} \\in L^2(\\Omega)$. Using the estimate $u_\\rho(x) \\le C \\rho |x|^{-(N-s)}$ near $x=0$, the integrability requires $2(p-1)(N-s) < N$. This condition is not guaranteed by the assumption $p < p_s = \\frac{N+s}{N-s}$ unless $N > 4s$. If $N \\le 4s$, the integrability might fail, potentially invalidating the proof of Claim 2 and the existence of a second solution via the Mountain Pass theorem (Theorem 1.10) in this case."
      }
    ],
    "token_usage": {
      "input": 7090,
      "thinking": 10705,
      "output": 1001
    }
  },
  {
    "entry_id": 103,
    "retraction_id": "2101.02111v2",
    "paper_id": "2101.02111v1",
    "retraction_comment": "We have found some data mistakes in our paper. The inverse transition in Section 3 (Figure 3d) and 7.1 (Figure 31) is probably consequence of inappropriate mesh configuration",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Pipe length limitation affecting transition phenomena",
        "Location": "Section 2 (page 7), Section 7.1 (page 45-46), Section 8 (page 47)",
        "Explanation": "The computational domain length (3D) is acknowledged to be potentially too short to accommodate large-scale turbulent structures like puffs or slugs, which are relevant to transition and decay processes in pipe flow. This limitation may affect the observed laminarization and sudden inverse transition phenomena, making the conclusions regarding the mechanisms of these specific processes potentially dependent on the domain size."
      },
      {
        "Problem": "Speculative explanation for inverse transition at high amplitude",
        "Location": "Section 7.1 (page 44-45), Figure 31",
        "Explanation": "The paper observes a sudden inverse transition from a near-laminar state back to turbulence for high amplitude control (e.g., A+=30, Figure 3d). The explanation provided for this phenomenon is presented as a 'plausible scenario' and is speculative, linking it to centrifugal instability and the invasion of streaming. A definitive mechanism for this critical loss of drag reduction at high amplitude is not fully established or supported by conclusive evidence within the paper."
      },
      {
        "Problem": "Interpretation of positive circumferential correlation as streak destruction",
        "Location": "Section 5.4 (page 29), Figure 20",
        "Explanation": "The observation that the near-wall circumferential two-point correlation becomes positive for controlled cases (Figure 20) is interpreted as the 'destruction of near-wall alternately low- and high-speed streaks'. However, instantaneous flow visualizations (Figure 25) still show alternating patterns, albeit modified. The positive statistical correlation is attributed to the unsteadiness and circumferential convection induced by transverse advection, which decorrelates the structures in the statistical average. Interpreting this statistical result as complete 'destruction' of the instantaneous alternating streak pattern might be an overstatement or misinterpretation."
      },
      {
        "Problem": "Inconsistent claims regarding streamwise momentum balance terms",
        "Location": "Section 4.1 (page 11-12), Figure 6(a)",
        "Explanation": "The paper initially claims that streaming (ūzur) and streamwise non-homogeneity (Nz) terms are negligible for 'most cases' in the streamwise momentum balance. However, for the case (λz+=1695, A+=30), the deviation from the simplified balance (excluding these terms) is stated to be nearly 15%, which is significant and indicates these terms are not negligible for this case. While the analysis for this specific case (Figure 6b) includes these terms, the initial broad claim of negligibility is not precisely defined or fully justified for all cases studied, potentially causing confusion."
      }
    ],
    "token_usage": {
      "input": 13540,
      "thinking": 5416,
      "output": 625
    }
  },
  {
    "entry_id": 104,
    "retraction_id": "1703.04839v2",
    "paper_id": "1703.04839v1",
    "retraction_comment": "Our discussion omits the dominant tree-level shift (discussed in 1203.0237) of the Higgs quartic coupling in the full theory relative to the Higgs quartic coupling of the low-energy effective Standard Model. This shift can easily the electroweak vacuum. Therefore our conclusions (and upper bound on $f_a$) are invalid",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent order of Renormalization Group equations used for coupling running.",
        "Location": "Section II, equations (2)-(6) and subsequent running calculation.",
        "Explanation": "The calculation of coupling running combines 2-loop Standard Model beta functions with only 1-loop contributions from the new axion sector couplings. Given the large assumed value of the portal coupling λhφ (O(0.1-1)), the missing 2-loop contributions involving these large couplings (e.g., to the Higgs self-coupling beta function) are likely significant and could substantially alter the running of couplings, thereby affecting the calculated vacuum instability scale and the derived upper bound on fa."
      },
      {
        "Problem": "Unjustified claim of the electroweak vacuum being the global or unique minimum.",
        "Location": "Section II, discussion of Figure 1 and effective potential (Eq 7); Section III, conclusions.",
        "Explanation": "The paper claims that the electroweak vacuum can become 'completely stable' or the 'only minimum' based on the leading-log approximation V(h) ≈ λh(h)h^4/4. This approximation is only sufficient to determine stability against decay to large field values (where λh becomes negative). It does not provide information about the existence or depth of other potential minima or the presence of potential barriers. A proper analysis of the global minimum structure requires a more complete calculation of the effective potential, including field-dependent terms and potentially higher-loop corrections."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 9103,
      "output": 331
    }
  },
  {
    "entry_id": 105,
    "retraction_id": "1704.03487v2",
    "paper_id": "1704.03487v1",
    "retraction_comment": "Due to the limitations of the interatomic potential used, it was not possible to ensure the accuracy of some of the results in the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inaccurate interatomic potential for the precipitate phase",
        "Location": "Page 4, Section 3.1",
        "Explanation": "The chosen Mendelev MEAM potential predicts a positive formation energy for the β-Mg17Al12 phase (49 meV/atom), which contradicts DFT calculations (-39 meV/atom). This significant discrepancy in the stability of the precipitate phase could lead to inaccurate predictions of precipitate properties and dislocation interactions."
      },
      {
        "Problem": "Limited scope of thermal activation study",
        "Location": "Page 19-21, Section 4.3",
        "Explanation": "Molecular dynamics simulations to study thermal activation were only performed at two temperatures (150K, 350K) and for a single precipitate size (8 nm diameter). The conclusion about the low activation free energy and rapid stress decrease with temperature relies on fitting to a phenomenological model (Friedel's) and comparison with Al-Cu data, which may not be fully applicable or sufficient to characterize the thermal behavior of dislocation-precipitate interaction in Mg-Al."
      },
      {
        "Problem": "Inappropriate comparison of shearing stress with Orowan stress",
        "Location": "Page 16, Section 4.2",
        "Explanation": "The paper compares the critical resolved shear stress (CRSS) for precipitate shearing with the theoretical Orowan stress, which is calculated based on a bypass mechanism. While the paper notes that shearing is observed, comparing a shearing stress to a bypass stress is not a direct comparison of the same mechanism and can be misleading when discussing strengthening potential."
      },
      {
        "Problem": "Potential artifacts from simulation setup preventing Orowan loop observation",
        "Location": "Page 5-7, Section 3.2; Page 16, Section 4.2",
        "Explanation": "The simulation box size and periodic boundary conditions, while chosen to minimize image forces, might be too small or restrictive to allow for the full formation and expansion of Orowan loops around the precipitates, especially for larger precipitate sizes. The conclusion that Orowan loops were 'never observed' might therefore be an artifact of the simulation setup rather than a definitive statement about the material's behavior."
      },
      {
        "Problem": "Simplified precipitate geometry",
        "Location": "Page 6, Section 3.2; Page 8, Section 4.",
        "Explanation": "The precipitates are modeled as simple circular disks with a constant height of 3 nm. Real β-Mg17Al12 precipitates are often lath-shaped or lozenge-shaped with varying aspect ratios. This simplification in geometry may not accurately capture the complex interaction between dislocations and precipitates of realistic shapes and could affect the calculated CRSS and interaction mechanisms."
      }
    ],
    "token_usage": {
      "input": 7348,
      "thinking": 1919,
      "output": 624
    }
  },
  {
    "entry_id": 106,
    "retraction_id": "2402.04633v2",
    "paper_id": "2402.04633v1",
    "retraction_comment": "An auxiliary result (Theorem 2.4) turns out to be wrong. This invalidates the proof of the main result",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof of the commutation relation for the codifferential",
        "Location": "Page 9-10, Lemma 1.11",
        "Explanation": "The proof of the second part of Lemma 1.11, which claims that the pullback map π* intertwines the codifferential operators δ∇ and δπ*∇, relies on statement (11). Statement (11) claims that δπ*∇(π*η) is in the image of π*. The justification provided for (11) (namely, the equality δπ*∇(π*(β ⊗ Z)) = π*(δ∇(β ⊗ Z))) is essentially the conclusion of Lemma 1.11 itself, making the argument circular. While statement (11) might be true for other reasons (e.g., O(q)-invariance as suggested by Lemma 1.13 and Corollary 1.16), the proof as written is invalid. This invalidates Lemma 1.11 as proven in the paper, and Lemma 1.11 is a crucial step in the proof of Proposition 2.1, which is the core of the main theorem."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 15825,
      "output": 265
    }
  },
  {
    "entry_id": 107,
    "retraction_id": "2408.08124v4",
    "paper_id": "2408.08124v3",
    "retraction_comment": "Achieving reliable simulation of closed new domain formation processes using a single phase-field method is unconvincing and requires the use of multiple algorithms for parallel comparison with experiments",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Cutoff frequency calculation error",
        "Location": "Section III, last paragraph",
        "Explanation": "The calculated cutoff frequency using the provided transconductance (gm = 2.75 µS) and input capacitance (Cgs = 12.10 aF, assuming Cgd is negligible or included) is approximately 36.2 GHz (ft = gm / (2πCgs)). This is significantly lower than the reported 0.228 THz (228 GHz), invalidating the claim of achieving a sub-terahertz cutoff frequency."
      },
      {
        "Problem": "Contradiction regarding vacuum in the microcavity",
        "Location": "Section III, first paragraph",
        "Explanation": "The paper states that the air pressure inside the microcavity is determined by the chamber pressure before deposition. This implies the cavity is filled with gas at some pressure, not a vacuum. This contradicts the concept of a 'vacuum microcavity' and the assumption of ballistic electron transport, which is crucial for the claimed high-frequency performance of vacuum field emission devices."
      },
      {
        "Problem": "Insufficient detail on performance simulation methodology",
        "Location": "Section III",
        "Explanation": "The paper mentions using 'charged particle tracking physical field' simulation but does not clearly explain how the electrical parameters necessary for the cutoff frequency calculation (transconductance gm and gate capacitance Cgs+Cgd) were extracted from this simulation. This lack of detail makes the simulation results and the derived cutoff frequency unverifiable and potentially unreliable."
      },
      {
        "Problem": "Inconsistency in fabrication process description",
        "Location": "Section III, third paragraph, and Fig 2",
        "Explanation": "The paper claims that the lithography step shown in Fig 2(b) (presumably referring to the step that creates the pattern in Fig 2(c)) is nonessential. However, Fig 2(b) shows the coating covering the gate area, which would lead to a short circuit. The lithography step to pattern the coating (as implied by Fig 2(c)) appears necessary for the device to function as a transistor, suggesting a misunderstanding or misstatement about the proposed fabrication process."
      },
      {
        "Problem": "Low reported on-state current",
        "Location": "Section III, last paragraph, and Fig 3(b)",
        "Explanation": "The simulation results in Fig 3(b) show an on-state current in the microampere range (up to ~9 µA). While the collection efficiency is high, this current level is typically very low for a high-frequency transistor operating in the THz range and might limit the device's practical power handling capability, despite the claimed high cutoff frequency (even if the calculation were correct)."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 3161,
      "output": 623
    }
  },
  {
    "entry_id": 108,
    "retraction_id": "1901.08297v2",
    "paper_id": "1901.08297v1",
    "retraction_comment": "The significance and novelty of the paper were not addressed. There are a couple of errors about calculations: the excitonic decay rates were computed by solving Eq (11), not based on Eq. (13) that was only an initial guess for the decay rate",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound handling of non-adiabatic coupling breakdown in non-radiative relaxation calculation.",
        "Location": "Page 10, Section II.B.",
        "Explanation": "The authors state that states where the non-adiabatic coupling term is large are neglected in the MEG analysis because their approximation yields \"artificially large\" non-radiative rates. This exclusion removes potentially dominant non-radiative relaxation pathways from the analysis, leading to an incorrect assessment of the competition between MEG and non-radiative relaxation and potentially invalidating conclusions about which process dominates and the existence of phonon bottlenecks."
      },
      {
        "Problem": "Approximation used for calculating excitonic inelastic scattering rates lacks sufficient validation.",
        "Location": "Page 3, Introduction; Page 6, Eq. 13 and surrounding text.",
        "Explanation": "The core rate for the MEG process in excitons (inelastic scattering rate) is calculated using an approximation (Eq. 13) that simplifies the dynamic Bethe-Salpeter equation. This approximation's validity is primarily supported by agreement with a more rigorous method for a smaller cluster (Si20). Its accuracy for the larger clusters (Si26, Si46) and the high excitation energies relevant for MEG is not sufficiently demonstrated, potentially leading to inaccurate MEG rates."
      },
      {
        "Problem": "Reliance on a crude model for non-radiative relaxation rates.",
        "Location": "Page 10, Section II.B.",
        "Explanation": "The non-radiative relaxation rates are calculated using a model based on the adiabatic approximation and perturbation theory, which the authors themselves acknowledge as a \"crude model\". This approach may not accurately capture the complex electron-phonon dynamics and non-adiabatic effects in silicon clusters, especially for high-energy excitations relevant to MEG, potentially leading to unreliable non-radiative rates used for comparison with MEG rates."
      },
      {
        "Problem": "Neglect of intersystem crossing as a relaxation pathway for excitons.",
        "Location": "Page 12, Section III.",
        "Explanation": "The analysis of relaxation pathways for excitons only considers internal conversion and neglects intersystem crossing from singlet to triplet states due to spin-orbit coupling. While spin-orbit coupling might be relatively weak in silicon, this omission could still represent a significant relaxation channel for higher-energy singlet excitons, potentially affecting their lifetime and the overall assessment of MEG efficiency."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 4450,
      "output": 528
    }
  },
  {
    "entry_id": 109,
    "retraction_id": "1705.01127v2",
    "paper_id": "1705.01127v1",
    "retraction_comment": "Paper has been withdrawn since we find that dust effects have an unignorable impact on our analyses. A part of analyses are reported by arXiv:1809.03715",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Severe Sample Completeness and Selection Bias",
        "Location": "Section 2, Figure 1, Section 4.1, Section 4.2",
        "Explanation": "The sample selection process, particularly the cross-matching with AKARI, results in very low completeness (e.g., 2.6% and 24% above certain SFR thresholds) and a bias towards detecting sources with significant IR emission. The paper acknowledges this bias misses high Ha/UV sources and might affect results, but does not fully quantify its impact on the observed distributions and the derived correlation between Ha/UV and AMS, potentially skewing the conclusions about the magnitude of SFH variability's effect on main sequence scatter."
      },
      {
        "Problem": "Conflicting Timescales for Main Sequence Evolution",
        "Location": "Section 4.1",
        "Explanation": "The paper interprets the Ha/UV-AMS correlation as evidence for galaxies oscillating across the main sequence on timescales less than 100 Myr due to SFH variability. However, it acknowledges that this conflicts with results from other studies (e.g., based on gas depletion timescales) which suggest a much longer timescale (~1 Gyr) for evolution or oscillations on the main sequence. This unresolved conflict weakens the proposed physical interpretation of the observed correlation."
      },
      {
        "Problem": "Limited Quantitative Impact on Main Sequence Scatter",
        "Location": "Section 4.1",
        "Explanation": "The paper quantifies the impact of the Ha/UV correlation on the main sequence scatter, finding that accounting for it reduces the scatter by only 0.04 dex (from 0.36 to 0.32 dex). This is a small fraction of the total scatter. While the correlation is statistically significant for massive galaxies, the quantitative result suggests that SFH variability, as traced by Ha/UV in this sample, is a minor contributor to the overall scatter in the star-forming main sequence, potentially overstating the significance of this finding for explaining the main sequence scatter."
      },
      {
        "Problem": "Unsound Metallicity Trend Interpretation",
        "Location": "Section 4.3",
        "Explanation": "The paper reports an unexpected trend where galaxies with lower Ha/UV ratios (interpreted as declining SF) tend to have slightly lower Oxygen abundances for massive galaxies. The difference is small (0.05 dex) and depends on the metallicity indicator used (N2 index shows no difference). The proposed interpretation (metal removal by feedback in the declining phase) is speculative and based on weak evidence, making this part of the discussion potentially unsound and misleading regarding the interplay between recent SFH and chemical evolution."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 4449,
      "output": 586
    }
  },
  {
    "entry_id": 110,
    "retraction_id": "2105.03304v2",
    "paper_id": "2105.03304v1",
    "retraction_comment": "Eq (2.4) is not correct and as such this invalidates Theorem 2.3 and consequently all the claimed results on the modulus of the zeros of chromatic polynomial. As fas as we can tell the results for the edge based block polynomials are correct (this concerns Sections 4 and 5). We will probably resubmit this part as part of a new paper at some point in the future",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof of Lemma 5.5, invalidating Theorem 1.3.",
        "Location": "Page 15, Proof of Lemma 5.5",
        "Explanation": "The proof uses the bound Σ_{l≥3} W_v^l (a|z|)^l ≤ 1 from Corollary 5.4 (with x = a|z|) to satisfy the condition Σ... ≤ a-1 for Theorem 4.2. This requires 1 ≤ a-1, or a ≥ 2. However, the value of a used in the lemma is (1+√5)/2 ≈ 1.618, which is less than 2. This contradiction makes the proof unsound."
      },
      {
        "Problem": "Unsound bounding method in Corollary 3.3 and Lemma 3.7, invalidating Theorem 1.1 and 1.2.",
        "Location": "Page 8, Proof of Corollary 3.3; Page 10, Proof of Lemma 3.7; Page 11, Proof of Lemma 3.9",
        "Explanation": "The proof of Corollary 3.3 bounds a sum over block paths S by a sum over trees T. The relationship used, Σ_{S∈BP(v,U;G)} q^{Σ(|B|-1)} (Num spanning trees in G[S]) ≤ Σ_{T∈T(v,U;G)} q^{|E(T)|}, appears incorrect. The sum on the left has q raised to the sum of (|B|-1) over blocks, not |S|-1 or |E(T)|. This incorrect bounding method is then used in Lemma 3.7 and Lemma 3.9 to derive bounds for bv,U;G(q), which are crucial for proving Theorem 1.1 and 1.2."
      },
      {
        "Problem": "Apparent exponent error in the proof of Theorem 2.3 (and likely Theorem 4.2).",
        "Location": "Page 6, Proof of Theorem 2.3",
        "Explanation": "In the proof, the ratio |B(G|U∪P; w) / B(G|U∪{v}; w)| is bounded by a^{|P|-2}. Based on the induction hypothesis |B(G|U'∪{v'}; w) / B(G|U'; w)| ≤ a, the correct bound for the ratio B(G|U_t; w) / B(G|U_0; w) = Π_{i=1}^t B(G|U_i; w) / B(G|U_{i-1}; w) should be a^t = a^{|P|-1}, where |P| = t+1. Using a^{|P|-2} seems incorrect. If the correct exponent |P|-1 is used, the proof requires a < 2 for the induction step to show non-zero. While the derived 'a' values for Theorem 1.1 and 1.2 (limit case) are less than 2, the proof as written is flawed."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 17281,
      "output": 702
    }
  },
  {
    "entry_id": 111,
    "retraction_id": "1608.03378v2",
    "paper_id": "1608.03378v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in equation 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of mobility data for composite model analysis",
        "Location": "Page 5, Discussion section, paragraph starting \"In our film...\"",
        "Explanation": "The calculation of the geometric parameter (l2/l1) in the composite model relies on the ratio of mobilities in the grain and intergrain regions (mu1/mu2). The paper claims this ratio is \"aroud 200\" based on Figure 6. However, Figure 6 shows the measured effective mobility of the entire composite film, not the individual mobilities of the different phases. Using the effective mobility value directly as the ratio of individual mobilities is a fundamental error in applying the composite model equations, invalidating the derived geometric parameter beta (l2/l1 = 1/4) and the conclusion about the untransitional phase length."
      },
      {
        "Problem": "Inappropriate application of intrinsic semiconductor model for band gap calculation",
        "Location": "Page 5, Discussion section, paragraph starting \"The temperature dependent carrier concentration allows us...\"",
        "Explanation": "The band gap of the semiconducting phase is calculated using the formula for intrinsic carrier concentration in a simple band semiconductor (Eq 14) and plotting ln(n/T^3/2) vs 1/T. VO2 is a strongly correlated electron material, often described as a Mott or Peierls insulator, not a simple intrinsic semiconductor. Its low-temperature transport may involve mechanisms like hopping or variable range hopping, especially in thin films with defects and grain boundaries. Applying the intrinsic semiconductor model without justification is inappropriate and likely leads to an incorrect or misleading band gap value."
      },
      {
        "Problem": "Inconsistency in composite model application above and below MIT",
        "Location": "Page 4-5, Discussion section, paragraphs discussing the composite model application",
        "Explanation": "The composite model is applied differently above and below the MIT. Above MIT, the intergrain region is assumed highly resistive (Schottky barrier), significantly affecting n*. Below MIT, the intergrain region resistivity is assumed comparable to grains (alpha ~ 1), leading to the conclusion that n* is approximately equal to the grain concentration n1. If the intergrain region has a significant volume fraction (beta = 1/4) and its resistivity is comparable to the grains (alpha ~ 1), the composite model equations predict that the intergrain properties should still significantly influence n*. The conclusion n* ~ n1 below MIT appears inconsistent with the model structure and parameters derived for the metallic phase, or it relies on unstated assumptions about the low-temperature behavior of the intergrain phase within the model."
      },
      {
        "Problem": "High film roughness not discussed as affecting transport properties",
        "Location": "Page 2, Table I and associated text describing XRR results",
        "Explanation": "The X-ray reflectivity analysis indicates a high film roughness (55 Å) relative to the film thickness (422 Å). High surface and interface roughness can significantly affect charge transport in thin films due to scattering, non-uniform current paths, and variations in local film properties. These effects can influence the measured effective resistivity, Hall coefficient, and mobility, and may complicate the interpretation based on bulk-like models or simple composite models that assume uniform regions. The paper does not discuss the potential impact of this significant roughness on the transport measurements or their interpretation."
      },
      {
        "Problem": "Lack of justification for specific composite model geometry",
        "Location": "Page 4, Discussion section, paragraph starting \"Here, we attempted to interpret...\"",
        "Explanation": "The analysis relies on a specific composite cube model (Volger's model, as presented in Ref 26) without providing justification for why this idealized geometry is appropriate for describing the complex grain structure and transport in the sputtered polycrystalline VO2 thin film. While some aspects of transport in inhomogeneous materials might be insensitive to geometry, applying a specific model without discussing its limitations or suitability for the actual film morphology weakens the validity of the quantitative conclusions derived from that model, such as the calculated geometric parameter (l2/l1)."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 3381,
      "output": 891
    }
  },
  {
    "entry_id": 112,
    "retraction_id": "1709.00434v2",
    "paper_id": "1709.00434v1",
    "retraction_comment": "Some of the content, including the assumption of vanishing vector potential at the interface and the application of the formalism to the gapped Dirac materials, are wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption of vanishing vector potential at the interface.",
        "Location": "Page 3, Eq. (18) and surrounding text.",
        "Explanation": "The paper assumes that the entire vector potential A±(r,t) vanishes at the interface (z=0). This is a strong assumption for electromagnetic modes like plasmons, especially magnetoplasmons where the magnetic field (related to the curl of A) is crucial. The paper cites Ref. [1] as justification, but Ref. [1] only assumes the z-component of A vanishes at the interface, not all components. Assuming A=0 simplifies the electric field calculation (Eq. 28) but likely neglects important contributions from the vector potential to the boundary conditions and the dispersion relation, fundamentally altering the problem being solved."
      },
      {
        "Problem": "Incorrect derivation of the differential equation from the integro-differential equation.",
        "Location": "Page 5, Eq. (36) and Page 6, Eq. (47).",
        "Explanation": "The paper derives an integro-differential equation (Eq. 36) involving the exact kernel L(y). To convert this to a differential equation, it seeks an operator Ô₀ such that Ô₀ L(y-ỹ) = δ(y-ỹ). However, it finds the operator Ô₀ for an *approximate* kernel Lo(y) (Eq. 45) and then applies this Ô₀ to the equation involving the *exact* kernel L(y) (Eq. 36) to obtain the differential equation (Eq. 47). This step is only valid if L(y) = Lo(y) exactly, which is stated as an approximation. Using the operator for an approximate kernel on the equation for the exact kernel is mathematically unsound and invalidates the resulting differential equation (Eq. 47) and all subsequent derivations based on it."
      },
      {
        "Problem": "Unclear and potentially incorrect derivation of the boundary condition at y=0.",
        "Location": "Page 7, Eqs. (58)-(61).",
        "Explanation": "The paper attempts to derive a boundary condition for the derivative of the scalar potential at y=0 by integrating the differential equation (Eq. 47) across the interface. The resulting equation (Eq. 59) and the intermediate steps (Eqs. 60, 61) involving integrals of the charge densities are presented without a clear, step-by-step derivation from Eq. 47. The connection between integrating the differential equation and the specific terms involving conductivity components and potential/derivative values at y=0- in Eq. 59 is not rigorously shown and appears complex, raising concerns about its correctness. This step is crucial for obtaining the dispersion relation."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 3420,
      "output": 616
    }
  },
  {
    "entry_id": 113,
    "retraction_id": "1610.01669v7",
    "paper_id": "1610.01669v6",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error on linear implication between games",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamentally flawed definition of Identity Games.",
        "Location": "Definition 4.4.1",
        "Explanation": "The identity game IdG(σ, τ) is defined as a subgame with 'just one strategy' (flip(G)). This is highly non-standard in game semantics, where games define possible plays and strategies are subsets of plays. This definition seems to conflate the notions and build in the uniqueness of identity proofs by fiat, rather than deriving it from the game structure. This undermines the game-theoretic interpretation of identity types."
      },
      {
        "Problem": "The claim that the model validates the Uniqueness of Identity Proofs (UIP) is based on the flawed definition of identity games.",
        "Location": "Section 6.3, Definition 4.4.1",
        "Explanation": "The proof sketch for UIP relies on the identity game IdA(a1, a2) having only one strategy. As noted in Problem 1, the definition of this game explicitly restricts it to a single strategy. Therefore, the model does not demonstrate that UIP holds as a consequence of the game structure; it holds because the identity game is defined to have only one strategy."
      },
      {
        "Problem": "The argument refuting the Univalence Axiom (UA) may be unsound due to a potential mismatch between informal game identity and formal object identity in the model.",
        "Location": "Section 6.5, Definition 5.1.1",
        "Explanation": "The refutation uses N and FSN(1) as an example, implying they are 'equivalent' games (making the UA premise true) but have different universe codes. However, N and FSN(1) are defined via distinct inductive constructions in EPG, suggesting they are distinct objects in the category. If they are distinct objects, the judgement N=FSN(1) type is false in the model, making the UA implication vacuously true. The argument seems to rely on an informal notion of game identity not formally captured by the model's structure."
      },
      {
        "Problem": "The proof of surjectivity for the interpretation in EPG is acknowledged to be 'cheap' and relies on the inductive definition of EPG elements.",
        "Location": "Remark on page 56, Corollary 5.2.1",
        "Explanation": "The surjectivity of the interpretation mapping MLTT judgements to EPG elements is proven by induction on the construction of EPG elements. The author notes this is 'cheap' as EPG is defined to correspond to the syntax. This weakens the significance of the bijectivity claim, as the model's structure seems tailored to match the syntax rather than demonstrating that the game structure naturally yields such an interpretation."
      },
      {
        "Problem": "The definition of game composition includes a non-standard condition on internal plays.",
        "Location": "Definition 3.1.4",
        "Explanation": "The definition of the set of valid positions for composed games J;K includes the condition s | B1, B2 ∈ prB, where prB is related to the linear implication game B1 -> B2. This condition on the internal communication seems non-standard compared to typical game semantics composition (parallel composition plus hiding) and its full implications for the properties of the composed games are not clearly justified."
      }
    ],
    "token_usage": {
      "input": 17668,
      "thinking": 6832,
      "output": 738
    }
  },
  {
    "entry_id": 114,
    "retraction_id": "1605.05588v2",
    "paper_id": "1605.05588v1",
    "retraction_comment": "It had to be noted that the assumption was made that all sensors have access to all observations and state estimate vectors. In addition, the summations in the DAQKF Algorithm are on all sensors, not just the neighbouring sensors",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and update of the matrix M",
        "Location": "Algorithm 1, 2, 3 (initialization of M_0|0) and Equation (5), Algorithm 3 (measurement update for M_l,n|n)",
        "Explanation": "The matrix M is defined as a covariance matrix (E[error*error^H]) in the initialization steps of Algorithms 1, 2, and 3. However, the measurement update rule for M in Equation (5) and Algorithm 3 involves adding terms of the form H^H R^{-1} H, which is the correct update rule for the *inverse* covariance matrix (information matrix) in the information filter formulation. This inconsistency means M is neither a correct covariance nor a correct information matrix after the first measurement update, invalidating the filter's state and covariance calculations."
      },
      {
        "Problem": "Incorrect measurement update rule for the covariance matrix M in the distributed algorithm",
        "Location": "Algorithm 3, Measurement update for M_l,n|n",
        "Explanation": "Building on the previous point, the local covariance matrix M_l,n|n in Algorithm 3 is updated by summing H^H R^{-1} H terms from neighbors. This is the update rule for the information matrix, not the covariance matrix. The model update step correctly calculates the predicted *covariance* M_l,n|n-1, leading to an inconsistent mix of covariance and information matrix updates within the same algorithm, rendering the calculated M_l,n|n incorrect."
      },
      {
        "Problem": "Confidence measure quantity depends on the unknown true state",
        "Location": "Equation (7)",
        "Explanation": "The quantity r_m,n, which is proposed as the basis for a confidence measure to detect erroneous observations, is defined in Equation (7) in a way that explicitly depends on the unknown true state x_n. This makes r_m,n non-computable by the sensor nodes in a real-world scenario, rendering the proposed fault detection mechanism impractical and unsound."
      },
      {
        "Problem": "Incorrect covariance calculation for the confidence measure quantity",
        "Location": "Equation (7), definition of C_r_m,n",
        "Explanation": "The calculated covariance C_r_m,n for the quantity r_m,n, which is needed to compute the Mahalanobis distance for the confidence measure, appears incorrect. The provided expression does not follow standard covariance propagation rules for Kalman filter residuals or related quantities, further invalidating the confidence measure based on this covariance."
      },
      {
        "Problem": "Unjustified additive diffusion strategy for state estimate",
        "Location": "Algorithm 3, Measurement update for x_l,n|n",
        "Explanation": "The final state estimate x_l,n|n is obtained by simply adding local update terms Δx_m,n from neighbors. While diffusion strategies exist for distributed Kalman filtering (often involving information-weighted averaging), this specific additive combination of state update terms, especially when Δx is calculated using potentially incorrect local covariances (due to Problem 2), is not a standard or rigorously justified method for combining state estimates in a Kalman filter context without further theoretical backing specific to this formulation."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 3741,
      "output": 725
    }
  },
  {
    "entry_id": 115,
    "retraction_id": "2112.14102v2",
    "paper_id": "2112.14102v1",
    "retraction_comment": "The paper was withdrawn due to a mistake in the proof of Theorem 15, in Section 4. The proposed translation is not equirealizable (the cases for disjunction and Release fail)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsoundness in the base case translation for atomic formulas in the inductive proof of Theorem 15.",
        "Location": "Page 10, Theorem 15, Proof (If φ = p)",
        "Explanation": "The proposed translation for an atomic formula φ=p (where p is a system variable) into a GX0 formula a∧□ψ does not appear to be equirealizable. If p is a system variable, φ=p is realizable if the system can always make p true. The translation s ∧ □((s → (p∧○¬s)) ∧ (¬s → ○¬s)) seems to only enforce p at time 0 (if s is true at time 0) and does not guarantee p holds at subsequent times, which is required for realizability of p."
      },
      {
        "Problem": "Unsoundness in the Release case translation in the inductive proof of Theorem 15.",
        "Location": "Page 10, Theorem 15, Proof (If φ = φ2Rφ1)",
        "Explanation": "The proof relies on the claim that □χ2R□χ1 is realizable if and only if □χ1 is realizable. This claim is incorrect based on the standard semantics of the Release operator (A R B is equivalent to □B ∨ (A U B)). □χ2R□χ1 is realizable if □χ1 is realizable OR □χ2 U □χ1 is realizable. The latter can be true even if □χ1 is unrealizable."
      },
      {
        "Problem": "Unsoundness in Lemma 13 regarding equirealizability between GX0 and GX formulas.",
        "Location": "Page 8, Lemma 13",
        "Explanation": "Lemma 13 claims that a GX0 formula a∧□ψ is equirealizable to the GX formula □((¬r → ψ) ∧ (□[0,d]r → Od+1¬r → Od+1a)). The proposed GX formula does not seem to correctly capture the 'resetting' intuition or preserve equirealizability. For instance, if the environment always sets the new variable r to false, the GX formula simplifies to □(¬r → ψ), which becomes □ψ if r is always false. This is not equirealizable to a∧□ψ, as a∧□ψ requires 'a' to be true at time 0, while □ψ does not."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 5604,
      "output": 552
    }
  },
  {
    "entry_id": 116,
    "retraction_id": "1606.07464v6",
    "paper_id": "1606.07464v5",
    "retraction_comment": "The arguments in the Sections 3.2 and 3.3 are not conclusive, and the Markov property is not disproved. Many other statements are though correct, see arXiv:2011.11476v4 (\"Revisiting the stochastic differential equations with multiplicative noise\")",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The disproof of the Markov property relies on an inconsistent comparison of different stochastic interpretations (alpha values).",
        "Location": "Section 3.2, page 6-7",
        "Explanation": "The disproof compares the maximum of a small-time propagator derived from an FPE corresponding to alpha=0 (Itô) without external drift (Eq. 3.4, derived from 3.2) with the steady-state maximum derived from an FPE corresponding to alpha=1/2 (Stratonovich) (Eq. 3.6). Using a small-time propagator from one interpretation/equation to test the Chapman-Kolmogorov equation for a steady state derived from a different interpretation/equation is inconsistent and invalidates the conclusion."
      },
      {
        "Problem": "The central claim that solutions of SDEs with multiplicative noise are not Markovian contradicts standard definitions and theory.",
        "Location": "Introduction (page 2), Section 3.2 (page 6-7), Summary (page 12)",
        "Explanation": "A stochastic differential equation of the form dX = A(X) dt + B(X) dW, regardless of the Itô or Stratonovich interpretation (which affects the form of A), defines a Markov process under standard regularity conditions on A and B. The Fokker-Planck equation describes the evolution of the probability density of this Markov process. The paper's assertion that the process is non-Markovian fundamentally conflicts with this established framework, suggesting a misunderstanding of the definition of an SDE solution as a Markov process."
      },
      {
        "Problem": "The argument for the anti-Itô case (alpha=1) preserving the Markov property on a coarse-grained scale is based on insufficient criteria.",
        "Location": "Section 3.3 (page 7-8)",
        "Explanation": "The argument that alpha=1 is special relies on the peak of the density moving with the velocity of the deterministic drift 'a'. While this is a property of the density peak in the anti-Itô case, it is not a sufficient condition for the underlying stochastic process to be Markovian, even on a coarse-grained scale. The Markov property is a statement about the conditional probability distribution, not just the location of its maximum."
      },
      {
        "Problem": "The paper makes potentially incorrect statements about the maximum of the small-time propagator for alpha=0.",
        "Location": "Section 3.3 (page 7)",
        "Explanation": "The paper states that the solution with w(x,0) = delta(x-x_hat) for the alpha=0 FPE (without external drift) has its maximum at x_hat. However, the preceding calculation on page 6 shows that for alpha=0 (Itô), the maximum of the small-time solution is at x_hat - a_sp tau, not x_hat. This error weakens the subsequent argument for why alpha=1 is special."
      },
      {
        "Problem": "The conclusion that stochastic integrals are affected due to non-independent increments is based on the flawed premise of non-Markovianity.",
        "Location": "Introduction (page 2)",
        "Explanation": "The paper states that the non-Markovian nature implies that the increments in a partitioned time interval are no longer independent, impacting the basis of stochastic integrals (Riemannian sums). Since the premise that the process is non-Markovian within the standard SDE framework is incorrect, this derived consequence regarding the independence of increments and the validity of stochastic integrals is also unfounded."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 2488,
      "output": 787
    }
  },
  {
    "entry_id": 117,
    "retraction_id": "1806.07478v2",
    "paper_id": "1806.07478v1",
    "retraction_comment": "The results fail to capture the non-simultaneously diagonalizable case",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed justification chain for scalar test equations in non-ST cases",
        "Location": "Section 3, specifically the connection between Theorem 9 and Proposition 5",
        "Explanation": "The paper claims Theorem 9 justifies using scalar test equations R(hλ, hμ) for non-ST splittings. However, Theorem 9 only relates eigenvalues of R(hN, δ⁻¹S) to R(hUN, hδ⁻¹US). The link from R(hUN, hδ⁻¹US) eigenvalues to the scalar stability function eigenvalues R(hλ, hμ) is provided by Proposition 5, which explicitly requires N and S to be simultaneously triangularizable (ST). Thus, the justification chain for non-ST cases is broken."
      },
      {
        "Problem": "Contradiction between justification and application results",
        "Location": "Section 5.2, discussion of Table 3 and Figure 7",
        "Explanation": "The application to the non-ST shallow water model shows that stability predictions based on scalar test equations are misleading. The paper's explanation for this failure confirms that scalar test equations do not characterize stability well in this non-ST case, contradicting the paper's stated goal of justifying their use for such cases."
      },
      {
        "Problem": "Undiscussed assumption Ĉ ⊗ S ≠ 0",
        "Location": "Theorem 7 (Page 9), Theorem 9 (Page 10), Lemma 8 (Page 10)",
        "Explanation": "The key perturbation theorems (Theorem 7 and 9) and Lemma 8 rely on the assumption Ĉ ⊗ S ≠ 0. The paper does not discuss the implications or limitations if this assumption is not met, limiting the generality of the perturbation analysis."
      },
      {
        "Problem": "Undiscussed holomorphicity assumption in Theorem 18",
        "Location": "Theorem 18 (Page 14)",
        "Explanation": "Theorem 18, which suggests a decoupling property for RK methods, relies on the assumption that the stability function R(w, z) is holomorphic at (hλ, hμ) for relevant h, λ, μ. This assumption is not guaranteed for all methods and all eigenvalues, as the stability function involves an inverse that might become singular, potentially limiting the applicability of the theorem."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 3661,
      "output": 529
    }
  },
  {
    "entry_id": 118,
    "retraction_id": "2302.13052v2",
    "paper_id": "2302.13052v1",
    "retraction_comment": "There are some errors and inappropriate writings. Thm 4.16 and don't work well for additive invariants",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect equivalences involving Ind_k and Idem",
        "Location": "Remark 2.21, 2.24, 2.31, 4.17, 6.7",
        "Explanation": "The paper frequently uses equivalences such as Ind_k(C) ~ C, Ind(C) ~ Idem(C), or C ~ Ind(C)^w for small stable or idempotent complete stable categories C. These equivalences are generally false. Ind_k(C) is the k-completion, and Idem(C) is the idempotent completion. A small idempotent complete stable category is not necessarily k-accessible or k-compactly generated for arbitrary k. This error propagates through many subsequent proofs, including those for corepresentability and product preservation."
      },
      {
        "Problem": "Flawed proof of independence of the choice of regular cardinal k",
        "Location": "Lemma 3.11, 3.12, 3.30, Definition 3.14, 3.31",
        "Explanation": "The definitions of the nonconnective K-theory K and Efimov K-theory K_cont depend on a choice of regular cardinal k. The paper claims this choice is irrelevant (Lemma 3.12, 3.30), but the proofs rely on Eilenberg swindle arguments (Lemma 3.11, 3.29) that appear to incorrectly assume the existence of countable products or direct sums in categories like Ind_k(C) or C^k for uncountable k. Without a valid proof of independence from k, the definitions are ambiguous."
      },
      {
        "Problem": "Flawed proof that Pr_st^dual admits small products",
        "Location": "Proposition 6.3",
        "Explanation": "The proof claims that any coproduct of dualizable presentable stable ∞-categories is still dualizable, which is used to show that Pr_st^dual admits small products. Dualizability is not generally preserved by infinite coproducts (or products, as they agree in Pr^L). This invalidates the claim that Pr_st^dual has small products and undermines theorems about K_cont commuting with products (Theorem 6.8, 6.10, 6.11)."
      },
      {
        "Problem": "Flawed proof that Calk_k preserves exact/split-exact sequences",
        "Location": "Proposition 3.35, Lemma 3.33",
        "Explanation": "Proposition 3.35, which is essential for proving that K_cont sends exact sequences to exact sequences (Corollary 3.36) and is an additive/localizing invariant (Lemma 3.38), relies on Lemma 3.33. The proof of Lemma 3.33 uses a result (NS18, Theorem 1.3.3(ii)) specific to mapping spaces in spectra, applying it incorrectly in a general ∞-category context. This invalidates the claimed exactness properties of Calk_k and K_cont."
      },
      {
        "Problem": "Flawed proofs for corepresentability and symmetric monoidal structure of K_cont",
        "Location": "Theorem 4.3, 4.13, Corollary 5.17, Proposition 5.18",
        "Explanation": "The proofs that K_cont is corepresentable (Theorem 4.3, 4.13) and lax symmetric monoidal (Proposition 5.18) rely on flawed intermediate results (Theorem 4.7, Corollary 5.17) and incorrect equivalences (Problem 1). The arguments for corepresentability also appear to confuse properties of K_cont (defined on Pr_st^dual) with K^cn (defined on Cat^perf)."
      }
    ],
    "token_usage": {
      "input": 11734,
      "thinking": 8953,
      "output": 853
    }
  },
  {
    "entry_id": 119,
    "retraction_id": "1511.07171v2",
    "paper_id": "1511.07171v1",
    "retraction_comment": "Error in equation 9",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Governing Equation",
        "Location": "Page 2, Eq. (1)",
        "Explanation": "The presented axisymmetric convected Helmholtz equation does not match the standard form derived from linearized fluid dynamics equations for acoustics in a uniform subsonic flow. This fundamental equation forms the basis of the entire formulation."
      },
      {
        "Problem": "Incorrect Green's Function Definition",
        "Location": "Page 2, Eq. (2) and (3)",
        "Explanation": "The definition of the 3D convected Green's function (Eq. 2) and the auxiliary distances `r*` and `R_β*` (Eq. 3) appears incorrect for a convected medium. The standard approach involves a transformed distance based on the Prandtl-Glauert transformation, which is not correctly implemented here."
      },
      {
        "Problem": "Missing and Flawed Integral Equation Derivation",
        "Location": "Page 2-4, Eq. (4), (7), (9)",
        "Explanation": "The derivation of the boundary integral equation (Eq. 9) from the governing equation is not provided. The intermediate equations (4) and (7) contain domain integrals for a homogeneous equation, which is not typical for standard BEM formulations. The transition from these domain integrals to the boundary integral equation is unexplained and appears mathematically unsound."
      },
      {
        "Problem": "Incorrect Treatment of Singular Integrals",
        "Location": "Page 5, Section 3 (Numerical implementation description)",
        "Explanation": "The paper claims that only the trapezoid method is needed for evaluating integrals related to the Green's function and its derivative. BEM integrals involving the Green's function kernel are singular when the source point is on the boundary, requiring special analytical or numerical techniques beyond simple quadrature like the trapezoid method for accurate evaluation."
      },
      {
        "Problem": "Inconsistent and Unjustified Operators",
        "Location": "Page 3, Eq. (5) and Page 4, Eq. (8)",
        "Explanation": "The definition of the 'particular normal derivative' in Eq. (5) is unusual and lacks clear mathematical or physical justification. Furthermore, a different operator is introduced in Eq. (8) using the same notation `d/dn_q`, leading to an inconsistency in the formulation."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 4195,
      "output": 526
    }
  },
  {
    "entry_id": 120,
    "retraction_id": "1106.1331v2",
    "paper_id": "1106.1331v1",
    "retraction_comment": "Withdrawn by the authors. Lemma 7.6 is false as stated, and Appendix B is flawed. Corrected and reorganized versions of the material will be posted in papers with different titles",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Proof of the key quantitative estimate (Lemma 11.5) relies on complex analysis of asymptotic expansions.",
        "Location": "Appendix C, Section C.1, Lemma 11.5",
        "Explanation": "The proof of Lemma 11.5, which is crucial for the error term estimates (Theorems E and F), involves intricate analysis of asymptotic expansions of matrix coefficients, particularly when spectral parameters are close. The argument for extending the result from generic parameters to all parameters is highly technical and a potential source of subtle errors that could invalidate the quantitative bounds."
      },
      {
        "Problem": "Main Term Counting for non-rigid spaces (Theorem D) depends on an unproven 'well-factorizing' property.",
        "Location": "Section 9.3, Section 10.1 (Theorem D)",
        "Explanation": "Theorem D's conclusion on Main Term Counting for non-rigid spaces relies on the geometric balls satisfying a 'well-factorizing' property (9.10). This property is not generally proven in the paper, but rather supported by examples and stated as empirically true. If this property fails for a specific non-rigid space, the argument for Main Term Counting in Theorem D breaks down for that space."
      },
      {
        "Problem": "Verification of 'strongly spherical type' for claimed examples is not fully detailed.",
        "Location": "Definition 7.7, Section 7.6, Corollary 8.6, Example 7.8",
        "Explanation": "Theorems C and D apply to spaces of 'strongly spherical type' (Definition 7.7). The paper claims several examples satisfy this property, but a detailed verification of all three conditions, especially condition (3) regarding the union of A+(P_j), is not provided for every case. If any claimed example does not meet the definition, the application of Theorems C and D to that example is unsound."
      },
      {
        "Problem": "Proof that spherical type implies polar type (Theorem 7.1) relies on complex arguments in Appendix B.",
        "Location": "Theorem 7.1, Lemma 7.6, Appendix B",
        "Explanation": "The proof of Theorem 7.1, which helps classify spaces as polar type (a requirement for strongly spherical type), depends on Lemma 7.6, proven in Appendix B. This proof involves sophisticated arguments using algebraic groups and complex analysis. Errors in this intricate structural argument could affect the classification and the applicability of subsequent theorems like C and D."
      }
    ],
    "token_usage": {
      "input": 17926,
      "thinking": 4301,
      "output": 560
    }
  },
  {
    "entry_id": 121,
    "retraction_id": "2106.14209v3",
    "paper_id": "2106.14209v2",
    "retraction_comment": "The paper builds on the wrong statement in the paper \"The quantum twistor bundle\" Theorem 4.2. Therefore the C*-algebra investigated in the present paper is not the one for the quantum symplectic sphere",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and likely incorrect target graph C*-algebra and Vaksman-Soibelman sphere",
        "Location": "Abstract, Introduction (page 2), Definition 1.2, Theorem 3.4, Corollary 3.5",
        "Explanation": "The paper claims C(S⁴ⁿ⁻¹) is isomorphic to C*(L₂₍<n+1>-1)) and subsequently to the Vaksman-Soibelman quantum sphere C(S²₍<n+1>-1)). However, the graph L₂₍<n+1>-1) is defined in the paper (Definition 1.2, with n replaced by n+1) as the graph L<n+1> (with n+1 vertices). The Vaksman-Soibelman sphere C(S²<m>-1) is isomorphic to C*(L₂<m>-1). The claim that C(S⁴ⁿ⁻¹) is isomorphic to C(S²₍<n+1>-1)) implies 4n-1 = 2(n+1)-1 = 2n+1, which only holds for n=1, contradicting the paper's scope (n ≥ 2). Furthermore, the graph L₂₍<n+1>-1) in the Vaksman-Soibelman context should have 2(n+1)-1 vertices, not n+1 vertices as defined in the paper. This fundamental inconsistency in the target of the isomorphism invalidates the main result."
      },
      {
        "Problem": "Incorrect definition of the graph C*-algebra representation ρ",
        "Location": "Page 5, Lemma 3.1, definition of ρ",
        "Explanation": "The definition of the representation ρ of C*(L<n+1>) on l²(ℕⁿ × ℤ) appears incorrect. The action of the partial isometries ρ(S<eᵢⱼ>) and ρ(S<eⱼ,<n+1>>) on the basis vectors |k₁, ..., k<n>, m> does not seem consistent with the source and range projection properties of graph C*-algebras. For example, the formula for ρ(S<eⱼ,<n+1>>) for j=1,...,n seems to imply a change in the dimension of the state vector indices, which is not possible in l²(ℕⁿ × ℤ). This representation is fundamental to the proof of the main theorem."
      },
      {
        "Problem": "Unsound calculations involving the representation ρ",
        "Location": "Pages 9-11, proof of Theorem 3.4, calculations of ρ(T(b₁, ..., bⱼ)*) and ρ(T(b₁, ..., bⱼ))",
        "Explanation": "The calculations of the action of operators T(b₁, ..., bⱼ) and their adjoints under the representation ρ appear to rely on an assumed annihilation/creation-like action on the state vector indices |k₁, ..., k<n>, m> that is not justified by the definition of ρ provided in Lemma 3.1 (which itself appears incorrect). These calculations are essential steps in showing that ρ ο φ = π and π ο φ⁻¹ = ρ, and their unsoundness invalidates the proof of the isomorphism."
      },
      {
        "Problem": "Lack of justification for the faithfulness of the representation π",
        "Location": "Page 5, Lemma 3.1",
        "Explanation": "The lemma states that the representation π is faithful, citing [1, Proposition 7]. However, Proposition 7 in [1] describes irreducible representations on Hilbert spaces l²(ℕᵏ × ℤ) for k=1,...,n, whereas π is defined on l²(ℕⁿ × ℤ). It is not immediately clear how the faithfulness of π follows from this reference without further explanation, such as π being a direct sum or integral of these irreducible representations. Faithfulness is a critical property required for the isomorphism to a faithful representation of the graph C*-algebra."
      },
      {
        "Problem": "Incomplete proof of the joint spectrum calculation",
        "Location": "Page 6, Lemma 3.2, proof",
        "Explanation": "The proof of the joint spectrum calculation for π(yᵢ*yᵢ) relies on an inductive argument for i=1,...,n-1 which is stated as 'By induction we get' without providing the inductive step or base case details. The derivation of the relations used in the proof from (2.2) and (2.3) is also not explicitly shown. While potentially fixable, this leaves a gap in the proof of a key lemma."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 16332,
      "output": 1007
    }
  },
  {
    "entry_id": 122,
    "retraction_id": "1608.08317v2",
    "paper_id": "1608.08317v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency between theoretical claim of stationarity and numerical results showing non-stationary energy.",
        "Location": "Theory Section (II.B, Page 2, text around Eq. 5) and Results Section (IV.A, Page 5, text below FIG. 4).",
        "Explanation": "The theory states that the Hellmann-Feynman theorem for Ω(ω) (Eq. 5) guarantees that local minima of Ω(ω) correspond to mean-field solutions, which are typically understood as stationary points of the energy functional. However, the results section explicitly describes the σ-SCF solutions as 'diabatic since they are not stationary in energy'. This fundamental inconsistency questions the nature of the states found by the method and the validity of the theoretical justification for finding mean-field states."
      },
      {
        "Problem": "Failure of the Hellmann-Feynman theorem for the σ-SCF energy.",
        "Location": "Concluding Remarks (VI, Page 9, right column).",
        "Explanation": "As acknowledged by the authors, the Hellmann-Feynman theorem does not hold for the energy of the σ-SCF states because they are not energy extrema. This is a significant practical limitation as it prevents the direct calculation of forces, which is essential for common applications of mean-field methods like geometry optimization and molecular dynamics."
      },
      {
        "Problem": "Method minimizes variance, not energy, for approximate wavefunctions.",
        "Location": "Theory Section (II.B, Page 2, Eq. 7, 8), Properties Section (II.D, Page 4), Ground States Section (V, Page 8).",
        "Explanation": "The method finds states by minimizing the variance functional S[Φ]. While variance is zero for exact eigenstates, it is generally non-zero for approximate wavefunctions like single determinants, especially for excited states. Minimizing variance does not theoretically guarantee finding the best possible energy approximation for approximate states, unlike energy minimization methods. The theoretical link between variance minima and good energy approximations for excited states is not as rigorously established as for energy minimization."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 3125,
      "output": 463
    }
  },
  {
    "entry_id": 123,
    "retraction_id": "1805.10733v3",
    "paper_id": "1805.10733v2",
    "retraction_comment": "The result (eq. 3) is not correct; therefore, latter part which is derived from this result is not correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The relationship between the infinitesimal statistical distance squared (ds²) and the average stochastic entropy change (⟨Δσsys⟩) is incorrectly stated.",
        "Location": "Equation 6, Page 2",
        "Explanation": "The paper claims ds² = 2⟨Δσsys⟩. Standard results in information geometry relate ds² to the Kullback-Leibler divergence DKL(p(t)||p(t+dt)). In stochastic thermodynamics, the average stochastic entropy change over a time interval Δt is related to -DKL(p(t+Δt)||p(t)). The stated relationship ds² = 2⟨Δσsys⟩ appears fundamentally incorrect and lacks justification from established principles, undermining the link between information geometry and stochastic thermodynamics in this work."
      },
      {
        "Problem": "The definition of the rate of thermodynamic cost change (C) is not standard and lacks clear thermodynamic justification.",
        "Location": "Equation 12, Page 3",
        "Explanation": "The paper defines C = ∫ (ds/dt)² dt. This quantity is the integral of the squared speed of the probability distribution in the statistical manifold. Standard definitions of thermodynamic cost are typically related to entropy production in the environment or total entropy production (e.g., dissipated heat). Without a clear derivation linking this specific quantity C to thermodynamic principles, its interpretation and use as a 'thermodynamic cost change' are unsound."
      },
      {
        "Problem": "The definition and interpretation of efficiency (η) are based on the problematic definition of C and an unclear definition of adaptation time (τ).",
        "Location": "Equation 16, Page 3; Figure 3 caption",
        "Explanation": "The efficiency is defined as η = L²/τC. Since the definition of C as a thermodynamic cost is questionable, the interpretation of η as a thermodynamic efficiency is also questionable. Furthermore, the paper uses τ as the running elapsed time in the figures, rather than a fixed duration for the adaptation process, which complicates the interpretation of η as the efficiency of a specific adaptation process duration. While the inequality τ ≥ L²/C is mathematically correct based on the definitions, its physical meaning as a thermodynamic bound on adaptation speed is not established if C is not a valid thermodynamic cost."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 3690,
      "output": 497
    }
  },
  {
    "entry_id": 124,
    "retraction_id": "1912.00541v2",
    "paper_id": "1912.00541v1",
    "retraction_comment": "As several people have pointed out to me, the last sentence of Lemma 5.3 is not justified. This likely counts as a fatal flaw that invalidates the main theorem (Theorem 5.4). I would like to thank those who took the time to read the preprint and send me their feedback. I hereby retract the claimed result",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof claims that a non-surjective self-map of a finite graph is a full model of an injective endomorphism of the infinite space k^G.",
        "Location": "Page 11, Proof of Theorem 5.4",
        "Explanation": "The proof constructs a map phi: Delta_q -> Delta_q (defined as psi*alpha) and correctly argues that it is not surjective on the finite set Delta_q (and thus not injective). It then claims that this map phi is a full model of an injective endomorphism of k^G. A map phi: Delta_q -> Delta_q is a full model of an endomorphism f': k^G -> k^G if the corresponding map phi*: Hom(G, Delta_q) -> Hom(G, Delta_q) is equivalent to f'. The map phi* corresponds to the cellular automaton f_phi defined by (f_phi(z))(g) = phi(z|_{G_q, g}). A known result states that f_phi is injective if and only if its local rule phi is injective on the configuration space of the neighborhood (Delta_q = k^Gq). Since phi is not injective on Delta_q, the corresponding cellular automaton f_phi is not injective on k^G. Therefore, phi cannot be a full model of an *injective* endomorphism of k^G. This contradiction invalidates the subsequent argument based on the iterates of phi."
      },
      {
        "Problem": "Proposition 4.1 claims a natural bijection between the space of k-colorings k^G and the set of homomorphisms Hom(G, Delta_r).",
        "Location": "Page 7, Proposition 4.1",
        "Explanation": "The proof of Proposition 4.1 defines a map from k^G to Hom(G, Delta_r) by sending a coloring x to the homomorphism h_x where h_x(g) = x|_{G_r, g}. This map is well-defined and injective. However, the proposed inverse map, which takes a homomorphism h: G -> Delta_r and constructs a coloring x_h, is generally not well-defined as an inverse. The construction relies on defining a global coloring from a collection of local colorings {h(g)}_{g in G}. For this to yield a consistent global coloring, the local colorings must satisfy a compatibility condition (e.g., (h(g))(g') = (h(gg'))(e) for all g in G, g' in G_r). This condition is not guaranteed for an arbitrary homomorphism h: G -> Delta_r. The set Hom(G, Delta_r) is generally larger than the set of k-colorings k^G. This invalidates the fundamental identification used throughout the paper to relate k^G and its endomorphisms to finite graphs and their homomorphisms."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 13707,
      "output": 631
    }
  },
  {
    "entry_id": 125,
    "retraction_id": "2002.11860v4",
    "paper_id": "2002.11860v3",
    "retraction_comment": "Mistake in Lemma 3 changing the announced rate. Withdrawing while fixing the error",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Algorithm 1 Step 4 is incorrectly specified.",
        "Location": "Algorithm 1, Step 4 (Page 3)",
        "Explanation": "Step 4 states \"Update a = f(xwt-1)\". Based on the surrounding description in Section 2.2 and the update rule for rt in Step 5, this step is intended to update the i-th coordinate of the vector `at` (the stochastic gradient estimator in Rⁿ). The correct update should likely be `[at]_i = ∇fi(x_i w_{t-1})`, where `∇fi` is the gradient of the i-th component function `fi` with respect to its scalar input `x_i w`. The current notation `f(xwt-1)` is dimensionally incorrect and uses the wrong function `f`."
      },
      {
        "Problem": "Incorrect smoothness constant used for the objective function.",
        "Location": "Proof of Lemma 1 (Appendix B, Page 11), Theorem 1 (Page 4)",
        "Explanation": "The paper assumes each `fi` is L-smooth and uses `L` as the smoothness constant for the composite objective function `g(w) = f(Xw) = (1/n) Σ fi(x_i w)` in the proof of Lemma 1 (e.g., inequality 34). However, the smoothness constant of `g(w)` with respect to `w` is generally not `L`. It depends on the matrix `X` and the individual smoothness constants `L_i` of `fi` with respect to their scalar input. If each `fi` is L-smooth w.r.t. its scalar input, the smoothness of `g(w)` w.r.t. `w` is bounded by `(L/n) Σ ||x_i||^2`. Using `L` instead of the correct smoothness constant invalidates the quantitative bounds in Lemma 1 and consequently the convergence rate in Theorem 1."
      },
      {
        "Problem": "Proof of Lemma 2 contains logical errors and incorrect bounds.",
        "Location": "Proof of Lemma 2 (Page 5)",
        "Explanation": "The proof bounding the expected error `E Ht = E ||at - ∇f(Xwt-1)||1` contains several questionable steps. For instance, the inequality `δt-1 ≤ Ht-1 + ||∇f(Xwt-2) - ∇f(Xwt-1)||1` is incorrect based on the definition `Ht = ||at - ∇f(Xwt-1)||1`. Furthermore, the bound on `||∇f(Xwt-2) - ∇f(Xwt-1)||1` using L-smoothness and the definition of D1 appears incorrect dimensionally and in its use of constants. These errors invalidate Lemma 2 and propagate to Lemma 3 and Theorem 1."
      },
      {
        "Problem": "Convergence rate in Theorem 1 is likely incorrect due to flawed lemmas.",
        "Location": "Theorem 1 (Page 4), Proof (Appendix C, Page 12)",
        "Explanation": "The proof of Theorem 1 relies critically on Lemma 1, Lemma 2, and Lemma 3. As identified, the proofs of Lemma 1 and Lemma 2 contain significant errors related to the smoothness constant and bounding techniques. Therefore, the derived convergence rate `O(LD_2^2/t + n^{7/2}LD_1D_2/t^2 + n^{7/2}D_2H_0/t^2)` in Theorem 1 is likely incorrect."
      },
      {
        "Problem": "Proof of non-convex convergence (Theorem 2) is incomplete or relies on unproven assumptions.",
        "Location": "Theorem 2 (Page 6), Proof (Appendix F, Page 15)",
        "Explanation": "The proof of Theorem 2 relies on the convergence of `Ht` to zero, which is shown in expectation in Lemma 3 (a lemma whose proof relies on the flawed Lemma 2). Convergence in expectation does not guarantee almost sure or in probability convergence, which is typically required to show convergence of the iterates `wt` to a stationary point. The argument also contains a confusing and incorrect statement about the step size `γu` not being the general term of a convergent series. The proof does not rigorously establish the necessary conditions for `wt` to converge to a stationary point."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 9346,
      "output": 994
    }
  },
  {
    "entry_id": 126,
    "retraction_id": "2109.13007v2",
    "paper_id": "2109.13007v1",
    "retraction_comment": "We found a gap in the claim 1 (we can not solve it)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed calculation in the boundary tangency argument",
        "Location": "Page 4-5, Proof of Proposition 1",
        "Explanation": "The calculation attempting to show that normal vectors η₁ and η₂ must be linearly dependent at a boundary tangency point p ∈ ∂Σ₁ ∩ Sⁿ contains a fundamental error in the first step (1 = (α(η₁, η₁), p)), where α is the second fundamental form of Sⁿ. Given that η₁ is tangent to Sⁿ at p (due to the free boundary condition), α(η₁, η₁) = -p. Thus, (α(η₁, η₁), p) = (-p, p) = -|p|² = -1 (since p ∈ Sⁿ). The calculation starts with 1 = ... and correctly derives -1 in the final step, leading to the false contradiction 1 = -1. This invalidates the argument that η₁ and η₂ must be linearly dependent."
      },
      {
        "Problem": "Unjustified application of the tangency principle at the boundary",
        "Location": "Page 4-6, Proofs of Proposition 1, Claim 1, and Claim 2",
        "Explanation": "The proofs repeatedly use the tangency principle to conclude that two surfaces must coincide (e.g., Σ₁ = ρ(θ₀, Σ₂), Σ₁⁺ = ρ(θ₂, D⁺), Σ₁⁺ = ρ(θ₀, Σ₂⁺)) when the tangency occurs at a boundary point p ∈ ∂Σ ∩ Sⁿ. While a tangency principle exists for free boundary minimal surfaces, concluding global coincidence from boundary tangency requires specific conditions (e.g., on the second fundamental form of the boundary or the ambient space boundary) that are not explicitly verified or referenced. The paper claims this follows from the argument in Proposition 1, which is itself based on a flawed calculation (Problem 1)."
      },
      {
        "Problem": "Unclear and potentially incorrect proof of Claim 2",
        "Location": "Page 6, Proof of Claim 2",
        "Explanation": "The definition of the equatorial disk D used in the proof is unclear and seems arbitrarily chosen based on the subspace I[p₁, p₂]. The application of Claim 1 to the set D⁻ = D ∩ H⁺[-v] appears incorrect, as Claim 1 was proven for equatorial semi-disks D⁺ = D ∩ H⁺[v] (intersections with H⁺[v]), not D⁻ (intersections with H⁺[-v]). The subsequent logical steps involving the invariant set I[p₁, p₂] and the tangency argument are difficult to follow and seem logically flawed, failing to establish the claimed contradiction."
      },
      {
        "Problem": "Misapplication of the Strong Frankel Property in the proof of the Two-Piece Property",
        "Location": "Page 7, Proof of Corollary B",
        "Explanation": "The proof of Corollary B attempts to show that Σ⁺ = Σ ∩ H⁺[v] is connected. It claims that the parts of Σ contained in H⁺[v] cannot be disjoint 'by the strong Frankel property'. Theorem A (Strong Frankel Property) states that two *different* free boundary minimal hypersurfaces (Σ₁ and Σ₂) must intersect in any half-ball H⁺[v]. It does not state that disjoint parts of a *single* hypersurface Σ within H⁺[v] must intersect. This is a fundamental misapplication of Theorem A, rendering the proof of Corollary B invalid."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 7573,
      "output": 777
    }
  },
  {
    "entry_id": 127,
    "retraction_id": "1305.3218v2",
    "paper_id": "1305.3218v1",
    "retraction_comment": "This paper has been withdrawn by the author. Due to the dependence of f(\\sigma) on z, Lemma 5.3 is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory claims in a lemma proof.",
        "Location": "Page A:29, Lemma 4.5 proof",
        "Explanation": "The proof of Lemma 4.5 relies on two claims: Claim 1 states that if d(f(sigma)) intersects z_j, then y(sigma) = y_j. Claim 2 states that if d(f(sigma)) intersects z_j, then y(sigma) != y_j. These two claims are contradictory, invalidating the lemma's proof and subsequent results that depend on it."
      },
      {
        "Problem": "Weak or missing justification for a crucial lemma on space-proportional splits.",
        "Location": "Page A:10, Lemma 2.9 and Appendix B, Page A:54-55",
        "Explanation": "Lemma 2.9, which guarantees the existence of a space-proportional split forming a majority, is critical for the shift construction. The proof in Appendix B describes a process but does not rigorously demonstrate that the constructed sets s_j and M_j satisfy the required size conditions (|s_j| - |X_j|m/n < 1 and |M_j|m/n < 1) at each step, which are essential for the sparsity calculation."
      },
      {
        "Problem": "Weak or missing justifications in key lemmas for the Extension Generator Theorem.",
        "Location": "Page A:12, Lemma 3.1 and Page A:15, Lemma 3.3",
        "Explanation": "The proof of Lemma 3.1 relies on a contradiction argument involving the maximality of the generator g, which is not clearly explained. The proof of Lemma 3.3, crucial for Phase II of the Extension Generator Theorem, includes an inequality for beta (β ≥ (1 − e¯κ(Ui)) + e¯κ(Tj) (1 – e¯κ(Us))) that is not justified, making the induction step questionable."
      },
      {
        "Problem": "Incorrect size bound calculation for the family of quadruples Q0.",
        "Location": "Page A:27, Lemma 4.2 (i)",
        "Explanation": "Lemma 4.2 (i) claims that the size of Q0 is bounded by e^(n^epsilon) << e^q. Q0 is defined as a family of quadruples (g, g1, g2, a). The number of such quadruples is bounded by the sum over nodes 'a' of the product of the number of generators g, g1, g2 found at 'a' and its children. Based on Theorem 3.4, the number of generators is related to sparsity, which is Omega(n^epsilon). The calculation leading to the claimed bound |Q0| < e^(n^epsilon) is not shown and appears inconsistent with the bounds on the number of generators derived from Theorem 3.4."
      },
      {
        "Problem": "Insufficient justification for size reduction claims in BLOCKEDEDGES algorithms.",
        "Location": "Page A:30, Lemma 4.8 and Page A:40, Lemma 5.3 (b)",
        "Explanation": "Lemma 4.8 and Lemma 5.3 (b) claim that the size of the set Q (or Q_j, Q_r) is reduced exponentially in each step of the BLOCKEDEDGES algorithms. The proofs attempt to show this by bounding the number of (z_j, sigma) pairs where d(f(sigma)) intersects z_j. However, they do not rigorously demonstrate that for a *fixed* z_j chosen in Step 1-4, the number of sigma such that d(f(sigma)) intersects this z_j is small relative to the current size of Q, which is necessary for the size reduction step (Step 1-6) to be effective as claimed."
      }
    ],
    "token_usage": {
      "input": 14314,
      "thinking": 5271,
      "output": 871
    }
  },
  {
    "entry_id": 128,
    "retraction_id": "1502.02299v3",
    "paper_id": "1502.02299v2",
    "retraction_comment": "This paper has been withdrawn by the authors due to a sign error in the last equation of system (2.11). In turn, this implies a change of sign of the last equation in the linearized system (3.1) as well. The linear three annuli property for solutions to the new system (3.1) is no longer valid",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed argument in the proof of the three-annuli property for the odd part of the linearized system.",
        "Location": "Page 18, Proof of Lemma 4.1",
        "Explanation": "The proof relies on a claim about non-negative convex functions h satisfying h'' >= h. The argument that such a function must be constant on an interval [t1, t3] if it satisfies h(t2) >= 1 >= max{h(t1), h(t3)} for t1 < t2 < t3 is incorrect for functions satisfying h'' >= h (as opposed to h'' = h). This invalidates the conclusion of Lemma 4.1, which is a crucial step for the linear and nonlinear three-annuli properties (Theorem 4.3 and 2.4) and ultimately Theorem 1.1."
      },
      {
        "Problem": "Unjustified application of Theorem 1.2 in the proof of the main result.",
        "Location": "Page 34, Proof of Theorem 1.1",
        "Explanation": "The proof of Theorem 1.1 applies Theorem 1.2, which requires the jump set to be described by a function a(r) satisfying r|a'(r)| <= ε0 for a small universal constant ε0. The paper claims this follows from David's result [14, Theorem 69.29], which provides an estimate of the form |a'(r)| <= C/r. The estimate |a'(r)| <= C/r implies r|a'(r)| <= C, but it does not imply that r|a'(r)| is small (<= ε0) as r approaches 0. The condition r|a'(r)| <= ε0 is a stronger regularity property not guaranteed by David's result, creating a critical gap in the proof."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 3784,
      "output": 418
    }
  },
  {
    "entry_id": 129,
    "retraction_id": "1901.07856v7",
    "paper_id": "1901.07856v6",
    "retraction_comment": "The proof of the the second inequality of Lemma 7 is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The termination condition for the MAINALGORITHM is insufficient to guarantee an acyclic edge coloring.",
        "Location": "Algorithm 2, line 1; Section 2.1",
        "Explanation": "The algorithm terminates when the coloring is proper and contains no bichromatic 4-cycles. However, an acyclic edge coloring requires the absence of bichromatic cycles of *any* length, not just 4-cycles. Thus, the algorithm may halt with bichromatic cycles of length 6, 8, etc., failing to produce the claimed result."
      },
      {
        "Problem": "The probability calculation for the success of the validation algorithm (COLORVAL) in Lemma 5 appears incorrect.",
        "Location": "Lemma 5 and its proof sketch, page 7",
        "Explanation": "Lemma 5 calculates the probability Pr[V_F] based on the condition that both same-parity sets Co(e_i) and C1(e_i) are monochromatic. The proof sketch and formula imply this probability is (1/K)^(2k_i-2). The correct probability for both sets being monochromatic is K^2 * (1/K)^{2k_i}. This fundamental error invalidates the subsequent probabilistic analysis that relies on this lemma."
      },
      {
        "Problem": "The recurrence relation derived in Lemma 8 for the sum of weights of feasible trees appears incorrectly formulated.",
        "Location": "Lemma 8 and derivation, page 8-9",
        "Explanation": "The recurrence models a tree node corresponding to a cycle of length 2k as having 2k-2 children corresponding to the first 2k-2 edges of the cycle. This structure and the associated weights do not accurately reflect the recursive calls in the RECOLOR procedure, which are triggered by edges in the recolored set that form new problematic cycles. The number and identity of children are not fixed in this manner, invalidating the basis for the generating function analysis."
      },
      {
        "Problem": "The coupling argument relating the probability of EDGECOLOR's execution trace to the success probability of COLORVAL(F) seems invalid.",
        "Location": "Proof sketch of Lemma 6, page 8",
        "Explanation": "The proof sketch suggests running COLORVAL(F) using the same random choices as EDGECOLOR. However, the conditions that trigger recoloring in EDGECOLOR (edge in cycle > 6 with homochromatic same-parity edges) and COLORVAL (both same-parity sets monochromatic) are different. This difference in triggers means the sequence of recoloring events and the resulting forest structure may not be the same for both algorithms, invalidating the probabilistic coupling used in the proof."
      },
      {
        "Problem": "The RECOLOR procedure arbitrarily excludes two edges from recoloring in the problematic cycle.",
        "Location": "Procedure RECOLOR, lines 1-3, page 4",
        "Explanation": "When a cycle C (length 2k > 6) with homochromatic same-parity edges is identified, the RECOLOR procedure only recolors the first 2k-2 edges of C(e), excluding e_{2k-1}^C and e_{2k}^C. It is not clear why these two edges are excluded, and this might prevent the procedure from effectively resolving the homochromatic same-parity issue within the cycle C itself, potentially hindering termination or requiring excessive steps."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 5227,
      "output": 747
    }
  },
  {
    "entry_id": 130,
    "retraction_id": "1912.10027v2",
    "paper_id": "1912.10027v1",
    "retraction_comment": "We have found some errors in the methods, in particular two of the methods are not A-stable",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Error Analysis Derivation",
        "Location": "Section 2.2, Section 3.1, Equations (21), (22), (23), (24)",
        "Explanation": "The derivation of the global error form En = Δt^{p+1} τ_{p+1}^n + O(Δt^{p+2}) appears to be based on an incorrect application of the discrete Duhamel principle. Specifically, the forcing term in the error evolution equation En+1 = Q^n En + R_n τ^{n+1} is τ^{n+1}, but the Duhamel sum (Eq 22) uses Δt τ^μ as the forcing term and omits the factor R_μ. This fundamental error in the error propagation analysis undermines the subsequent claims about the specific form of the leading error term that the post-processing method is designed to remove."
      },
      {
        "Problem": "Contradiction between Theory and Numerical Results (Order before Post-processing)",
        "Location": "Section 3.1 (Theorem 1), Section 5 (Tables 2 and 3)",
        "Explanation": "The paper theoretically claims that satisfying condition (19a), D τ_{p+1} = 0, is sufficient for the global error to be of order p+1 (i.e., O(Δt^{p+1})) before post-processing. However, the numerical results presented in Tables 2 and 3 for the p=3 methods (IMEX-EIS+(3,3), pIMEX-EIS+(3,3), IMEX-EIS+(3,4), pIMEX-EIS+(3,4)) and p=4 methods (IMEX-EIS+(4,5), pIMEX-EIS+(4,5)) consistently show a global error order of p before post-processing (approximately 2 for p=3, and approximately 4 for p=4). This direct contradiction suggests that either the theoretical claim regarding the order before post-processing is incorrect, or the constructed methods do not fully satisfy the necessary conditions in a way that guarantees the claimed order."
      },
      {
        "Problem": "Contradiction between Theory and Numerical Results (Order after Post-processing)",
        "Location": "Section 3.1 (Theorem 1), Section 5 (Tables 2 and 3)",
        "Explanation": "The paper theoretically claims that satisfying conditions (19a-d) allows the solution to be post-processed to achieve an accuracy of order p+2. While the numerical results for p=3 and p=4 methods show an increase in order after post-processing, they only reach order p+1 (approximately 3 for p=3, and approximately 5 for p=4), not the claimed p+2. This discrepancy suggests that the post-processing procedure, as applied to these methods, does not achieve the theoretically predicted order, or that the methods do not fully satisfy the conditions required for p+2 accuracy after post-processing."
      },
      {
        "Problem": "Inconsistency in Numerical Results for p=5 Method",
        "Location": "Section 5 (Table 2)",
        "Explanation": "For the IMEX-EIS+(5,6) method (p=5), the paper states that the observed order before post-processing is higher than expected (p+1=6 observed vs p expected), and the overall order (after post-processing) is 'as expected'. The expected overall order is p+2=7. However, Table 2 shows an observed order of 6 both before and after post-processing. This contradicts the claim that the overall order is as expected (7) and suggests that the post-processing did not improve the order beyond what was already achieved by error inhibition."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 15249,
      "output": 836
    }
  },
  {
    "entry_id": 131,
    "retraction_id": "1502.05353v3",
    "paper_id": "1502.05353v2",
    "retraction_comment": "This paper has been withdrawn due to some errors. The main error is the wrong spin function of Eq. (5), which makes equations (13) and (14) incorrect, and in turn puts doubts on the final conclusions",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition and calculation of the direct exchange integral (Jd).",
        "Location": "Page 10, Eq. 13; Page 12, Eq. 18",
        "Explanation": "The direct exchange integral Jd is defined as proportional to the overlap integral O12 multiplied by the diagonal energy 2*tilde{epsilon}+. This is not the standard definition of an exchange integral, which arises from the off-diagonal matrix element of the electron-electron repulsion operator between product wave functions. This fundamental error invalidates the calculated values of Jd in Table 1 and subsequent comparisons."
      },
      {
        "Problem": "Incorrect definition and calculation of the hopping parameters (tau and tilde{tau}).",
        "Location": "Page 15, Eq. 19-21",
        "Explanation": "The hopping parameters are defined as matrix elements of two-particle Hamiltonians (Hab,<ij> or H<ij>) between single-particle wave functions (psi_i, psi_j). Standard hopping integrals in tight-binding models are single-particle matrix elements of the kinetic energy and potential operators between orbitals on different sites. The subsequent calculation and approximation appear inconsistent with standard methods, invalidating the calculated values."
      },
      {
        "Problem": "Arbitrary form and likely incorrect coefficient of the direct exchange term in the modified Hamiltonian.",
        "Location": "Page 18, Conclusion 4; Page 19, Eq. 27",
        "Explanation": "The proposed direct exchange term 4Jd Si.Sj in the modified Hamiltonian is introduced with an arbitrary coefficient (4) and sign, which are not justified by standard theoretical frameworks for magnetic interactions. Adding this term to the t-J Hamiltonian, an effective model, without a rigorous derivation from a more fundamental model is also problematic."
      },
      {
        "Problem": "Error in the calculation of the critical doping.",
        "Location": "Page 19, Case (A) critical doping calculation",
        "Explanation": "The energy balance equation used to determine the critical doping by equating the energies of the ordered and metallic phases appears to be incorrectly formulated or solved. This invalidates the calculated critical doping values for all cases (A, B, C) and the conclusion that the proposed modified Hamiltonian provides better agreement with experimental optimal doping."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 6256,
      "output": 519
    }
  },
  {
    "entry_id": 132,
    "retraction_id": "1808.08722v2",
    "paper_id": "1808.08722v1",
    "retraction_comment": "We find the polarization degrees of freedom of the squeezed light had not been treated properly in our analysis, which would affect our results significantly especially in the case of dissipative quantum walks. A new analysis is currently underway. We thank [REDACTED-NAME] for help in clarifying these issues",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unaccounted Probabilistic Encoding Success Rate",
        "Location": "Section II.B, Fig. 1(b), Eq. 14, 17, 19",
        "Explanation": "The dissipative quantum walk encoding scheme relies on probabilistic projection operations (at each step within the gadget and a final projection onto the diagonal polarization). The paper defines the codewords based on the outcome of these successful projections but does not analyze or report the overall success probability of generating a codeword instance. This omission makes it impossible to assess the practical feasibility and efficiency of the scheme, as many encoding attempts may fail."
      },
      {
        "Problem": "Conditional Error Correction Performance Metric",
        "Location": "Section II.B, Fig. 4, Appendix B",
        "Explanation": "The reported error correction performance (Pno error) is calculated assuming that a codeword has been successfully prepared. This analysis does not incorporate the probability of failure during the encoding process itself due to the probabilistic projections. Therefore, the reported performance metric does not represent the overall success rate of the combined encoding and error correction procedure in a realistic scenario, potentially overstating the scheme's practical utility."
      },
      {
        "Problem": "Complex Arbitrary Logical State Preparation",
        "Location": "Section II.B, Eq. 17, 19, 22",
        "Explanation": "Encoding an arbitrary logical qubit state (α|0⟩L + β|1⟩L) requires preparing a specific input polarization (α|H⟩ + β|V⟩) where the coefficients (α, β) must be pre-calculated and adjusted based on parameters like the number of QW steps (N) and squeezing parameter (r). This is necessary to compensate for the different normalization factors (ZN, ZN+1) of the resulting codewords introduced by the dissipative process, adding significant experimental complexity for preparing arbitrary logical states."
      },
      {
        "Problem": "Resource Cost of Dissipative Encoding Not Discussed",
        "Location": "Section II.B",
        "Explanation": "The dissipative nature of the encoding implies that many encoding attempts will fail due to the probabilistic projections. The paper does not discuss the resource cost associated with these failures, such as the number of input states required or the need for post-selection. This lack of analysis is crucial for evaluating the scalability and overall efficiency of the scheme in a practical quantum computing context."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 4248,
      "output": 531
    }
  },
  {
    "entry_id": 133,
    "retraction_id": "2406.11623v4",
    "paper_id": "2406.11623v3",
    "retraction_comment": "Some errors appeared in the article that seem difficult to correct. For example, the Green function $G_R(o,x)$ for the geodesic ball $B(R)$ was misunderstood to satisfy the Dirichlet boundary condition on the geodesic sphere $\\partial B(R)$, however, this is not the case",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof of the Calculus Lemma (Theorem 4.2)",
        "Location": "Page 16, Proof of Theorem 4.2",
        "Explanation": "The proof uses an incorrect application of integration over a domain. The step relating the integral over the domain $\\Delta(r)$ to an integral over boundaries $\\partial\\Delta(t)$ for $0 < t < r$ (specifically, $\\int_{\\Delta(r)} g_r(o, x) k dv = \\int_0^r dt \\int_{\\partial\\Delta(t)} g_r(o, x) k d\\sigma_t$) is not generally valid. The domain $\\Delta(r)$ is defined by a level set of $G_R(o,x)$, not as a union of boundaries $\\partial\\Delta(t)$ for varying $t$ in this manner."
      },
      {
        "Problem": "Unsound proof of Lemma 4.8",
        "Location": "Page 21, Proof of Lemma 4.8",
        "Explanation": "Similar to the proof of Theorem 4.2, the proof of Lemma 4.8 relies on the same incorrect integration step relating an integral over the domain $\\Delta(r)$ to an integral over boundaries $\\partial\\Delta(t)$, rendering the proof unsound."
      },
      {
        "Problem": "Unsound proof of the Logarithmic Derivative Lemma (Theorem 4.10)",
        "Location": "Page 22, Proof of Theorem 4.10",
        "Explanation": "The proof of Theorem 4.10 relies on estimates derived from Lemma 4.9 and Theorem 4.2. Since the proofs of Lemma 4.8 (used in Lemma 4.9) and Theorem 4.2 are unsound due to the incorrect integration technique, the proof of Theorem 4.10 is also unsound."
      },
      {
        "Problem": "Unsound proof of the Second Main Theorem (Theorem 5.1)",
        "Location": "Page 27, Proof of Theorem 5.1",
        "Explanation": "The proof of the Second Main Theorem relies heavily on the estimates provided by the Logarithmic Derivative Lemma (Theorem 4.10) and the Calculus Lemma (Theorem 4.2). As the proofs of these fundamental lemmas are unsound, the proof of the Second Main Theorem is also unsound."
      },
      {
        "Problem": "Questionable limit calculation in the estimate of harmonic measure",
        "Location": "Page 11, Proof of Theorem 2.2",
        "Explanation": "The calculation of the normal derivative of $g_r(o,x)$ on $\\partial\\Delta(r)$ involves the limit $\\lim_{t \\to r} \\frac{r-t}{p_{t,\\tilde{\\nu}}(x)}$. The paper claims this limit is 1 (or approaches 1 as $r \\to R$), which seems to lack rigorous justification based on the properties of the distance function $p_{t,\\tilde{\\nu}}(x)$ and might be circular with later arguments on page 12. This step is crucial for the estimate of the harmonic measure $d\\pi_r$."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 5088,
      "output": 730
    }
  },
  {
    "entry_id": 134,
    "retraction_id": "2108.09325v2",
    "paper_id": "2108.09325v1",
    "retraction_comment": "Several sections, particularly Section 5, contain an error interpreting the mutual inclination directly as the obliquity",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of observed companion locations in parameter space.",
        "Location": "Page 4, Section 3, Figure 3.",
        "Explanation": "The paper claims observed planetary companions to perpendicular planets (diamonds in Figure 3) 'appear to be in the correct part of parameter space for this scenario to occur'. However, these points fall below the colored regions representing the GR-reduced HEM regime for warm origins, which the paper states corresponds to 'no HEM at all'. This contradicts the claim of observational support from these systems."
      },
      {
        "Problem": "Simplified assumption for final mutual inclination after tidal migration.",
        "Location": "Page 2, Section 2.",
        "Explanation": "The paper assumes the final mutual inclination after tidal migration is approximately equal to the minimum mutual inclination (imin) reached during the Kozai-Lidov cycle. While tidal dissipation is strongest at imin (when eccentricity is maximum), the final inclination depends on the complex interplay and relative timescales of Kozai-Lidov oscillations, tidal circularization, and tidal damping of inclination throughout the migration process. This simplification may not accurately predict the final obliquity distribution."
      },
      {
        "Problem": "Simplified criterion for High Eccentricity Tidal Migration completion.",
        "Location": "Page 4, Section 3.",
        "Explanation": "The paper uses a fixed periapse distance criterion (a(1-emax) < 0.07 AU) to determine if HEM is completed. Tidal migration efficiency depends on various factors including the planet's tidal quality factor, radius, mass, and the star's properties, which are not explicitly included in this simple criterion. Using a fixed periapse threshold might not accurately represent the conditions under which tidal migration successfully brings a planet to a hot orbit across different system architectures and planet/star properties."
      },
      {
        "Problem": "Neglect of octupole potential and stellar oblateness in population synthesis.",
        "Location": "Page 2, Section 2; Page 4, Section 3; Page 5, Section 4.",
        "Explanation": "The main population synthesis results (Figure 4) are based on a simplified model neglecting the octupole term of the secular potential and stellar oblateness precession. While these effects are discussed in Section 4, their omission from the core simulation used to generate the predicted obliquity distribution (Figure 4) could affect the accuracy of the results, particularly the boundaries of the GR-reduced regime and the precise shape and range of the predicted obliquity distribution."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 4260,
      "output": 559
    }
  },
  {
    "entry_id": 135,
    "retraction_id": "1705.00151v2",
    "paper_id": "1705.00151v1",
    "retraction_comment": "We apologize that in the results and algorithms of Section 4.1, Proposition 4.1 and Lemma 4.2, there are some missing conditions and assumptions on the hypergraphs. Hence we want to withdraw the manuscript. Moreover, we want to work out more results, and merge this manuscript together to write a publishable paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Vague or potentially incorrect definition of the associated simplicial complex (KH).",
        "Location": "Definition 4, Page 4",
        "Explanation": "The definition of the associated simplicial complex KH as the 'smallest simplicial complex that H can be embedded in' is not mathematically precise. Standard definitions typically involve taking the union of all subsets of hyperedges. The ambiguity or deviation from standard definitions impacts the correctness of subsequent theorems, proofs, and algorithms that rely on KH."
      },
      {
        "Problem": "Incorrect claim and proof that embedded homology is a local property.",
        "Location": "Theorem 4.1, Page 5",
        "Explanation": "The theorem claims that the n-th embedded homology Hn(H) depends only on the n- and (n+1)-dimensional hyperedges. However, the definition of embedded homology (3.1) involves boundary maps of the full associated simplicial complex KH, which depends on all hyperedges in H. The proof based on this incorrect premise is flawed."
      },
      {
        "Problem": "Flawed definition of 'simplicial-like hyperedge' and related collapsing heuristic.",
        "Location": "Definition on Page 12, Proposition 5.4, Algorithm 5",
        "Explanation": "The definition of a 'simplicial-like hyperedge' (StKHσ ⊆ H) compares a simplicial complex (the star StKHσ) with a set of hyperedges (H), which is a category error. This invalidates Proposition 5.4, which relies on this definition, and consequently undermines Algorithm 5, a key heuristic based on Proposition 5.4."
      },
      {
        "Problem": "Missing experimental results to support claims of algorithmic efficiency.",
        "Location": "Section 8, Tables 1-4, Pages 18-19",
        "Explanation": "The tables intended to present experimental results demonstrating the efficiency of the proposed algorithms and heuristics are empty, stating 'Data in progress'. Without these results, the paper lacks empirical evidence to support its claims about the practical performance and efficiency improvements of the algorithms."
      },
      {
        "Problem": "Incorrect application of torsion bounds derived for simplicial homology to embedded homology.",
        "Location": "Section 7, Page 17, Algorithm 10",
        "Explanation": "The paper applies a known torsion bound for simplicial homology (from [15]) to embedded homology without providing a valid theoretical justification. The intermediate argument attempting to relate embedded homology to a cokernel is incorrect, failing to establish a connection that would allow the direct transfer of the torsion bound."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 16324,
      "output": 578
    }
  },
  {
    "entry_id": 136,
    "retraction_id": "1701.02653v2",
    "paper_id": "1701.02653v1",
    "retraction_comment": "This paper has been withdrawn to an error in Proposition 8 when moving from the quenched to the annealed measure. Thus, it is not a straightforward adaptation of the theorem cited",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect statement of the size-biased property for the voter model cluster size.",
        "Location": "Page 4, Lemma 9",
        "Explanation": "Lemma 9 states that for a unimodular random graph, P(|ζ_t^(ρ)| = n) = n * P(|ζ_t^(ρ)| = n). This equation is trivial (implying P(|ζ_t^(ρ)| = n) = 0 for n != 1) and does not represent the standard size-biased distribution property expected for unimodular graphs, which typically relates the distribution at the root to a size-weighted distribution."
      },
      {
        "Problem": "Incorrect proof of the size-biased property (Lemma 9).",
        "Location": "Page 5, Proof of Lemma 9",
        "Explanation": "The application of the Mass-Transport Principle (MTP) with the chosen function F(G, ρ, x) = E_G[1(|ζ_t^(x)| = n, ρ ∈ ζ_t^(x))] correctly leads to the equation P(|ζ_t^(ρ)| = n) = n * P(|ζ_t^(ρ)| = n). However, this equation is the result of the calculation, not the size-biased property itself, and the proof incorrectly claims this trivial result establishes the size-biased property."
      },
      {
        "Problem": "Incorrect inequality and reliance on incorrect Lemma 9 in the lower bound for pt.",
        "Location": "Page 5, Lemma 10",
        "Explanation": "The proof of Lemma 10 claims P(ζ_t^(ρ) != 0) = Σ_{n>0} P(|ζ_t^(ρ)| = n) = Σ_{n>0} n * P(|ζ_t^(ρ)| = n) = E[|ζ_t^(ρ)|]. The second equality relies on the incorrect statement of Lemma 9. Furthermore, the inequality P(ζ_t^(ρ) != 0) >= (E[|ζ_t^(ρ)|])^-1 (i.e., P(X>0) >= 1/E[X]) is generally false for positive random variables X and is not a consequence of Jensen's inequality as suggested in the proof."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 8104,
      "output": 513
    }
  },
  {
    "entry_id": 137,
    "retraction_id": "2011.07585v2",
    "paper_id": "2011.07585v1",
    "retraction_comment": "The article contains wrong idea. There was mistake in the H3 assumption",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between the function minimized by the inner method (DSGD) and the surrogate function required by Catalyst.",
        "Location": "Section 2, Section 3, Section 2.1, Algorithm 1.2",
        "Explanation": "The Catalyst framework requires the inner method to minimize a single function hk(x). The paper proposes using DSGD as the inner method. However, DSGD is designed to minimize an average of node-local functions, typically of the form (1/n) sum fi(xi). While the paper defines Hk(X) for a matrix of node variables and hk(x) for a single variable, claiming numerical equality for X=x1^T, the application of DSGD (which operates on node variables Xi) to minimize a single function hk(x) or Hk(x) is not properly defined or justified within the standard DSGD framework. This fundamental mismatch makes the proposed Algorithm 1.2 and its analysis unsound."
      },
      {
        "Problem": "Unjustified assumption on DSGD convergence for the inner problem.",
        "Location": "Page 2, Page 7 (Algorithm 1.2, step 4), Page 9 (Derivation of total iterations)",
        "Explanation": "The analysis of the total number of iterations relies on the inner method (DSGD) satisfying a specific convergence property (e.g., E[Hk(xk) - Hk*] <= epsilon_k). The paper seems to assume that the known convergence rate of DSGD for the original problem min (1/n) sum fi(xi) can be directly applied to the inner problem of minimizing the surrogate function hk(x) or Hk(x). The convergence rate of DSGD when applied to minimize hk(x) or Hk(x) (or a decentralized version of it) is not derived or referenced, making the subsequent analysis of the total complexity unsound."
      },
      {
        "Problem": "Flawed proof of Lemma 1 (Property H2).",
        "Location": "Page 4, Lemma 1",
        "Explanation": "Lemma 1 attempts to prove property (H2): E[hk(x)] <= f(x) + (L/2) ||x - Yk-1||^2 (which is E[hk(x)] <= Hk(x)) for x = alpha_k-1 x* + (1-alpha_k-1) xk-1. The proof shows hk(z_k-1) <= Hk(z_k-1) for z_k-1 = alpha_k-1 x* + (1-alpha_k-1) xk-1. This inequality is shown only for a specific point z_k-1 and without expectation, failing to prove the required property (H2) which must hold for any x under expectation."
      },
      {
        "Problem": "Flawed proof of Lemma 2 (Property H3).",
        "Location": "Page 4, Lemma 2",
        "Explanation": "Lemma 2 attempts to prove property (H3): E[f(xk)] <= E[hk*] + delta_k. The proof starts with E[Hk(xk) - Hk*] <= epsilon_k, which is stated as the assumption on the inner method M minimizing Hk, not hk. It then uses E[f(xk)] <= E[Hk(xk)] and seems to incorrectly relate the inner method's error (epsilon_k) to the outer loop term (delta_k). The derivation of delta_k from epsilon_k is unclear and appears incorrect given the definitions of hk and Hk and the required property (H3)."
      },
      {
        "Problem": "Significant notational inconsistency and confusion.",
        "Location": "Throughout the paper, e.g., Page 5, Page 7, Algorithm 1.2",
        "Explanation": "The paper uses similar notations (e.g., x, x, X, hk, Hk) for different mathematical objects (single variable, average variable, matrix variable, different surrogate functions) without clear and consistent definitions or distinctions. This ambiguity makes it extremely difficult to follow the algorithms, understand the relationships between the functions being minimized, and verify the mathematical steps and claims made in the analysis."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 5293,
      "output": 939
    }
  },
  {
    "entry_id": 138,
    "retraction_id": "1803.09392v2",
    "paper_id": "1803.09392v1",
    "retraction_comment": "This paper is withdrawn as the proof of Lemma 2.4 is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 1930,
      "thinking": 65536,
      "output": 1
    }
  },
  {
    "entry_id": 139,
    "retraction_id": "1709.04340v2",
    "paper_id": "1709.04340v1",
    "retraction_comment": "A problem with the proofs of Propositions 2 and 3 (a gap or fault in the reasoning used to claim that the expression in (3.9) is dominated by that in (3.11)); a similar problem with the proof of Proposition $1'$ (it is hard to justify the particular application of the Bourgain-Guth reduction theory implicit in a paragraph above Proposition $1'$). Theorems 1, 2 and 3 lose their status as theorems",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Proof of Theorem 1 relies on an unproven analogue of Proposition 3.",
        "Location": "Page 22, second paragraph",
        "Explanation": "The derivation of the bound for A_p* (analogue of (6.6)) in the proof of Theorem 1 implicitly requires an analogue of Proposition 3 (3.25) for the zeta function sum (2.2). The authors explicitly state that they 'do not know it to be the case that Proposition 3 remains valid' for this sum. This gap means the subsequent derivation of the estimate (8.7) and the proof of Theorem 1 are not fully justified."
      },
      {
        "Problem": "Proof of Theorem 2 relies on an unverified correction to a published theorem.",
        "Location": "Page 17, paragraph after Eq (7.2)",
        "Explanation": "The starting point for the proof of Theorem 2 is a formula (7.2) for R(X) which the authors state is a 'corrected (and reformulated)' version of [GK91, Theorem 4.8], based on the proof in [GK91]. The paper does not provide the corrected statement of the theorem or a proof of the correction. Relying on an unverified correction to a previous result makes the proof of Theorem 2 dependent on an unsubstantiated claim."
      },
      {
        "Problem": "Unclear justification for using a second spacing problem lemma for first spacing problem estimates.",
        "Location": "Page 13, paragraph after Eq (5.22)",
        "Explanation": "The derivation of the key bound (5.23) for the sum S in the proof of Theorem 2 relies on estimates for A_4 and A+ which are claimed to be 'supplied by [H03, Lemma 3.1]'. However, A_p and A_p+ (defined in (5.13) and (5.14)) are related to sums over k and l arising from the first spacing problem, while [H03, Lemma 3.1] provides estimates for sums over m related to the second spacing problem. The paper does not clearly explain or reference how Lemma 3.1 is applicable to provide estimates for A_4 and A+, leaving a gap in the justification of (5.23)."
      },
      {
        "Problem": "High complexity and potential for error in the final exponent calculation.",
        "Location": "Page 23, final paragraph",
        "Explanation": "The proof of Theorem 1 concludes by showing S*/M is bounded by T raised to a negative power (T^{-\\phi\\epsilon} with \\phi > 0). The calculation of the exponent \\phi involves combining numerous exponents from various inequalities and conditions throughout the paper in a highly condensed manner. The complexity of this arithmetic makes it very susceptible to errors. A mistake in this calculation could lead to an incorrect value for \\phi, potentially invalidating the final bound and the proof of Theorem 1."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 9467,
      "output": 665
    }
  },
  {
    "entry_id": 140,
    "retraction_id": "1106.5292v3",
    "paper_id": "1106.5292v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of Equivalence of Equations of Motion",
        "Location": "Section 3.3, comparison between Eq. (20) and Eq. (24)",
        "Explanation": "The central argument for mathematical inequivalence is based on comparing the Einstein equation (rewritten in Jordan frame variables) with the Jordan frame equation for the metric. This comparison is flawed because the single Einstein equation is equivalent to the *system* of Jordan frame equations (for both the metric and the scalar field), not just the metric equation alone. The equivalence implies that a solution to the Einstein equation implies a solution to the *set* of Jordan frame equations, and vice versa."
      },
      {
        "Problem": "Potential Error in the Transformed Einstein Equation",
        "Location": "Page 5, derivation leading to Eq. (24)",
        "Explanation": "The paper claims that Eq. (24) is the result of substituting the transformation rules (Eqs. 5 and 6) into the Einstein equation (Eq. 16). Based on standard derivations and attempts to reproduce it, this equation appears to be incorrectly derived. This incorrect equation is then used as the basis for comparison and the claim of inequivalence."
      },
      {
        "Problem": "Potential Errors in Transformation Formulas",
        "Location": "Page 5, Equations (22) and (23)",
        "Explanation": "The transformation formulas for the Ricci tensor (Eq. 22) and Ricci scalar (Eq. 23) in terms of the Jordan frame metric and scalar field, based on the paper's definition of the scalar field (Eq. 8), appear inconsistent with the fundamental transformation rules (Eqs. 5 and 6). Errors in these basic formulas undermine the subsequent derivations."
      },
      {
        "Problem": "Misapplied Yang-Mills Analogy",
        "Location": "Section 4.1",
        "Explanation": "The paper uses a Yang-Mills analogy to argue that 'gauge fixing' (interpreted as the conformal transformation) and variation do not commute, leading to different equations of motion. This analogy is misapplied as the conformal transformation is a field redefinition, and the equivalence of actions (up to boundary terms) guarantees the equivalence of the full dynamics, unlike some gauge-fixing procedures."
      },
      {
        "Problem": "Conflation of Bulk Equation Incompatibility with Boundary Term Issues",
        "Location": "Section 4.2 and Section 5 (Discussions)",
        "Explanation": "The discussion of boundary terms is conflated with the argument for the mathematical incompatibility of the bulk equations of motion. The alleged incompatibility of the bulk equations, as presented in the paper, is a more fundamental issue (likely due to misinterpretation or miscalculation) than the differences arising from boundary conditions."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 15308,
      "output": 620
    }
  },
  {
    "entry_id": 141,
    "retraction_id": "1903.00526v2",
    "paper_id": "1903.00526v1",
    "retraction_comment": "An error occurs in Section 5. Post-measurement results in the RTO experiment are improperlystated to directly apply to the entangled measurement state itself. This puts the conclusions stated in the abstract into question",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect reinterpretation of product states",
        "Location": "Abstract, Page 1, Page 5, Page 7",
        "Explanation": "The paper reinterprets the product state |A1>|B1> to mean \"A has property |A1> if and only if B has property |B1>\". In standard quantum mechanics, a product state |A1>|B1> describes a composite system where subsystem A is in state |A1> and subsystem B is in state |B1>, meaning A possesses the property associated with |A1> and B possesses the property associated with |B1>. The proposed \"if and only if\" phrasing describes a correlation, which is a property of the joint state, not the individual product state basis vectors themselves. This reinterpretation is a fundamental departure from standard quantum mechanics without sufficient justification."
      },
      {
        "Problem": "Flawed argument connecting RTO experiment results to the reinterpretation of product states",
        "Location": "Page 3, Page 4, Page 5",
        "Explanation": "The paper uses the RTO experiment results, specifically the phase-dependent correlations and the mixed local states (Table 1), to argue that the entangled state (2) must be a superposition of correlations, thereby necessitating the reinterpretation of product states. However, these experimental results and their description (mixed local states, phase-dependent correlations) are standard features of entangled states and are fully consistent with the standard interpretation of (2) as a superposition of joint states |A1>|B1> and |A2>|B2>. The correlations arise *from* the entanglement structure, not from a redefinition of the product state basis vectors. The argument incorrectly uses standard consequences of entanglement to justify a non-standard interpretation of the basis states."
      },
      {
        "Problem": "The proposed interpretation does not fully resolve the definite outcomes problem",
        "Location": "Abstract, Page 1, Page 7",
        "Explanation": "The paper claims that interpreting the entangled state (2) as a superposition of correlations (\"|A1> if and only if |B1>, and |A2> if and only if |B2>\") makes it non-paradoxical and definite, resolving the problem of definite outcomes. However, this is still a superposition of two distinct possibilities for the composite system's state/properties (whether interpreted as joint properties or correlations). The core problem of definite outcomes in quantum measurement is explaining why, upon measurement, only *one* of the terms in the superposition is observed, rather than the system remaining in the superposition. The proposed reinterpretation of the terms does not inherently explain this selection process or the apparent collapse."
      },
      {
        "Problem": "Misleading use of the term \"decoherence\"",
        "Location": "Page 3, Page 5, Page 7",
        "Explanation": "The paper states that entanglement \"decoheres\" both photons (Page 3, Page 5). While entanglement leads to the subsystems being described by mixed states (which is related to decoherence in the context of interaction with an environment), the term \"decoherence\" typically refers to the loss of coherence due to interaction with an environment, leading to a transition from a pure state to a mixed state. In the case of entanglement between two subsystems A and B, the *composite* system AB remains in a pure state (2), and the coherence is present in the correlations between A and B. The subsystems A and B are in mixed states (3) and (4) when considered in isolation (by tracing over the other subsystem), but this is a consequence of entanglement, not necessarily \"decoherence\" of the subsystems themselves in the usual sense. The author later clarifies that entanglement \"shifts coherence to the composite system\" (Page 4, Page 7), which is more accurate, but the initial use of \"decoheres both photons\" is potentially misleading."
      },
      {
        "Problem": "Incomplete explanation of the transition to a single outcome",
        "Location": "Section 3, Page 5-7",
        "Explanation": "The paper describes the measurement process as a unitary evolution into the entangled state (2), followed by a \"collapse\" at the instant of entanglement, leading to the subsystems being in ontological mixtures (3) and (4). It then invokes the irreversibility of macroscopic recording (FAPP) to explain the single observed outcome. However, the transition from the pure entangled state (2) to a single definite outcome (e.g., A1 and B1) is not fully explained by the unitary evolution or the FAPP irreversibility of recording. The paper states that \"nonlocal properties of entanglement guarantee that one and only one outcome is realized\" (Page 7), but this is a statement of the outcome, not a mechanism derived from the proposed interpretation or the described process. The core issue of how the system selects a single branch from the superposition (2) is not clearly resolved."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 3232,
      "output": 1071
    }
  },
  {
    "entry_id": 142,
    "retraction_id": "1503.07411v2",
    "paper_id": "1503.07411v1",
    "retraction_comment": "This paper has been withdrawn due to a gap in the proof of Proposition 2.19",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed intersection theory calculation in the proof of Proposition 2.19.",
        "Location": "Page 11, Proof of Proposition 2.19",
        "Explanation": "The calculation of the class of the 1-cycle Z = H₁·H₂ and its relation to the basis {C, l} and the intersection number (-Kx)³ appears incorrect. Specifically, the formula Z = μ²(Kx)² + 2dμνl seems dimensionally inconsistent, and the relation β = (-Kx)³ + dnef(X/P¹) used to bound the vertical component γ mixes a coefficient of a 1-cycle class with a 0-cycle intersection number. This invalidates the final contradiction used to prove that the map is square."
      },
      {
        "Problem": "Incorrect calculation of the anticanonical volume (-Kx)³ in Lemma 3.6.",
        "Location": "Page 16, Proof of Lemma 3.6",
        "Explanation": "The calculation of (-Kx)³ for the constructed fibrations Xn/P¹ relies on intermediate intersection numbers H³ = n/4 and H²·F = 2. The derivation of H³ = n/4 and the subsequent formula (-Kx)³ = 12 - 5n appear to use non-standard or incorrectly applied intersection theory notation for the weighted projective space bundle. The resulting formula for (-Kx)³ contradicts the standard expansion of (-Kx)³ = (H - (n-2)F)³ using the stated values for H³ and H²·F. This error affects the verification of condition (4) of Theorem 1.1, which is crucial for proving the birational rigidity of Xn/P¹."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 15369,
      "output": 399
    }
  },
  {
    "entry_id": 143,
    "retraction_id": "1602.03949v2",
    "paper_id": "1602.03949v1",
    "retraction_comment": "This paper has been withdrawn by the author due to the different description of second-order correlation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition of Signal-to-Noise Ratio (SNR) used in Equation (1) is non-standard for imaging and ghost imaging. It calculates the ratio of the sum of object pixels to the sum of the difference between object and reconstructed image pixels. This metric is more akin to a fidelity or PSNR measure and does not represent the conventional definition of SNR (e.g., mean signal divided by standard deviation of noise), which quantifies the ability to distinguish signal from noise fluctuations. Using this non-standard definition makes the claim of \"improving signal-to-noise ratio\" potentially misleading, as the observed improvement might reflect increased image fidelity or reduced overall error rather than improved robustness against noise in the conventional sense.",
        "Location": "Equation (1), Page 2",
        "Explanation": "The formula `SNR = 20 * log10 | Sum(S(x,y)) / Sum(S(x,y) - O(x,y)) |` is used. S(x,y) is the binary object, O(x,y) is the reconstructed image. This is not the standard definition of SNR in imaging (mean/std dev). The conclusions about SNR improvement are based on this metric, which may not reflect the system's performance in overcoming noise fluctuations."
      },
      {
        "Problem": "The comparison labeled \"direct imaging\" in Figure 3 appears to be based on analyzing the raw speckle patterns captured by the camera in the idler arm of the ghost imaging setup, rather than a true direct image of the object. The camera in the idler arm receives light that has interacted with the object in the signal arm and been split by BS2. This is part of the ghost imaging process, not a standard direct imaging setup where the object is focused onto the sensor. Comparing the filtering effect in ghost imaging to this mislabeled \"direct imaging\" is misleading and weakens the argument that filtering is particularly beneficial for ghost imaging compared to conventional imaging.",
        "Location": "Figure 3, Page 2",
        "Explanation": "Figure 3 presents results for \"direct imaging SNR\". However, the experimental setup (Figure 1) shows the camera is in the idler arm, capturing speckle patterns. Analyzing these patterns without correlation is not direct imaging of the object. The comparison is therefore based on an invalid premise."
      },
      {
        "Problem": "The experimental setup involves mixing a strong, wideband thermal background with the narrowband signal *before* the object and filter. While a filter is placed in the signal arm *after* the object, the idler arm receives unfiltered broadband background light (in addition to the signal component split by BS2). The correlation process relies on correlating the signal arm measurement (filtered) with the idler arm measurement (unfiltered broadband background + signal). The presence of significant unfiltered broadband background in the idler arm could introduce noise into the correlation, and the paper does not fully explain how this is handled or its impact, beyond stating that the iris controls the total light. While the filtering in the signal arm helps, the unfiltered background in the idler arm remains a potential source of noise that is not explicitly addressed in the context of the correlation calculation.",
        "Location": "Figure 1 (Experimental setup), Page 1; Section 2 (Method & Result), Page 1",
        "Explanation": "The background light is mixed before the object and filter. The filter is only in the signal arm. The idler arm camera receives unfiltered broadband background light. The correlation is performed between the filtered signal arm measurement and the idler arm measurement containing unfiltered background. The impact of this unfiltered background on the correlation noise is not clearly analyzed or mitigated, potentially affecting the interpretation of the results."
      }
    ],
    "token_usage": {
      "input": 640,
      "thinking": 3781,
      "output": 797
    }
  },
  {
    "entry_id": 144,
    "retraction_id": "2203.01307v2",
    "paper_id": "2203.01307v1",
    "retraction_comment": "Lemma 2.1 is true for Heisenberg type groups, but in general not for M_tivier groups, cf. Eq. (2.4) of M_ller and Stein [MS94]",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect kernel support assumption and misuse in estimating the 'large distance' term.",
        "Location": "Section 6, Step (4) and Step (5)",
        "Explanation": "Step (4) claims the convolution kernel $K_{F_\\ell(L,U)}(x,u)$ is essentially supported in a ball of dimension $(2^\\ell R_\\epsilon) \\times R^2$. This is incorrect; the support in the $g_1$ variable is related to $R_\\epsilon = 2^{(\\iota-\\ell)/2}$, not $2^\\ell R_\\epsilon$, and the kernel is not compactly supported in the $g_2$ variable $u$. Step (5) then uses this flawed support property (specifically, the condition $|x-y| \\ge 2^\\gamma C R_\\epsilon$) to estimate the $g_{<\\iota}^{(2)}$ term, which represents the contribution from regions where $|x-y|$ is large. The kernel is actually supported where $|x-y|$ is small, making this argument invalid. The proof requires a kernel decay estimate for large $|x-y|$ and $|u|$, which is not provided or correctly applied."
      },
      {
        "Problem": "Flawed estimate for the 'small distance' term.",
        "Location": "Section 6, Step (5)",
        "Explanation": "The estimate for the $g_{<\\iota}^{(1)}$ term, which represents the contribution from regions where $|x-y|$ is small, relies on a volume factor $(2^{\\ell(d_1-d_2)+2\\ell d_2})^{1/q}$ that is incorrectly derived. Using the correct volume factor for the support in $g_1$ (related to $2^{(\\iota-\\ell)d_1/2}$) in conjunction with the $L^p \\to L^2$ estimate from Proposition 4.2 and summing over $\\ell \\le \\iota$ does not yield the required exponential decay in $\\iota$. This indicates a fundamental error in the calculation for the small eigenvalues part of the multiplier decomposition."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 12455,
      "output": 473
    }
  },
  {
    "entry_id": 145,
    "retraction_id": "2112.10980v2",
    "paper_id": "2112.10980v1",
    "retraction_comment": "There is an error in the proof of the co-primality statement in Proposition 6. The author has constructed examples of knots with integer surgeries so that the orders of the groups generated by these knots and their surgery duals have a non-trivial common factor, so in fact the co-primality statement in Proposition 6 is false",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of knot order in connected sum",
        "Location": "Page 4, Proof of Theorem 7",
        "Explanation": "In the proof, the author considers a link L = K ∪ m in Y and performs -2 surgery on the meridian m to obtain Y#RP³. The knot K becomes a knot K' in Y#RP³. The author claims |K'| = 2|K|. However, the homology class of K' in H₁(Y#RP³) ≃ H₁(Y) ⊕ Z₂ is the image of the class of K in H₁(Y) under the inclusion, which has order |K|. Thus, |K'| = |K|, not 2|K|. This error invalidates the subsequent steps in the proof of Theorem 7."
      },
      {
        "Problem": "Unjustified intersection number claims",
        "Location": "Page 4, Proof of Proposition 6",
        "Explanation": "The proof relies on the claims that the intersection numbers ι(x, Σ̂K*) = |K*| and ι(x*, Σ̂K) = |K|, where x = K × [0,1] ∪ c(H), x* is the co-core of H, Σ̂K is the closed surface generating H₂(W), and Σ̂K* is the dual surface. These claims are crucial for deriving the equation n|K*| + n*|K| = 1, which implies the coprimality of |K| and |K*|. However, these intersection number values are not justified in the text and appear non-trivial to prove, potentially being incorrect."
      },
      {
        "Problem": "Unclear derivation of |p| = |K||K*|",
        "Location": "Page 4, Proof of Proposition 6",
        "Explanation": "The proof of Proposition 6 claims that |p| = |K||K*| based on the exactness of the sequence involving H₁(∂W), H₁(W), and H₁(W, ∂W) and the orders of these groups. The argument provided is very brief and does not clearly show how the coefficient p, which arises from the identification H₂(W, ∂W) ≃ Z ⊕ H₁(W), is related to the orders |K| and |K*| via the maps in the sequence. This step is essential for establishing the first part of Proposition 6, |ι(Σ̂K, Σ̂K)| = |K||K*|."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 6476,
      "output": 560
    }
  },
  {
    "entry_id": 146,
    "retraction_id": "2006.16461v2",
    "paper_id": "2006.16461v1",
    "retraction_comment": "withdrawn due to an error in Lemma 4.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition and value of N(n, p, q) for the base case n=0 are unclear and seem inconsistent with the parametrization for n>0.",
        "Location": "Page 1, Page 9 (Conventions), Page 12 (Lemma 4.2), Page 14 (Proof of Theorem 1.1)",
        "Explanation": "The (n, p, q) parametrization describes the dividing set on ∂M, where 2n is the number of components. For n=0, there are no components, making the definition of p and q (winding numbers of each component) problematic. The paper uses a convention N(0, p, q) = N(1, p', q') where (p', q') are derived from (p, q) via a bypass on a (1, -p, q) structure. This defines N(0, p, q) based on a different dividing set type (1, -p', q') rather than a (0, -p, q) set, which is confusing and lacks justification for why this convention is valid for the recurrence base case. The proof of Theorem 1.1 relies on the formula agreeing with N(n, p, q) for n=0, but the formula C0(s) = s requires s to be defined for n=0, which is also problematic as s depends on p and q of the n=0 dividing set."
      },
      {
        "Problem": "Lemma 4.1 claims that attaching k nonadjacent bypasses changes the suture from (n, -p, q) to (n-k, -p, q), implying the (p, q) parameters are invariant.",
        "Location": "Page 12, Lemma 4.1 and its proof",
        "Explanation": "The definition of (p, q) depends on the winding numbers of *each component* of the dividing set. Attaching bypasses merges components. The proof does not adequately explain why the new, merged components (or the resulting dividing set structure) would have the same (p, q) winding numbers as the original components. The proof for k=2 is also difficult to follow regarding how the second bypass interacts with the modified dividing set. This lemma is crucial for the recurrence relation in Lemma 4.2."
      },
      {
        "Problem": "The proof of Lemma 4.2 assumes that the union of the images of the bypass maps Ba covers the entire set of tight contact structures Tn.",
        "Location": "Page 12, Proof of Lemma 4.2",
        "Explanation": "The proof uses the inclusion-exclusion principle on the sets Ba(Tn-1) to derive the recurrence relation. This requires the union of these sets to be equal to Tn, meaning every tight contact structure on Γn must be obtainable by attaching *some* interior bypass (and reversing). This is a strong assumption that is not proven in the paper and is essential for the validity of the derived recurrence relation."
      },
      {
        "Problem": "The conclusion in Proposition 3.10 that the original tight structure must be overtwisted is not fully justified.",
        "Location": "Page 11, Proposition 3.10 and its proof",
        "Explanation": "The proof constructs a subset of M obtained by attaching two specific bypasses and shows its boundary has a homotopically trivial dividing curve, implying the contact structure on this subset is overtwisted by Giroux's criterion. It then concludes the *original* tight structure must have been overtwisted. Attaching interior bypasses is stated to preserve tightness (Proposition 3.8 proof). The argument needs to clarify why the specific combination of these two bypasses, even if viewed as operations on the original manifold, leads to overtwistedness of the original structure, rather than just the resulting structure on the subset."
      },
      {
        "Problem": "The convention N(0, p, q) = N(1, p', q') introduces confusion regarding the domain of the (p, q) parameters for n=0.",
        "Location": "Page 9 (Conventions), Page 12 (Lemma 4.1)",
        "Explanation": "The main theorem and the definition of (n, p, q) for n>0 assume 0 < q < p and gcd(p,q)=1. Lemma 3.7 defines (p', q') from (p, q) satisfying 0 < q < p. The convention N(0, p, q) = N(1, p', q') seems to imply that N(0, p, q) is defined for the same (p, q) values as the theorem (0 < q < p, gcd(p,q)=1), but its value is given by N for a *different* dividing set (1, -p', q'). This is inconsistent with the idea that N(n, p, q) classifies structures for the dividing set (n, -p, q). It makes the n=0 case of the recurrence and the base case for the main theorem's proof difficult to interpret correctly."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 7461,
      "output": 1117
    }
  },
  {
    "entry_id": 147,
    "retraction_id": "1811.02204v3",
    "paper_id": "1811.02204v2",
    "retraction_comment": "Some arguments in the proof of Thm. 2.3.3 are erroneous. One of the faulty arguments lies in the estimate on the first line of page 24. The author mistakenly treats the orthogonal decomposition with respect to the unweighted inner product as the one with respect to the weighted one. Contents which are free from irreparable errors are contained in arXiv:1912.08076",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear definition and properties of the lc-measure and σf",
        "Location": "Definition 1.3.1, eq 1.3.1, Section 3",
        "Explanation": "The definition of the lc-measure (eq 1.3.1) involves a limit as ε→0+. The convergence of this limit for general f and g, and the rigorous proof that the integral is finite for exactly one value of σ (defining σf), are not fully detailed. Proposition 3.0.1 proves this only for specific cases on a coordinate neighborhood under snc assumptions, and the generalization to the whole manifold X is not explicitly shown to be rigorous."
      },
      {
        "Problem": "Insufficient justification for auxiliary function construction",
        "Location": "Section 2.2, Section 2.3, e.g., Page 13, Page 20",
        "Explanation": "The construction of the crucial auxiliary functions ηε, λε, and ν (or variants) used in the twisted Bochner-Kodaira inequality is presented by 'putting' specific forms. The detailed verification that these specific choices satisfy all the necessary inequalities (e.g., eq 2.2.5a, 2.2.5b, 2.3.3), particularly the positivity of λε and the required lower bounds for the curvature term Θ, is not fully provided."
      },
      {
        "Problem": "Incomplete proof of continuation Lemma 2.3.4",
        "Location": "Lemma 2.3.4, Page 25",
        "Explanation": "The proof outline for Lemma 2.3.4, which is essential for extending the solution of the ∂-equation across higher codimension analytic sets, is incomplete. The induction step and the claim that the lemma follows from Lemma 2.2.3 after the induction are not rigorously justified."
      },
      {
        "Problem": "Insufficient justification for the limit process and holomorphicity of the extended section",
        "Location": "Proofs of Theorems 2.2.5, 2.3.7, 2.3.8, e.g., Page 18, Page 30",
        "Explanation": "The final step of the main theorems involves taking a limit of approximate solutions Fε. While weak L² convergence is claimed, the justification for the holomorphicity of the limit F on the whole manifold X, which relies on arguments involving local uniform convergence via Montel's theorem applied to Fε - sε, requires more detailed and rigorous steps connecting the different modes of convergence and the properties of the auxiliary sections sε."
      },
      {
        "Problem": "Reliance on snc reduction without fully justifying the transformation of estimates/measure",
        "Location": "Section 2.1, Page 8-9",
        "Explanation": "The paper reduces the problem to the case where the polar divisors and S are snc via log-resolution (Section 2.1). While this is standard for ideal sheaves, the transformation of the novel lc-measure and the specific weighted L² estimates under blow-up needs careful justification, especially the claim that the estimates are valid 'even before blowing up'."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 3478,
      "output": 711
    }
  },
  {
    "entry_id": 148,
    "retraction_id": "1303.6535v2",
    "paper_id": "1303.6535v1",
    "retraction_comment": "Crucial flaw in proof of Theorem 3. The argument only gives a lower bound, not purity as claimed (the latter most likely does not hold except for in small rank)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect purity weight for Ext¹ groups.",
        "Location": "Theorem 4, Page 2",
        "Explanation": "Theorem 4 claims that Ext¹(Δv, Δw) is pure of weight 2 for all v < w. Using the geometric interpretation Ext¹(Δv, Δw) = H_c¹+l(w)-l(v)(Cv ∩ Cw) and the fact that Cv ∩ Cw is a smooth variety of dimension d = l(w)-l(v) for v ≤ w, the purity weight of H_c^k(X) for a smooth variety X of dimension d is k-2d. Thus, the purity weight of Ext¹(Δv, Δw) should be (1+d) - 2d = 1-d = 1-(l(w)-l(v)). This is generally not equal to 2 for all v < w."
      },
      {
        "Problem": "Incorrect statement about the dimension of Hom between Verma modules.",
        "Location": "Proof of Corollary 2, Page 2; Proof of Corollary 3, Page 2",
        "Explanation": "The paper states that 'dim Hom(Δx, Δy) = 1 if and only if x ≤ y, and that Hom(Δx, Δy) = 0 if x < y'. The correct statement for Verma modules Δx and Δy is that dim Hom(Δx, Δy) = 1 if x=y and 0 if x ≠ y (for x ≤ y). This fundamental error is used in the proofs of Corollary 2 and 3, invalidating their arguments."
      },
      {
        "Problem": "Proposition describing the topology of Schubert cell intersections appears incomplete.",
        "Location": "Proposition 1, Page 1",
        "Explanation": "Proposition 1 describes the topology of Cv ∩ Cw (for v < w, ws < w) based on whether vs < v or vs > v. The case vs > v is split into subcases vs ≠ ws and vs ≤ ws. This does not cover all possibilities for the relationship between vs and ws when vs > v (e.g., vs > ws or vs incomparable to ws). This incompleteness means the proposition does not provide a complete case analysis for the geometric decomposition, which is foundational for the subsequent recursive formulas."
      },
      {
        "Problem": "Derivation of recursive formulas for Ext¹ dimensions appears incorrect.",
        "Location": "Corollary 5, Page 2",
        "Explanation": "The recursive formulas for dim Ext¹(Δv, Δw) in Corollary 5 are derived from the topological descriptions in Proposition 1 using properties of cohomology (implicitly Künneth formula and LES). The application of the Künneth formula for compactly supported cohomology to the product decomposition in Proposition 1 (ii) does not yield the stated dimension formula. Similarly, the LES arising from the decomposition in Proposition 1 (iii) does not directly yield the stated dimension formula."
      },
      {
        "Problem": "Purity argument in the inductive proof of Theorem 4 is flawed.",
        "Location": "Proof of Theorem 4, Page 2",
        "Explanation": "The inductive step in the proof of Theorem 4 relies on Corollary 3 providing relations between Ext¹ groups as pure Hodge structures. Corollary 3 involves direct sums (e.g., Ext¹(Δv, Δw) ⊕ Q^H(-1)) and exact sequences. A direct sum of pure Hodge structures is pure only if they have the same weight. An exact sequence of pure Hodge structures implies purity for the middle term only under specific weight conditions. The weights involved (e.g., weight 2 for Q^H(-1) and the expected weight 1-(l(w)-l(v)) for Ext¹) are generally different, invalidating the purity arguments used in the induction."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 17454,
      "output": 860
    }
  },
  {
    "entry_id": 149,
    "retraction_id": "1204.0036v3",
    "paper_id": "1204.0036v2",
    "retraction_comment": "This paper has been withdrawn by the authors because Lemma 11, for p>1, is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect statement about the function on the fiber of the projection",
        "Location": "Page 27, Proof of Theorem 3",
        "Explanation": "The statement claims that the function $\\theta_h(\\zeta)$, defined on $H(d) \\times P(C^{n+1})$, is constant on the fiber of the projection $\\pi_1: V \\to H(d)$. The fiber at $h \\in H(d)$ is the set of pairs $(h, \\eta)$ where $\\eta$ is a root of $h$. The function $\\theta_h(\\zeta)$ is defined for a fixed $h$ as a function of $\\zeta \\in P(C^{n+1})$, and its definition clearly depends on $\\zeta$. Therefore, it is not constant on the set of roots $\\eta$, which constitutes the second component of the fiber pairs $(h, \\eta)$. This misunderstanding appears to lead to errors in the subsequent application of Hölder's inequality."
      },
      {
        "Problem": "Incorrect application of Hölder's inequality",
        "Location": "Page 28, Proof of Theorem 3",
        "Explanation": "The authors apply Hölder's inequality to the integral $\\int_V (\\mu(h, \\eta)^2 / ||h||^2) \\Theta(h, \\eta) dpv$. While the inequality itself is correct, the terms on the right-hand side of the inequality presented on page 28 do not match the terms obtained by correctly applying Hölder's inequality to this integral using the co-area formula derivation from page 27. Specifically, the second term involves the expectation of an $L_p$ norm over $P(C^{n+1})$, $E_{H(d)}[||\\theta_h||_{L_p}]$, whereas the correct application would yield the expectation of a sum over roots, $E_G[\\sum_{\\eta} \\Theta(h, \\eta)^p]$. This mismatch invalidates the bound derived in Proposition 4 and consequently Theorem 3."
      },
      {
        "Problem": "Missing factor in the final bound derivation",
        "Location": "Page 28, Proof of Theorem 3",
        "Explanation": "The definition of the measure $dpv$ on $V$ includes a factor of $D^{-1}$ and the Jacobian $NJ_{\\pi_1}(h, \\eta)$. When applying the co-area formula for the projection $\\pi_1: V \\to H(d)$, the Jacobian $NJ_{\\pi_1}(h, \\eta)$ cancels out, leaving the $D^{-1}$ factor outside the integral over $H(d)$. This factor $D^{-1}$ appears to be missing in the final bound presented on page 28 for $(I)$, which has factors $CD^{3/2} D^{1/p}$ outside the expectations, suggesting an error in carrying the factors through the derivation from the integral over $V$ to the expectations over $H(d)$."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 9992,
      "output": 676
    }
  },
  {
    "entry_id": 150,
    "retraction_id": "2111.11437v6",
    "paper_id": "2111.11437v5",
    "retraction_comment": "There is an error. In section 3.4, the author identifies $Hom_Q(M, _M)$ with the set $Mat_{r \\times r}$ through the decomposition of M into a direct sum of indecomposable modules, and discusses nilpotent matrices in $Mat_{r \\times r}$. This is misleading because here we do not have a natural ring structure on $Mat_{r \\times r}$",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Conflation of Ext groups over Q and AQ",
        "Location": "Throughout the paper, e.g., Proposition 1.1, Theorem 1.2, Theorem 3.12, Theorem 4.6, Proposition 4.5.",
        "Explanation": "The paper uses the same notation Ext^1(M,N) for both representations of the quiver Q and modules over the preprojective algebra AQ. The main theorems relate the vanishing of Ext^1 over AQ to combinatorial conditions derived from calculations involving Ext/Hom over Q (Theorem 3.12). The necessary link between these two types of Ext groups (e.g., formula (4.1)) is not established or used in the proofs, creating a logical gap."
      },
      {
        "Problem": "Incorrect identification of the map ra,b with matrix multiplication",
        "Location": "Proof of Theorem 3.11, reliance on Lemma 3.8.",
        "Explanation": "The map ra,b for AQ modules is defined as f ↦ τ(f)a - bf. The proof calculates its kernel dimension by treating a, b, and f as matrices and the map as f ↦ af - fb. This identification ignores the Auslander-Reiten translation τ acting on the Q-morphism f, which is a fundamental part of the map's definition, invalidating the calculation and the theorems that depend on it."
      },
      {
        "Problem": "Inconsistent and unclear definition of the set R(λ, κ)",
        "Location": "Definition (1.3), Theorem 1.2, Theorem 3.11, Theorem 3.12, Theorem 4.6.",
        "Explanation": "The set R(λ, κ) is given different definitions in different parts of the paper ((1.3) vs Theorem 3.11). Furthermore, the proof of Theorem 3.12 uses related but distinct sets (Γλ,κ, Γλ,τκ). The connection between the set R(λ, κ) used in the statement of the main theorems (1.2, 4.6) and the sets used in the supporting proofs is not clearly defined, making it impossible to verify the combinatorial conditions."
      },
      {
        "Problem": "Confusing and potentially incorrect definition of the dual representation M*",
        "Location": "Definition 2.2.",
        "Explanation": "Definition 2.2 defines the dual representation M* as a set of elements in D Ext^1_Q(M,M) satisfying a minimality condition. It then states that this set is a unique element up to isomorphism, which is contradictory. This definition is used to define the AQ module structure (Mλ, a) with a=Mλ*, which is essential for the paper's framework."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 7376,
      "output": 627
    }
  },
  {
    "entry_id": 151,
    "retraction_id": "0912.4084v3",
    "paper_id": "0912.4084v2",
    "retraction_comment": "This paper has been withdrawn by the author. Paper is withdrawn. On review the paper contributes nothing of significance. The runtime analysis of the algorithms presented, while correct in terms of number of operations, does not represent the complexity of the algorithms in terms of \"bits input\". A naive mistake in reasoning",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Algorithm 1 Decomposition Complexity Analysis is unsound.",
        "Location": "Page 3, Section 2.1.1",
        "Explanation": "The analysis claims a worst-case execution time of O(n log10 n) in magnitude. This relies on an incorrect bound for the total number of inner loop iterations (stated as O(n^0.5 log n)) and an incorrect complexity for arithmetic operations (stated as O(n) in bits instead of O(log n)). A correct analysis of the described subtraction-based division leads to a higher complexity, such as O(n (log n)^2) in bits."
      },
      {
        "Problem": "Algorithm 1 Prime Factoring Complexity Analysis is unsound.",
        "Location": "Page 4, Section 2.1.2",
        "Explanation": "The analysis claims a worst-case execution time of O(n^1.5 log10 n) in magnitude for prime factoring. This is based on the incorrect assumption that the decomposition algorithm is executed sqrt(n) times recursively. The number of recursive calls is bounded by the number of prime factors, which is O(log n)."
      },
      {
        "Problem": "Algorithm 2 Sieve Complexity Analysis is unsound.",
        "Location": "Page 5, Section 3.2.2",
        "Explanation": "The analysis for the sieve process, particularly the complexity calculations for Loop 3 and Loop 5, is fundamentally flawed. It involves multiplying unrelated terms and misapplying complexity bounds, leading to an unjustified O(n^2.5) complexity claim for the sieve."
      },
      {
        "Problem": "Algorithm 2 Filter Complexity Analysis is unsound.",
        "Location": "Page 6, Section 3.2.3",
        "Explanation": "The analysis for the filter process claims a worst-case execution time of O(n^2.5). This is based on an incorrect complexity for the summation/addition operation within Loop 7, which is stated as O(n^1) but should be O(log n) in bits. The correct analysis for the described inefficient filter is O(n^1.5 log n) in bits."
      },
      {
        "Problem": "Incorrect initialization in Algorithm 1 implementation.",
        "Location": "Page 8, Section 6.1",
        "Explanation": "The initialization of the remainder variable 'lv_lng_r' as 'n % (x*y)' is incorrect for the relation n = x*y + r where r is the remainder of n divided by x*y. It should be 'n - x*y'. While the subsequent loops might correct the state, the initial state is based on a misunderstanding of the division relation."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 7956,
      "output": 614
    }
  },
  {
    "entry_id": 152,
    "retraction_id": "2106.04691v2",
    "paper_id": "2106.04691v1",
    "retraction_comment": "Theorem 1.7 is established only under a restrictive hypothesis, not the generality that the authors assert",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misplaced/Confused Proof Outline",
        "Location": "Page 21, Proof outline of Theorem 3.31",
        "Explanation": "The paragraph starting 'The Hodge index theorem then implies...' presents a contradiction argument that is used in the proof of Corollary 3.37, not Theorem 3.31. Its inclusion in the outline for Theorem 3.31 makes that outline logically inconsistent as presented, as the contradiction derived is not used to prove the ampleness of L_m."
      }
    ],
    "token_usage": {
      "input": 11734,
      "thinking": 12739,
      "output": 124
    }
  },
  {
    "entry_id": 153,
    "retraction_id": "1308.2817v2",
    "paper_id": "1308.2817v1",
    "retraction_comment": "The paper has been withdrawn because Eq.(4) is incorrect (isospin CG coefficients have been omitted). The corrected results change some of the discussion for 48Ca while the conclusions for 208Pb are hardly effected. A revised manuscript is under preparation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Reliance on theoretical angular distribution shape for 0-degree cross section extrapolation.",
        "Location": "Page 2, text below Fig. 2; Page 3, text above Eq. 2",
        "Explanation": "The method requires the cross section at 0 degrees, but data is taken at finite angles (0.4°-5.2°). Extrapolation relies on the theoretical angular distribution shape from DWBA calculations. While the paper uses the shape rather than absolute values, the accuracy of the theoretical shape at these extreme forward angles is critical for reliable extrapolation, and this accuracy is not independently verified against model-independent data at 0 degrees."
      },
      {
        "Problem": "Unverified assumption of identical nuclear matrix elements for analog GT and spin-flip M1στ transitions.",
        "Location": "Page 3, text above Eq. 3; Eq. 3",
        "Explanation": "The core of the method relies on the assumption that the nuclear matrix element ||Σσκτκ||² is identical for the GT transition in the (p,n) reaction and the analog spin-flip M1στ transition in the (p,p') reaction. This is based on perfect isospin symmetry, which is an approximation. While the paper shows agreement for the 48Ca case after scaling (Fig. 3), this validates the relation between cross sections for that specific state, not necessarily the identity of the underlying matrix elements in general or for other states/nuclei like 208Pb."
      },
      {
        "Problem": "Dependence on global systematics for the Gamow-Teller unit cross section (ôGT).",
        "Location": "Page 3, Eq. 5 and surrounding text",
        "Explanation": "The method uses a parameterization of ôGT derived from systematics of (p,n) reactions on various nuclei (Eq. 5) to normalize the strength. This introduces an uncertainty (stated as 9%) and assumes that the target nuclei (48Ca and 208Pb) conform to this global trend. Relying on a global systematics rather than a target-specific measurement or calculation for ôGT introduces a potential source of systematic error in the derived ôM1 and subsequently B(M1στ)."
      },
      {
        "Problem": "Approximation used to convert B(M1στ) to B(M1) for comparison with electromagnetic data.",
        "Location": "Page 3, text above Eq. 7; Page 4, Eq. 7",
        "Explanation": "The method primarily extracts B(M1στ), the isovector spin-flip M1 strength. To compare with results from electromagnetic probes (which measure B(M1)), the paper uses an approximation (Eq. 7) that neglects the isoscalar spin part and orbital M1 strength. While justified for 48Ca, the accuracy of this approximation for 208Pb is not explicitly discussed, and its general validity for all states and nuclei studied with this method is assumed when comparing to B(M1) values."
      },
      {
        "Problem": "Potential incompleteness of the observed M1 strength distribution in 208Pb.",
        "Location": "Page 4, Discussion section; Fig. 4",
        "Explanation": "The paper finds additional strength in 208Pb above 8 MeV. However, the strength distribution shown in Fig 4 only goes up to 9 MeV, while the experimental spectra (Fig 1) extend to 25 MeV. The conclusion about the 'total strength' or a 'reasonably complete M1 strength distribution' relies on the assumption that no significant M1 strength exists at higher excitation energies within the measured range (up to 25 MeV) that was not identified or included in the summation. Evidence for completeness above 9 MeV is not provided."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 3933,
      "output": 841
    }
  },
  {
    "entry_id": 154,
    "retraction_id": "1412.0982v2",
    "paper_id": "1412.0982v1",
    "retraction_comment": "This paper has been withdrawn by the authors. As pointed out to us by [REDACTED-NAME], [REDACTED-NAME] and [REDACTED-NAME], Theorem 3.1 is incorrect, namely, the zero locus should be larger than that in Theorem 3.1. We are sincerely grateful to them for their valuable comments. Nevertheless, the metrics we constructed have positive sectional curvature almost everywhere on the Gromoll-Meyer sphere and on the homotopy (not diffeomorphic) RP^7",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Failure to prove positive sectional curvature everywhere for the conformally deformed metric.",
        "Location": "Proof of Theorem 4.1, page 15",
        "Explanation": "The proof relies on showing that a lower bound for the sectional curvature, denoted as $K_t^+$, is strictly positive. At points where the original metric $\tilde{g}_r$ has zero sectional curvature (which occur on the focal submanifolds where $|F|=1$), the proof requires the term $t\\pi(|y_1|^2 + |y_2|^2)$ to be strictly positive for any zero-curvature plane. However, analysis of the horizontal space shows that there exist horizontal planes with zero $\tilde{g}_r$ curvature for which $|y_1|^2 + |y_2|^2 = 0$. For these planes, $K_t^+$ is zero, implying the conformally deformed metric $\tilde{g}_t^\\phi$ has zero sectional curvature, contradicting the claim of positive curvature everywhere."
      },
      {
        "Problem": "Incorrect identification of the set of zero sectional curvature planes for the base metric $\tilde{g}_r$.",
        "Location": "Proof of Theorem 3.1, pages 9-11",
        "Explanation": "The proof attempts to identify the set of points where the base metric $\tilde{g}_r$ has zero sectional curvature. It analyzes the condition for zero sectional curvature of the total space metric $g_r$ and then restricts to horizontal lifts whose Lie bracket is also horizontal. The correct condition for zero sectional curvature on the base space $\\Sigma^7$, according to the Gray-O'Neill formula, involves the vertical component of the Lie bracket of horizontal lifts. The analysis in the paper does not use this correct condition, leading to an incomplete or incorrect identification of the zero curvature planes for $\tilde{g}_r$."
      }
    ],
    "token_usage": {
      "input": 5284,
      "thinking": 22367,
      "output": 415
    }
  },
  {
    "entry_id": 155,
    "retraction_id": "1402.3490v2",
    "paper_id": "1402.3490v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error of the combination rule",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous Definition of Base Set and Elements",
        "Location": "Definition 1 (Page 7), Section 3",
        "Explanation": "The paper defines D numbers on subsets of a set Θ = {F1, ..., FN}, where F_i are presented as concepts or labels. However, the combination rule uses set intersection of these subsets, and examples involving overlapping concepts (like linguistic terms) imply that F_i should be subsets of an underlying universe, or that Θ is the universe itself and D numbers are defined on its subsets. This fundamental ambiguity makes the formal interpretation and application of D numbers problematic, especially when relaxing the exclusiveness hypothesis."
      },
      {
        "Problem": "Lack of Formal Analysis of Combination Rule Properties",
        "Location": "Definition 3 (Page 8), Section 3",
        "Explanation": "A new combination rule for D numbers is proposed, but the paper does not provide a formal analysis of its mathematical properties, such as associativity, commutativity, or its behavior under specific conditions like high conflict or total ignorance. Without such analysis, the soundness, reliability, and theoretical implications of the rule as a method for combining uncertain information cannot be fully assessed or compared to existing methods."
      },
      {
        "Problem": "Counter-intuitive Behavior of Combined Completeness Degree",
        "Location": "Definition 2 (Page 7), Definition 3 (Page 8), Example 2 (Page 12-13)",
        "Explanation": "The combination rule results in a combined D number whose sum of masses (defined as the completeness degree Q) is the product of the input completeness degrees (Q1 * Q2). Since Q1, Q2 ≤ 1, this implies that combining two incomplete information sources results in a combined representation that is generally more incomplete (Q1*Q2 ≤ min(Q1, Q2)). This behavior is counter-intuitive if Q represents the 'degree of information's completeness' and is not justified or explained in the paper."
      },
      {
        "Problem": "Inconsistency in Example 1 Application vs. Definition",
        "Location": "Definition 1 (Page 7), Example 1 (Page 9-10), Figure 2 (Page 10)",
        "Explanation": "Example 1 applies D numbers to linguistic variables 'High' and 'Medium', which are treated as sets whose intersection receives mass in the combined result. This application aligns with modeling overlapping concepts as sets. However, the formal definition of D numbers is on subsets of a set of *labels* {F1, ..., FN}, not on subsets of an underlying domain where linguistic terms are defined as sets. This inconsistency between the formal definition and its application in a key motivating example weakens the theory's foundation."
      },
      {
        "Problem": "Unsubstantiated Claim of Generalization and Enhanced Capability",
        "Location": "Abstract (Page 1), Introduction (Page 3), Conclusions (Page 16)",
        "Explanation": "The paper claims D numbers theory is a generalization of Dempster-Shafer theory and enhances its uncertainty modeling capability by relaxing the exclusiveness and completeness constraints. While these constraints are indeed relaxed, the paper lacks a rigorous formal proof of generalization and a comprehensive comparison with other existing methods (like DSmT) that also address DST's limitations. The claim of enhanced capability is not adequately supported by the provided analysis and simple examples."
      }
    ],
    "token_usage": {
      "input": 9670,
      "thinking": 13113,
      "output": 746
    }
  },
  {
    "entry_id": 156,
    "retraction_id": "1504.06694v3",
    "paper_id": "1504.06694v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a logical fallacy was made in transition from equation (46) to equations (47)-(50)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Identity",
        "Location": "Section 3, Equation (35)",
        "Explanation": "The paper claims that for n ≥ 8, 1+n! = 1 + 24 · (5)^(n-4). This identity is false. For example, when n=8, 1+8! = 40321, but 1 + 24 · 5^(8-4) = 1 + 24 · 5^4 = 15001. This fundamental error invalidates the entire argument in Section 3."
      },
      {
        "Problem": "Unjustified Assumption",
        "Location": "Section 3.1 and 3.2",
        "Explanation": "The argument relies on assuming that the variable r, which is related to m in the expressions (1+10r)^2 or (9+10r)^2, can be written as a polynomial in 5 with integer coefficients (r = ∑ a_k 5^k). This assumption is not justified and is critical for the subsequent coefficient comparison method."
      },
      {
        "Problem": "Flawed Coefficient Comparison",
        "Location": "Section 3.1, Equations (42-45); Section 3.2, Equations (47-50)",
        "Explanation": "The method of comparing coefficients of powers of 5 (or x) in the derived equations (e.g., Eq 41, 46) appears to contain errors. Specifically, the final equations (45 and 50) and the conclusion that a coefficient (a_{n-2}) must be irrational are based on incorrect coefficient extraction or calculation. The index used (n-2) is also inconsistent with the sum limit (n-4)."
      },
      {
        "Problem": "Incorrect Representation of Known Solution",
        "Location": "Section 2, Equations (7) and (18)",
        "Explanation": "The paper incorrectly states that 7! = (71+1)(70-1). The correct factorization related to 7!+1=71^2 is 7! = 71^2 - 1 = (71-1)(71+1) = 70 · 72. This factual error appears early in the paper when describing known solutions."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 8229,
      "output": 565
    }
  },
  {
    "entry_id": 157,
    "retraction_id": "1502.02090v5",
    "paper_id": "1502.02090v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 3.15",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect characterization of irreducible components of 2-forms on G2 manifolds.",
        "Location": "Page 5, Section 3.1",
        "Explanation": "The paper states that \\Lambda^7(M) = {\\alpha \\in \\Lambda^2(M) | \\alpha \\wedge \\phi = 2 * \\phi} and \\Lambda^{14}(M) = {\\alpha \\in \\Lambda^2(M) | \\alpha \\wedge \\phi = - * \\phi}. This is incorrect. The standard characterization is \\Lambda^7(M) = {\\alpha \\in \\Lambda^2(M) | \\alpha \\wedge \\phi = 0} and \\Lambda^{14}(M) = {\\alpha \\in \\Lambda^2(M) | *\\alpha \\wedge \\phi = 0}. This fundamental error invalidates the decomposition of the curvature and subsequent calculations."
      },
      {
        "Problem": "Incorrect formula for the Yang-Mills energy on G2 manifolds.",
        "Location": "Page 8, Section 3.2",
        "Explanation": "The paper claims ||F_A||^2 = 3||F_A^7||^2 - \\int_M tr(F_A^{14} \\wedge \\phi). On a G2 manifold, \\Lambda^2(M) decomposes orthogonally into \\Lambda^7(M) and \\Lambda^{14}(M). Thus, ||F_A||^2 = ||F_A^7||^2 + ||F_A^{14}||^2. The formula given in the paper is incorrect and is used in subsequent variational arguments."
      },
      {
        "Problem": "Incorrect second variation inequality for Yang-Mills energy.",
        "Location": "Page 3, Section 2 and Page 9, Section 3.6",
        "Explanation": "The second variation inequality for a Yang-Mills connection A being a minimum should be 0 \\le ||d_A\\psi||^2 + 2(F_A, \\psi \\wedge \\psi) for a variation by an ad(E)-valued 1-form \\psi. The paper uses 0 \\le ||d_A\\psi||^2 + (F_A, \\psi \\wedge \\psi) (missing a factor of 2). Furthermore, in the proof of Theorem 3.6, the inequality is incorrectly applied to the decomposed curvature and variation."
      },
      {
        "Problem": "Incorrect definition and properties of the form \\psi_A on Calabi-Yau manifolds.",
        "Location": "Page 11, Section 4",
        "Explanation": "The paper defines an ad(E)-valued (0,1) form \\psi_A such that \\Lambda_\\Omega(\\psi_A) = F_A^{0,2}, where \\Lambda_\\Omega is contraction with the (3,0) form \\Omega. Contracting a (0,1) form with a (3,0) form results in a form of type (3,-1), not a (0,2) form. The local expression given for \\psi_A is also dimensionally incorrect. This invalidates arguments relying on the properties of \\psi_A."
      },
      {
        "Problem": "Incorrect Kähler identity and derived energy formula on Calabi-Yau manifolds.",
        "Location": "Page 10, Section 4",
        "Explanation": "The stated Kähler identity \\omega \\wedge F_A = *(F_A^{2,0} + 2\\phi_A\\omega - F_A^{1,1} + F_A^{0,2}) appears incorrect. The derived energy formula 4||F_A^{0,2}||^2 + 9||\\phi_A||^2 - ||F_A||^2 = constant is also incorrect. These errors undermine the calculations and variational arguments in the Calabi-Yau section."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 11472,
      "output": 890
    }
  },
  {
    "entry_id": 158,
    "retraction_id": "1611.05964v2",
    "paper_id": "1611.05964v1",
    "retraction_comment": "Algorithm 1 is inefficient since line 2 is processed n 3 times need to be changed There are inconsistent notations throughout the manuscript [REDACTED-NAME] are not defined",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of Tensor Nuclear Norm",
        "Location": "Definition 8, Eq. 18, Page 4",
        "Explanation": "The definition of the generalized nuclear norm sums over 'j' up to min(n1, n2). The tensor nuclear norm based on t-SVD is typically defined as the sum of the nuclear norms of the frontal slices in the Fourier domain, which corresponds to summing the singular values of each frontal slice across all slices. The summation over 'j' is incorrect."
      },
      {
        "Problem": "Incorrect definition and application of Weighted Tensor Nuclear Norm",
        "Location": "Definition 9, Eq. 24, Eq. 33, Algorithm 2 step 8, Page 5-6",
        "Explanation": "Similar to the standard tensor nuclear norm definition, the weighted version includes an incorrect summation over 'j'. Furthermore, the weight tensor Wc is applied element-wise to the singular value tensor Σf (which should be diagonal in the Fourier domain), and the weight update formula (Eq. 36) is also element-wise. This is inconsistent with the standard approach of weighting singular values directly."
      },
      {
        "Problem": "Algorithm steps do not correctly solve the weighted nuclear norm proximal problem",
        "Location": "Algorithm 2, steps 6-10, Page 5",
        "Explanation": "The algorithm computes the t-SVD of Z, multiplies the singular value tensor by the weight tensor, reconstructs Z, and then applies unweighted SVT. This sequence does not correspond to the standard method for solving a weighted nuclear norm proximal problem, which involves applying weighted SVT directly to the input tensor (Z). The derivation of these steps from the IAL objective (Eq. 27) appears flawed."
      },
      {
        "Problem": "Inconsistent weight updating scheme",
        "Location": "Eq. 36, Page 6",
        "Explanation": "The weight Wc(i, j, k) is defined element-wise based on Σf(i, j, k). Since Σf is the singular value tensor in the Fourier domain (which should be diagonal), applying weights Wc(i, j, k) where i != j is problematic as Σf(i, j, k) should be zero for i != j. The weights should ideally be defined based on the singular values themselves (the diagonal elements of Σf), not element-wise on the entire tensor."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 2667,
      "output": 552
    }
  },
  {
    "entry_id": 159,
    "retraction_id": "2206.04913v2",
    "paper_id": "2206.04913v1",
    "retraction_comment": "I really apologize the audience for this withdrawal. The last section has some errors, because the proof of Lemma 4.2 is not true. Also other sections should be improved",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of proof for a key inductive inequality.",
        "Location": "Proposition 4.3, Part 2, Page 15",
        "Explanation": "Proposition 4.3 Part 2 provides an inductive inequality for the regularity of powers of a monomial ideal, which is subsequently used in Proposition 4.4 and Corollary 4.5 (the main upper bound result). However, no proof is provided for this part of the proposition."
      },
      {
        "Problem": "Incorrect short exact sequence used in a proof.",
        "Location": "Proposition 4.3, Part 1, Page 15",
        "Explanation": "The proof of Proposition 4.3 Part 1 relies on a short exact sequence 0 -> (Im-s(-d))^s -> Sum_{i=1}^s (Im-s+i(-d)) -> It -> 0. However, the sequence proven in Lemma 4.2 is 0 -> (Im-s(-d))^s -> Sum_{i=1}^s (Im-s+i(-d)) -> Im-s It -> 0. The final term is different (It vs Im-s It), invalidating the application of the regularity formula for short exact sequences."
      },
      {
        "Problem": "Flawed understanding of simplicial complex faces and degree calculation.",
        "Location": "Proof of Theorem 3.5, Page 10-11",
        "Explanation": "The proof of Theorem 3.5, which characterizes certain Betti numbers, assumes faces of the simplicial complex L^2(I) have specific forms (e.g., {S1, S1S2, ...} or {Se1Se1, ...}) which do not correctly represent sets of monomials labelling vertices of L^2(I). Furthermore, the calculation of the degree of the lcm of monomials labelling a face is inconsistent and appears incorrect based on the definition of degree using the Max(AB) vector. This undermines the entire proof of Theorem 3.5."
      },
      {
        "Problem": "Unsound derivation of lower bounds for Betti numbers and regularity.",
        "Location": "Theorem 3.7, Parts 1, 2, and 3, Page 12",
        "Explanation": "The proofs of all three parts of Theorem 3.7 rely on the flawed degree calculation and understanding of faces from the proof of Theorem 3.5. Specifically, the degree of the lcm of monomials corresponding to the constructed faces is calculated incorrectly (tj vs d(t-1)+j), leading to an incorrect identification of the Betti number index. This makes the derived lower bounds for Betti numbers and regularity unsound."
      },
      {
        "Problem": "Unclear and potentially flawed proof of a key lemma about minimal generators.",
        "Location": "Proof of Lemma 3.3, Page 9-10",
        "Explanation": "Lemma 3.3 claims that for a self semi-induced matching S={S1,...,Si}, the product of k monomials Su1...Suk is a minimal generator of Ik. The proof attempts to derive a contradiction using monomial division and the self semi-induced property. However, the step where monomial division (Sr | Suj1...Sujt) is used to imply vertex set containment (V(Sr) subset of Union V(Sujt)) and then contradict the self semi-induced property is not clearly justified and appears potentially flawed, as monomial divisibility does not always imply the required vertex set containment in this context. This lemma is used in the proof of Theorem 3.7."
      }
    ],
    "token_usage": {
      "input": 4768,
      "thinking": 10155,
      "output": 794
    }
  },
  {
    "entry_id": 160,
    "retraction_id": "1705.06716v2",
    "paper_id": "1705.06716v1",
    "retraction_comment": "This study needs many major modifications. Majority of the study includes mistakes. For example, all the plots and the numbers that are generated using ALPGEN MC generator in the tables are not correct. In addition, the selected factorization and renormalization scales do not define the correct form of the interaction. Even the title of the study must be changed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unquantified theoretical uncertainty for W/Z+jets predictions.",
        "Location": "Section 3, Tables 9 and 10, Conclusion",
        "Explanation": "The paper presents W/Z+jets cross section predictions up to 6 jets at 14 TeV using only a Leading Order (LO) Monte Carlo generator (Alpgen) with a LO PDF (CTEQ6L1). Theoretical uncertainties from scale dependence, PDF choice, and matching/merging are known to be large for multi-jet LO calculations but are not quantified or discussed. Presenting only statistical errors from the generator is insufficient for a reliable theoretical prediction."
      },
      {
        "Problem": "Significant discrepancies between Alpgen LO predictions and ATLAS data for W/Z+jets validation.",
        "Location": "Section 3, Tables 7 and 8",
        "Explanation": "The validation of the Alpgen predictions against ATLAS experimental data shows notable discrepancies, particularly for W+jets and Z+jets with higher jet multiplicities (>=3 jets). The differences are often larger than the statistical errors and sometimes comparable to or exceeding the systematic errors reported by ATLAS. Claiming good agreement based on these comparisons is debatable and weakens the justification for using Alpgen LO for predictions at 14 TeV."
      },
      {
        "Problem": "Non-standard and empirically tuned renormalization and factorization scales for W/Z+jets.",
        "Location": "Section 3, page 6",
        "Explanation": "The renormalization and factorization scales for W/Z+jets are chosen as sqrt(m^2 + (pT_jet)^2) scaled by factors of 2 (W+jets) or 4 (Z+jets). The paper explicitly states these factors were chosen 'to be consistent with ATLAS results'. This suggests tuning the scales to match existing data rather than using a theoretically motivated approach. The impact of varying these non-standard scales to estimate theoretical uncertainty is not assessed, which is a standard practice."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 3943,
      "output": 437
    }
  },
  {
    "entry_id": 161,
    "retraction_id": "1604.05964v2",
    "paper_id": "1604.05964v1",
    "retraction_comment": "equation no. 16 17 and 18 have flaws, result of which final outage derivation is not converging",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of a single secondary interferer for primary outage analysis.",
        "Location": "Section III.A, Equations (6), (11), (13)",
        "Explanation": "The primary outage analysis assumes interference from only one secondary BS (Ione,Si). While the secondary resource allocation aims to assign unique RBs from the unoccupied set, under imperfect detection (misdetection), multiple secondary BSs could potentially use the same RB and interfere with a primary user. The assumption of a single secondary interferer is not justified by the system model description under imperfect detection and is likely incorrect for a PPP distribution of secondary BSs, invalidating the primary outage analysis."
      },
      {
        "Problem": "Assumption of a single primary interferer for secondary outage analysis.",
        "Location": "Section III.B, Equation (19)",
        "Explanation": "The secondary outage analysis assumes interference from only one primary BS (Ione,P). Under imperfect detection by secondary users, multiple primary BSs could potentially be misdetected and interfere with a secondary user using the same RB. The assumption of a single primary interferer is not justified by the system model description under imperfect detection and is likely incorrect for a PPP distribution of primary BSs, invalidating the secondary outage analysis."
      },
      {
        "Problem": "Disconnect between sensing/allocation strategy and interference model.",
        "Location": "Section II, Section III",
        "Explanation": "The paper describes a detailed sensing strategy (hard decisions, majority rule) and resource allocation mechanism (cloud distributing unique RBs from unoccupied set) for secondary users. However, the stochastic geometry outage analysis in Section III uses simplified interference models (assuming a single interferer of each type under imperfect detection) that do not appear to be rigorously derived from the probabilistic outcomes of the described sensing and allocation processes under imperfect detection. The link between the system's operational details and the probabilistic interference model used in the analysis is weak, casting doubt on the validity of the analytical results."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 3716,
      "output": 434
    }
  },
  {
    "entry_id": 162,
    "retraction_id": "1010.6286v5",
    "paper_id": "1010.6286v4",
    "retraction_comment": "This paper has been withdrawn by the author due to the map described in Thorem 2.4 is not injective",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Initial map is not a homomorphism",
        "Location": "Proof of Theorem 2.4, page 5",
        "Explanation": "The proof defines an initial map Ψ: Ar → Bl by sending generators gi of Ar to ψ_{2i-1} = σ_{2i-1}^2 in Bl. If Ar is not free abelian, there exist generators gi and gj that do not commute in Ar (i.e., {i,j} is an edge in Γ). However, for i ≠ j, the elements σ_{2i-1}^2 and σ_{2j-1}^2 commute in Bl (and PB_l) because the indices 2i-1 and 2j-1 differ by at least 2. Thus, Ψ maps non-commuting elements to commuting elements, which means Ψ is not a homomorphism unless Ar is free abelian."
      },
      {
        "Problem": "Claim about commuting subgroups is false",
        "Location": "Proof of Theorem 2.4, page 5",
        "Explanation": "The proof claims that in PB_{k+3}, the subgroups Ψ(Ar) and F2 = (ψ_{k+2}, ψ_{k+3}) admit a Cartesian product, meaning every element in Ψ(Ar) commutes with every element in F2. Ψ(Ar) is generated by {σ_{2i-1}^2 | i ∈ V(Γ)} and F2 is generated by {σ_{k+2}^2, σ_{k+3}^2}. For these subgroups to commute element-wise, [σ_a^2, σ_b^2] must be 1 for all generators σ_a^2 from Ψ(Ar) and σ_b^2 from F2. By Theorem 1.1, [σ_a^2, σ_b^2] = 1 if and only if [σ_a, σ_b] = 1, which in B_l means |a-b| ≥ 2. With k = 2|Γ|-1, the indices for Ψ(Ar) are {1, 3, ..., 2|Γ|-1} and for F2 are {2|Γ|+1, 2|Γ|+2}. The difference between the largest index in Ψ(Ar) (2|Γ|-1) and the smallest index in F2 (2|Γ|+1) is 2. Thus, σ_{2|Γ|-1} and σ_{2|Γ|+1} do not commute in B_l, and by Theorem 1.1, σ_{2|Γ|-1}^2 and σ_{2|Γ|+1}^2 do not commute. Therefore, Ψ(Ar) and F2 do not commute, and they do not admit a Cartesian product."
      },
      {
        "Problem": "Definition and properties of 'Couple product' are unclear and likely incorrect",
        "Location": "Definition 2.2 (page 3) and Proposition 2.3 (page 4)",
        "Explanation": "The definition of the 'couple product' is difficult to understand and appears inconsistent with standard group theoretic constructions. The notation and description of the generators for the couple product are ambiguous. Furthermore, the properties listed in Proposition 2.3, particularly the claim that G x Fk coupled along generators is isomorphic to Fk (Proposition 2.3 (4)), seem incorrect based on plausible interpretations of the definition. The proof of the main theorem relies heavily on this ill-defined and potentially incorrect construction and its properties, rendering the proof unsound."
      },
      {
        "Problem": "Calculation of required number of strands is inconsistent",
        "Location": "Proof of Theorem 2.4, page 5",
        "Explanation": "The proof describes an iterative process where for each edge in E(Γ), the images of the incident vertices are modified using two new generators (ψ_{k+2}, ψ_{k+3}). This modification step, applied |E(Γ)| times, would add 2|E(Γ)| to the initial number of generators (2|Γ|-1), resulting in a total of 2|Γ|-1 + 2|E(Γ)| generators, requiring n = 2|Γ| + 2|E(Γ)| strands. The proof's claim that 'three more generators for each edge' are required, leading to a total of 2|Γ| + 3|E(Γ)| - 1 generators and n ≥ 2|Γ| + 3|E(Γ)| strands, is inconsistent with the described construction step using only two new generators per edge modification."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 7821,
      "output": 1013
    }
  },
  {
    "entry_id": 163,
    "retraction_id": "0811.2430v4",
    "paper_id": "0811.2430v3",
    "retraction_comment": "The author revised the article and considers that the proof is not rigorous. The main counter-argument is that one should not draw conclusions from a truncated wave-function",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The total state of the two particles is incorrectly formulated as a difference of two components.",
        "Location": "Eq (1), Page 2",
        "Explanation": "The state |ψ> is given as 2⁻¹/² (|ψ₂> − |ψ₁,₁>), where |ψ₂> describes particles detected in the same region and |ψ₁,₁> describes particles detected in different regions. Based on the definitions in (2) and (3) and the experimental setup, the total state resulting from the beam splitters should be a superposition (sum) of these components, not a difference. This fundamental error propagates through the subsequent calculations."
      },
      {
        "Problem": "The symmetry analysis of the state component |ψ₂> is incorrect.",
        "Location": "Eq (5) and surrounding text, Page 2",
        "Explanation": "The author claims that the second line of Eq (5) is antisymmetric under the interchange of particles (interpreted as swapping the L and R source labels). However, performing the L↔R label swap on the terms in the second line shows that it does not result in the negative of the original expression. This indicates a misunderstanding of how particle exchange symmetry applies in this notation."
      },
      {
        "Problem": "The derivation and normalization of the symmetric and antisymmetric components of |ψ₁,₁> are flawed.",
        "Location": "Eq (8) and (9), Page 3",
        "Explanation": "Equations (8) and (9) are presented as the symmetric and antisymmetric parts of |ψ₁,₁> (Eq 6). However, attempting to derive (8) and (9) by applying standard symmetrization/antisymmetrization procedures to (6) reveals errors in both the normalization factor (stated as 1/4 instead of 1/4√2) and the coefficients of several terms. This makes the subsequent probability calculations unreliable, even if the final results (10) and (11) happen to match a specific interpretation."
      },
      {
        "Problem": "The interpretation of the state component |ψ₁,₁> as representing particles that 'never meet' is problematic and leads to a questionable conclusion about non-local symmetry.",
        "Location": "Section 3 (Discussion), Page 4",
        "Explanation": "The paper argues that the symmetry of |ψ₁,₁> is particularly interesting because it describes particles detected in different regions (V and E) that 'never meet'. However, |ψ₁,₁> is merely a component of the total state arising from interference at the final beam splitters (BSᵥ and BS_E), which are locations where particles from different initial paths (A/A' and B/B') converge and could interact/interfere. The symmetry postulate applies to the total state of identical particles, not selectively to components defined by measurement outcomes or specific path combinations after interaction points."
      },
      {
        "Problem": "The conclusion that symmetry (antisymmetry) is produced 'at-a-distance' is based on flawed premises.",
        "Location": "Section 3 (Discussion), Page 4",
        "Explanation": "The main conclusion relies on the idea that the symmetry of |ψ₁,₁> demonstrates a non-local effect because these particles 'never meet'. As discussed in Problem 4, the 'never meet' argument is weak in the context of interference at beam splitters. Furthermore, the symmetry is a property of the overall state of identical particles, not something that is 'produced' for a specific subset of outcomes (|ψ₁,₁>) independently of others (|ψ₂>). The conclusion is built upon the incorrect state formulation and interpretation."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 20179,
      "output": 797
    }
  },
  {
    "entry_id": 164,
    "retraction_id": "2201.05255v2",
    "paper_id": "2201.05255v1",
    "retraction_comment": "Our definition of the higher Toda brackets is not effective, i.e. not well defined, in the category of pointed spaces",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous Inductive Definition Notation",
        "Location": "Page 1-2, Definition of {f}m for n >= 4",
        "Explanation": "The notation used for the inductive step (n >= 4) is ambiguous. The expression {fn,..., f4, [f3, A2, ∑m3 f2], (∑m3 f2, ∑m3 A1, ∑m[3,2] f1)}(mn,...,m4,0,0) inside the union U_A is denoted using the bracket notation, which typically implies the standard inductive definition of a bracket for the sequence of maps provided. If interpreted as the standard inductive definition, the overall definition of {f}m becomes a nested union structure (a union over A of a union over admissible sequences for the inner maps). The notation on page 1-2 does not show this nesting, suggesting a potential misstatement of the definition or the use of non-standard notation for the inner term without explicit definition, which makes the precise definition unclear and subsequent proofs difficult to verify."
      },
      {
        "Problem": "Flawed Proof of Lemma 2.3(1)",
        "Location": "Page 8, Proof of Lemma 2.3(1) for n >= 4",
        "Explanation": "The proof attempts to show that if {f_n, ..., f1}m is non-empty, then {f_{n-1}, ..., f1}m is non-empty, using induction on n. Assuming the standard nested inductive definition of the bracket, the proof for n >= 4 incorrectly applies the inductive hypothesis. It applies the hypothesis (which is about a bracket of length n) to an inner bracket of length n-1, and draws a conclusion about a bracket of length n-2, which is not the required {f_{n-1}, ..., f1}m. This invalidates the proof of Lemma 2.3(1) for n >= 4."
      },
      {
        "Problem": "Flawed Proof of Lemma 2.3(2)",
        "Location": "Page 8, Proof of Lemma 2.3(2)",
        "Explanation": "The proof states that the conclusion (non-emptiness implies containing 0 for shorter sequences) follows from Lemma 2.3(1). However, Lemma 2.3(1) only claims non-emptiness of a bracket, not that it contains the zero element. This misinterpretation of Lemma 2.3(1) invalidates the proof of Lemma 2.3(2)."
      },
      {
        "Problem": "Flawed Proof of Proposition A.3",
        "Location": "Page 35, Proof of Proposition A.3 for n >= 4",
        "Explanation": "The proof attempts to show {g'} o Sigma^{n-2} b1 = bn+1 o {g} using induction on n. Assuming the standard nested inductive definition of the bracket, the proof for n >= 4 incorrectly applies the inductive hypothesis. It applies the hypothesis (which is about a bracket of length n) to an inner bracket of length n-1. This invalidates the proof of Proposition A.3 for n >= 4."
      },
      {
        "Problem": "Unsoundness of Theorem 1.4",
        "Location": "Page 29, Theorem 1.4; Page 30, Proof of Lemma 10.2; Page 35, Proof of Proposition A.3",
        "Explanation": "Theorem 1.4, which defines and relates unstable and stable brackets, relies on Lemma 10.2. The proof of Lemma 10.2 relies on Proposition A.3. Since the proof of Proposition A.3 is flawed (Problem 4), the proof of Lemma 10.2 and consequently Theorem 1.4 are unsound."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 12110,
      "output": 858
    }
  },
  {
    "entry_id": 165,
    "retraction_id": "1601.01217v3",
    "paper_id": "1601.01217v2",
    "retraction_comment": "There is an important mistake in the definition of the global smoothing operator preserving the presymplectic form",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the combined flow of non-commuting vector fields used in the construction of the global smoothing operator.",
        "Location": "Section 6.3, Equation (6.38)",
        "Explanation": "The formula provided for the components of the combined flow \\Phi_x(v) = \\varphi_{v_n}^{Z_n} \\circ \\dots \\circ \\varphi_{v_1}^{Z_1}(x) appears to assume that the vector fields Z_k commute. However, the paper states that pairs (Z_i, Z_{q+i}) do not commute. The composition of flows of non-commuting vector fields is generally not given by such a simple component-wise formula. This potential error in the definition of \\Phi_x invalidates subsequent results that rely on this formula, including the proof that \\Phi_x is a diffeomorphism with the given inverse and, crucially, the proof that the global smoothing operator preserves the presymplectic property (Proposition 6.17), which is essential for the global rigidity theorem."
      },
      {
        "Problem": "The SCI/CI group structure and action properties for the subgroup of diffeomorphisms preserving the presymplectic form are not fully justified.",
        "Location": "Section 4.3 (proof outline), Section 7.2.1",
        "Explanation": "The abstract normal form theorem requires the group acting on the space of structures (diffeomorphisms acting on presymplectic actions) to be of SCI/CI type at the identity and its action to be of SCI/CI type, satisfying specific tameness estimates. The paper uses the subgroup of diffeomorphisms preserving the presymplectic form (G0). While the full group of diffeomorphisms is discussed as CI-type, it is not explicitly shown that this specific subgroup G0 satisfies all the necessary SCI/CI group and action properties, including the crucial tameness estimates required by the abstract theorem (7.11/7.23), for its action on the space of presymplectic actions (S)."
      },
      {
        "Problem": "The tameness estimates for the map from presymplectic vector fields to their time-1 flow are not fully derived within the paper.",
        "Location": "Page 10, Page 11, Equations (7.10), (7.22)",
        "Explanation": "The abstract normal form theorem requires the map \\Phi (defined as the time-1 flow map) to satisfy specific tameness estimates (7.10/7.22). The paper refers to an external reference ([27], Lemma B.3) for these estimates. While such estimates are generally expected for flow maps, relying on an external lemma from a slightly different context (Poisson manifolds) without providing a proof or detailed justification within the paper could be considered a gap, especially given the specific SCI/CI norms and spaces used here."
      },
      {
        "Problem": "The degree of the polynomial in the quadratic convergence estimate might not satisfy the requirements of the abstract normal form theorem.",
        "Location": "Lemma 5.8, Equations (5.18), (7.12), (7.24)",
        "Explanation": "The abstract normal form theorem requires the polynomial Q in the quadratic convergence estimate (7.12/7.24) to have a degree in its first variable that is independent of the smoothness parameter k. Lemma 5.8 provides a polynomial Pk for the corresponding estimate (5.18). It is not explicitly stated or proven that the degree of Pk is independent of k. This independence is a crucial condition for guaranteeing the convergence of the Nash-Moser iteration in the abstract theorem."
      }
    ],
    "token_usage": {
      "input": 10702,
      "thinking": 14445,
      "output": 804
    }
  },
  {
    "entry_id": 166,
    "retraction_id": "1412.3838v2",
    "paper_id": "1412.3838v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the statement according to which the volume element does not depend on the choice of the time orientation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Dependence of the volume element on time orientation",
        "Location": "Definition 5 (Eq. 20), page 11; Claims on pages 2, 11, 12",
        "Explanation": "The volume element is defined by an integral over a domain claimed to be the Euclidean unit ball B_n, based on the assertion that the unit ball of the constructed metric g^{t,+} is B_n. This assertion is incorrect; the unit ball of g^{t,+} is an ellipsoid that depends on the chosen time orientation vector field t. Consequently, the domain of integration and the resulting volume element depend on t, contradicting the paper's claim of independence from time orientation."
      },
      {
        "Problem": "Potential ill-definedness of the integral due to singularity of the integrand",
        "Location": "Definition 5 (Eq. 20), page 11; Definition of Finsler spacetime, page 8",
        "Explanation": "The integral defining the volume element involves the determinant of the Finsler metric tensor, |g(x,y)|, integrated over a domain (the unit ball of g^{t,+}) that includes the origin y=0. For a general Finsler spacetime, g_ij(x,y) is typically only defined and smooth for y != 0 and can be singular or undefined at y=0 or on lightlike directions. Integrating a potentially singular function over a domain including the singularity makes the integral ill-defined or potentially infinite, unless specific properties of |g(x,y)| ensure integrability, which is not generally guaranteed."
      },
      {
        "Problem": "Incorrect calculation and contradiction in the example",
        "Location": "Section 5, page 13",
        "Explanation": "The calculation of the metric g^{t,+} for the Berwald-Moor example is incorrect. The resulting matrix is singular, contradicting Proposition 4 which claims g^{t,+} is positive definite. This error invalidates the example calculation and casts significant doubt on the general validity of Proposition 4 and the construction that relies on g^{t,+} being positive definite."
      },
      {
        "Problem": "Unjustified claim about the unit ball of g^{t,+}",
        "Location": "Page 11, point 2) below Eq. 19",
        "Explanation": "The paper claims that the unit balls of all metrics g^{t,+} are identical and are the Euclidean unit ball B_n. This is incorrect. The unit ball of g^{t,+} is an ellipsoid defined by the matrix G^{t,+}_{ij}(x) = 2 g^t_{ik}(x) t^k(x) g^t_{jl}(x) t^l(x) - g^t_{ij}(x), which depends on t(x). This false claim is crucial for arguing the independence of the volume element from t and for specifying the domain of integration as B_n."
      },
      {
        "Problem": "Reliance on continuous extension of the metric determinant",
        "Location": "Page 9, first paragraph; Remark 2, page 12",
        "Explanation": "The construction assumes that the determinant g = det(g_ij) can be constructed by continuous extension to points where g_ij is not defined (e.g., y=0 or lightlike directions). While this might hold for specific cases, it is not generally guaranteed for a Finsler spacetime and is problematic for the integral definition of the volume element, which integrates |g(x,y)| over a domain including such points."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 9899,
      "output": 797
    }
  },
  {
    "entry_id": 167,
    "retraction_id": "1301.0396v3",
    "paper_id": "1301.0396v2",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in Lemma 2.9",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof that the constructed semifilter S is not comeagre (equivalently, not ultra by finite-to-one).",
        "Location": "Lemma 4.2, Proof, second and third paragraphs",
        "Explanation": "The paper claims S is not comeagre and not ultra by finite-to-one. By a referenced result (Talagrand [36] via [23, Th. 4.1]), these two properties are equivalent for a semifilter. The paper attempts to prove 'S is not ultra by finite-to-one' by showing 'S is not nearly coherent with E'. It states these are equivalent, but this equivalence is not standard and is not justified. The argument presented actually proves 'S is not nearly coherent with E', which is not the required conclusion for the negation of SFT."
      },
      {
        "Problem": "Insufficient justification for the filter U_beta generated by the 'good sequence' being an ultrafilter.",
        "Location": "Lemma 4.3, Proof, Case (c), first paragraph after the case heading",
        "Explanation": "The paper claims that the 'centred system U_beta generated by the good sequence is a stable ordered-union ultrafilter' as a consequence of the sequence having lower bounds and the Hindman tasks. While the Hindman tasks are related to filter properties, they do not automatically guarantee that the generated filter is maximal (an ultrafilter). Proving that a filter generated by a sequence is an ultrafilter typically requires a diagonalisation argument showing that for any set, either the set or its complement is in the filter. This crucial step, necessary for defining Q_beta = M(U_beta) based on an ultrafilter, is not sufficiently detailed or justified."
      },
      {
        "Problem": "Unclear connection between iteration properties (I2) and (I3) and the conclusion that the Filter Dichotomy Principle (FD) holds in the final model.",
        "Location": "Lemma 4.2, Proof, first paragraph",
        "Explanation": "The paper states that 'The filter dichotomy holds because of (12) and (13)'. Property (I2) states that a specific filter cl(E) is ultra. Property (I3) relates non-meagre filters to cl(E) via the function g_beta. While these properties are likely designed to imply u < g_f (which is equivalent to FD), the proof does not explicitly show how they lead to the conclusion that *every* non-meagre filter in the final model is ultra by finite-to-one. This step requires demonstrating that the cardinal characteristic g_f is strictly greater than u in the final model, which is not explicitly shown or linked to (I2) and (I3) in the proof of Lemma 4.2."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 6683,
      "output": 620
    }
  },
  {
    "entry_id": 168,
    "retraction_id": "1808.04792v3",
    "paper_id": "1808.04792v2",
    "retraction_comment": "The velocities in the radiative transfer analysis for each snapshot of the simulated collapsing core are a factor of 1.732 (the square root of 3) smaller along each of the three dimensions. This error is currently being rectified",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of Turbulence in the Simulation",
        "Location": "Abstract, Section 2.1",
        "Explanation": "The numerical simulation explicitly excludes turbulence, which is considered a fundamental component in the formation and dynamics of molecular cloud cores within the prevalent 'gravoturbulent' paradigm. This idealization may result in density and velocity structures that are not representative of real cores, potentially limiting the applicability of the synthetic observations and the conclusions drawn about interpreting observed infall signatures."
      },
      {
        "Problem": "Assumption of Constant Molecular Abundances",
        "Location": "Section 2.3",
        "Explanation": "The paper assumes constant relative abundances for the modeled molecular species (HCO+ and N2H+). In reality, molecular abundances, especially in dense, cold core interiors, are known to vary significantly due to processes like freeze-out onto dust grains. This spatial variation in abundance directly impacts the distribution of the gas that emits and absorbs radiation, which is crucial for shaping the observed line profiles and determining how different velocities are weighted, potentially leading to inaccurate synthetic spectra and flawed interpretations."
      },
      {
        "Problem": "Isothermal Assumption for the Gas",
        "Location": "Section 2.1",
        "Explanation": "The simulation assumes the gas is isothermal. Real collapsing cores are not perfectly isothermal; they develop temperature gradients due to compression and potentially protostellar heating. Temperature affects the excitation state of molecules, which is a key factor in radiative transfer calculations. Assuming a constant temperature may introduce inaccuracies in the synthetic line profiles, particularly for transitions sensitive to temperature variations."
      },
      {
        "Problem": "Highly Idealized Initial Conditions and Spherical Symmetry",
        "Location": "Section 2.1",
        "Explanation": "The simulation starts from a smooth, spherically symmetric density perturbation in a uniform background, initially at rest. Real molecular cloud cores form from complex, turbulent flows and are often non-spherical with potentially non-zero initial velocity fields. This high degree of idealization may lead to a specific 'outside-in' velocity profile that is not universally representative of all observed cores, potentially limiting the generality of the paper's conclusions regarding the interpretation of infall signatures."
      },
      {
        "Problem": "Finite Simulation Box Size and Periodic Boundary Conditions",
        "Location": "Section 2.1, Section 5.2.1",
        "Explanation": "The simulation is performed in a finite box with periodic boundary conditions. The paper acknowledges that the decrease in infall speed towards the box edge is an artifact of these conditions. While argued to mimic large-scale simulations, the finite size and boundary conditions can influence the flow structure, particularly near the edge of the simulated region where the highest infall speeds occur in the model, potentially affecting the accuracy of the synthetic spectra and their interpretation."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 3505,
      "output": 613
    }
  },
  {
    "entry_id": 169,
    "retraction_id": "1306.2988v2",
    "paper_id": "1306.2988v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The result claiming a factor 0.56 algorithm is invalid because of a crucial bug in Claim 2 which was brought to our attention by [REDACTED-NAME], [REDACTED-NAME], and [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsoundness in Lemma 3 proof sketch",
        "Location": "Page 6, Lemma 3 proof sketch",
        "Explanation": "The proof claims that the total number of non-monotone events $\\sum_{s,p} \\Gamma(s,t,p)$ is at most $|\\Omega_V|(1-x_t)$, the number of permutations where $p(t)$ is unmatched. However, for each such permutation, translating $p(t)$ to *each* of the $n$ positions $s$ can potentially generate a non-monotone event. Thus, the total number of non-monotone events could be up to $n \\times |\\Omega_V|(1-x_t)$, making the inequality $n(1-x_t) \\le \\sum_{s<t} x_s + \\sum_{s<t, p} \\Gamma(s,t,p)/|\\Omega_V|$ (Lemma 8) and the LP constraint derived from Lemma 3 potentially incorrect."
      },
      {
        "Problem": "Unsoundness in Lemma 7 proof sketch and supporting claims",
        "Location": "Page 7-8, Lemma 7 proof sketch and Appendix page 15 (Claims 2, 3)",
        "Explanation": "Lemma 7 is a pivotal technical lemma relating non-monotone events and good-events, crucial for the LP. Its proof sketch relies on Claims 2 and 3. The proof of Claim 2 (w is matched in Shuffle(p'[w* -> s]) for all s) seems insufficient, only showing an option is available. The proof of Claim 3 (w* is matched for s < t) relies on an argument about vertex consideration order that appears inconsistent with the SHUFFLE algorithm's rank-based processing. If these claims or the overall mapping in Lemma 7 are incorrect, the LP constraint derived from it is unsound."
      },
      {
        "Problem": "Unsoundness in Lemma 8 proof sketch",
        "Location": "Page 9, Lemma 8 proof sketch",
        "Explanation": "Lemma 8 relates unmatched probability to matched probability and non-monotone events, used in the LP. The proof sketch uses a mapping from a single miss event for $p(t)$ in Shuffle(p) to $n$ potential events (match above t or non-monotone at s) by considering Shuffle($p[u \\to s]$) for all $s$. The claim that \"the set of events generated for distinct miss events are disjoint\" is not justified and appears unlikely, as different initial permutations could lead to overlapping sets of $n$ generated events. This mapping and disjointness assumption are critical for the inequality $n(1-x_t) \\le \\sum_{s<t} x_s + \\sum_{s<t, p} \\Gamma(s,t,p)/|\\Omega_V|$ to hold."
      },
      {
        "Problem": "Incorrect statement and proof of Lemma 10",
        "Location": "Page 10, Lemma 10 statement and Appendix page 15-18, Proof of Lemma 10",
        "Explanation": "Lemma 10 claims LP-OPT(k) < LP-OPT(n) for k dividing n, used to justify that LP values for small n lower bound the factor for large n. The proof constructs a feasible solution $\\hat{s}^k$ for LP(k) from an optimal solution $s^n$ for LP(n). However, the proof shows that the objective value of $\\hat{s}^k$ is $ALG^n/q = LP-OPT(n)/(n/k) = (k/n) LP-OPT(n)$. Thus, LP-OPT(k) $\\le (k/n) LP-OPT(n)$. This inequality is weaker than LP-OPT(k) < LP-OPT(n) and does not support the claim that LP values for small k lower bound the factor for large n in the way the paper implies (e.g., using Table 1 for n=400 to bound performance for any n)."
      },
      {
        "Problem": "Unsoundness in the proof of the 0.75 upper bound for VI algorithms",
        "Location": "Page 20-21, Proof of Theorem 14 and Lemma 19 (Claims 11, 13)",
        "Explanation": "The proof relies on analyzing the Random-Reveal (RR) algorithm on a specific graph distribution I. Lemma 19's proof relies on Claim 11, which states that the number of active vertices in C equals the number in P at any stage, implying Pr[v in C] = Pr[v in P] = 0.5 for a randomly chosen active vertex v. This invariant is not maintained by the RR algorithm's matching process (e.g., matching v in C to a neighbor in C removes two C vertices). The subsequent calculation of expected matched and inactive vertices in Claim 13 is based on this incorrect 0.5 probability and uses unclear accounting, rendering the final 0.75 bound derived from this analysis unsound."
      }
    ],
    "token_usage": {
      "input": 5542,
      "thinking": 6749,
      "output": 1151
    }
  },
  {
    "entry_id": 170,
    "retraction_id": "1901.07086v3",
    "paper_id": "1901.07086v2",
    "retraction_comment": "The claim of Main Theorem 1 is wrong. The prime counting function on the complex plan does not satisfy the inequality. The prime number Theorem contradicts the claim",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misapplication of Real Prime Distribution Theorem",
        "Location": "Page 6, Proof of Main Theorem 1, Case (I)",
        "Explanation": "The proof attempts to apply Proposition 2 (Generalization of Bertrand's Postulate for real primes) to the distribution of Gaussian primes on a complex segment. It maps integer lattice points on the segment to the real line by taking their modulus (or squared modulus) and assumes that the distribution of these moduli allows for the direct application of a theorem about primes in a real interval. This mapping does not preserve the necessary structure, and the set of moduli of lattice points on a segment is a discrete set, not a continuous interval of integers or primes."
      },
      {
        "Problem": "Incorrect Inequality for Moduli of Lattice Points",
        "Location": "Page 5, Inequality (3.2)",
        "Explanation": "The statement claims that for every integer lattice point (l1, l2) lying on the segment between (a,b) and (c,d), its squared modulus (l1^2 + l2^2) must lie strictly between the squared moduli of the endpoints (a^2+b^2 < l1^2+l2^2 < c^2+d^2). This is false. Points on a line segment do not necessarily have moduli that are monotonically increasing or decreasing along the segment, nor must they lie within the annulus defined by the endpoint moduli."
      },
      {
        "Problem": "Incorrect Characterization of Gaussian Primes on Axes",
        "Location": "Page 6, Proof of Main Theorem 1, Case (II)",
        "Explanation": "In Case (II), considering Gaussian integers on the imaginary axis (z=iz2), the proof states it is proving the result for Gaussian primes of the form congruent to 3 (mod 4). However, Gaussian primes on the imaginary axis are of the form 'ip' where 'p' is a real prime congruent to 1 (mod 4), or 'i'. The subsequent argument applying Chebyshev Bias for primes congruent to 3 (mod 4) contradicts the definition of Gaussian primes on the imaginary axis."
      },
      {
        "Problem": "Flawed Geometric Interpretation and Figure",
        "Location": "Page 5, Figure 1 and associated text",
        "Explanation": "Figure 1 and the surrounding text contain confusing and mathematically incorrect labels and descriptions related to the 'gap' and the moduli of points. For example, the label '(a^2+c^2)-(b^2+d^2)' is nonsensical in this context, and the figure reinforces the incorrect idea that points on the segment are directly related to distances or moduli in a simple way that supports the flawed application of real prime theorems."
      },
      {
        "Problem": "Unjustified Application of Chebyshev Bias",
        "Location": "Page 6, Proof of Main Theorem 1, Case (I) and (II)",
        "Explanation": "The proof divides the expected number of primes by 2 based on Chebyshev Bias to claim a minimum number of Gaussian primes of a specific form (1 mod 4 or 3 mod 4). While Chebyshev Bias describes an asymptotic tendency for real primes, its direct application to guarantee a minimum number of Gaussian primes of a certain type on a complex segment is not rigorously justified by the arguments presented."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 4387,
      "output": 737
    }
  },
  {
    "entry_id": 171,
    "retraction_id": "2204.01118v2",
    "paper_id": "2204.01118v1",
    "retraction_comment": "In the proof of Theorem 5, page 10, line 1O, a term was missing in the r.h.s, that is \\|f''\\|_p^p",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect necessary and sufficient condition for a function to act on Lp(R^n) for p > 1.",
        "Location": "Page 3, Proposition 1",
        "Explanation": "The paper states that f acts on Lp(R^n) iff |f(t)| <= c|t|. This is incorrect for p > 1. The correct condition for p > 1 is typically |f(t)| <= C(|t| + |t|^p) (or |f(t)| <= C|t|^p for large |t| and |f(t)| <= C|t| for small |t| if f(0)=0). The proof sketch only demonstrates that if |f(t)| grows faster than |t| for large |t|, f does not act on Lp, which is insufficient to prove the stated equivalence."
      },
      {
        "Problem": "Flawed proof of continuity of composition operators on Lp spaces.",
        "Location": "Page 5, Proposition 4 and Page 16, Proposition 10",
        "Explanation": "The proof sketch for the sufficiency part of Proposition 4 (Tf continuous if f continuous) refers to Proposition 10 in the Appendix. The proof of Proposition 10 relies on the growth condition |f(t)| <= c|t|. As noted in the problem with Proposition 1, this condition is incorrect and insufficient for f to act on Lp for p > 1. Consequently, the proof of continuity based on this condition is invalid for p > 1."
      },
      {
        "Problem": "Contradictory application of a lemma in the proof characterizing polynomial composition operators.",
        "Location": "Page 7, Proof of Proposition 9",
        "Explanation": "The proof uses Lemma 1, which states that g(x) = |x|^\\lambda \\phi(x) is in Wm(R^n) iff \\lambda > m - n/p (under certain conditions). To obtain a contradiction, the proof constructs g such that g is in Wm but f o g is not. The chosen range for \\lambda is m - n/p < \\lambda < 1/k. The proof then claims that f o g, which behaves like |x|^{k\\lambda} near 0, is not in Wm by applying Lemma 1, which requires k\\lambda <= m - n/p. The chosen range for \\lambda implies k\\lambda > k(m - n/p). If m - n/p < 0 (which is true under the condition of Theorem 1, where Proposition 9 is used), then k(m - n/p) < m - n/p for k > 1. Thus, k\\lambda > k(m - n/p) < m - n/p, which does not necessarily contradict k\\lambda <= m - n/p. However, the proof seems to imply that k\\lambda <= m - n/p is required for the contradiction, which contradicts the choice \\lambda > m - n/p when k > 1 and m - n/p < 0."
      },
      {
        "Problem": "Flawed derivation in the proof of the main characterization theorem for m < n/p.",
        "Location": "Page 8, Proof of Theorem 1",
        "Explanation": "The proof attempts to show that if f acts on Wm(R^n) and m < n/p, then f must be a polynomial of degree at most m-1 by showing that f^(m) = 0. This is done by constructing test functions g_a and using the boundedness property from Proposition 2. The derivation of the integral inequality \\int |f^(m)(t)|^p dt = 0 from the bound on the Wm norm of f o g_a appears incomplete and potentially incorrect. Specifically, the step relating the Wm norm to an integral of |f(a)|^p is not justified, and the subsequent steps leading to the integral of |f^(m)(t)|^p are unclear and likely incorrect."
      },
      {
        "Problem": "Incorrect inequality and integration by parts step in the proof of the sufficient condition for higher order Sobolev spaces.",
        "Location": "Page 9, Proof of Theorem 4",
        "Explanation": "In the proof sketch for m=2, the inequality ||(f'' o g) \\partial_j g \\partial_k g||_p <= U_j^{1/2p} U_k^{1/2p} is stated, where U_j = \\int |f'' o g|^p |\\partial_j g|^{2p} dx. This inequality does not appear to follow from standard inequalities like Cauchy-Schwarz or Holder. Furthermore, the subsequent integration by parts step applied to U_j seems incorrectly formulated or applied, making the derivation of the bound on U_j unreliable."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 13006,
      "output": 1071
    }
  },
  {
    "entry_id": 172,
    "retraction_id": "2001.10956v2",
    "paper_id": "2001.10956v1",
    "retraction_comment": "The second equation (2.22) is incorrect. The follow-up of the correct equation demands new developments, which I shall provide in a new version soon. wh",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of operator properties in the proof of Proposition 5.1.",
        "Location": "Proof of Proposition 5.1, step <p^(N-k)(2iπε-1) B¹, h> = <B¹, p^(N-k)(2iπε+1) h>",
        "Explanation": "The proof relies on the identity <p^(N-k)(2iπε-1) B¹, h> = <B¹, p^(N-k)(2iπε+1) h>. The operator 2iπε is a first-order differential operator (x ∂/∂x + ξ ∂/∂ξ + 1). Its formal adjoint with respect to the standard pairing <S, h> = S(h) is -2iπε. Thus, the adjoint of p^(N-k)(2iπε-1) should be p^(N-k)(-2iπε-1). The identity used in the proof implies an adjoint relation that does not hold. Furthermore, B¹ is a sum of eigenfunctions of Tdist, not an eigenfunction of 2iπε in the manner implied by applying Proposition 2.1 directly to B¹ as if it were an eigenfunction of 2iπε."
      },
      {
        "Problem": "Misapplication of the localization operator Φᴺ(2iπε) to isolate Laplacian eigenvalues.",
        "Location": "Section 5, definition of Φᴺ(iλ) in (5.11) and its application in Proposition 5.3 and Theorem 5.4 (Eq 5.9)",
        "Explanation": "The function Φᴺ(iλ) is defined in (5.11) as exp(-Nβ(λ-λ₀)²), where λ₀ is chosen to isolate a specific *Laplacian* eigenvalue (1+λ₀²)/4. The operator applied is Φᴺ(2iπε). The operator 2iπε has eigenvalues -1-iλ on modular distributions of degree -1-iλ. Applying Φᴺ(2iπε) to a modular distribution S (eigenfunction of 2iπε with eigenvalue μ) yields Φᴺ(μ)S. To isolate a Laplacian eigenvalue, one should apply an operator that is a function of the Laplacian or a related operator like π²ε². The use of Φᴺ(2iπε) to isolate a Laplacian eigenvalue appears fundamentally incorrect, as its eigenvalues on the relevant distributions are related to the homogeneity degree, not the Laplacian eigenvalue parameter λ used in the definition of Φᴺ."
      },
      {
        "Problem": "Unclear and potentially incorrect proof steps in Proposition 5.2.",
        "Location": "Proof of Proposition 5.2",
        "Explanation": "The proof of Proposition 5.2, which aims to show that the continuous part of (Tdist)²ᴺ B¹ is bounded, contains confusing steps. For example, it mentions 'forgetting about the sum over k... we must insert the extra factor p^(N-k)ν' in the context of the integral representation (5.3). This step is difficult to interpret and justify rigorously within the framework of the spectral decomposition and operator actions, casting doubt on the validity of the resulting bounds for the continuous spectrum."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 8753,
      "output": 704
    }
  },
  {
    "entry_id": 173,
    "retraction_id": "1407.6492v2",
    "paper_id": "1407.6492v1",
    "retraction_comment": "This paper has been withdrawn by the main author due to the Table 1 and equation 2 errors",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Testing on training data reported as a valid result",
        "Location": "Page 4, Section 3",
        "Explanation": "The paper reports achieving 100% accuracy when training and testing on the same 20,000 data samples. This is a fundamental error in evaluating a machine learning model's generalization ability, as it measures memorization rather than performance on unseen data. This specific result (100%) is therefore invalid as a measure of the method's effectiveness."
      },
      {
        "Problem": "Unclear and potentially incorrect feature definitions",
        "Location": "Page 2, Section 2.1 (Angle Features) and Section 2.2 (Distance Feature)",
        "Explanation": "The mathematical formulas (Equations 1 and 2) for Angle and Distance features appear inconsistent (summing over 'nb' pixels but dividing by 'n' white pixels) and descriptions are vague (e.g., 'agent point', 'ratio as feature' for Transit). This lack of clarity and potential mathematical error makes the feature extraction process difficult or impossible to reproduce and verify."
      },
      {
        "Problem": "Arbitrary image normalization size",
        "Location": "Page 2, Section 2",
        "Explanation": "Images are normalized to a fixed size of 60x30 pixels based on a statistic that >96% of images have width/length less than 30 pixels. Normalizing to a fixed size without considering the original aspect ratio can distort the shape of the numerals, which is critical for recognition. The chosen size seems arbitrary and not well-justified by the provided statistic."
      },
      {
        "Problem": "Inconsistent description of feature vector size",
        "Location": "Page 2, Section 2 and Page 3, Section 2.3",
        "Explanation": "The paper states that 3 features (transit, angle, distance) are computed for each of the 18 blocks, resulting in 54 features total. However, Section 2.3 specifically states that 'A total of 18 features will be extracted for each characters and this will serve as feature vector' for the Transit feature. This creates confusion about the actual composition and total size of the feature vector."
      },
      {
        "Problem": "Missing crucial K-NN parameter",
        "Location": "Page 3, Section 2.4.4 and Section 3",
        "Explanation": "The paper uses a K-Nearest Neighbour (K-NN) classifier but does not specify the value of 'k' used in the experiments. The choice of 'k' is a critical parameter for K-NN that significantly impacts performance. Without this information, the reported results are not fully reproducible."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 2620,
      "output": 612
    }
  },
  {
    "entry_id": 174,
    "retraction_id": "1802.06370v4",
    "paper_id": "1802.06370v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial explanation error of redundancy",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of the equation for F(p,x)",
        "Location": "Page 4, Equation (2.5)",
        "Explanation": "Substituting the ansatz H(p,x) = α₂eα₁F(p,x) into the combined Hamilton's equations (2.2) does not yield equation (2.5). The terms involving second derivatives of F with respect to p and x appear to be incorrect or have incorrect signs compared to a direct substitution."
      },
      {
        "Problem": "Flawed interpretation and splitting of equation (2.5)",
        "Location": "Page 4, Equations (2.5), (2.6), (2.7), (2.8)",
        "Explanation": "The paper claims that if F(p,x) = H(p,x), the first three terms of (2.5) give (2.2). This is incorrect, as the terms in (2.5) are second derivatives of F, while (2.2) involves first and second derivatives of H. This invalidates the subsequent step of requiring the last bracket (2.6) to vanish to obtain the condition on F (2.7)."
      },
      {
        "Problem": "Circular reasoning in solving for F in the additive case",
        "Location": "Page 5, Equations (2.12), (2.13), (2.14)",
        "Explanation": "In solving for F(p,x) = T(p) + V(x) from the derived condition (2.7), the paper uses the equation of motion ûp = -dV/dx in equation (2.13). The purpose of the Hamiltonian is to produce the equation of motion via Hamilton's equations. Using the equation of motion to determine the function F that defines the Hamiltonian constitutes circular reasoning, as F is not derived independently of the dynamics it is supposed to generate."
      },
      {
        "Problem": "Subsequent constructions rely on flawed derivation",
        "Location": "Section 2.3, Section 2.4, Section 2.5",
        "Explanation": "The construction of the Cabbatonian (Section 2.3), the generalized Cabbatonian (Section 2.4), and the 'More Hamiltonians' (Section 2.5) are all based on the condition on F (equation 2.7) or similar conditions derived from substituting into the problematic equation (2.8). Since the derivation of these conditions appears fundamentally flawed, the resulting Hamiltonians are not rigorously shown to produce the correct equation of motion."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 4508,
      "output": 606
    }
  },
  {
    "entry_id": 175,
    "retraction_id": "1403.0340v2",
    "paper_id": "1403.0340v1",
    "retraction_comment": "This paper has been withdrawn by the author because of Projection measurement tacit usage (while generalized one should have been used)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of stochastic Bell states.",
        "Location": "Section 4 (Eqs. 25-28) vs. Section 6.1 (Eqs. 44-47, 60).",
        "Explanation": "The paper defines 'stochastic Bell states' differently in different sections. In Section 4, they are defined as entangled states of four individual subsystems (two qubits, two l=1 detectors). In Section 6.1, they are defined as product states of qubit Bell states and detector Bell states. These definitions are mathematically distinct and lead to confusion and potentially incorrect analysis in the teleportation sections."
      },
      {
        "Problem": "Incorrect expansion of the global state in the Bell basis for teleportation in Section 5.",
        "Location": "Section 5, Eq. 34.",
        "Explanation": "The algebraic expansion of the global state in terms of Alice's stochastic Bell basis and Bob's state does not follow the standard procedure for expressing a bipartite state in a Bell basis. This leads to incorrect coefficients for Bob's state after Alice's measurement, suggesting teleportation is achieved without correction for some outcomes, which is fundamentally wrong."
      },
      {
        "Problem": "Incorrect expansion of the global state in the Bell basis for teleportation in Section 6.2.",
        "Location": "Section 6.2, Eq. 64.",
        "Explanation": "Similar to Section 5, the expansion of the global state in terms of Alice's stochastic Bell basis (from Section 6.1) and Bob's state is mathematically incorrect. The resulting coefficients for Bob's state after Alice's measurement are dependent on summation indices rather than the original state's coefficients, leading to the erroneous conclusion that teleportation is impossible except for specific initial states."
      },
      {
        "Problem": "Misinterpretation of the required correction operation in teleportation.",
        "Location": "Section 5 (page 12) and Section 6.2 (page 11, conclusion page 12).",
        "Explanation": "Based on the incorrect global state expansions, the paper suggests Bob applies correction operations sometimes to the qubit part and sometimes to the detector part of his system. This deviates from the standard teleportation protocol where the correction is applied to Bob's qubit (or the system receiving the teleported state) and indicates a misunderstanding of how the teleported state (the composite qubit-detector state) should be recovered."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 4686,
      "output": 554
    }
  },
  {
    "entry_id": 176,
    "retraction_id": "2106.01585v2",
    "paper_id": "2106.01585v1",
    "retraction_comment": "The proof of Lemma 3.1 has a gap. While there is exponential mixing for Holder functions, the rate of the mixing depends on the Holder exponent of the function. This leads to a vicious circle",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of Sobolev embedding/regularity lemma in establishing the smoothness of the correction term.",
        "Location": "Page 10, Proof of Proposition 3.4",
        "Explanation": "The proof uses Lemma 2.5 to argue that \\omega_\\lambda is in H^{k'+(2+d/2)} based on its derivatives D^\\alpha \\omega_\\lambda being in H^{-(2+d/2+\\epsilon)}. Lemma 2.5 states that if derivatives D^\\alpha f are in H^s for |\\alpha| \\le k, then f is in H^{s+k}. Applying this with s = -(2+d/2+\\epsilon) and k = k'-(2+d/2+\\epsilon) would imply \\omega_\\lambda is in H^{k'-(2+d/2+\\epsilon)}, not H^{k'+(2+d/2)}. This seems to be a misapplication of the lemma and Sobolev embedding (Theorem 2.6), failing to rigorously establish the required C^k regularity of \\omega."
      },
      {
        "Problem": "KAM error estimate in C^0 norm contains a term that grows with the smoothing parameter J.",
        "Location": "Page 14, Proposition 3.11 and its proof",
        "Explanation": "The estimate for the C^0 norm of the new error ||R^{(1)}||_{C^0} includes a term proportional to J^\\sigma||R||_{C^1}||R||_{C^k} (derived from J^0||R||_{C^1}||\\omega||_{C^0} and ||\\omega||_{C^0} \\ll J^\\sigma||R||_{C^k}). Since \\sigma = (2+d/2)+2d > 0, this term grows with J. A standard KAM scheme requires the linear part of the error estimate to shrink with J (typically with a negative power) for convergence. This growing term prevents the required quadratic convergence property in the C^0 norm."
      },
      {
        "Problem": "KAM error estimate in higher C^k norm grows with the smoothing parameter J.",
        "Location": "Page 15, Lemma 3.12 and its proof",
        "Explanation": "The estimate for the C^{k+k} norm of the new error ||R^{(1)}||_{C^{k+k}} is given as \\ll J^{\\sigma+k}||R||_{C^k}. Since \\sigma > 0 and k \\ge 0, the exponent \\sigma+k is positive. This implies that the error norm in higher regularity spaces grows with J, which is fatal for the convergence of the KAM iteration in these spaces. A convergent KAM scheme requires these norms to shrink with J."
      },
      {
        "Problem": "KAM iteration convergence proof fails due to growing error norms.",
        "Location": "Page 15, Section 4, particularly estimates (4.1), (4.2), and subsequent bounds",
        "Explanation": "The convergence of the KAM iteration relies on the error estimates from Section 3 (specifically Lemma 3.12). As identified in previous points, these estimates show that the error norms ||R^{(n)}||_{C^{k_n}} grow with the smoothing parameter J_n chosen at each step (due to positive exponents of J_n in the bounds). This prevents the sequence of errors from converging to zero in the relevant C^{k_n} spaces, which is necessary for the KAM scheme to produce a smooth conjugacy."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 5384,
      "output": 799
    }
  },
  {
    "entry_id": 177,
    "retraction_id": "1509.00106v3",
    "paper_id": "1509.00106v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (21)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and likely incorrect assumption on the Lipschitz constant of the smoothed function's gradient.",
        "Location": "Lemma 1 (Page 6), Section 4.5 (Page 16), Proof of Lemma 4 (Page 9).",
        "Explanation": "Lemma 1 states the Lipschitz constant of the gradient of the smoothed function fγ (defined using the composite proximity function b(Au)) is γ⁻¹Lf with Lf=1. Section 4.5 provides a different, also potentially incorrect, formula for Lf. The proof of Lemma 4 relies on Lf=1. The correct Lipschitz constant should depend on ||A||² and the strong convexity parameter of b(Au) with respect to u, which is generally not 1, especially if A is not a full column rank matrix. This fundamental error undermines the convergence analysis presented in subsequent lemmas and theorems."
      },
      {
        "Problem": "Flawed proof demonstrating that the proposed parameter update rules satisfy the required conditions.",
        "Location": "Proof of Lemma 5 (Page 10).",
        "Explanation": "Lemma 4 establishes convergence bounds under certain conditions on the parameters τk and γk (Eq. 21). Lemma 5 proposes specific update rules for these parameters (Eq. 24) and claims they satisfy conditions (21). However, the proof's justification for the first condition of (21) uses a different, hypothetical update rule for γk+1, not the one derived from (24). This gap means the paper does not rigorously show that the parameters used in Algorithm 1 satisfy the necessary conditions for the derived convergence rates."
      },
      {
        "Problem": "Lack of guarantee for strong convexity in the subproblem required for uniqueness and smoothness.",
        "Location": "Definition of fγ and u*γ(x) (Eq. 7, 8), Lemma 1 (Page 6).",
        "Explanation": "The smoothed function fγ is defined via a maximization problem (8). For fγ to be smooth with a Lipschitz gradient and for the solution u*γ(x) to be unique, the objective function φ(u) + γb(Au) must be strongly convex on the set U. While b is assumed strongly convex, b(Au) may not be strongly convex with respect to u if the matrix A is not full column rank. The paper does not assume A is full rank or that φ is strongly convex on U. Without this strong convexity, the properties stated in Lemma 1 (uniqueness of u*γ(x), Lipschitz gradient of fγ) may not hold, invalidating the basis for applying accelerated gradient methods."
      }
    ],
    "token_usage": {
      "input": 6316,
      "thinking": 4660,
      "output": 587
    }
  },
  {
    "entry_id": 178,
    "retraction_id": "1905.01749v2",
    "paper_id": "1905.01749v1",
    "retraction_comment": "There is a serious flaw with Theorems 2-4 which makes their results incorrect. We are working on fixing the issue and uploading a new version of this paper. This flaw, however, does not in any way affect the correctness of evaluations and the gains obtained using the proposed approach",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed or unclear proof for Theorem 1",
        "Location": "Section IV, Theorem 1 Proof",
        "Explanation": "The proof for the Pareto-optimality of grouping consecutive receivers on the relaxed topology is difficult to follow and appears potentially flawed. The logic regarding swapping receivers between partitions to improve rates is not clearly explained and may not hold, weakening the theoretical inspiration for the main heuristic."
      },
      {
        "Problem": "Algorithm contradicts the purpose of the objective vector",
        "Location": "Section V-D, Algorithm 4",
        "Explanation": "Algorithm 4 selects the best partitioning from the hierarchy by minimizing the average minimum completion time across *all* receivers (sum of weighted partition completion times). This contradicts the stated goal of the binary objective vector (WR), which is to prioritize completion times for receivers marked '1' and potentially sacrifice others ('0's) for bandwidth savings. The objective vector is used for the base partitioning but not for the final selection criterion from the hierarchy."
      },
      {
        "Problem": "Invalid lower bound used in evaluation",
        "Location": "Section VI-A, Figure 7",
        "Explanation": "The 'Lower Bound' used for comparison is computed on a simplified aggregate topology that removes network core bottlenecks present in the actual physical topology. This is not a true lower bound for the problem on the real network, making the comparison in Figure 7 misleading regarding the optimality gap on the actual topology."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 3539,
      "output": 327
    }
  },
  {
    "entry_id": 179,
    "retraction_id": "1312.6644v4",
    "paper_id": "1312.6644v3",
    "retraction_comment": "This paper has been withdrawn by the author because Eqs. (7) and (8) are not correct. An update with corrected expressions and plots will follow soon",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Analysis limited to transverse modes only",
        "Location": "Section II, Section III",
        "Explanation": "The paper analyzes heat transport only through the transverse vibrational modes (vibrons) of the ion crystal, neglecting the contribution and interaction with axial modes. While vibrons are relevant, total heat transport involves all degrees of freedom. Conclusions about general \"heat transport through ion crystals\" are therefore based on a partial picture, potentially missing important energy transfer mechanisms and contributions from axial modes."
      },
      {
        "Problem": "Harmonic approximation neglects anharmonicity",
        "Location": "Section II, Eq. 1",
        "Explanation": "The dynamics of the ions around their equilibrium positions is treated within the harmonic approximation. Anharmonic effects, which arise from higher-order terms in the potential energy expansion, are neglected. Anharmonicity is often crucial for thermalization and can drive systems towards normal heat transport behavior (Fourier's law). Its omission might affect the interpretation of the observed transition to linear temperature profiles and reduced conductivity with disorder, which could be primarily due to disorder-induced localization rather than thermalization via inter-mode scattering."
      },
      {
        "Problem": "Overstated claim of \"heat insulator\"",
        "Location": "Section III, Section IV",
        "Explanation": "The paper claims that disordered 2D zig-zag crystals become \"heat insulators\", implying conductivity approaches zero in the thermodynamic limit. While the presented data (Figure 2b, Figure 3a) shows a significant reduction in conductivity with disorder, the conductivity for the largest system size shown at fixed disorder is still non-zero. The term \"heat insulator\" might be an overstatement based solely on the provided figures, which do not conclusively demonstrate that the conductivity tends to zero as the system size increases at fixed disorder."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 4068,
      "output": 397
    }
  },
  {
    "entry_id": 180,
    "retraction_id": "2103.11473v2",
    "paper_id": "2103.11473v1",
    "retraction_comment": "The proof of the cluster property (E4) for the superposition is wrong. [REDACTED-NAME] and [REDACTED-NAME] gave a counterexample s.t. the statement of cluster property can't hold in its full generality",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation in Example 2.11",
        "Location": "Example 2.11, pages 7-8",
        "Explanation": "The calculation of the fourth truncated Schwinger function S_{4,p}^T for the given measure p contains algebraic errors and an incorrect factor (4) in the first line. This example is used to demonstrate that the constructed field is non-Gaussian and thus non-trivial, a key property claimed by the paper. The flawed calculation undermines the validity of this demonstration, even though the conclusion of non-Gaussianity might still hold based on a correct derivation."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 18828,
      "output": 142
    }
  },
  {
    "entry_id": 181,
    "retraction_id": "1303.6851v2",
    "paper_id": "1303.6851v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a loophole in the argument of the classical bound",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of the Tsirelson bound from the uncertainty principle.",
        "Location": "Section II, derivation of inequality (15)",
        "Explanation": "The paper attempts to derive the quantum bound on the CHSH inequality from the uncertainty principle by applying it to a non-standard operator B = ÃαPα + ÃβPβ, where Pα = Bα + Bβ and Pβ = Bα - Bβ. This operator is not the standard CHSH operator S = A₁B₁ + A₁B₂ + A₂B₁ - A₂B₂. While the derived bound for B might be 2√2 for specific operators and states, this does not demonstrate that the Tsirelson bound for the standard CHSH inequality S follows from the uncertainty principle in the way claimed, failing to establish the primary connection between uncertainty and standard nonlocality."
      },
      {
        "Problem": "Flawed argument for classical nonlocality based on a non-standard classical quantity.",
        "Location": "Section III.A, derivation of inequality (19) and subsequent conclusion",
        "Explanation": "The paper derives a bound of 2√2 for a classical expression |<<AαPα>> + <<AβPβ>>|, which is the average of a classical variable analogous to the paper's non-standard quantum operator B. This is then compared to the Tsirelson bound for the *standard* quantum CHSH operator S to argue that nonlocality can exist classically and is thus trivial. However, the standard classical bound (2) applies to the average of the *standard* CHSH expression. Deriving a 2√2 bound for a different classical quantity does not show that the standard CHSH inequality can be violated classically, nor does it imply that nonlocality (as defined by standard Bell violations) exists classically or is trivial."
      },
      {
        "Problem": "Misunderstanding of PR box properties and inconsistency argument.",
        "Location": "Section III.B, discussion of the nonlocal box",
        "Explanation": "The paper claims the Popescu-Rohrlich (PR) box model is inconsistent because local probabilities cannot be consistently assigned. This is incorrect. The PR box satisfies the no-signaling condition, and local probabilities P(a|x) and P(b|y) are well-defined (and equal to 1/2). The PR box is inconsistent *only* with the assumption of local hidden variables, which is precisely why it is studied in the context of nonlocality. The paper's argument that the PR box is not physical due to internal inconsistency based on local probabilities is flawed."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 3311,
      "output": 575
    }
  },
  {
    "entry_id": 182,
    "retraction_id": "1208.2556v2",
    "paper_id": "1208.2556v1",
    "retraction_comment": "This paper has been withdrawn by the author due to some nodes in the graph have not been taken into account",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "False assumption about predecessor parity in trajectory.",
        "Location": "Page 2, Proof of Lemma 2.1",
        "Explanation": "The proof claims that 'before an odd is always an even in the trajectory'. This is incorrect for the Collatz function. An odd number can follow either an even number (n/2) or an odd number (3n+1)."
      },
      {
        "Problem": "Incorrect calculation of C^6(d_{i-3}) formula.",
        "Location": "Page 2, Proof of Lemma 2.1",
        "Explanation": "The formula given for C^6(d_{i-3}) is stated as 3(((3d_{i-3}+1)/2)/2) + 1 = (9d_{i-3}+7)/4. This formula does not represent applying the Collatz function 6 times, nor does it align with the sequence of operations implied by the claimed parities of d_{i-3}, d_{i-2}, d_{i-1}, d_i, d_0."
      },
      {
        "Problem": "Incorrect derivation of cycle element forms in Lemma 2.1.",
        "Location": "Page 2, Lemma 2.1 statement and proof",
        "Explanation": "The specific forms {36k+16, 18k+8, ..., 12k+5} for the elements of any normalized cycle ≠ {4,2,1} are derived using the flawed parity assumptions and incorrect calculations in the proof. This set of forms serves as the foundation for the entire proof of the main theorem."
      },
      {
        "Problem": "Incorrect inverse function calculations in Theorem 3.1 proof.",
        "Location": "Pages 4-6, Proof of Theorem 3.1",
        "Explanation": "The proof works backwards from the maximum element using inverse functions κ⁻¹ and τ⁻¹. Several calculations of these inverse steps and the resulting forms (in terms of 9q+r) appear arithmetically incorrect (e.g., κ⁻¹(9a+16) calculation on page 4), invalidating the subsequent steps in the backward analysis for each case of k."
      },
      {
        "Problem": "Misapplication or misinterpretation of Lemma 2.1 in Theorem 3.1 proof.",
        "Location": "Pages 4-6, Proof of Theorem 3.1",
        "Explanation": "The proof attempts to derive contradictions by claiming that intermediate predecessors do not satisfy conditions from Lemma 2.1. However, Lemma 2.1 only specifies the forms of the cycle elements themselves (d₀, d₁, ..., dᵢ), not the forms of all intermediate predecessors generated when working backwards from d₀ using inverse functions. The criteria for contradiction are unclear and seem misapplied."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 10754,
      "output": 639
    }
  },
  {
    "entry_id": 183,
    "retraction_id": "1804.05635v2",
    "paper_id": "1804.05635v1",
    "retraction_comment": "Theorem 1 is questionable and needs revision. Others parts should also be modified accorrdingly. Before the new version is ready, this version should not be referred",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of Guarantee for Resource Capacity Constraints",
        "Location": "Section III.C, Theorem 3",
        "Explanation": "The decentralized winner determination process (Algorithm 2 based on Algorithm 3) allows agents to declare themselves winners based on local conditions (outranking a key predecessor among declared winners in their conflict set) and critical values. This process does not include a global check to ensure that the total resource demand of all agents who ultimately declare themselves winners respects the overall resource capacity constraints for each resource type. Theorem 3 claims this constraint is met, but its proof relies on the correctness claim of Theorem 2, which is also flawed."
      },
      {
        "Problem": "Incorrect Consistency Proof",
        "Location": "Section III.C, Theorem 4",
        "Explanation": "Theorem 4 claims that the decentralized approach identifies the exact same set of winners as the centralized greedy algorithm (Algorithm 1) using the same BRF. However, the decentralized algorithm determines winners through a dynamic, local interaction process based on critical values and key predecessors, while the centralized algorithm uses a single greedy pass over all bids ranked by the BRF, checking against global capacity. These are fundamentally different mechanisms, and the proof provided does not rigorously establish that they yield the same final set of winners."
      },
      {
        "Problem": "Flawed Correctness Proof",
        "Location": "Section III.C, Theorem 2",
        "Explanation": "Theorem 2 claims that the outcome of Algorithm 2 conforms to the BRF-based winner determination rule (Definition 3), which requires that an agent wins only if the sum of demands of all higher-ranked *declared winners* plus its own demand does not exceed capacity (Equation 17). The proof attempts to show this using the key predecessor logic (Algorithm 3). However, Algorithm 3 only considers declared winners *within the agent's conflict set* that rank below the agent, not *all* higher-ranked declared winners as required by Definition 3. Thus, the proof does not demonstrate that the decentralized outcome satisfies the stated correctness criterion."
      },
      {
        "Problem": "Flawed Finiteness Proof",
        "Location": "Section III.C, Theorem 1",
        "Explanation": "The proof for Theorem 1, which claims the decentralized protocol eventually stabilizes, relies on the assumption that agents only raise their bids. Algorithm 2 allows an agent to set its bid `bi` within the range `[ci + €, vi]` if `ci + € < vi`. The critical value `ci` is calculated based on the current set of *declared winners*. If changes in other agents' declarations cause `ci` to decrease such that the new range `[ci + €, vi]` is below the agent's current bid, the agent might set a lower bid, violating the 'only raise bids' assumption and potentially preventing the system from converging to a stable state."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 4993,
      "output": 635
    }
  },
  {
    "entry_id": 184,
    "retraction_id": "1503.01380v2",
    "paper_id": "1503.01380v1",
    "retraction_comment": "incomplete and inaccurate, requesting withdrawal immediately. the ranking method is not correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proposed Journal Influence Score (JIS) is presented as a new, lightweight measure, but the methodology trains and validates it against the SCImago Journal Rank (SJR). This makes JIS essentially a linear regression approximation of SJR, rather than an independent measure of journal influence.",
        "Location": "Abstract, Section 2.1, Section 3, Conclusions",
        "Explanation": "The paper claims to propose a new score (JIS) but uses historical SJR data as the target variable for regression and validates the results by comparing rankings to SJR. This means the model is designed to predict SJR, not to provide an alternative, independent measure of influence. The 'lightweight' aspect comes from using fewer input variables than SJR might implicitly use, but the output is a proxy for SJR."
      },
      {
        "Problem": "The description of the variable selection process, particularly the application of Principal Component Analysis (PCA) and the final regression model, is inconsistent and unclear.",
        "Location": "Page 2 (Section 2.2), Page 5 (Analysis Phase-III, Principal Component Analysis), Page 6 (Principal Component Analysis, Table, Summary Output)",
        "Explanation": "The paper states the final model is MLR on principal components (Page 2) but later describes PCA as a feature reduction step where original variables are removed based on variance explained and 'percentage match' (Page 5-6). The final regression table (Page 6) shows coefficients for original variable names (Quarter, H-index, etc.), not principal components. This inconsistency makes it impossible to definitively understand the final model structure and its statistical basis."
      },
      {
        "Problem": "The variable selection rule in Analysis Phase-I and Phase-II ('P-value > 0.05 & Correlation Coefficient < 0.4, then remove parameter') is statistically unsound and arbitrary.",
        "Location": "Page 4 (Analysis Phase-I), Page 5 (Analysis Phase-II), Page 3 (Algorithm Step 7)",
        "Explanation": "Standard statistical practice for variable selection in regression typically relies on P-values (to assess significance given other predictors) or measures of multicollinearity (like VIF) and correlation (to understand bivariate relationships), but not a combined rule like this. A variable can have a high P-value but a moderate correlation, or vice-versa. Removing variables based on this specific joint condition lacks theoretical justification and may lead to suboptimal or incorrect model specification."
      },
      {
        "Problem": "The categorical variable 'Quarter' is included directly in the linear regression model as if it were a continuous variable.",
        "Location": "Page 2 (Section 2.2, Model equation), Page 6 (Summary Output, Coefficients table), Page 7 (Regression equation)",
        "Explanation": "Quarter (Q1, Q2, Q3, Q4) represents distinct periods and should be treated as a categorical variable in a regression model, typically using dummy variables. Including it as a single continuous variable assumes a linear relationship between the quarter number (1, 2, 3, 4) and the outcome, which is inappropriate and misinterprets the nature of the data."
      },
      {
        "Problem": "The claim that the method 'does not require any data storage' is misleading, as historical data is necessary to train the regression model.",
        "Location": "Abstract, Page 2 (Section 2.1, first paragraph)",
        "Explanation": "While the method might be lightweight for *applying* the trained model to a new journal, the entire process described involves importing data from SCImago (Step 1, Page 3) and using it to train the regression model (Steps 3-9, 18, Page 3). This training phase explicitly requires storing and processing historical data on journal metrics and their corresponding SJR values. The claim of 'no data storage' is therefore inaccurate."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 2372,
      "output": 860
    }
  },
  {
    "entry_id": 185,
    "retraction_id": "1711.11197v4",
    "paper_id": "1711.11197v3",
    "retraction_comment": "Theorem 4.3 is false as states and it requires a completely different approach. Section 5 is completely correct but it will developed separately",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Morita equivalence statement in Lemma 4.1",
        "Location": "Page 18, Lemma 4.1",
        "Explanation": "Lemma 4.1 states a Morita equivalence between `bN` (the total space of a vector bundle over M) and a groupoid `(H(M,F) x RN)|_U`. A vector bundle is not a groupoid in the sense required for Morita equivalence to a general Lie groupoid. The proof attempts to show this using Blup functoriality, but the initial step `bN ~ Blupr,s(N, Nv)` seems to confuse the Lie algebroid with the groupoid or its units. This fundamental error invalidates the construction of the topological index `bInd_t` in Definition 4.2 and the proof of Theorem 4.4."
      },
      {
        "Problem": "Incorrect computation of orbit space in Proposition 5.2 (part 1)",
        "Location": "Page 25, Proposition 5.2 (part 1)",
        "Explanation": "Proposition 5.2 claims that the orbit space of the semi-direct product groupoid `Gamma_phi(M)^h` is diffeomorphic to `B x RN`. Based on the definition of the semi-direct product `(M x RN) x_h Gamma_phi(M)` with units `M x RN` and the map `h: Gamma_phi(M) -> RN`, the orbits on `M x RN` are of the form `phi^{-1}(phi(x)) x {X}`. The map `q(x, X) = (phi(x), X - j_0(x))` is claimed to induce a bijection on the quotient, but it is not constant on these orbits unless `j_0` is constant on the fibers of `phi`, which is not generally true for an embedding. This incorrect orbit space computation invalidates the topological index construction in Definition 5.5 and the proof of Theorem 5.7."
      },
      {
        "Problem": "Incorrect computation of orbit space in Proposition 5.2 (part 2)",
        "Location": "Page 25, Proposition 5.2 (part 2)",
        "Explanation": "Proposition 5.2 claims that the orbit space of the semi-direct product groupoid `(bT_phi M)^ho` is diffeomorphic to `N_phi(RN, M)`. `(bT_phi M)^ho` is the semi-direct product `(M x RN) x_ho bT_phi M` with units `M x RN` and `ho: bT_phi M -> RN` being the differential of the embedding. The orbits on `M x RN` are of the form `{(y, X) | exists xi in bT_phi M with s(xi)=x, r(xi)=y, Y = X - ho(xi))}`. If `ho` is injective (as claimed in the proof of Proposition 5.1), then `ho(xi)=0` implies `xi=0`, meaning `x=y`. This would imply the orbits are just points `(x, X)`, contradicting the claim that the orbit space is `N_phi(RN, M)`, which is a vector bundle over M. This incorrect orbit space computation invalidates the topological index construction in Definition 5.5 and the proof of Theorem 5.7."
      }
    ],
    "token_usage": {
      "input": 7864,
      "thinking": 9190,
      "output": 761
    }
  },
  {
    "entry_id": 186,
    "retraction_id": "2301.09693v2",
    "paper_id": "2301.09693v1",
    "retraction_comment": "An important technical mistake in the set-up of this variant of generalization to Seiberg-Witten equations was pointed out to the author. In particular, the equations are not elliptic as claimed. As a result, any statement about (or uses) regularity and transversality of the moduli space has to be disregarded. However, the moduli space is still compact",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition and application of the quadratic map $\\mu_{0,\\delta}$.",
        "Location": "Section 1, paragraph before (1.5), and Lemma 2.1",
        "Explanation": "The definition of the quadratic map $\\mu_{0,\\delta}(\\psi)$ using projections $P$ and $Q$ from $gl(\\mathbb{C}^2) \\otimes gl(\\mathbb{C}^n)$ is inconsistent with $\\psi\\psi^*$ being an endomorphism of $\\mathbb{C}^2 \\otimes \\mathbb{C}^n \\cong \\mathbb{C}^{2n}$. This makes the curvature equation ill-posed and invalidates the properness argument in Lemma 2.1."
      },
      {
        "Problem": "Flawed proof of properness for $\\mu_{0,0}$.",
        "Location": "Lemma 2.1",
        "Explanation": "The step $P(\\begin{pmatrix} \\alpha\\alpha^* & \\alpha\\beta^* \\\\ \\beta\\alpha^* & \\beta\\beta^* \\end{pmatrix}) = \\begin{pmatrix} (\\alpha\\alpha^*)_0 & (\\alpha\\beta^*)_0 \\\\ (\\beta\\alpha^*)_0 & (\\beta\\beta^*)_0 \\end{pmatrix}$ incorrectly applies the traceless projection to blocks of the matrix $\\psi\\psi^*$ instead of the entire matrix. This invalidates the conclusion that $\\mu_{0,0}(\\psi)=0$ implies $\\psi=0$."
      },
      {
        "Problem": "Unjustified inequality in the proof of estimate (7.1).",
        "Location": "Section 7.1, step from (7.6) to (7.8)",
        "Explanation": "The inequality $i L_A^d |s|^2 |s| - \\sum_j \\partial \\lambda_j \\wedge \\bar{\\partial} \\lambda_j \\le 0$ used to derive estimate (7.1) is not justified and appears potentially incorrect. This estimate is crucial for establishing $L^p$ bounds for solutions, which are necessary for compactness and convergence arguments."
      },
      {
        "Problem": "Logical error in the proof of Proposition 6.15.",
        "Location": "Section 7.2, deduction of (7.14) from (7.17)",
        "Explanation": "The inequality (7.17) implies that the left-hand side of (7.14) goes to zero as $j \\to \\infty$ for a minimizing sequence, which is the opposite of what is needed to deduce (7.14) directly. This undermines the contradiction argument in Proposition 6.14, which is essential for proving the existence of the desired Hermitian metric in Theorem 6.5."
      }
    ],
    "token_usage": {
      "input": 11992,
      "thinking": 7263,
      "output": 643
    }
  },
  {
    "entry_id": 187,
    "retraction_id": "1609.01275v2",
    "paper_id": "1609.01275v1",
    "retraction_comment": "There is a serious error 3 lines below \"Step (II)\". It is not true that \"It follows that the set C' of all oriented colourings for ... is equal to the set of extension colourings.. .\" (In fact they only account for half of the extension colourings.)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The relationship between determinant terms before and after joint splitting is not formally derived.",
        "Location": "Page 13, Steps I and II, and page 14, Lemma 5.3",
        "Explanation": "The proof of Lemma 5.3 relies on a specific multiplicative relationship between the terms Xμ associated with an oriented colouring μ of the original graph and the terms Xμ' associated with an extended colouring μ' of the new graph. This relationship is described informally (Steps I and II on page 13) and used in the form Xμ' = d_i Xμ (or pol(μ') = q_i(z) pol(μ)). A rigorous derivation of this relationship from the definition of Xμ as a signed product of matrix entries and the definition of the joint-splitting move (which changes the matrix Φ(z)) is missing. This lack of formal derivation makes the subsequent arguments about the nature of d_i/q_i(z) and the preservation of the palindrome property unsound."
      },
      {
        "Problem": "The deduction of the strong palindrome property for the new origami appears flawed.",
        "Location": "Page 14, Lemma 5.3 proof",
        "Explanation": "The strong palindrome property for O' requires that for *every* local oriented colouring λ' at *every* joint v' of O', the sum X^λ' = Σ_{μ': λ' C μ'} Xμ' is palindromic (up to a factor). The proof on page 14, for types (a), (b), (c), shows that the sum Σ_{i=i1,i2} X'_{λ1,i} is palindromic, where λ1,i are different local colourings at v1 in the new graph GM'. This is a sum over different λ' terms, not a single X^λ' term. The argument does not demonstrate that each individual X'_{λ1,i} (or any other X^λ' for a local colouring λ' at v0 or v1) is palindromic. This is a critical gap in the proof that the strong palindrome property is preserved."
      },
      {
        "Problem": "The nature of the multiplicative factors d_i and q_i(z) is not sufficiently justified.",
        "Location": "Page 13-14, Lemma 5.3 proof",
        "Explanation": "The proof relies on the factors d_i (or q_i(z) for reflexive bars) having specific properties (being monomial multiples, or palindromic/antipalindromic rational functions). These factors arise from the change in the determinant terms Xμ' relative to Xμ due to the joint-splitting. Without a formal derivation of the relationship between Xμ and Xμ' (Problem 1), the nature of these factors cannot be rigorously established. The claim that d_i is a scalar multiple of a monomial whose degree is independent of i (page 13) and that q_i(z) is palindromic or antipalindromic (page 14) are crucial for the palindrome argument but are not adequately justified."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 4558,
      "output": 693
    }
  },
  {
    "entry_id": 188,
    "retraction_id": "2106.14795v2",
    "paper_id": "2106.14795v1",
    "retraction_comment": "Proof of Threorem 17, part 2 not correct as displayed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect pairing of finite element spaces for the discrete state system.",
        "Location": "Section 3, page 9, equations (23a)-(23b) and preceding text.",
        "Explanation": "The paper uses the Raviart-Thomas elements of lowest order (P0, P1) for the discrete state system. In the standard RT0 method for the problem -y''=u (with z=y'), the flux z is approximated by P0 and the state y by P1. The paper assigns the state yh to P0 (piecewise constant) and the flux zh to P1 (piecewise linear), which is the reverse of the standard RT0 pairing and leads to a discrete system that does not correctly approximate the continuous mixed formulation."
      },
      {
        "Problem": "Incorrect formulation of the discrete adjoint system.",
        "Location": "Section 3, page 10, Theorem 8 and page 11, equations (33)-(34).",
        "Explanation": "The discrete adjoint system is formulated with adjoint variables (ph, qh) assigned to spaces (P0, P1) respectively. Equation (34) involves the L^2 integral of the derivative of ph, which is piecewise constant (ph ∈ P0). The derivative of a piecewise constant function is a sum of Dirac measures, making the L^2 integral ill-defined in the standard sense. This indicates a fundamental error in the discrete adjoint system formulation given the chosen spaces."
      },
      {
        "Problem": "Inconsistent and incorrect definition of the discrete optimal control structure.",
        "Location": "Section 3, page 8, page 12, and page 13.",
        "Explanation": "The variational discrete control ūh is defined as Yhū, the L^1 projection of the continuous optimal control ū onto the space of piecewise constant functions P0. Thus, ūh must be piecewise constant. However, the paper later represents ūh (and uses this representation in the error analysis) as a BV function with jumps (ūh = āh + ∑ ĉ_j(i) 1_{(xj(i), 1)}), which contradicts its definition as a piecewise constant function and invalidates the subsequent analysis based on this structure."
      },
      {
        "Problem": "Incorrect sparsity structure derived for the continuous optimal control.",
        "Location": "Section 2, page 7, Lemma 5.",
        "Explanation": "The lemma states that the support of the derivative of the optimal control ū' is contained in the set where |Φ(x)| = α, which is further contained in the set where p(x) = 0. The standard theory for BV regularization dictates that the support of ū' is contained in the set where the absolute value of the adjoint state p equals the regularization parameter α, i.e., supp(ū') ⊂ {x ∈ Ω : |p(x)| = α}. The derived sparsity condition contradicts this fundamental result."
      },
      {
        "Problem": "Incorrect regularity stated for the continuous adjoint state.",
        "Location": "Section 2, page 5, Theorem 4.",
        "Explanation": "The theorem states that the adjoint state (p, ᾷ) ∈ H^2(Ω) ∩ H^1_0(Ω) × H^1(Ω). Based on the adjoint system derived from the mixed formulation (p' = -(ӯ - yd), ᾷ = p'), p should be in H^1_0(Ω) and ᾷ = p' should be in L^2(Ω) given the regularity of the state ӯ and desired state yd. The stated higher regularity (p ∈ H^2(Ω), ᾷ ∈ H^1(Ω)) is not generally guaranteed and might impact the validity of subsequent analysis that relies on this regularity."
      }
    ],
    "token_usage": {
      "input": 9412,
      "thinking": 15634,
      "output": 840
    }
  },
  {
    "entry_id": 189,
    "retraction_id": "2108.05981v2",
    "paper_id": "2108.05981v1",
    "retraction_comment": "The article has been withdrawn due to incorrect model formulation. Particularly, introducing the so-called \"field with two elements\" was a mistake that made the main equation (observation) of the paper incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified application of Klein-Gordon equation and derivation of mass formula for a finite field.",
        "Location": "Page 3, Section 2.A, Equations (1)-(4)",
        "Explanation": "The Klein-Gordon equation is a partial differential equation for continuous fields. Applying it to a 'discrete complex scalar finite field' requires rigorous justification for the definition of the discrete Laplacian and the concept of 'wavenumber' (2π/q) in this context. The derivation of the dispersion relation (Eq. 2) and the mass formula (Eq. 4) from a discrete KG equation is not standard and appears to lack a solid mathematical foundation within the framework of finite fields."
      },
      {
        "Problem": "Arbitrary assumption equating the finite field quanta mass at the critical point to the Higgs mass.",
        "Location": "Page 4, Section 2.B",
        "Explanation": "The paper assumes that the mass of the bosons of the finite field at the critical point (mqc) is equal to the mass of the Higgs boson (MH). This assumption is used to calculate qc, which then leads to the observation about the Monster group. This makes the subsequent 'prediction' of the Higgs mass (Eq. 14) circular, as the known Higgs mass was used as input to establish the core relationship."
      },
      {
        "Problem": "Arbitrary assumption equating the critical order of the symmetry group to the Monster group order.",
        "Location": "Page 5, Section 3, Equation (8)",
        "Explanation": "Based on the numerical closeness of the calculated order of SU2(qc^2) and the Monster group order, the paper makes a strong assumption that the critical order of SU2(q*^2) is exactly equal to the Monster group order. This is a 'curious proposal' without theoretical justification within the established framework, yet it is central to determining the value of q* used in the final mass calculation."
      },
      {
        "Problem": "Unsound derivation and identification of m2 with the reduced Planck mass.",
        "Location": "Page 5, Section 3, Equations (11)-(12)",
        "Explanation": "The paper attempts to relate m2 (mass for q=2 field) to the reduced Planck mass (Mp). The argument that extrapolating Eq. 3 to q=2 yields m2 = π is mathematically unsound, as Eq. 3 is derived for the critical point qc, not arbitrary q, and q is a prime power, not a continuous variable allowing a limit to 2. The subsequent replacement of π with m2 in Eq. 11/12 lacks a clear derivation from the proposed finite field framework."
      },
      {
        "Problem": "Incorrect derivation and arbitrary insertion of the factor 24 as spatial dimensions.",
        "Location": "Page 6, Section 3, Equation (13)",
        "Explanation": "The paper inserts the factor 24 into the main observation (Eq. 13) and interprets it as the number of spatial dimensions (D) or CFT central charge. The attempted derivation from a D-dimensional KG equation, stating that -D (2π/qc)^2 = mqc^2 results in |mq| = (2π/qc) * sqrt(D), is mathematically incorrect. The factor 24 appears to be inserted to match the desired numerical result rather than being a consequence of the theoretical framework."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 1928,
      "output": 761
    }
  },
  {
    "entry_id": 190,
    "retraction_id": "2209.07447v2",
    "paper_id": "2209.07447v1",
    "retraction_comment": "Theorem 11.1 is false : the kernel is not trivial as stated",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lemma 9.2 claims a surjective map that is not generally surjective.",
        "Location": "Page 20, Lemma 9.2",
        "Explanation": "Lemma 9.2 states that the map H¹(K, μ3 × μ3) → H¹(K, S × SL1(D)) induced by the embedding μ3 × μ3 → S × SL1(D) is surjective. This map is the product of the maps H¹(K, μ3) → H¹(K, S) and H¹(K, μ3) → H¹(K, SL1(D)). Neither of these individual maps is generally surjective for arbitrary fields K and division algebras D or tori S, meaning their product is also not generally surjective. For instance, H¹(K, μ3) is K*/K*³, while H¹(K, SL1(D)) is K*/Nrd(D)×, and the map between them is not surjective in general."
      },
      {
        "Problem": "Proof of Theorem 9.1 relies on the false Lemma 9.2.",
        "Location": "Page 21, Proof of Theorem 9.1",
        "Explanation": "The proof of Theorem 9.1 uses the claimed surjectivity from Lemma 9.2 to assert that an element [ξ'] in H¹(K, S) × H¹(K, SL1(D)) can be written in a specific form (a, b) where a, b come from H¹(K, μ3). This step is crucial for the subsequent manipulation of the cocycle [ξ'] to show it is trivial. Since Lemma 9.2 is false, this step is invalid, and the proof of Theorem 9.1 fails for arbitrary fields. This invalidates the reduction to the pro-3-group case."
      },
      {
        "Problem": "Key results and the main theorem rely on an unproven reduction to the pro-3-group case.",
        "Location": "Sections 10, 11, and Theorem 3.7 (Page 6)",
        "Explanation": "Sections 10 and 11, which establish crucial intermediate results (e.g., Theorem 10.5, Theorem 11.1) leading to the proof of the main theorem, explicitly assume that the Galois group Gal(K) is a pro-3-group. This assumption is justified by Theorem 9.1. As the proof of Theorem 9.1 is invalid for arbitrary fields (due to its reliance on the false Lemma 9.2), the results in Sections 10 and 11 are only proven for fields with pro-3 Galois groups. Consequently, the main theorem (Theorem 3.7), which claims the classification holds for arbitrary fields, is not proven by the arguments presented."
      },
      {
        "Problem": "Flawed argument in the proof of Lemma 11.2 (v).",
        "Location": "Page 27, Proof of Lemma 11.2, step (v)",
        "Explanation": "In step (v) of the proof of Lemma 11.2, the argument attempts to show that dim((P∩N)⁰) ≤ 2. It considers a quadratic field extension L/K that splits Z/(P∩N)⁰ and claims that the cubic division algebra D (associated with SL1(D)) remains a division algebra over L and the torus S remains anisotropic over L. This is not necessarily true. A quadratic extension L can split a cubic division algebra D (making DL isomorphic to M3(L)), in which case SL1(D)L becomes SL3,L, which is isotropic. This contradicts the argument that ZL is isotropic only if (P∩N)⁰ is 2-dimensional. The reasoning in this step is flawed."
      }
    ],
    "token_usage": {
      "input": 8896,
      "thinking": 57355,
      "output": 854
    }
  },
  {
    "entry_id": 191,
    "retraction_id": "1305.2623v2",
    "paper_id": "1305.2623v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in the calculation of Equation (28)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory definition of strong parameters condition for random walk mobility",
        "Location": "Section 2.2.1, Random walk mobility model, Strong parameters condition",
        "Explanation": "The strong parameters condition for random walk mobility states that all velocities are of the same order, are 'w(sqrt(log n / nd))' AND 'o(n^-1)'. These two asymptotic notations describe fundamentally different behaviors as n grows large: 'w(f(n))' means the function grows faster than f(n), while 'o(g(n))' means the function grows slower than g(n). For positive functions f(n) and g(n), a function cannot simultaneously be 'w(f(n))' and 'o(g(n))' if f(n) does not go to zero faster than g(n). In this case, sqrt(log n / nd) grows with n (for constant d), while n^-1 goes to zero. A velocity cannot be both growing with n and going to zero as n goes to infinity. This contradictory definition makes the strong parameters condition ill-defined and invalidates any results derived under it for the random walk model."
      },
      {
        "Problem": "Invalid independence assumption (Lemma 2) due to non-negligible overlap of covered areas",
        "Location": "Section 4, Lemma 2 and its proof in Appendix, Section 5.1, Proposition 1",
        "Explanation": "Lemma 2 asserts asymptotic independence of events related to connectivity in different time slots and for different cluster members. The proof in the Appendix (Section 1°) for random walk mobility relies on the overlap area (Sp) of covered transmission areas going to zero as n approaches infinity. However, under the weak parameters condition, the critical transmission range r is of order sqrt(log n / nd) and velocities v are of order w(sqrt(log n / nd)). The covered area Si is pi*r^2 + 2rviT. The overlap area Sp involves terms proportional to r*vT. The product r*vT is of order sqrt(log n / nd) * w(sqrt(log n / nd)), which does not go to zero as n approaches infinity. Thus, the overlap is not negligible, the independence assumption in Lemma 2 (properties 1-a, 1-b) is likely invalid, which undermines Proposition 1 and subsequent results that rely on it for random walk weak conditions."
      },
      {
        "Problem": "Incorrect approximation of covered transmission area (Si) for random walk weak conditions",
        "Location": "Section 5.1, Proposition 2",
        "Explanation": "Proposition 2, which is crucial for deriving the critical transmission range under random walk mobility, uses the approximation Si ~ 2rviT. The correct formula for the covered area in a time slot is Si = pi*r^2 + 2rviT. Under the weak parameters condition, the critical transmission range r is of order sqrt(log n / nd) and velocities vi are of order w(sqrt(log n / nd)). Therefore, r^2 is of order log n / nd and rviT is of order sqrt(log n / nd) * w(sqrt(log n / nd)). If vi is of the same order as v*, rviT is of order log n / nd. In this case, r^2 and rviT are of the same order (log n / nd), and r^2 is not negligible compared to rviT. The approximation Si ~ 2rviT is incorrect, invalidating Proposition 2 and the subsequent derivation of the critical transmission range (Theorem 1) for random walk weak conditions."
      },
      {
        "Problem": "Invalid independence assumption (Lemma 2) for i.i.d. mobility due to non-negligible overlap of covered areas",
        "Location": "Section 4, Lemma 2 and its proof in Appendix, Section 6, Proposition 7, 8",
        "Explanation": "Lemma 2 asserts asymptotic independence of events for i.i.d. mobility. The proof in the Appendix (Section 2°) relies on the probability of overlap between covered transmission areas going to zero. For i.i.d. mobility, the covered area in a time slot is a circle of radius r (Si = pi*r^2). The critical transmission range r is of order sqrt(log n / nd). The probability that two such areas overlap is non-negligible if their centers are within 2r. The expected number of overlapping pairs of areas among n members over m slots is proportional to (mn)^2 * (2r)^2, which is of order (mn)^2 * (log n / nd) = m^2 * n^2 * log n / nd = (m^2/d) * n * log n. This quantity goes to infinity as n approaches infinity. Thus, the overlap is not negligible, the independence assumptions in Lemma 2 (properties 1-a, 1-b, 2) are likely invalid, which undermines Proposition 7, 8, and Theorem 3 for i.i.d. mobility."
      },
      {
        "Problem": "Invalid independence assumption (Lemma 2) for random walk strong conditions due to non-negligible overlap",
        "Location": "Section 4, Lemma 2 and its proof in Appendix, Section 5.2, Proposition 3(b)",
        "Explanation": "Lemma 2 (property 2) asserts asymptotic independence of disconnected events Ei under strong parameters conditions, relying on the probability P* (that covered areas don't overlap) going to 1. The proof in the Appendix (Section 2°) for random walk strong conditions states P* -> 1 using a similar method as the weak condition case, which relies on the overlap area going to zero. However, as identified in Problem 1, the strong parameter condition for RW contains a contradiction regarding velocity scaling. If we interpret velocities as w(sqrt(log n / nd)), then r*vT is of order log n / nd, meaning overlap is significant, contradicting P* -> 1. If we interpret velocities as o(n^-1), the critical range r grows very fast, also leading to significant overlap. In either case, the assumption P* -> 1 seems incorrect, invalidating Lemma 2(2) and the strong parameter results (Proposition 3(b), Theorem 1) for random walk mobility."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 4846,
      "output": 1414
    }
  },
  {
    "entry_id": 192,
    "retraction_id": "0909.5521v3",
    "paper_id": "0909.5521v2",
    "retraction_comment": "Manuscript withdrawn, because results are incorrect. If phi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be expressed as a universal Horn sentence in ESO (NOT even when the structure is ordered)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper's central premise regarding the expressibility of the Objective Function Constraint (OFC) in ESO-ord-Π₁-Horn logic is directly contradicted by a cited source (Dawar [Da09]).",
        "Location": "Abstract, Section 2.1, Remark 8, Remark 9, Section 3.1, [Da09] reference",
        "Explanation": "The paper argues that the OFC for optimization problems can be expressed in ESO-ord-Π₁-Horn and re-used for NP problems. However, the author cites Dawar [Da09] who proved that the OFC cannot be expressed in this logic, regardless of the successor relation. This fundamental contradiction, acknowledged by the author in Section 3.1, invalidates the paper's main conclusion (Proposition 10)."
      },
      {
        "Problem": "Assumption 4, which is critical for the paper's argument that the OFC must be expressible in ESO-ord-Π₁-Horn, is unproven and likely false.",
        "Location": "Assumption 4 (Page 2), Section 3.1 (Page 6)",
        "Explanation": "Assumption 4 states that if a conjunction of clauses is equivalent to a Horn formula, then each clause must be a Horn clause. The author provides a weak, non-rigorous argument for this in Section 3.1. However, the author's own example `(p V q) ^ ¬q` shows a conjunction of a non-Horn clause (`p V q`) and a Horn clause (`¬q`) that is equivalent to a Horn formula (`p ^ ¬q`). This contradicts Assumption 4."
      },
      {
        "Problem": "The paper claims the OFC (e.g., `|S| ≥ K`) can be expressed as a quantifier-free conjunction of Horn clauses over first-order variables (within the Π₁-Horn structure) but provides no justification or explicit expression.",
        "Location": "Section 2.1 (Page 4), Remark 11 (Page 4), Section 2.2 (Page 5), Section 2.3 (Page 5)",
        "Explanation": "Expressing cardinality constraints like `|S| ≥ K` or `|T| ≥ K1` using only first-order variables and a quantifier-free conjunction of Horn clauses (even with second-order predicates) is highly non-trivial and likely impossible within the strict definition of Π₁-Horn logic, especially without violating the quantifier structure or the Horn property of the first-order part. The paper relies on this expressibility without demonstrating it, which is a significant technical gap."
      },
      {
        "Problem": "The paper appears to misinterpret or misapply Grädel's Theorem (Theorem 6) in the context of separating and re-using the OFC expression.",
        "Location": "Theorem 6 (Page 3), Corollary 7 (Page 3), Remark 8 (Page 3), Remark 9 (Page 3), Section 2.1 (Page 4)",
        "Explanation": "Theorem 6 states that problems in P are *expressible* in ESO-ord-Π₁-Horn. The paper interprets this as meaning that the BFC and OFC parts of a P problem are *separately* expressible in this form, allowing the OFC part to be re-used for NP problems. This separation and re-use strategy, particularly for the OFC in this specific logical form, is not a direct consequence of Theorem 6 and is contradicted by Dawar's result, suggesting a misunderstanding of the theorem's scope or implications for problem decomposition."
      },
      {
        "Problem": "The argument in Section 3.1 attempting to justify Assumption 4 based on the \"unrelatedness\" of BFC and OFC properties is flawed and not a valid logical proof.",
        "Location": "Section 3.1 (Page 6)",
        "Explanation": "The author argues that because BFC and OFC are \"independent and completely unrelated properties,\" if their conjunction is Horn, then both must be Horn. This is a non-sequitur. Logical equivalence does not depend on the \"relatedness\" of the properties being expressed. The author's own example `(p V q) ^ ¬q` being equivalent to `p ^ ¬q` demonstrates that a conjunction of unrelated properties (p and q) where one clause is non-Horn can be equivalent to a Horn formula. The subsequent argument about negation is specific to the example and doesn't support the general claim."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 3281,
      "output": 1007
    }
  },
  {
    "entry_id": 193,
    "retraction_id": "1810.09527v2",
    "paper_id": "1810.09527v1",
    "retraction_comment": "Appears that the three transitions interpreted as blueshifted molecular emission from methanol and methanimine are recombination line transitions with similar rest frequencies Paper being withdrawn while this is confirmed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of precise spatial localization of the emission.",
        "Location": "Section 4.1, Figure 2",
        "Explanation": "The angular resolution of the primary observations is low (~25 arcseconds, corresponding to ~450 pc at the assumed distance). While non-detection on longer baselines indicates the emission is extended on scales greater than ~2 arcseconds (~40 pc), the precise location and morphology relative to the galaxy's nucleus, continuum source, and other features (like the 36.2 GHz maser) are poorly constrained by the low-resolution images. This limits the ability to definitively link the emission to a specific origin (e.g., nuclear outflow vs. distributed star formation) and fully characterize its spatial nature."
      },
      {
        "Problem": "Interpretation of the spectral profile shape based on a poorly fitting model.",
        "Location": "Figure 1, Section 4.2",
        "Explanation": "The authors interpret the broad spectral profile of the 6.7 GHz methanol emission as consistent with a spherical outflow amplifying background continuum, fitting it with a specific model (Equation 1). However, the visual fit of this model to the observed spectrum is poor, particularly on the blue edge and the relatively flat peak. This weakens the evidence derived from the profile shape for the proposed outflow geometry and amplification mechanism, which are key aspects of the authors' interpretation of the maser's nature."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 6522,
      "output": 318
    }
  },
  {
    "entry_id": 194,
    "retraction_id": "1603.01872v4",
    "paper_id": "1603.01872v3",
    "retraction_comment": "This paper contains an error: the diagram (13) in the proof of Proposition 6.5 does not strictly commute as claimed. See this https URL for more details. The authors would like to thank [REDACTED-NAME] and [REDACTED-NAME] for finding this error and bringing it to their attention",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unverifiable justification for diagram commutativity in the finite covering case.",
        "Location": "Section 7, Proof of Proposition 7.1, pages 22-23.",
        "Explanation": "The proof relies on checking the commutativity of diagrams (16) and (17). The justification for commutativity is given by describing the maps using formulas on elements (e.g., \"p, f, x1, x2 -> f(x1), p, x2\"). These descriptions are difficult to interpret as maps in the category of spectra and appear inconsistent with the structure of the diagrams, making the claimed commutativity unverifiable. The statement regarding the right-hand region of (17) having the same formula for both branches but not commuting easily is contradictory."
      },
      {
        "Problem": "Unjustified claim of strict commutativity.",
        "Location": "Section 6, Proof of Proposition 6.5, page 20, concerning diagram (13).",
        "Explanation": "The proof claims that diagram (13) commutes as *strict* maps of spectra. This is a strong claim that requires detailed justification based on the specific model category of spectra used and the precise definitions of all maps as strict maps. Without this justification, assuming strict commutativity where only homotopy commutativity might hold is a potential flaw in the argument."
      }
    ],
    "token_usage": {
      "input": 7090,
      "thinking": 4379,
      "output": 307
    }
  },
  {
    "entry_id": 195,
    "retraction_id": "2404.01980v6",
    "paper_id": "2404.01980v5",
    "retraction_comment": "There is a flaw in the proof of Theorem 3.3 that the A at t=0 and A at t=T cannot be guaranteed to be identical, thus the key inequality fails",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Conflation of isoperimetric ratio for a specific curve and the infimum ratio.",
        "Location": "Definition (2.2), Theorem 2.3 (Eq 2.5), Proposition 3.1, Proof of Theorem 3.2",
        "Explanation": "The paper defines IA as the infimum of the isoperimetric ratio over all curves enclosing a given area A (Eq 2.2). However, the evolution equation (Eq 2.5) is for the isoperimetric ratio of a specific curve, parameterized by r. The subsequent arguments, including Proposition 3.1 and the proof of Theorem 3.2, rely on the evolution of the infimum ratio, but incorrectly apply results derived from the PDE (2.5) for the ratio of a specific curve. The evolution of the infimum of a function is not generally described by the evolution equation of the function itself."
      },
      {
        "Problem": "Flawed maximum principle argument in Proposition 3.1.",
        "Location": "Proof of Proposition 3.1",
        "Explanation": "The proof of Proposition 3.1 attempts to derive a lower bound for IA (treated as the ratio for a specific curve in the context of the PDE) by comparing the PDE (Eq 2.5) to an ODE. This comparison implicitly ignores the diffusion term ∂²/∂r² ln IA² or assumes it has a favorable sign, which is not justified. A rigorous application of the maximum principle for parabolic equations requires considering the full PDE and appropriate boundary conditions, which are not discussed or used correctly here. This invalidates the derived lower bound IA² ≥ 1 / (1 + e⁻ᴮᵗ⁻ᶜ)."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 7801,
      "output": 380
    }
  },
  {
    "entry_id": 196,
    "retraction_id": "1105.1572v2",
    "paper_id": "1105.1572v1",
    "retraction_comment": "This was withdrawn because the key distribution figures Figure 1 and 3 in the paper are technically incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misstatement of QKD eavesdropping detection mechanism",
        "Location": "Page 4, Section IV.D, Tentative Attack",
        "Explanation": "The paper states that Bob detects Oscar's interception because he 'will not receive the expected qubits'. In reality, QKD security relies on detecting the perturbation caused by Oscar's measurement, which manifests as an increased Quantum Bit Error Rate (QBER) in the sifted key, not simply a lack of received photons (which can be due to channel loss)."
      },
      {
        "Problem": "Confusing and potentially flawed presentation of intercept-resend attack analysis",
        "Location": "Page 4, Section IV.D, Intercept-resend strategy and Table 2",
        "Explanation": "The explanation and Table 2 describing the correct rate for Bob's measurements under an intercept-resend attack are confusingly presented. The table entries appear to be contributions to the total correct rate rather than conditional probabilities, and the calculation logic is difficult to follow, potentially misrepresenting how the 25% error rate arises from the probabilities of Oscar's and Bob's basis choices. While the final 25% error rate is a known result for this attack, the paper's derivation is unsound as explained."
      },
      {
        "Problem": "Unclear and potentially unsound explanation of the qutrit-based Byzantine Agreement protocol",
        "Location": "Page 8-9, Section VI.A",
        "Explanation": "The description of the Fitzi, Gisin, and Maurer qutrit protocol for Byzantine Agreement is very difficult to understand from the text provided. The explanation of key steps (like step 6 and the subsequent example analysis) is confusing and does not clearly demonstrate how the protocol works or why qutrits are necessary or provide an advantage over classical methods or qubits, making the claim of a quantum solution's superiority poorly supported within the paper's own explanation."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 7837,
      "output": 433
    }
  },
  {
    "entry_id": 197,
    "retraction_id": "2003.05595v3",
    "paper_id": "2003.05595v2",
    "retraction_comment": "Equation (24) was wrong: algebraic cancellations of this type are invalid in general",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 2704,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 198,
    "retraction_id": "1609.00445v2",
    "paper_id": "1609.00445v1",
    "retraction_comment": "Withdrawn due to an error in the numerical code, used to obtain the numerical results",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Claim that Mean-Field Approximation (MFA) results stabilize the spin liquid (SL).",
        "Location": "Introduction, Discussion",
        "Explanation": "MFA is a classical approximation that neglects quantum fluctuations. While it can identify classical ground state degeneracy (a potential precursor), it cannot describe or prove the stability of a quantum spin liquid, which is inherently a quantum state stabilized by fluctuations."
      },
      {
        "Problem": "Claim of exact equivalence to a 2D kagome lattice Hamiltonian at specific parameter values.",
        "Location": "Page 3, \"Second, Heff at J1 = -J0 and D1 = -Do is exactly the same as the spin Hamiltonian of the S=1/2 kagome lattice...\"",
        "Explanation": "The pyrochlore lattice is a 3D structure. Setting specific parameter values in the 3D Hamiltonian does not automatically reduce it to an *exactly* equivalent 2D kagome lattice Hamiltonian. This claim requires a rigorous demonstration of how the inter-layer interactions effectively disappear or decouple, which is not provided."
      },
      {
        "Problem": "Drawing strong conclusions about the stability and competition of complex chiral orders and spin liquid based solely on Mean-Field Approximation.",
        "Location": "Mean-field approximation section, Analytic results, Numerical results, Discussion",
        "Explanation": "MFA is often unreliable for determining the true ground state of highly frustrated spin systems, potentially overestimating ordering tendencies and failing to capture the effects of fluctuations crucial for determining the true ground state, especially when competing orders or spin liquid states are involved. Relying solely on MFA ground states for definitive conclusions about stability and competition is questionable."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 2765,
      "output": 372
    }
  },
  {
    "entry_id": 199,
    "retraction_id": "1810.09697v2",
    "paper_id": "1810.09697v1",
    "retraction_comment": "We get more general results in Theorem 1.1. Corollary 5.27 and Theorem 1.3 are false",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the sum of bi-unitary divisors of an irreducible polynomial raised to an even power.",
        "Location": "Lemma 2.2 i)",
        "Explanation": "The lemma states that for an irreducible polynomial T, σ**(T^2n) = (1 + T)σ(T^n)σ(T^(n-1)). However, based on the definition of bi-unitary divisors (divisors D such that gcd_u(D, S/D) = 1), the bi-unitary divisors of T^2n are only 1 and T^2n. Thus, σ**(T^2n) should be 1 + T^2n. This fundamental error propagates through many subsequent results."
      },
      {
        "Problem": "Incorrect formula for the sum of bi-unitary divisors of an irreducible polynomial raised to a power greater than 1.",
        "Location": "Lemma 5.6 iii), Lemma 5.7 iii)",
        "Explanation": "The paper uses the formula σ**(Q^d) = (1 + Q)^d for an irreducible polynomial Q and d > 1. However, for an irreducible polynomial Q, the bi-unitary divisors of Q^d are only 1 and Q^d. Thus, σ**(Q^d) should be 1 + Q^d. This error invalidates derivations relying on this formula."
      },
      {
        "Problem": "Incorrect application or factorization of the sum of divisors function σ.",
        "Location": "Lemma 5.9 ii), Lemma 5.11",
        "Explanation": "The proofs of these lemmas rely on incorrect factorizations or equalities involving σ(x^2m) and σ(P^2m). For example, σ(x^2m) is the sum 1 + x + ... + x^2m, which is not generally equal to expressions like x(x+1)^(2v-1) * (stuff) as implied in Lemma 5.9 ii). Similarly, σ(P^2m) = 1 + P + ... + P^2m is not equal to P * (something) as implied in Lemma 5.11. These errors undermine the derivations in Section 5."
      },
      {
        "Problem": "The theoretical basis for computational search is flawed.",
        "Location": "Sections 3, 4, 5 (e.g., 'By direct computations', 'By Maple computations')",
        "Explanation": "The paper states that the final lists of polynomials are obtained through direct or Maple computations. However, the constraints and possible forms of the polynomials and their exponents used as input for these computations are derived from the preceding lemmas and corollaries, which contain critical errors regarding the formulas for σ** and the application of σ. Therefore, the computational results are based on incorrect theoretical premises and cannot be considered reliable."
      },
      {
        "Problem": "Derivations rely on results based on incorrect σ** formulas.",
        "Location": "Corollary 2.3, Corollary 2.4, Lemma 3.2, Corollary 3.3, Lemma 4.1, Lemmas 5.1, 5.2, 5.7, Lemma 5.12, etc.",
        "Explanation": "Many subsequent lemmas and corollaries build upon the incorrect formulas for σ** given in Lemma 2.2 and Lemma 5.6/5.7. For instance, Lemma 4.1, crucial for Theorem 1.2, relies on Corollary 2.4, which relies on Lemma 2.2. The entire structure of the proofs for Theorems 1.1, 1.2, and 1.3 is compromised by the propagation of these initial errors."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 5241,
      "output": 828
    }
  },
  {
    "entry_id": 200,
    "retraction_id": "1309.2621v7",
    "paper_id": "1309.2621v6",
    "retraction_comment": "This paper was withdrawn because the author did not prove that the function lambda_0(t) = gamma(t) on page 14 is strictly increasing. This is why we cannot make the crucial time change that proves the main theorem about infinite dimensional SRBM",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Direct application of a finite-dimensional existence theorem for controlled martingale problems to the infinite-dimensional setting.",
        "Location": "Page 9, Proof of Lemma 2.3",
        "Explanation": "The proof of Lemma 2.3 relies on Theorem 4.1 from Stockbridge (1990) [47] to assert the existence of a solution to a controlled martingale problem. However, [47] deals with finite-dimensional problems. Applying this theorem directly to an infinite-dimensional state space (R^∞) and processes without justification or reference to an infinite-dimensional version of this result is a critical gap that invalidates the construction of the stationary solution."
      },
      {
        "Problem": "Lack of rigorous justification for applying the Burkholder-Davis-Gundy inequality in infinite dimensions.",
        "Location": "Page 12, Proof of Theorem 2.1",
        "Explanation": "The proof of the compact containment condition for the sequence of processes (ξ^(n)) uses the Burkholder-Davis-Gundy inequality to bound moments of an infinite-dimensional martingale M^(n). Standard versions of this inequality, including the referenced Theorem 3.28 in Karatzas and Shreve (1991) [36], apply to finite-dimensional martingales. Its application in the infinite-dimensional setting requires justification, which is not provided, potentially invalidating the compact containment argument."
      },
      {
        "Problem": "Insufficient justification for the convergence of infinite sums and integrals in the Basic Adjoint Relationship proof.",
        "Location": "Pages 16-18, Proof of Theorem 2.2",
        "Explanation": "The adaptation of the Basic Adjoint Relationship proof from finite to infinite dimensions involves integration by parts and manipulating infinite sums and integrals. While the use of test functions depending on finitely many variables simplifies some parts, the convergence and interchange of limits and integrals for the infinite sums arising from the reflection term (e.g., on page 17) are not fully justified, which is necessary for the argument to be rigorous in the infinite-dimensional setting."
      },
      {
        "Problem": "The equivalence between the CBP condition (3) and the SRBM condition Rb = -μ is stated but not proven.",
        "Location": "Page 20, Proof of Theorem 1.1",
        "Explanation": "Theorem 1.1 concludes that the existence of a sequence b satisfying condition (3) implies the existence of the stated stationary distribution. This relies on the claim that condition (3) is equivalent to the SRBM parameters (19), (20) satisfying Rb = -μ for some b > 0, which is required by Theorem 2.2. This crucial equivalence is stated without proof, leaving a gap in the logical flow from the CBP conditions to the SRBM stationary distribution."
      },
      {
        "Problem": "The proof of the equivalence of skew-symmetry conditions in Lemma 3.3 is incomplete.",
        "Location": "Page 20, Lemma 3.3 and its proof",
        "Explanation": "Lemma 3.3 claims that the skew-symmetry condition (2) for CBP is equivalent to RD + DRT = 2A for the SRBM parameters (19), (20). The proof verifies this equality for specific index cases (i=j, |i-j|>=2, i=j+1). While these cover the structure of the given R and A matrices, the proof does not explicitly state or verify that these are the only non-zero entries or that the equivalence holds for all relevant indices (i, j >= 1 or k in Z), leaving the proof of equivalence incomplete."
      }
    ],
    "token_usage": {
      "input": 7348,
      "thinking": 3658,
      "output": 810
    }
  },
  {
    "entry_id": 201,
    "retraction_id": "0811.0505v2",
    "paper_id": "0811.0505v1",
    "retraction_comment": "This paper has been withdrawn by the author since there were errors in the calculus of the defect coefficient in Page 11. The corrected calculus gives actually zero which do not lead to a contradiction on the continuity of the flow-map of the Benjamin-Ono equation. The author warmly thank [REDACTED-NAME] G_rard for having pointing out this error to him",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of the limit of the L² norm of the gauge transform at initial time.",
        "Location": "Lemma 4.2, page 10-11",
        "Explanation": "The proof calculates the limit of the L² norm of P₊(u₀,ₙ e⁻¹ᴷ₀,ₙ²) instead of the L² norm of w₀,ₙ = ∂ₓ P₊(u₀,ₙ e⁻¹ᴷ₀,ₙ²). The missing spatial derivative (∂ₓ) operator in the calculation on the Fourier side corresponds to multiplication by ik, which significantly changes the behavior of the sum and likely causes the limit to diverge, invalidating the calculation of the defect term a(0)."
      },
      {
        "Problem": "Incorrect calculation of the limit of the L² norm of the initial data sequence.",
        "Location": "Equation (24), page 10",
        "Explanation": "The calculation of the limit of the L² norm of the initial data sequence u₀,ₙ = ũ₀,ₙ + cos(nx) as n → ∞ appears incorrect. The stated limit, ||u₀||_L²²(ℤ) + 2π, differs from the expected limit, ||u₀||_L²²(ℤ) + π, based on the L² norm definition and the properties of Fourier series. This error affects the calculation of the defect term α²."
      },
      {
        "Problem": "Inconsistent final contradiction equation.",
        "Location": "Page 11, last equation",
        "Explanation": "The final equation derived to show a contradiction by equating the calculated defect term at t=0 to -i/(4π) does not hold. Substituting the intermediate results from equations (24) and (25) into the defect term expression leads to an inconsistent equation (-i/4 = -i/(4π) or -3i/(16π) = -i/(4π), depending on the interpretation of the 1/(2π) factor), indicating a fundamental error in the derivation of the perturbed equation (23) or the calculation of the defect terms."
      }
    ],
    "token_usage": {
      "input": 8380,
      "thinking": 12305,
      "output": 704
    }
  },
  {
    "entry_id": 202,
    "retraction_id": "1404.7350v2",
    "paper_id": "1404.7350v1",
    "retraction_comment": "The paper has been withdrawn by the author since Lemma 3.27 is wrong. The author thanks [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 2.21",
        "Location": "Page 15, Proof of Lemma 2.21",
        "Explanation": "The lemma claims that if R1 and R2 are selective and nearly coherent, then (R1, R2) is homogenic, which implies that for any X in R1 & R2, there exist A in R1 and B in R2 such that A x B intersect Delta2 is a subset of X. The proof attempts to show this by constructing a specific set B in R2 (using the Ramsey property and the isomorphism f) and showing that for a specific A'' in R1, A'' x B intersect Delta2 is a subset of X. This does not prove the lemma as stated, which requires the property to hold for *any* B in R2. This flaw undermines subsequent results (Corollary 2.22, Lemmas 2.24-2.28, Lemma 2.31) that are crucial for the construction of the Milliken-Taylor ultrafilter in Theorem 2.12/2.13, which is then used in the main iterated forcing construction."
      }
    ],
    "token_usage": {
      "input": 11734,
      "thinking": 7137,
      "output": 262
    }
  },
  {
    "entry_id": 203,
    "retraction_id": "1612.01576v2",
    "paper_id": "1612.01576v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error in the inductive proof of Theorem 3.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of inductive hypothesis in Theorem 3.1 proof.",
        "Location": "Page 8-9, Proof of Theorem 3.1",
        "Explanation": "In the inductive step, the proof bounds Pr[W_T(v) ≠ Z_T(v)] by relating the number of updates within the sub-box B_v(r) to the inductive hypothesis on the coupling time of the chain restricted to B_v(r). The number of updates is T|B_v(r)|/n. The inductive hypothesis is on the coupling time T_ID(B_v(r)) of the chain running on the subgraph B_v(r). The paper claims T|B_v(r)|/n is sufficient for mixing based on T_ID(B_v(r)), using the inequality (log n)² ≥ (log |B_v(r)|)² log₄(40n). However, |B_v(r)| is roughly (log n)²ᵈ, making this inequality false for large n. The number of updates is insufficient according to the inductive bound."
      },
      {
        "Problem": "Application of Glauber dynamics lemma to systematic scan dynamics.",
        "Location": "Page 11, Proof of Lemma 4.3",
        "Explanation": "The proof of Lemma 4.3, which establishes the coupling time for systematic scan dynamics (Theorem 4.1), applies Lemma 3.2. Lemma 3.2 is a disagreement percolation bound specifically derived for Glauber dynamics, which uses random vertex updates. Systematic scan dynamics updates vertices in a fixed order, leading to different disagreement propagation behavior. Applying a result for random-scan dynamics to systematic-scan dynamics without justification that the bound holds in this different setting is unsound."
      },
      {
        "Problem": "Incorrect spectral gap comparison inequality in Lemma 5.5.",
        "Location": "Page 18, Proof of Lemma 5.5",
        "Explanation": "The proof of Lemma 5.5, which is crucial for Theorem 5.1 (Swendsen-Wang dynamics), claims λ(P₁³) ≥ λ(Poe) based on the inequality (f, P₁³f)π ≤ (f, PoPoPef)π + (7/8)(f, f)π. This inequality is not justified by the definitions of P₁ and Poe, and appears incorrect. P₁³ is the cube of the transition matrix P₁ = (Pe+Po)/2, and its expansion contains multiple terms, not just PoPoPe and a multiple of the identity operator, making this comparison invalid."
      },
      {
        "Problem": "Incorrect relationship between spectral gaps of Poe and Peoe.",
        "Location": "Page 18, Proof of Lemma 5.5",
        "Explanation": "The proof of Lemma 5.5 states that λ(Poe) = λ(Peoe). This is incorrect. Poe is defined as a lazy version of Peoe (Poe = (1/8)Peoe + (7/8)I). For a lazy Markov chain P' = αP + (1-α)I, the spectral gap is related by λ(P') = αλ(P). Therefore, λ(Poe) = (1/8)λ(Peoe). This error affects the final conclusion that λ(Psw) = Ω(1)."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 7037,
      "output": 753
    }
  },
  {
    "entry_id": 204,
    "retraction_id": "1501.05036v2",
    "paper_id": "1501.05036v1",
    "retraction_comment": "Eq. (9) only implies correlation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The main theoretical result relies on an unproven hypothesis about LCS length decay.",
        "Location": "Hypothesis (H) on Page 8, Proof of Theorem 1 on Page 10.",
        "Explanation": "Theorem 1 states that the path-averaged scalar converges to a uniform value along a hyperbolic LCS for long integration times. The proof of this theorem directly depends on Hypothesis (H), which assumes the length of a hyperbolic LCS decays exponentially in time. This is a strong assumption that is not rigorously proven in the paper, and its general validity for LCSs in arbitrary unsteady, area-preserving flows is not clearly established by the cited literature. If this hypothesis is not generally true, the proof of Theorem 1 is invalid, undermining the theoretical basis for the main conclusion that LCSs align with contours of path-averaged scalars."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 6067,
      "output": 187
    }
  },
  {
    "entry_id": 205,
    "retraction_id": "1208.6493v2",
    "paper_id": "1208.6493v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in a claim about singular supports in the proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 1672,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 206,
    "retraction_id": "1909.06350v2",
    "paper_id": "1909.06350v1",
    "retraction_comment": "The proof contained an error in the definition of the coupling in (4.8) that the authors currently cannot fix. The authors thank [REDACTED-NAME] for pointing this error out to them",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Error in error estimation for stochastic term E1 in Lemma 5.2",
        "Location": "Page 17, Proof of Lemma 5.2, bound on E1",
        "Explanation": "The calculation of the bound for the stochastic term E1 in Lemma 5.2, which involves a stochastic integral and the BDG inequality, appears to lead to an error term that grows with n (positive power of n) rather than vanishing as n approaches infinity. This would invalidate Lemma 5.2 and subsequent results that rely on it, including Lemma 5.3, Lemma 4.2, Proposition 4.1, and the main Theorem 2.5."
      },
      {
        "Problem": "Unsubstantiated correction of prior work on small singular value universality",
        "Location": "Page 7, discussion of [11, Theorem 3.2] and Proposition 2.9",
        "Explanation": "The proof relies on Proposition 2.9, which states the universality of the smallest singular values and is presented as a corrected version of a result from [11]. The paper acknowledges imprecisions in the original statement in [11] but does not provide details on how these imprecisions were remedied in Proposition 2.9. This leaves a critical part of the argument, specifically the handling of the very small η regime (term I_3 in the integral splitting), unsubstantiated."
      },
      {
        "Problem": "Potential misapplication of results from [15] for the isotropic local law",
        "Location": "Appendix A, Proof of Proposition 2.6, reliance on [15, Theorem 4.1]",
        "Explanation": "The proof of the isotropic local law for the Hermitized matrix H (Proposition 2.6) relies on applying results from [15] concerning random matrices with correlated entries. The matrix H has a specific block structure with large zero blocks, which implies correlations and non-flatness. While the paper claims that [15, Theorem 4.1] applies without requiring flatness for the error term D, the correctness of this application to the specific structure of H and the subsequent bootstrap argument requires careful verification and represents a potential point of failure in the proof of Proposition 2.6, which is a fundamental input for later steps."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 10998,
      "output": 512
    }
  },
  {
    "entry_id": 207,
    "retraction_id": "0904.3281v2",
    "paper_id": "0904.3281v1",
    "retraction_comment": "The integrality statement is false. See the publication \"A norm compatible system of Galois cohomology classes for GSp(4)\" of the author for a correct statement and proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradiction between constructed classes and weight zero property",
        "Location": "Page 12, Corollary 3.3 and spectral sequence argument",
        "Explanation": "The paper constructs Eisenstein classes E^{k,k'}_N in H^4(S(N), W^{k,k'}) which are invariant under the action of the Galois group G_N = Gal(Q(zeta_N)/Q). The spectral sequence E^{p,q} = H^p(G_N, H^q(S(N), W^{k,k'})) => H^{p+q}(S(N), W^{k,k'}) implies that the G_N-invariant part of H^4(S(N), W^{k,k'}) is given by the term E_2^{0,4} = H^0(G_N, H^4(S(N), W^{k,k'})). The paper cites [19] Lem. 2.8, which states that R^4 s_{N*} W^{k,k'} has no weight zero. In this context, this implies H^0(G_N, H^4(S(N), W^{k,k'})) = 0. If the G_N-invariant part of H^4(S(N), W^{k,k'}) is zero, then any G_N-invariant class in this space, including the constructed Eisenstein class E^{k,k'}_N, must be zero. This contradicts the premise that these are non-zero classes forming a basis for further study and the construction of a p-adic L-function."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 9757,
      "output": 371
    }
  },
  {
    "entry_id": 208,
    "retraction_id": "1705.03737v2",
    "paper_id": "1705.03737v1",
    "retraction_comment": "This paper contains a flaw that the proposed methods were overfitted thus the experimental results were not suitable. At this point, we do not want to update this article bu are developing a quite new approache where the authors are different from this paper,, and the title of our paper will be changed. 8 pages, 6 figures",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unfair comparison of computational efficiency with state-of-the-art",
        "Location": "Section 6.3, Table 5",
        "Explanation": "The paper compares the speed (fps) and memory consumption (#Param) of their proposed methods (implemented in Matlab/MatConvNet) with a re-implementation of the state-of-the-art Deep3D (originally in Python/MXNet) also in Matlab/MatConvNet. Performance can vary significantly between different deep learning frameworks and specific implementations, making this comparison potentially misleading and the claims of efficiency gains over the original Deep3D unsound."
      },
      {
        "Problem": "Potential lack of diversity and bias in the training dataset",
        "Location": "Section 4, Section 5.1",
        "Explanation": "The dataset consists of 2 million frames derived from only 27 non-animated stereoscopic movies. While the total number of frames is large, the limited number of source movies raises concerns about the diversity of visual content, styles, and scenes. Training on such a dataset might lead to a model that is biased towards the characteristics of these specific movies and may not generalize well to other types of stereoscopic content."
      },
      {
        "Problem": "Limitation to a fixed, discrete disparity range",
        "Location": "Section 3 (DeepView_ren architecture, Fig 2, Eq 3), Section 5.1 (Implementation details)",
        "Explanation": "The proposed methods predict disparity from a fixed, discrete set of values (Ω = {-15, ..., 17}). This limits the network's ability to handle scenes with disparity ranges outside this interval or to predict continuous disparity values, potentially reducing accuracy and applicability for diverse real-world scenarios with varying depth complexities."
      },
      {
        "Problem": "Subjective evaluation does not include the DeepView_ren architecture",
        "Location": "Section 6.2",
        "Explanation": "The subjective quality assessment compares only DeepView_dec and Deep3D. DeepView_ren, which is presented as a key contribution offering significant speed and memory advantages, is not included in the subjective study. This makes it difficult to assess the perceived quality trade-off associated with the efficiency gains of DeepView_ren compared to both DeepView_dec and Deep3D."
      },
      {
        "Problem": "Spatial scalability is demonstrated only for DeepView_rec, not DeepView_ren",
        "Location": "Section 5.3",
        "Explanation": "The paper claims spatial scalability for 'Our architectures' (plural) but the experimental validation in Section 5.3 and Figure 5 is only presented for DeepView_rec. While the FCN design principle supports scalability, the specific architecture of DeepView_ren, including its rendering network, is not explicitly shown to maintain performance across different input resolutions."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 3487,
      "output": 634
    }
  },
  {
    "entry_id": 209,
    "retraction_id": "2307.01627v2",
    "paper_id": "2307.01627v1",
    "retraction_comment": "The proof of Theorem 2.6 is incorrect. Without this theorem the main claim of the paper becomes unproven",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and use of tower components",
        "Location": "Section 3, Proof setup and steps (2), (4)",
        "Explanation": "The proof sets up the application of supporting theorems by defining objects V, P, Q, and X. These definitions mix sections (Pi = Si/Ti) and subgroups (Si) from the A-tower definition in Remark 3.2 (e.g., V=Ph, P=Ph-1, but Q=Sh-2). This inconsistent notation makes the subsequent arguments, which rely on these objects having specific group-theoretic properties or being subgroups/sections in particular contexts (like applying Theorem 2.6), logically unsound."
      },
      {
        "Problem": "Incorrect application of Theorem 2.6",
        "Location": "Section 3, Step (4) of the proof",
        "Explanation": "Theorem 2.6 is applied to the action of XA on V. For this theorem, V is the module, X is the group G, and P and Q are subgroups of X satisfying certain conditions. The proof identifies V with Ph (a section of G), X with S1...Sh-2 (a subgroup of G), P with Ph-1 (a section of G), and Q with Sh-2 (a subgroup of G). However, Ph-1 is a section of G, not a subgroup of X = S1...Sh-2. Therefore, the conditions for applying Theorem 2.6 are not met, and the conclusion drawn from it is invalid."
      },
      {
        "Problem": "Flawed argument in Step (2) regarding the structure of Q and P",
        "Location": "Section 3, Step (2) of the proof",
        "Explanation": "The proof claims that the Frattini factor group of Q/Q0 is A-irreducible under the action of S1...Sh-3. This statement, central to the argument in Step (2), is not justified by the properties of the A-tower (Remark 3.2) or standard group theory results. The subsequent deductions regarding the structure of Q and P based on this claim are therefore unfounded, undermining a key part of the proof."
      },
      {
        "Problem": "Unclear and potentially incorrect inductive argument structure",
        "Location": "Section 3, Step (2) and the final step of the proof",
        "Explanation": "The proof appears to attempt an inductive argument on the nilpotent length h, suggested by the inequality used in Step (2) involving a sequence of length h-2. However, the base case and the precise inductive hypothesis are not clearly stated. Furthermore, the sequence of sections (Ph-2/Phi(Ph-2), Ph-3, ..., P1) used in the inductive step in Step (2) is not shown to form a tower or series that fits the definition required for applying the induction hypothesis or the definition of c(...; A). The final step's derivation of the concluding inequality also seems to rely on an unstated and potentially incorrect inductive assumption."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 8801,
      "output": 674
    }
  },
  {
    "entry_id": 210,
    "retraction_id": "1907.08721v2",
    "paper_id": "1907.08721v1",
    "retraction_comment": "A wrong fact on Hochschild homology was used in the proof of the main result (section 2, Theorem 2.0.4)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of the main result (h^(0,p) invariance)",
        "Location": "Corollary 1.0.3, page 3 and page 9",
        "Explanation": "The proof of Corollary 1.0.3 claims that the equality h^(0,p)(X1) = h^(0,p)(X2) for all p follows directly from Theorem 3.0.2, which states that H*(X1, ω_X1) is isomorphic to H*(X2, ω_X2) as graded vector spaces. Theorem 3.0.2 implies dim H^k(X1, ω_X1) = dim H^k(X2, ω_X2) for all k. H^k(X, ω_X) = H^k(X, Ω^{dim X}), and its dimension is not equal to h^(0,k)(X) in general. The stated deduction is incorrect and invalidates the main conclusion."
      },
      {
        "Problem": "Unjustified identification of dual homological units under derived equivalence",
        "Location": "Proof of Theorem 3.0.2, page 8",
        "Explanation": "The proof of Theorem 3.0.2 relies on the claim that the dual homological unit for D^b(X1) with respect to the rank function rk_2 is isomorphic to H*(X2, ω_X2). The rank function rk_2 on D^b(X1) is defined via the derived equivalence Φ_E and the rank function rk_{O_X2} on D^b(X2). The paper cites Remark 2.0.3(2) for this identification, but this remark only identifies H*(X, ω_X) as the dual homological unit for D^b(X) with respect to the rank function rk_{O_X}. It does not establish that the dual homological unit is preserved under derived equivalence in the manner used here. This is a critical gap in the proof of Theorem 3.0.2."
      },
      {
        "Problem": "Inconsistent definition of the dual homological unit",
        "Location": "Definition 2.0.2, page 4",
        "Explanation": "The dual homological unit I_X is defined as a 'graded algebra', but it is later described as a 'graded sub-vector space of the Hochschild homology' (page 3) and the embedding into Hochschild homology is stated as a 'graded vector spaces injective morphism' (Remark 2.0.3(3), page 5). Hochschild homology is a graded vector space, not generally an algebra. This inconsistency makes the definition unclear and potentially unsound if the algebra structure is required for the definition or subsequent arguments, as HH.(X) does not generally possess a compatible algebra structure."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 11407,
      "output": 636
    }
  },
  {
    "entry_id": 211,
    "retraction_id": "1608.07104v2",
    "paper_id": "1608.07104v1",
    "retraction_comment": "This paper has been withdrawn due to errors in the crucial estimates in Lemma 1 and Theorem 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of a key lemma regarding function space norms.",
        "Location": "Page 5, Lemma 1 Proof",
        "Explanation": "The proof of the estimate S_k <= 4 for the case kappa >= 4s relies on the inequality |2s(k1 + ik2) + is| < 2sk, which is generally false for k in Z^n. This undermines the definition and properties of the function spaces X_s^b used throughout the paper."
      },
      {
        "Problem": "Incorrect statement of the mapping properties of the right inverse operator G_s.",
        "Location": "Page 6, Theorem 3",
        "Explanation": "Theorem 3 states that G_s is an isometric right inverse from X_s^{1/2} to X_s^{1/2}. Based on the definition of the norms, G_s is an isometry from X_s^{-1/2} to X_s^{1/2}. This fundamental misunderstanding of the operator's domain and range affects the subsequent construction of solutions via Neumann series."
      },
      {
        "Problem": "Incorrect formulation of the equation for the remainder term in CGO construction.",
        "Location": "Page 7, Section 3",
        "Explanation": "The paper derives A_s r + qr = -q and states that r can be obtained by solving (I + qG_s) r = -q. The correct equation for r should be (I + G_s q) r = -G_s q, where G_s is a right inverse for A_s. The operator qG_s is different from G_s q, and the subsequent contraction argument relies on the properties of the incorrect operator."
      },
      {
        "Problem": "Assumption of compact support for the potential in the CGO existence theorem.",
        "Location": "Page 8, Theorem 5",
        "Explanation": "Theorem 5, which guarantees the existence of CGO solutions, assumes that the potential q is compactly supported. The potential q = sigma^{-1/2} Delta sigma^{1/2} derived from a W^{1,p} conductivity in the Calderón problem is generally not compactly supported unless the conductivity is constant near the boundary, which is not the setting of the inverse problem."
      },
      {
        "Problem": "Flawed derivation of the identity linking the Dirichlet-to-Neumann map difference to the potential difference.",
        "Location": "Page 12, Step 4",
        "Explanation": "The derivation of equation (11), (Lambda_1 - Lambda_2) v1|Gamma, v2|Gamma = (q2 - q1, u1 u2), appears incorrect. The standard Green's identity for the difference of DN maps requires the solutions v1 and v2 to correspond to the *same* boundary data under the respective operators, which is not the case for the chosen solutions v_j = p_j^{-1} u_j where u_j are CGO solutions."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 11089,
      "output": 681
    }
  },
  {
    "entry_id": 212,
    "retraction_id": "2401.17112v2",
    "paper_id": "2401.17112v1",
    "retraction_comment": "Bug. Lemma 1 is incorrect. The lemma needs the sets to be closed under subtraction which they are not",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Theorem Statement and Application",
        "Location": "Theorem 2, page 2",
        "Explanation": "Theorem 2 states that for H-independent tuples v1, ..., vm from R^n, the product of the sizes of the coefficient sets, Product(|Si|), is bounded by |R|^n. This statement is dimensionally incorrect and not a standard result in linear algebra over rings. The bound 5^r * 4^t <= 6^n used in the proof of Theorem 3 is derived from the assumption that the map from coefficient tuples (ai in Si) to linear combinations is injective, which requires a stronger independence property (linear independence over Si - Si) than H-independence (linear independence over Si)."
      },
      {
        "Problem": "Unjustified Bound Derivation",
        "Location": "Proof of Theorem 3, page 3, line starting 'Hence by the bound...'",
        "Explanation": "The derivation of the bound |Su|^r|Sv|^t <= |Z6|^n relies on the argument that the set of linear combinations { Sum(ai ui) + Sum(bj vj) | ai in Su, bj in Sv } has size |Su|^r|Sv|^t. This is true if and only if the map from coefficient tuples to linear combinations is injective. Injectivity requires that if a linear combination is zero, all coefficients must be zero, where the coefficients are taken from Su - Su and Sv - Sv. Since Su - Su = Z6 and Sv - Sv = Z6, this requires the vectors {u1, ..., ur, v1, ..., vt} to be linearly independent over Z6."
      },
      {
        "Problem": "Vectors are Not Linearly Independent over Z6",
        "Location": "Proof of Theorem 3, definition of vectors v_j, page 2",
        "Explanation": "The vectors v_j correspond to sets with sizes congruent to 3 mod 6. For any such vector v_j, 2 * v_j = 2 * |A_j| mod 6 = 2 * 3 mod 6 = 0 mod 6. Since v_j is not the zero vector (unless the universe size n=0), this shows that the vectors v_j are not linearly independent over Z6. This contradicts the requirement of linear independence over Z6 needed to justify the bound |Su|^r|Sv|^t <= |Z6|^n used in the proof."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 12185,
      "output": 550
    }
  },
  {
    "entry_id": 213,
    "retraction_id": "1710.01525v2",
    "paper_id": "1710.01525v1",
    "retraction_comment": "We can not prove Lemma 1 in Sect 2.4, and Terras did not prove it either, we misunderstood Terras's result here. Thus our proof about Theorem 2 is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Theorem 2 is false for a class of integers.",
        "Location": "Page 3, Theorem 2",
        "Explanation": "The theorem states that for any integer n > 1 with finite Glide, the inequality 2^(E(n)-1) < 3^O(n) < 2^E(n) must hold. However, for integers of the form n = 2^m where m >= 1, the sequence is (2^m, 2^(m-1), ..., 1). The Glide G(n) = m, O(n) = 0, and E(n) = m. Substituting these values into the inequality gives 2^(m-1) < 3^0 < 2^m, which simplifies to 2^(m-1) < 1 < 2^m. This inequality is false for all m >= 1 (e.g., for m=1, 1 < 1 < 2 is false; for m=2, 2 < 1 < 4 is false; etc.). Since the theorem is stated for *any* n > 1 with finite Glide, and it fails for powers of 2, the theorem is false."
      },
      {
        "Problem": "Lemma 2 is false for a class of integers.",
        "Location": "Page 6, Lemma 2",
        "Explanation": "Lemma 2 states that for any integer n > 1 with finite Glide and s_G(n) = K, the inequality n/2 < K < n must hold. However, for integers of the form n = 2^m where m >= 1, the sequence is (2^m, 2^(m-1), ..., 1). The Glide G(n) = m and K = s_m = 1. Substituting these values into the inequality gives 2^m / 2 < 1 < 2^m, which simplifies to 2^(m-1) < 1 < 2^m. This inequality is false for all m >= 1 (as shown in the explanation for Problem 1). Since the lemma is stated for *any* n > 1 with finite Glide, and it fails for powers of 2, the lemma is false."
      },
      {
        "Problem": "The proof of Lemma 2 is flawed.",
        "Location": "Page 6, Proof of Lemma 2",
        "Explanation": "The proof attempts to show K > n/2 by stating 'especially, there must be s_{G(n)-1} = 2K > n, since s_G(n) = K = s_{G(n)-1}/2'. This step assumes that the last step in the sequence (from s_{G(n)-1} to s_G(n)) is an even step (division by 2). However, the last step could be an odd step (resulting from (3*s_{G(n)-1}+1)/2). The proof is incomplete as it only considers one case for the last step. While the conclusion K > n/2 is true for n > 1, the provided proof is unsound."
      },
      {
        "Problem": "The proof of Lemma 3 relies on an incorrect inequality.",
        "Location": "Page 6, Proof of Lemma 3",
        "Explanation": "The proof of Lemma 3 attempts to bound the remainder term Res(n) by summing individual terms. It claims that 'Su[i] > n and K < n imply that 3^(O(n)-1-i) / 2^lambda(i) < 1/3' for each term in the sum. This inequality is not generally true. For example, with n=3, G(3)=2, O(3)=1, E(3)=1, u=(0), lambda(0)=1. The term for i=0 is 3^(1-1-0) / 2^lambda(0) = 3^0 / 2^1 = 1/2. 1/2 is not less than 1/3. Since the proof of the bound on Res(n) relies on this false premise, the proof is invalid."
      },
      {
        "Problem": "The bound on Res(n) stated in Lemma 3 is incorrect.",
        "Location": "Page 6, Lemma 3 and its proof",
        "Explanation": "Lemma 3 claims that Res(n) < O(n)/3. This bound is derived in the proof by summing the terms 3^(O(n)-1-i) / 2^lambda(i) and incorrectly asserting that each term is less than 1/3. As shown in the explanation for Problem 4, the inequality 3^(O(n)-1-i) / 2^lambda(i) < 1/3 is false for n=3, i=0. For n=3, Res(3) = 1/2 and O(3)/3 = 1/3. Since 1/2 is not less than 1/3, the claimed bound Res(n) < O(n)/3 is false."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 15817,
      "output": 1152
    }
  },
  {
    "entry_id": 214,
    "retraction_id": "2011.05544v2",
    "paper_id": "2011.05544v1",
    "retraction_comment": "Comments are welcome. There is a problem with the Theorem 4.7. Which could be fixed by taking double duals (category of reflexive sheaves) but it ruins the double deformation construction",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect group law claimed for the fiber term",
        "Location": "Proposition 3.3, page 5",
        "Explanation": "The proof claims that the group operation in the fiber term π₀(|d↔ K((Bq)ⁿVect(X × Aᵈ), Gᵐ¹)|) is composition of automorphisms, i.e., [(b, Θ₁)] + [(b, Θ₂)] = [(b, Θ₁ ◦ Θ₂)]. This is generally false; the operation in K₁-like groups is related to direct sum, [(b, Θ₁)] + [(b, Θ₂)] = [(b ⊕ b, Θ₁ ⊕ Θ₂)]. The provided 3x3 matrix argument only demonstrates additivity for direct sums, not the composition rule. This invalidates Corollary 3.5, which claims the fiber term is torsion."
      },
      {
        "Problem": "Unjustified claim that double deformation CA,B consists of vector bundles",
        "Location": "Proposition 4.14, page 9-10",
        "Explanation": "The construction of CA,B is a pushout in the category of binary complexes of coherent sheaves (BⁿCoh). The proof claims that the graded objects of CA,B are vector bundles. This is not generally true for pushouts of vector bundles. The justification relies on extending from an open subset using Theorem 4.7 and Corollary 4.10, but the argument is circular, using Remark 4.13 (which assumes the vector bundle property on the open set) to prove the vector bundle property."
      },
      {
        "Problem": "Unjustified claim that double deformation CA,B is acyclic",
        "Location": "Proposition 4.14, page 10",
        "Explanation": "The proof claims that the acyclicity of the binary complex CA,B follows from extending a splitting from an open subset (where it is claimed to split) to the whole space X × A². This is a misapplication of extension theorems for vector bundles (Theorem 4.7, Corollary 4.10), which apply to objects (vector bundles or coherent sheaves), not to splittings of complexes. A complex being split on an open set does not imply it is acyclic globally."
      },
      {
        "Problem": "Misapplication of Lemma 4.4",
        "Location": "Proposition 4.15, page 10",
        "Explanation": "Lemma 4.4 states that extended objects in (Bq)ⁿVect(X × A¹) have trivial class in the group π₀(|d↔ K((Bq)ⁿVect(X × Aᵈ), Gᵐ¹)|) (the fiber term). The proof of Proposition 4.15 applies this lemma to claim that extended objects have trivial class in the group π₁(|d→ K®((Bq)ⁿVect(X × Aᵈ))|) (the base term). These are different groups arising from different parts of the fibration sequence, and the triviality in one does not imply triviality in the other."
      },
      {
        "Problem": "Flawed inductive argument based on 'rank'",
        "Location": "Proposition 4.15, page 10",
        "Explanation": "The proof attempts an inductive argument using the double deformation CA,A to show that elements [α] - [β] are trivial. It claims the process reduces the problem to differences of objects with decreasing 'rank'. The notion of 'rank' for a binary complex is not standard, and the argument that this process terminates with rank zero bundles whose class is zero is not rigorously established. This step relies heavily on the correctness of Proposition 4.14, which is itself questionable."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 6623,
      "output": 828
    }
  },
  {
    "entry_id": 215,
    "retraction_id": "1301.3486v2",
    "paper_id": "1301.3486v1",
    "retraction_comment": "Withdrawn because certain correction terms that arise in the Lace expansion of Section 3 were not identified and taken into account in the subsequent derivation. A new version with these correction terms included is in preparation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Deferred proof of Lemma 3.6 (Self-repellence for backbone-pivotal bonds).",
        "Location": "Page 19, Lemma 3.6",
        "Explanation": "Lemma 3.6 is crucial for proving tightness (Proposition 2.2), which is a necessary condition for the main scaling limit result (Theorem 1.1). The proof is omitted and described as a 'straightforward iterative application' of previous results. Iterative arguments, especially involving bounds, can be complex and non-trivial, and omitting the details makes independent verification difficult."
      },
      {
        "Problem": "Deferred proof of significant parts of Proposition 4.3 (Bounds on spatial fractional derivatives).",
        "Location": "Page 27, Proposition 4.3; Supplementary Material Section D",
        "Explanation": "Proposition 4.3 provides essential bounds on the spatial moments of the lace expansion coefficients, which are used in the proofs of several key results supporting the main theorems (e.g., Theorem 1.5, Theorem 1.6, Proposition 2.1, Lemma 8.1). The supplementary material provides only an outline for parts of the proof (ii)-(iv), deferring significant steps to external results ([2]) without showing explicit derivations in the context of this paper's specific setup. This reliance on external results without full exposition is a potential source of error if their application here is not perfectly valid or sufficient."
      },
      {
        "Problem": "Concise derivation of fundamental graphical bounds (Supplementary C.1).",
        "Location": "Supplementary Material Section C.1",
        "Explanation": "The graphical bounds (C)-(Z) derived in this section are foundational for proving the properties of the lace expansion coefficients (Lemmas B.1, B.2, B.3, and subsequently Propositions 4.1, 4.4, Lemma 4.5). Their derivation is presented very compactly using graphical notation and labels indicating the steps, rather than explicit formulaic inequalities. While standard in this specialized field, this presentation makes independent verification challenging for readers not fully familiar with this specific graphical calculus, and potential errors in applying the rules or combining bounds at this fundamental level could invalidate subsequent results."
      }
    ],
    "token_usage": {
      "input": 15346,
      "thinking": 5803,
      "output": 493
    }
  },
  {
    "entry_id": 216,
    "retraction_id": "2101.07819v3",
    "paper_id": "2101.07819v2",
    "retraction_comment": "We are withdrawing because of a significant error. The category Weil used to define tangent structures is too strict for the construction of our main example. In particular the map alpha in 7.19 is not well-defined. To resolve this we will replace Weil with a suitable $\\infty$-category and post a new version when possible. We are grateful to [REDACTED-NAME] and [REDACTED-NAME] for pointing out this error",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof relies on a non-standard or insufficiently justified modeling choice regarding functor ∞-categories.",
        "Location": "Section 8, Proof of Proposition 8.20",
        "Explanation": "The definition of a tangent structure requires a strict monoidal functor. The proof that the constructed functor T is strictly monoidal relies on a claimed strict equality of functor ∞-categories, Fun(S n' fin,∗, Fun(S n fin,∗, C)) = Fun(S n+n' fin,∗, C). This equality is not a standard property in typical models of ∞-categories. Stating it as a recall rather than a definition or a proven property of the chosen model undermines the rigor of the construction of the strict monoidal functor T."
      },
      {
        "Problem": "The construction of the functor φ˜i,j in Definition 8.18 relies on unexplicitly defined generalized natural transformations.",
        "Location": "Section 8, Definition 8.18, page 107",
        "Explanation": "The definition of the map Tφ(λ), which defines the action of Weil on simplexes of RelCatdiff∞, requires defining functors φ˜i,j : Pi,j → Fun(S nj fin,∗, S ni fin,∗). The definition of φ˜i,j on morphisms e in Pi,j is described as a generalization of the natural transformation α from Definition 7.19 to compositions of more than two Weil morphisms. These generalized natural transformations are not explicitly defined, leaving a gap in the construction of φ˜i,j."
      },
      {
        "Problem": "The proof that φ˜i,j is a functor relies on a lemma that does not appear to imply the required general functoriality.",
        "Location": "Section 8, Definition 8.18, page 107, and Lemma 8.19 proof, page 108",
        "Explanation": "For Tφ(λ) to be a valid simplex, φ˜i,j must be a functor from the poset Pi,j. The paper claims the required functoriality (preserving composition in Pi,j) follows from Lemma 7.34. However, Lemma 7.34 only deals with a specific compatibility for a composition of three Weil algebras, not the general composition structure in the poset Pi,j. This leaves a gap in the proof that φ˜i,j is a functor, which is necessary for Tφ(λ) to be a well-defined simplex."
      },
      {
        "Problem": "A crucial step in the proof of the vertical lift axiom relies on an equivalence that is not a direct or obvious consequence of the cited result.",
        "Location": "Section 7, Proof of Proposition 7.38, page 95",
        "Explanation": "The proof of the vertical lift axiom, a key property for a tangent structure, relies on the equivalence D(X, Y) ≃ D(X ∧ Y, S0) for the multilinear functor D(X, Y) := hofib(M(X, Y) → M(∗, Y)). This equivalence is stated to follow from Lurie's classification of multilinear functors ([Lur17, 1.4.2.22]), but it is not a direct or obvious consequence of that result, leaving a potential gap in the proof of this crucial axiom."
      }
    ],
    "token_usage": {
      "input": 35212,
      "thinking": 14567,
      "output": 754
    }
  },
  {
    "entry_id": 217,
    "retraction_id": "1711.07883v3",
    "paper_id": "1711.07883v2",
    "retraction_comment": "The paper has some problems on the Poisson homomorphism from the motivic Hall algebra to the motivic quantum torus",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed argument for vanishing Poisson brackets",
        "Location": "Section 2.4.2, Section 3.4.2, Section 4.4.3, Section 4.4.4",
        "Explanation": "The paper claims that Poisson brackets vanish for certain elements in the completed semiclassical d-critical Hall algebra based on the assertion that Ext^s(E,F) = 0 for all s by dimensional reasons when E and F have support of dimension at most 1. This is generally incorrect for objects with 1-dimensional support, where Ext^s can be non-zero for s=0, 1, 2. This invalidates the application of the integration map as a Poisson algebra homomorphism in the exponential formula used in the proofs."
      },
      {
        "Problem": "Unclear justification for specific Hall algebra elements being in the domain of the integration map",
        "Location": "Section 2.4.2, Section 3.4.2, Section 4.4.4, Definition 2.2.7",
        "Explanation": "The integration map I is defined on Hssc,d-Crit(A), which is spanned by classes of maps [X -> M] where (X,s) is a d-critical scheme. Key Hall algebra elements used in the proofs (e.g., H<1, H#, PH<1, Hexc, 1PF[1]) are defined as maps or inclusions of stacks (e.g., [Hilb<1(Y) -> M≤1]). While the relevant moduli spaces are d-critical schemes, it is not explicitly shown that these specific elements, as defined in the motivic Hall algebra, are in the domain of I or its completion IΛ in a way that justifies applying the map to them."
      },
      {
        "Problem": "Insufficient justification for the Laurent property in the motivic setting",
        "Location": "Section 2.3.5, Section 3.3, Proposition 3.7",
        "Explanation": "The proofs rely on applying the integration map to the completion of the Hall algebra, which requires the relevant elements to be Laurent. Proposition 3.7 claims this for key elements by citing results from Calabrese [16], which deals with non-motivic DT invariants. The generalization of the Laurent property from the non-motivic setting to the motivic setting is crucial for the argument but is not explicitly proven or justified in detail in the paper."
      },
      {
        "Problem": "Correctness of Hall algebra identities in the motivic setting not fully established",
        "Location": "Proposition 2.14, Proposition 3.4",
        "Explanation": "The proofs of the main theorems rely on specific Hall algebra identities (Proposition 2.14, Proposition 3.4). While these identities might be known in the non-motivic setting (from Bridgeland [9] and Calabrese [16]), their validity in the motivic Hall algebra H(A) is essential. The paper often states the proof is 'the same as' or 'following the method of' previous non-motivic works, but a detailed verification that these proofs carry over without issue to the motivic setting is not provided."
      }
    ],
    "token_usage": {
      "input": 8122,
      "thinking": 6136,
      "output": 710
    }
  },
  {
    "entry_id": 218,
    "retraction_id": "1603.02912v3",
    "paper_id": "1603.02912v2",
    "retraction_comment": "The calculation of the apparent charge density in this paper was wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper incorrectly claims that the charge density in the moving frame is zero after completing the Lorentz transformation.",
        "Location": "Page 3, Eq. (5)",
        "Explanation": "The standard Lorentz transformation of the charge-current four-vector (ρ, j) from a frame S (where ρ=0) to a frame S' moving with velocity V yields ρ' = γ(ρ - V ⋅ j). For a neutral current loop in S (ρ=0, j ≠ 0), this gives ρ' = -γ V ⋅ j. This is the charge density at a spacetime point (r, t) in S, as measured in S'. Expressing this density as a function of the coordinates (r', t') in S' by substituting the inverse Lorentz transformation does not make it zero; it remains ρ'(r', t') = -γ V ⋅ j(r(r', t'), t(r', t')), which is non-zero inside the transformed wire."
      },
      {
        "Problem": "The paper's explanation for the standard charge density result (Eq. 1) as arising from 'miscounting' is flawed and leads to an incorrect conclusion.",
        "Location": "Page 2-3, discussion around Fig. 1 and footnote 2",
        "Explanation": "The charge density ρ' = -γ V ⋅ j in the moving frame is a real physical effect, a consequence of the relativistic transformation of charge and current densities. The author's attempt to explain this using a 'miscounting' argument based on averaging over a region at a fixed time in the moving frame is confusing and incorrectly leads the author to conclude that the actual charge density is zero, rather than explaining why the standard non-zero result is correct."
      },
      {
        "Problem": "The paper's main conclusion that a moving neutral current loop has no induced charge density or electric dipole moment is incorrect.",
        "Location": "Abstract, Page 4, paragraph 1",
        "Explanation": "Based on the incorrect claim that the charge density in the moving frame is zero, the paper concludes there is no induced charge density or electric dipole moment. However, the standard and correct result is that a moving neutral current loop does acquire a non-zero charge density ρ' = -γ V ⋅ j, which results in an electric dipole moment if V is not perpendicular to j."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 10014,
      "output": 521
    }
  },
  {
    "entry_id": 219,
    "retraction_id": "2205.10165v2",
    "paper_id": "2205.10165v1",
    "retraction_comment": "It is not proved that the function $S$ is in fact an inner function",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The constructed function S is claimed to be a singular inner function (SInn), but the fixed-point equation implies it is not an inner function.",
        "Location": "Page 2, after the fixed-point equation for S",
        "Explanation": "The sequence {Sn} converges to a limit function S satisfying S(z) = exp(-(1+zS(z))/(1-zS(z))). This equation implies |S(z)| < 1 for all z in the unit disk U. A function analytic in U with modulus strictly less than 1 everywhere in U cannot be an inner function unless it is a constant of modulus less than 1. The argument correctly shows S is not a constant. Therefore, S is not an inner function, let alone a singular inner function. The conclusion 'S ∈ SInn' based on Hurwitz Theorem is incorrect; Hurwitz Theorem does not guarantee that the limit of inner functions is an inner function."
      },
      {
        "Problem": "The function zS is claimed to be an inner function (specifically, in Inn - SInn), but it is not.",
        "Location": "Page 1, after the definition of S1 (z·S1 ∈ Inn - SInn)",
        "Explanation": "Since the constructed function S satisfies |S(z)| < 1 for all z in U, the function w(z) = zS(z) satisfies |w(z)| = |zS(z)| < |z| < 1 for z in U \\ {0}, and w(0)=0. Thus |w(z)| < 1 for all z in U. For w to be an inner function, its radial limits must have modulus 1 almost everywhere on the boundary. This would require |S(e^iφ)|=1 a.e., which contradicts |S(z)|<1 in U. Therefore, w(z) is not an inner function."
      },
      {
        "Problem": "The proof of Theorem 1.2 relies on the constructed function S being a singular inner function.",
        "Location": "Page 2, Proof of Theorem 1.2",
        "Explanation": "Theorem 1.2 states the existence of a singular inner function S with certain properties. The proof attempts to show that the constructed function S satisfies these properties. However, as shown above, the constructed S is not a singular inner function (or even an inner function). Therefore, the proof does not establish the existence of a *singular inner function* with the stated properties, failing to prove the theorem as stated."
      }
    ],
    "token_usage": {
      "input": 1672,
      "thinking": 10035,
      "output": 568
    }
  },
  {
    "entry_id": 220,
    "retraction_id": "1511.00570v2",
    "paper_id": "1511.00570v1",
    "retraction_comment": "This paper has been withdrawn because the analysis therein completely oversimplified the physics during primordial nucleosynthesis",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Simplified BBN Network",
        "Location": "Section II, Equations (5)-(8), (13)",
        "Explanation": "The model uses a highly simplified BBN network that only tracks neutrons and protons before the deuterium bottleneck and 4He and protons after. This ignores the formation and destruction of intermediate nuclei like deuterium, which is crucial for determining the bottleneck timing and subsequent 4He production. Macro absorption of neutrons and protons directly impacts deuterium formation, and ignoring deuterium evolution and absorption could lead to inaccurate predictions for 4He abundance, especially when Macro interactions are significant."
      },
      {
        "Problem": "Unsound Application of Perturbative Analysis",
        "Location": "Section II, Equation (14); Section III, Figures 1 and 2 (dashed lines)",
        "Explanation": "The derivation of the deviation in 4He abundance (Eq. 14) relies on assuming a perturbatively small effect from Macros. However, the paper presents constraints (indicated by dashed lines in Figures 1 and 2) in regions where a significant fraction (10-50%) of neutrons are absorbed before the deuterium bottleneck. In these regions, the effect of Macros is not perturbatively small, rendering the linear approximation used in Eq. (14) invalid and the resulting constraints unsound."
      },
      {
        "Problem": "Potential Shift in Deuterium Bottleneck Temperature (TB)",
        "Location": "Section II, Equation (13); Section III, Footnote 1; Section IV",
        "Explanation": "The analysis assumes that the deuterium bottleneck temperature (TB) does not change significantly (less than 10%) from its standard value. However, substantial absorption of neutrons and protons by Macros before TB could significantly alter the n/p ratio and deuterium abundance, potentially shifting TB. If TB shifts significantly, the time-temperature relation and integration limits used in the calculations would be incorrect, further undermining the validity of the results, particularly in regimes with high Macro absorption."
      },
      {
        "Problem": "Unexplained Vanishing Constraint",
        "Location": "Section III, Figure 2; Section IV",
        "Explanation": "The paper observes and attempts to explain a region near V(Rx) ~ 0.01 MeV where the constraint on σχ/Mx essentially vanishes. The explanation involves a complex cancellation of effects from absorption before and after the bottleneck for different species. Given the simplified BBN network and the potential issues with the perturbative approach and TB shift, it is possible that this vanishing constraint is an artifact of the model's limitations rather than a robust physical prediction, suggesting the model may not accurately capture the physics in this specific regime."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 3064,
      "output": 581
    }
  },
  {
    "entry_id": 221,
    "retraction_id": "1911.02706v2",
    "paper_id": "1911.02706v1",
    "retraction_comment": "A missing sign in the argument to prove Lemma 2 renders the proof incorrect. The note is withdrawn since we are unable to provide a corrected proof that works with the stated generality",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof that scalar curvature is constant (Lemma 2)",
        "Location": "Page 5, Proof of Lemma 2",
        "Explanation": "The proof attempts to show that the scalar curvature s_g of a critical metric is constant by considering variations of the form h_φ = ∇_g dφ. However, these variations are only valid within the space of constant volume metrics if trace(h_φ) = Δ_g φ = 0. The proof then applies this argument with φ = s_g, which is only valid if s_g is harmonic (Δ_g s_g = 0). This assumes the conclusion (s_g is harmonic/constant) to justify the choice of variation, resulting in a circular argument. The calculation presented in the proof also contains unclear notation."
      },
      {
        "Problem": "Misapplication of unique continuation principle",
        "Location": "Page 4, discussion following equation (10)",
        "Explanation": "The argument that s_g is constant for n > 4 relies on a unique continuation principle applied to equation (10), or its equivalent form for u_g = s_g - π_g(s_g). This equation is a nonlinear PDE involving the non-local term π_g(s_g^2) or π_g(u_g^2). Standard unique continuation theorems (like Aronszajn's cited) apply to linear elliptic equations or certain nonlinear equations without non-local terms. The presence of the L^2 projection π_g makes the equation non-local, rendering the standard unique continuation argument inapplicable without further justification or a different theorem. The claim that a zero of order 3 implies vanishing to infinite order is not justified for this non-local equation."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 9618,
      "output": 394
    }
  },
  {
    "entry_id": 222,
    "retraction_id": "1806.06939v2",
    "paper_id": "1806.06939v1",
    "retraction_comment": "The objective in (8) allows for trivial solutions e.g. the prior",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The derivation of the importance sampling based KL divergence estimate appears theoretically unsound.",
        "Location": "Section 3.3, Appendix A",
        "Explanation": "The derivation in Appendix A leads to an objective function (S4) that does not correspond to the standard Evidence Lower Bound (ELBO) maximization typically used in variational inference with importance sampling. This undermines the theoretical justification for the proposed training method."
      },
      {
        "Problem": "Dropout rates for the variational distribution q(w) are manually set without theoretical justification.",
        "Location": "Section 3.1, Section 4",
        "Explanation": "The paper states that the Bernoulli probability p_k for the variational distribution q(w) is chosen manually (0.15 for Bayes-S, 0.20 for Bayes-WD/WD-IS). In a principled Bayesian approach using dropout as variational inference, this parameter corresponds to the variational distribution and should ideally be learned or justified theoretically. Manually setting different rates without a clear basis weakens the claim of a fully Bayesian treatment and makes the experimental results potentially dependent on arbitrary hyperparameter choices."
      },
      {
        "Problem": "The CVAE baseline used for comparison is overly simplistic and potentially unfair.",
        "Location": "Section 4, Table 9",
        "Explanation": "The ResG-CVAE baseline only adds Gaussian noise at the final convolutional block. This is a limited architecture compared to typical CVAEs which use latent variables sampled from a learned distribution that influence the generation process more globally. The poor performance of this baseline may not accurately reflect the capabilities of CVAE models in general for this task, making the comparison and conclusions about alternative methods potentially misleading."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 3685,
      "output": 376
    }
  },
  {
    "entry_id": 223,
    "retraction_id": "1310.8031v2",
    "paper_id": "1310.8031v1",
    "retraction_comment": "The solution for the NS equations provided can only be constant or very small magnitude",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation of the nonlinear term bound in the energy estimate.",
        "Location": "Lemma 4, equations (30)-(36)",
        "Explanation": "The decomposition of the nonlinear term b(u,u,Δ^r u) into terms like (30) and (31) is non-standard and appears incorrect based on derivative counts. The subsequent inequalities (33), (34), (35), and (36) used to bound these terms contain errors, particularly the interpolation inequalities in (34) which use incorrect exponents. This invalidates the crucial energy estimate (27)."
      },
      {
        "Problem": "Incorrect exponent in the nonlinear term bound.",
        "Location": "Equation (27), (40), (41)",
        "Explanation": "The exponent 1 + 4r/(2r-1) = (6r-1)/(2r-1) on ||u(t)||_r in the nonlinear term bound in (27) appears incorrect. For r=1, this exponent is 5, whereas standard estimates for the H^1 norm yield a bound involving ||u||_1^4. This error propagates through the subsequent analysis of the ODE for ||u||_r^2."
      },
      {
        "Problem": "Unjustified claim of global existence time for smooth initial data.",
        "Location": "Equation (43) and Proposal 5",
        "Explanation": "The analysis of the finite time T in (43) derived from the ODE for ||u||_r^2 shows that T depends on r, the constant c_r from the nonlinear estimate, and the initial norm ||u_0||_r. The claim that T approaches infinity as r approaches infinity for general smooth initial data (u_0 in H^∞) is not justified. The constant c_r typically grows rapidly with r, and the norms ||u_0||_r for a non-analytic smooth function also grow rapidly. The argument does not demonstrate that the growth of λ_1^((r-1)/2) is sufficient to overcome these growths, which is generally not the case for non-analytic data. This invalidates the conclusion of global existence for smooth solutions."
      },
      {
        "Problem": "Ambiguous or overly strong assumption on initial data smoothness.",
        "Location": "Proposal 5, condition (38)",
        "Explanation": "The condition sup_{k<∞} ||u_0||_k = K_3 < ∞ is stated for 'smooth initial data'. If 'smooth' means C^∞ or H^∞, this condition implies that the sequence of H^k norms is uniformly bounded, which is equivalent to the initial data being analytic. If the proof relies on this stronger condition (analyticity), it should be stated clearly, and the result (global existence for analytic data) is already known. If 'smooth' means H^∞ without the uniform bound, then the subsequent argument for global existence is flawed (as per the previous problem)."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 13800,
      "output": 673
    }
  },
  {
    "entry_id": 224,
    "retraction_id": "0904.3516v4",
    "paper_id": "0904.3516v3",
    "retraction_comment": "This paper has been withdrawn by the authors. The present version has several results that are correct, but, there is a problem in the use of sections 7 and 8 to derive generic properties for the set of analytic potentials g. All sections before this are OK",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Genericity results proven for continuous functions are applied to analytic functions without justification.",
        "Location": "Theorem 6.2, Section 7 (Theorem 7.1), Section 8 (Theorem 8.1)",
        "Explanation": "The paper's main result (Theorem 6.2) claims piecewise analyticity for a generic *analytic* potential g (meaning A=log g is analytic). However, the supporting genericity results (Theorems 7.1 and 8.1), which establish properties like unique maximizing measures, Aubry set structure, and the 'R* is good' condition, are proven for potentials A in the space of *continuous* functions C0(K,R). Genericity (holding on a residual set) in a larger space like C0 does not automatically imply genericity in a smaller subspace like analytic functions. The proofs provided for C0 do not appear to directly extend to the analytic setting required for Theorem 6.2."
      },
      {
        "Problem": "Genericity of the twist condition for analytic potentials is not proven.",
        "Location": "Section 6 (proof strategy, Definition 6.2, Theorem 6.2)",
        "Explanation": "The proof strategy for the piecewise analyticity of the subaction V relies critically on the twist condition for the potential A=log g to ensure the local constancy of the optimal parameter wx. Theorem 6.2 claims the result for a generic analytic potential g, implying the twist condition should hold generically for A=log g. While the paper states the twist condition is an open property for analytic A, it does not provide a proof that the set of analytic potentials A=log g satisfying the twist condition is generic in the space of analytic potentials, nor that this set is non-empty."
      },
      {
        "Problem": "Genericity of the condition 'R* is good' for analytic potentials is not proven.",
        "Location": "Section 6 (Theorem 6.2, Example 2), Section 8 (Theorem 8.1)",
        "Explanation": "Theorem 6.2 requires the condition 'R* is good for A*', which is shown to be non-trivial by Example 2. The paper claims this condition holds for a generic analytic potential g. This claim is supported by Theorem 8.1, which proves genericity of this property for potentials A in C0(K,R) via a specific duality for T(x)=2x. It is not clear that this result generalizes to analytic potentials A=log g for a general map f, nor that the specific duality used in Section 8 is applicable or sufficient in the general analytic setting of Theorem 6.2 to transfer this genericity property."
      },
      {
        "Problem": "Uniqueness of the maximizing probability for analytic potentials is assumed but its genericity is not established in the analytic setting.",
        "Location": "Theorem 6.2, Section 7 (Theorem 7.1)",
        "Explanation": "Theorem 6.2 assumes that the maximizing probability μ∞ for A=log g is unique and supported on a periodic orbit for the generic analytic potential g. Theorem 7.1 shows that the set of potentials A in C0(K,R) with a unique maximizing measure is residual. However, this result for C0 potentials does not directly establish the genericity of a unique maximizing probability in the space of analytic potentials, which is the setting of the main theorem."
      },
      {
        "Problem": "Duality theory and genericity results from a specific example are applied to a general setting without sufficient justification.",
        "Location": "Section 8 (Introduction, Theorem 8.1), Section 6 (Theorem 6.2)",
        "Explanation": "Section 8 develops a duality theory and proves genericity results (Theorem 8.1) for a specific dynamical system (T(x)=2x on KxΣ). The main theorem (Theorem 6.2) is stated for a general piecewise analytic expanding map f on [0,1] and its dual on Σ. While the paper suggests the Section 8 results generalize to natural extensions, the detailed proofs rely on the specific structure of the T(x)=2x example. Applying these specific results to the general setting of Theorem 6.2 without a more general duality theory or a rigorous proof of generalization constitutes a potential gap in the argument."
      }
    ],
    "token_usage": {
      "input": 10186,
      "thinking": 4445,
      "output": 955
    }
  },
  {
    "entry_id": 225,
    "retraction_id": "1509.01802v3",
    "paper_id": "1509.01802v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equations 22 and 23",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of singularity structure for term c).",
        "Location": "Page 9, Concluding Discussion and Eq. 17",
        "Explanation": "The paper claims that term c) of the 7-gluon amplitude is 'not singular' when the intermediate momenta P345 and P671 are both on mass shell (s345 and s671 are close to zero). However, Eq. 17 explicitly shows term c) is proportional to 1/(P345^2 P671^2), which means it is proportional to 1/(s345 s671). This factor represents a double pole, indicating a strong enhancement (singularity) in the configuration where s345 and s671 are small, which is characteristic of the intermediate propagators being near mass shell in a DPI-like process. This contradiction undermines the argument that the amplitude is not enhanced in the relevant kinematic configuration."
      },
      {
        "Problem": "Unsound argument for term c) being small when initial gluons are parallel.",
        "Location": "Page 9, Concluding Discussion and Eq. 25",
        "Explanation": "The paper argues that term c) is 'very small' when initial gluons 1 and 3 are almost parallel, based on a calculation in a specific kinematic limit (P345 and P671 proportional to p2, Eq. 25). This specific limit does not necessarily correspond to gluons 1 and 3 being parallel. Furthermore, the calculation showing the amplitude is finite in this particular limit does not prove it is small in the general DPI configuration where s345 and s671 are small and initial partons 1 and 3 might be parallel. The connection between the analyzed limit and the conclusion about the amplitude's size in the relevant configuration is not clearly justified and appears flawed."
      },
      {
        "Problem": "Conflation of different kinematic limits in the dominance argument.",
        "Location": "Page 9, Concluding Discussion",
        "Explanation": "The paper argues that the overall amplitude is dominated by terms like a) and b) (which have fusion singularities when initial partons are collinear) compared to term c) (which has singularities when intermediate propagators are near mass shell). This compares enhancements arising from different kinematic limits (initial parton collinearity vs. intermediate propagator near mass shell). The DPI-like configuration is characterized by the latter (s345, s671 small), not necessarily the former. Comparing the amplitude's behavior in these distinct limits to determine dominance in the specific DPI configuration is logically unsound."
      },
      {
        "Problem": "Main conclusion invalidated by singularity misinterpretation.",
        "Location": "Page 9, Concluding Discussion",
        "Explanation": "The paper's primary negative conclusion, stating that the 7-gluon color ordered amplitude is 'not enhanced in the pairwise back to back configuration... typical of DPIs', is directly based on the incorrect claim that term c) is not singular/enhanced when s345 and s671 are small. As established, term c) *is* enhanced by the 1/(s345 s671) factor in this configuration. Therefore, the conclusion that this amplitude does not contribute significantly to DPIs in the considered configuration is invalidated by this fundamental error regarding the singularity structure."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 2435,
      "output": 747
    }
  },
  {
    "entry_id": 226,
    "retraction_id": "2312.05804v3",
    "paper_id": "2312.05804v2",
    "retraction_comment": "Error in the derivation of equation 11 in section 4.3.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Reliance on 2D mask matching for 3D geometric alignment",
        "Location": "Section 4.3.2, Eq 13, Section 6 (Limitations)",
        "Explanation": "The primary loss for matching body and clothing geometry (L_match) is based on comparing 2D binary masks rendered from the deformed SMPL body and the clothing NeRF. This 2D projection loss may not accurately capture complex 3D geometric misalignments, especially for non-convex shapes or self-occlusions, potentially leading to unnatural or incorrect 3D fits, as acknowledged by the authors in the limitations section. This undermines the claim of achieving accurate geometric alignment."
      },
      {
        "Problem": "Unsoundness and vagueness of the 3D Semantic Confidence Strategy",
        "Location": "Section 4.3.1, Eq 10, 11, 12, Fig 2(b)",
        "Explanation": "The strategy aims to remove non-clothing content by comparing a 2D feature derived from a potentially pre-trained 2D semantic segmentation network (Fsa) with an integrated 3D confidence value predicted by an MLP (Fsw). Comparing a 2D feature with an integrated 3D value is conceptually problematic for ensuring 3D semantic consistency. The description of how Fsa obtains \"clothing features\" from rendered images and how these 2D features supervise the 3D confidence prediction is vague and lacks detail, making it difficult to assess its soundness and effectiveness in consistently removing unwanted 3D content."
      },
      {
        "Problem": "The body deformation process contradicts the claim of physically decoupled body and clothing",
        "Location": "Section 4.3.2, Fig 2(b)",
        "Explanation": "The method explicitly deforms the generated body (via SMPL-X vertex offsets optimized by L_match) to fit the generated clothing. This means the final body shape is dependent on the clothing shape. While the initial generation is decoupled, the subsequent matching stage couples the final geometry, where the body adapts to the clothing. This dependency limits the ability to arbitrarily and separately change/edit the body and clothing without potentially requiring re-matching or leading to inconsistencies, thus weakening the claim of true physical decoupling."
      },
      {
        "Problem": "Potential issues with applying body-centric LBS deformation to arbitrary clothing geometry",
        "Location": "Section 4.3.2, Eq 15, 16",
        "Explanation": "The method deforms the clothing NeRF's canonical space using Linear Blend Skinning (LBS) weights derived from the SMPL body. LBS is designed for deforming meshes based on a skeletal structure and skinning weights. Applying these body-centric weights to deform arbitrary clothing geometry generated by a diffusion model, especially for loose or complex garments, might not be appropriate or effective, potentially leading to unnatural deformations or geometric inconsistencies in the clothing layer during the matching stage."
      },
      {
        "Problem": "Lack of rigorous evaluation for the \"physically-decoupled\" claim",
        "Location": "Section 5 (Experiments)",
        "Explanation": "The paper claims \"physically-decoupled\" generation and the ability to \"arbitrarily and separately change and edit the body and clothing\". While clothing transfer is demonstrated (Fig 7), the evaluation metrics (user study on quality, consistency) and qualitative results primarily focus on the final dressed human. There is no specific evaluation or quantitative metric presented to assess the quality or consistency of the *separate* body and clothing layers *before* matching, or to demonstrate the ease and quality of *independent* editing of these layers, which would be crucial to fully support the strong claim of physical decoupling."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 3554,
      "output": 818
    }
  },
  {
    "entry_id": 227,
    "retraction_id": "1401.1766v5",
    "paper_id": "1401.1766v4",
    "retraction_comment": "This paper has been withdrawn by the author due to errors in figure 1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Subjective evaluation lacks rigor and standard metrics.",
        "Location": "Results section, page 15-17",
        "Explanation": "The performance evaluation relies on a subjective comparison by 20 graduate students using arbitrary criteria for categorization (e.g., 25% difference threshold). Standard information retrieval evaluation metrics (like Precision, Recall, NDCG) based on ground truth relevance judgments are not used, making the claims of superiority less convincing and the results difficult to reproduce or compare objectively."
      },
      {
        "Problem": "Details of user intention discovery and re-ranking are underspecified.",
        "Location": "Methods section, page 11, Figure 1, Figure 4",
        "Explanation": "A key claimed innovation is the re-ranking of results based on user-selected articles to determine 'true search intention' and calculate 'semantic similarities'. However, the specific methods for extracting key concepts from selected articles, forming the 'additional query', and calculating semantic similarity for re-ranking are not described in sufficient detail, making this core component difficult to evaluate or reproduce."
      },
      {
        "Problem": "IDF calculation for query expansion uses a potentially biased corpus.",
        "Location": "Methods section, page 10",
        "Explanation": "The Inverse Document Frequency (IDF) values used to re-rank concepts for query expansion are calculated using the OHSUMED dataset (a clinically-oriented subset of MEDLINE) instead of the entire MEDLINE database being searched. This could lead to IDF values that are not representative of the full corpus, potentially biasing the concept weighting and query expansion process."
      },
      {
        "Problem": "Query expansion weighting parameter description is confusing or incorrect.",
        "Location": "Methods section, page 10, formula (3)",
        "Explanation": "The formula for weighting concepts for query expansion includes a tuning parameter γ∈[0,1]. The description states it is 'used to increase the p₁ by decreasing γ'. If γ is in [0,1], raising p₁ (a probability) to the power of γ would increase p₁ only if γ < 1, and the phrase 'by decreasing γ' is unclear in this context. The specific value of γ used in experiments is also not provided, hindering reproducibility."
      },
      {
        "Problem": "Fairness of PubMed comparison regarding query interpretation is unclear.",
        "Location": "Results section, page 17-18",
        "Explanation": "The paper highlights PubMed's difficulty with natural language queries (like #17) due to assuming 'AND' operators. While this points to a potential usability issue for novice users, it's unclear how queries were submitted to PubMed in the evaluation (e.g., raw natural language vs. optimized Boolean queries). If raw natural language was used, the comparison might be biased against PubMed's capabilities when used effectively by experienced users or with better query formulation."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 2202,
      "output": 643
    }
  },
  {
    "entry_id": 228,
    "retraction_id": "2011.03931v2",
    "paper_id": "2011.03931v1",
    "retraction_comment": "There is a error in the experimental EBSD map of albite due to pseudosymmetry. The two parts A and B are actually linked by a 180_ rotation around b-axis. The theory remains valid to my point of view, but the EBSD map of albite cannot be used as an \"experimental proof\". I would like to apologize to the readers of the first versions deposited on Arxiv",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of fundamental physical criterion for 'slight distortion'",
        "Location": "§3.1, §3.2, §4.3, §4.4, §6",
        "Explanation": "The core concept of heteroplane and heterotwin relies on a 'slight distortion' between reticular planes/directions. This is quantified by arbitrary tolerances on length/angle differences and a generalized strain sg. The paper lacks a fundamental physical criterion (e.g., based on energy) for what constitutes a 'slight' distortion that can form a stable twin interface, making the definition and ranking somewhat arbitrary."
      },
      {
        "Problem": "Unjustified hypothesis about intraplanar accommodation",
        "Location": "§3.1, §6, §7",
        "Explanation": "The theory hypothesizes that the distortion associated with the heteroplane is accommodated within the interface or a delocalized zone. This is a critical assumption for the heteroplane to be the composition plane, departing from classical theory. However, the paper does not provide a physical mechanism or energetic justification for this accommodation process."
      },
      {
        "Problem": "Reliance on generalized strain (sg) as the sole predictor of twin likelihood",
        "Location": "§4.4, §6, §7",
        "Explanation": "The theory ranks predicted heterotwins based solely on the generalized strain sg, a purely geometric measure. This ignores the crucial role of the atomic motif, shuffling, and energy barriers, which are essential for twin formation. The fact that some low-sg predictions are not observed, and the authors acknowledge this limitation, weakens the predictive power regarding which twins will actually form."
      },
      {
        "Problem": "Arbitrary choice of tolerances in the search algorithm",
        "Location": "§3.1, §3.2, §4.4",
        "Explanation": "The algorithm for identifying potential heteroplanes depends on arbitrary tolerance values for the difference in length and angle between reticular directions. The resulting list of predicted heterotwins is sensitive to these chosen values, and the paper does not provide a rigorous justification for these specific tolerances, introducing an element of arbitrariness into the prediction process."
      }
    ],
    "token_usage": {
      "input": 12766,
      "thinking": 3444,
      "output": 487
    }
  },
  {
    "entry_id": 229,
    "retraction_id": "1501.02643v7",
    "paper_id": "1501.02643v6",
    "retraction_comment": "This article has been withdrawn due to error in Eq. 8",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified and potentially invalid SMM two-level approximation",
        "Location": "Page 2, 'Spin Hall Effect' section, paragraph starting 'Due to the complexity...'; Eq. 7, 8",
        "Explanation": "The reduction of the SMM with 2S+1 energy levels to a two-level system is a significant approximation. The paper states it is valid 'At high order in degenerate perturbation theory' but does not clearly specify the conditions (e.g., relative energy scales of anisotropy, interaction, tunneling, and temperature) under which this approximation holds when the SMM is coupled to the TI surface and includes tunneling. The validity of this approximation throughout the analysis is crucial but not rigorously established."
      },
      {
        "Problem": "Unjustified form of the interaction term",
        "Location": "Page 2, Eq. 8",
        "Explanation": "The paper transitions from the general s-d interaction (Eq. 6) to a specific form -λτzσz in the combined Hamiltonian (Eq. 8) for the two-level SMM. This reduction is not derived or justified. It assumes a particular coupling between the SMM state (represented by τz) and the TI electron spin (σz), which may not be a general consequence of the s-d interaction when the SMM is treated as a two-level system. The parameter λ is also introduced without a clear relation to the s-d coupling constant J and the SMM spin S."
      },
      {
        "Problem": "Non-standard and unclear definition of Spin Hall Conductivity",
        "Location": "Page 3, Eq. 19",
        "Explanation": "The paper defines the spin Hall conductivity (Eq. 19) based on the difference in charge Hall conductivity between the two SMM states (τz=±1), multiplied by ħ/2e. This is not the standard definition related to the transport of the electron's spin (e.g., σz). Since the TI electron spin σz is not conserved in the relevant Hamiltonians (H↑↓), the physical meaning of this defined 'spin Hall conductivity' is ambiguous and potentially misleading regarding actual spin transport."
      },
      {
        "Problem": "Apparent error in the eigenvalue calculation under SMM tunneling",
        "Location": "Page 3, Eq. 20",
        "Explanation": "The formula for the eigenvalues (Eq. 20) of the full Hamiltonian including SMM tunneling (Δa in Eq. 8) appears incorrect or derived from an unstated, potentially invalid approximation. The formula contains terms (like Δx and s) that are not clearly defined in the context of diagonalizing Eq. 8. This error propagates to the calculation of eigenspinors (Eq. 21) and the subsequent pseudo spin Chern number, potentially invalidating the conclusions about the topological phase under tunneling."
      },
      {
        "Problem": "Inconsistent notation for SMM tunneling parameter",
        "Location": "Page 2, Eq. 7, 8 (Δa); Page 3, Eq. 20 (Δx)",
        "Explanation": "The tunneling splitting in the SMM two-level model is denoted as Δa in Eq. 7 and 8. However, the eigenvalue formula (Eq. 20), which is supposed to describe the system *with* tunneling, uses a parameter Δx. While Δx is related to the tunneling term H1 in the original SMM Hamiltonian (Eq. 1), its appearance in Eq. 20 without a clear definition or relation to Δa, and within a likely incorrect eigenvalue formula, adds confusion and suggests an error in the derivation or notation."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 4177,
      "output": 818
    }
  },
  {
    "entry_id": 230,
    "retraction_id": "1903.02670v2",
    "paper_id": "1903.02670v1",
    "retraction_comment": "We can not use fixed-point theorem in the spaces defined in section 4.",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misidentification of the main equation and its physical origin.",
        "Location": "Abstract, Introduction (Eq 1.1, 1.3), Page 1-2 (Derivation section)",
        "Explanation": "The paper claims to study the Kuramoto-Sivashinsky (KS) equation (1.1) and states it is equivalent to the derived equation (1.3). However, equation (1.1) is not the standard KS equation, and its linear part (-d_xx u - mu(1-d_x^2)^(-1/2) u) is different from both the standard KS linear part (d_xxxx u + d_xx u) and the linear part of the derived equation (1.3) (-Dc d_xx H - (G/(8pi)) (1+d_x^2)^(-1/2) H in Fourier space). The claimed equivalence between (1.1) and (1.3) is not demonstrated and appears incorrect. The paper is thus studying a different equation than the one announced and derived from physics."
      },
      {
        "Problem": "Incorrect relationship between the two main equations.",
        "Location": "Introduction (Eq 1.2), Page 1 (text below Eq 1.1)",
        "Explanation": "Equation (1.2) is presented as the 'derivative equation' of (1.1). If u is a solution of (1.1), its spatial derivative v = d_x u should satisfy v_t - d_xx v - mu(1-d_x^2)^(-1/2) v - 2v d_x v = 0. However, equation (1.2) is v_t - d_xx v - mu(1-d_x^2)^(-1/2) v - v d_x v = 0. The nonlinear term in (1.2) is -v d_x v, whereas the derivative of the nonlinear term in (1.1) leads to -2v d_x v. Thus, (1.2) is not the derivative of (1.1)."
      },
      {
        "Problem": "Misleading claim about convergence to Burgers' equation.",
        "Location": "Abstract, Section 6 (Title, Theorems 6.1, 6.2)",
        "Explanation": "The paper claims that the method used allows obtaining the solution of the Burgers' equation when mu -> 0. Equation (1.1) with mu=0 is u_t - u_xx - (u_x)^2 = 0, which is not Burgers' equation (u_t + u u_x = 0). While equation (1.2) with mu=0 is equivalent to Burgers' equation (v_t - v_xx - v v_x = 0), the paper incorrectly identifies (1.2) as the derivative of (1.1). The claim that the results for (1.1) recover Burgers' equation is false."
      },
      {
        "Problem": "Mathematical results presented under a false premise.",
        "Location": "Abstract, Introduction, Theorems 1.1-1.7, Sections 2, 3, 4, 5, 7",
        "Explanation": "All the main mathematical results (well-posedness, ill-posedness, convergence) are derived for the specific equations (1.1) and (1.2). However, the paper presents these results as contributions to the theory of the Kuramoto-Sivashinsky equation and its derivative, and claims a connection to a physical model (1.3) that appears incorrect. Since (1.1) is not the standard KS, not equivalent to (1.3), and (1.2) is not the derivative of (1.1), the interpretation and significance of the mathematical results are fundamentally misrepresented."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 4773,
      "output": 858
    }
  },
  {
    "entry_id": 231,
    "retraction_id": "1408.0367v2",
    "paper_id": "1408.0367v1",
    "retraction_comment": "This paper has been withdrawn by the author. The paper only considers the omega>k regime, but the undamped modes have omega<k",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent application of vacuum polarisation and conductivity in Schwinger-Dyson equations.",
        "Location": "Page 2, Section II; Page 3, Section III.B; Appendix A",
        "Explanation": "The vacuum polarisation (Π) and conductivity (σ) used in the Schwinger-Dyson equations (Eqs. 7, 8, 27) and mode equations (Eq. 20) are taken from standard thermal field theory results, typically derived for effective equations of mean fields or linearized fluctuations in flat space. Applying these directly to the S-D equations for operator correlators in a non-equilibrium, expanding universe is a strong assumption that lacks rigorous justification within the presented framework. The self-energies in the S-D equations should ideally be derived consistently for the operator correlator in the specific background."
      },
      {
        "Problem": "Incorrect assumption of constant coefficients in the radiation era mode equation.",
        "Location": "Page 3, Section III.B, Eq. 20 and subsequent analysis",
        "Explanation": "The analysis of the mode equation (Eq. 20) in the radiation era assumes that the coefficients ασ and am_A are 'roughly constant' in conformal time η. However, in the radiation era, the scale factor a ~ η and temperature T ~ 1/η. Given the stated dependencies σ ~ e⁻²T and m_A ~ eT (from Appendix A), ασ ~ η e⁻²(const/η) and am_A ~ η e(const/η). These are not constant functions of η, invalidating the simple exponential solutions (Eq. 21) and the subsequent damping analysis based on constant roots (Eq. 22)."
      },
      {
        "Problem": "Inconsistent application of the long-wavelength approximation for vacuum polarisation.",
        "Location": "Page 3, Section III.B; Appendix A",
        "Explanation": "The paper uses the approximation that the vacuum polarisation reduces to a mass term a²m_A² in the mode equation (Eq. 20) for 'long vector wavelengths'. Appendix A states this approximation is valid for k < |ω|. In the context of the mode equation, ω is related to the time evolution rate p. The condition k < |p| must hold for the approximation to be valid. However, the roots p depend on k and the mass term itself. For the slow mode, |p| can be small, potentially violating the condition k < |p| and making the mass term approximation inconsistent for that mode."
      },
      {
        "Problem": "Reliance on perturbative conductivity for dissipation in a dense plasma.",
        "Location": "Page 3, Section III.B; Appendix A; References [14, 15]",
        "Explanation": "The conductivity σ, which is responsible for ohmic dissipation and is a key component of the damping mechanism, is derived from perturbative calculations in thermal field theory (Appendix A, [14]). Dissipation is fundamentally a non-perturbative process in many contexts. Using a perturbatively calculated conductivity as a dominant damping term in a dense, non-equilibrium plasma in the early universe might not accurately capture the full dissipative dynamics."
      },
      {
        "Problem": "Questionable assumption of vacuum scalar fluctuations in a hot plasma.",
        "Location": "Page 5, Section IV.A and IV.B",
        "Explanation": "The calculation of sourced magnetic fields relies on current fluctuations from charged scalar fields. The scalar correlator is assumed to be dominated by vacuum fluctuations (Eq. 35, 37, 38), even in the context of a hot plasma during reheating and the radiation era. The paper itself questions whether scalar correlators retain their vacuum form in a hot plasma. This assumption is likely invalid and undermines the calculation of the sourced magnetic field power spectrum from this source."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 4837,
      "output": 844
    }
  },
  {
    "entry_id": 232,
    "retraction_id": "1809.01643v2",
    "paper_id": "1809.01643v1",
    "retraction_comment": "Error in proof for efficiency bound. Variation of time variable is not taken into account",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 7090,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 233,
    "retraction_id": "1203.2581v2",
    "paper_id": "1203.2581v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 2",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and unclear theoretical formulation of the pairing gap equations.",
        "Location": "Page 3, around Eq. (2) and Eq. (3)",
        "Explanation": "The paper presents conflicting definitions and relationships between the pairing order parameter \\Delta_a(k), the pairing interaction strengths (V1, V2, V\\u22a5), and the basis functions (\\u03a6i). Eq. (2) suggests contributions \\Delta1,a, \\Delta2,a, \\Delta\\u22a5,a driven by V1, V2, V\\u22a5 respectively, associated with basis functions \\u03a61, \\u03a62, \\u03a6\\u22a5 (which are not clearly defined among the listed \\u03a61-\\u03a66). The text then states \\Delta_a(k) is a linear combination of three intraband pairings \\Deltai,a(k). Finally, Eq. (3) gives a specific form \\Delta_a(k) = \\Delta0[cos kx cos ky + \\u03b4a cos kz]. This inconsistency makes the derivation of the gap equations and the resulting phase diagram difficult to verify and potentially unsound."
      },
      {
        "Problem": "Unjustified direct substitution of calculated magnetic exchange parameters for pairing interaction strengths.",
        "Location": "Page 4, section discussing magnetic exchange couplings",
        "Explanation": "The paper calculates magnetic exchange parameters (J's) from first principles and then directly uses them as pairing interaction strengths (V's) to determine the pairing symmetry. While spin fluctuations are a plausible pairing mechanism, simply replacing phenomenological pairing interaction strengths (V1, V2, V\\u22a5) with calculated magnetic exchange parameters (J1, J2, J\\u22a5) is a specific model assumption (e.g., related to RPA spin fluctuation theory) that is not derived or justified within the paper. This direct substitution lacks theoretical rigor and weakens the conclusion drawn from this part of the analysis regarding the Sx2+y2 symmetry."
      },
      {
        "Problem": "Lack of microscopic justification for the specific ratios of phenomenological pairing parameters.",
        "Location": "Page 3-4, section discussing the phase diagram and its interpretation",
        "Explanation": "The main phase diagram and the conclusion about the k\\u208a-dependent s-wave stability rely on specific ratios of phenomenological pairing interaction strengths (V1, V2, V\\u22a5). The paper explores the phase space of these parameters but does not provide a microscopic derivation or strong justification from the first-principles calculations (other than the problematic magnetic J substitution) for why the specific region of parameter space (V\\u22a5 > V2 and V\\u22a5/V1 > 0.8) where the k\\u208a-dependent s-wave is stable is relevant for KFe2As2. Without this link, the conclusion that this phase is 'most favored' under certain conditions remains speculative regarding the actual material."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 3787,
      "output": 702
    }
  },
  {
    "entry_id": 234,
    "retraction_id": "1912.11842v3",
    "paper_id": "1912.11842v2",
    "retraction_comment": "There is a serious mistake in the section 4 in this paper. The paper concludes that there is new particle production in the system due to the plasma oscillation. However, the fact that the imaginary part of the self-energy will always be zero in the nonrelativistic limit indicates no new particle created",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound Classical Limit Method for Background Fields",
        "Location": "Section III.1, Eq. (72)-(80)",
        "Explanation": "The method used to determine the background fields (ψ₀, Aµ) by replacing statistical averages of field operator products with products of classical fields (e.g., <Ω(β)|ψ^(α)ψ^(α)|Ω(β)> ~ ψ₀^(α)ψ₀^(α)) lacks rigorous derivation from Thermo Field Dynamics or standard finite-temperature QFT. This ad-hoc replacement, especially for quantities representing the many-body state, undermines the validity of the calculated background polarization tensor, which is a crucial input for the dispersion relations."
      },
      {
        "Problem": "Presence of Infinite Factor in Polarization Tensor",
        "Location": "Eq. (144), Eq. (146)",
        "Explanation": "The background polarization tensor Π_bac,2(k) is found to be proportional to (2π)⁴δ(4)(0), an infinite factor. While the paper attempts a heuristic explanation based on S-matrix elements, the presence of this factor in the polarization tensor itself makes the dispersion relation equation (Eq. 69) ill-defined. Polarization tensors are typically functions of momentum, and this divergence suggests a fundamental issue with the calculation or its interpretation within the framework."
      },
      {
        "Problem": "Misinterpretation of Particle Production",
        "Location": "Eq. (167), Section IV.A.1",
        "Explanation": "The paper interprets the correction term δη in the longitudinal dispersion relation (Eq. 167) as 'particle production induced by plasma oscillation'. Dispersion relations describe the behavior of excitations (collective modes) on top of a given background state. Relating a term in the dispersion relation to a net increase in the particle number density (δη) of the background state is a misinterpretation. Particle number in thermal equilibrium is determined by temperature and chemical potential, not the frequency of collective oscillations."
      },
      {
        "Problem": "Inconsistent Ideal Gas Assumption for Background",
        "Location": "Section III.2, last assumption",
        "Explanation": "The paper assumes the background plasma particles are in an ideal gas state for simplicity. However, the background fields are intended to capture the non-perturbative many-body effects and long-range Coulomb interactions characteristic of a plasma. Assuming an ideal gas state for the background contradicts this purpose and likely invalidates the calculated background polarization tensor as representative of a real, interacting plasma."
      },
      {
        "Problem": "Divergent Results in High Energy Limit",
        "Location": "Eq. (174), Section IV.B",
        "Explanation": "In the high energy limit, the calculated dispersion relation yields infinite real and imaginary parts for the frequency. While the paper attempts to interpret these as related to particle creation and wave decay, infinite results typically indicate a breakdown of the theoretical framework or approximations used in that limit. This suggests the calculation is not valid in the high-energy regime, rendering the conclusions about wave behavior there unreliable."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 2459,
      "output": 680
    }
  },
  {
    "entry_id": 235,
    "retraction_id": "2212.07368v2",
    "paper_id": "2212.07368v1",
    "retraction_comment": "There is an error in the use of Corollary 1 in our Paper, which does not apply in our case",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of guaranteed convergence for the iterative Step 2",
        "Location": "Section IV, Step 2 - Shuffled Regression (Page 5)",
        "Explanation": "The iterative procedure in Step 2 alternates between estimating regression coefficients using a robust MM-estimator and estimating the permutation matrix via convex relaxation and projection. The paper explicitly states that this process does not guarantee convergence due to the non-convexity of the MM-estimator and the binary projection step. This means the algorithm might not converge to the optimal solution."
      },
      {
        "Problem": "Suitability of the robust MM-estimator for errors in the regressor matrix",
        "Location": "Section IV, Step 2 - Shuffled Regression (Page 5), Remark 3 (Page 4)",
        "Explanation": "The sensing matrix Â used as the regressor matrix in Step 2 is estimated from noisy data in Step 1. Errors in this estimation can lead to errors in Â, which act as leverage points. While the MM-estimator is robust to outliers in the response variable or residuals, its robustness properties are primarily analyzed for errors in the response, not necessarily for errors in the regressor matrix itself. The paper does not provide analysis or justification for the MM-estimator's effectiveness against this specific type of error in Â."
      },
      {
        "Problem": "Sensitivity of the sensing matrix to support estimation errors",
        "Location": "Section II.B (Page 3), Section IV, Step 1 (Page 4, Remark 3), Section V.C (Page 7, Remark 5)",
        "Explanation": "The sensing matrix Â is constructed based on the estimated support locations from Step 1. The theoretical uniqueness results rely on the true sensing matrix having full column rank, which depends on the true locations being distinct. In the noisy case, estimation errors in Step 1 can lead to estimated locations that are close or identical, potentially making the estimated matrix Â ill-conditioned or rank-deficient. This violates assumptions underlying the regression problem in Step 2 and can degrade performance or make the problem ill-posed in practice, despite the theoretical guarantees for the noiseless case."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 4230,
      "output": 474
    }
  },
  {
    "entry_id": 236,
    "retraction_id": "1104.1920v2",
    "paper_id": "1104.1920v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 42, 50, 51",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The assumed form of Eve's general collective Gaussian attack is too restrictive.",
        "Location": "Section III, Eq. (21), Page 10",
        "Explanation": "The paper claims to derive bounds against 'all possible collective Gaussian attacks' by assuming Eve's symplectic transformation matrix S has a specific block-diagonal form (Eq. 21). However, a general Gaussian attack involves a symplectic transformation on the combined system of the channel mode and Eve's ancillae, which does not necessarily result in this restricted form for the effective transformation on the signal mode plus ancillae. This means the derived bounds are only valid for a subset of collective Gaussian attacks, not all of them, invalidating the claim of generality and tightness against all such attacks."
      },
      {
        "Problem": "Contradictory claims regarding the dependence of Eve's accessible information on Alice-Bob correlation.",
        "Location": "Page 15 (RR scheme) and Page 23 (DR scheme)",
        "Explanation": "The paper claims that in the reverse reconciliation (RR) scheme, Eve's accessible information (Holevo bound) is independent of the correlation between Alice and Bob modes (Page 15). Conversely, in the direct reconciliation (DR) scheme, it claims Eve's information is strongly dependent on this correlation (Page 23). The derived formulas for the Holevo bound in both schemes (e.g., dependence on V and a^2) clearly show a dependence on parameters characterizing the initial Alice-Bob state (correlation) in both RR and DR cases. This contradiction indicates a fundamental error in the interpretation or derivation of the results."
      },
      {
        "Problem": "Inconsistent claims about the tightness of the derived bounds.",
        "Location": "Abstract, Page 9, Page 15, Page 19",
        "Explanation": "The paper first states that bounds derived based on Eve purifying the Alice-Bob state (Section II) are not tight for mixed entanglement (Page 9). It then claims the new bounds derived in Section III are tight for all CV-QKD protocols involving two-mode entangled states (Abstract, Page 19). However, it also states that the new bounds are identical to those from Section II for the maximally entangled case (Page 15). If the new bounds are identical to the non-tight bounds from Section II in a specific case (maximal entanglement), and the Section II bounds are generally not tight for mixed entanglement, it is contradictory to claim the new bounds are tight for all two-mode entangled states (which include mixed states). Furthermore, the restricted attack model assumed (Problem 1) prevents the bounds from being tight against general collective attacks."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 3343,
      "output": 589
    }
  },
  {
    "entry_id": 237,
    "retraction_id": "1406.6450v2",
    "paper_id": "1406.6450v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a gap in the inequality of (2.7)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of weights for the example.",
        "Location": "Figure 1(ii) and Equation (1.5), page 4.",
        "Explanation": "The weights for the 0th horizontal slice of T1 (denoted Wa with weights {an}) are defined numerically in Figure 1(ii) (e.g., α(0,0)=√1/2, α(1,0)=√2/3) and by formula (1.5) (a0=1/2, an=√(2n+2)/(2n+1) for n>=1). These definitions are contradictory, invalidating the specific example used as the basis for the theorem."
      },
      {
        "Problem": "Incorrect calculation of moments for the 0th horizontal slice Wa.",
        "Location": "Equation (2.4), page 7.",
        "Explanation": "The calculation of the moments γl(Wa) in equation (2.4) does not match the definition of the moments (γl = Π_{j=0}^{l-1} aj^2) when using the weights {an} from (1.5). This error propagates through the analysis of T1 subnormality and subsequent calculations."
      },
      {
        "Problem": "Incorrect argument for T2 subnormality.",
        "Location": "Page 7, Proof of Theorem 1.1 (i).",
        "Explanation": "The paper states T2 is subnormal if and only if a condition involving β(i,0) and a measure related to T1's slice holds. This condition appears to be a misapplication or misinterpretation of a known criterion for a different operator or context, and does not correctly establish the subnormality of the 2-variable shift T2 based on its weights."
      },
      {
        "Problem": "Incorrect application of the joint hyponormality criterion.",
        "Location": "Page 7, Proof of Theorem 1.1 (i).",
        "Explanation": "The paper claims that (T1, T2) is hyponormal if and only if M(k1,0)((T1,T2)) >= 0 for all k1 >= 0. The correct criterion (Lemma 2.1) requires the matrix M(k)((T1,T2)) to be positive semi-definite for *all* k = (k1, k2) in Z+^2, not just for k2=0."
      },
      {
        "Problem": "Incorrect identification for subnormality of the pair (T1, T2).",
        "Location": "Page 7, Proof of Theorem 1.1 (iii).",
        "Explanation": "The paper claims that the restriction (T1, T2)|M equals the canonical embedding Θ(Wa|L1). Comparing the weights of these operators shows they are different. This incorrect identification leads to a misapplication of Lemma 2.3 and Lemma 2.2, which are central tools for proving the subnormality of the pair (T1, T2)."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 9707,
      "output": 689
    }
  },
  {
    "entry_id": 238,
    "retraction_id": "1510.05979v4",
    "paper_id": "1510.05979v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (39)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Action Functional Definition",
        "Location": "Page 11, Equation (43)",
        "Explanation": "The action functional Aσ(y) for the continuous system is incorrectly defined in equation (43). It should be the double integral form given in equation (40), which represents the potential energy of a continuous mass distribution interacting with itself. Equation (43) uses a potential term that represents interaction with a fixed point (y(0)), integrated over the curve, which is not the correct potential for the continuous n-body problem limit."
      },
      {
        "Problem": "Existence Proof Based on Incorrect Functional",
        "Location": "Page 12, Theorem 3.1 and its proof",
        "Explanation": "Theorem 3.1 claims the existence of a minimizer for the action functional Aσ(y) defined in (43). Since the functional (43) is incorrect, the proof of coercivity and weak lower semicontinuity, which relies on the form of (43), does not apply to the correct action functional (40). Therefore, the existence of a minimizer for the actual continuous system's action functional (40) is not established by this theorem."
      },
      {
        "Problem": "Proof that Circle is Not a Minimizer Uses Incorrect Functional",
        "Location": "Page 15, Proposition 3.3 and Equation (59)",
        "Explanation": "The proof that the circle is not a minimizer of Aσ(y) attempts to calculate the first variation of the action functional for a perturbed circle. However, the action functional used in equation (59) for this calculation is different from both the correct functional (40) and the incorrect functional (43). Consequently, the calculation (60) and the conclusion of Proposition 3.3 are invalid for the action functional (40) that the paper claims to be studying."
      },
      {
        "Problem": "Irrelevant Functional in Proposition 3.2",
        "Location": "Page 14, Proposition 3.2 and Equation (54)",
        "Explanation": "Proposition 3.2 discusses the infimum of a functional Ŭ = I_C² U_C, where U_C is related to the incorrect potential term in (43). This functional Ŭ is not directly related to the action functional Aσ(y) from (40) whose minimization is the main goal for proving existence of solutions. This proposition appears disconnected from the main line of argument regarding the existence and properties of continuous choreographies as minimizers of Aσ(y) from (40)."
      }
    ],
    "token_usage": {
      "input": 4768,
      "thinking": 4757,
      "output": 585
    }
  },
  {
    "entry_id": 239,
    "retraction_id": "1202.0569v2",
    "paper_id": "1202.0569v1",
    "retraction_comment": "Due to a flaw in Lemma 9, the paper has been withdrawn",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed construction of a circulation in Lemma 7",
        "Location": "Page 9, Proof of Lemma 7, Case 2",
        "Explanation": "When deg_M(U) = 2, the set S = E(C) \\ A \\cup E(P_{uu'}) is claimed to induce a circulation. However, vertices incident to edges in M but not in U will have odd degree in the graph induced by S, violating the definition of a circulation."
      },
      {
        "Problem": "Unsound algorithm and proof for Lemma 9",
        "Location": "Pages 10-11, Proof of Lemma 9",
        "Explanation": "The iterative algorithm modifies the graph and the set A, but the definition of a C-augmenting set is tied to the original graph and circulation. The algorithm's state variables and termination condition are unclear, and it is not shown that the final set A' is C-augmenting for the original graph G and circulation C, or that G-A' is bridge-free."
      },
      {
        "Problem": "Unproven claims in the proof of Lemma 6",
        "Location": "Page 8, Proof of Lemma 6",
        "Explanation": "The argument for the existence of an edge e_r with a specific type in Step 5 relies on complex deductions about unique connections and twist structures that are not formally defined or proven to hold for arbitrary alternating paths, making the proof unsound."
      },
      {
        "Problem": "Flawed argument in the proof of Lemma 8",
        "Location": "Page 10, Proof of Lemma 8",
        "Explanation": "The proof assumes that a bridge b in G-A must be in E(G)\\E(C) and incorrectly claims that specific edges from E(C) must be in A to resolve the bridge, without proper justification based on the properties of A as a C-augmenting set."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 8665,
      "output": 442
    }
  },
  {
    "entry_id": 240,
    "retraction_id": "2111.02352v2",
    "paper_id": "2111.02352v1",
    "retraction_comment": "The previous to the last sentence of Section 4, namely that \"This means that $\\hat{Q}$ and, by Lemma 6, $\\hat{Q}$ too, is less than 1.\" is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency in the witness forest definition and its relation to the algorithm's recursive calls.",
        "Location": "Definition 3 (page 7), sentence following Definition 3 (page 7), Algorithm 1 (RECOLOR procedure, page 6), Lemma 7 (page 9).",
        "Explanation": "Definition 3(ii) states that the vertex-labels of the children of a node labeled (u, B) in the witness forest comprise the set sc(B(u)). The scope sc(B(u)) has size 3 when B is a 4-cycle and size 5 when B is a 5-path. However, the sentence immediately following Definition 3 states that a node with a 4-cycle label has two children and a node with a 5-path label has four children. This fixed branching factor (2 or 4) is used in the recurrence relation (Lemma 7) and the subsequent generating function analysis. This contradicts Definition 3(ii) and the scope sizes, meaning the witness forest structure used for the probabilistic analysis does not accurately model the recursive calls made by the RECOLOR procedure (Algorithm 1, line 2), which are triggered by all pivot vertices in the scope that are part of a badly colored set. This fundamental inconsistency invalidates the probabilistic bounds derived from the combinatorial analysis of the witness forest."
      },
      {
        "Problem": "Unsound proof for the bound on the number of main loop iterations.",
        "Location": "Lemma 3 and its proof (page 6), Lemma 4 (page 6).",
        "Explanation": "Lemma 4 claims that the main while loop of MOSERALG (Algorithm 1, line 4) is repeated at most l times, where l is the number of vertices. This claim is based entirely on Lemma 3, which states that vertices not initially pivot vertices in a badly colored set remain so after a RECOLOR call terminates. The proof of Lemma 3 is weak and does not convincingly demonstrate that recursive calls within RECOLOR cannot create new violations involving previously unaffected vertices, which could then become pivot vertices and trigger further main loop iterations. The argument relies on the 'least' rule but does not fully justify why this prevents the creation of new pivot vertices in badly colored sets outside the current recursive scope. Consequently, Lemma 4's bound on the number of main loop iterations is unsubstantiated by the provided proof."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 12202,
      "output": 526
    }
  },
  {
    "entry_id": 241,
    "retraction_id": "2207.08480v2",
    "paper_id": "2207.08480v1",
    "retraction_comment": "Errors in the method to determine the S-transformation coefficients, because the characters for the surfaces are not simply the product of characters for cylinders. Errors in the linear spaces assigned to surfaces in string vertices this http URL concrete definition for open sector linear spaces also required",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unproven generality of core conditions and isomorphism",
        "Location": "Section 3.1.2, Eq (38), Eq (43), Section 3.2",
        "Explanation": "The definition of S-transformation relies on the isomorphism between closed and open sector linear spaces (Eq 43), which is derived from the condition that open sector representation coefficients η are identical to closed sector fusion coefficients N (Eq 38) and boundary condition completeness ({μ}={P}). While these hold for diagonal RCFTs, the paper claims applicability to \"more classes of CFT2\" without providing proof or justification that these crucial conditions hold for a broader class. If these conditions are not generally true, the definition of S-transformation as a map between these spaces is only valid for a very restricted set of CFTs, undermining the generality of the proposed framework."
      },
      {
        "Problem": "Unjustified definition of open sector fusing matrices",
        "Location": "Section 3.4.1, Eq (91)",
        "Explanation": "The paper introduces a novel definition of open sector fusing matrices F^o based on the direct sum structure of the open sector linear spaces (Eq 91). This definition is stated to be different from the conventional one derived from the associativity of boundary condition changing operators. The paper does not provide a rigorous derivation or proof of consistency with fundamental CFT axioms, leaving the physical meaning and soundness of this definition unclear."
      },
      {
        "Problem": "Reliance on unproven relations in key derivation",
        "Location": "Section 3.4.1, Eq (95), Eq (96), Eq (97)",
        "Explanation": "The derivation showing that open sector representation coefficients form a matrix representation of fusion algebra (Eq 95) relies on relations (Eq 96 and Eq 97) which are explicitly stated as unproven. This weakens the soundness of a significant result concerning the algebraic structure of the open sector spaces within this framework."
      },
      {
        "Problem": "Incomplete moduli space coverage for covariant surfaces",
        "Location": "Section 3.5",
        "Explanation": "The paper acknowledges that surfaces constructed from sewing covariant string vertices do not cover the full moduli space of Riemann surfaces. Despite this, it claims this is not a problem for defining S-transformations by assigning linear spaces to these surfaces. Modular transformations are typically defined on the full moduli space. Defining S-transformations based on linear spaces associated with only a subset of the moduli space (the string vertices region) means the defined transformation may not correspond to the true modular S-transformation of the CFT, limiting the scope and validity of the definition for covariant surfaces."
      },
      {
        "Problem": "Opacity of the relation to conventional S-matrices",
        "Location": "Section 3.3.2, Eq (72)",
        "Explanation": "The paper attempts to relate the newly defined S-transformation coefficients C to conventional S-matrices S by reducing the partition function modular invariance constraint at a specific limit. This relation (Eq 72) involves coefficients A_μ(1) and A_μ3μ2(2) whose definition and properties are not clearly explained in the paper. This lack of clarity makes it difficult to verify the consistency of the new framework with established results in conventional CFT, leaving a gap in the argument for the validity of the defined S-transformation."
      }
    ],
    "token_usage": {
      "input": 11476,
      "thinking": 5160,
      "output": 747
    }
  },
  {
    "entry_id": 242,
    "retraction_id": "2302.04323v3",
    "paper_id": "2302.04323v2",
    "retraction_comment": "The first statement on page 9 is not necessarily true. Roughly speaking, the problem is that the indices \"i_s\" and \"r\" are competing with each other and therefore what I believed to be immediate, as happens naturally in the case of a single index, and as can be seen in the proof of Theorem 6.7 of the FHHMZ reference, is in fact not immediate in the situation where double indices are involved",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of the main theorem relies on a set M being non-empty, but no element is shown to belong to M.",
        "Location": "Page 6, Proof of Main Theorem, definition of set M and subsequent argument",
        "Explanation": "The proof defines the set M = {[v_i] ∈ [K]: ∃x ∈ K s.t. ||[v_i] - x|| ≤ d and ||[v_i] - [xn_{i+1}]|| ≤ 1/2} and then derives a contradiction by showing that M must be empty. This is only a valid contradiction if M is known to be non-empty. The proof does not demonstrate that M contains any element. For instance, the sequence [θk] defined later is shown not to be in M."
      },
      {
        "Problem": "The proof that the set M is invariant under the ultrapower map [T] is flawed.",
        "Location": "Page 6, Proof of Main Theorem, argument for [T](M) ⊂ M",
        "Explanation": "To show [T](M) ⊂ M, the proof needs to show that if [v_i] ∈ M, then [T(v_i)] ∈ M. This requires showing ∃y ∈ K s.t. ||[T(v_i)] - y|| ≤ d and ||[T(v_i)] - [xn_{i+1}]|| ≤ 1/2. While the first condition is correctly shown for y=Tx, the proof for the second condition ||[T(v_i)] - [xn_{i+1}]|| ≤ 1/2 uses an incorrect inequality in the limsup norm (||A - C|| <= ||A - B|| + ||B - C|| is correct, but the terms used are not directly related in the ultrapower norm) and relies on terms like ||[v_i] - [xn_i]|| and ||[xn_i] - [xn_{i+1}]|| being small, which is not justified by the properties of the sequences (v_i) and (xn_i) as defined."
      }
    ],
    "token_usage": {
      "input": 4510,
      "thinking": 14871,
      "output": 481
    }
  },
  {
    "entry_id": 243,
    "retraction_id": "1911.03748v2",
    "paper_id": "1911.03748v1",
    "retraction_comment": "Unfortunately, our proof contains a serious flaw. Specifically, Lemma 5.3 does not prove the assertion it claims to prove and this collapses the entire argument. We thank [REDACTED-NAME] for pointing out the flaw, and apologize to the community for posting an eventually incorrect proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed inequality in the proof of Lemma 5.3",
        "Location": "Page 12, Proof of Lemma 5.3",
        "Explanation": "The proof finds sets J, S and an assignment x_J such that E_{z,y}[f(x_J, z, y)^2] >= E[f^2] - epsilon, where the expectation is over variables in S\\J (z) and [n]\\S (y). It then claims this implies E_y[(E_z[f(x_J, z, y)])^2] >= E[f^2] - epsilon, where g(y) = E_z[f(x_J, z, y)] is a function of y in [n]\\S. By Jensen's inequality, the opposite inequality holds: E_y[(E_z[f(x_J, z, y)])^2] <= E_{z,y}[f(x_J, z, y)^2]. The required inequality E_y[g(y)^2] >= E[f^2] - epsilon does not follow from the preceding steps. This step is central to proving the existence of an influential coalition (Lemma 5.3 and Proposition 5.4), which is a key component of the main theorem (Theorem 1.6)."
      }
    ],
    "token_usage": {
      "input": 5026,
      "thinking": 12313,
      "output": 306
    }
  },
  {
    "entry_id": 244,
    "retraction_id": "2212.12846v2",
    "paper_id": "2212.12846v1",
    "retraction_comment": "We found an error in Lemma 3.5.--which is used in the subsequent analysis to establish the rate of convergence. Since the error is not fixable, we would like to withdraw the article",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified L-infinity bound for the approximate solution",
        "Location": "Lemma 3.3, page 8",
        "Explanation": "Lemma 3.3 claims a uniform L-infinity bound for the approximate solution u_∆x by referencing [43]. However, [43] deals with conservation laws (without diffusion or degenerate diffusion). The presence of degenerate diffusion (Φ) and stochastic terms in the viscous problem (2.1) makes the L-infinity bound non-trivial, and the argument from [43] is not directly applicable or sufficient without significant modifications, which are not provided. This bound is crucial for controlling tail behavior in sums and applying convergence theorems later in the paper."
      },
      {
        "Problem": "Insufficient justification for adapting proofs of noise term estimates",
        "Location": "Section 4, particularly Lemmas 4.9, 4.11, 4.12",
        "Explanation": "The estimation of stochastic terms driven by Lévy noise relies heavily on adapting proofs from referenced papers ([7, 13, 16]). These papers address problems with either Brownian noise or Lévy noise but typically without the complexity of degenerate diffusion. The interaction between degenerate diffusion and Lévy noise is non-trivial, and the adaptation of existing proofs requires careful justification and potentially significant modifications, which are not provided in the paper. This lack of detail makes the validity of these crucial estimates uncertain."
      },
      {
        "Problem": "Unclear justification for adapting proofs of degenerate diffusion term estimates",
        "Location": "Section 4, particularly terms I4, J4 and Lemmas 4.4, 4.7",
        "Explanation": "The estimation of terms arising from the degenerate diffusion operator relies on adapting proofs from referenced papers ([7, 16, 42, 43]). While these papers address aspects of degenerate diffusion, their arguments may not directly apply to the specific finite difference scheme (2.7) for the viscous problem (2.1) in the presence of Lévy noise without careful adaptation. The paper lacks sufficient detail on how these adaptations are performed, leaving the validity of these estimates questionable."
      },
      {
        "Problem": "Unjustified step from weighted L1 estimate to unweighted L1 estimate",
        "Location": "Page 30-31, transition from inequality (4.24)",
        "Explanation": "The proof concludes by combining various estimates, resulting in a bound for a weighted L1 difference (4.24). The final step involves removing the weight function ρ_δ(x-y) and the test function ψ to obtain a bound for the standard L1 difference E[||u_∆y - u_ε||_L1]. The paper does not provide a rigorous justification for this transition, which is essential for establishing the claimed convergence rate in the L1 norm."
      },
      {
        "Problem": "Incomplete specification and justification of parameter choices",
        "Location": "Page 31, final paragraph of the proof",
        "Explanation": "The final convergence rate is obtained by balancing errors and choosing parameters ε, ξ, δ in terms of ∆x. However, the intermediate estimates involve other parameters (e.g., κ, δο, l) related to mollifiers and the doubling variable method. The paper does not explicitly state how all these parameters are chosen in terms of ∆x in the final balancing step, which is necessary to ensure that all terms in the combined error estimate contribute to the desired rate and that the limits (κ→0, δο→0, l→0) are compatible with the chosen relation between ε, ξ, δ and ∆x."
      }
    ],
    "token_usage": {
      "input": 8638,
      "thinking": 5527,
      "output": 798
    }
  }
]