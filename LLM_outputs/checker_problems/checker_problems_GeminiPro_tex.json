[
  {
    "entry_id": 0,
    "retraction_id": "2303.17613v10",
    "paper_id": "2303.17613v9",
    "retraction_comment": "The theoretical structure, in particular the existence of the Riemannian metric, was flawed and will be resubmitted after reconsideration",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "PCA control case definition is problematic for signatures.",
        "Location": "Section 4.1, Results, Principal modes, PCA description",
        "Explanation": "The PCA modes are described as $m \\pm \\sigma_1 v_1$, where $m$ is a signature and $v_1$ is a vector in the embedding space $\\mathbb{R}^{341}$. The sum $m+v_1$ is an operation in the ambient space and the result is not guaranteed to be a valid signature (i.e., it may not satisfy the shuffle relations). This makes its interpretation, its conversion back to a path, and the subsequent error calculation (Eq. 20) problematic, potentially invalidating the comparison with PGA where components are valid signatures on the manifold."
      },
      {
        "Problem": "PGA second mode calculation is non-standard and potentially suboptimal.",
        "Location": "Section 3.2, Problem setting, item 2 (The second mode)",
        "Explanation": "The method for finding the second PGA mode $v'$ (Eqs. 16-17) fixes the coefficients $t_\\ell$ obtained from the first mode optimization when defining the projection surface $m \\exp{(t_{\\ell} v+t'_{\\ell}v')}$. This means for each data point $x_\\ell$, only $t'_\\ell$ is optimized for the new direction $v'$, rather than re-optimizing coefficients for both $v$ and $v'$. This greedy approach is not equivalent to finding the best 2-dimensional geodesic subspace (which would typically involve optimizing $m \\exp(s_{\\ell,1}v_1 + s_{\\ell,2}v_2)$ w.r.t. both $s_{\\ell,1}, s_{\\ell,2}$ for fixed $v_1, v_2$). This may lead to a suboptimal second principal geodesic and misrepresent the principal subspace."
      },
      {
        "Problem": "Gradient descent update rule for $v$ in PGA appears incorrect.",
        "Location": "Section 3.3, Gradient Descent, formula for $v^{\\text{new}}$ (derived from Eq. 19 and surrounding text)",
        "Explanation": "The gradient descent update rule for $v$ is described as $v^{\\text{new}} = v-\\epsilon' P \\sum_{\\ell=1}^L t_\\ell (\\partial \\exp|_{t_\\ell v})^\\top P (\\partial_2\\mathrm{prod}|_{m,\\exp{(t_\\ell v)}})^\\top (-2)p_\\ell\\log{\\left(p_\\ell^{-1}x_\\ell \\right)}$, where $P=C^\\dagger C$. The inner projection operator $P$ (the one inside the sum) is not justified by the derivation of the gradient in Appendix D, which suggests a form $P \\sum A^\\top B^\\top C_\\ell$. This extra $P$ seems to be an error in the gradient formula, which could lead the optimization algorithm to converge to an incorrect stationary point of the objective function."
      },
      {
        "Problem": "Potential inconsistency between the Riemannian PGA framework and the chosen geodesics/gradients for non-bi-invariant Lie groups.",
        "Location": "Section 2.4 (Eq. 6), Section 2.7.2, Appendix A (Eq. A.7), Appendix B",
        "Explanation": "The paper implements Principal Geodesic Analysis (PGA, Fletcher 2004), which is a Riemannian method minimizing squared geodesic distances $d(m,x)$. It uses geodesics and logarithmic maps derived from the Cartan-Schouten Connection (CSC), specifically $\\Log_m x = m \\log(m^{-1}x)$. The gradient formula $\\nabla_m d^2(m,x) = -2 \\Log_m x$ (from Appendix B) is valid if $\\Log_m x$ is the log map of the Riemannian metric defining $d(m,x)$. However, CSC geodesics (which are 1-parameter subgroups) are generally not the length-minimizing geodesics for arbitrary left-invariant Riemannian metrics on Lie groups unless the metric is bi-invariant (which is not the case for the signature group). If $d^2(m,x)$ is implicitly defined as $\\|\\log(m^{-1}x)\\|_e^2$ (a common choice using the Euclidean norm of log-coordinates at identity), its Riemannian gradient $\\nabla_m d^2(m,x)$ is not $-2m\\log(m^{-1}x)$ without further assumptions (like bi-invariance of the metric). This suggests a fundamental inconsistency: the algorithm might not be minimizing the stated Riemannian objective, or the gradient formula used is incorrect for the implicit distance $d^2(m,x)=\\|\\log(m^{-1}x)\\|_e^2$ on this specific Lie group structure. This could mean the method does not implement Riemannian PGA as laid out by Fletcher."
      }
    ],
    "token_usage": {
      "input": 16422,
      "thinking": 15797,
      "output": 1123
    }
  },
  {
    "entry_id": 1,
    "retraction_id": "2103.13332v3",
    "paper_id": "2103.13332v1",
    "retraction_comment": "The notion of stabilizing ordinal is not well-defined, i.e., Definition 14 is flawed. As a consequence the results presented in the paper are either incorrect or remain unproved",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of the similarity ordering $\\leq_w$ and weak centering, potentially trivializing the safety condition and undermining the paper's core motivation.",
        "Location": "Definition 2 (Ordering frame), p. 3; Footnotes 4 and 5, p. 3; Figure 1, p. 5",
        "Explanation": "Definition 2 states $\\leq_w$ is a partial ordering and weak centering means $\\forall v \\in W (w \\preceq_w v)$ (i.e., $w \\leq_w v$). A partial order is antisymmetric. If $w \\leq_w v$ for all $v$, then $w$ is the unique $\\leq_w$-minimal world. (If $v_0$ is minimal, then $w \\leq_w v_0$. If $w \\neq v_0$, then $w \\prec_w v_0$, contradicting $v_0$'s minimality. So $w=v_0$.) If $w$ is the unique $\\leq_w$-minimal world, the safety condition in Definition 5 (clause 14) simplifies, making $\\sbel\\psi \\Leftrightarrow \\bel\\psi \\land \\psi$. This version of $\\sbel$ is monotone. If $\\sbel$ is monotone, the Kripke jump $\\mathcal{K}$ would also be monotone, and the standard fixed-point construction would apply, removing the need for the paper's quasi-inductive approach. This contradicts the paper's central claim of dealing with non-monotonicity. Furthermore, Figure 1 depicts $w \\leftrightarrow z$ under $\\preceq_w$, implying $w \\leq_w z$ and $z \\leq_w w$. If $\\leq_w$ is a partial order, this means $w=z$, but the diagram and Example 1 treat $w$ and $z$ as distinct. This indicates an inconsistency between the formal definition of 'partial order', 'weak centering', and their intended use (described in footnotes 4, 5 and illustrated in Figure 1) which requires multiple minimal worlds or $\\leq_w$ to be a preorder."
      },
      {
        "Problem": "The definition of the iteration of operator F in Example 2 for constructing sbel-teller fixed points contains a typo.",
        "Location": "Section 4.2, Example 2, p. 15, item 3",
        "Explanation": "The recursive definition of ${\\sf F}^\\alpha(Y)$ for a successor ordinal $\\alpha=\\beta+1$ is given as ${\\sf F}({\\sf F}^\\beta(Y)\\cup{\\sf F}^\\beta(Y))$. The union ${\\sf F}^\\beta(Y)\\cup{\\sf F}^\\beta(Y)$ is simply ${\\sf F}^\\beta(Y)$. So the definition should be ${\\sf F}^{\\beta+1}(Y) = {\\sf F}({\\sf F}^\\beta(Y))$. While this is likely a typo, it makes the definition, as written, slightly confusing. This is a minor issue compared to others but points to a lack of precision in a specific construction."
      },
      {
        "Problem": "The definition of the Sim operator in Example 2 is highly suspect and likely incorrect for its intended purpose.",
        "Location": "Section 4.2, Example 2, p. 15, item 2",
        "Explanation": "The operator ${\\sf Sim}$ is defined as ${\\sf Sim}(Y)=\\{v\\in W\\,|\\,\\exists w'\\in W(w'\\approx_{w'} v)\\}$. This definition makes ${\\sf Sim}(Y)$ independent of $Y$; it's a constant set of worlds $S_0 = \\{v \\in W \\,|\\, \\exists w' \\in W (w' \\approx_{w'} v)\\}$. If ${\\sf Sim}$ is a constant operator, then ${\\sf F} = {\\sf Sim} \\circ {\\sf TC}$ would map any non-empty set ${\\sf TC}(Y)$ to $S_0$. This would mean ${\\sf F}^1(\\{w\\}) = S_0$ and ${\\sf F}^\\mu(\\{w\\}) = S_0$ for $\\mu \\ge 1$. The construction then states $f(v) = \\{\\sbel\\T\\iota\\}$ if $v \\in S_0$. This seems too simplistic and likely not the intended behavior for identifying worlds where $\\sbel\\T\\iota$ should be initially assumed true to make it true at a specific world $w$. The definition of ${\\sf Sim}$ needs to be relative to the worlds in $Y$ or the target world $w$ for the construction to be meaningful."
      }
    ],
    "token_usage": {
      "input": 29276,
      "thinking": 25605,
      "output": 1075
    }
  },
  {
    "entry_id": 2,
    "retraction_id": "1602.07129v2",
    "paper_id": "1602.07129v1",
    "retraction_comment": "this paper has been withdrawn due to minor error in the calculation of dielectric constant",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential incorrect starting material composition",
        "Location": "Page 3, Experimental section, first paragraph",
        "Explanation": "The text states, 'The starting reagents SrCO3, BaCO3, TiO2 and MnO2 were dried...'. The target compound is Sr2TiMnO6. The inclusion of BaCO3 as a starting reagent is problematic. If BaCO3 was indeed used and not a typo for SrCO3, the synthesized material would not be pure Sr2TiMnO6 but would likely contain Barium (e.g., (Sr,Ba)2TiMnO6 or a phase mixture). This would fundamentally alter the material's identity, structural parameters, ionic radii, tolerance factor, and consequently its magnetic and electronic properties. All subsequent analyses and conclusions in the paper are based on the premise of pure Sr2TiMnO6, which would be invalidated if Ba is present due to the use of BaCO3."
      },
      {
        "Problem": "Inconsistent Mn ionic state and magnetic moment",
        "Location": "Page 4, discussion of Curie-Weiss fit; Page 5-6, specific heat analysis",
        "Explanation": "The experimentally determined effective magnetic moment (μ_eff = 5.01 μB/Mn) is significantly higher than the spin-only value for Mn4+ (S=3/2, μ_eff_so ≈ 3.87 μB), which the paper assumes to be the sole magnetic ion. This discrepancy (approx. 29% higher) is dismissed as 'slightly higher' but could indicate a different or mixed Mn valence state (e.g., presence of Mn3+ with S=2, μ_eff_so ≈ 4.9 μB). Despite this, the entire theoretical framework, particularly the calculation of theoretical magnetic entropy (Smag_theo = Rln(2S+1) = 11.5 J/mol-K based on S=3/2 for Mn4+), relies on the pure Mn4+ (S=3/2) assignment. This fundamental inconsistency regarding the Mn spin state undermines the quantitative magnetic analysis and comparisons to theory, making them unsound."
      },
      {
        "Problem": "Contradictory and poorly justified specific heat analysis for magnetic entropy",
        "Location": "Page 5-6, Specific Heat section, Equations 1-3, Figure 4",
        "Explanation": "The paper presents two conflicting methods for subtracting the lattice specific heat contribution (Clatt) to determine the magnetic entropy change (Smag), leading to vastly different experimental Smag values: 0.5 J/mol-K and 10.86 J/mol-K. The first value (0.5 J/mol-K from a polynomial fit of Clatt over 20-40K) shows a large discrepancy with the theoretical Smag for Mn4+ (S=3/2), which is 11.5 J/mol-K. The second value (10.86 J/mol-K from a Debye model for Clatt with θD=545K) is claimed to be a 'best physical fit' and matches the theoretical value. However, the justification for this specific θD is weak, the fitting range is not clearly defined, and the visual representation of this Debye fit in the inset of Fig. 4(a) suggests it may not accurately model Clatt, potentially underestimating it at low temperatures where the magnetic anomaly is significant, thereby artificially inflating the calculated Smag. The paper uses arguments based on both Smag values without robustly defending one method over the other or reconciling the large differences, rendering conclusions about the magnetic entropy and the nature of the magnetic ordering unreliable."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 9086,
      "output": 809
    }
  },
  {
    "entry_id": 3,
    "retraction_id": "2006.00175v4",
    "paper_id": "2006.00175v3",
    "retraction_comment": "In eq 38, misses a d^2 phi term, breaking down the results of the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect premise for quantum symmetry.",
        "Location": "Section I, primarily the argument for the unnumbered equation following Eq. (10) (the one starting with $\\int \\Pi_y d\\phi(y) d\\psi(y) e^{-\\frac{i}{\\hbar}\\int d^d x L} f(\\phi(z),\\phi^*(z)) \\frac{d L}{d\\psi(z)_\\alpha} = 0$).",
        "Explanation": "The paper claims that if an action under a transformation changes as $S \\rightarrow S +\\int d^4 x \\epsilon f(\\phi, \\phi^*)\\frac{\\partial L}{\\partial\\psi} + \\dots$, this implies a quantum symmetry because the expectation value $\\langle f(\\phi, \\phi^*) \\frac{\\partial L}{\\partial\\psi} \\rangle = 0$. This assertion is based on the path integral of a total derivative. However, the identity $\\int D\\chi \\frac{\\delta}{\\delta\\chi(x)} (F e^{-S}) = 0$ leads to $\\langle F \\frac{\\delta S}{\\delta\\chi(x)} \\rangle = \\langle \\frac{\\delta F}{\\delta\\chi(x)} \\rangle$. If $F$ does not depend on $\\chi$, then $\\langle F \\frac{\\delta S}{\\delta\\chi(x)} \\rangle = 0$. Here $\\frac{\\delta S}{\\delta\\chi(x)}$ is the full Euler-Lagrange expression. The paper uses $\\frac{\\partial L}{\\partial\\psi}$ (the partial derivative of $L$ w.r.t. $\\psi$, not involving derivatives of $\\psi$) instead of $\\frac{\\delta S}{\\delta\\psi}$. For Lagrangians with derivatives of $\\psi$ (like all kinetic terms considered), $\\frac{\\partial L}{\\partial\\psi} \\neq \\frac{\\delta S}{\\delta\\psi}$. The statement $\\langle f(\\phi, \\phi^*) \\frac{\\partial L}{\\partial\\psi} \\rangle = 0$ is not generally true. This fundamental error invalidates the entire framework and the conditions derived for the proposed 'quantum symmetries' throughout the paper."
      },
      {
        "Problem": "Flawed derivation of $W_1$ and the scalar potential $V$.",
        "Location": "Section II (Eq. \\ref{repeat} and subsequent derivation of $V(\\phi,\\phi^*)$), with implications for Sections IV and VI.",
        "Explanation": "The paper derives a condition for the 'quantum symmetry' of the form $\\frac{d W_1 }{d\\phi} = - \\frac{d W(\\phi, \\phi^*)^*}{d\\phi^*} W_2(\\phi,\\phi^*)$, where $W_2 = \\frac{d^2 W(\\phi, \\phi^*)}{d\\phi^2}$. The subsequent integration to obtain $W_1 = - \\frac{d W(\\phi, \\phi^*)^*}{d\\phi^*} \\frac{d W(\\phi, \\phi^*)}{d\\phi} + f(\\phi^*)$ (Eq. \\ref{repeat}) is only valid under the strong and unstated condition that $\\frac{\\partial^2 W}{\\partial\\phi^* \\partial\\phi} = 0$ (i.e., $W(\\phi, \\phi^*) = W_a(\\phi) + W_b(\\phi^*)$) or $\\frac{\\partial W}{\\partial\\phi}=0$. The general expression for the scalar potential $V$ based on this flawed $W_1$ is therefore unsound. This affects the conclusions about the form and properties of the potential in the theories constructed."
      },
      {
        "Problem": "Non-Hermitian action in Gauge Theory I.",
        "Location": "Section IV, Eq. \\ref{gauge_action}.",
        "Explanation": "The action for Gauge Theory I is given as $S = \\int d^4 x [ \\frac{-i}{4g^2}F_a^{\\mu \\nu }{F_a}_{\\mu \\nu } + \\dots]$. Since $F_a^{\\mu \\nu }{F_a}_{\\mu \\nu }$ is a real quantity, the term $\\frac{-i}{4g^2}F_a^{\\mu \\nu }{F_a}_{\\mu \\nu }$ is purely imaginary. This makes the action non-Hermitian, which is a fundamental issue for a physical theory as it typically leads to non-unitary time evolution or complex energy eigenvalues. The statement '$+h.c.$' in the equation applies only to specific later terms, not the gauge kinetic terms."
      },
      {
        "Problem": "Incorrect D-term contribution to the scalar potential in Gauge Theory II.",
        "Location": "Section VI, the final expression for $V$.",
        "Explanation": "In Gauge Theory II, the Lagrangian includes terms $\\frac{1}{2g^2} D^a D^a - D^a \\phi^* T^a \\phi$. Eliminating the auxiliary field $D^a$ (using its equation of motion $D^a = g^2 \\phi^* T^a \\phi$) yields a D-term contribution to the scalar potential of $\\frac{g^2}{2} (\\phi^*T^a\\phi)^2$. However, the paper's expression for the total potential $V$ includes this term as $2g^2 (\\phi^*T^a\\phi)^2$. This is an error by a factor of 4, which incorrectly represents the scalar potential of the model."
      },
      {
        "Problem": "Unsubstantiated claims about the algebra of the new symmetry generators.",
        "Location": "Section IB, 'Generator of Symmetry'.",
        "Explanation": "The paper argues that the generators $Q'$ of the proposed symmetry do not follow the supersymmetry algebra. This argument relies on constructing $Q'$ by subtracting a term $E^0$ from the Noether charge, where $\\partial_\\mu E^\\mu = f(\\phi, \\phi^*) \\frac{dL}{d\\psi}$. The existence of a local $E^\\mu$ is not guaranteed; if $E^\\mu$ is non-local, $Q'$ becomes a non-local charge. The paper's example $E^\\mu = \\nabla^\\mu \\phi$ is arbitrary and doesn't correspond to the actual $f(\\phi, \\phi^*) \\frac{dL}{d\\psi}$ terms. The argument that $\\{Q', Q'^{\\dagger}\\} \\nsim P_\\mu$ due to potential non-locality or structure of $E^0$ is not rigorously established and is hand-wavy, making the claim that these symmetries are definitively 'non-supersymmetric' in their algebraic structure (beyond simply not matching field content) poorly supported."
      }
    ],
    "token_usage": {
      "input": 20324,
      "thinking": 16055,
      "output": 1558
    }
  },
  {
    "entry_id": 4,
    "retraction_id": "2108.05829v5",
    "paper_id": "2108.05829v4",
    "retraction_comment": "There is a mistake in the proof. The second term of the last equation in Lemma 2.2 does not have the desired asymptotic behavior. I am grateful with [REDACTED-NAME] for pointing out this mistake",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The derivation of the property $P \\ge 1$ for the function $P(x)$ in Lemma 2.2 is flawed.",
        "Location": "Lemma 2.2, pages 3-4 (specifically, the assumption on the local form of $\\tilde{U}$ and the deduction that $c_p$ is an integer and $P \\ge 1$).",
        "Explanation": "The paper assumes that locally $\\tilde{U}|_{W_p}= \\pm\\,w_1^{d_1}\\ldots w_n^{d_n}$. However, the correct local form after monomialization is generally $\\tilde{U}|_{W_p}= \\epsilon(w) w_1^{d_1}\\ldots w_n^{d_n}$, where $\\epsilon(w)$ is a real analytic unit function (i.e., $\\epsilon(p) \\neq 0$ for $p \\in H$). This implies that the term $c_p$ in the expression $\\tilde{V}_p(\\tilde{U})= c_p\\,\\tilde{U}$ is actually a function $C_p(w) = (\\sum d_i) + (\\sum_j w_j \\partial_{w_j}\\epsilon)/\\epsilon$, not necessarily a positive integer as claimed. While $C_p(w)$ tends to an integer $\\sum d_i \\ge 1$ as $w \\to 0$ (i.e., as $x \\to x_0$), the function $P(x) = \\sum f_p(x) C_p(\\sigma^{-1}(x))$ is not guaranteed to be $\\ge 1$ throughout the required domain $W-\\mathcal{V}(U)$. At best, it can be argued that $P(x) \\ge 1-\\delta$ for any $\\delta > 0$ if $W$ is chosen sufficiently small and $x$ is close to $x_0$. The lemma's stronger claim $P \\ge 1$ is not substantiated."
      },
      {
        "Problem": "The inequality $-P U \\ge -E$ in the proof of the main theorem relies on the unsubstantiated claim $P \\ge 1$.",
        "Location": "Page 5, Proof of the conjecture.",
        "Explanation": "The derivation of the lower bound for $\\dot{F}$ uses the step $\\dot{F} \\ge -P U \\ge -E$. The second inequality, $-P U \\ge -E$, requires $P(x) \\ge 1$ for $x=\\gamma(t)$ (since $U(x) \\le E < 0$). As the claim $P \\ge 1$ is not rigorously established in Lemma 2.2 (see Problem 1), this step in the proof of the main theorem is a non-sequitur. If, for instance, $P(x)$ was only known to be $P(x) \\ge c_0$ for some $0 < c_0 < 1$, this step would be invalid. While the overall argument structure (showing $F(t) \\to \\infty$) could potentially be salvaged with $P(x) \\ge c_0 > 0$ (leading to $\\dot{F} \\ge -c_0 E$), the proof as presented relies on the stronger, unproven condition $P \\ge 1$."
      }
    ],
    "token_usage": {
      "input": 7913,
      "thinking": 23590,
      "output": 766
    }
  },
  {
    "entry_id": 5,
    "retraction_id": "2403.19848v2",
    "paper_id": "2403.19848v1",
    "retraction_comment": "We're withdrawing our paper from arXiv due to a critical error in our review methodology, which excluded key studies on sustainable road freight transport. This oversight could mislead the scientific community. We plan to correct this, ensuring comprehensive study inclusion, and will resubmit our paper for a more accurate review",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Vague and Undisclosed Review Methodology",
        "Location": "Section 2. Methodology, Page 4, first paragraph",
        "Explanation": "The paper claims to conduct a 'systematic review' but fails to adequately detail its methodology. Crucial information such as the search strategy (databases, keywords), specific criteria for paper selection beyond general 'sustainable criteria,' the inclusion/exclusion process, and any quality assessment of the selected studies is missing. This lack of transparency makes it impossible to evaluate the review's comprehensiveness, potential biases, and the reliability of its findings, thereby undermining the validity of its conclusions."
      },
      {
        "Problem": "Overstated or Potentially Misleading Claims about Reviewed Literature",
        "Location": "Section 3. Results and discussion, Page 8, first paragraph; Conclusion, Page 10",
        "Explanation": "The paper makes generalizations about the reviewed literature that are not strongly supported by, or appear contradicted by, its own summary data in Table 1. For example, the assertion that 'Recent studies on sustainability measure in road freight transportation combined the analysis of the three dimensions' (Page 8) is not clearly supported by Table 1, where only one study (Aloui et al., 2021) is explicitly shown covering all three. Such overstatements can misrepresent the actual state of research and weaken the credibility of the paper's conclusions."
      },
      {
        "Problem": "Lack of Clearly Defined Specific Research Gap and Novel Contribution",
        "Location": "Abstract, Page 1; Introduction, Page 3, last paragraph; Conclusion, Page 10",
        "Explanation": "The paper mentions a 'research gap' (Page 3) but does not articulate a specific, nuanced gap that the review intends to address. Furthermore, the paper's claim in the abstract to 'provide a theoretical research findings' is not substantiated with new theoretical insights or a novel conceptual framework. The conclusions largely reiterate general knowledge rather than offering new perspectives derived from a rigorous synthesis, making its unique contribution unclear."
      },
      {
        "Problem": "Inconsistent or Ambiguous Data Presentation in Table 1",
        "Location": "Table 1, Pages 4-6 (e.g., duplicate entries for Holguín-Veras et al., 2016 on page 4 and page 5 with different 'Sustainable dimension' attributions)",
        "Explanation": "Table 1, which forms the core evidence for the review, contains inconsistencies such as the duplicate listing of at least one study with different sustainability dimensions attributed across its entries. This raises concerns about the rigor of data extraction and the reliability of the categorization of studies, which is fundamental to the paper's analysis and subsequent discussion of sustainability dimensions."
      },
      {
        "Problem": "Superficial Analysis of Methodologies Used in Reviewed Studies",
        "Location": "Table 1 (Method column); Discussion of dimensions, Pages 6-8; Conclusion, Page 10",
        "Explanation": "While the paper lists methods used in the reviewed studies (Table 1) and mentions them in the text, it lacks a critical analysis or in-depth discussion of these methodologies. There is no substantive evaluation of their evolution, strengths, weaknesses, or suitability for addressing sustainability in road freight transport. This superficial treatment limits the paper's ability to provide meaningful insights into 'how the researchers have used different analysis techniques' (Page 10) beyond a descriptive summary."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 3541,
      "output": 759
    }
  },
  {
    "entry_id": 6,
    "retraction_id": "2210.14117v3",
    "paper_id": "2210.14117v2",
    "retraction_comment": "Error in formulation of Bronold-Fehske model. The plots shown are actually in terms of E' + chi, shifted incorrectly by a factor of the electron affinity. The apparent perfect reflection region is therefore nonphysical",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of steady state due to plasma cooling invalidates claims about material-specific sheath structures.",
        "Location": "Section 3, paragraph starting 'The gain, shown in Fig. 8...' and subsequent discussion.",
        "Explanation": "The paper acknowledges that the plasma is cooling over time, causing the electron flux gain $\\gamma$ to continuously increase. Since the type of sheath (classical vs. SCL) depends critically on $\\gamma$, the observed sheath structures (e.g., SCL for Boron Nitride) are transient phenomena resulting from this cooling process, rather than stable, material-specific characteristics. The authors dismiss this lack of steady state as 'not considered critical,' but it fundamentally undermines the conclusion that specific material parameters definitively lead to certain sheath regimes under the model, as the system is evolving due to simulation artifacts (energy loss at the wall not balanced by the source, exacerbated by collisions)."
      },
      {
        "Problem": "The formulation of the electron reflection boundary condition (Eq. 9) is unclear and, if implemented as written, unphysical.",
        "Location": "Section 2.A, Eq. (9) and surrounding text.",
        "Explanation": "Equation (9), $f_{out}(\\mathbf{x}=\\mathbf{x}_{wall}, \\mathbf{v}) = \\int R(E'(\\mathbf{v}'), \\mu'(\\mathbf{v}'))f_{in}(\\mathbf{x}=\\mathbf{x}_{wall}, \\mathbf{v}')d\\mathbf{v}'$, defines the outgoing electron distribution $f_{out}$ at a specific velocity $\\mathbf{v}$ as an integral over all incoming velocities $\\mathbf{v}'$. This would result in $f_{out}(\\mathbf{v})$ being a single scalar value, independent of $\\mathbf{v}$, which is unphysical for a velocity distribution function. A correct boundary condition for elastic reflection should relate specific incoming velocity states to specific outgoing velocity states (e.g., via specular reflection, $f_{out}(\\mathbf{v}) = R(\\mathbf{v}_{in}) f_{in}(\\mathbf{v}_{in})$ where $\\mathbf{v}_{in}$ maps to $\\mathbf{v}$). If Eq. (9) reflects the actual implementation, the electron reflection physics is incorrectly modeled, invalidating all subsequent results. If it is a misrepresentation of a correct implementation, it critically obscures the methodology."
      },
      {
        "Problem": "Arbitrary assumption of surface roughness parameter $C=2$ for Boron Nitride without sensitivity analysis.",
        "Location": "Section 2.A, paragraph discussing Eq. (7).",
        "Explanation": "The electron reflection model uses a surface roughness parameter $C$. The value $C=2$ is chosen based on experimental fits for Magnesium Oxide and then assumed to be 'sufficiently applicable for other dielectric materials,' specifically Boron Nitride, without further justification. The paper does not provide a sensitivity analysis to show how variations in $C$ would affect the reflection probability, the electron flux gain $\\gamma$, and consequently, the predicted sheath structure for Boron Nitride. If the formation of an SCL sheath for Boron Nitride is sensitive to this specific choice of $C$, and the actual $C$ for Boron Nitride differs significantly, the conclusion is speculative and potentially incorrect."
      },
      {
        "Problem": "Particle and energy sourcing method contributes to non-physical system evolution.",
        "Location": "Section 2.B, paragraph on source term; Section 3, discussion of cooling.",
        "Explanation": "The particle source injects electrons and ions at rates determined by the ion flux to the wall and at the initial plasma temperature. This approach is acknowledged to result in 'collision-driven cooling' because energy lost to the wall is not adequately replenished. Furthermore, setting both electron and ion source rates equal to the ion loss rate may not ensure a stable electron population or overall quasineutrality if electron and ion loss dynamics are different. This sourcing strategy is a primary contributor to the lack of a steady state, rendering the presented 'final' sheath profiles as snapshots of an evolving, potentially unphysical system state."
      },
      {
        "Problem": "The artificial collision model's impact on system dynamics and physical realism is not fully established.",
        "Location": "Section 2.C, particularly Fig. 5 and discussion of artificial collision frequency.",
        "Explanation": "An artificially inflated and spatially profiled collision frequency is employed to thermalize the presheath while aiming for a collisionless sheath. Figure 5 demonstrates that the choice of collision frequency significantly alters the electron distribution at the wall. While such artificial models are common, the specific ad-hoc parameters and profile, combined with the Lenard-Bernstein operator, interact with the inadequate sourcing and wall losses. This interaction contributes to the system's continuous cooling and prevents a steady state. It is unclear whether the presheath conditions achieved truly represent a physical, larger system, especially given the overall thermal non-equilibrium of the simulation."
      }
    ],
    "token_usage": {
      "input": 8838,
      "thinking": 7742,
      "output": 1091
    }
  },
  {
    "entry_id": 7,
    "retraction_id": "1902.09447v2",
    "paper_id": "1902.09447v1",
    "retraction_comment": "We have to change the simulations section since the authors of the RANA method do not agree that we did fair comparisons with their method",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent shift indexing in gradient formulation for L>1",
        "Location": "Eq. (7) (definition of q_bar_l,p) and Algorithm 1, Line 12 (definition of q^(t)_l,p)",
        "Explanation": "The definition of q_bar_l,p (and q^(t)_l,p) involves terms like z[l+p] and z[l-p], implying a shift by 'p'. However, the FROG measurement model (Eq. 1) and the definition of g_p (used in the same gradient calculation) involve shifts by 'pL' (e.g., x[n]x[n+pL]). If L is not equal to 1, using a shift 'p' instead of 'pL' in q_bar_l,p would make the gradient calculation incorrect. While Theorem 1 is restricted to L=1 (where this distinction might be less apparent if 'p' is used loosely for 'pL' when L=1), the algorithm is presented and numerically evaluated for L>1."
      },
      {
        "Problem": "Lipschitz constant of the smoothed gradient depends on the smoothing parameter mu",
        "Location": "Appendix C, proof of Lemma 1, part 3 (specifically Eq. C.8-C.15 leading to r_k,p and U)",
        "Explanation": "The derived Lipschitz constant U for the gradient of the smoothed function h(z,mu) (via r_k,p in Eq. C.15) includes terms inversely proportional to powers of mu (e.g., M_phi_mu/mu, M_phi_mu/mu^2). The convergence proof for Theorem 1 (Appendix B) relies on standard stochastic gradient descent theory (e.g., Ghadimi & Lan, 2013), which typically assumes that the Lipschitz constant U is independent of mu. If U(mu) tends to infinity as mu tends to 0, the step size condition alpha in (0, 2/U] would require alpha to tend to 0, and the convergence analysis as presented (especially for mu -> 0) is flawed."
      },
      {
        "Problem": "Step size condition for stochastic gradient descent is incorrect",
        "Location": "Theorem 1 (step size condition alpha in (0, 2/U]) and Algorithm 1, Line 8 (update rule)",
        "Explanation": "The stochastic gradient d_Gamma(t) (Algorithm 1, Line 9) is a sum of Q components. The full gradient (Eq. 7, after correcting for the sum over p and assuming proper component definition) is an average over NR components. It can be shown that E[d_Gamma(t)] = Q * (grad h). The update rule is x^(t+1) = x^(t) - alpha * d_Gamma(t). This means the effective update using an unbiased estimate of grad h (i.e., (1/Q)*d_Gamma(t)) would be x^(t+1) = x^(t) - (alpha*Q) * ( (1/Q)*d_Gamma(t) ). For standard SGD convergence results, the step size for the unbiased gradient estimator must be in (0, 2/U]. Thus, alpha*Q should be in (0, 2/U], implying alpha should be in (0, 2/(UQ)]. The paper's condition alpha in (0, 2/U] makes the step size potentially too large by a factor of Q, which could lead to divergence."
      },
      {
        "Problem": "Incorrect claim about circulant matrix structure in initialization",
        "Location": "Section IV-A, paragraph following Eq. (14)",
        "Explanation": "The paper states that for L=1, the matrix G_l (defined in Eq. 14 as G_l[p,n] := x_pL[n] * conj(x_pL[n+l])) is a circulant matrix. For L=1, G_l[p,n] = x[n+p] * conj(x[n+p+l]). A matrix M is circulant if its entries M_ij depend only on (i-j) mod N. The defined G_l does not generally satisfy this property. Consequently, the subsequent assertion that G_l is invertible if and only if the DFT of its first column is non-vanishing is also incorrect. This flawed justification affects the understanding and theoretical basis of the proposed initialization method, which is shown to be critical for the algorithm's overall performance."
      },
      {
        "Problem": "Gradient summation range for index 'p' is inconsistent with loss function",
        "Location": "Eq. (7) (summation for p) compared to Eq. (4) (summation for p)",
        "Explanation": "The objective function h(z,mu) in Eq. (4) is defined with a sum over p from 0 to R-1. However, the Wirtinger derivative in Eq. (7) calculates the sum over p from 1 to R-1. This means the gradient term corresponding to p=0 (zero delay) is missing from the derivative calculation. The p=0 term is generally non-trivial and contributes to the loss, so its omission from the gradient is an error."
      }
    ],
    "token_usage": {
      "input": 48956,
      "thinking": 16687,
      "output": 1193
    }
  },
  {
    "entry_id": 8,
    "retraction_id": "1610.03889v2",
    "paper_id": "1610.03889v1",
    "retraction_comment": "There is a serious gap about the tangent space of the dimension 2 foliations induced by a linear pull-back. I do not know if the scheme is reduced and so it is possible that the dimension of the tangent space of this scheme is bigger than his topological dimension",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Zariski density argument for globalizing local results.",
        "Location": "Proof of Theorem 1.1 (page 5, paragraph starting \"If $\\xi$ is any bivector field...\") and Theorem 4.1 (page 4).",
        "Explanation": "The proof asserts that the trivector field $\\alpha_0 \\wedge Y$ vanishes globally on $\\mathbb{P}^{n-1}$ because it vanishes on an integral curve $C$ (of $\\partial/\\partial y_1$ in local linearizing coordinates for $Y$). This relies on Theorem 4.1 claiming $C$ is Zariski dense in $\\mathbb{P}^n$ (presumably meant $\\mathbb{P}^{n-1}$). An integral curve, being 1-dimensional, cannot be Zariski dense in $\\mathbb{P}^{n-1}$ for $n-1 \\ge 2$ (the paper assumes $n \\ge 4$). This step is crucial for concluding $\\alpha_0 \\wedge Y = 0$ globally, which in turn is needed to show that deformations of $\\Pi$ are deformations of the foliation $\\mathcal{F}$ (i.e., $\\xi \\wedge \\Pi = 0$)."
      },
      {
        "Problem": "Ambiguous or ill-defined global Poisson structure $\\Pi$.",
        "Location": "Page 2, paragraph below Theorem 1.1 (stating \"The bivector field $\\Pi \\in H^0(\\lm{P}^{n},\\bigwedge^2T\\lm{P}^{n})$ defined by $\\Pi=\\dbyd{}{X_{n}}\\wedge Y$\") and Abstract.",
        "Explanation": "The Poisson structure $\\Pi$ is defined as $\\frac{\\partial}{\\partial X_n} \\wedge Y$ using a homogeneous coordinate $X_n$ and $Y$ (a vector field on $\\mathbb{P}^{n-1}$). This expression is not standard for a well-defined global bivector field on $\\mathbb{P}^n$. A precise definition, likely via homogeneity conditions for bivectors on the affine cone $\\mathbb{C}^{n+1}$ (which would typically place $\\Pi$ in $H^0(\\mathbb{P}^n, \\bigwedge^2 T\\mathbb{P}^n(2))$), or by careful patching of affine representations, is missing. The standard space $H^0(\\mathbb{P}^n, \\bigwedge^2 T\\mathbb{P}^n)$ is zero for $n \\ge 2$. This foundational definition affects the nature of $\\Pi$ and the space of its deformations $\\xi$."
      },
      {
        "Problem": "Potential misapplication of \"de Rham Lemma\" for polynomial vector fields to holomorphic germs.",
        "Location": "Proposition 3.3, page 4 (the proof relies on a \"de Rham Lemma\" to deduce $[Y,\\alpha_0]=Y\\wedge V$ from $[Y,\\alpha_0]\\wedge Y=0$).",
        "Explanation": "The proof of Proposition 3.3 uses a \"de Rham Lemma\" where $Y$ is the locally linearized vector field $\\sum \\lambda_i y_i \\partial_{y_i}$ and $\\alpha_0$ is a germ of a bivector field. These are germs of holomorphic fields, not necessarily polynomial. The version of the lemma usually cited for polynomial fields (as in the LaTeX comment in the paper: \"cod sing $Y \\ge 3$\") may not directly apply without justification for holomorphic germs. While analogous results exist for holomorphic functions/vector fields (e.g., related to Saito's theory of free divisors or Malgrange-Martinet theorems), their specific conditions and applicability here are not established."
      },
      {
        "Problem": "Inconsistent degrees in the local polynomial expansion of deformations.",
        "Location": "Lemma 2.1, page 3 (decomposition of $\\xi$).",
        "Explanation": "The deformation $\\xi$ is expanded in affine coordinates as $\\xi=\\alpha_0+x_n\\alpha_1+x_n^2\\alpha_2+x_n^3\\alpha_3+ \\dbyd{}{x_n}\\wedge \\beta$. If $\\Pi$ is interpreted as an element of $H^0(\\mathbb{P}^n, \\bigwedge^2 T\\mathbb{P}^n(2))$ (a common and likely intended setting for Poisson structures on $\\mathbb{P}^n$), then any deformation $\\xi$ in the same space must have components in affine coordinates that are polynomials of total degree at most 2. The term $x_n^3\\alpha_3$ (where $\\alpha_3$ is non-zero and its coefficients are polynomials in other variables) would typically correspond to a term of total degree at least 3, which is inconsistent with $\\xi$ being a global section of $\\bigwedge^2 T\\mathbb{P}^n(2)$. Thus, $\\alpha_3$ (and higher order terms in $x_n$) should be zero. While this might not break the subsequent logic of Lemma 2.1 if $\\alpha_3$ is simply taken as zero, its presence indicates a lack of precision in defining the space of deformations."
      }
    ],
    "token_usage": {
      "input": 7740,
      "thinking": 21652,
      "output": 1189
    }
  },
  {
    "entry_id": 9,
    "retraction_id": "1208.1540v2",
    "paper_id": "1208.1540v1",
    "retraction_comment": "This paper has been withdrawn because there is a gap in the construction of the canonical quadratic refinement on a mapping torus",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The justification for the extendability of cohomology classes from a boundary manifold $\\partial W$ to $W$ (Appendix A) is flawed, potentially undermining the construction of the canonical relative Wu lift and subsequent canonical quadratic refinements.",
        "Location": "Appendix A (specifically Lemma A.2), and its applications in Section 3.3 (construction of relative lift $\\check{\\lambda}$), Section 4.3 (construction of canonical $\\check{\\mu}^c$ and $\\check{\\lambda}^c$), and Proposition 4.3.",
        "Explanation": "The construction of the relative lift $\\check{\\lambda} = \\check{\\nu} - 2\\check{\\mu}_W$ requires extending a class $\\check{\\mu}$ from $\\partial W$ to $\\check{\\mu}_W$ on $W$. Appendix A aims to show this is possible for spin manifolds for relevant dimensions. Lemma A.2 claims $\\tilde{\\Omega}^{\\rm spin}_{4\\ell+3}(K(\\mathbbm{Z},2\\ell+2)) = 0$, which would imply $a(\\check{\\mu})$ extends. The proof relies on $H_{2\\ell+1}(MSpin;\\mathbbm{Z}) \\cong H_{2\\ell+1}(BSpin;\\mathbb{Z})$ vanishing. However, the argument that $H_p(BSpin;\\mathbb{Z})$ vanishes for odd $p$ is incorrect; for example, $H_3(BSpin;\\mathbb{Z}) = \\mathbbm{Z}$ (corresponding to $\\ell=1$). If $H_{2\\ell+1}(MSpin;\\mathbb{Z})$ is non-zero (e.g., for $\\ell=1$), the extension of $a(\\check{\\mu})$ is obstructed. This also affects the extension of auxiliary classes like $u_1, u_2$ used in Proposition 4.3. The paper's central assumption (footnote 1, p.3; Sec 3.3) that such extensions are always possible for the claimed values of $\\ell$ (including $\\ell=1$) is not correctly justified by Appendix A, potentially invalidating the existence or canonicity of $\\check{\\lambda}^c$ and the derived quadratic refinements $Q^c, \\mathcal{Q}^c$ in these cases."
      },
      {
        "Problem": "The formula for the Arf invariant of $\\mathcal{Q}^c$ (Theorem 4.5) might be missing a term, impacting its application to the global anomaly formula.",
        "Location": "Section 4.5, proof of Theorem 4.5 (leading to Eq. 4.6), and its use in Section 7 (Eq. 1.3 / Eq. 6.2).",
        "Explanation": "Theorem 4.5 states $A(\\mathcal{Q}^c) = \\frac{1}{8}\\left( \\int_W \\underline{\\lambda}^c \\wedge \\underline{\\lambda}^c - \\sigma_W \\right) \\pmod 1$. This relies on the Brumfiel-Morgan theorem (Theorem 2.3), which gives $A(\\mathcal{Q}^c) - \\mathcal{Q}^c(b) = \\frac{1}{8}\\left( \\langle \\lambda^c \\cup \\lambda^c, [W,\\partial W] \\rangle - \\sigma_W \\right)$, where $b \\in H^{2\\ell+2}_{\\rm tors}(\\partial W,\\mathbbm{Z})$ is defined by $\\mathcal{Q}^c(s) = L_{\\partial W}(s,b)$ for $s \\in S = \\mathrm{Im}(H^{2\\ell+2}_{\\rm tors}(W) \\to H^{2\\ell+2}_{\\rm tors}(\\partial W))$. The proof of Theorem 4.5 argues that $b$ vanishes or $\\mathcal{Q}^c(b)=0$. While $\\mathcal{Q}^c$ is trivial on $S$ (implying $b \\in S^\\perp$), this does not guarantee $b=0$ or $\\mathcal{Q}^c(b)=0$. If $\\mathcal{Q}^c(b) \\neq 0$, the formula in Theorem 4.5 and its subsequent use in the global anomaly formula (Eq. 1.3, Eq. 6.2) would be incorrect, missing the term $\\mathcal{Q}^c(b)$."
      },
      {
        "Problem": "The proof of the compatibility theorem (Theorem 5.5) relies on an unjustified equivalence between cochain-level cup product expressions and differential form integral expressions for the quadratic refinement $Q^c(x)$.",
        "Location": "Section 5.5, proof of Theorem 5.5, specifically the step from line 3 to line 4 in Eq. 5.10.",
        "Explanation": "The proof of Theorem 5.5 equates the expression $-\\frac{1}{2} \\langle \\hat{z}_1 \\cup (\\hat{z}_1 - \\hat{\\lambda}_1^c), [W_1,\\partial W_1] \\rangle$ with $-Q^c(x)$. $Q^c(x)$ is defined by Eq. 5.2 as $\\frac{1}{2} \\int_{W_1} \\underline{z}_1 \\wedge (\\underline{z}_1 - \\underline{\\lambda}_1^c) \\pmod 1$. The cochain $\\hat{\\lambda}_1^c$ represents the integral cohomology class $a(\\check{\\lambda}_1^c)$, while the form $\\underline{\\lambda}_1^c$ is $\\omega(\\check{\\lambda}_1^c)$. The de Rham class of $a(\\check{\\lambda}_1^c)$ matches that of $\\omega(\\check{\\lambda}_1^c)$, but $a(\\check{\\lambda}_1^c)$ can have a torsion part, $a(\\check{\\lambda}_1^c)_{\\rm tors}$. The difference between the two expressions for $Q^c(x)$ (modulo 1) involves $\\frac{1}{2} \\langle z_1 \\cup a(\\check{\\lambda}_1^c)_{\\rm tors}, [W_1,\\partial W_1] \\rangle$. This term is not necessarily an integer, so the equality modulo 1 is not guaranteed. This potential discrepancy could invalidate the compatibility Theorem 5.5 and its Corollary 5.6, which states that $\\mathcal{Q}^c$ is the quadratic refinement induced by $Q^c$."
      }
    ],
    "token_usage": {
      "input": 37854,
      "thinking": 20557,
      "output": 1498
    }
  },
  {
    "entry_id": 10,
    "retraction_id": "1708.09822v3",
    "paper_id": "1708.09822v2",
    "retraction_comment": "incorrect example (Example 5)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 28483,
      "thinking": 30743,
      "output": 1
    }
  },
  {
    "entry_id": 11,
    "retraction_id": "2011.04373v3",
    "paper_id": "2011.04373v2",
    "retraction_comment": "paper withdrawn since dimension reduction might not hold in the parabolic setting",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified crucial assumption (H5)",
        "Location": "Page 3, H5, Equation (1.2) (labeled hypothesisii)",
        "Explanation": "Hypothesis (H5), particularly the inequality (1.2), is a strong assumption on the solution $u$. It states $\\sup_{-\\theta<t<\\theta}\\int_{B_{\\rho}}|u|^2\\,dx\\geq \\int_{0}^{\\rho}\\sup_{-\\theta<t<\\theta}\\int_{S_r}|u|^2\\,d\\mch^{N-1}\\,dr$. This is a non-standard condition. The general validity of this assumption for weak solutions of the considered equation is not discussed or justified. If this assumption does not hold for all solutions, the theorem's applicability is significantly limited to a potentially small subclass of solutions satisfying this specific property. The acknowledgement indicates this assumption was added to fix a previous error, highlighting its critical role in the argument."
      },
      {
        "Problem": "Incorrect estimation of an integral term in the energy inequality derivation, leading to an erroneous recursive structure",
        "Location": "Page 7, Equation (3.14), specifically the derivation of its last term from $J$ (defined in (3.12), via $J_2 = \\iint |\\nabla (u-k_{i+1})_+|^{q_*} dz$ part of $J$)",
        "Explanation": "The estimation of $J_2 = \\iint_{Q_i} |\\nabla (u-k_{i+1})_+|^{q_*} dz$ (the gradient part of $J$) is flawed. Applying H\\\"older's inequality correctly, $J_2 \\leq (\\iint_{Q_i} |\\nabla (u-k_i)_+|^p dz)^{q_*/p} (|A_{i+1}|)^{(p-q_*)/p}$. The term $|A_{i+1}|^{(p-q_*)/p}$ contributes factors involving $Y_i$ (specifically $(|Q_i|Y_i)^{(p-q_*)/p}$) and powers of $k$. The paper's derivation of the last term in (3.14) effectively replaces $(\\iint |\nabla(u-k_i)_+|^p dz)^{q_*/p}$ with $\\iint |\nabla(u-k_i)_+|^p dz$ (problematic if the integral is $<1$) and, more critically, omits the factor $(|Q_i|Y_i)^{(p-q_*)/p}$. This error means the last term in (3.14) should be proportional to $Z_i^{q_*/p} Y_i^{(p-q_*)/p}$ (ignoring other factors and exponents for clarity) instead of $Z_i$. This incorrect derivation leads to an erroneous definition of $M_i$ in (3.15) (def_A), which should be $M_i \\approx Y_i + Y_i Z_i^\\kappa + Z_i^{\\kappa + q_*/p} Y_i^{(p-q_*)/p}$ instead of $M_i = Y_i + Y_i Z_i^\\kappa + Z_i^{1+\\kappa}$. This fundamentally alters the recursive relations in Section 4 and invalidates the proof of convergence."
      },
      {
        "Problem": "Unmentioned restriction $q < N+1$ required for the applicability of Sobolev embedding on spheres",
        "Location": "Page 5, Lemma 2.4 (sphereembedding) and its application in Page 6, Equation (3.10) (third_term_III)",
        "Explanation": "The proof relies on the Sobolev embedding on the sphere (Lemma 2.4) for functions in $W^{1,s}(S_r^{N-1})$, which is valid for $s \\in [1, N-1)$. In the paper, this lemma is applied with $s=q_*$ (see equation (3.10)). Therefore, the condition $q_* < N-1$ must hold. Given $q_* = q \\frac{N-1}{N+1}$ (defined before (3.8)), this implies $q \\frac{N-1}{N+1} < N-1$, which simplifies to $q < N+1$. This restriction $q < N+1$ is not stated in the hypotheses (H1-H5). Hypothesis (H1) only requires $q < p \\frac{N+1}{N-1}$. If $p > N-1$, then $p \\frac{N+1}{N-1}$ can be larger than $N+1$. For example, if $N=3$ and $p=3$, (H1) allows $q<6$, but the method requires $q<4$. This oversight means the theorem, as stated, is not proven for the entire range of $q$ claimed, specifically when $N+1 \\leq q < p \\frac{N+1}{N-1}$ (for $p>N-1$)."
      },
      {
        "Problem": "Incorrect H\\\"older exponent in an intermediate estimate",
        "Location": "Page 7, Equation (3.13)",
        "Explanation": "In equation (3.13), estimating the integral $J$, H\\\"older's inequality is applied as $J \\leq ( \\iint (\\dots)^p )^{q_*/p} |A_{i+1}|^{\\frac{p-q_*}{q}}$. The correct exponent for the measure term $|A_{i+1}|$ should be $1 - q_*/p = (p-q_*)/p$, not $(p-q_*)/q$ as written. If the written exponent $(p-q_*)/q$ was actually used in deriving the powers of $k$ or $Y_i$ from this step, it would lead to incorrect coefficients unless $p=q$. While subsequent calculations for powers of $k$ in (3.14) seem to stem from a correct application of H\\\"older's inequality for different parts of $J$, this explicit typo in (3.13) is an error and can cause significant confusion."
      }
    ],
    "token_usage": {
      "input": 20460,
      "thinking": 21455,
      "output": 1396
    }
  },
  {
    "entry_id": 12,
    "retraction_id": "2401.02488v3",
    "paper_id": "2401.02488v2",
    "retraction_comment": "Lemma 3.4 on page 7 is incorrect. This is crucial to the argument. The problem that could not be fixed is if there are parts of hilden subgroup elements that contain parts of powers of the garside element",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The claim that the Garside element $\\Delta$ is in the Hilden subgroup $H_n$ is incorrect.",
        "Location": "Proof of Lemma 3.1, p. 5 (Section 3), and its use in Section 4.1 (p. 7) and Section 5 (p. 8). Figure 5 caption also states this.",
        "Explanation": "The paper's core argument for reducing the double coset problem to positive braids relies on $\\Delta \\in H_n$. An element is in $H_n$ (the Hilden subgroup of $B_{2n}$ related to $n$-bridge plat closures) if its plat closure is a trivial $n$-component unlink. The plat closure of $\\Delta_{2n}$ (for $2n$ strands) is generally a non-trivial link for $n>1$ (e.g., for $B_4$, plat($\\Delta_4$) is $L4a1$, not the trivial 2-component unlink). The geometric argument in Figure 5, intended to show plat($\\Delta \\beta$) $\\cong$ plat($\\beta$), which would imply $\\Delta \\in H_n$, is likely flawed. If $\\Delta \\notin H_n$, then $\\Delta^m P_0$ is not generally in the same Hilden double coset as $P_0$, invalidating Lemma 3.1 and the main strategy."
      },
      {
        "Problem": "The proof of Lemma 3.2 makes unjustified assumptions about the elements $A, B \\in H_n$.",
        "Location": "Lemma 3.2 proof, p. 6 (Section 3.1).",
        "Explanation": "The proof states that if $A\\alpha B=P$ (where $\\alpha, P$ are positive, $\\Delta$-free braids, and $A,B \\in H_n$), then $A, B$ can be written as $P_A, P_B$ (positive, $\\Delta$-free parts from Garside decomposition $A=\\Delta^m P_A$, $B=P_B\\Delta^k$) and $P_A \\alpha P_B = P$. This implies $m=0, k=0$. This step requires that $P_A \\alpha P_B$ is $\\Delta$-free, which is not true in general (e.g., if $P_A=\\sigma_1, \\alpha=\\sigma_2\\sigma_1$, then $P_A\\alpha = \\Delta_3$). If $P_A \\alpha P_B = \\Delta^s Q_0$ with $s>0$, then $A=\\Delta^{-s}P_A$, meaning $A$ is not a positive word. The subsequent conclusion $Len(A\\alpha B)=Len(A)+Len(\\alpha)+Len(B)=Len(P)$ 'because each term is positive' is then false, as $A$ (and potentially $B$) might not be representable as positive words, and standard word length additivity does not hold."
      },
      {
        "Problem": "The algorithm to find the minimal positive representative $\\gamma_0$ relies on a search for $A, B \\in H_n$ that is not proven to be finite.",
        "Location": "Procedure to obtain $\\gamma_0$, p. 6 (Section 3.1), particularly the step 'Decide in finite time if there exists $A,B\\in H_n$ with $A\\alpha B=P$'.",
        "Explanation": "The algorithm needs to check if $A\\alpha'B=P$. This check is claimed to be finite because 'there are only finitely many $A,B\\in H_n$ with $Len(A)+Len(\\alpha)+Len(B)=Len(P)$'. This relies on Lemma 3.2, specifically that $A, B$ are positive words and lengths are additive. As explained in Problem 2, $A, B$ are not necessarily positive words. If $A$ or $B$ are not positive words (e.g., contain inverses of generators or $\\Delta^{-1}$ factors), the concept of $Len(A)$ as positive word length is not applicable, and the argument for bounding the search space for $A, B$ fails. Thus, the decidability of this step, and consequently the entire algorithm for solving the Hilden double coset problem, is not established."
      }
    ],
    "token_usage": {
      "input": 8347,
      "thinking": 14744,
      "output": 1007
    }
  },
  {
    "entry_id": 13,
    "retraction_id": "1208.2556v8",
    "paper_id": "1208.2556v7",
    "retraction_comment": "This paper has been withdrawn by the author because (k+1)n<k(n+2) is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The main algebraic argument based on the equation $(2z_0-z_1)+k(3z_0-2z_1)=0$ is flawed because this equation reduces to an identity $0=0$.",
        "Location": "Section 3, from the derivation of $(2z_0-z_1)+k(3z_0-2z_1)=0$ (page 3) to the end of the proof of Theorem 3.1 (page 4).",
        "Explanation": "The variables $z_0$ and $z_1$ are defined by $m_j(2^y-3^x)=z_j$. Substituting $z_0=(2^y-3^x)m_0$ and $z_1=(2^y-3^x)m_2$ into the equation $(2z_0-z_1)+k(3z_0-2z_1)=0$ (where $k$ is from $m_0=2k+1$), and also substituting $m_0=2k+1$ and $m_2=3k+2$, causes the equation to simplify to $(2^y-3^x) \\cdot [ (2(2k+1)-(3k+2)) + k(3(2k+1)-2(3k+2)) ] = 0$, which further simplifies to $(2^y-3^x) \\cdot [k + k(-1)] = 0$, i.e., $(2^y-3^x) \\cdot 0 = 0$. This identity holds true for any value of $2^y-3^x$. Therefore, this equation cannot be used to derive any specific value for $2^y-3^x$ (such as $1$, which would imply $3^x+1=2^y$). The subsequent deduction that $3^x+1=2^y$ is thus unsupported."
      },
      {
        "Problem": "The proof implicitly assumes that $k$ in $m_0=2k+1$ is odd, thereby restricting the types of cycles covered.",
        "Location": "Section 3, paragraph 2, specifically the line \"For odd $m_0$ and $m_2$, then...\" and the subsequent application of Lemma 2.1 to $m_2$.",
        "Explanation": "The proof applies Lemma 2.1 to both $m_0$ and $m_2=C^2(m_0)$. Lemma 2.1 is stated for odd elements of a cycle. For $m_2=(3m_0+1)/2$ to be odd, given $m_0=2k+1$, $m_2=3k+2$ must be odd. This implies $3k$ must be odd, which means $k$ must be odd. The proof does not address cycles where $m_0=2k+1$ and $k$ is an even integer greater than 0 (e.g., $m_0=5$ where $k=2$; $m_0=9$ where $k=4$). For such cycles, $m_2$ would be even, and thus Lemma 2.1 cannot be applied to $m_2$ in the manner shown. The case $k=0$ (for $m_0=1$) is correctly excluded as the theorem searches for cycles other than $\\{1,4,2\\}$."
      },
      {
        "Problem": "The deduction that $z_0=2n+1$ is not generally valid.",
        "Location": "Page 3, paragraph starting \"Let $z_0=2n$\" and concluding \"precisely $2n+1$\".",
        "Explanation": "The argument that $z_0$ must be $2n+1$ relies on establishing $2n < z_0 < 2n+2$. The upper bound $z_0 < 2n+2$ is derived from the inequality $(k+1)n < k(n+2)$, which simplifies to $n<2k$. This inequality is assumed (\"Obviously $\\forall n \\in \\mathbb{N}, n \\geq k: (k+1)n<k(n+2)$\", which is false if $n \\ge 2k$). If $n \\ge 2k$, this argument for $z_0 < 2n+2$ fails. For example, if $n=2k$, the equation $(k+1)n=k(z_0-n)$ yields $z_0=2n+2$. If $n=3k$, it yields $z_0=2n+3$. These cases correspond to $2^y-3^x = c$ for $c \\ge 2$. The paper does not adequately rule out these possibilities to uniquely conclude $z_0=2n+1$ (which corresponds to $c=1$, i.e., $2^y-3^x=1$). While this issue is part of the larger argument rendered moot by the first critical problem, it represents a distinct logical flaw in this specific part of the derivation."
      }
    ],
    "token_usage": {
      "input": 4462,
      "thinking": 16759,
      "output": 1154
    }
  },
  {
    "entry_id": 14,
    "retraction_id": "1905.08897v3",
    "paper_id": "1905.08897v2",
    "retraction_comment": "Although the quasi-nodal surface has been identified in our preprint, there is a tiny band gap (millivolt-level) in the non high symmetry k-line (e.g.,K1-K5). In this regard, the proposed bct-C40 should be a nodal net semimetal based on the strict definition of topological semimetal. We would like to withdraw this work to avoid misleading the readers from Arxiv",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Insufficient demonstration of continuous 2D degeneracy for nodal surfaces",
        "Location": "Page 3, paragraph starting 'To ascertain the actual situation...', Figure 2",
        "Explanation": "The paper asserts the formation of nodal surfaces based on 3D Brillouin Zone calculations but does not provide sufficient methodological detail on how the continuous 2D nature of these degeneracies was rigorously established. It is not detailed how these were distinguished from, for example, a very dense collection of 1D nodal lines or potential artifacts arising from k-space sampling density or interpolation methods. This lack of detail makes it difficult to fully assess the robustness of the primary evidence supporting the nodal surface claim."
      },
      {
        "Problem": "Lack of explicit symmetry analysis for the claimed nodal surfaces",
        "Location": "Page 3, last paragraph; Page 4, first paragraph; citing Ref [5]",
        "Explanation": "The paper classifies the claimed nodal features as 'Class-I nodal surfaces' purportedly protected by mirror symmetry. However, it omits a specific symmetry analysis for bct-C40 (space group I4/mmm) that would identify the particular mirror symmetries responsible for protecting the claimed surfaces. It also does not demonstrate how these symmetries lead to the extensive 2D degeneracies depicted in Figure 2. Such analysis is crucial for establishing the topological nature and stability of the claimed nodal surfaces."
      },
      {
        "Problem": "Potential oversimplification of the relationship between nodal nets and nodal surfaces",
        "Location": "Overall argument, e.g., Page 1, Abstract ('in fact a nodal surface semimetal'), Page 4, Conclusion ('Thus bct-C40 is actually just a new member of topological nodal surface semimetals')",
        "Explanation": "The paper frames its findings as a reclassification from a nodal-net to a nodal-surface semimetal, implying these descriptions are mutually exclusive for bct-C40. It does not consider or discuss the possibility that nodal lines (potentially forming a net) could coexist with nodal surfaces, or that the lines reported in the original study (Ref. [1]) might be specific features embedded within, or constituting parts of, the more extensive surfaces the 'Comment' authors find. This potentially oversimplified dichotomy might affect the interpretation of how the previous findings relate to the new claims."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 9224,
      "output": 513
    }
  },
  {
    "entry_id": 15,
    "retraction_id": "1712.07752v2",
    "paper_id": "1712.07752v1",
    "retraction_comment": "Based on the numerous reviews I have received, the figures illustrated in the paper are highly incorrect and vague. This might guide a novice reader towards a wrong direction and lead to improper understanding of the subject. Also, the paper covers a diverse range of topics but doesn't get into the details of any and hence the proposals remain pragmatically irrelevant",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The 'Unanimous' Requirement for UIRB-AI",
        "Location": "Title, Abstract, and multiple sections including 'Need for an unanimous international regulatory body for AI'",
        "Explanation": "The paper's insistence on a 'unanimous' international body for AI regulation sets an extremely high and likely unattainable bar for its formation and operation, given the complexities and divergent interests of nations. This fundamental requirement may render the proposal unworkable, as the paper does not adequately address how such unanimity would be achieved or sustained, potentially invalidating the proposed solution."
      },
      {
        "Problem": "Flawed Premise of Economic Superiority for International Governance",
        "Location": "Figure 2, Section 'Artificial Intelligence and National Governance', Section 'Need for an economically superior UIRB-AI'",
        "Explanation": "The argument that an international body like the proposed UIRB-AI must be economically superior to its member states to be effective is based on a flawed analogy between the UN (an organization of sovereign states) and federal systems (Figure 2), and an oversimplified view of international relations. This unsound premise incorrectly justifies the subsequent extreme proposal for funding the UIRB-AI, thereby weakening the paper's central argument for the body's structure and power."
      },
      {
        "Problem": "Impracticality of the Proposed 'AI Tax' for Achieving Economic Supremacy",
        "Location": "Section '\\textit{AI Tax} and \\textit{Robot Tax}: Revenue generation for the UIRB-AI'",
        "Explanation": "The proposed 'AI tax,' intended to make the UIRB-AI economically dominant over nations (based on the flawed premise of Problem 2), is politically and practically unfeasible. Sovereign nations are highly unlikely to cede such extensive taxation authority or allow an international body to achieve the suggested level of financial power. This makes the core funding and empowerment mechanism for the UIRB-AI unrealistic, undermining the viability of the overall proposal."
      },
      {
        "Problem": "Dependency on Radical and Unlikely Broader UN Reforms",
        "Location": "Section 'Why the United Nations?'",
        "Explanation": "The paper implies that the success and ideal functioning of the UIRB-AI are contingent upon fundamental and radical reforms to the United Nations itself (e.g., direct election of UN delegates, UN budget exceeding national budgets). Such large-scale geopolitical transformations are highly improbable in the foreseeable future, making the UIRB-AI proposal dependent on unrealistic preconditions that are outside the scope of AI governance alone."
      },
      {
        "Problem": "Confusing Application of Gartner Hype Cycle to AI Risk Management",
        "Location": "Figure 3b, Section 'Objectives of the UIRB-AI'",
        "Explanation": "Figure 3b's use of a 'Modified Gartner's hype cycle' to represent the management of 'Risks of AI' is conceptually flawed and misleading. The hype cycle typically models technology adoption and expectations, not the active suppression or mitigation of risks. This misapplication creates confusion about how the UIRB-AI would strategize, measure, or achieve its objective of minimizing AI risks, indicating a weakness in the conceptual framework for the UIRB-AI's objectives."
      }
    ],
    "token_usage": {
      "input": 9028,
      "thinking": 5711,
      "output": 717
    }
  },
  {
    "entry_id": 16,
    "retraction_id": "2110.09901v3",
    "paper_id": "2110.09901v2",
    "retraction_comment": "It relies on maximizing the distance over an intersection of balls to a given point. The used algorithm for this however, is not able to solve the class of problem the SSP generates",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect radius calculation for hypercube approximating balls",
        "Location": "Section 3.1, Equations (E3.20), (E18b) and surrounding text",
        "Explanation": "The centers $C_{k+} = \\frac{1}{2} \\cdot 1 + q_k e_k$ and $C_{k-} = \\frac{1}{2} \\cdot 1 - q_k e_k$ are intended to define balls that approximate the hypercube constraints $x_k \\le 1$ and $x_k \\ge 0$ respectively. The radius $r_{k+}$ for the ball $\\mathcal{B}(C_{k+}, r_{k+})$ should be determined by the corners of the facet $x_k=1$ (center $F_{k1} = \\frac{1}{2} \\cdot 1 + \\frac{1}{2} e_k$). Similarly, $r_{k-}$ for $\\mathcal{B}(C_{k-}, r_{k-})$ should be determined by corners of facet $x_k=0$ (center $F_{k0} = \\frac{1}{2} \\cdot 1 - \\frac{1}{2} e_k$). Equation (E3.20) incorrectly associates $C_{k+}$ with $F_{k0}$ and $C_{k-}$ with $F_{k1}$: $r_{k+}^2 = \\|F_{k0} - C_{k+}\\|^2 + (\\frac{\\sqrt{n-1}}{2})^2$ and $r_{k-}^2 = \\|F_{k1} - C_{k-}\\|^2 + (\\frac{\\sqrt{n-1}}{2})^2$. This fundamental error in geometric construction means the set $\\tilde{\\mathcal{Q}}_\\rho$, and thus $\\mathcal{Q}_\\rho$, may not correctly approximate the hypercube as intended, potentially not even containing it or having the desired properties for later proofs."
      },
      {
        "Problem": "The crucial claim that $\\mathcal{Q}_\\rho \\subseteq \\bar{\\mathcal{B}}(\\frac{1}{2} \\cdot 1, \\frac{\\sqrt{n}}{2})$ (denoted $B_0$) is unsubstantiated and likely false.",
        "Location": "Remark 4, point 3 (page 7) and its use in Lemma 3.4a (page 9)",
        "Explanation": "Lemma 3.4a, which is central to proving that the algorithm finds a $\\{0,1\\}$ solution if one exists, relies on $x^{\\star}_\\rho \\in \\mathcal{Q}_\\rho \\subseteq B_0$. The proof sketch for $\\mathcal{Q}_\\rho \\subseteq B_0$ in Remark 4 (point 3) is insufficient. A counter-analysis (detailed in thought process) suggests that $\\tilde{\\mathcal{Q}}_\\rho$ (and thus $\\mathcal{Q}_\\rho$) is generally not a subset of $B_0$ for $\\rho > 0$. If this inclusion is false, then point 1 of Lemma 3.4a ($\\left\\|x^{\\star}_{\\rho} - \\frac{1}{2} \\cdot 1_{n \\times 1} \\right\\| \\leq \\frac{\\sqrt{n}}{2}$) is false, and the subsequent arguments in Lemma 3.4a that depend on $x^{\\star}_\\rho$ being in $B_0$ (like deriving $x^{\\star}_\\rho \\in \\{0,1\\}^{n \\times 1}$) are invalidated."
      },
      {
        "Problem": "The claim that points in $\\tilde{\\mathcal{Q}}_\\rho \\cap \\partial B_0$ must be hypercube corners (i.e., in $\\{0,1\\}^n$) is unsubstantiated.",
        "Location": "Lemma 3.4a, proof of point 2 (page 9)",
        "Explanation": "The proof that if $\\left\\|x^{\\star}_{\\rho} - \\frac{1}{2} \\cdot 1_{n \\times 1} \\right\\| = \\frac{\\sqrt{n}}{2}$ then $x^{\\star}_{\\rho} \\in \\{0,1\\}^{n \\times 1}$ relies on the assertion $x^{\\star}_{\\rho} \\in \\tilde{\\mathcal{Q}}_\\rho \\cap \\partial B_0 \\subseteq \\{0,1\\}^{n \\times 1}$. While the hypercube's intersection with its circumsphere $\\partial B_0$ yields only its corners, $\\tilde{\\mathcal{Q}}_\\rho$ is an intersection of balls approximating the hypercube. It is not proven that $\\tilde{\\mathcal{Q}}_\\rho$ cannot intersect $\\partial B_0$ at points other than hypercube corners, especially if $\\tilde{\\mathcal{Q}}_\\rho$ 'bulges' outside the hypercube. Without this property, $x^{\\star}_\\rho$ having norm $\\frac{\\sqrt{n}}{2}$ with respect to the hypercube center does not guarantee it is a $\\{0,1\\}$ vector."
      },
      {
        "Problem": "The assumption that $\\mathcal{X}^{\\star}_{\\rho,C}$ (the minimizer in Eq. E54b) is a unique point is strong and unjustified.",
        "Location": "Section 3.4, paragraph after Eq. (E54b) (page 10)",
        "Explanation": "The function $h_{\\rho}(x) - \\|x - C\\|^2$ is a maximum of affine functions, hence it is convex. The feasible set $h_{\\rho}(x) \\leq 1$ is also convex. A convex function minimized over a convex set may have non-unique minimizers (e.g., if the function is flat in some region or its level sets align with the boundary). The subsequent analysis (e.g., defining $\\bar{R}^2_{\\rho,C}$ based on $x^{\\star}_{\\rho,C}$ and casework based on $h_{\\rho}(x^{\\star}_{\\rho,C})$) implicitly relies on $x^{\\star}_{\\rho,C}$ being a well-defined single point. If the minimizer is not unique, the algorithm's path is not clearly defined."
      },
      {
        "Problem": "Mismatch between the 'FPTAS' claim in the title and the described algorithm's nature and complexity.",
        "Location": "Title, Abstract, Section 3.5 (Brief overview on the complexity), Conclusion",
        "Explanation": "The paper is titled 'A FPTAS for the Subset Sum Problem with Real Numbers'. An FPTAS (Fully Polynomial Time Approximation Scheme) for subset sum typically implies an algorithm that finds an approximate solution (e.g., sum close to target, or variables close to 0/1) in time polynomial in $n$ and $1/\\epsilon$, where $\\epsilon$ is the approximation parameter. However, the conclusion claims the algorithm can assert exact feasibility: 'if the returned candidate is a solution ..., then we assert that the subset sum has a solution otherwise we assert that it does not'. The complexity $\\mathcal{O} ( \\log ( \\frac{\\bar{R}_{\\rho, C}}{\\epsilon} ) \\cdot \\text{poly}(n) )$ involves an $\\epsilon$ related to the precision of a bisection search for a radius $R$, not directly to the subset sum approximation quality in the standard FPTAS sense. This suggests an exact algorithm (perhaps under a real number computation model like BSS) rather than an FPTAS. The conceptual framing is inconsistent."
      }
    ],
    "token_usage": {
      "input": 39062,
      "thinking": 18362,
      "output": 1752
    }
  },
  {
    "entry_id": 17,
    "retraction_id": "2001.09967v3",
    "paper_id": "2001.09967v2",
    "retraction_comment": "This paper is withdrawn because there is an error in the last section: the algebraic identities, in the limit n-> \\infty, all collapse to the first conservation law. One could wonder whether this can be fixed via a suitable renormalization scheme but at present, the argument is incomplete",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed step in proof of Theorem 3",
        "Location": "Page 5, Proof of Theorem 3",
        "Explanation": "The proof states: \"The Cauchy-Schwarz inequality implies $2 \\int u(t,x) x^2 dx \\leq 2 M(-m) \\leq m^2 + M^2$.\" This line has multiple issues. First, the quantity $2 \\int u(t,x) x^2 dx$ is not $2 \\times \\text{Variance}$ of the relevant probability distribution $w(x) = u(t,x)/(1-t)$ (assuming mean 0), to which the Bhatia-Davis inequality applies. The variance involves $\\int \\frac{u(t,x)}{1-t} x^2 dx$. Second, the first inequality $2 \\text{Var}(w) \\leq 2M(-m)$ (if that was intended) stems from Bhatia-Davis inequality, not Cauchy-Schwarz. While the theorem's conclusion might be reachable through a corrected argument, this specific step as presented is unsound."
      },
      {
        "Problem": "Unjustified extension of Hilbert Transform identity to unbounded support",
        "Location": "Page 7, Section 4.2, discussion of Gaussian initial data",
        "Explanation": "The paper claims that for an initial Gaussian density $u(0,x) = e^{-(x-1)^2}/\\sqrt{\\pi}$ (which has unbounded support), an explicit computation \"is sufficient to show that\" one of the derived Hilbert Transform identities holds. However, these identities (derived in Section 2.2) are contingent on the validity of the proposed PDE. The paper acknowledges (e.g., Section 1.2, Section 2.2 'A Word of Warning') that the PDE's derivation is for initial data $u(0,x)$ that is compactly supported on a single interval. Extending the PDE's consequences, such as the Hilbert Transform identities, to functions with unbounded support without rigorously establishing the PDE's applicability in this broader context is an overstatement of the result's domain."
      }
    ],
    "token_usage": {
      "input": 17528,
      "thinking": 23510,
      "output": 475
    }
  },
  {
    "entry_id": 18,
    "retraction_id": "2003.01493v2",
    "paper_id": "2003.01493v1",
    "retraction_comment": "Theorem 3.3 is not true in general. If it holds, for example, when n=2, we infer that all 2-cluster tilting subcategories are 2Z-cluster tilting, but it can't hold in general",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially insufficient justification for the $n$-exactness of a mapping cone.",
        "Location": "Proof of Lemma 3.2 (Lemma \\ref{contra}), specifically the argument for '(iii) => (ii)' in the case r=s=1 (page 10).",
        "Explanation": "The proof states: 'By the $n$-exactness of the mapping cone of $n$-pushout $H\\to \\lambda_E\\cdot H$, there exists $s:M\\to E^n$ such that $us=t,\\lambda_Es=0$'. This step requires the mapping cone to be exact at the term $H^1 \\oplus B$ (i.e., $\\Ker d_C^0 = \\Img d_C^{-1}$). However, an $n$-pushout diagram's mapping cone $C(f)$ is generally only guaranteed to be right $n$-exact (as stated in Section 2.2(2) of the paper). For $C(f)$ to be $n$-exact (exact at all positions), additional conditions on the map $f^0$ (here $\\lambda_E: E^n \\to B$) or the complex $X$ (here $H_X = (E^n \\xrightarrow{u} H^1 \\to \\dots \\to H^{n-1})$) are typically needed (e.g., $f^0$ being a monomorphism and $X$ being $n$-exact, as in Jasso [GJ, Prop 4.6(3)]). The map $\\lambda_E$ is the last map of an $n$-extension $E$, which is typically an epimorphism, not necessarily a monomorphism. Without explicit justification for why this specific mapping cone is $n$-exact (beyond right $n$-exact), the argument for the existence of such $s$ (which is crucial for the lemma) is not fully substantiated by the reason provided. While the claim itself might be derivable through other means, the paper's stated reliance on the cone's full $n$-exactness at this step lacks clear support."
      }
    ],
    "token_usage": {
      "input": 25602,
      "thinking": 23058,
      "output": 473
    }
  },
  {
    "entry_id": 19,
    "retraction_id": "2005.08379v2",
    "paper_id": "2005.08379v1",
    "retraction_comment": "Figure 1 is incorrect. Will be updated in the revision",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of Normalization and Uncontrolled Confounding Variables",
        "Location": "Section 3.1 (Temporal Analysis, Figure 3), Table 1, Abstract, Section 4 (Discussion and Conclusion)",
        "Explanation": "The study compares absolute volumes of tweets and trends across countries without normalizing for population size, Twitter penetration rates, or general internet usage. This makes it difficult to ascertain if higher volumes in S2 countries reflect a more targeted COVID-19 response or simply higher baseline Twitter activity. Crucially, the paper implies a causal link between Twitter activity and pandemic spread (e.g., 'effective social media usage can influence public behavior') without controlling for major confounding variables such as government policies, healthcare system quality, population density, testing rates, or demographic differences, which significantly impact pandemic outcomes. This omission makes the causal interpretation unsound."
      },
      {
        "Problem": "Inadequate Handling of Multilingual Data in NLP Tasks",
        "Location": "Section 3.2 (Topic Modeling, Figure 4, Table 2), Section 3.3 (Sentiment Analysis, Figure 5)",
        "Explanation": "The methodology for processing and comparing textual data across multiple languages is unclear and potentially flawed. Topic modeling results (Figure 4, Table 2) present a mix of English and native language terms, making direct comparisons of topic 'dominance' unreliable without a robust cross-lingual framework. For sentiment analysis, using TextBlob (primarily optimized for English) on untranslated non-English tweets (from Spain, Italy, Sweden, Austria, Belgium) would yield inaccurate sentiment scores. If translation was performed, its impact on meaning and sentiment is not discussed or evaluated, undermining the validity of conclusions about topic prevalence and user sentiment in different countries."
      },
      {
        "Problem": "Oversimplified Definition and Measurement of 'Pandemic Spread'",
        "Location": "Section 3.1 (Case Study setup), Table 1, Abstract, Section 4",
        "Explanation": "The paper defines 'lower pandemic spread' primarily based on absolute total case counts by a specific date (April 19, 2020, for country selection; April 5, 2020, for case study comparison). This metric fails to account for crucial factors like population size (i.e., per capita rates), differences in testing capacity and strategies across countries, and the varying timelines of the pandemic wave in each nation. Grouping countries into S1 (higher spread) and S2 (lower spread) based on this crude measure may not accurately reflect differences in pandemic severity or management effectiveness, thereby weakening the foundation of the comparative analysis and the conclusions drawn from it."
      },
      {
        "Problem": "Potentially Flawed Tweet Categorization Logic for Volume Analysis",
        "Location": "Section 3.1, Algorithm 1 (lines 8-9), Figure 3a",
        "Explanation": "Algorithm 1, used for temporal analysis, includes a condition (lines 8-9) where tweets are counted if they appear under a COVID-19 related trend, even if the tweet text itself does not contain COVID-19 keywords. This means tweets that are off-topic, spam, or replies without direct relevance to COVID-19 could be included in the 'tweets in COVID-19 related trends' (Figure 3a). This potentially inflates the volume of COVID-19 specific discussion and weakens the interpretation of Figure 3a as a measure of user engagement specifically on COVID-19 topics within those trends."
      },
      {
        "Problem": "Overgeneralization and Inconsistent Support for Sentiment Analysis Claims",
        "Location": "Abstract, Section 3.3 (Sentiment Analysis, Figure 5)",
        "Explanation": "The abstract claims that 'in countries with a lower spread, users had a positive sentiment towards COVID-19 preventive measures.' However, the detailed results in Figure 5 provide mixed and inconsistent support for this generalization. For example, sentiment towards 'social distancing' is not uniformly more positive in S2 countries compared to S1. For 'quarantine,' all countries show similar positive sentiment. While Austria and Belgium (S2) show strong positive sentiment for 'lockdown,' Sweden (also S2) does not exhibit the same pattern. This discrepancy between the summarized claim and the nuanced (and potentially flawed due to language issues) data undermines this specific conclusion."
      }
    ],
    "token_usage": {
      "input": 15010,
      "thinking": 5855,
      "output": 951
    }
  },
  {
    "entry_id": 20,
    "retraction_id": "2408.09172v3",
    "paper_id": "2408.09172v2",
    "retraction_comment": "The model diagram in Figure 1 on page 3 of the paper has significant ambiguities. It may lead readers to mistakenly believe that the experiments were conducted in a multi-turn dialogue format. Therefore, we request the withdrawal of this submission",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Confounding Effect of Random Supplementation for ICL Examples",
        "Location": "Section 5.1 'Example Selection Details'; impacts interpretation of Table 1 results.",
        "Explanation": "The methodology allows supplementing Unc-TTP categories with random examples if insufficient instances are available for K-way 1-shot ICL (requiring K examples, one per class label). If the 'Uncertain' categories that perform best on the validation set (and are subsequently used for test results in Table 1) frequently require such supplementation, their reported superior performance could be partially attributable to these random examples rather than purely to the intrinsic properties of the Unc-TTP-defined uncertainty of that category. The paper does not quantify the frequency or extent of this supplementation for the 1-shot results in Table 1, making it difficult to assess its true impact and potentially weakening the claim that specific Unc-TTP uncertainty types are inherently more informative."
      },
      {
        "Problem": "Selection of Optimal 'Uncertain' Sub-Category via Validation Obscures Generalizability of a Single Uncertainty Type",
        "Location": "Section 5.1 'Example Selection Details'; Table 1 (specifically the 'Unc' rows for Unc-TTP); Appendix Table 4.",
        "Explanation": "The paper reports that 'Uncertain' (Unc) examples selected by Unc-TTP outperform others. However, 'Uncertain' comprises six distinct sub-categories. The best-performing sub-category is chosen based on validation set accuracy for each model/dataset combination. This means there isn't a single, universally superior type of Unc-TTP-defined uncertainty that is identified and applied. The conclusion that 'Unc-TTP uncertain examples are better' relies on this validation-driven selection of a specific wavering pattern from the six options. This makes the claim about the utility of Unc-TTP's 'uncertain' classification less direct, as it depends on an intermediate tuning step to find the most effective sub-category for each specific setup, rather than identifying a generally applicable 'uncertain' state."
      },
      {
        "Problem": "Unc-TTP Prompt May Induce Artificial 'Wavering' Not Reflective of True Model Uncertainty",
        "Location": "Section 3.1 (description of prompts for right/wrong label settings); Section 3.2 'Uncertainty Category Labeling'.",
        "Explanation": "The Unc-TTP framework classifies instances as 'uncertain' based on model responses to prompts that include injected labels and a directive: '...you should still have your own thinking and do not change your stance so easily.' Certain resulting patterns of (dis)agreement are labeled 'uncertain.' This complex instruction could lead to model behaviors that are artifacts of interpreting this nuanced prompt (e.g., confusion, specific reactions to the 'do not change stance easily' clause) rather than expressions of intrinsic uncertainty about the task instance itself. If the observed 'wavering' is significantly influenced by the prompt's specific phrasing, the conclusion that Unc-TTP effectively classifies and leverages genuine model uncertainty for ICL could be based on a mischaracterization of the model's state."
      },
      {
        "Problem": "Limited Availability and Practical Utility of Theoretically 'Most Informative' Uncertain Categories",
        "Location": "Section 4.2 'Uncertainty Category Distribution' (especially Figure 4 and the accompanying text discussing scarcity of categories like '011').",
        "Explanation": "The paper suggests that certain Unc-TTP categories, like '011' (incorrect with no-label, correct with right-label, correct with wrong-label), are anticipated to be 'most informative.' However, it also states these categories 'are also scarce.' If the theoretically most potent types of uncertainty identified by Unc-TTP are consistently rare across datasets and models, their practical utility for the proposed ICL example selection strategy is diminished. The method might then often rely on more common but potentially less 'deeply' informative uncertain categories, or face frequent supplementation issues (linking to Problem 1), potentially limiting the realized impact of the Unc-TTP classification in finding these specific high-value examples."
      }
    ],
    "token_usage": {
      "input": 20607,
      "thinking": 6659,
      "output": 916
    }
  },
  {
    "entry_id": 21,
    "retraction_id": "1207.2800v2",
    "paper_id": "1207.2800v1",
    "retraction_comment": "This paper has been withdrawn by the authors because the proof of Lemma 3.3 has a gap. More precisely, the claim \"If R has a pylonic vertex, v, incident with at least two cables, the pylonicity of v is destroyed by the splitting of any corner\", as stated, is unjustified and looks false in whole generality; the authors overlooked some cases",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect redefinition of 'rod' and 'irreducible' for punctured surfaces.",
        "Location": "Page 4, Section 3, first paragraph (the 'agreement')",
        "Explanation": "The paper makes an 'agreement' that for punctured surfaces S-D (S != S0), an edge 'e is a rod provided e occurs in some non-null-homotopic 3-cycle, and e is a cable otherwise.' This redefines what a 'rod' (unshrinkable edge) is. However, an edge is fundamentally unshrinkable (a rod) if shrinking it creates multiple edges or changes topology. An edge in a null-homotopic, non-facial 3-cycle would create multiple edges upon shrinking, making it a rod by the primary definition (page 3). Under the new 'agreement,' such an edge would be classified as a 'cable.' This redefinition could mean that triangulations considered 'irreducible' under this new agreement might actually contain shrinkable edges (cables by the primary definition), invalidating the concept of irreducibility used and potentially affecting the finiteness proof (Theorem 3.5) and enumeration results for punctured surfaces (e.g., Mobius band in Section 5)."
      },
      {
        "Problem": "Contradictory argument in the proof of Lemma 3.4 regarding boundary edges.",
        "Location": "Page 6, Proof of Lemma 3.4, Case 2",
        "Explanation": "In Case 2 of the proof of Lemma 3.4, it is assumed that 'The length of dD is equal to 3.' The proof then proceeds to 'Assume that there is at least one cable in dD.' However, condition (2.3) on page 3 states: 'e is a boundary edge in the case in which the boundary cycle is a 3-cycle' is an impediment to shrinkability, meaning such an edge is a rod. If the boundary dD is a 3-cycle, its edges are boundary edges and thus should be rods in T, not cables. This contradiction regarding the nature of edges in dD (if they are edges of T) makes this part of the proof of a key lemma unsound. Lemma 3.4 is crucial for establishing the finiteness of irreducible triangulations for punctured surfaces."
      },
      {
        "Problem": "Flawed reasoning in the proof of Lemma 6.1 for pinched torus triangulations.",
        "Location": "Page 13, Proof of Lemma 6.1",
        "Explanation": "The proof of Lemma 6.1 states that if T is an irreducible triangulation of S0[2], then V(T) = {s1, s2} U N(s1) U N(s2). In the proof by contradiction, for a vertex v not in this set, it considers deg(v,T) >= 4. It then claims 'each edge incident with v could only satisfy condition (6.1)' for being a rod. This dismisses conditions (6.2) (edge in a path of length 3 joining s1 with s2) and (6.3) (edge in dSt(si) if it's a 3-cycle) without sufficient justification. An edge incident to v could potentially satisfy (6.2) if v is an internal vertex of such a path, even if v is not a neighbor of s1 or s2. The subsequent argument relying on Kuratowski's Theorem is based on this possibly incorrect premise, weakening the proof of a lemma fundamental to the classification of irreducible pinched torus triangulations (Theorem 6.3)."
      },
      {
        "Problem": "Incorrect argument for non-isomorphism of projective plane triangulations P1 and P2.",
        "Location": "Page 9, paragraph preceding Theorem 4.2",
        "Explanation": "The paper argues for the pairwise non-isomorphism of triangulations in Fig. 2 by stating they 'have pairwise non-isomorphic cable-subgraphs (emphasized by bold lines) except for the pairs: {P1,P2}, ...'. P1 (also referred to as P_R) and P2 are the two irreducible triangulations of the projective plane (stated on page 7). By definition, irreducible triangulations contain no cables. Therefore, their cable-subgraphs are empty. Empty graphs are isomorphic to each other. Thus, the claim that P1 and P2 have non-isomorphic cable-subgraphs is false. While P1 and P2 are indeed non-isomorphic (as later argued by vertex-degree sequences), this specific part of the reasoning is erroneous."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 10052,
      "output": 1009
    }
  },
  {
    "entry_id": 22,
    "retraction_id": "2212.04565v2",
    "paper_id": "2212.04565v1",
    "retraction_comment": "There is an error. Some cases were not considered in the proof of Theorem 1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Corollary 2.2 is false.",
        "Location": "Page 3, Corollary 2.2",
        "Explanation": "The equality asserted in Corollary 2.2, $N[(g_k,h_k)] \\setminus \\cup_{i=1}^{k-1}N[(g_i,h_i)] = \\{(c,d) : c \\in N[g_k]\\setminus \\cup_{i=1}^{k-1}N[g_i], d\\in N[h_k]\\} \\cup \\{(c,d) : c \\in N[g_k], d\\in N[h_k]\\setminus \\cup_{i=1}^{k-1}N[h_i]\\}$, does not hold for $k > 2$. Let $X_j = N[g_j]$ and $Y_j = N[h_j]$. The corollary claims $(X_k \\times Y_k) \\setminus \\cup_{i=1}^{k-1} (X_i \\times Y_i) = ((X_k \\setminus \\cup_{i=1}^{k-1}X_i) \\times Y_k) \\cup (X_k \\times (Y_k \\setminus \\cup_{i=1}^{k-1}Y_i))$. The right hand side (RHS) is a subset of the left hand side (LHS), but LHS is not necessarily a subset of RHS. For a counterexample, let $k=3$. Let $X_1=\\{1\\}, Y_1=\\{a\\}$, $X_2=\\{2\\}, Y_2=\\{b\\}$, and $X_3=\\{1,2,3\\}, Y_3=\\{a,b,c\\}$. Then the element $(1,b)$ is in LHS but not in RHS. Specifically, $(1,b) \\in X_3 \\times Y_3$. $(1,b) \\notin X_1 \\times Y_1$ (since $b \\neq a$) and $(1,b) \\notin X_2 \\times Y_2$ (since $1 \\neq 2$). So $(1,b) \\in LHS$. For the RHS, $X_1 \\cup X_2 = \\{1,2\\}$ and $Y_1 \\cup Y_2 = \\{a,b\\}$. So $X_3 \\setminus (X_1 \\cup X_2) = \\{3\\}$ and $Y_3 \\setminus (Y_1 \\cup Y_2) = \\{c\\}$. The RHS becomes $(\\{3\\} \\times Y_3) \\cup (X_3 \\times \\{c\\})$. The element $(1,b)$ is not in this set."
      },
      {
        "Problem": "Corollary 2.3 is false and its proof is unsound.",
        "Location": "Page 3, Corollary 2.3",
        "Explanation": "Corollary 2.3 states an inequality for the size of the set difference: $|N[(g_k,h_k)] \\setminus \\cup_{i=1}^{k-1}N[(g_i,h_i)]| \\leq |(N[g_k]\\setminus \\cup_{i=1}^{k-1}N[g_i])| \\times |N[h_k]| + |(N[h_k]\\setminus \\cup_{i=1}^{k-1}N[h_i])| \\times |N[g_k]|$. The proof of this corollary relies on the equality from Corollary 2.2, which is false. Furthermore, the inequality stated in Corollary 2.3 is itself false. Using the same counterexample as for Corollary 2.2 (with $X_j=N[g_j], Y_j=N[h_j]$: $X_1=\\{1\\}, Y_1=\\{a\\}$; $X_2=\\{2\\}, Y_2=\\{b\\}$; $X_3=\\{1,2,3\\}, Y_3=\\{a,b,c\\}$): The LHS of the inequality is $|(X_3 \\times Y_3) \\setminus ((X_1 \\times Y_1) \\cup (X_2 \\times Y_2))| = |(\\{ (1,a), (1,b), (1,c), (2,a), (2,b), (2,c), (3,a), (3,b), (3,c) \\}) \\setminus \\{ (1,a), (2,b) \\}| = 7$. The RHS sum is $|(X_3 \\setminus (X_1 \\cup X_2))| \\times |Y_3| + |(Y_3 \\setminus (Y_1 \\cup Y_2))| \\times |X_3| = |\\{3\\}| \\times |Y_3| + |\\{c\\}| \\times |X_3| = (1 \\times 3) + (1 \\times 3) = 3+3=6$. The inequality $7 \\leq 6$ is false. This corollary is critical for the main theorem's proof."
      },
      {
        "Problem": "Flawed logical deduction in the proof of Conjecture 1.1 regarding the conditions for newly dominated vertices.",
        "Location": "Page 4, Subsection 'Proof of Conjecture 1.1'",
        "Explanation": "The proof argues that $|N[(g_k,h_k)] \\setminus \\cup_{i=1}^{k-1}N[(g_i,h_i)]|$ becomes 0 if $N[g_k]\\setminus \\cup_{i=1}^{k-1}N[g_i]= \\emptyset$ and $N[h_k]\\setminus \\cup_{i=1}^{k-1}N[h_i]=\\emptyset$. It then claims: 'The former equality holds when there are at most $\\gamma_{gr}(G)$ elements in the sequence and the second equality holds when there are at most $\\gamma_{gr}(H)$ elements in the sequence.' This reasoning is flawed. The definition of $\\gamma_{gr}(G)$ implies that any sequence of $p > \\gamma_{gr}(G)$ *distinct* vertices $x_1, \\dots, x_p$ is not a Grundy sequence in $G$, meaning for *some* $j \\leq p$, $N[x_j] \\setminus \\cup_{l=1}^{j-1}N[x_l] = \\emptyset$. This does not imply that for the specific $k$-th vertex $g_k$ in the sequence $(g_1, \\dots, g_k)$ (where $g_i$ are not necessarily distinct, nor is $(g_1, \\dots, g_k)$ a Grundy sequence for $G$), $N[g_k]\\setminus \\cup_{i=1}^{k-1}N[g_i]$ must be empty just because $k$ is large or the number of distinct $g_i$'s is large. The set $\\cup_{i=1}^{k-1}N[g_i]$ is also different from the union in the Grundy definition if $g_i$ are not distinct or not chosen by Grundy criteria."
      },
      {
        "Problem": "Circular reasoning in the conclusion of the proof of Conjecture 1.1.",
        "Location": "Page 4, Subsection 'Proof of Conjecture 1.1', last two sentences",
        "Explanation": "The proof concludes with the statement: 'Since the two sequences are independent, there can be at most $\\gamma_{gr}(G)\\gamma_{gr}(H)$ unique elements of $\\widehat{S}$. Hence $|\\widehat{S}| \\leq \\gamma_{gr}(G)\\gamma_{gr}(H)$.' This assertion is effectively a restatement of the conjecture that $\\gamma_{gr}(G \\boxtimes H) = \\gamma_{gr}(G)\\gamma_{gr}(H)$ (given the known inequality in the other direction). The argument provided ('Since the two sequences are independent...') is insufficient to justify this conclusion, making the reasoning circular as it assumes what needs to be proven."
      }
    ],
    "token_usage": {
      "input": 8419,
      "thinking": 17256,
      "output": 1849
    }
  },
  {
    "entry_id": 23,
    "retraction_id": "2209.08741v2",
    "paper_id": "2209.08741v1",
    "retraction_comment": "This manuscript has been withdrawn by the authors. Condition (B) needs to be modified for the proofs to work",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent curvature assumption for planar domains ($n=1$). Theorem 1.1 assumes the Bergman metric has Gaussian curvature $-2$ (i.e., $c^2=2$). However, a domain biholomorphic to a disk (the conclusion of Theorem 1.1) must have a Bergman metric with Gaussian curvature $-1$ (i.e., $c^2=1$). The proof of Theorem 1.1 appears to rely on Theorem 2.3 (via the phrase \"Similar to the proof of Theorem \\ref{with B}, Part 1)\"), which requires $c^2=2/(n+1)$. For $n=1$, this means Theorem 2.3 requires $c^2=1$. This contradiction between the assumed curvature ($c^2=2$) and the required curvature for the conclusion ($c^2=1$) invalidates the proof and the main statement of Theorem 1.1.",
        "Location": "Theorem 1.1 (statement, page 3), and its proof in Section 3 (pages 9-10). Specifically, the invocation of arguments similar to Theorem 2.2's proof which relies on Theorem 2.3.",
        "Explanation": "A domain in $\\mathbb{C}$ is biholomorphic to a disk if and only if its Bergman metric has constant Gaussian curvature $-1$. Theorem 1.1 assumes this curvature is $-2$. This fundamental mismatch makes the conclusion of biholomorphism to a disk untenable under the given assumption. The proof structure also relies on a condition ($c^2=1$) that contradicts the explicit assumption ($c^2=2$)."
      },
      {
        "Problem": "Inconsistent formula for Bergman kernel transformation in planar case. Equation (3.3) (referred to as \\eqref{relation} in the text), $K(z, p) = \\frac{g(p)}{2\\pi} T'(z)$, is used in the proof of Theorem 1.1, Part 2, and is central to Corollary 1.2. This formula is derived from $K(z,p) = T'(z) K_{\\mathbb{D}_r}(T(z),0)$ with $K_{\\mathbb{D}_r}(0,0) = 1/(\\pi r^2)$, implying $\\pi r^2 = 2\\pi/g(p)$, or $r^2 = 2/g(p)$. The radius $r$ of the target disk for the Bergman representative coordinate $T(z)$ is $r^2 = (2/c^2)/g(p)$ (assuming $T(p)=0$ and appropriate normalization for $T'(p)$ in relation to $g(p)$). For $r^2=2/g(p)$ to hold, $c^2$ must be $1$. However, Theorem 1.1 assumes $c^2=2$. If $c^2=2$ were used consistently, then $r^2=1/g(p)$, and the formula should be $K(z,p) = \\frac{g(p)}{\\pi}T'(z)$. This factor of 2 discrepancy indicates an internal inconsistency regarding the assumed value of $c^2$ for the planar case.",
        "Location": "Equation (3.3) (page 10, labeled as \\eqref{relation} in the proof of Theorem 1.1 Part 2) and its use in the proofs of Theorem 1.1 and Corollary 1.2.",
        "Explanation": "The formula relating $K(z,p)$ and $T'(z)$ depends on the radius of the target disk, which in turn depends on the curvature $c^2$. The formula used is consistent with $c^2=1$, but Theorem 1.1 assumes $c^2=2$. This inconsistency affects the quantitative aspects of Theorem 1.1 and related results."
      }
    ],
    "token_usage": {
      "input": 25413,
      "thinking": 18747,
      "output": 862
    }
  },
  {
    "entry_id": 24,
    "retraction_id": "1603.02871v2",
    "paper_id": "1603.02871v1",
    "retraction_comment": "Problems in the proof....specifically maximal pivotality. The estimates on the number of pivotal edges is fine",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption that the set of all pivotal edges is jointly pivotal.",
        "Location": "Proof of Lemma 3(i), page 5, specifically the sentence: \"By definition of pivotal edge, we have omega' in A for every omega' in Omega_E.\"",
        "Explanation": "The argument for Lemma 3(i) states that if E is the set of pivotal edges for (A, omega) (where A={N=1} and N(omega)=2, so A does not occur for omega), then any configuration omega' agreeing with omega outside E and having at least one edge in E open will result in A occurring (i.e., N(omega')=1). This property, that E is 'jointly pivotal', is asserted to follow 'By definition of pivotal edge'. However, the definition of a single pivotal edge only implies that flipping that *one* edge results in A occurring. It does not automatically imply that flipping an arbitrary non-empty subset of E will also result in A occurring. This is a stronger property that requires separate justification based on the specific nature of the event A={N=1}. If the set of all pivotal edges E is not jointly pivotal, then P_e(omega) (the maximal jointly pivotal set containing e) may not be equal to E_n(omega) (the set of all pivotal edges in B_n), which would undermine a crucial step in the main proof's counting argument that relies on P_{e_0} = E_n."
      },
      {
        "Problem": "Lack of justification for the finite-size approximation of pivotal events for A={N=1}.",
        "Location": "Proof of Lemma 2 (lem_piv), page 4, around equation (II.7) and the statement \"T_M(e_1) intersect A_{12} decreases to H_{e_1}\".",
        "Explanation": "Lemma 2 estimates the variance of the number of pivotal edges. This estimate relies on approximating the global event H_{e1} (edge e1 is pivotal for A={N=1}) by a local event T_M(e1) (depending on edges in a box B'_M(e1) of size M around e1). The paper states that 'T_M(e_1) intersect A_{12} decreases to H_{e_1}' (where A_{12}={N=1 or N=2}), implying P(T_M(e1)) approximates P(H_{e1}) for large M. While such finite-size criteria are standard for simple monotone events in percolation (like connectivity), the event A={N=1} (number of infinite clusters is exactly one) is not monotone and is considerably more complex. The paper does not provide a proof or a reference for this approximation in the context of A={N=1}. If this approximation is not valid or the convergence is not sufficiently controlled, the subsequent covariance estimates (I_{2,2}(e_1)) and thus the overall variance bound for X_n might be incorrect, potentially invalidating the Chebychev inequality application."
      }
    ],
    "token_usage": {
      "input": 13645,
      "thinking": 16856,
      "output": 683
    }
  },
  {
    "entry_id": 25,
    "retraction_id": "1110.2623v5",
    "paper_id": "1110.2623v4",
    "retraction_comment": "This paper has been withdrawn since a necessary condition for the existence of an asymptotically cylindrical Calabi-Yau metric on W_1 is in fact not satisified",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The original construction of the threefolds $\\Wbar$ in Section 6 is flawed for $p \\ge 3$, invalidating them as 'admissible pairs'.",
        "Location": "Section 6.1, pp. 10-11 (description of $Z=(S \\times \\mathbb{P}^1)/(\\rho \\times \\psi)$ and $D$).",
        "Explanation": "For $p \\ge 3$: (a) The quotient $Z$ does not have Gorenstein singularities as claimed (paragraph after eq. 6.2). The determinant of the local group action $\\rho \\times \\psi$ on tangent spaces is $\\zeta_p^2 \\ne 1$, not $1$. This invalidates the cited results from Roan for Gorenstein orbifolds and the subsequent Chen-Ruan calculations which assume integer ages. (b) The divisor $D$ (strict transform of $S \\times \\{x\\}$) is not anti-canonical in $\\Wbar$ (paragraph before Lemma 6.1). The paper's argument that $K_{S \\times \\mathbb{P}^1} \\otimes L(S \\times \\{x\\})$ is trivial is incorrect. This means $(\\Wbar, D)$ does not satisfy the conditions of Theorem 2.2. (The erratum attempts to fix these issues with a new construction.)"
      },
      {
        "Problem": "The Hodge number calculations for $\\Wbar$ in Section 6 (for $p \\ge 3$) are unreliable due to incorrect local group actions and 'age' values.",
        "Location": "Section 6, subsections 'Automorphisms of order 3' (p.13) and 'Automorphisms of order p>3' (p.14), and the resulting tables of $h^{1,1}, h^{1,2}$.",
        "Explanation": "The 'age' values, crucial for Chen-Ruan orbifold cohomology, are derived from specific matrix forms for the local action of $\\rho \\times \\psi$. These matrices (e.g., $\\text{diag}(\\zeta_3^2, \\zeta_3^2, \\zeta_3^2)$ for $p=3$ isolated fixed points) do not correctly follow from the definitions of $\\rho$ (Section 4) and $\\psi(z)=\\zeta_p z$ (Section 6.1). For example, for $p=3$, the action on a curve fixed point using $\\psi(z)=\\zeta_3 z$ should be $\\text{diag}(\\zeta_3,1,\\zeta_3)$, leading to a non-integer age $2/3$, not the claimed integer age 1. This makes the computed Hodge numbers $h^{p,q}(\\Wbar)$ incorrect."
      },
      {
        "Problem": "The stated Betti numbers for the new $G_2$-manifolds are unsubstantiated.",
        "Location": "Section 7, p.20 (final Betti number calculations, e.g., $(42,91), (42,113)$) and their reliance on Section 6.",
        "Explanation": "The Betti numbers $(b^2(M), b^3(M))$ of the constructed $G_2$-manifolds are calculated using Theorem 7.9, which depends on the Hodge numbers $h^{p,q}(\\Wbar_1)$ derived in Section 6. Since the construction of $\\Wbar_1$ (Problem 1) and its Hodge number calculation (Problem 2) are flawed for $p \\ge 3$, the final Betti numbers for $M$ are not reliably established. The erratum itself notes that these Betti numbers would change with a corrected construction."
      },
      {
        "Problem": "The erratum's proposed new construction of admissible pairs $(\\overline{W}', D')$ relies on an unjustified application of Hirzebruch's Lemma.",
        "Location": "Erratum, Section 2 ('A new construction of admissible pairs'), Step 3.",
        "Explanation": "The erratum's revised construction involves a $p$-fold ramified cover $\\pi: \\overline{W}' \\to \\overline{W}'_0$ branched along a divisor $D'_0$. This step invokes Hirzebruch's Lemma, which requires the divisor class $[D'_0]$ to be $p$-divisible in $H^2(\\overline{W}'_0, \\mathbb{Z})$ (i.e., $[D'_0] = p \\cdot \\beta$ for some integral class $\\beta$). The erratum does not provide a justification for this $p$-divisibility. The stated relation $p[D'_0] \\sim -[K_{\\overline{W}'_0}]$ implies that $[-K_{\\overline{W}'_0}]$ is $p$-divisible, but not necessarily $[D'_0]$ itself. Without this justification, the construction of $\\overline{W}'$ such that $D'$ is anti-canonical is incomplete."
      }
    ],
    "token_usage": {
      "input": 37566,
      "thinking": 14805,
      "output": 1131
    }
  },
  {
    "entry_id": 26,
    "retraction_id": "1307.5957v4",
    "paper_id": "1307.5957v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect energy functional for the stated NLS equation.",
        "Location": "Eq. (1.1), Eq. (2.7) and related discussion of energy, p.3",
        "Explanation": "The NLS equation is given as $iu_t + \\Delta u = |u|^2 u$ in (1.1). This is a focusing NLS, and its conserved energy is $E(t) = \\int (|\\nabla u|^2 - \\frac{1}{2}|u|^4) dx$. However, the paper defines the energy in (2.7) as $E(t) = \\int (\\frac{1}{2}|\\nabla u|^2 + \\frac{1}{4}|u|^4) dx$. This functional corresponds to a different NLS equation (e.g., $iu_t + \\frac{1}{2}\\Delta u + \\frac{1}{2}|u|^2 u = 0$) and typically describes defocusing dynamics if the nonlinear term has a positive sign. This discrepancy is fundamental as the nature of the energy functional dictates the qualitative properties of solutions, including conservation laws and stability."
      },
      {
        "Problem": "Theorem 2.1 is questionable and its proof sketch is unsound.",
        "Location": "Theorem 2.1 and its proof sketch, p.4",
        "Explanation": "Theorem 2.1 states $\\left|\\int Im(u_{x}\\overline{u})(t,0)dt\\right| \\leq C\\left\\|{\\nabla u(x)}\\right\\|^{2}_{L^{2}_{x}(\\R)}$. Firstly, the norm on the RHS, $\\left\\|{\\nabla u(x)}\\right\\|^{2}_{L^{2}_{x}(\\R)}$, is ambiguous regarding the time at which $u(x)$ is evaluated; presumably, it refers to the initial data $u_0(x)$. Secondly, the proof sketch suggests using the Poincar\\'e inequality in the form $\\left\\|{u(x)}\\right\\|^{2}_{L^{2}_{x}(\\R)} \\leq C\\left\\|{\\nabla u(x)}\\right\\|^{2}_{L^{2}_{x}(\\R)}$ for functions on $\\R$. This inequality is not generally true for functions in $H^1(\\R)$ without additional assumptions (e.g., compact support or zero mean), which are not stated. Thirdly, if the proof strategy involves estimating the integral by Cauchy-Schwarz, i.e., $\\int |u(t,0)| |u_x(t,0)| dt \\leq (\\int |u(t,0)|^2 dt)^{1/2} (\\int |u_x(t,0)|^2 dt)^{1/2}$, it would rely on bounding $\\int |u(t,0)|^2 dt$. However, for $d=1$, the $L^2$ local smoothing estimate $\\int |u(t,x_0)|^2 dt \\lesssim \\|u_0\\|_{L^2_x}^2$ is known to be false. These issues make the theorem's validity and proof highly suspect."
      },
      {
        "Problem": "The derivation of Proposition 3.1 in Lagrangian Mechanics is unsound.",
        "Location": "Proposition 3.1 and its derivation, Section 3, Eqs. (3.1)-(3.4), p.4-5",
        "Explanation": "Proposition 3.1 presents an equation of motion (3.2) for a particle-like coordinate $x(t)$. The derivation is flawed: 1. The Lagrangian $L(u)$ in (3.1) is $\\int (\\frac{1}{2}|\\nabla{u}(t,y)|^{2}-\\frac{1}{4}|u(t,y)|^{4})dy$. This is a functional of the field $u(t, \\cdot)$ at a given time $t$. It is not formulated as a classical particle Lagrangian $L(x(t), \\dot{x}(t), t)$. The dependence of $L(u)$ on $x(t)$ and $\\dot{x}(t)$ is not specified, rendering the application of the particle Euler-Lagrange equation (3.3) unjustified. 2. The resulting equation (3.4) is $m\\partial_{tt}x=-V(x)$. If $L=T-V_{pot}(x)$, the Euler-Lagrange equation is $m\\ddot{x} = -\\partial V_{pot}(x)/\\partial x$. The paper identifies $m = \\int|u|^2 dy$ and implies the force is $F_x = -\\frac{1}{4}\\int|u|^4 dy$. This force $F_x$ does not depend on $x(t)$ unless $u$ itself depends on $x(t)$ in a specific, unstated way. The argument conflates field theory concepts with particle mechanics without proper justification."
      },
      {
        "Problem": "Incorrect action functional for the NLS equation.",
        "Location": "Section 3.1 'The Action', Eq. (3.5), p.5",
        "Explanation": "The action functional $S(u(t,x))$ defined in Eq. (3.5) is $S(u) = \\int_{\\R_t} \\int_{\\R_d} (\\frac{1}{2}|\\nabla{u}|^{2}-\\frac{1}{4}|u|^{4})dx dt$. The Lagrangian density $\\mathcal{L}_0 = \\frac{1}{2}|\\nabla u|^2 - \\frac{1}{4}|u|^4$ does not depend on time derivatives of $u$. Applying the principle of least action by varying $S$ with respect to $u$ (or $\\bar{u}$) would yield an elliptic partial differential equation (e.g., $-\\Delta u - |u|^2 u = 0$ if $u$ is real and varied, or similar for complex $u$ varying w.r.t $\\bar{u}$). This describes stationary solutions (standing waves) rather than the time-dependent NLS equation (1.1). The standard Lagrangian density for NLS requires a term involving $u_t$, such as $\\frac{i}{2}(u\\bar{u}_t - \\bar{u}u_t)$."
      }
    ],
    "token_usage": {
      "input": 4610,
      "thinking": 13910,
      "output": 1428
    }
  },
  {
    "entry_id": 27,
    "retraction_id": "2211.05302v2",
    "paper_id": "2211.05302v1",
    "retraction_comment": "We just noted the explanation on phase retardation was incorrect and accordingly, the inhibition mechanism of zeroth-order light was not properly elucidated. We will submit a revised version soon",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental Misunderstanding or Misrepresentation of Vc, Vo, and Δφ in SLM Operation",
        "Location": "Page 1, description of Eq. (1); Page 2, Eq. (5) and surrounding text",
        "Explanation": "The paper defines Vc as 'threshold voltage (Dark voltages)' and Vo as 'excess voltage (Bright voltages)' in the context of Eq. (1). Equation (1) describes intrinsic liquid crystal (LC) behavior, where Vc is an LC threshold and Vo is a parameter related to the steepness of the voltage-response curve. These are typically not the user-settable 'Bright' and 'Dark' voltages of an SLM driver, which define the 0 and 2π phase points. The paper does not clarify how adjusting user-settable 'Bright/Dark' voltages would modify the intrinsic Vc and Vo of Eq. (1). Furthermore, Δφ, the phase retardation derived from Eq. (1) and (3), is described as a 'contamination' in the context of T = Tc + Δφ (Eq. 5), where Tc is the designed phase. However, Δφ(V) is the fundamental phase modulation mechanism of the SLM; it's how Tc is realized. This apparent contradiction suggests a misunderstanding of how SLMs generate phase patterns and what the parameters Vc, Vo, and Δφ physically represent in the model used, undermining the soundness of the proposed optimization method."
      },
      {
        "Problem": "Unclear Physical Mechanism for Zeroth-Order Elimination from 'Pixelation Effect'",
        "Location": "Page 1, Abstract & Introduction; Page 4, Discussion of results",
        "Explanation": "The paper claims its primary achievement is eliminating zeroth-order light 'caused by the pixelation effect of SLM' by adjusting Vc and Vo. The 'pixelation effect' typically refers to diffraction from the SLM's discrete pixel structure and inter-pixel gaps. The paper does not provide a clear physical mechanism explaining how tuning global phase response parameters Vc and Vo (as defined in Eq. 1, which affect the overall voltage-to-phase curve) specifically counteracts or eliminates the zeroth-order diffraction arising from these fixed structural characteristics of the SLM. While optimizing phase modulation fidelity can improve diffraction efficiency and reduce unwanted light, the direct causal link to mitigating the 'pixelation effect' component of the zeroth order via the described Vc/Vo adjustment is not established, making the central claim about zeroth-order elimination poorly substantiated."
      },
      {
        "Problem": "Inconsistent and Contradictory Definition of 'Default' SLM Parameters (Vc and Vo)",
        "Location": "Page 3, first paragraph, and Figure 2 caption",
        "Explanation": "There is a direct contradiction in the stated 'default values' for Vc and Vo, which are critical for establishing the baseline performance and understanding the optimization strategy. The text on page 3 states the default values are 'Vc = 6.19 and Vo = 0.03'. In contrast, the caption for Figure 2(a) (and Fig 2(a1)) states, '(a) Vo = 6.19 and Vc = 0.03 are the default values from the manufacture'. The roles of Vc and Vo are swapped between these two statements. This inconsistency makes it impossible to reliably interpret the optimization process (e.g., 'properly increasing Vc and decreasing Vo from their default values') and assess the reported improvements relative to a well-defined baseline. Such a discrepancy in fundamental parameters raises concerns about the reliability and carefulness of the study's presentation."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 6186,
      "output": 795
    }
  },
  {
    "entry_id": 28,
    "retraction_id": "1910.05809v3",
    "paper_id": "1910.05809v2",
    "retraction_comment": "Need to fix some error in the paper. In the last step of the proof, the hypersurface of the minimal principle curvature equal to zero may be tangent to the boundary of the domain",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Claim 2.1 (labelled as Claim \\ref{rank} in the TeX, page 4) is flawed.",
        "Location": "Page 4, Proof of Theorem 2.1, Claim \\ref{rank}",
        "Explanation": "The claim states that $\\max_{\\Omega^T}|\\nabla u^T|$ is achieved at a point $Q \\in \\Gamma^T$ where $\\det{(u^T_{ij}(Q))}>0$. The proof asserts $u^T_{nk}(Q)=0$ for $k<n$ (where $e_n$ is normal to $\\Gamma^T$ at $Q$, and $e_k$ are tangential). This is not necessarily true; $u^T=0$ on $\\Gamma^T$ implies $u^T_k(Q)=0$ for $k<n$, but $u^T_{nk}(Q)$ can be non-zero. Consequently, the deduction $\\det{(u^T_{ij}(Q))}=u^T_{nn}(Q)\\Pi_{k<n} u^T_{kk}(Q)>0$ (using $k=2..n$ in paper, should be $k=1..n-1$) is not justified, as the determinant formula for a matrix that is not block-diagonal involves off-diagonal terms $u^T_{nk}(Q)$. Thus, $\\det{(u^T_{ij}(Q))}>0$ is not proven."
      },
      {
        "Problem": "Misapplication of the Constant Rank Theorem.",
        "Location": "Page 4, Proof of Theorem 2.1, paragraph after Claim \\ref{rank}",
        "Explanation": "The paper states: 'By the constant rank theorem of Bian and Guan ..., the rank of $(u^T_{ij})$ is $n$ in $\\Omega^T$ by Claim \\ref{rank}.' Claim \\ref{rank} asserts properties at a boundary point $Q \\in \\Gamma^T$. However, the cited Constant Rank Theorem (Corollary 1.3 of [BG09]) requires the point $x_0$ where the rank is known (e.g., rank $n$) to be an interior point of the domain $\\Omega^T$. Using a property at a boundary point $Q$ does not directly allow the application of this theorem to determine the rank in the interior $\\Omega^T$. While the conclusion that rank is $n$ in $\\Omega^T$ (and thus any singularity $\\lambda_1=0$ must occur at the boundary) is standard in such arguments, it is typically established by contradiction, assuming rank drops in the interior and showing this leads to issues with boundary conditions or initial convexity at $t=0$."
      },
      {
        "Problem": "Incorrect statement about the monotonicity of mean curvature for the foliation.",
        "Location": "Page 4, Proof of Theorem 2.1, description of foliation $\\Gamma^t$",
        "Explanation": "The paper states (after re-indexing so $\\Gamma^0=\\{O\\}$ and $\\Gamma^1=\\Gamma$) that '$\\min_{\\Gamma^t} h^t $ is strictly increasing in $t, \\, 0\\leq t <1$'. Here $t \\in [0,1)$ and $\\Omega^t$ expands as $t$ increases. For expanding domains (e.g. a ball $\\Omega^t = B_t(0)$ whose radius $t$ increases), the mean curvature $h^t = (n-1)/t$ is strictly decreasing. If the foliation is by mean curvature flow of $\\Gamma$ (run forwards in time, so domains shrink), then $h^t$ increases as domains shrink. The paper's indexing implies expanding domains. While this error in monotonicity direction might seem minor (if $h^t$ is decreasing, $h^t \\ge h_{\\Gamma} \\ge (1+\\epsilon)H$ still holds), it indicates a potential confusion in setting up the continuity method or describing the properties of the chosen foliation. If the foliation is by level sets of $w$ with $(\\delta_{ij}-\\frac{w_i w_j}{|\\nabla w|^2})w_{ij} = -1$, then $h^t$ is constant, which is a very specific requirement."
      }
    ],
    "token_usage": {
      "input": 9647,
      "thinking": 24591,
      "output": 978
    }
  },
  {
    "entry_id": 29,
    "retraction_id": "1108.1348v2",
    "paper_id": "1108.1348v1",
    "retraction_comment": "Withdrawn because of a crucial error in eq.(15)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect premise for $\\lambda=1, B=0$ solutions leading to flawed discontinuity argument.",
        "Location": "Section 1, page 3, paragraph 3; Section 3.2, page 6, last paragraph.",
        "Explanation": "The paper asserts that for $\\lambda=1, B=0$ (i.e., $f(r)=1$), Schwarzschild-Painlevé-Gullstrand (PG) solutions with non-zero mass $M$ exist (citing their Ref. [13]). However, the Hamiltonian constraint for $\\lambda=1, B=0, f=1$ is $\\int_0^\\infty dr (-2(rn^2)') = -2[rn^2(r)]_0^\\infty = 0$. For the PG form $n(r)=\\sqrt{2M/r}$, $rn^2(r)=2M$, so the constraint forces $M=0$ (flat spacetime). This contradicts the paper's claim that PG solutions with $M \\neq 0$ are valid for $\\lambda=1, B=0$. This error undermines the subsequent argument in Sec. 3.2 about a discontinuity in solutions when $\\lambda \\rightarrow 1$, as it implies that both $\\lambda=1$ and $\\lambda \\neq 1$ cases for $B=0$ might only admit flat spacetime."
      },
      {
        "Problem": "Flawed derivation of the first-order correction $n_1(r)$ in the asymptotic expansion.",
        "Location": "Section 3.3, page 7, equation for $n_1$ before Eq. (3.16) and derivation of Eq. (3.16).",
        "Explanation": "In Sec. 3.3, an asymptotic expansion $n(r) = n_0(r) + (B/r)n_1(r) + \\dots$ is used. The differential equation for $n_1/r$ is of the form $D_0(n_1/r) = S(r)$, where $D_0(y)=y''+(2/r)y'+(2/r^2)y$ and $S(r)$ is a non-zero source term proportional to $r^{-7/2}$ times oscillations. The paper incorrectly assumes a solution for $n_1(r)$ of the form $r^{-1/2}$ times an oscillatory function (i.e., $n_1/r \\propto r^{-3/2}$ times oscillations). This form is a solution to the homogeneous equation $D_0(y)=0$ (if $y \\propto r^{-1/2} \\times$ osc.) or related to it, but it cannot be the particular solution to the inhomogeneous equation $D_0(n_1/r)=S(r)$ because the radial dependencies do not match ($r^{-3/2}$ vs $r^{-7/2}$ for the source). The method used to determine coefficients $\\tilde{a}, \\tilde{b}$ (Eq. 3.16) by substituting this incorrect form is invalid. This error makes the derived asymptotic solution for $n(r)$ (Eq. 3.17), the potential $\\phi(r)$ (Eq. 3.18), and the subsequent analysis in Sec. 4 unreliable."
      },
      {
        "Problem": "Hamiltonian constraint not verified for asymptotic solutions with $B \\neq 0, n \\neq 0$.",
        "Location": "Section 3.3, page 7, paragraph after Eq. (3.17).",
        "Explanation": "The paper explicitly states: \"Additionally, we have not checked if solutions with the above asymptotic behavior of Eq. (3.17) indeed satisfy the Hamiltonian constraint.\" For any derived solution to be physically valid, it must satisfy all equations of motion, including all constraints (like Eq. 3.10). Without verifying the Hamiltonian constraint, the physical relevance of the asymptotic solution $n(r)$ and the derived potential $\\phi(r)$ (Eq. 3.18) for the $B \\neq 0, n \\neq 0$ case is undetermined. The constraint could impose further conditions on the integration constants $a,b$ or even show that such asymptotic solutions are not permissible."
      }
    ],
    "token_usage": {
      "input": 12343,
      "thinking": 20089,
      "output": 964
    }
  },
  {
    "entry_id": 30,
    "retraction_id": "1505.02494v2",
    "paper_id": "1505.02494v1",
    "retraction_comment": "This paper has been withdrawn by the author due to crucial sign errors in Theorem 5 and equation (10)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The claimed monotonic convergence of Algorithm 2 (Shifted Projected Power Method) is not strictly guaranteed by the algorithm as stated.",
        "Location": "Algorithm 2 (page 10-11), the convergence theorem for Algorithm 2 (page 12, second theorem), and related statements in Abstract and Section 4 introduction.",
        "Explanation": "The theorem on page 12, which establishes monotonic increase of the sequence {\\lambda(x^k)}, relies on the condition that the new iterate x^{k+1} lies within a neighborhood \\Sigma(x^k) of the current iterate x^k where the shifted objective function f_hat is convex. Algorithm 2, as presented, calculates the shift parameter \\alpha_k based on the Hessian at x^k to ensure local convexity of f_hat around x^k. However, the algorithm does not include a mechanism to ensure that x^{k+1} (obtained by a projected gradient step and normalization) will necessarily be in \\Sigma(x^k). The paper mentions that strategies to enforce this exist (e.g., by sufficiently increasing \\alpha_k) but are not incorporated into Algorithm 2 as implemented, due to good empirical performance. Consequently, there is a gap between the algorithm as stated/implemented and the conditions under which monotonic convergence is proven. This weakens the claim that monotonic convergence is 'established' for the proposed Algorithm 2, as stated in the abstract ('The monotonic convergence is also established.') and the introduction to Section 4."
      }
    ],
    "token_usage": {
      "input": 22173,
      "thinking": 26132,
      "output": 333
    }
  },
  {
    "entry_id": 31,
    "retraction_id": "1504.07542v2",
    "paper_id": "1504.07542v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial sign error in equation 9",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Invalid kernel approximation in the fundamental integral equation for the gap.",
        "Location": "Eq. (2.5), Eq. (2.9), and their implicit derivation from a BCS-like gap equation (e.g., generalization of Eq. (2.3)).",
        "Explanation": "The integral equation (2.5) (and its specific form in (2.9)) for the energy gap $\\Delta(\\xi)$ uses a kernel of the form $1/(2|\\xi'|)\\tanh(|\\xi'|/(2T))$. This kernel arises from approximating the quasiparticle energy $E_{\\xi'} = \\sqrt{\\xi'^2 + \\Delta_{eff}^2}$ as $E_{\\xi'} \\approx |\\xi'|$, where $\\Delta_{eff}$ is the effective pair field. In this model, $\\Delta_{eff}(\\xi') = \\Delta(\\xi') - \\upsilon \\text{sgn}(\\Delta(\\xi'))$. Near the claimed critical temperature $T_c^*$, $\\Delta(\\xi') \\to 0$, so $\\Delta_{eff}(\\xi') \\to -\\upsilon \\text{sgn}(\\Delta(\\xi'))$. The approximation $E_{\\xi'} \\approx |\\xi'|$ requires $\\Delta_{eff}^2 \\ll \\xi'^2$, which means $\\upsilon^2 \\ll \\xi'^2$. This condition is not generally satisfied for energies $\\xi'$ near the Fermi surface (where the kernel is most significant), especially if $\\upsilon$ is not infinitesimally small. Using an unjustified kernel invalidates the quantitative (and potentially qualitative) results for $T_c^*$ and $\\Delta_{ph}(T)$ derived from these equations."
      },
      {
        "Problem": "Ad-hoc temperature dependence introduced in the source term coefficient of the Ginzburg-Landau free energy.",
        "Location": "Page 4, the paragraph discussing the modification of the free energy contribution from $\\langle\\widehat{H}_{ext}\\rangle$, leading to the coefficient $u$ in Eq. (3.5).",
        "Explanation": "The paper modifies the contribution of the external pair potential to the free energy from $\\frac{2\\upsilon}{u_{ph}}|\\Delta|$ to $\\frac{2\\upsilon}{u_{ph}}(1-\\frac{T}{T_c^*})|\\Delta|$. This leads to the coefficient $u = \\eta\\upsilon(1-T/T_c^*)$ in the Ginzburg-Landau free energy (Eq. 3.5). This modification is stated as necessary to obtain consistency with the asymptotic behavior of $\\Delta_{ph}$ from Eq. (2.21). However, this factor $(1-T/T_c^*)$ is introduced into the coefficient of the source term without microscopic derivation or physical justification. The source term's strength in the free energy should correspond to the applied external field $\\upsilon$, not be arbitrarily scaled by a temperature factor that already describes the order parameter's vanishing."
      },
      {
        "Problem": "Unconventional Ginzburg-Landau functional form lacking essential terms and using unusual coefficients.",
        "Location": "Eq. (3.5) and its subsequent application.",
        "Explanation": "The proposed Ginzburg-Landau (GL) free energy in Eq. (3.5), $G_s = G_n + a|\\Psi|^2 + 2u|\\Psi| + \\text{gradient terms}$, has two major issues: (1) It lacks the standard positive $\\beta|\\Psi|^4/2$ term, which is essential for ensuring thermodynamic stability at finite order parameter in the absence of a source, for describing the nature of the phase transition (e.g. second order), and for obtaining a finite $H_{c2}$ in many cases. (2) The coefficient $a$ is taken as $a=\\alpha T$ (stated as valid for $T \\gg T_c$), which is unusual for a GL theory intended to be used near a critical temperature $T_c^*$. Standard GL theory uses $a \\propto (T-T_c^{BCS})$. These departures from the established GL framework make the phenomenological analysis, including predictions for critical fields like $H_{c2}=\\infty$ and other thermodynamic properties, fundamentally questionable and potentially unsound."
      }
    ],
    "token_usage": {
      "input": 7572,
      "thinking": 19145,
      "output": 958
    }
  },
  {
    "entry_id": 32,
    "retraction_id": "2012.10766v4",
    "paper_id": "2012.10766v3",
    "retraction_comment": "Propositions 3 and 4 are incorrect, and so is their proof. The proof requires the shifted convolution problem for the coefficients of the cusp forms, which is not presented here. The definition of the mollifier M(f,s) is wrong. It needs to be defined as a convolution inverse of the Fourier coefficients of the automorphic forms",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Proposition 3.4 is incomplete and potentially flawed. The proposition aims to show $\\int_{T}^{2T} |1-L(f,\\sigma_0+it)M(f,\\sigma_0+it)|^2 dt = o(1)$, which relies on proving $\\int_{T}^{2T} |L(f,\\sigma_0+it)M(f,\\sigma_0+it)|^2 dt = T+o(T)$. The paper attempts this by evaluating $\\sum_{h,k} c_h \\bar{c_k} I(k,h)$, where $c_n$ are coefficients of the mollifier $M(f,s)$ and $I(k,h)$ is the twisted second moment $\\int |L(f,s)|^2 (k/h)^{it} dt$. Lemma 7.2 (Lemma 5 in paper) gives an asymptotic for $I(k,h) \\approx \\frac{T}{\\sqrt{kh}} (Z_{0,0,k,h}(0) + Z_{0,0,k,h}(0))$. The crucial step of summing these terms, i.e., evaluating $\\sum_{h,k} \\frac{\\mu(h)a(h)\\lambda_f(h)\\mu(k)a(k)\\bar{\\lambda}_f(k)}{(hk)^{\\sigma_0}} \\frac{T}{\\sqrt{kh}} (2 Z_{0,0,k,h}(0))$, and showing it equals $T+o(T)$ is missing. The paper's conclusion for Proposition 3.4, stating 'Since $h$ and $k$ is very small... we can say that the main term is $\\sim T$', is a non-sequitur as $h,k$ are summation variables ranging up to $T^\\epsilon$. This summation is non-trivial and central to the argument.",
        "Location": "Section 7, Proof of Proposition 3.4, specifically the arguments following Lemma 7.2 (Lemma 5) and the final 'Proof of Proposition 3.4' paragraph.",
        "Explanation": "To validate Proposition 3.4, it is essential to correctly sum the contributions from the twisted moments $I(k,h)$. The paper provides an asymptotic for individual $I(k,h)$ terms (Lemma 7.2) but does not carry out the summation over $h$ and $k$ with the mollifier coefficients. The assertion that the sum is $\\sim T$ is not justified. This step is critical because Proposition 3.4 is one of the four main pillars for proving Theorem 1.1. An error or omission here could invalidate the central conclusion of the paper."
      },
      {
        "Problem": "The choice of method and supporting references for Proposition 3.4 may be inappropriate or misapplied. The paper cites Hughes and Young [13] (twisted fourth moment of $\\zeta(s)$) and Heath-Brown [14] (fourth moment of $\\zeta(s)$) as inspiration. While methodological analogies can exist, $L(f,s)$ is a $GL(2)$ $L$-function, and its second moment properties are distinct from fourth moments of $\\zeta(s)$. More critically, the paper mentions Kühn, Robles, and Zeindler [18] for error term calculations and as providing a 'type result'. However, Theorem 2.1 of [18] calculates a family average of twisted $L$-functions (average over forms $f$), not a $t$-aspect average for a single form $f$ as required in Proposition 3.4. If the results from these references are not directly applicable or if their adaptation is non-trivial, the argument for Proposition 3.4 lacks adequate support.",
        "Location": "Section 7, throughout the proof of Proposition 3.4, particularly the introductory part and the Remarks after Lemma 7.2 (Lemma 5).",
        "Explanation": "Proposition 3.4 requires a $t$-aspect mean value estimate for $|L(f,s)M(f,s)|^2$. The primary references cited treat different problems (moments of $\\zeta(s)$ or family averages for $GL(2)$ $L$-functions). The paper does not sufficiently detail how these methods are adapted or if there are other results that directly support the specific calculation needed for the $t$-average of a single $L(f,s)$ multiplied by its mollifier. This makes the foundation of Proposition 3.4's proof questionable."
      }
    ],
    "token_usage": {
      "input": 34556,
      "thinking": 18737,
      "output": 1009
    }
  },
  {
    "entry_id": 33,
    "retraction_id": "1703.02535v2",
    "paper_id": "1703.02535v1",
    "retraction_comment": "Error in the diffusion constant of Theorem 2.2, equation (2.4) due to a delicate issue in the method of the proof which is not trivial to correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The lower bound $V_{\\mu}(\\lambda) \\geq V_{\\delta_{0}}(I_{\\mu}\\lambda)$ in Lemma 4.8, which is crucial for the main theorems concerning the disordered system (Theorems 2.6 and 2.7: criteria for universality classes and bounds for synchronization levels), is not rigorously proven. It is stated to be verified numerically for only three types of disorder (Appendix B.2). This means Theorems 2.6 and 2.7 are conditional on this inequality holding true for general symmetric unimodal disorder.",
        "Location": "Lemma 4.8 (p. 19), Appendix B.2 (p. 23-25), Theorems 2.6 & 2.7 (p. 8-9)",
        "Explanation": "Mathematical theorems require rigorous proofs. Numerical verification for a few examples, while suggestive, does not constitute a proof for a general class of disorder distributions. The conclusions of Theorems 2.6 and 2.7 are therefore not fully established."
      },
      {
        "Problem": "The derivation of the stochastic differential equations for the block average phases (Theorems 2.2 and 2.5, proof in Section 3.2) relies on heuristic averaging and decoupling arguments that are not rigorously justified. For instance, certain terms like $I_1(k,N;t)$ for $\\ell \\leq k-1$ and $I_2(k,N;t)$ for $\\ell \\leq k$ are claimed to vanish based on symmetry and decoupling assumptions.",
        "Location": "Section 3.2, pp. 13-16 (specifically, arguments for vanishing of terms in $I_1(k,N;t)$ and $I_2(k,N;t)$)",
        "Explanation": "Terms that are not manifestly small by powers of $N$ (e.g., $I_1(k,N;t)$ for $\\ell < k$ involves a factor $N^{k-\\ell}$) are argued to vanish due to averaging over rapidly equilibrating, symmetrically distributed phases. These kinds of arguments (e.g., 'decouples from the disorder', 'vanishes on average because of ...') are common in physics but require substantial mathematical work (e.g., using ergodic theorems for interacting particle systems, controlling correlations) to be made rigorous. Without such justification, the derivation of the renormalized SDEs is not fully proven."
      },
      {
        "Problem": "The analysis of the disordered system relies on properties of $V_{\\mu}(\\lambda)$ (defined in Eq. 4.1) such as concavity, which is mentioned in Remark 4.1 (Vconj) to be conjectured for symmetric unimodal disorder but only proven for narrow (small) disorder. The paper assumes small disorder (Section 2, first paragraph) but believes it to be redundant. If concavity (or related properties ensuring a unique, stable, non-trivial solution to the self-consistency equation for $R^{[k+1]}$) does not hold for general disorder, the renormalization scheme itself might be ill-defined or lead to multiple solutions.",
        "Location": "Section 2, first paragraph (p. 6); Remark 4.1 (Vconj) (p. 17); Section 4.1 (p.17-18)",
        "Explanation": "The renormalization map involves solving $\\bar{R} = R V_{\\mu}(2K\\bar{R}\\sqrt{Q})$. The uniqueness and behavior of the solution $\\bar{R}$ depend on properties of $V_\\mu$. If these properties are not established for the general class of disorder considered, the iterative application of the renormalization map $(R^{[k]}, Q^{[k]})$ might not be well-behaved (e.g. $R^{[k]}$ might not be uniquely determined)."
      },
      {
        "Problem": "The asymptotic analysis of $V_{\\mu}(\\lambda)$ for large $\\lambda$ in Appendix A.2 (Eq. 4.12) claims $1-V_{\\mu}(\\lambda) \\sim 1/(2\\lambda)$, implying the leading correction term is independent of the disorder distribution $\\mu$. The derivation details in Appendix A.2 are highly condensed. A preliminary check of the intermediate steps (e.g., the calculation of the quotient involving Gaussian-like integrals on p. 22) suggests a possible dependence of the $O(1/\\lambda^2)$ term, or even the $O(1/\\lambda)$ term, on moments of $\\mu$ (like $\\langle \\omega^2 \\rangle_{\\mu}$). If the stated asymptotic is incorrect, it would be an error in itself and could affect the justification or understanding of Lemma 4.8, particularly for large $\\lambda$.",
        "Location": "Appendix A.2 (pp. 21-22), Eq. 4.12 (p. 19)",
        "Explanation": "The asymptotic behavior of $V_\\mu(\\lambda)$ is important for understanding the system under strong coupling. The derivation provided for $1-V_\\mu(\\lambda) \\sim 1/(2\\lambda)$ involves several approximations (saddle-point, integral evaluations) whose validity and $\\omega$-dependence at each step are not entirely clear. An error here would affect the theoretical understanding of $V_\\mu(\\lambda)$ and its comparison with $V_{\\delta_0}(I_\\mu\\lambda)$."
      }
    ],
    "token_usage": {
      "input": 35286,
      "thinking": 25841,
      "output": 1208
    }
  },
  {
    "entry_id": 34,
    "retraction_id": "1611.01102v3",
    "paper_id": "1611.01102v2",
    "retraction_comment": "The paper fails to appreciate that the necessitation rule is tacitly presupposed in the formulation of the Girle-Priest tableau rules. If those presuppositions were made explicit, the proofs of this paper would depend on a use of necessitation, contra what was claimed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of the existence of a self-referential proposition `q` whose defining property (`q` is identical to `~□q`) holds necessarily.",
        "Location": "Page 1, definition of `q` in relation to (i), and premise (Def) `□(q = ~□q)` on page 3.",
        "Explanation": "The argument's foundation is the existence of a proposition `q` that is identical to the proposition `~□q`, and that this identity `q ↔ ~□q` is a necessary truth (leading to (Def) `□(q = ~□q)`). Standard propositional modal logics (like system T) typically define well-formed formulas syntactically from propositional atoms and logical connectives. These systems do not inherently possess mechanisms (such as a diagonalization lemma or fixed-point theorem for propositions) to guarantee the existence or expressibility of such a self-referential proposition `q`. The paper does not demonstrate how `q` can be constructed or why its definitional identity should be considered necessary within standard operator modal logic. Without this, the paradox appears to arise not from system T itself, but from augmenting T with a strong, external assumption about the availability of such self-referential propositions whose definitions are necessary. The author's claim (page 4) that 'modal logic contains no stipulation against something like (Def)' is insufficient, as formal systems are defined by their constructive capabilities, not by the absence of explicit prohibitions against arbitrary additions."
      },
      {
        "Problem": "Lack of specification of the formal language that can express the self-referential proposition `q` and justify its properties.",
        "Location": "General, but particularly relevant to the setup on page 1 and the introduction of (Def) on page 3.",
        "Explanation": "The paper employs notation and rules common to propositional modal logic. However, the central self-referential proposition `q` (where `q` is `~□q`) and the assumption that its defining equivalence is necessary (i.e., `□(q ↔ ~□q)`) require a language with expressive capabilities beyond standard propositional modal logic. Such capabilities might include mechanisms for self-reference, proposition-forming operators from predicates, or a theory of propositions that allows for fixed points. The paper does not specify such a richer formal language wherein `q` is constructible and (Def) is either derivable or a well-motivated axiom. Without this specification, it is unclear whether the demonstrated paradox applies to the 'operator view' as commonly understood in modal logic (e.g., standard Kripke semantics for propositional modal languages) or only to some unspecified, more powerful system. This ambiguity undermines the claim that standard systems like T inherently 'breed paradox'."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 11481,
      "output": 595
    }
  },
  {
    "entry_id": 35,
    "retraction_id": "2205.15802v2",
    "paper_id": "2205.15802v1",
    "retraction_comment": "The proof of Theorem 3 is wrong: in the display equation below Equation (22), bottom of page 15, the gradient of $\\phi_{t+1}$ is missing a factor $1/(\\alpha\\eta_t)$",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Error in the regret analysis for learning the interaction matrix A",
        "Location": "Appendix A.5, Proof of Theorem 3.3 (thm:regret_ball_expanded), specifically the bound on the term accounting for learning A (referred to as eq:A_part in the proof, which is $\\phi_{t+1}(X_{t+1}, A_t) - \\phi_{t+1}(X_{t+1}, A_{t+1})$). This also affects the proof of Theorem A.4 (thm:adatask_anyproba) in Appendix A.7.",
        "Explanation": "The paper bounds the term $\\phi_{t+1}(X_{t+1}, A_t) - \\phi_{t+1}(X_{t+1}, A_{t+1})$ by $\\frac{\\alpha^2\\eta_t}{\\lambda^{3/2}} \\| X_{t+1}X_{t+1}^\\top - X_t X_t^\\top \\|_{\\mathrm{Fr}}^2$. A careful derivation using the strong convexity of $\\phi(X, \\cdot)$ (specifically $\\phi_{t+1}(X_{t+1}, \\cdot)$) and the optimality of $A_{t+1}$ suggests this term should be bounded by an expression closer to $\\frac{\\alpha}{8\\eta'_t \\lambda^{3/2}} \\| X_{t+1}X_{t+1}^\\top - X_t X_t^\\top \\|_{\\mathrm{Fr}}^2 = \\frac{1}{8\\eta_t \\lambda^{3/2}} \\| X_{t+1}X_{t+1}^\\top - X_t X_t^\\top \\|_{\\mathrm{Fr}}^2$. When $\\eta_t \\sim 1/\\sqrt{t}$, the paper's bound for this term (after bounding the norm difference by a constant) sums to $O(\\sqrt{T})$. The corrected bound sums to $O(T^{3/2})$. This discrepancy invalidates the claimed $O(\\sqrt{T/N})$ regret rate in Theorem 3.1 (thm:schatten_ball) and consequently Theorem 3.5 (thm:adatask) and Theorem A.4 (thm:adatask_anyproba)."
      },
      {
        "Problem": "Inconsistency in the definition and analysis of AdaTask for arbitrary activation probabilities",
        "Location": "Algorithm 3 (AdaTask for arbitrary activation probabilities, Appendix C) and its analysis in Theorem A.4 (thm:adatask_anyproba, Appendix A.7).",
        "Explanation": "Algorithm 3 defines the update for $\\tilde{X}_t$ as an optimization over the Schatten-1 unit ball $\\mathcal{B}_{S(1)} = \\{X \\colon \\|X\\|_{S(1)} \\le 1\\}$. However, the analysis for Theorem A.4 (specifically the 'Bound on $\\mathcal{B}_\\Pi$' part in Appendix A.7) assumes that $\\tilde{X}_t$ is optimized over $\\mathcal{B}_\\Pi = \\{X \\colon \\|\\Pi^{1/2}X\\|_{S(1)} \\le 1\\}$. The parameter-free construction used in the proof of Theorem A.4 requires the base Schatten-FTRL algorithm to be defined and analyzed for iterates $X_t$ and comparators $U$ in $\\mathcal{B}_\\Pi$. The mismatch between the algorithm's specified optimization domain ($\\mathcal{B}_{S(1)}$) and the domain assumed in its analysis ($\\mathcal{B}_\\Pi$) means the proof does not directly apply to the described Algorithm 3."
      }
    ],
    "token_usage": {
      "input": 34260,
      "thinking": 21733,
      "output": 842
    }
  },
  {
    "entry_id": 36,
    "retraction_id": "2006.05804v2",
    "paper_id": "2006.05804v1",
    "retraction_comment": "Lemma 2.2 is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 50169,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 37,
    "retraction_id": "1708.02698v3",
    "paper_id": "1708.02698v2",
    "retraction_comment": "It turns out that there is an error in the argument for the curve case in Lemma 2.5 which makes the main result (Theorem 2.4) partially incorrect. We will post a modified version of the paper in which this is fixed. Meanwhile we withdraw the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The assumption that the local ring $R_\\p$ is a Discrete Valuation Ring (DVR) in Theorem 1.8 is critical for its proof, but it may not hold in the main construction.",
        "Location": "Theorem 1.8 (page 6), and its use in the proof of Theorem 2.5 (page 10-11).",
        "Explanation": "Theorem 1.8 states that the Rees algebra $\\mathcal{A}_v(R)$ (and associated graded ring $\\text{gr}_v(R)$) is finitely generated if $R$ is a f.g. domain, $I=(x)$ is principal, $\\p = \\sqrt{I}$ is prime, and $R_\\p$ is a DVR ( $v$ is the valuation of $R_\\p$). The proof of Theorem 2.5 (main theorem) iteratively applies this result to algebras $R^{(i)}$. Specifically, $R^{(i+1)} = \\text{gr}_v(R^{(i)})$. For this to work, at each step $i$, a prime ideal $\\p_i \\subset R^{(i)}$ must be found such that $(R^{(i)})_{\\p_i}$ is a DVR. The paper argues such $\\p_i$ can be chosen using Lemma 2.4. However, $R^{(i)}$ (for $i>0$) is an associated graded ring from a previous step. Such rings are often not normal, even if $R^{(0)}$ is. If $R^{(i)}$ is not normal, its localization $(R^{(i)})_{\\p_i}$ at a height 1 prime $\\p_i$ is not necessarily a DVR. For example, if $R^{(0)}$ is the coordinate ring of an elliptic curve (normal), $R^{(1)}$ can be the coordinate ring of a cuspidal cubic (not normal, as shown in Example 1.5). If the construction needs to proceed further with this non-normal $R^{(1)}$, finding a $\\p_1$ such that $(R^{(1)})_{\\p_1}$ is a DVR is not guaranteed by Lemma 2.4. Lemma 2.4 (Bertini-type argument) ensures $\\p_i = \\sqrt{(f_i)}$ is prime and $V(\\p_i)$ intersects the stable locus. It does not guarantee that $(R^{(i)})_{\\p_i}$ is a DVR if $R^{(i)}$ itself is not normal or does not satisfy Serre's condition $R_1$. The paper states (page 10, proof of Thm 2.5) 'Since there are only finitely many one-dimensional local rings of A that are not normal, we can moreover assume that for such a prime ideal p, the localization A_p is normal and hence a discrete valuation ring.' This statement is problematic: a ring $A$ can have its non-normal locus (where $A_\\mathfrak{q}$ is not DVR for ht 1 $\\mathfrak{q}$) be of codimension 1, meaning such primes $\\mathfrak{q}$ are dense. A 'general' choice of $\\p$ from Lemma 2.4 might fall into this non-normal locus if $A=R^{(i)}$ is not $R_1$. If $(R^{(i)})_{\\p_i}$ is not a DVR, Theorem 1.8 cannot be applied, and the argument for finite generation of $R^{(i+1)}$ fails."
      }
    ],
    "token_usage": {
      "input": 20361,
      "thinking": 21295,
      "output": 771
    }
  },
  {
    "entry_id": 38,
    "retraction_id": "1201.3873v3",
    "paper_id": "1201.3873v2",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial gap in the estimates for m>=4",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Calculation of Sum of Coefficients for B-H Inequality ($m \\ge 4$)",
        "Location": "Section 3 (m=4), Section 4 (m>=6), pages 3-5. Specifically, the definition of $f_4(a,b,c)$, $g_4(a,c)$, and $g_6(a,c)$.",
        "Explanation": "The formulae for the functions $f_m(a,b,c)$ (or $g_m(a,c)$) used to derive lower bounds for $D_m$ for $m \\ge 4$ appear to incorrectly calculate the sum $\\left( \\sum_{\\left\\vert \\alpha\\right\\vert =m} \\left\\vert a_{\\alpha}\\right\\vert ^{\\frac{2m}{m+1}}\\right)^{\\frac{m+1}{2m}}$. The Bohnenblust-Hille inequality requires summing powers of the coefficients $a_\\alpha$ of the polynomial $P_m(z) = \\sum_{\\left\\vert \\alpha\\right\\vert =m}a_{\\alpha}z^{\\alpha}$ after all terms for each distinct monomial $z^\\alpha$ have been collected. The paper's method for $P_m = (P_2)^{m/2}$ seems to sum powers of coefficients of intermediate terms from the expansion (e.g., from $(X+Y)^k = \\sum \\binom{k}{j} X^j Y^{k-j}$ and further expansions of $X^j$ and $Y^{k-j}$) before collecting terms for identical monomials. For example, for $m=4$ and $P_4=(az_1^2+bz_2^2+cz_1z_2)^2$, the coefficient of $z_1^2z_2^2$ is $(c^2+2ab)$. The paper's formula for $f_4$ appears to use terms like $|c^2|^{8/5}$ and $|2ab|^{8/5}$ separately instead of $|c^2+2ab|^{8/5}$. This error is systemic for $m \\ge 4$ and invalidates the computed lower bounds for $D_m$ ($m \\ge 4$) and consequently the estimated lower bound for the hypercontractivity constant $C$."
      },
      {
        "Problem": "Numerical Discrepancy and Incorrect Maximum for $f_2(a,b,c)$",
        "Location": "Section 2, page 3, paragraph evaluating $f_2(a,b,c)$.",
        "Explanation": "The paper states that for $a=1, b=-1, c_0 = \\frac{352203}{125000} \\approx 2.8176$, $f_2(1,-1,c_0) \\approx 1.1066$. It also claims that '$f_2(a,b,c) < 1.1067$ for all $a,b,c$'. However, direct calculation using the provided formula for $f_2(1,-1,c)$ yields $f_2(1,-1,c_0) \\approx 1.120$. Furthermore, optimizing $f_2(1,-1,c)$ with respect to $c$ (e.g., for $c \\approx 2.72$) yields values around $1.132$, which contradicts the claimed upper bound of $1.1067$. This numerical error and incorrect assertion about the maximum affect the validity of the specific lower bound $D_2 \\ge 1.1066$ and the subsequent arguments relying on this precise value."
      },
      {
        "Problem": "Overly Strong Claim Regarding Non-Existence of Sequences $(D_m)$ with $\\lim D_m/D_{m-1}=1$",
        "Location": "Abstract (page 1) and Introduction (page 2, end of 4th paragraph).",
        "Explanation": "The paper claims its results 'strongly support the claim that there is no sequence $(D_m)_{m=1}^{\\infty}$ of constants satisfying the polynomial Bohnenblust--Hille inequality and so that $\\lim_{m\\rightarrow\\infty}\\frac{D_{m}}{D_{m-1}}=1$.' This statement is too strong and potentially misleading. The Bohnenblust-Hille inequality asserts the existence of such constants $D_m$. Research typically focuses on the *optimal* (smallest possible) constants, let's call them $D_m^{opt}$. If the authors' method correctly showed that $D_m^{opt}$ grow exponentially (e.g., $D_m^{opt} \\ge x^m$ for $x>1$), then it would indeed imply that for this sequence of optimal constants, $\\lim_{m\\rightarrow\\infty}\\frac{D_m^{opt}}{D_{m-1}^{opt}} \\neq 1$. However, this does not preclude the existence of *some* (non-optimal) sequence $D'_m$ that satisfies the inequality (i.e., $D'_m \\ge D_m^{opt}$) and also $\\lim_{m\\rightarrow\\infty}\\frac{D'_{m}}{D'_{m-1}}=1$. For example, one could choose $D'_m$ to be much larger than $D_m^{opt}$ in a way that satisfies this limit condition. The paper's conclusion should be restricted to the sequence of optimal constants."
      },
      {
        "Problem": "Flawed Reasoning for Lower Bound of Hypercontractivity Constant $C$",
        "Location": "Section 5, page 5, discussion around equation (5.1).",
        "Explanation": "The paper argues for a lower bound on the hypercontractivity constant $C$ by stating: 'If $x>1$ is so that $D_{m}\\geq x^{m}$ for all $m\\geq2$, then we can easily check that $x\\geq1.0845$.' This premise ($D_m \\ge x^m$ for all $m$) implies $x \\le (D_m)^{1/m}$ for all $m$, and thus $x \\le \\inf_m (D_m)^{1/m}$. However, the value $1.0845$ is derived from $(D_{14})^{1/14}$ (using their computed lower bounds for $D_m$), which is the maximum of $(D_m)^{1/m}$ in their provided list. The correct reasoning for a lower bound on $C$ (assuming $C$ is the smallest constant such that $D_m^{opt} \\le C^m$) would be that $C \\ge (D_m^{low})^{1/m}$ for any particular $m$ where $D_m^{low}$ is a valid lower bound for $D_m^{opt}$. Therefore, $C \\ge \\sup_m (D_m^{low})^{1/m}$. The paper's phrasing for deriving $x \\ge 1.0845$ (which should be $C \\ge 1.0845$) is logically misstated."
      },
      {
        "Problem": "Misleading Definition of Hypercontractivity in Abstract",
        "Location": "Abstract, page 1, first sentence.",
        "Explanation": "The abstract states: 'Recently, it was proved that the polynomial Bohnenblust--Hille inequality is hypercontractive, i.e., there is a constant $C>1$ (from now on called constant of hypercontractivity) so that $\\frac{D_{m}}{D_{m-1}}=C$ for every $m$ ...'. This definition of hypercontractivity is non-standard and significantly stronger than the commonly accepted one (which is $D_m \\le K^m$ for some $K$, as correctly stated in Section 1 of the paper). If the abstract's definition were true, then $\\lim_{m\\rightarrow\\infty} \\frac{D_m}{D_{m-1}} = C > 1$. This would make the paper's subsequent question 'natural to wonder if there exist constants $D_m$'s such that $\\lim_{m\\rightarrow\\infty} \\frac{D_m}{D_{m-1}}=1$' trivially answered as 'no' from the outset. This initial misstatement creates fundamental confusion about the paper's premise and motivation."
      }
    ],
    "token_usage": {
      "input": 9316,
      "thinking": 16483,
      "output": 1903
    }
  },
  {
    "entry_id": 39,
    "retraction_id": "1006.2189v2",
    "paper_id": "1006.2189v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The proof of the verification of axiom 1 for the smoothing functor that is given in the paper is false, since it would violate what is known in dimension 4. If U is a subset of V and both are diffeomorphic to R^4, then the restriction map of smoothing spaces sm(V) -> sm(U) need not be one-to-one on path components. Thus axiom 1 is violated in dimension 4. The verification of axiom 1 in higher dimensions is probably a consequence of the product structure theorem",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect statement of the Isotopy Extension Theorem (Lemma 2.3).",
        "Location": "Page 4, Lemma 2.3",
        "Explanation": "Lemma 2.3 states: 'Let $K \\subset L$ be an inclusion of compact subsets of a topological manifold $N$. Then the restriction map $E(K,N) \\to E(L,N)$ is a Kan fibration.' The map $E(K,N) \\to E(L,N)$ would correspond to extending an embedding of $K$ to an embedding of $L$. This is not generally possible, nor is it a fibration. The restriction map goes from embeddings of $L$ to embeddings of $K$, i.e., $E(L,N) \\to E(K,N)$. The cited references [KE, Cor. 1.2] and [Lees] refer to this standard restriction map. This error is significant as Lemma 2.3 is invoked in the proof of Lemma 2.2."
      },
      {
        "Problem": "Mismatch between the cited Isotopy Extension Theorem (Lemma 2.3) and its application in Lemma 2.2.",
        "Location": "Page 3-4, Proof of Lemma 2.2",
        "Explanation": "The proof of Lemma 2.2 (that $\\Sm(K) \\to \\Sm(L)$ is a Kan fibration) states it uses 'the isotopy extension theorem (Lemma \\ref{isotopy-extension})'. The argument requires extending an isotopy $g_t: U \\to V$ (where $U$ is an open subset of $V$) to an isotopy $G_t: V \\to V$ of homeomorphisms. Lemma 2.3, even if its statement were corrected to $E(L,N) \\to E(K,N)$ being a Kan fibration (which concerns embeddings), does not directly state or imply the specific type of isotopy extension for homeomorphisms of $V$ that is used in the proof of Lemma 2.2. A more precise statement or citation of the appropriate isotopy extension theorem for homeomorphisms (e.g., by Edwards, Kirby, or Siebenmann for topological manifolds) is needed for the argument to be rigorous."
      },
      {
        "Problem": "Unjustified reduction step in the proof of excision for $\\Sm(U)$.",
        "Location": "Page 6, Proof of Proposition 3.5",
        "Explanation": "The proof that $U \\mapsto \\Sm(U)$ is excisive (Proposition 3.5) asserts: 'The discussion in \\S\\ref{good-functors} shows that it is enough to prove that the pullback square ... is a homotopy pullback whenever $K_1,K_2$ are compact codimension zero smooth submanifolds of $M$ whose boundaries meet transversely.' While reducing problems from open sets to compact submanifolds is a common technique in manifold topology and surgery theory (often justifiable using properties like Axiom (2) for good functors), the paper does not explicitly detail how the 'goodness' properties from \\S2 (specifically Axiom (2) which relates $\\Sm(U)$ to $\\holim \\Sm(K_i)$) are used to justify this reduction for the excision property. For a 'low-tech account', this step might warrant more explanation."
      }
    ],
    "token_usage": {
      "input": 13024,
      "thinking": 19942,
      "output": 749
    }
  },
  {
    "entry_id": 40,
    "retraction_id": "1207.1467v2",
    "paper_id": "1207.1467v1",
    "retraction_comment": "This paper has been withdrawn due to a logica error in equation 1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of the Bird, Stewart, Lightfoot (BSL) model and the concept of 'enhanced diffusion'.",
        "Location": "Section 3.1 (A Comparison with Bird, Lightfoot, and Stewart), particularly pages 5-6 and the conclusion on page 6.",
        "Explanation": "The paper argues that the BSL model, which for stagnant air ($\\mathbf{v}^{g_a}=0$) results in a nonlinear diffusion coefficient $D/(1-C^{g_v})$, 'falsely reports enhanced diffusion' compared to a linear diffusion model ($\\partial\rho^{g_v}/\\partial t = \nabla \\cdot (D \nabla \rho^{g_v})$). This linear model implicitly assumes zero bulk velocity ($\\mathbf{v}^g=0$). The BSL model with $\\mathbf{v}^{g_a}=0$ correctly describes a physical situation where diffusion of species $g_v$ induces a bulk flow (Stefan wind, $\\mathbf{v}^g \neq 0$). The 'enhancement' is a real effect of this advective transport. Comparing these two models describes two physically distinct scenarios ($\\mathbf{v}^{g_a}=0$ vs. $\\mathbf{v}^g=0$), not a flaw in the BSL model itself. The paper's algebraic reduction of one formulation to another is correct but does not support the claim of 'false enhancement'. Additionally, Eq. (3.5) is stated to be 'a simple expression of momentum balance', which is incorrect; it is a direct consequence of the definition of mass-average velocity and diffusive fluxes."
      },
      {
        "Problem": "Inconsistent temperature assumptions in the coupled advection-diffusion-momentum model.",
        "Location": "Section 4 (Advection Diffusion Models), Equations (4.5a-e) (labeled as 'eqn:Pepg').",
        "Explanation": "Equations (4.5a) and (4.5b) for relative humidity $\\rh$ and air density $\\rho^{g_a}$ are derived assuming constant temperature $T$ (which means $\\rho_{sat}$ and $D$ are constants that can be factored out of spatial derivatives). However, Equation (4.5d) for the gas phase pressure $p^g$ explicitly includes $\\rho_{sat}(T)$, implying $T$ can be variable, and refers to $R^{g_v}T\\rho_{sat}(T)\\rh$. This is inconsistent. If $T$ is variable (as considered in Sec 3.3 for thermal gradients), then $\\rho_{sat}$ and $D$ are functions of $T(x,t)$, and the mass transport equations (4.5a, 4.5b) must be written in their more general forms, e.g., $\\partial_t(\\rho_{sat}\\rh) + \\nabla \\cdot (\\rho_{sat}\\rh \\mathbf{v}^g) = \\nabla \\cdot (D \\nabla (\\rho_{sat}\\rh))$ for (4.5a), and the subsequent nondimensionalization would also be affected."
      },
      {
        "Problem": "Incorrect dimensionless form for the air species conservation equation.",
        "Location": "Section 4, page 10, the unnumbered equation for dimensionless air-species density $\\tilde{\\rho}^{g_a}$ following the dimensionless equation for $\\rh$.",
        "Explanation": "The dimensional equation for air density $\\rho^{g_a}$ is given by Eq. (4.5b): $\\partial_t \\rho^{g_a} + \\nabla \\cdot (\\rho^{g_a} \\mathbf{v}^g) = -D \\rho_{sat} \\nabla^2 \\rh$. The paper then presents a dimensionless form for $\\tilde{\\rho}^{g_a} = \\rho^{g_a}/\\rho_{sat}(T)$ as $\\partial_\\tau \\tilde{\\rho}^{g_a} + Pe \\nabla_\\xi \\cdot (\\tilde{\\rho}^{g_a} \\tilde{\\mathbf{v}}^g) = \\nabla_\\xi^2 \\tilde{\\rho}^{g_a}$. This dimensionless form would correspond to a dimensional equation like $\\partial_t \\rho^{g_a} + \\nabla \\cdot (\\rho^{g_a} \\mathbf{v}^g) = D \\nabla^2 \\rho^{g_a}$ (assuming $D$ is the same diffusivity and $T$ is constant). This fundamentally differs from the starting dimensional Eq. (4.5b), particularly the right-hand side (a source term related to $\\rh$ versus a self-diffusion term for $\\rho^{g_a}$). This error invalidates the subsequent analysis based on this system."
      },
      {
        "Problem": "Flawed argument for neglecting bulk velocity in natural convection.",
        "Location": "Section 4, page 11, discussion following the dimensionless momentum equation leading to Eq. (4.10).",
        "Explanation": "The paper argues that because coefficients of acceleration, advection, and gravity terms in the dimensionless momentum equation are small, the bulk velocity $\\mathbf{v}^g$ is negligible. The analysis leads to $\\nabla_\\xi \\rh + (R^{g_a}/R^{g_v}) \\nabla_\\xi \\tilde{\\rho}^{g_a} \\approx \\mathbf{0}$, which implies $\\nabla p^g \\approx 0$ (spatially uniform pressure). However, $\\nabla p^g \\approx 0$ does not necessarily mean $\\mathbf{v}^g \\approx 0$. The momentum equation would simplify to $\\rho^g (D\\mathbf{v}^g/Dt) \\approx \\rho^g \\mathbf{g}$ (if viscous forces are also negligible), describing buoyancy-driven flow. The velocity scale $v_c \\approx D/L$ was assumed for $Pe \\approx 1$. While this velocity might be small, its negligibility in the mass transport equation requires more rigorous justification than provided, potentially underestimating the role of natural convection."
      },
      {
        "Problem": "Incorrect coefficient in the dimensionless momentum equation for the constant pressure case.",
        "Location": "Section 4, Equation (4.11b) (labeled 'eqn:Pe_case_1b').",
        "Explanation": "For the case where total gas pressure $p^g$ is assumed constant, the dimensionless momentum equation is given as $\\partial_\\tau \\tilde{\\mathbf{v}}^g + \\tilde{\\mathbf{v}}^g \\cdot \\nabla_\\xi \\tilde{\\mathbf{v}}^g = (L^2 g / D^2) \\mathbf{e}_3$. Starting from $\\partial_t \\mathbf{v}^g + \\mathbf{v}^g \\cdot \\nabla \\mathbf{v}^g = \\mathbf{g}$ (assuming $\\rho^g$ is constant and cancels), and using the scalings $\\mathbf{v}^g = v_c \\tilde{\\mathbf{v}}^g$, $t=(L^2/D)\\tau$, $\\xi=x/L$: the equation becomes $\\frac{v_c D}{L^2}\\partial_\\tau \\tilde{\\mathbf{v}}^g + \\frac{v_c^2}{L} (\\tilde{\\mathbf{v}}^g \\cdot \\nabla_\\xi \\tilde{\\mathbf{v}}^g) = \\mathbf{g}$. If the coefficient of the convective term is set to $Pe = Lv_c/D$ (as implied by the paper, or $1$ if $Pe=1$), then dividing by $v_cD/L^2$ yields $\\partial_\\tau \\tilde{\\mathbf{v}}^g + Pe (\\tilde{\\mathbf{v}}^g \\cdot \\nabla_\\xi \\tilde{\\mathbf{v}}^g) = (L^2 g / (v_c D)) \\mathbf{e}_3$. If $Pe=1$ is assumed (i.e., $v_c=D/L$), the coefficient of the gravity term becomes $L^3 g / D^2$. The paper's coefficient $L^2 g / D^2$ is missing a factor of $L$ or depends on a different choice of $v_c$ not consistently applied."
      }
    ],
    "token_usage": {
      "input": 21358,
      "thinking": 18943,
      "output": 1852
    }
  },
  {
    "entry_id": 41,
    "retraction_id": "1503.03121v2",
    "paper_id": "1503.03121v1",
    "retraction_comment": "This paper has been withdrawn by the author because the duality is indefensible speculation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unphysical Selective Jettisoning of Matter and Black Holes",
        "Location": "Section 1, p. 2, paragraph 3 (CBE assumption)",
        "Explanation": "The model assumes that all matter (luminous, dark) and black holes are selectively jettisoned from the introverse at turnaround, while radiation, dark energy, and curvature are retained. No physical mechanism is provided for this selective expulsion of specific components from a causally defined region (particle horizon), which is a foundational yet unsupported step for achieving low entropy and specific composition for the contracting phase. The paper states this is done 'with impunity' but offers no process."
      },
      {
        "Problem": "Inconsistent Assumption of Radiation-Dominated Contraction",
        "Location": "Section 1, p. 2, para 3 (content of introverse) and Section 2, Eq. (19) & (21) (contraction dynamics and $t_T$ calculation)",
        "Explanation": "The calculation of the cycle period $t_T$ relies on the contracting universe being radiation-dominated ($\\hat{a}(t) \\propto t^{1/2}$). However, the model states the retained introverse contains dark energy. If this dark energy is inherited from the late-time expanding universe (at $t_T \\sim 1.3 \\text{ Ty}$), its energy density would vastly exceed that of radiation (by factors like $10^{160}$ or more). This would lead to dark-energy-dominated contraction dynamics, invalidating the $t^{1/2}$ scaling and the subsequent calculation of $t_T$. If dark energy is assumed absent during contraction, this contradicts the stated composition of the retained introverse."
      },
      {
        "Problem": "Undefined Physical Process for Scale Factor Reset at Turnaround",
        "Location": "Section 1, p.3, Eq. (13) and Section 2, Eq. (18)",
        "Explanation": "The model postulates that the scale factor for the contracting introverse begins at a fixed value $\\hat{a}(t_T) = 1.11$. This value is derived from $f(t_T)a(t_T)$, where $a(t_T)$ is the scale factor of the expanding universe at turnaround (which can be enormous, e.g., $10^{40}$). This implies an instantaneous, drastic rescaling of the universe patch that forms the new contracting phase. The physical process effecting this transition, and how energy densities of the retained components (radiation, dark energy, curvature) are defined or transform during this reset, is not explained. This makes the initial conditions for the contracting phase physically ambiguous and the transition itself an unexplained event."
      },
      {
        "Problem": "Absence of Bounce Physics",
        "Location": "Section 1, Eq. (1) (model sequence) and throughout Section 2 (implicit reliance on a bounce)",
        "Explanation": "The model proposes infinite cycles of expansion and contraction, necessarily requiring a bounce to transition from contraction back to expansion. The paper does not address the physical mechanism of this bounce. A bounce must resolve the singularity predicted by classical general relativity at the end of contraction and ensure a smooth transition that preserves necessary cosmological properties (e.g., flatness, homogeneity) into the next expansion phase. Without detailing the bounce physics, the model's claim of achieving 'infinite cyclicity' is critically undermined, as the bounce is an essential and physically challenging component of any such cyclic scenario."
      }
    ],
    "token_usage": {
      "input": 6402,
      "thinking": 10769,
      "output": 773
    }
  },
  {
    "entry_id": 42,
    "retraction_id": "2405.12710v3",
    "paper_id": "2405.12710v2",
    "retraction_comment": "The author has withdrawn this paper due to a critical definitional error in concept learning for global/local-interaction learning during training. This error led to an alignment issue with the definition of the text-video retrieval task, causing an unfair comparison with state-of-the-art (SOTA) methods. Consequently, this hindered the accurate evaluation of the paper's contributions",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misleading computational complexity analysis for GLSCL and its impact on efficiency claims.",
        "Location": "Abstract (efficiency claim), Introduction (Fig. 1 caption and complexity $\\mathcal{O}(N_tN_v(1+N_q))$), Section III.B (GIM definition, Eq. 4), Table 1 (FLOPs comparison), Table 5 (Time Complexity for GLSCL).",
        "Explanation": "The Global Interaction Module (GIM), as defined in Eq. 4, computes text-guided video features $\\boldsymbol{\\Tilde{v}}$ that are dependent on both the video $\\boldsymbol{v}'$ and the text $\\boldsymbol{\\Tilde{t}}$. This necessitates recomputing $\\boldsymbol{\\Tilde{v}}$ for each text-video pair, incurring a pairwise cost of $\\mathcal{O}(N_f D)$ for GIM alone (where $N_f$ is number of frames, $D$ is feature dimension). Consequently, the dominant pairwise computational complexity for GLSCL's similarity scoring is $\\mathcal{O}(N_t N_v (N_f D + N_q D))$, or $\\mathcal{O}(N_t N_v N_f)$ if $N_f D$ dominates $N_q D$. This places GLSCL in the same asymptotic complexity class as methods like X-Pool (also $\\mathcal{O}(N_t N_v N_f)$). However, the paper repeatedly states GLSCL's complexity as $\\mathcal{O}(N_tN_v(1+N_q))$ (e.g., Fig. 1 caption, Table 5), which omits the crucial $N_f$ factor from GIM's pairwise computation. This underrepresents GLSCL's true asymptotic complexity for the matching stage. While GLSCL might still be more efficient due to smaller constant factors or specific implementation choices (as suggested by the 1.0G FLOPs vs X-Pool's 275.0G in Table 1), the claimed difference in complexity class is inaccurate and potentially misleads the assessment of its efficiency benefits over some SOTA methods."
      },
      {
        "Problem": "The formulation of the $\\gamma$ term in the Inter-Consistency Loss (ICL) is counter-intuitive and potentially detrimental.",
        "Location": "Section III.D, Equation 7; Section IV.A (hyperparameter $\\lambda=0.75$).",
        "Explanation": "The ICL includes a term $\\gamma = \\sum_{i=1}^{N_q}(\\lambda - {(\\boldsymbol{c}^t_i})^\\top \\boldsymbol{c}^v_i)^2$, where $\\lambda$ is set to 0.75. If concept embeddings are normalized (as implied by other parts of the method), ${(\\boldsymbol{c}^t_i})^\\top \\boldsymbol{c}^v_i$ is their cosine similarity. This term penalizes deviations from a target similarity of 0.75. This means it actively discourages corresponding text and video concepts from achieving higher similarity (e.g., a cosine similarity of 0.9 or 1.0, representing better alignment). This contradicts: (1) the intuitive goal of 'consistency' which should promote maximal alignment; (2) the Euclidean distance term $\\mathcal{D}^i$ within the same ICL, which encourages $\\boldsymbol{c}^t_i = \\boldsymbol{c}^v_i$ (implying maximal similarity); and (3) the main contrastive loss $\\mathcal{L}_{\\texttt{CL}}$ (via $\\mathcal{S}_\\texttt{F}$), which also promotes maximal similarity for positive pairs. The justification ('avoid overfitting', 'suitable margin') is insufficient for this specific formulation that punishes strong positive alignment."
      },
      {
        "Problem": "Ambiguity regarding L2 normalization of concept embeddings used in ICL and similarity scores.",
        "Location": "Section III.D (Eq. 7 for ICL's $\\gamma$ term), Section III.E (Eq. 12 for fine-grained similarity score $\\mathcal{S}_\\texttt{F}$).",
        "Explanation": "The paper does not explicitly state whether concept embeddings $\\boldsymbol{c}^t_i, \\boldsymbol{c}^v_i$ are L2 normalized before their dot product ${(\\boldsymbol{c}^t_i})^\\top \\boldsymbol{c}^v_i$ is used in ICL's $\\gamma$ term (Eq. 7) or in the fine-grained similarity score $\\mathcal{S}_\\texttt{F}$ (Eq. 12, which defines it as a sum of cosine similarities). The Intra-Diversity Loss (IDL, Eq. 9) explicitly uses `COS`, implying normalization for concepts there. If concepts are normalized for $\\mathcal{S}_\\texttt{F}$ and IDL, this should apply to ICL's dot product as well, exacerbating the issue outlined in Problem 2. If they are not normalized for Eq. 7, the meaning of a target dot product value $\\lambda=0.75$ becomes unclear, as the dot product's scale can vary significantly. This lack of clarity on a fundamental operation affects the interpretation, soundness, and reproducibility of these key components and their interactions."
      }
    ],
    "token_usage": {
      "input": 35709,
      "thinking": 11260,
      "output": 1186
    }
  },
  {
    "entry_id": 43,
    "retraction_id": "1305.5284v3",
    "paper_id": "1305.5284v2",
    "retraction_comment": "This paper has been withdrawn by the author due to missing phase-space factor in eq(1)/(2), thus the whole structure is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound Statistical Argument for Quark Suppression at High Temperatures",
        "Location": "Page 2, Column 1, Equations (1)-(2) and surrounding text, particularly the sentence 'At high temperature limit, $E/T \\rightarrow 0$ so that $n_{\\rm B}  \\rightarrow \\inf,  n_{\\rm F} \\rightarrow 1/2$.'",
        "Explanation": "The paper argues that high temperature inherently favors a pure gluon plasma by suppressing quark presence, based on a misinterpretation of Bose-Einstein and Fermi-Dirac distributions for single energy states ($n_B, n_F$) rather than integrated particle number densities. In thermal equilibrium at high temperatures ($T \\gg m_q$), quark-antiquark pairs are expected to be copiously produced until chemical equilibrium is reached, with their density relative to gluons determined by statistical weights and phase space integrals, not by $n_B/n_F \\rightarrow \\inf$. This flawed argument undermines the fundamental premise for the existence of the proposed 'Glasma' phase as a thermalized, pure gluon system sustained by high temperature, which is central to all the paper's conclusions regarding heavy ion collisions."
      },
      {
        "Problem": "Absolute Claim of Zero Electromagnetic Emission from Glasma",
        "Location": "Page 2, Column 1, paragraph starting 'Now let's high temperature...' (e.g., 'Glasma can emit neither photons nor leptons') and the Table on Page 2.",
        "Explanation": "The paper asserts that a pure gluon plasma (Glasma) has strictly zero photon and dilepton emission rates because gluons lack electric charge. This neglects higher-order processes, such as $gg \\rightarrow \\text{virtual } q\\bar{q} \\rightarrow \\gamma$ or $gg \\rightarrow \\text{virtual } q\\bar{q} \\rightarrow l^+l^-$, which, though loop-suppressed, would lead to non-zero electromagnetic emission. Claiming 'zero' emission is an overstatement. If the emission is non-zero, even if small, the extent to which this 'Glasma' can be considered 'dark' and solve the photon/dilepton puzzles by simply not radiating is diminished, potentially invalidating the proposed solutions."
      },
      {
        "Problem": "Questionable Stability and Thermal Nature of the Proposed Pure Gluon Phase",
        "Location": "Abstract ('Glasma ... may exist at very high temperature'); Page 1, Col 1 ('what is the matter before QGP formation... Glasma'); Page 2, Col 1 ('Hydrodynamics works for the collective motion... The dynamic equation $e=e(p)$ of QGP is naturally replaced by that of Glasma').",
        "Explanation": "The paper posits a 'Glasma' phase that is thermalized (described by hydrodynamics and an equation of state) and sufficiently long-lived to impact observables like elliptic flow, yet remains purely gluonic. Given the flawed argument for quark suppression at high temperatures (Problem 1), there is no sound mechanism presented for preventing rapid chemical equilibration via $gg \\leftrightarrow q\\bar{q}$ in such a hot, dense, and supposedly thermalized system. Without this, the existence of an extended, thermalized, *purely* gluonic phase distinct from a standard QGP (which includes quarks) is highly questionable, thereby invalidating its proposed role in the evolution of the collision system and its effects on observables."
      },
      {
        "Problem": "Misleading Critique of Standard Photon/Dilepton Rate Calculations",
        "Location": "Page 2, Column 1-2, paragraph starting 'So if the system evolution is well constrained...', specifically the claim about 'the approximation of classic limit, replacing Eq.(1) and (2) with $1/\\exp(E/T)$ in \\cite{Kapusta1991}'.",
        "Explanation": "The paper claims that conventional calculations of photon and dilepton rates (e.g., Kapusta, AMY) overestimate high-temperature emission due to using a 'classic limit' (Boltzmann) approximation for parton distributions, which is stated to be invalid for $E/T \\sim 1$. This appears to be a mischaracterization, as standard derivations (like Kapusta et al., 1991) explicitly use the correct quantum statistical distributions (Fermi-Dirac and Bose-Einstein) and associated $(1 \\pm f)$ factors. If this critique is incorrect, then a key argument for why existing models fail (and thus why the new Glasma picture is needed to explain data) is weakened. The primary effect of the paper's Glasma would be the absence of quarks, not a correction to how QGP rates are calculated."
      },
      {
        "Problem": "Unsupported and Speculative Cosmological Claims",
        "Location": "Page 2, Column 2, sections discussing Glasma as dark matter and dark energy.",
        "Explanation": "The paper speculates that its 'Glasma' could be a candidate for cosmological dark matter and dark energy. The proposed properties (e.g., hot, dense, purely gluonic, existing at a 'core of the universe,' causing cosmic acceleration via pressure gradients from this core) are inconsistent with established characteristics of dark matter (cold/warm, stable, non-baryonic issues for primordial gluons) and dark energy (negative pressure, smooth distribution). These claims are highly speculative and appear to be based on misunderstandings of standard cosmology. While not directly invalidating the heavy-ion collision arguments, they suggest a potential lack of rigor in applying concepts to other fields, which can cast doubt on the overall theoretical framework presented."
      }
    ],
    "token_usage": {
      "input": 7292,
      "thinking": 7674,
      "output": 1224
    }
  },
  {
    "entry_id": 44,
    "retraction_id": "2307.11176v2",
    "paper_id": "2307.11176v1",
    "retraction_comment": "There is an irrecoverable error in Lemma 2.5. There are counterexamples even in case R=Q[x]. The lemma is crucial for the rest of the paper and it does not work unless strong assumptions are made (like: the modules are graded)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 2.3",
        "Location": "Page 3, Proof of Lemma 2.3",
        "Explanation": "The proof of Lemma 2.3, which states $\\bigcap\\mathcal{F}^jM=0$ for a regularly $\\mathbb{Z}$-filtered module $M$, relies on the step $\\bigcap \\mathcal{F}^jM=\\phi(\\bigcap I^jR[w]^k)$ (where $I=(w)$ and $\\phi: R[w]^k \\to \\mathcal{F}^0M$ is a surjection). This step is not generally correct, as $\\bigcap w^j \\phi(A) \\neq \\phi(\\bigcap w^j A)$. However, the statement of Lemma 2.3 is correct and can be proven directly: if $x \\in \\bigcap \\mathcal{F}^j M$ and $x \\neq 0$, then $x$ must belong to $\\mathcal{F}^k M \\setminus \\mathcal{F}^{k+1} M$ for some integer $k$. But $x \\in \\bigcap \\mathcal{F}^j M$ implies $x \\in \\mathcal{F}^{k+1} M$, a contradiction. Thus $x=0$. While the statement is correct and crucial, the provided proof is flawed."
      },
      {
        "Problem": "Incorrect characterization of units in $R[w,w^{-1}]$ for non-commutative $R$",
        "Location": "Page 7, Proof of Lemma 6.2 (formerly Lemma 6.3, (b) => (c))",
        "Explanation": "In the proof of Lemma 6.2 (b) $\\implies$ (c), it is stated: 'The elements invertible in $R[w,w^{-1}]$ are of form $w^kr$, where $k\\in\\mathbb{Z}$ and $r\\in R$ is invertible.' This characterization of units is generally true if $R$ is commutative, but it is not true for arbitrary non-commutative rings $R$. For example, if $R=M_2(\\mathbb{C})$ (2x2 matrices over complex numbers), then $\\begin{pmatrix} w & 0 \\\\ 0 & 1 \\end{pmatrix}$ is a unit in $R[w,w^{-1}]$ but not of the form $w^k r$. The argument that $\\widetilde{g} = w^k \\otimes g$ can be made by choosing $w^k$ to clear denominators when writing $\\widetilde{g} = g_0/w^k$, and then absorbing any unit from $R$ into $g_0$. The specific claim about the form $w^k r$ is an oversimplification for the non-commutative case. The overall implication (b) $\\implies$ (c) is likely still valid as $S=\\{w^k\\}$ is a central multiplicative set, but the specific reasoning step is imprecise for non-commutative $R$."
      }
    ],
    "token_usage": {
      "input": 16362,
      "thinking": 26630,
      "output": 676
    }
  },
  {
    "entry_id": 45,
    "retraction_id": "0804.4876v3",
    "paper_id": "0804.4876v2",
    "retraction_comment": "A counterexample to Theorem 1.2 has been pointed out to the author (x^2+3 reduced modulo 2). The mistake cannot be corrected at this time",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The generalization of the Kummer-Dedekind Theorem (Theorem 1.2) is stated to hold without the customary hypothesis (e.g., that the prime $p$ does not divide the index $[\\mathcal{O}_K : \\mathcal{O}_k[\\alpha]]$), but the theorem statement in this generality is incorrect, and its proof in Section 4 is unsound.",
        "Location": "Theorem 1.2 (page 2), Remark 1.3 (page 2), and Proof of Theorem 1.2 in Section 4 (pages 7-8, specifically the 'Notation' subsection and Step 2). Also mentioned in the Abstract.",
        "Explanation": "Theorem 1.2 claims to relate the factorization of a polynomial $c(x)$ modulo a prime $p$ (i.e., $\bar{c}=\bar{c}_1^{e_1}\\cdots\bar{c}_s^{e_s}$) to the splitting of $p$ in $\\mathcal{O}_K$ (i.e., $p\\mathcal{O}_K=P_1^{e(P_1|p)}\\cdots P_r^{e(P_r|p)}$) by asserting $r=s$, $e(P_i|p)=e_i$, and $f(P_i|p)=f_i$, without the standard condition that $p$ does not divide the index of $\\mathcal{O}_k[\\alpha]$ in $\\mathcal{O}_K$. This generalized statement is known to be false; counterexamples exist where $e_i \neq e(P_i|p)$ when $p$ divides the index. The proof provided in Section 4 is flawed because: \n1. In the 'Notation' subsection for the proof (page 7), it asserts cardinalities for sets of roots: '$|R_i|=e_if_i$' and '$|R_i^{(j)}|=e_i$'. These assertions effectively assume part of what needs to be proven (that the polynomial multiplicities $e_i$ correspond to certain counts of roots reducing to factors of $\bar{c}_i \\pmod P$) and are not justified in the general case where the index condition is violated.\n2. In Step 2 of the proof, the claim that the set $R_i$ (roots of $c(x)$ reducing modulo $P$ to roots of $\bar{c}_i$) is a $D$-transitive set (i.e., a single orbit under the decomposition group $D$) is not justified. $R_i$ is $D$-stable, but not necessarily $D$-transitive in general. \nThis error is critical as the removal of constraints from the Kummer-Dedekind Theorem is presented as a 'remarkable example' and a 'new ingredient' (Abstract, Remark 1.3). While other results in the paper relying on Kummer-Dedekind for unramified primes (where $e_i=1$) might still hold, this central claim about generalization is invalid."
      }
    ],
    "token_usage": {
      "input": 19077,
      "thinking": 15112,
      "output": 670
    }
  },
  {
    "entry_id": 46,
    "retraction_id": "2105.09970v2",
    "paper_id": "2105.09970v1",
    "retraction_comment": "The proof of the main Lemma (3.11, section 3.4) is incomplete: in the middle of page 22, the fact that $\\gamma$ is weakly distributive is not sufficient to justify the chain of two inclusions used to invoke Proposition 2.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The correctness proof of the main algorithm relies on an assumption about the input forest algebra's horizontal monoid that may not hold for the entire class of languages/algebras being considered.",
        "Location": "Section 3 (overall), specifically assumption in 'Vocabulary and notations' (p. 7), Proposition 2.1 (p. 5), Proposition 3.10 (p. 11), Lemma 3.11 (p. 12), and Theorem 3.1 (p. 6).",
        "Explanation": "The algorithm and its correctness proof (Lemma 3.11, relying on Prop. 3.10 and Prop. 2.1) assume that the horizontal monoid $G$ of the input forest algebra $\\mathcal{G}$ is commutative and aperiodic. This assumption is crucial for Proposition 2.1, which characterizes ideals using $\\mathcal{J}$-order properties specific to such monoids ($\\mathcal{J}$-triviality). However, the class $\\mathbf{*D}$ (iterated wreath products of weakly distributive algebras) is defined from weakly distributive spas whose horizontal semigroups are not required to be commutative or aperiodic. Consequently, a syntactic forest algebra $\\mathcal{G}$ of a language in $\\mathsf{*D}$ (or an arbitrary algebra in $\\mathbf{*D}$) may not have a commutative and aperiodic horizontal monoid. If $G$ is not commutative and aperiodic, Prop. 2.1 does not hold as stated, and the subsequent proofs (Prop. 3.10 establishing $\\mathcal{G} \\preceq \\mathcal{M}_1^{\\alpha}$, and Lemma 3.11 establishing $\\mathcal{G} \\preceq \\mathcal{D}_n^{\\alpha}$) are unsound for the general case. This potentially limits the decidability result of Theorem 3.1 to a subclass of $\\mathbf{*D}$ (those algebras whose horizontal monoids are commutative and aperiodic), rather than the full class $\\mathbf{*D}$ as claimed. While this assumption holds for subclasses like $\\mathsf{PDL}$ and $\\mathsf{CTL^*}$ (whose underlying path algebras have commutative and aperiodic horizontal monoids), it's not justified for the general classes $\\mathsf{*D}$ and $*(\\mathsf{D} \\wedge \\mathsf{\\hat{A}^s})$. The paper does not explicitly state that the main theorem for $\\mathsf{*D}$ is restricted to algebras satisfying this condition on their horizontal monoid."
      }
    ],
    "token_usage": {
      "input": 57485,
      "thinking": 23417,
      "output": 551
    }
  },
  {
    "entry_id": 47,
    "retraction_id": "1508.06018v3",
    "paper_id": "1508.06018v2",
    "retraction_comment": "This paper has been withdrawn by the authors due the fact that the main results Proposition 4.1 and Theorem 4.8 are not correct. Anonymous reviewers notice, that In the former the set B\\A is not necessarily nonempty while, in the latter, the formulation and proof are unclear",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency in indexing and undefined terms for the $j=0$ case in Theorem 4.5",
        "Location": "Theorem 4.5 (statement: p.8-9, definition of $\\bS_j$ p.8, proof: Sec 6.3 p.14)",
        "Explanation": "Theorem 4.5 defines $L$ small-gain regions associated with D-paths $\\sigma_j$ for $j=1,\\ldots,L$. These paths define quantities like $\\bB_j, \\underline{g}_j, \\eta_j, \\overline{m}_j$. However, the 'gap' regions $\\bS_j$ (where density propagation is assumed) are indexed $j=0,\\ldots,L$. The proof (Sec 6.3, Eq. 6.12) states that solutions starting in $\\bS_j$ converge towards a ball centered at $\\bB_j$. This makes $\\bB_0$ undefined, as there is no $\\sigma_0$. Similarly, the final aggregated gain $\\omega(\\cdot)$ in the proof conclusion (p.14) uses $\\underline{g}_0, \\eta_0, \\overline{m}_0$, which are also not defined by $\\sigma_j$ for $j \\ge 1$. This creates a significant gap in the argument, especially for the behavior of trajectories in the region $\\bS_0$ (typically near the origin) when it is non-empty (i.e., when the first small-gain region $\\sigma_1$ does not start from the origin)."
      },
      {
        "Problem": "Unconventional and potentially overly restrictive bounds in Assumption 3.1.iv",
        "Location": "Assumption 3.1.iv, page 5",
        "Explanation": "Assumption 3.1.iv imposes bounds on the derivative of the inverse D-path components: $\\underline{m} < c \\leq (\\sigma_i^{-1})'(r) \\leq C < \\overline{m}$ for $r \\in \\bK \\subset (\\underline{m}, \\overline{m})$. \n1. Comparing derivative bounds $c, C$ with Lyapunov function values $\\underline{m} = \\max \\underline{M}_i$ and $\\overline{m} = \\min \\overline{M}_i$ in this manner (e.g., $c > \\underline{m}$ and $C < \\overline{m}$) is highly unconventional. Standard conditions typically involve bounds like $0 < c_{bound} \\leq (\\sigma_i^{-1})'(r) \\leq C_{bound}$.\n2. If taken literally, these bounds impose severe restrictions. For instance, the condition $C < \\overline{m}$ applied to the example in Section 5 (where $(\\sigma_{0,i}^{-1})'(s) = b_0/M_{0,i}$) implies $b_0/M_{0,i} < \\overline{m}_0$. If $M_{0,i}$ are components of $M_0$ and $M_{0,i} = \\overline{m}_0 = \\min_k \\overline{M}_{0,k}$ (e.g., $M_0$ has identical components), this means $b_0 < (\\overline{m}_0)^2$. This contradicts the claim in Section 5 that $b_0$ can be 'any positive value'. A similar issue arises for $a_\\infty$ with the $\\underline{m} < c$ part of the condition. This makes the assumption potentially too restrictive for general D-paths or inconsistent with its application in the paper, thereby affecting the foundation of Proposition 4.1."
      },
      {
        "Problem": "Misapplication of Assumption 3.1.iv in the proof of Proposition 4.1",
        "Location": "Section 6.1 (Proof of Proposition 4.1), page 11, paragraph after Eq. 6.6",
        "Explanation": "Assumption 3.1.iv specifies that the derivative $(\\sigma_i^{-1})'(r)$ has certain bounds when its argument $r$ (which corresponds to $V_i(x_i)$) is in a compact set $\\bK \\subset (\\underline{m}, \\overline{m})$. Thus, $\\bK$ must be a compact set of Lyapunov function values. However, the proof of Proposition 4.1 defines $\\bK$ as $\\left\\{x_i\\in\\R^{N_i}:\\underline{m}+\\frac{\\overline{m}-\\delta}{2}\\leq |x_i|\\leq\\overline{m}+\\frac{\\underline{m}-\\delta}{2}\\right\\}$. This defines $\\bK$ as a compact set of states $x_i$, not Lyapunov function values $V_i(x_i)$. Using a compact set of $x_i$ values does not guarantee that $V_i(x_i)$ falls into the required type of compact set of Lyapunov values for Assumption 3.1.iv to be applicable, unless specific strong conditions are placed on $V_i$ (e.g., $V_i(x_i) = |x_i|$ and the sandwich bounds $\\underline{\\alpha}_i, \\overline{\\alpha}_i$ are identities). This represents a flaw in applying the assumption within a key proof."
      }
    ],
    "token_usage": {
      "input": 31086,
      "thinking": 15605,
      "output": 1227
    }
  },
  {
    "entry_id": 48,
    "retraction_id": "1310.8403v3",
    "paper_id": "1310.8403v2",
    "retraction_comment": "This paper has been withdrawn as a bug has been discovered in the proof of Claim 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed assumption about local effects of point perturbation in Claim 1.",
        "Location": "Page 4, Proof of Claim 1, first sentence of the proof.",
        "Explanation": "The proof of Claim 1 states: 'As $V(p_{1})$ is empty, $p_{i}$ cannot be on the boundary of any other rectangle except for the rectangles anchored at $p_{1}$ and $p_{i}$.' This assertion is critical for the argument that moving $p_i$ only affects $R_i$ and the definition of $V(p_1)$. However, $V(p_1)$ being an empty rectangle (no points of $P_n$ in its interior) does not preclude $p_i$ (a point on the boundary of $V(p_1)$) from being on the boundary of another rectangle $R_k$ (where $k \ne 1, i$). If $p_i$ is part of the boundary of $R_k$, moving $p_i$ to $p_i'$ could alter $R_k$'s dimensions or validity. This interconnectedness is not addressed, potentially invalidating the comparison of sums of areas in the rest of Claim 1's proof."
      },
      {
        "Problem": "Unjustified assumption that $R_1$ (rectangle at $p_1$) is invariant under perturbation in Claim 1.",
        "Location": "Page 4, Proof of Claim 1, sentence starting 'Now as $\\mathcal{R}(Q_n)$ and $\\mathcal{R}(P_n)$ both contain $R_{1}$...'",
        "Explanation": "The proof of Claim 1 assumes that the optimal rectangle $R_1$ anchored at $p_1$ in the packing $\\mathcal{R}(P_n)$ is the same rectangle chosen for $p_1$ in the optimal packing $\\mathcal{R}(Q_n)$ after point $p_i$ is moved to $p_i'$. The change from point set $P_n$ to $Q_n$ means that the optimal choice of a rectangle for $p_1$ could change. The proof states 'in $\\mathcal{R}(Q_{n})$ we will choose $R_{1}$ instead of $V(p_{1})$', implying $R_1$ from $\\mathcal{R}(P_n)$ is carried over, which is not necessarily true for $\\mathcal{R}(Q_n)$ being the new optimal packing."
      },
      {
        "Problem": "Lemma 3 and Claim 2 inherit flaws from Claim 1.",
        "Location": "Page 5, Proof of Claim 2 and Lemma 3.",
        "Explanation": "The proof of Claim 2, which is essential for Lemma 3, is stated to follow 'from the proof technique of Claim 1.' Consequently, Claim 2 inherits the potential flaws of Claim 1 (identified in Problems 1 and 2). If Claim 1 is unsound, then Claim 2 and Lemma 3 are also unsupported. The argument becomes more complex when two points ($p_i, p_j$) are perturbed simultaneously, making it even more susceptible to the unaddressed interdependencies between rectangles."
      },
      {
        "Problem": "Inconsistent premises for perturbation argument in Lemma 3.",
        "Location": "Page 5, Setup for Claim 2 within the proof of Lemma 3.",
        "Explanation": "Lemma 3 aims to prove properties for a MIN-MAX point set $\\mathcal{P}_n$. By Lemma 2, for $\\mathcal{P}_n$, it should hold that $\\mathcal{A}^{\\mathcal{P}_n}(R_1) = \\mathcal{A}^{\\mathcal{P}_n}(V(p_1)) = \\mathcal{A}^{\\mathcal{P}_n}(H(p_1))$. However, the setup for Claim 2, used in Lemma 3's proof, states: 'let $\\mathcal{A}^{P_n}(R_1) - \\mathcal{A}^{P_n}(V(p_1)) = \\epsilon_1 > 0$ and $\\mathcal{A}^{P_n}(R_1) - \\mathcal{A}^{P_n}(H(p_1)) = \\epsilon_2 > 0$.' If $P_n$ is the MIN-MAX set $\\mathcal{P}_n$, then $\\epsilon_1$ and $\\epsilon_2$ must be zero. This inconsistency in the premise for the perturbation argument makes the logic of Lemma 3 difficult to follow and potentially unsound, as it seems to rely on these epsilons being positive, which would contradict Lemma 2 for a MIN-MAX set."
      }
    ],
    "token_usage": {
      "input": 9355,
      "thinking": 21579,
      "output": 1039
    }
  },
  {
    "entry_id": 49,
    "retraction_id": "2003.05237v3",
    "paper_id": "2003.05237v2",
    "retraction_comment": "There is an issue in the proof of Lemma 3.7: evaluation of the involved classes gives back the same values for the coinvariants and not necessarily for the coefficients themselves. At the moment I do not see how to fix it. The lemma is needed in the proof of the main Theorem",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 29203,
      "thinking": 13767,
      "output": 1
    }
  },
  {
    "entry_id": 50,
    "retraction_id": "2203.03600v2",
    "paper_id": "2203.03600v1",
    "retraction_comment": "The main technical result, Lemma 4, has a major error in the proof: The claim in the proof \"... we could decompose $y^i$, and therefore $y$ into at least two sign-compatible, non-zero cycles of $\\mc A$ ...\" is NOT true. This claim is based on our claim in Lemma 3 that the decomposition of cycles $y^i$ into bricks $y^{i^j}$ yields cycles $y^{i^j}$ of the N-fold matrix $\\mc A$. This is not true",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Invalid proof of Lemma 3 leading to an unsupported main theorem.",
        "Location": "Proof of Lemma 3, pp. 7-8 (Section 4)",
        "Explanation": "The proof of Lemma 3 aims to bound $||y^i||_1$ by bounding the number of terms $N$ in the sum $R_i y^i = \\sum v_k = 0$. The bound on $N$ (p. 8, line 5) relies on the argument that if $N$ were larger than $(2|P_i| \\Delta L_B + 1)^{|P_i|}$, then $y$ (a Graver basis element of $\\mathcal{A}$) would be decomposable into sign-compatible cycles of $\\mathcal{A}$. This decomposition (e.g., $y^i = z_1 + z_2$, leading to a decomposition of $y$) requires $z_1$ and $z_2$ to be cycles of $\\mathcal{A}$. $z_1$ (and $z_2$) is constructed as a sum of $y^{i(j)}_{k_j}$ terms. According to Lemma 2 (p. 7), $y^{i(j)}_{k_j}$ are formed by taking Graver basis elements of $B^{(j)}$ (denoted $y^{(j)}_{k_j}$, satisfying $B^{(j)}y^{(j)}_{k_j}=0$) and setting entries to zero if they correspond to columns outside $\\supp(R_i)$ (the support of the $i$-th part of the $A$-matrix partition). This masking operation means that $B^{(j)}y^{i(j)}_{k_j}$ is generally not zero. Consequently, $B_{diag} z_1 = (B^{(1)}(z_1)_1, \\dots, B^{(n)}(z_1)_n)^T$ will generally not be zero, meaning $z_1$ is not a cycle of $\\mathcal{A}$. Thus, the contradiction argument that $y$ is decomposable fails. This invalidates the bound on $N$, the subsequent bound on $||y^i||_1$ in Lemma 3, which in turn invalidates Theorem 1 and its applications."
      },
      {
        "Problem": "Ambiguous and contradictory definition of 'column-independent partition'.",
        "Location": "Page 2 ('Our contributions') vs. Page 5 (Section 3)",
        "Explanation": "The paper presents two different definitions for the partitioning scheme. On page 2, it states: 'Two rows are in the same partition class if they share at least one entry with a non-zero element.' This implies a standard connected components definition based on shared column supports. However, the formal definition in Section 3 (p. 5) states: 'a partition $\\mathcal{P}_M$ of $R_M$ into non-empty sets of rows, such that the following holds for all elements $P_1, P_2$ of $\\mathcal{P}_M$: for all $r_1 \\in P_1, r_2 \\in P_2$, their supports $\\supp(r_1)$ and $\\supp(r_2)$ are disjoint.' If $P_1=P_2$, this definition implies that any two distinct rows within the same partition class must have disjoint supports. These two definitions are contradictory. For example, for $A=I_d$ (identity matrix), the page 2 definition yields $p_A=1, S_A=d$ (which is used in corollaries), while the Section 3 definition would allow $P_1 = \\{r_1, \\dots, r_d\\}$ so $p_A=d, S_A=1$. The choice of definition critically affects the parameters $p_A$ and $S_A$ and thus the claimed improvements."
      },
      {
        "Problem": "Incorrect runtime derivation for Minimum Sum Coloring in Corollary 4.",
        "Location": "Corollary 4, p. 13 and Table 1",
        "Explanation": "Even if Theorem 1 were correct, the claimed runtime $k^{\\bigO(k^3)} |V(G)| \\log^3(|V(G)|)$ for Minimum Sum Coloring appears to be a miscalculation based on the parameters provided. The parameters are $r=k, s=k^2, t=k, \\Delta=1, n=|V(G)|$. For $A^{(i)}$ being identity matrices, $S_A=k, p_A=1$. For the $B$ matrices, $p_B=k^2$. Plugging these into the runtime formula of Theorem 1, $nt \\log(nt) L (S_A)^{\\bigO(r+s)} (p_A p_B \\Delta)^{\\bigO(r p_A p_B + s p_A p_B)}$, the dominant parameter-dependent part is $(S_A)^{\\bigO(r+s)} (p_A p_B \\Delta)^{\\bigO(r p_A p_B + s p_A p_B)} = k^{\\bigO(k+k^2)} (1 \\cdot k^2 \\cdot 1)^{\\bigO(k \\cdot 1 \\cdot k^2 + k^2 \\cdot 1 \\cdot k^2)} = k^{\\bigO(k^2)} (k^2)^{\\bigO(k^3 + k^4)} = k^{\\bigO(k^2)} k^{\\bigO(k^4)} = k^{\\bigO(k^4)}$. The claimed $k^{\\bigO(k^3)}$ dependency is not justified by Theorem 1 with the stated parameters."
      }
    ],
    "token_usage": {
      "input": 20737,
      "thinking": 21412,
      "output": 1292
    }
  },
  {
    "entry_id": 51,
    "retraction_id": "2001.10983v3",
    "paper_id": "2001.10983v2",
    "retraction_comment": "A case in the proof of Proposition 2.8 was overlooked (thanks to [REDACTED-NAME] for pointing out this) and I withdraw the paper until that gap is filled",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of the set of 27 lines on a cubic surface.",
        "Location": "Section 1.1, Equation (1.2)",
        "Explanation": "Equation (1.2) defines the lines $b_{ij}$ as $e_0-e_i-e_j$ with $1<i\\leq j<6$. This indexing is incorrect. If $i=j$, $\\langle b_{ii}, b_{ii} \\rangle = \\langle e_0-2e_i, e_0-2e_i \\rangle = 1 - 4(-1) = 5 \\neq -1$, so $i$ cannot be equal to $j$. If $i < j$, the condition $1<i<j<6$ yields only 6 lines ($b_{23}, b_{24}, b_{25}, b_{34}, b_{35}, b_{45}$). This means the total number of lines defined ($a_i, b_{ij}, c_i$) would be $6+6+6=18$, not 27. The standard indexing for $b_{ij}$ is $1 \\leq i < j \\leq 6$, which gives $\\binom{6}{2}=15$ lines. This error makes the set $L_6$ ill-defined. Proposition 1.5, which states that ${\\rm Aut}({\\rm I}_{1,6},h) \\to {\\rm Aut}(L_6)$ is an isomorphism, relies on $L_6$ being the full set of 27 lines and that these lines span ${\\rm I}_{1,6}$. An incorrect $L_6$ (with fewer lines) might not span ${\\rm I}_{1,6}$, invalidating the proof of Prop 1.5. Since Prop 1.5 is used in Section 1.3 (first paragraph) to link the monodromy action on cohomology to the monodromy action on lines, this error is critical for the argument that the monodromy group of lines is $W(E_6)$."
      },
      {
        "Problem": "The proof of Proposition 1.6 is flawed.",
        "Location": "Section 1.1, Proof of Proposition 1.6",
        "Explanation": "Proposition 1.6 claims that any automorphism $\\sigma$ of the 27 lines (preserving intersections) has an invariant set of 6 disjoint lines. The proof argues that one only needs to check this for simple reflections $s_{\\alpha_i}$ because $W(E_6)$ is generated by them and acts transitively on roots (so all reflections are conjugate). While $s_{\\alpha_2}$ is shown to preserve $\\{e_1, ..., e_6\\}$, this does not imply that any product of such reflections (an arbitrary element of $W(E_6)$) must also preserve some set of 6 disjoint lines. The argument only shows that every reflection $s_\\alpha$ has an invariant set of 6 disjoint lines, not that any arbitrary element of $W(E_6)$ does. However, this proposition is used to support a known result about the monodromy of the universal family of cubic surfaces $\\mathcal{Y}_V/V$, and the author states that this specific approach is not used for the paper's main result concerning $\\mathcal{X}_U/U$ (Theorem in the introduction and Section 1.3). Therefore, this flaw might not be critical to the paper's main new contributions but makes the argument for the known result incomplete."
      },
      {
        "Problem": "The proof of Proposition 1.12, while the proposition itself is a standard result, is potentially flawed or unclear.",
        "Location": "Section 1.3, Proof of Proposition 1.12 and Lemma 1.14",
        "Explanation": "Proposition 1.12 states that reflections associated with a set of roots $\\{v_i\\}$ that spans the root lattice $\\Lambda$ generate the full Weyl group $W(R)$. This is a standard result in Lie theory (e.g., if $S$ is a set of roots generating $\\Lambda_R$ and $S=-S$, then $W(R)$ is generated by $\\{s_\\alpha \\mid \\alpha \\in S\\}$). The proof provided via Lemma 1.14 (existence of a 'good sequence') is non-standard. In the proof of Lemma 1.14, the argument that $u_0-v$ has length at most $n-1$ (where $n$ is the minimal length of $u_0$) requires $v$ (a root in $R_{>0} \\cap \\{\\pm v_i\\}$) to be one of the specific $v^{(j)}$ in the minimal sum representation $u_0 = \\sum v^{(j)}$. This is not explicitly justified. While the proposition itself is correct and its application is likely valid, the provided proof is sketchy and may contain gaps. A clearer approach would be to cite the standard result directly."
      },
      {
        "Problem": "Misstatement of the Lefschetz Hyperplane Theorem for $H^2$.",
        "Location": "Section 1.3, paragraph 3 (step ii)",
        "Explanation": "The text states: 'Note that the Lefschetz hyperplane theorem says this $j^*$ here is an isomorphism'. Here $j^*: H^2(X, \\mathbb{Z}) \\to H^2(X_0, \\mathbb{Z})$, where $X$ is a cubic threefold and $X_0$ is a smooth hyperplane section (a cubic surface). This map $j^*$ is an injection, not an isomorphism, as $H^2(X, \\mathbb{Z}) \\cong \\mathbb{Z}$ while $H^2(X_0, \\mathbb{Z}) \\cong \\mathbb{Z}^7$. While this specific statement is incorrect, the crucial consequence derived, 'the primitive cohomology $\\text{Ker}([X_0]|_{X_0}\\cup)$ equals the vanishing cohomology $\\text{Ker}(j_*)$' (referring to $j_*: H_2(X_0) \\to H_2(X)$ or its dual $j_*: H^2(X_0) \\to H^4(X)$), is a standard result in Lefschetz theory. The argument given for this equality, $[X_0]|_{X_0} \\cup \\alpha = j^* \\circ j_* \\alpha$, involves $j^*: H^4(X, \\mathbb{Z}) \\to H^4(X_0, \\mathbb{Z})$, which is indeed an isomorphism (degree map). So the error might be a localized misstatement rather than one that invalidates the deduction about primitive and vanishing cohomology if the correct $j^*$ is implicitly used for the deduction."
      }
    ],
    "token_usage": {
      "input": 20181,
      "thinking": 21493,
      "output": 1521
    }
  },
  {
    "entry_id": 52,
    "retraction_id": "2307.05226v3",
    "paper_id": "2307.05226v2",
    "retraction_comment": "The paper has been withdrawn because of the basic mistake: the map $f$ has in general rank q, not p < q (Section 3)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect inclusion of modules of differential forms",
        "Location": "Section 5, page 8, the last displayed formula before Lemma 5.1, and the line preceding it.",
        "Explanation": "The paper claims that $y_{s}^{N} \\cdot \tau_{J} \\in \\sum_{i=1}^{q} \\, (df_{i} \\circ \\phi) \\wedge \\Omega^{n-p-1}$ which is then asserted to be a subset of $\\sum_{j=1}^{n} \\phi_{j} \\cdot \\Omega^{n-p}$. This inclusion $\\sum_{i=1}^{q} \\, (df_{i} \\circ \\phi) \\wedge \\Omega^{n-p-1} \\subset \\sum_{j=1}^{n} \\phi_{j} \\cdot \\Omega^{n-p}$ is critical for the final contradiction. However, this inclusion does not hold in general. For example, if $f_i = x_i$ (so $X$ is the origin, $df_i = dx_i$) and $\\phi_j = y_j$ (identity map), then $df_i \\circ \\phi = dy_i$. The inclusion would imply that $dy_i \\wedge \\alpha \\in (y_1, \\ldots, y_n)\\Omega^{n-p}_y$ for $\\alpha \\in \\Omega^{n-p-1}_y$. Taking $p=1, n-p-1=0$, this means $dy_i \\in (y_1, \\ldots, y_n)\\Omega^1_y$. This is false, as $dy_i$ is a generator of the $\\mathcal{O}_y$-module $\\Omega^1_y$ and is not in the submodule $\\mathfrak{m}_y \\Omega^1_y$. This invalidates the concluding steps of the proof of Proposition 4.2 and thus the main theorem."
      },
      {
        "Problem": "Flawed argument for the vanishing of $H^1(U \\setminus \\mathrm{Sing}(\\mathcal{F}_X), \\mathcal{O}^*)$",
        "Location": "Section 3, proof of Proposition 3.1, page 5.",
        "Explanation": "The proof of Proposition 3.1, which asserts the existence of a global $p$-form $\\omega_X$, relies on $H^1(U \\setminus \\mathrm{Sing}(\\mathcal{F}_X), \\mathcal{O}^*) = 0$. The argument provided uses the exact sequence $ \\dots \to H^1(U \\setminus S, \\mathcal{O}) \to H^1(U \\setminus S, \\mathcal{O}^*) \to H^2(U \\setminus S, \\mathbb{Z}) \to \\dots $ (where $S = \\mathrm{Sing}(\\mathcal{F}_X)$). It is claimed that $H^1(U \\setminus S, \\mathcal{O}) = 0$ and $H^2(U \\setminus S, \\mathbb{Z}) = 0$. According to Theorem 1.2 (Riemann-Hartogs), $H^q(M \\setminus Z, \\mathcal{S}) \\cong H^q(M, \\mathcal{S})$ if $q \\le \\mathrm{codim}(Z) - 2$. For $H^1(U \\setminus S, \\mathcal{O}) \\cong H^1(U, \\mathcal{O}) (=0 \text{ as } U \text{ is Stein})$, we need $1 \\le \\mathrm{codim}(S) - 2$, so $\\mathrm{codim}(S) \\ge 3$. For $H^2(U \\setminus S, \\mathbb{Z}) \\cong H^2(U, \\mathbb{Z}) (=0 \text{ as } U \text{ is a polydisc/Stein})$, we need $2 \\le \\mathrm{codim}(S) - 2$, so $\\mathrm{codim}(S) \\ge 4$. The paper argues that $\\mathrm{codim}(S) \\ge 3$. This is sufficient for $H^1(U \\setminus S, \\mathcal{O})=0$, but not for $H^2(U \\setminus S, \\mathbb{Z})=0$. Thus, the presented proof for $H^1(U \\setminus S, \\mathcal{O}^*)=0$ is incomplete or incorrect under the claimed $\\mathrm{codim}(S) \\ge 3$. While $H^1(U \\setminus S, \\mathcal{O}^*)=0$ might hold if $\\mathrm{codim}(S) \\ge 2$ by other standard results, the proof path chosen in the paper is flawed."
      },
      {
        "Problem": "Incorrect justification for the codimension of $\\mathrm{Sing}(\\mathcal{F}_X)$ and $\\mathrm{Sing}(X)$",
        "Location": "Section 3, page 4, paragraph starting 'Now consider the irreducible germ...'",
        "Explanation": "The paper claims that because $Y=\\phi^{-1}(X)$ is smooth, $X$ is normal (citing Lebl [L]), and then states 'thus its singular locus $\\mathrm{Sing}\\,(X)$ is at least of codimension $p+2$'. Normality of $X$ (an $(n-p)$-dimensional variety) implies that $\\mathrm{codim}_X \\mathrm{Sing}(X) \\ge 2$, which means $\\mathrm{codim}_{\\mathbb{C}^n} \\mathrm{Sing}(X) \\ge p+2$. This deduction is correct. However, this is then used to argue that $\\mathrm{codim}_{\\mathbb{C}^n} \\mathrm{Sing}(\\mathcal{F}_X) \\ge 3$. The argument is: 'In this case, it follows as before from equality (3.1) that the singular locus $\\mathrm{Sing}\\, (\\mathcal{F}_{X})$ ... is at least of codimension $3$'. Equation (3.1) is $\\dim g(\\mathrm{Sing}\\, (\\mathcal{G})) \\leq p-1$, where $g$ and $\\mathcal{G}$ are not defined in this context. The preceding argument for $\\mathrm{codim} \\, \\mathrm{Sing}\\, (\\mathcal{F}_{X}) \\geq 2$ also refers to this undefined $g(\\mathrm{Sing}\\, (\\mathcal{G}))$. The link between $\\mathrm{codim} \\, \\mathrm{Sing}(X)$ and $\\mathrm{codim} \\, \\mathrm{Sing}(\\mathcal{F}_X)$ is not clearly established, and the reliance on an undefined setup makes the argument for $\\mathrm{codim} \\, \\mathrm{Sing}(\\mathcal{F}_X) \\ge 3$ unsound. This codimension estimate is crucial for the subsequent application of cohomology extension theorems as argued in the paper."
      },
      {
        "Problem": "Fundamental notational inconsistency in the proof of the special case",
        "Location": "Section 1, page 2, paragraph 'Proof of the case where Y not subset of Z'",
        "Explanation": "The proof for the special case $Y \not\\subset Z$ states: 'The map $\\phi: (\\mathbb{C}^{n}_{y},0) \to (\\mathbb{C}^{n}_{x},0), \\ x=(x_1,\\ldots,x_n), \\ y=(y_1,\\ldots,y_n)$ induces a finite local ring homomorphism $\\phi^{*}: A := \\mathbb{C}\\{ y \\} \to B := \\mathbb{C}\\{ x \\}$.' Standardly, if $\\phi$ maps $y$-coordinates to $x$-coordinates, the pullback $\\phi^*$ maps functions of $x$ to functions of $y$. Thus, it should be $\\phi^{*}: \\mathbb{C}\\{ x \\} \to \\mathbb{C}\\{ y \\}$. The paper's formulation $A := \\mathbb{C}\\{ y \\}$ and $B := \\mathbb{C}\\{ x \\}$ means $\\phi^*$ maps functions on the source space $\\mathbb{C}^n_y$ to functions on the target space $\\mathbb{C}^n_x$. This is contrary to the definition of a pullback homomorphism and makes the subsequent algebraic arguments difficult to follow or verify. While this is for a special case, such a basic notational error raises concerns."
      }
    ],
    "token_usage": {
      "input": 13850,
      "thinking": 19180,
      "output": 1837
    }
  },
  {
    "entry_id": 53,
    "retraction_id": "1702.07688v4",
    "paper_id": "1702.07688v3",
    "retraction_comment": "I no longer believe that the conclusions are supported by the calculations done in this manuscript. The paper tried to determine what will limit the precision in practice. I incorrectly pointed to small 1 qubit (precision) errors happening everywhere in the circuits",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Justification, Interpretation, and Mapping of the 'Measurement Direction Error' Model",
        "Location": "Page 2, Eq. 3; Page 3, Eq. 5 and its description; Page 3, statement about equivalence of Eq. 5 to rotations on all physical qubits.",
        "Explanation": "The paper's central argument hinges on modeling 'error in measurement direction' (conceptualized in Eq. 3 for a single qubit measurement) as a specific error in the CNOT gate's control operation (Eq. 5). In this model, the control axis $\\vec{m}_\\epsilon$ is assumed to be independently random for each CNOT instance. This specific mapping and the assumption of rapid, independent gate-to-gate randomness for $\\vec{m}_\\epsilon$ are critical: 1. The translation from a general concept of 'measurement direction error' to this particular CNOT gate error (rather than, e.g., an error in the final ancilla readout) needs stronger justification. 2. The assumption of independent randomness for each CNOT implies extremely fast fluctuations of control parameters. Slower (e.g., quasi-static) fluctuations might lead to different error characteristics (like a coherent rotation of the code space) with potentially different QEC outcomes. The paper does not sufficiently argue why this specific fast-fluctuation model is the definitive one that universally invalidates QEC. 3. The claim on page 3 that the CNOT error of Eq. 5 'is equivalaent to applying a small one qubit rotation before and after an exact CNOT gate on all the physical qubits (except the ancilla)' is imprecise; Eq. 5 describes an error localized to the control qubit of that specific CNOT ($U CNOT U^\\dagger$ form where $U$ acts on control qubit), not rotations on 'all' data qubits."
      },
      {
        "Problem": "Mechanism of error accumulation and the role of 'intermediate rotations' in the analytical example",
        "Location": "Supplementary Material, 'A pedestrian approach to the 3 qubit repetition code', specifically the transition from state $|\\Psi_2\\rangle$ to $|\\Psi_3\\rangle$ and the related explanatory comment.",
        "Explanation": "The analytical derivation for the 3-qubit code in the Supplementary Material introduces 'another round of small rotations error' (transforming $|\\Psi_2\\rangle$ to $|\\Psi_3\\rangle$) between the measurements of the two stabilizers. The paper states this step is crucial for obtaining the linear error scaling ($E_0 \\propto p_\\epsilon$). However, the physical origin and direct, rigorous derivation of this 'intermediate rotation' step as an inevitable consequence of the primary $\\vec{m}_\\epsilon$ error (from Eq. 5 in CNOTs) is not made sufficiently clear. If the $\\vec{m}_\\epsilon$ error in CNOTs is the sole source of $p_\\epsilon$, its effects should be encapsulated within the superoperator describing the stabilizer measurement itself. By modeling it as a separate, intervening error process, it's harder to assess whether the resulting linear error accumulation is a fundamental consequence of imperfect measurement direction (as modeled by Eq. 5) or an artifact of the specific sequence of operations and errors assumed in this illustrative derivation. The magnitude and precise nature of these 'intermediate rotations' and their direct relationship to $p_\\epsilon$ from Eq. 5 need clearer justification."
      },
      {
        "Problem": "Potentially incomplete dismissal of standard Fault Tolerance mechanisms",
        "Location": "Page 3, discussion of Fig. 1b (fault-tolerant stabilizer measurement).",
        "Explanation": "The paper asserts that fault-tolerant (FT) circuits, like the one in Fig. 1b, 'do not help here: they only help to correct errors on the ancillas'. This may be an oversimplification or incomplete assessment of FT capabilities. FT protocols are designed to prevent a single fault—occurring during a gate, measurement, or on an ancilla/data qubit—from propagating to cause uncorrectable logical errors. The error model in Eq. 5, if interpreted as a fault within CNOT gates, is a type of coherent gate error. Standard FT analysis often demonstrates that such gate errors, even coherent ones, can be managed, typically by ensuring they don't propagate catastrophically or by converting them into effectively Pauli errors at a higher order of precision. The paper does not provide a detailed analysis of why the specific error from Eq. 5 (randomly oriented CNOT control) would uniquely bypass all relevant aspects of FT design, particularly those concerning the mitigation of gate error propagation. A more thorough engagement with how FT protocols handle coherent gate errors with similar characteristics is needed."
      },
      {
        "Problem": "Consequences of non-commuting effective stabilizers and the measurement process",
        "Location": "Page 3, right column, statement: 'With finite precision, the stabilizers $\\tilde g_i$ are not perfectly known and do not commute perfectly with each other...'",
        "Explanation": "A key claim is that the effectively measured stabilizers, $\\tilde{g}_i$ (resulting from CNOTs with Eq. 5 errors), do not commute. This is plausible if $\\vec{m}_\\epsilon$ is independently random for each CNOT involved in constructing each $\\tilde{g}_i$. However, the implications of measuring such non-commuting operators sequentially are profound and may not be fully captured by the resulting linear error scaling. If the $\\tilde{g}_i$ truly do not commute, there is no shared eigenbasis, and the standard QEC concept of projecting into a well-defined syndrome subspace becomes problematic. The paper needs to clarify: 1. How the syndrome is extracted and interpreted if the underlying measured observables $\\tilde{g}_i$ do not commute (e.g., does the measurement order matter? What state is the system projected into?). 2. How this non-commutation directly leads to the observed linear scaling of error $E_0 \\propto p_\\epsilon$ in a way that fundamentally prevents QEC from improving fidelity. The argument that non-commuting $\\tilde{g}_i$ undermine the code structure is powerful, but its precise impact on the error correction outcome and fidelity requires a more detailed exposition beyond the assertion of a resulting linear error."
      }
    ],
    "token_usage": {
      "input": 8148,
      "thinking": 10887,
      "output": 1373
    }
  },
  {
    "entry_id": 54,
    "retraction_id": "1408.2493v2",
    "paper_id": "1408.2493v1",
    "retraction_comment": "This paper has been withdrawn by the author. The proof of Theorem 6.2 is incorrect and the Theorem probably fails to be true",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous definition of subsequence notation $\\alpha^n(m)$",
        "Location": "Page 4, Section 2.2, last paragraph before subsection 2.3",
        "Explanation": "The definition of the $m$-th term of the $n$-th subsequence $\\alpha^n$ of $\\alpha$ is given as $\\alpha^n(m) := \\alpha(\\langle n \\rangle \\ast m)$. The concatenation operator $\\ast$ is defined for two finite sequence codes. If $m$ is a natural number (intended as an index for the subsequence $\\alpha^n$), then $m$ is not a sequence code, so $\\langle n \\rangle \\ast m$ is not well-defined by the provided definition of $\\ast$. If $m$ is meant to be the sequence code $\\langle m \\rangle$, it should be written as $\\alpha(\\langle n \\rangle \\ast \\langle m \\rangle) = \\alpha(\\langle n,m \\rangle)$. If $m$ itself is a sequence code, then $\\alpha^n$ would be a function from sequence codes to $\\mathbb{N}$, not a sequence $\\mathbb{N} \\to \\mathbb{N}$ as implied by the term 'subsequence'. Given that function variables like $\\alpha$ are defined to take a single natural number (which can be a code for a pair, e.g., $\\alpha(J(x,y))$), this notation is inconsistent or insufficiently explained. This ambiguity can affect the interpretation and verification of proofs that use this subsequence notation, for instance, in Section 5.2 where $\\gamma^n \\in \\mathcal{R}$ implies $\\gamma^n$ is a sequence $\\mathbb{N} \\to \\mathbb{S}$ and $\\gamma^n(k)$ is its $k$-th term."
      },
      {
        "Problem": "Undefined comparison $s \\le a$ in the proof of Theorem 3.3",
        "Location": "Page 8, Proof of Theorem 3.3, (i) $\\Rightarrow$ (ii), definition of $\\beta(a)$",
        "Explanation": "In the proof that FT' implies HB, a function $\\beta$ on $\\mathit{Bin}$ is defined: '$\\beta(a) = 1$ if and only if there exists $s$ in $\\mathbb{S}$ such that $s \\le a$ and $B(a) \\sqsubset_{\\mathbb{S}} s$ and $\\alpha(s) = 1$'. Here, $s$ is a (code for a) rational segment and $a$ is a (code for a) finite binary sequence. The relation $s \\le a$ between these two distinct types of objects (a rational segment code and a binary sequence code) is not defined in Section 2.2 or elsewhere in the paper. If it's a numerical comparison of their Gödel numbers, its mathematical relevance is obscure. If it's a typo for a different condition (e.g., $s$ being in a finite initial part of $D_\\alpha$, or $s$ being numerically less than some bound related to $a$), this needs clarification. Without a clear definition of $s \\le a$, the definition of $\\beta(a)$ is ambiguous, making the subsequent argument that $D_\\beta$ is a bar, and the remainder of the proof, difficult to verify."
      },
      {
        "Problem": "Flawed proof of Dickson's Lemma (Lemma 11.1(i))",
        "Location": "Page 24, Section 11, Proof of Lemma 11.1(i)",
        "Explanation": "The proof of Dickson's Lemma (Lemma 11.1(i)) by induction on $k$ contains an error in the base case $k=1$. The paper states: 'Note: $\\forall \\zeta[\\forall n[\\zeta(n) \\in \\omega^1]\\rightarrow \\exists i\\le\\bigl(\\zeta(0)\\bigr)(0)[\\zeta(i) \\le^1\\zeta(i+1)]]$. This settles the case $k=1$'. This statement is false and does not correctly represent Dickson's Lemma for $k=1$. Dickson's Lemma for $k=1$ asserts that for any infinite sequence of natural numbers $(x_n)_{n \\in \\mathbb{N}}$ (where $x_n = (\\zeta(n))(0)$), there exist $i<j$ such that $x_i \\le x_j$. The provided statement, however, only considers consecutive elements $x_i, x_{i+1}$ and incorrectly bounds the search for $i$ by $x_0$. A simple counterexample is the sequence $N, N-1, \\dots, 1, 0, \\dots$, where $x_i > x_{i+1}$ for $i < N$. The correct proof for $k=1$ relies on the well-foundedness of $\\mathbb{N}$ with the usual order. Since Lemma 11.1(i) is used to prove Lemma 11.1(ii), which in turn is used in the proof of Theorem 11.2 (i) $\\Rightarrow$ (ii), this flawed proof of a supporting lemma is a critical issue. While Dickson's Lemma itself is true and provable in $\\mathsf{BIM}$, the specific proof presented is incorrect."
      }
    ],
    "token_usage": {
      "input": 92240,
      "thinking": 33674,
      "output": 1217
    }
  },
  {
    "entry_id": 55,
    "retraction_id": "2112.06228v2",
    "paper_id": "2112.06228v1",
    "retraction_comment": "Theorem 4.3 is missing the terms corresponding to the linear pentagon equation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified Shuffle Algebra Property for the Explicit Coefficients of New Associators",
        "Location": "Theorem 4.3, Corollary 4.4, Theorem 4.5, and their reliance on Theorem 3.5",
        "Explanation": "The main claim that $\\phi_{KZ,z}$ (defined with coefficients $\\zeta^z_{III}(W) = \\sum 1/((z+n_1)^{k_1}\\dots(rz+n_r)^{k_r})$ as in Section 4.2 and implicitly Corollary 4.4) are associators relies on Theorem 4.3. Theorem 4.3 requires the map $\\sigma^z: \\zeta(W) \\mapsto \\zeta^z_{III}(W)$ to be a shuffle algebra morphism. This property is asserted via Theorem 3.5. However, Theorem 3.5 proves this for different coefficients $\\zeta^z_{II}(W)$ obtained by specific integral substitutions ($dx/(1-x) \\to x^z dx/(1-x)$ in the integrand of MZVs). The paper does not demonstrate that these two types of coefficients, $\\zeta^z_{III}(W)$ and $\\zeta^z_{II}(W)$, are identical. Without this equality or an independent proof that $\\sigma^z_{III}$ (mapping to Type III coefficients) is a shuffle algebra morphism, the conclusion that $\\phi_{KZ,z}$ are associators is not soundly established."
      },
      {
        "Problem": "Contradictory or Incorrect Definition of the $\\star$ Operation for Power Series",
        "Location": "Section 3.2, page 7, paragraph before Proposition 3.3",
        "Explanation": "The operation $f(x)\\star g(x)$ is first defined via other poset-derived operations as $f(x)\\star g(x) := \\pchain[1]*^+\\big(f(x)*g(x)\\big)$. This evaluates to $\\frac{x}{(1-x)^2} \\frac{1-x}{x} (f(x)(1-x)g(x)) = \\frac{1}{1-x} f(x)(1-x)g(x) = f(x)g(x)$ if $f(x)*g(x)$ means $f(x)(1-x)g(x)$. However, the paper states $f(x)*g(x) :=f(x)(1-x)g(x)$, so the expression becomes $\\frac{1}{1-x} (f(x)(1-x)g(x)) = f(x)g(x)$. This seems to correctly yield the pointwise product. The issue might be subtle: the paper states 'In terms of posets, $\\mathfrak{X} \\star \\mathfrak{Y}$ is the element of $\\poset$ whose order series is given by $|\\mathfrak{X}\\star\\mathfrak{Y}|= |\\mathfrak{X}| \\cdot |\\mathfrak{Y}|$. This means that $\\star$ acts as the usual product of functions on power series'. The derivation $f(x)\\star g(x):=\\pchain[1]*^+\\big(f(x)*g(x)\\big)$ is presented as if it's a known way to get this product from other poset operations. If this derivation is flawed or relies on unstated properties from [P], the foundation of the poset construction of polylogarithms (Prop 3.3) and their truncated versions (eq. 3.3) is weakened, as these crucially use $\\star$ as pointwise product. The definition should be clarified if $f(x)g(x)$ is simply asserted or if its derivation from $*,*^+$ is robust."
      },
      {
        "Problem": "Incorrect Recovery of Standard Multiple Zeta Values for $\\zeta^0(W)$",
        "Location": "Section 3.3, definition of $\\zeta^n(W)$ before Theorem 3.5, and its relation to eq. (3.3) and Corollary 4.4",
        "Explanation": "The map $\\zeta^n(W)$ is defined using $|\\mayadigit{0}|^{*(n+1)}$ as the base for truncation, where $n+1$ is intended to be the parameter $m$ in the sum formula of eq. (3.3). If $n=0$ (which should correspond to the standard KZ associator), this implies $m=1$ for eq. (3.3). However, eq. (3.3) with $m=1$ (and $x=1$) yields sums of the form $\\sum_{1<n_1, n_1+1<n_2, \\dots} \\frac{1}{n_1^{k_1}n_2^{k_2}\\cdots n_r^{k_r}}$, not the standard Multiple Zeta Value (MZV) sums $\\sum_{0<n_1<n_2< \\dots} \\frac{1}{n_1^{k_1}n_2^{k_2}\\cdots n_r^{k_r}}$. This contradicts the claim in Corollary 4.4 that $\\phi_{KZ,0} = \\phi_{KZ}$. For $\\phi_{KZ,0}$ to correctly be $\\phi_{KZ}$, the truncation parameter $m$ in the sums of Corollary 4.4 (derived from eq. (3.3)) must be $0$ when $n=0$. This suggests an off-by-one error in linking the parameter $n$ of $\\zeta^n$ to the parameter $m$ of the poset construction in eq. (3.3); specifically, $|\\mayadigit{0}|^{*n}$ should likely be used instead of $|\\mayadigit{0}|^{*(n+1)}$ if $n$ is the direct truncation parameter."
      }
    ],
    "token_usage": {
      "input": 40366,
      "thinking": 20872,
      "output": 1318
    }
  },
  {
    "entry_id": 56,
    "retraction_id": "1311.7114v2",
    "paper_id": "1311.7114v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the derivation of equation 24 and 25",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for partitioned kinetic energy integrals over s-functions",
        "Location": "Section II.B, subsection \"Integral evaluation\", bullet point \"Kinetic energy integrals\"",
        "Explanation": "The formula provided for partitioned kinetic energy integrals, ${\\cal T}_{rs}^{(p)} = -\\frac{1}{2}\\big[ 3\\eta-2\\eta^2 (\\mathbf{R_A}-\\mathbf{R_B})^2\\big]S_{rs}^{(p)}$, is incorrect. The presence of the spatial projection operator $\\theta_p(\\mathbf{r})$ inside the integral $\\int d\\mathbf{r}\\phi_r(\\mathbf{r})\\theta_p(\\mathbf{r})(-\\frac{1}{2}\\nabla^2_\\rr) \\phi_s(\\mathbf{r})$ means the operator $(-\\frac{1}{2}\\nabla^2_\\rr)$ acts on the product $\\theta_p(\\mathbf{r}) \\phi_s(\\mathbf{r})$ (if symmetrized) or involves derivatives of $\\theta_p(\\mathbf{r})$ if integration by parts is used. The $\\theta_p(\\mathbf{r})$ operator does not generally commute with $\\nabla^2$, and its derivatives (e.g., delta functions at boundaries for a step function) are neglected. The formula incorrectly assumes the standard kinetic energy expression can be simply multiplied by the partitioned overlap $S_{rs}^{(p)}$, which would lead to inaccurate kinetic energy contributions to the partitioned energy."
      },
      {
        "Problem": "Approximation in partitioned nuclear attraction integral formula for s-functions",
        "Location": "Section II.B, subsection \"Integral evaluation\", bullet point \"Nuclear attraction integrals\"",
        "Explanation": "The formula $V_{rs}^{(p)} = 2\\left(\\frac{\\zeta}{\\pi}\\right)^{1/2}\\sum_\\alpha F_0(\\zeta(\\RR_{P}-\\RR_\\alpha)^2) S_{rs}^{(p)}$ for partitioned nuclear attraction integrals appears to be an unevaluated approximation. The standard Boys function $F_0$ and its argument are derived assuming integration over all space for the electronic coordinate. The presence of $\\theta_p(\\mathbf{r})$ restricts the integration domain, which would alter the form of the $F_0$ function or require a different analytical/numerical approach. The formula seems to approximate the potential $Z_\\alpha/|\\rr-\\RR_\\alpha |$ as being constant (evaluated at $\\mathbf{R}_P$) over the region where $\\phi_r \\phi_s \\theta_p$ is non-zero, which is not generally valid and can lead to inaccuracies."
      },
      {
        "Problem": "Approximation in partitioned two-electron integral formula for s-functions",
        "Location": "Section II.B, subsection \"Integral evaluation\", bullet point \"Two-electron integrals\"",
        "Explanation": "The formula for partitioned two-electron integrals, which evaluates to $\\frac{N(\\xi_r)N(\\xi_s)N(\\xi_t)N(\\xi_u)}{\\sqrt{\\xi_r+\\xi_s+\\xi_t+\\xi_u}} \\big[ S_{rs}^{(p)}S_{tu}^{(q)} + S_{rs}^{(q)}S_{tu}^{(p)}\\big] F_0(\\tau)$, is a Mulliken-type approximation. It effectively decouples the integral over $\\mathbf{r}_1$ and $\\mathbf{r}_2$ with the $1/|\\mathbf{r}_1-\\mathbf{r}_2|$ operator into a product of partitioned one-electron overlaps multiplied by an average repulsion factor $F_0(\\tau)$. The standard $F_0(\\tau)$ arises from integration over all space for both $\\mathbf{r}_1$ and $\\mathbf{r}_2$. The projection operators $\\theta_p(\\mathbf{r}_1)$ and $\\theta_q(\\mathbf{r}_2)$ restrict these domains, meaning this factorization and use of the standard $F_0(\\tau)$ is an approximation, not an exact reformulation, and can introduce significant errors."
      },
      {
        "Problem": "Unjustified application of standard Obara-Saika recurrence relations for partitioned integrals",
        "Location": "Section II.B, subsection \"Integral evaluation\", particularly the statement: \"Therefore, the partitioning implementation only requires changing electron integrals over $s$-functions to their partitioned counterparts.\"",
        "Explanation": "The paper implies that standard Obara-Saika (OS) recurrence relations can be directly applied using the (potentially incorrectly calculated) partitioned s-function integrals as a base to obtain integrals for higher angular momentum functions. The OS relations rely on specific derivative properties of Gaussian functions and the translational invariance of the operators, which are broken by the introduction of the fixed-in-space $\\theta_p(\\mathbf{r})$ projection operators. The recurrence relations themselves would likely need to be re-derived for partitioned integrals. Applying standard OS relations in this context is unlikely to be valid and would lead to incorrect partitioned integrals for basis sets including functions with angular momentum higher than s-type."
      }
    ],
    "token_usage": {
      "input": 10854,
      "thinking": 10821,
      "output": 1142
    }
  },
  {
    "entry_id": 57,
    "retraction_id": "1206.3652v3",
    "paper_id": "1206.3652v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in Theorem 2.6 under the metric of Grassmannian manifolds induced from the riemannian submersion",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect assumption $XX^*=O_m$ in the proof of Theorem 2.2.",
        "Location": "Page 5, proof of Theorem 2.2, 'Conversely' part, condition (2), lines starting 'Since $[\\hat{X}, \\widehat{iX}] \\in {\\mathfrak u}(n+m)$, $XX^*$ will be an element in ${\\mathfrak u}(m)$, so $O_m$.'",
        "Explanation": "The statement that $XX^*$ is $O_m$ (the zero matrix) is incorrect. While $XX^*$ is Hermitian (so $iXX^* \\in \\mathfrak{u}(m)$), $XX^*$ is generally not zero if $X^*X=\\lambda I_n$ with $\\lambda \neq 0$. For example, if $n=m$, $XX^*=\\lambda I_m$. This error leads to an incorrect simplification of the Lie bracket $[\\hat{X}, \\widehat{iX}]$ from its correct form $\\begin{pmatrix} -2i\\lambda I_n & 0 \\ 0 & 2i XX^* \\end{pmatrix}$ to $\\begin{pmatrix} -2i\\lambda I_n & 0 \\ 0 & O_m \\end{pmatrix}$. This in turn makes the subsequent calculations of $[[\\cdot,\\cdot],\\cdot]$ terms incorrect (e.g., $[[\\hat{X}, \\widehat{iX}], \\hat{X}]$ becomes $2\\lambda \\widehat{iX}$ in the paper, whereas the corrected calculation without $XX^*=O_m$ yields $4\\lambda \\widehat{iX}$)."
      },
      {
        "Problem": "Erroneous Lie algebra element $K$ and flawed $\\mathfrak{su}(2)$ structure in Theorem 2.4.",
        "Location": "Page 6, proof of Theorem 2.4(2), definition of $K$ and subsequent commutation relations.",
        "Explanation": "The element $K = \\mathrm{diag}(-\\lambda I_n, O_m)$ is not skew-Hermitian unless $\\lambda=0$ (which is disallowed as $X^*X=\\lambda I_n$ and $\\lambda \neq 0$). Therefore, $K$ is not in the Lie algebra $\\mathfrak{u}(n)$ (nor in $\\mathfrak{u}(n+m)$). Consequently, the claimed Lie algebra commutation relations, such as $[\\hat{X},\\widehat{iX}]=2K$, $[K,\\hat{X}]=2\\widehat{iX}$, and $[K,\\widehat{iX}]=-2\\hat{X}$, are not valid with this definition of $K$ and the (either corrected or uncorrected) expression for $[\\hat{X},\\widehat{iX}]$. This invalidates the asserted $\\mathfrak{su}(2)$ Lie algebra isomorphism $f: \\mathfrak{su}(1+1) \\to \\mathfrak{u}(n+m)$, which is crucial for the argument that the bundle reduces to a Hopf bundle structure."
      },
      {
        "Problem": "Unsubstantiated holonomy factor for complex submanifolds in the main theorem.",
        "Location": "Theorem 2.5 (main result), relying on Theorem 2.4(2).",
        "Explanation": "The main result (Theorem 2.5) claims that the holonomy displacement along $\\gamma$ on a complex totally geodesic surface $S$ is $V(\\gamma)=e^{\frac{1}{2} A(\\gamma) i}$. This $1/2$ factor is justified by an asserted isomorphism to the Hopf bundle $S^1 \\to S^3 \\to S^2$, as stated in Theorem 2.4(2). However, the proof of Theorem 2.4(2) is flawed due to the incorrect $\\mathfrak{su}(2)$ algebra construction (see Problem 2). Without a valid reduction to the Hopf bundle structure, the $1/2$ factor is not justified for the general $G_{n,m}$ case. A direct calculation of the curvature form $\\Omega(\\hat{X},\\widehat{iX})_{\\mathfrak{u}(n)} = 2i\\lambda I_n$ (using $X^*X=\\lambda I_n$) would suggest a holonomy factor of $2\\lambda$, not $1/2$ (assuming $\\lambda=1$ for an orthonormal basis defining the area)."
      }
    ],
    "token_usage": {
      "input": 13678,
      "thinking": 23520,
      "output": 974
    }
  },
  {
    "entry_id": 58,
    "retraction_id": "1511.00057v2",
    "paper_id": "1511.00057v1",
    "retraction_comment": "Several proofs were found to be incomplete or in error including the proof that quantum rotations can induce arbitrary noise weights. A fully corrected version of this paper is published as: A. Paris, G. Atia, A. Vosoughi, and S. Berman, \"Hidden quantum processes, quantum ion channels, and 1/f-type noise\", [REDACTED-NAME], vol. 30, num. 7, pp. 1830-1929 (2018), doi:https://doi.org/10.1162/neco_a_01067",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incomplete or flawed proof of Theorem DHAMM (thm:DHAMM)",
        "Location": "Sec 2.5 (or 2.2.5 in some enumerations, titled 'Hidden Quantum and Markov Models' in ToC, 'HAMM' in text), Proof of thm:DHAMM, specifically the step involving change of basis: 'Let $\\Op{U}$ be the change-of-basis matrix ... $\\cdots$ \\qed'",
        "Explanation": "The theorem claims that a diagonalizable Hidden Activated Measurement Model (HAMM) has a posterior distribution which is a formal Hidden Markov Model (HMM). The proof derives Markovian evolution for coefficients $a_i(t)$ of the quantum state in the eigenbasis $\\Curly{\\Ket{\\phi}_i}$ of an observable $A$. However, the conditional distribution operators $\\Op{f}(\\alpha)$ are assumed to be diagonal in a potentially different basis $\\Curly{\\Ket{\\psi}_i}$. The proof does not demonstrate that the resulting posterior probability $p(\\alpha_1, \\ldots, \\alpha_n)$ retains the HMM structure if these bases $\\Curly{\\Ket{\\phi}_i}$ and $\\Curly{\\Ket{\\psi}_i}$ are different. The transformation of Markovian probabilities $\\pi(j_1, \\ldots, j_n)$ by coefficients $|U_{k_m j_m}|^2$ (where $U$ is the change of basis matrix) does not generally yield a new set of probabilities $P(k_1, \\ldots, k_n)$ that are themselves Markovian. This gap undermines the claimed equivalence between this class of HQMs and HMMs."
      },
      {
        "Problem": "The Generalized Born Axiom (eq:nBorn) is a significant extension of quantum mechanics whose justification and consistency are not fully established.",
        "Location": "Def. def:Correlatable and eq:nBorn (Sec 2.2.1 'Quantum Stochastic Processes'); discussed further in Sec 4.1 'Quantum Foundations'.",
        "Explanation": "The paper defines multi-time expectation values using $\\Expv[A_1(t_1) \\cdots A_n(t_n) | \\Op{\\Psi}] = \\Trace(\\Op{A}_1 \\otimes \\cdots \\otimes \\Op{A}_n \\cdot \\Op{\\Psi}(t_1, \\ldots, t_n))$. This is acknowledged as an extension of standard quantum mechanics. While necessary for the paper's goals in signal processing, its fundamental justification, consistency with the standard measurement postulates (especially concerning sequential measurements and state collapse for arbitrary protocols), and the precise mechanism by which $\\Op{\\Psi}(t_1, \\ldots, t_n)$ 'codes' the measurement protocol are not sufficiently elaborated. The soundness of the entire framework for multi-time correlations rests on this axiom."
      },
      {
        "Problem": "Ambiguity regarding 'classical readings' not disturbing the hidden quantum process in Hidden Quantum Models (HQMs).",
        "Location": "Sec 2.4 (or 2.2.4, titled 'HQM'), Remark after Def. def:HQM.",
        "Explanation": "The paper states that for HQMs, 'measurements of the manifest A process are entirely classical: they do not disturb the hidden quantum stochastic process in any way.' This is a strong claim. Typically, any measurement or information gain about a quantum system, even if mediated by classical instruments or described by POVM elements (like $\\Op{f}(\\alpha)$ could be), leads to a change in the quantum state (disturbance/collapse). If these 'classical readings' do not cause disturbance, their nature and interaction with the quantum system must be very specific and needs to be clearly defined and justified within quantum theory. The current explanation is insufficient and could hide conceptual inconsistencies."
      },
      {
        "Problem": "The specific mathematical form of the ion activator $\\AbsTwo{\\Op{Q}(T)}$ (eq:QfromE) is an ansatz lacking clear derivation or justification.",
        "Location": "Sec 3.1 'Ion Channels and Models', eq:QfromE.",
        "Explanation": "The equation for $\\AbsTwo{\\Op{Q}(T)}$ is central to the ion channel application. Its particular structure, involving a matrix of ones in the last row and the term $e^{-\\widetilde{\\mathbf{E}}/k_BT}$, is presented without derivation from the preceding quantum formalism (e.g., from the configuration energy operator $\\Op{E}$ or general principles of activated measurement). For the conclusions about ion channels (Thm 3.1.0.3) to hold, this $\\AbsTwo{\\Op{Q}(T)}$ must (a) be a valid column-stochastic matrix for all relevant parameters, and (b) correctly relate to the known kinetic rate matrix $\\Op{K}$ of the HMM (e.g., via $\\Op{K} = \\lambda (\\AbsTwo{\\Op{Q}} - I)$ after appropriate transformations). These properties and connections are not demonstrated, making the specific results for ion channels speculative."
      },
      {
        "Problem": "Assumptions about the solvability, uniqueness, and properties of the configuration energy operator $\\Op{E}$ (eq:EfromR) are not sufficiently justified.",
        "Location": "Sec 3.1 'Ion Channels and Models', eq:EfromR.",
        "Explanation": "The configuration energy operator $\\Op{E}$ is defined implicitly by the equation $\\Op{K} = \\lambda(T) \\Op{D}_{\\Ket{\\pi}} e^{-\\mathbf{E}/k_BT} (\\Op{I} - \\Ket{\\pi}\\Htransp{\\Ket{\\pi}}) \\Op{D}_{\\Ket{\\pi}}^{-1}$. The paper asserts that $\\Op{E}$ is unique, non-negative definite, and hermitian. However, the conditions under which this equation can be solved for $\\Op{E}$ and yield an operator with these properties are not discussed or proven. The presence of the projector $(\\Op{I} - \\Ket{\\pi}\\Htransp{\\Ket{\\pi}})$, which is singular, complicates solving for $e^{-\\mathbf{E}/k_BT}$. Without ensuring these properties of $\\Op{E}$, its physical interpretation as an energy operator and its use in subsequent derivations (like for $\\Op{Q}(T)$) are unsubstantiated."
      }
    ],
    "token_usage": {
      "input": 26438,
      "thinking": 14466,
      "output": 1442
    }
  },
  {
    "entry_id": 59,
    "retraction_id": "1704.08680v2",
    "paper_id": "1704.08680v1",
    "retraction_comment": "Withdrawn by the author. In particular, Lemma 4 and hence Lemma 5 are incorrect invalidating the claimed result",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound justification of Lemma 6 concerning the cost of shortcut edges.",
        "Location": "Page 7, Lemma 6 (and its use in Theorem 8, Page 9)",
        "Explanation": "Lemma 6 claims $c(e_i') \\leq y_{C_1}^1+y_{C_2}^1$ for a shortcut edge $e_i'$ and specific Phase I dual variables $C_1, C_2$. The proof attempts to argue this by contradiction. However, standard primal-dual relationships state that for an edge $(v_i,s_i)$ chosen in Phase I due to dual $C_1$ (with degree 1 in $T_1'$), its cost $c(v_i,s_i) \\geq y_{C_1}^1$ (where $y_{C_1}^1$ is the final value of the dual $C_1$). Similarly, $c(s_i,w_i) \\geq y_{C_2}^1$. By the triangle inequality (assuming metric completion, as stated in the paper), $c(e_i') \\leq c(v_i,s_i) + c(s_i,w_i)$. Combining these, we get $c(e_i') \\leq c(v_i,s_i) + c(s_i,w_i) \\geq y_{C_1}^1 + y_{C_2}^1$. This does not yield the required $c(e_i') \\leq y_{C_1}^1+y_{C_2}^1$. The lemma's conclusion is critical for the main theorem's accounting of shortcut edge costs, and its current justification appears flawed."
      },
      {
        "Problem": "Feasibility of the short-cutting procedure in Phase III.",
        "Location": "Page 4, Algorithm 3 description (lines 11-13) and reference to Lemma 5 (page 6)",
        "Explanation": "The short-cutting step in Phase III requires selecting $d=d_2-d_1$ nodes from $\\Delta_2(C)$ (the frontier of $C$ in $T_2'$) such that these selected nodes do not have an 'incoming edge' from $o(C)$ within $C$. The paper states this is possible because 'there can be at most 1 node with an incoming edge', referencing Lemma 5. However, Lemma 5 establishes this structural property for nodes in $\\Delta_1(C)$ (the frontier of $C$ in $T_1'$) based on the construction of $T_1'$ in Phase I. It is not demonstrated that this structural property necessarily transfers to $\\Delta_2(C)$ in $T_2'$, as $T_2'$ is constructed using different rules (variable speed dual growth based on $T_1'$ degrees). If this property does not hold for $T_2'$, the described short-cutting selection might not be possible, potentially invalidating the claim that Phase III ensures final edge degrees match those in $T_1'$."
      },
      {
        "Problem": "Definition of minimally violated sets in Phase II.",
        "Location": "Page 4, Algorithm 2, Line 6",
        "Explanation": "Algorithm 2 (Phase II), Line 6 states: 'Let $\\mathcal{C}$ be the set of all minimally violated sets $C$ on $(V,T_1)$'. $T_1$ is the tree constructed in Phase I, which should already connect all terminals in $R - \\{r\\}$ to $r$. If $T_1$ is a feasible Steiner tree, then there are no minimally violated sets on $(V,T_1)$ with respect to the root $r$. Consequently, $\\mathcal{C}$ would be empty, and Phase II would not execute. If this is a typo and should be 'on $(V,T_2)$' (where $T_2$ is the tree being built in Phase II), then the subsequent analysis (e.g., Lemma 5, which relates $C$ to its degree in $T_1'$) must clearly establish how properties of $C$ (as an MVS in $T_2$) are tied to its characteristics in $T_1'$. The current wording makes the start of Phase II problematic."
      }
    ],
    "token_usage": {
      "input": 17581,
      "thinking": 21090,
      "output": 967
    }
  },
  {
    "entry_id": 60,
    "retraction_id": "2406.04846v2",
    "paper_id": "2406.04846v1",
    "retraction_comment": "The claim in this manuscript is incorrect due to a mistake in Eq. (6). The reason is that expression in Eq. (6) is derived in real arithmetic. It is incompatible with the modulo 2 arithmetic in the state ket",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect state stabilization in Figure 1",
        "Location": "Figure 1 and associated text (p.2, \"Method\" section, description of Fig. 1)",
        "Explanation": "The state $\\ket{\\Theta(\\alpha)}_\\text{L} \\equiv (\\ket{0}_\\text{L} + e^{i \\alpha} \\ket{1}_\\text{L})/\\sqrt{2}$ is generally not a +1 eigenstate of the operator $\\Gatename{P(\\alpha)_\\text{L} X_\\text{L} P(-\\alpha)_\\text{L}}$ that is supposedly measured for stabilization. This measurement would thus project the state to something other than the desired $\\ket{\\Theta(\\alpha)}_\\text{L}$ for arbitrary $\\alpha$, undermining the fault-tolerant preparation of this crucial resource state."
      },
      {
        "Problem": "Incorrect gate teleportation circuit in Figure 2",
        "Location": "Figure 2 and associated text (p.2, \"Method\" section, description of Fig. 2)",
        "Explanation": "The gate teleportation circuit depicted in Figure 2 does not implement the target logical gate $\\Gatename{P(\\alpha)}_\\text{L}$. A step-by-step analysis of the circuit shows that the output state on the first qubit is not $\\Gatename{P(\\alpha)}_\\text{L} \\ket{\\phi}_\\text{L}$. The claim that this circuit corresponds to the standard fault-tolerant T-gate implementation for $\\alpha=\\pi/4$ is also incorrect."
      },
      {
        "Problem": "Circularity and unsubstantiated fault-tolerance in the recursive step",
        "Location": "Figure 1, discussion of recursion (p.2, \"Method\" section), and Conclusion (p.3)",
        "Explanation": "The fault-tolerant preparation of the resource state $\\ket{\\Theta(\\alpha)}_\\text{L}$ (Fig. 1) requires the application of $\\Gatename{P(\\alpha)}_\\text{L}$ (in the red box and for the stabilizer measurement). If this $\\Gatename{P(\\alpha)}_\\text{L}$ is the gate being recursively constructed, the logic is circular. If it refers to a transversal implementation using physical $\\Gatename{P(\\alpha)}$ gates (as suggested in the Conclusion), the fault-tolerance of these physical gates is not established. If these underlying physical $\\Gatename{P(\\alpha)}$ gates are faulty, the state $\\ket{\\Theta(\\alpha)}_\\text{L}$ will not be fault-tolerant, thereby invalidating the fault-tolerance claim for the entire recursive construction of $\\Gatename{P(\\alpha)}_\\text{L}$."
      },
      {
        "Problem": "Unjustified gate complexity and inconsistent precision requirements",
        "Location": "Abstract, Introduction (p.1, \"$\\BigOh{\\log[1/\\epsilon] \\log\\log[1/\\epsilon] \\cdots}$\"), Conclusion (p.3, angle accuracy and complexity statement)",
        "Explanation": "The paper claims a gate complexity of $\\BigOh{\\log[1/\\epsilon] \\log\\log[1/\\epsilon] \\log\\log\\log[1/\\epsilon] \\cdots}$, but a derivation for this specific form is absent. The described recursive method, if its steps have constant cost, appears to yield $\\BigOh{\\log(1/\\epsilon)}$ gates. Furthermore, the required angle precision $\\delta$ is stated in the Conclusion as '$\\epsilon \\log_2(1/\\epsilon) \\log_2\\log_2(1/\\epsilon) \\cdots$', which implies $\\delta \\gg \\epsilon$. Such low angular precision would not result in an $\\epsilon$-accurate gate."
      },
      {
        "Problem": "Ambiguity of 'finite set of gates' and its impact on the main claim",
        "Location": "Abstract (p.1), Conclusion (p.3, \"gates needed are drawn from the set...\")",
        "Explanation": "The paper claims the construction uses gates from a 'finite set depending on the value of $\\epsilon$'. If the set of primitive gates $\\{ \\Gatename{P(\\pi \\ell / 2^m)} \\}$ grows in size with $1/\\epsilon$ (i.e., $m \\sim \\log(1/\\epsilon)$), this fundamentally differs from the standard context of the Solovay-Kitaev theorem or the Nielsen & Chuang challenge, which typically assume a fixed finite gate set. If arbitrary physical $\\Gatename{P(\\phi)}$ gates are considered elementary (as suggested by the Conclusion's reference to their ease of implementation), the complexity would likely be $\\BigOh{\\log(1/\\epsilon)}$, contradicting the paper's stated complexity and changing the interpretation of the achievement relative to the challenge."
      }
    ],
    "token_usage": {
      "input": 6273,
      "thinking": 17442,
      "output": 1095
    }
  },
  {
    "entry_id": 61,
    "retraction_id": "2306.09163v2",
    "paper_id": "2306.09163v1",
    "retraction_comment": "Theorem 1 is false for A = F_2[x]/(x^3): (A, +) \\cong C_2 x C_2; (A, \\circ) \\cong C_4",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The method for counting left ideals $i(A)$ is unsound, particularly in Section 3 for $A_{24}$ and potentially affecting degree estimates in Section 4.",
        "Location": "Section 3, paragraph starting 'To count left ideals, we illustrate with de Graaf's algebra $A = A_{24}$...' and the subsequent calculation of $i(A)$. Also impacts Section 4's estimation of $i(A)$ and its degree $d_i$.",
        "Explanation": "The paper determines the number of left ideals by first identifying 'permissible' Reduced Row Echelon Forms (RREFs) based on pivot sequences that are compatible with the ideal structure (e.g., if $a$ is a generator, $a^2$ must be generated). It then sums $p^{n(M_S)}$ for these RREFs, where $n(M_S)$ is the number of free parameters for a *subspace* with that RREF. This is flawed because not every such subspace is a left ideal. The condition $x \\cdot v \\in J$ (for $x \\in A, v \\in J$) imposes further constraints on the free parameters in the RREF, typically reducing them. For example, in $A_{24}$, the pivot sequence $S=13$ is stated to contribute $p^3$ to $i(A)$, but analysis shows it likely contributes a term of degree $p^1$. This error makes specific $i(A)$ calculations (like for $A_{24}$) incorrect and may lead to overestimation of the degree of $i(A)$ in Section 4, affecting the GCR bounds."
      },
      {
        "Problem": "The asymptotic estimate for the exponent $t$ in Theorem 3 is incorrect.",
        "Location": "Section 4, Theorem 3, specifically the expression '$t = \\dots \\sim (\\frac {n^2}{4}) (-n^{2e}(n-1))$' and the resulting GCR estimate '$\\sim p^{-(\\frac {n^2}{4})(n^{2e}(n-1))}$'.",
        "Explanation": "Theorem 3 provides an upper bound for the GCR for the algebra $A_{n,e}$. The exponent $t$ in $p^t$ is given by $t = \\deg_p i(A) - \\deg_p s(A)$. The paper correctly states $t = \\frac{n^2}{4} \\left( \\frac{n^{2e}-1}{n^2-1} - \\left(\\frac{n^e-1}{n-1}\\right)^2 \\right)$. However, its subsequent asymptotic approximation for large $n$, $t \\sim (\\frac {n^2}{4}) (-n^{2e}(n-1))$, is incorrect. The term $\\left( \\frac{n^{2e}-1}{n^2-1} - \\left(\\frac{n^e-1}{n-1}\\right)^2 \\right)$ is asymptotically $\\approx -2n^{2e-3}$ for $e>1$ and large $n$. The paper's approximation $-n^{2e}(n-1) \\approx -n^{2e+1}$ is of a significantly different order (larger magnitude). While the GCR likely still tends to 0, the rate is miscalculated."
      },
      {
        "Problem": "Arithmetic error in the calculated exponent for $i(A)/s(A)$ in the bi-skew brace case ($e=2$).",
        "Location": "Section 5, last equation: '$i(A)/s(A) \\sim p^{(\\frac{n^2}{2})^2 -(\\frac{n+n^2}{2})^2} = \\frac{1}{p^{\\frac{2n^3 + n^2}{2}}}$'.",
        "Explanation": "For $e=2$, the paper calculates the difference in degrees of $p$ for $i(A)$ and $s(A)$. The degree for $i(A)$ is taken as $(n^2/2)^2 = n^4/4$. The degree for $s(A)$ is $((n+n^2)/2)^2 = n^2(n+1)^2/4$. The difference is $(n^4/4) - (n^2(n+1)^2/4) = (n^4 - (n^4+2n^3+n^2))/4 = (-2n^3-n^2)/4$. Therefore, $i(A)/s(A) \\sim p^{(-2n^3-n^2)/4} = 1/p^{(2n^3+n^2)/4}$. The paper's stated result is $1/p^{(2n^3+n^2)/2}$. The exponent's magnitude in the denominator given in the paper is twice what it should be."
      }
    ],
    "token_usage": {
      "input": 9587,
      "thinking": 22885,
      "output": 1109
    }
  },
  {
    "entry_id": 62,
    "retraction_id": "1607.07976v3",
    "paper_id": "1607.07976v2",
    "retraction_comment": "The statement about approximate equality of phase and group velocities is incorrect. Therefore, all arguments based on this statement are unfounded",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental issue with the assumed equality of laser phase and group velocities (v_ph,laser = v_g).",
        "Location": "Page 30 (assumption [ω_0 ≈ 0]|_PCM), Page 21 (justification for v_ph=v_g), Eq. (10) and related discussions.",
        "Explanation": "The paper assumes that the laser carrier frequency is approximately zero in the pulse co-moving (PCM) frame (ω_0|_PCM ≈ 0). This leads to the conclusion that the laser's phase velocity (v_ph,laser) equals its group velocity (v_g). This equality is generally incorrect for a pulse propagating in a dispersive medium like plasma, as it implies either no dispersion (ω_p=0) or v_g=c (which also implies ω_p=0 if the standard EM dispersion relation ω² = ω_p² + c²k² holds). The paper's justification on page 21 that 'the laser pulse is a pure radiation and not a packet of electromagnetic modes, therefore its local phase and group velocities may equal' is physically unsound for a pulse, which is inherently a superposition of modes. This flawed premise underpins key derivations for spectral evolution (e.g., Eq. (10)) and subsequent interpretations of pulse dynamics, potentially invalidating conclusions regarding quantitative predictions of frequency shifts and pulse amplification."
      },
      {
        "Problem": "Incorrect formula for frequency shift in electromagnetic cascading and its use to derive vacuum dispersion for generated modes.",
        "Location": "Equation (11b) on page 40, and derivation of Equation (11e) on page 42.",
        "Explanation": "Equation (11b) for the frequency ω of generated modes, given as ω = ω_0 + γ_g c Δk|_PCM, appears to be incorrect. A consistent Lorentz transformation for frequency from the PCM frame (where ω|_PCM ≈ ω_0|_PCM and k|_PCM = k_0|_PCM + Δk|_PCM) to the lab frame yields ω = ω_0 + γ_g v_g Δk|_PCM (or ω = ω_0 + γ_g c β_g Δk|_PCM). The paper seems to use the form with 'c' instead of 'v_g' (or cβ_g) to derive Eq. (11e) (ω=ck), concluding that new modes appear on the vacuum dispersion curve. If Eq. (11b) is incorrect as stated, then the derivation of Eq. (11e) is not sound. This would invalidate the conclusion that the generated spectral components follow the vacuum dispersion relation under the stated conditions."
      },
      {
        "Problem": "Unjustified substitution of global group velocity with local phase velocity in the non-adiabatic model.",
        "Location": "Page 47, discussion on modifying Eqs. (10), (11a), (11b) for non-adiabatic effects.",
        "Explanation": "To model non-adiabatic effects such as phase modulation, the paper proposes replacing the global pulse group velocity parameters {β_g, γ_g} with local plasma phase velocity parameters {β_ph.l, γ_ph.l} in equations (10, 11a, 11b). These equations were originally derived based on Lorentz transformations pertaining to a single, global PCM frame (moving at v_g) and the assumption of ω|_PCM ≈ 0. Substituting a spatially varying local phase velocity (β_ph.l) into these global-frame equations lacks rigorous justification. This ad-hoc modification appears to break the self-consistency of the theoretical framework established for the adiabatic regime, making the subsequent predictions for spectral changes due to phase deceleration (e.g., multi-hump structures) unreliable."
      }
    ],
    "token_usage": {
      "input": 13282,
      "thinking": 9605,
      "output": 836
    }
  },
  {
    "entry_id": 63,
    "retraction_id": "2006.15984v5",
    "paper_id": "2006.15984v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial definition error of Canonical Huffman Table",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Underspecified NFRS Selection Rule for GA",
        "Location": "Section 5.1.1 'Population initialization'",
        "Explanation": "The rule for selecting 10 NFRSs for the GA optimization ('the leftmost one is the closest to and greater than the required capacity') is ambiguous. 'Leftmost' is not defined (e.g., in terms of frequency, RS value order), and how an RS is 'closest to and greater than the required capacity' is unclear. This lack of precise definition hinders reproducibility and critical evaluation of this key heuristic in the proposed GA method, which is the primary realization of the framework."
      },
      {
        "Problem": "Potential Suboptimality due to Restrictive GA Heuristics and Lack of Analysis",
        "Location": "Section 5.1.1 and 5.1.2",
        "Explanation": "The GA implementation solves a significantly constrained version of the optimization problem in Eq. 1 by: (a) limiting consideration to only 10 NFRSs selected by an empirical and vaguely defined rule, (b) requiring these 10 NFRSs to be 'consecutive' (in an unspecified order), and (c) restricting $x_i$ values (number of VLCs mapped to an NFRS) to $\\{1,2,4,8\\}$. While individual restrictions are mentioned as practical choices, their combined impact on the solution's proximity to the true optimum of the general problem (Eq. 1) is not analyzed. This makes it difficult to assess whether the GA finds a 'nearly optimal' solution in a broader sense or only for a heavily constrained version of the problem."
      },
      {
        "Problem": "Lack of Justification for 'Consecutive' NFRS Selection Constraint",
        "Location": "Section 5.1.1 'Population initialization'",
        "Explanation": "The heuristic of selecting 10 'consecutively ones' NFRSs for GA optimization lacks clear theoretical or strong empirical justification beyond being chosen 'after many attempts'. The optimal set of NFRSs for which $x_i > 1$ might not be consecutive in any standard ordering (e.g., by frequency or RS value). This specific constraint could arbitrarily exclude potentially better solutions from the search space, and its basis is not sufficiently explained, making this aspect of the method appear arbitrary."
      }
    ],
    "token_usage": {
      "input": 29085,
      "thinking": 14340,
      "output": 520
    }
  },
  {
    "entry_id": 64,
    "retraction_id": "1512.06616v5",
    "paper_id": "1512.06616v4",
    "retraction_comment": "Withdrawn after detection of a major error in the C-E expansion",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of the diffusive transmission condition for hole-hole interaction.",
        "Location": "Section 5.2, Equation (40) (second line), and Remark on page 9",
        "Explanation": "The derivation of the second diffusive transmission condition in Eq. (40), specifically for the case $(s,s')=(-,-)$ (hole-hole interaction across the barrier), appears to be incorrect. The general form $e^{sA_s^1} - e^{\beta\\delta V} e^{s'A_{s'}^2} = \tau (\\dots)$ combined with the substitution rule $(n_k/n_0)^k$ for $e^{kA_k}$ (derived from $A_k^w=A_k^f$ and $e^{A_k^f}=n_k/n_0$) leads to $1/n_-^1 - e^{\beta\\delta V}/n_-^2 = \tau(\\dots)$ for this case. The paper's result $n^1_- - e^{-\beta \\delta V} n^2_- = \tau(\\dots)$ cannot be obtained consistently from the preceding steps. The M-B approximations for $\\weq_-$ and its relation to $\\feq_-$ in the Remark on page 9 are also problematic and do not seem to correctly lead to the stated equation."
      },
      {
        "Problem": "Contradictory conditions for the validity of Maxwell-Boltzmann approximation.",
        "Location": "Section 5.2, Remark on page 9",
        "Explanation": "The Maxwell-Boltzmann (M-B) approximation is used to simplify the diffusive transmission conditions. This approximation is typically valid for $n_s \\ll n_0$ (low densities), which corresponds to chemical potentials $A_s \\ll 0$ (for $f_s$ distributions). However, the Remark at the end of Section 5.2 suggests that the approximations are compatible with conditions like $A^1_- \\approx 0$ or $A^2_- \\approx \beta\\delta V$ (for $\\delta V > 0$). These values for $A_s$ imply that the hole system is not in the M-B regime (it would be non-degenerate or degenerate), which contradicts the initial assumption used to derive the simplified conditions. This makes the applicability of the derived M-B conditions questionable."
      },
      {
        "Problem": "Inconsistent definition and use of the asymptotic boundary layer corrector $\\tilde\\theta_s^{i,\\infty}$.",
        "Location": "Section 5.2, around Theorem 5.1 and Eq. (38)-(39)",
        "Explanation": "Theorem 5.1 states that the boundary layer corrector $\\theta_s^i$ converges to $\\theta_s^{i,\\infty}$, which are Fermi-Dirac distributions (like $\\feq_s$). The transformation $\\tilde\\theta_s = s\\theta_s$ is used. This implies $\\tilde\\theta_-^{i,\\infty} = -\\theta_-^{i,\\infty} = -\\feq_-(\\cdot, A_-^{i,\\infty})$. However, in the derivation of Eq. (39) (which leads to Eq. (40)), $\\tilde\\theta_s^{i,\\infty}$ is effectively treated as $\\weq_s(\\cdot, A_s^{i,\\infty})$. For $s=-1$, this means $-\\feq_-(\\cdot, A_-^{i,\\infty}) = \\weq_-(\\cdot, A_-^{i,\\infty})$. Since $\\weq_- = 1-\\feq_-$, this leads to $-\\feq_- = 1-\\feq_-$, which implies $1=0$. This fundamental inconsistency in handling the asymptotic corrector term invalidates the derivation of the first-order diffusive transmission conditions."
      }
    ],
    "token_usage": {
      "input": 14348,
      "thinking": 20118,
      "output": 860
    }
  },
  {
    "entry_id": 65,
    "retraction_id": "2309.14057v2",
    "paper_id": "2309.14057v1",
    "retraction_comment": "Our description in Chapter 3, Section 3.2 of the paper is too repetitive with the paper \"Object detection meets knowledge graphs\". There is an error in the description of formula (5) in Section 3.3. And a detailed reasoning process is required for formula (5). Therefore, we wish to request a retraction of the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear and Potentially Incorrect Formulation of Graph Reasoning Mapping (GRM) Module Operations",
        "Location": "Section 3.4, Equations (7) and (8), Figure 5",
        "Explanation": "The description of the GRM module contains several ambiguities and potential errors: 1. Equation (7) for compatibility matrix $H_v$: The definition of the weight matrix $W$ as '$W \\in R^{D \\times D}$ ... obtained by a $1 \\times 1$ convolution' is unclear in its application to the concatenated features $[v, x_i]$ (a GCN node embedding $v$ and a visual pixel feature $x_i$). The dimensions and specific operation of $W$ are not adequately explained to ensure $[v, x_i]W$ results in a scalar for the exponent. 2. Equation (8) for updated visual features $X^{l+1}$: The matrix multiplication $H_v V^{l+1}$ (where $H_v \\in R^{C \\times HW}$ and $V^{l+1} \\in R^{C \\times D'}$) is mathematically invalid as written. A valid operation, such as $(V^{l+1})^T H_v$ or $H_v^T V^{l+1}$ (potentially with transpositions to align dimensions), would be needed to produce features that can be reshaped to $D' \\times HW$ or $HW \\times D'$. 3. Dimensionality Mismatch in Residual Connection: The element-wise addition '$+X$' in Equation (8) requires the output of $\\sigma(H_v V^{l+1})$ (after reshaping) to have the same channel dimension as the input visual features $X$. However, $V^{l+1}$ (output of GCN using GloVe embeddings) is described as having dimension $D'$ (e.g., 300, as per Section 3.1), while $X$ (input visual features from ASPP) has $D_{vis}=256$ channels (Section 4.3). No explicit projection layer is mentioned to reconcile these dimensions, or it's not clearly stated if $D'$ is made equal to $D_{vis}$ within the GRM's GCN design."
      },
      {
        "Problem": "Ambiguity in GCN Integration for Multi-Label Classification Scores",
        "Location": "Section 3.3, paragraph describing the GCN-based classifier and Equation (5)",
        "Explanation": "The method for using the GCN output $V_c \\in R^{C \\times D}$ (where $D$ is the node feature dimension from GCN) as 'interdependent classifiers' and how it is 'multiplied' with the globally average-pooled image features $x$ (from ResNet-50, e.g., $1 \\times D_{img}$) to obtain prediction scores for the $L_{fl}$ loss is not precisely formulated. The text states, 'Then multiply the obtained classifier with the last layer of feature map representation $x$ after global average pooling and dimension transformation to get the prediction score, ie $x$.' The 'ie $x$' is a typo and should refer to the scores. More critically, the exact mathematical operation, including any necessary projections or reshaping of $V_c$ or $x$ to ensure dimensional conformity for producing $C$ class scores (e.g., $scores = V_c \\cdot (W_{proj} \\cdot x^T)$), is not detailed. This lack of clarity hinders understanding and reproducibility of this component."
      },
      {
        "Problem": "Confusing Presentation and Potentially Flawed Interpretation in Ablation Study on GCN Inputs",
        "Location": "Section 5.2.3, Figure 10, and accompanying text",
        "Explanation": "The ablation study in Section 5.2.3 is confusingly presented. Figure 10's title refers to 'different semantic relation matrices,' but its legend ('GloVe', 'GoogleNews', 'FastText', 'ConceptNet') and the main text discuss different 'word embeddings' (which are GCN node features $V$), not different relation matrices $E$. The inclusion of 'ConceptNet' in the legend, as if it were an alternative word embedding, is incorrect, given that ConceptNet is consistently stated as the source for the relation matrix $E$ throughout the paper. Furthermore, the concluding sentence, 'It is worth noting that the application of the robust relationship matrix, ConceptNet, as the matrix of label correlations leads to improved performance,' is unsubstantiated within this specific ablation study, as no comparison with alternative sources for the relation matrix $E$ is presented. This section lacks clarity and may misrepresent the experimental setup and its conclusions."
      },
      {
        "Problem": "Unclear Mechanism for Adaptability of GCN Output Dimension in GRM",
        "Location": "Section 5.2.2 (Ablation study: 'Which ConvBlock to add GRM layer?') and implicitly Section 3.4",
        "Explanation": "In Section 5.2.2, when discussing the placement of the GRM module, the paper states: 'as convolutional networks deepen, the output channels of layer-3 and layer-4 expand to 1024 and 2048 dimensions, respectively. Consequently, the graph convolutional outputs of the GRM module also increase to 1024 and 2048 dimensions.' This implies that the output feature dimension $D'$ of the GCN within the GRM (which processes word embeddings $V \\in R^{C \\times K}$, with $K=300$) dynamically changes to match the channel dimension of the visual features $X$ at different insertion points. However, the core methodology (Sections 3.1 for GCN basics, and 3.4 for GRM) does not explain how this adaptation of the GCN's output dimension $D'$ is achieved (e.g., by altering the GCN's final layer's weight matrix $W^L$ to map from $K$ to $D_{visual}$). This is a crucial architectural detail for the GRM to function as described with the residual connection in Equation (8), especially if $D'$ must match $D_{vis}$. Its omission makes the claimed adaptability and the reported results in Table 5 difficult to fully assess or reproduce."
      }
    ],
    "token_usage": {
      "input": 15131,
      "thinking": 8131,
      "output": 1394
    }
  },
  {
    "entry_id": 66,
    "retraction_id": "1206.0667v2",
    "paper_id": "1206.0667v1",
    "retraction_comment": "This paper is withdrawn by the author because the paper did not prove the second inequality of (4.3), which is unlikely to hold in general",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Reliance on deep results from singularity theory for the structure of the basic Lagrangian cycle.",
        "Location": "Proposition 2.3, p. 4; Definition 2.4, p. 5; Lemma 2.5, p. 6.",
        "Explanation": "The construction of the 'basic Lagrangian cycle' $\\sigma_F^{add}$ as a mod-2 cycle is fundamental. Proposition 2.3 asserts that for $\\dim M=2$ and generic $F$, $\\partial(\\sigma_F + \\sigma_{F;[-+]})$ is the boundary of $\\Sigma_{F;\\Delta^2}$. This relies on cited results from the theory of Lagrangian singularities (Arnold, Givental, Zakalyukin-Roberts). If this proposition is incorrect or misapplied, $\\sigma_F^{add}$ may not be a cycle, or not be homologous to the zero section $o_\\Delta$. This would invalidate Lemma 2.5, which states that $\\pi_{2, \\Sigma_{\\mathbb F^t}^{add}}: \\Sigma_{\\mathbb F^t}^{add} \\to M$ has mod-2 degree 1. The surjectivity implied by this lemma is crucial for ensuring the existence of the point $\\widetilde{\\bf x}$ for any ${\\bf x}$ in Section 4 (specifically for Theorem 4.3), which is a cornerstone of the main proof."
      },
      {
        "Problem": "Brief derivation of a key estimate for an integral over the chain $\\Xi$.",
        "Location": "Equation (3.8) (estimate for $\\int_{\\Xi} d\\Theta \\wedge \\Omega_1$), p. 8, and its use in Theorem 3.1.",
        "Explanation": "Theorem 3.1 provides an estimate for $\\left|\\int_{\\phi_\\mathbb G^1(o_\\Delta)} h_{\\underline{H}(1)}({\\bf q}) \\, \\Omega_1^n\\right|$. A crucial part of this estimate is bounding $\\left|\\int_{\\Xi} d\\Theta \\wedge \\Omega_1\\right|$ by $C_2\\overline d(\\phi_G,id)^2 \\text{Area}_\\omega(M)$ (Eq. 3.8). This is presented as an 'immediate corollary' of Proposition 3.3, Lemma 3.4, and the co-area formula. For $\\dim M=2$, $\\Xi$ is a 4-chain and $d\\Theta \\wedge \\Omega_1$ is a 4-form. The quadratic dependence on $\\overline d(\\phi_G,id)$ is plausible. However, the derivation is highly condensed. An error in the application of the co-area formula or in the implicit geometric arguments (e.g., volume of $\\Xi$) could lead to an incorrect order of magnitude for this term. Since this estimate directly feeds into Corollary 3.2 and the final contradiction argument of Theorem 1.1, an error here would be critical."
      },
      {
        "Problem": "Complexity of the transversality argument for the properties of the chain $\\Xi$.",
        "Location": "Proposition 3.3, p. 7-8.",
        "Explanation": "Proposition 3.3 states that for a generic choice of $G$, the self-intersection points of the chain $\\Xi$ in $T^*\\Delta$ have codimension at least one. The proof involves a transversality argument for the map $\\Xi(s,v,x)$. The argument distinguishes cases $s=s'$ and $s \\neq s'$. For $s \\neq s'$, the argument relies on considering the specific case $v=1, v'=1$ and then extending the conclusion. While the logic for this extension (if $\\phi_G^s(x) \\neq \\phi_G^{s'}(x')$, then first components of $\\Xi$ differ) seems plausible, the overall argument is intricate. A flaw in this genericity and transversality reasoning could mean that $\\Xi$ has more substantial self-intersections, potentially complicating the application of Stokes' theorem or the co-area formula used to estimate integrals over $\\Xi$ in Theorem 3.1."
      }
    ],
    "token_usage": {
      "input": 19218,
      "thinking": 22327,
      "output": 947
    }
  },
  {
    "entry_id": 67,
    "retraction_id": "1503.03000v3",
    "paper_id": "1503.03000v2",
    "retraction_comment": "This paper has been withdrawn by the author because the renormalization constructed in it is not compatible with renormalization in perturbative quantum field theory. Main Theorem of \\S5 is not true",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect recursive definition of renormalization",
        "Location": "Section 2, Equation (11)",
        "Explanation": "Equation (11) defines $\\overline{R}(\\Gamma)$, the quantity from which the singular part is extracted to define the counterterm $C(\\Gamma)$. The provided formula, $\\overline{R}(\\Gamma)=\\sum_{\\gamma\\subset\\Gamma, \ne}C(\\widetilde\\gamma)U(\\Gamma/\\gamma)$, appears to erroneously omit the unrenormalized value $U(\\Gamma)$ and instead includes $C(\\Gamma)$ (the counterterm for $\\Gamma$ itself, as $\tilde{\\gamma}$ can be $\\Gamma$) in the sum defining $\\overline{R}(\\Gamma)$. A standard BPHZ-type recursion would define $\\overline{R}(\\Gamma)$ (or an equivalent quantity) as $U(\\Gamma) + \\sum_{\text{proper subgraphs }\\gamma'} C(\\gamma')U(\\Gamma/\\gamma')$. The formula as stated would lead to an incorrect recursive definition for $C(\\Gamma)$, fundamentally undermining the renormalization procedure as it would not correctly identify and subtract the divergences associated with $U(\\Gamma)$."
      },
      {
        "Problem": "Central theorem on equivalence to perturbative QFT stated without proof",
        "Location": "Section 5, Theorem",
        "Explanation": "The paper's main claim connecting its formalism to established physics is encapsulated in the Theorem in Section 5, which states that its S-matrix and Green functions coincide with those of perturbative QFT. This theorem is presented without any proof, sketch of a proof, or reference to one. Given the significant departures from standard QFT methods (e.g., Weyl-Moyal algebra for $S$-matrix elements, a bespoke 'Hamiltonian regularization', renormalization applied to 'all graphs' via a specific Hopf algebra structure, and a different conceptualization of counterterms), this equivalence is a highly non-trivial assertion that requires rigorous demonstration to be accepted."
      },
      {
        "Problem": "Properties of the proposed 'Hamiltonian Regularization' are undefined and assumed",
        "Location": "Section 2, paragraph starting 'To overcome this difficulty...'",
        "Explanation": "The entire renormalization scheme hinges on the introduction of a regularized Hamiltonian $H_\\epsilon(t)$ and the behavior of $U_\\epsilon(\\Gamma)$. The paper makes a 'main technical assumption' that the divergent part of $U_\\epsilon(\\Gamma)$ is a polynomial in $\\epsilon^{-1}$ and $\\log\\epsilon$. However, the 'Hamiltonian regularization' itself is not explicitly defined, nor are its properties discussed. It's not shown that such a regularization scheme exists for 'arbitrary Hamiltonians' (including non-local ones) that would satisfy this crucial assumption. Furthermore, other essential properties of a regularization scheme, such as preservation of symmetries (e.g., gauge symmetries, Lorentz invariance if applicable) or its implications for the locality of counterterms, are not addressed."
      },
      {
        "Problem": "Ambiguity regarding the 'non-perturbative' nature and convergence of the renormalized series",
        "Location": "Section 2, Equation (15) and Introduction",
        "Explanation": "The renormalized evolution operator $\tilde{U}$ is defined in Equation (15) as a sum $\\sum_\\Gamma R(\\Gamma)|_{\\epsilon=0}$ over all Feynman graphs. In quantum field theory, such sums are typically formal asymptotic series, not convergent objects. The paper claims to provide a 'non-perturbative renormalization' (Introduction). If the sum in Eq. (15) is merely a formal series, then the construction is 'non-perturbative' only in the limited sense of not being an expansion in a specific coupling constant, but it remains perturbative in the sense of a graph expansion. If actual convergence of this sum is claimed, especially for the 'arbitrary Hamiltonians' considered, this is an exceptionally strong assertion that lacks any analytical justification or discussion of convergence criteria within the paper."
      }
    ],
    "token_usage": {
      "input": 7356,
      "thinking": 9331,
      "output": 858
    }
  },
  {
    "entry_id": 68,
    "retraction_id": "2010.16005v2",
    "paper_id": "2010.16005v1",
    "retraction_comment": "There is a potential issue with trilinear estimates and the indices needs to be adjusted",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect polynomial inequality used in trilinear estimates",
        "Location": "Page 9, Equation (3.5) and the line preceding it",
        "Explanation": "The inequality $\\langle 3\\xi_2-3\\xi+2+(3\\xi_2^2-3\\xi^2+2\\xi+2\\xi_2)^2+4(3\\xi_2-3\\xi+2)(\\xi^3-\\xi^2-2\\xi_2^2+\\tau)\\rangle{}^\\frac{1}{2} \\gtrsim \\langle{}\\xi_2\\rangle{}^{1.5}|\\xi_2-(4\\tau-\\gamma(\\xi))|^\\frac{1}{2}|\\xi|^\\frac{1}{2}$ is stated to hold by Lemma 3.1. However, comparing the highest powers of $\\xi_2$ on both sides ($\\xi_2^2$ on LHS, $\\xi_2^2 |\\xi|^{1/2}$ on RHS) suggests this inequality implies $1 \\gtrsim |\\xi|^{1/2}$, which is false for large $|\\xi|$. Lemma 3.1 is for upper bounds of polynomial ratios and does not justify this lower bound. If this inequality is incorrect, the subsequent derivation of the bound for the integral (and thus all trilinear estimates) fails."
      },
      {
        "Problem": "Misinterpretation of the Riesz derivative term in the nonlinearity",
        "Location": "Page 7, Remark before 'Proof of Theorem 2' and subsequent proof of trilinear estimate (2.5) (referred to as (2.3) in Theorem 2)",
        "Explanation": "The paper aims to estimate the term $i u \\p_{|x|}(|u|^2)$ from eq (1.1). However, the proof of the trilinear estimate (Theorem 2, eq (2.5)) considers $\\p_{|x|}(fgh)$, which corresponds to $\\p_{|x|}(i u |u|^2)$. The Riesz derivative (multiplier $-|\\xi|$) is applied to the Fourier transform of the entire product $u|u|^2$, rather than to $|u|^2$ before multiplication by $u$. The remark on page 7 ($||| iu\\p_{|x|}(|u|^2)|||_{s,b} \\simeq{} ||| i\\p_{|x|}(u|u|^2) |||_{s,b}$) asserts an equivalence of norms for these two different operations, but this is a non-standard claim and is not justified. This misinterpretation means the provided estimate is not for the actual term in the PDE."
      },
      {
        "Problem": "Misinterpretation of spatial derivative terms in the nonlinearity",
        "Location": "Page 10, last paragraph (discussion of $|u|^2u_x$ and $u^2\\bar{u}_x$ terms)",
        "Explanation": "Similar to the Riesz derivative term, the paper states that the trilinear estimates for terms like $|u|^2u_x$ (i.e., $f\\bar{g}(\\partial_x h)$) follow the same argument, with a factor of $\\xi$ from the derivative. The proof of Theorem 2, eq (2.4) ($|||\\partial_x(fgh)|||_{s,b-1}$) implies the derivative $\\partial_x$ (multiplier $i\\xi$) acts on the entire product $fgh$. This is not equivalent to the derivative acting on a single function within the product (e.g., $fg(\\partial_x h)$). The argument structure would differ significantly if the multiplier $i\\xi_k$ (where $\\xi_k$ is an internal frequency variable) were inside the convolution integrals."
      },
      {
        "Problem": "Unjustified form of the contraction estimate for $Tu-Tv$",
        "Location": "Page 3, Proposition 1, Equation (2.2)",
        "Explanation": "Proposition 1 states $|||Tu-Tv|||_{s,b}\\leq{}c\\biggl|\\biggl|\\biggl|u+v\\left(\\frac{1+i\\sqrt{3}}{2}\\right)\\biggr|\\biggr|\\biggr|_{s,b}\\biggl|\\biggl|\\biggl|u+v\\left(\\frac{1-i\\sqrt{3}}{2}\\right)\\biggr|\\biggr|\\biggr|_{s,b}|||u-v|||_{s,b}$. This specific factorization involving complex cube roots of -1 is characteristic of polynomial nonlinearities (e.g., $u^3-v^3$). Its validity for the mixed nonlinearities in the MNLS equation (1.1), which include conjugates and derivatives (e.g., $|u|^2u_x$, $u\\partial_{|x|}(|u|^2)$), is not standard and is presented without derivation. If this form is not justified for all nonlinear terms, the proof that $T$ is a contraction is incomplete."
      }
    ],
    "token_usage": {
      "input": 20202,
      "thinking": 14118,
      "output": 1130
    }
  },
  {
    "entry_id": 69,
    "retraction_id": "2305.08639v2",
    "paper_id": "2305.08639v1",
    "retraction_comment": "Proof of Theorem 5.4 is wrong. In particular, the map that is claimed to be a homomorphism, it is not a homomorphism. Also, some of the main results of the paper rely on that Theorem",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of homomorphism images in Section 6",
        "Location": "Section 6, p. 14-16, particularly the computation of $\\tilde{\\tau}(\\sigma_1^{-1} \\sigma_2^3 \\sigma_1)$ and $\\tilde{\\tau}(\\sigma_i^3)$",
        "Explanation": "The explicit computations of the images of braid group elements under the homomorphism $\\tilde{\\tau}$ appear to be incorrect. For instance, for $g = \\sigma_1^{-1} \\sigma_2^3 \\sigma_1$, the component $g(x_1)x_1^{-1}$ is calculated in the paper to be $[(\\tilde{x}_3^{\\tilde{x}_2}, \\tilde{x}_1)]$. However, a direct calculation using the provided actions $\\sigma_i(x_j)$ yields $g(x_1)x_1^{-1} = ( (x_3, x_1^{x_2})^{x_1x_2} )$, which is different. Similar discrepancies appear for $\\tilde{\\tau}(\\sigma_i^3)$, where the derivation seems to rely on unproven identities like $(u,v) = -(v,u)$ for the paper's definition of $(u,v)$. If these calculations are incorrect, the matrix representation of the linear system in Lemma 6.2 would be wrong, invalidating its solution and thus Theorem B (the ranks of $H_1(G_3^3;\\mathbb{Z})$ and $H_1(G_4^3;\\mathbb{Z})$) and Corollary 1.1."
      },
      {
        "Problem": "Incorrect statement of Theorem E",
        "Location": "Page 3, Theorem E, and its proof in Section 3, p.8",
        "Explanation": "Theorem E states a short exact sequence $1 \\to S_n \\to \\frac{B_n[l]}{B_n[2pl]} \\to \\mathbb{Z}/p^{\\binom{n}{2}} \\to 1$. However, the derivation in Section 3 (Lemmas 3.2, 3.3 and proof of Theorem E) indicates that the quotient group $B_n[l]/B_n[pl]$ is isomorphic to $\\mathfrak{sp}_{n-1}(\\mathbb{Z}/p)$. This Lie algebra, considered as an abelian group, is isomorphic to $(\\mathbb{Z}/p)^{\\binom{n}{2}}$, not $\\mathbb{Z}/p^{\\binom{n}{2}}$ (a cyclic group). The group $(\\mathbb{Z}/p)^{\\binom{n}{2}}$ is a direct product of $\\binom{n}{2}$ copies of $\\mathbb{Z}/p$, which is different from the cyclic group $\\mathbb{Z}/p^{\\binom{n}{2}}$ unless $\\binom{n}{2}=1$ (i.e., $n=2$, but $n \\ge 3$ is assumed). This makes the statement of Theorem E incorrect as written."
      },
      {
        "Problem": "Unusual notation and insufficiently justified relations for the group N",
        "Location": "Section 4.1, p. 8 (definition of $(a,b)$) and Lemma 4.5, p. 10 (relations in $N/[\\pi, N]$)",
        "Explanation": "The paper defines an element $(a,b) = abab^{-1}a^{-1}b^{-1}$, which is a non-standard notation in the context of braid groups and fundamental groups (standard notation is typically for commutators like $aba^{-1}b^{-1}$). The subgroup $N$ is defined using these elements. Lemma 4.5 lists relations for these elements in $N/[\\pi, N]$, such as $(\\tilde{x}_i^{-1}, \\tilde{x}_j^{-1}) = (\\tilde{x}_j, \\tilde{x}_i)$. These relations are crucial for subsequent proofs (e.g., Lemma 4.7, Propositions 4.8, 4.9, and the calculations in Section 6). However, the proofs for these relations in Lemma 4.5 are either missing or extremely brief (e.g., the proof for relation 1 is just an assertion of an equality). Without rigorous proofs for these fundamental relations, the correctness of large parts of the paper, including the structure of $\\tilde{A}_n$ and the computations for Theorem B, is uncertain."
      }
    ],
    "token_usage": {
      "input": 33923,
      "thinking": 24146,
      "output": 1017
    }
  },
  {
    "entry_id": 70,
    "retraction_id": "1706.06242v2",
    "paper_id": "1706.06242v1",
    "retraction_comment": "An error has occurred: The classical Kolmogorov result about characterization of compactness is usually applied with linear operators. Unfortunately, commutator of Hardy-Littlewood maximal operator is a sublinear one",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The estimate for terms $I_2$ and $I_3$ in Claim 1 (Case 2) is flawed for $n>1$.",
        "Location": "Page 5, Proof of Claim 1",
        "Explanation": "In the proof of Claim 1, Case 2, the terms $I_2$ and $I_3$ are estimated. For $I_2$ (and similarly for $I_3$), the paper arrives at an intermediate estimate proportional to $C\\left(\\frac{|B_2|-|B_1|}{|B_2|}\\right)^{1/s'} M(f_1)(x) M_s(f_2)(x)$ (adjusting for apparent typos in which functions $f_1, f_2$ are associated with $M$ or $M_s$). This is then claimed to be bounded by $C\\frac{|x-x'|^{\\alpha}}{|B_2|^{\\alpha/n}} M_s(f_1)(x) M(f_2)(x)$. Letting $h = |x-x'|$ and $r$ be the radius of $B_1$ (where $r>h$), this step requires the inequality $(\\frac{h}{r})^{1/s'} \\leq C (\\frac{h}{r})^{\\alpha}$. This inequality holds if $1/s' \\geq \\alpha$. However, the condition imposed on $s$ is $\\frac{n}{n-\\alpha} \\leq s < \\min\\{p_1,p_2\\}$, which implies $1/s' = 1-1/s \\geq \\alpha/n$. If $n>1$, then $\\alpha/n < \\alpha$. Thus, it is possible that $\\alpha/n \\leq 1/s' < \\alpha$. In this situation, since $h/r < 1$, the inequality $(\\frac{h}{r})^{1/s'} \\leq C (\\frac{h}{r})^{\\alpha}$ is false. This makes Claim 1 unsound for $n>1$, which in turn invalidates the proof of Theorem 1.1 (a) $\\Rightarrow$ (b) for $n>1$ as it relies on this claim."
      },
      {
        "Problem": "The derivation of the estimate for $I_1$ in Claim 1 (Case 2) contains an incorrect intermediate step.",
        "Location": "Page 5, Proof of Claim 1, estimate for $I_1$",
        "Explanation": "For the term $I_1$ in Case 2 of Claim 1, the paper states that $I_1 = \\frac{|B_2|^2-|B_1|^2}{|B_2|^2} \\cdot \\frac{1}{|B_1|^2} \\int_{B_1}\\int_{B_1} |f_1||f_2| dy_1 dy_2 \\leq C \\frac{|x-x'|^n}{|B_2|} M(f_1)(x)M(f_2)(x)$. The factor $\\frac{|B_2|^2-|B_1|^2}{|B_2|^2}$ is $1-(|B_1|/|B_2|)^2 = 1-(r/(r+h))^{2n} \\approx C \\frac{h}{r}$ for $h<r$. The paper's factor $C\\frac{|x-x'|^n}{|B_2|}$ corresponds to $C (h/r)^n$ (since $|B_2| \\approx r^n$). While the subsequent step $C (h/r)^n \\leq C (h/r)^{\\alpha}$ is true (as $n \\ge 1 \\ge \\alpha$), the intermediate factorization $C\\frac{|x-x'|^n}{|B_2|}$ is not the correct consequence of $\\frac{|B_2|^2-|B_1|^2}{|B_2|^2}$. The correct factor $C h/r$ also leads to $C h/r \\leq C (h/r)^{\\alpha}$ (since $1 \\ge \\alpha$), so the final bound for $I_1$ might hold, but the derivation shown is incorrect."
      },
      {
        "Problem": "The use of $M_s$ versus $M$ in the conclusion of Claim 1 and its application in Theorem 1.1 is inconsistent.",
        "Location": "Page 5, Conclusion of Claim 1 and its application on Page 6",
        "Explanation": "The proof of Claim 1 attempts to bound three terms $I_1, I_2, I_3$. The paper's bounds for these terms are (modulo typos): $I_1 \\lesssim (h/r)^{\\alpha} M(f_1)M(f_2)$, $I_2 \\lesssim (h/r)^{\\alpha} M_s(f_1)M(f_2)$, and $I_3 \\lesssim (h/r)^{\\alpha} M(f_1)M_s(f_2)$. Summing these does not yield the stated conclusion of Claim 1, which is $C \\frac{|x-x'|^{\\alpha}}{|B_2|^{\\alpha/n}} M_s(f_1)(x)M_s(f_2)(x)$. Instead, it would yield a sum of terms involving mixed $M$ and $M_s$, which could be bounded by $C (h/r)^{\\alpha} M(f_1)(x)M(f_2)(x)$ (since $M_s \\le M$). If Claim 1 concluded with $M(f_1)M(f_2)$ on the right-hand side, the main argument of Theorem 1.1 would still follow, i.e., $\\|M(M(f_1)M(f_2))\\|_{L^p} \\le C \\|f_1\\|_{L^{p_1}}\\|f_2\\|_{L^{p_2}}$. The discrepancy in the use of $M_s$ versus $M$ indicates an issue in the precision of the estimates."
      },
      {
        "Problem": "Typo in inequality (3.2) in the proof of Theorem 1.1.",
        "Location": "Page 4, inequality (3.2)",
        "Explanation": "Inequality (3.2) reads: $\\frac{1}{|B_{2}|^{2}}\\int_{B_{2}}\\int_{B_{2}}|b_{1}(x)-b_{1}(y_{1})||f_{1}(y_{1})||f_{2}(y_{2})|dy_{1}dy_{2}\\leq [b_{1},\\mathcal{M}]_{1}(f_{1},f_{2})(x')$. The term $|b_1(x)-b_1(y_1)|$ should be $|b_1(x')-b_1(y_1)|$ as it relates to the definition of $[b_1,\\mathcal{M}]_1(f_1,f_2)(x')$. The subsequent derivation correctly uses $|b_1(x')-b_1(y_1)|$ after adding and subtracting $b_1(x')$. This is a minor typo but could confuse the reader."
      }
    ],
    "token_usage": {
      "input": 12989,
      "thinking": 25025,
      "output": 1641
    }
  },
  {
    "entry_id": 71,
    "retraction_id": "1510.01988v2",
    "paper_id": "1510.01988v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to an error in Lemma 2; terms involving the normal derivative of $\\rho$ are missing",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch in vector field V(x) definition and resulting flux calculation.",
        "Location": "Page 3 (Definition of V(x)), Page 5 (Equation (5) and preceding lines)",
        "Explanation": "The vector field V(x) is defined as $V(x) = \\frac{1}{\\rho^k (|x|)}\\frac{x-y}{|x-y|^k} + \\frac{k-2}{2\\rho^k(|x|)} \\int_{0}^1 \\frac{tx-y}{|tx-y|^{k}} dt$. The leading term as $x \\rightarrow y$ is $\\frac{1}{\\rho^k(r)}\\frac{x-y}{|x-y|^k}$. The flux of this term (relevant for the integral $\\int_{\\Sigma \\cap \\partial D_{\\epsilon}(y)} \\langle W, \\nu\\rangle_{\\rho^2 g}$) is $\\omega_k / \\rho^{k-1}(r)$. However, the paper states the limit of this integral is $\\omega_k/2$ (Equation (5)). This factor of $1/2$ is crucial for the main theorem's inequality $|\\Sigma|_{\\rho^2 g} \\geq |B^k(r)|_{\\rho^2 g}$. If the limit were $\\omega_k$, the result would be $|\\Sigma|_{\\rho^2 g} \\geq 2|B^k(r)|_{\\rho^2 g}$. Brendle's 2012 GFA paper, which this work is based on, uses a vector field $V(x,y_0)$ (see Lemma 7 there) which has an explicit factor of $1/2$ in its definition, leading to a flux of $\\omega_k/2$. The $V(x)$ in this paper does not have this $1/2$ factor. This discrepancy suggests either $V(x)$ is misdefined, or the residue calculation is incorrect. If $V(x)$ were to be scaled by $1/2$ to fix the flux, then Lemma 2.3 Part (4) would change, and consequently $W$ (defined on page 4) would no longer be tangential along $\\partial B^n(r)$ (Lemma 2.4 would fail), invalidating a key part of the divergence theorem argument."
      },
      {
        "Problem": "Incorrect derivation of the divergence of $U^\\top$.",
        "Location": "Page 3, Lemma 2.3, part (1)",
        "Explanation": "In the proof of Lemma 2.3 part (1), the derivation of $\\text{div}_{\\Sigma, \\rho^2 g} U^\\top(x)$ appears to use the identity $\\text{div}_{\\Sigma, g} x^\\top = k$. This identity is only true if $\\Sigma$ is a k-plane through the origin (i.e., $x^\\perp = 0$). The correct identity is $\\text{div}_{\\Sigma, g} x^\\top = k - \\frac{|x^\\perp|^2}{|x|^2}$. Using the correct identity, the expression for $\\text{div}_{\\Sigma, \\rho^2 g} U^\\top(x)$ becomes $1 + \\left( \\frac{(k-1)I(|x|)}{\\rho^k(|x|)|x|^{k+2}} - \\frac{1}{|x|^2} \\right) |x^\\perp|^2$. Fortunately, the subsequent inequality $\\text{div}_{\\Sigma, \\rho^2 g} U^\\top(x) \\leq 1$ still holds with this corrected expression due to condition (C2) on $\\rho$. The condition for equality $\\text{div}_{\\Sigma, \\rho^2 g} U^\\top(x) = 1$ also correctly implies $|x^\\perp|=0$ (unless the coefficient of $|x^\\perp|^2$ is zero, which happens if $\\rho$ is constant and $k=1$, or if $|x|=0$). While the final inequality holds, the erroneous derivation of the explicit formula is a significant flaw in a key lemma."
      },
      {
        "Problem": "Imprecise statement of Lemma 2.5 (singularity of W(x)) for k=2.",
        "Location": "Page 4, Lemma 2.5",
        "Explanation": "Lemma 2.5 states $W(x) = - \\frac{1}{\\rho^k(r)}\\frac{x-y}{|x-y|^k}+o\\left(\\frac{1}{|x-y|^{k-1}}\\right)$. The proof relies on cancellation of $O(1)$ terms. Specifically, the term (I) from $U(x)$ and the regular part of $V(x)$ (term (III), the integral term) are shown to cancel each other's limits as $x \\to y$. However, this cancellation of $O(1)$ terms relies on the integral term in $V(x)$ being non-zero, which is true for $k \\neq 2$. When $k=2$, the integral term (III) is zero. In this case, the $O(1)$ term from $U(x)$, which is $A(x) = \\frac{I(|x|)}{2I(r)\\rho^k(|x|)|x|^k} x \\to \\frac{y}{2\\rho^2(r)r^2}$ as $x \\to y$, does not cancel. Thus, for $k=2$, $W(x) = - \\frac{1}{\\rho^2(r)}\\frac{x-y}{|x-y|^2} + \\frac{y}{2\\rho^2(r)r^2} + o\\left(\\frac{1}{|x-y|}\\right)$. This additional constant term $\\frac{y}{2\\rho^2(r)r^2}$ does not affect the final residue calculation in Equation (5) because its integral over $\\Sigma \\cap \\partial D_\\epsilon(y)$ is $O(\\epsilon^{k-1}) = O(\\epsilon)$ for $k=2$, which vanishes as $\\epsilon \\to 0$. However, the lemma statement as written is inaccurate for $k=2$."
      },
      {
        "Problem": "Incorrect calculation of divergence in 'Further Remarks' section.",
        "Location": "Page 6 (Section 3)",
        "Explanation": "The calculation of $\\text{div}_{\\Sigma, \\tilde{\\rho}^2 g} \\tilde{U}^T$ for the sphere case (where $\\tilde{\\rho}(t) = \\frac{2}{1+t^2}$ and $k=2$) repeats the error from Lemma 2.3 part (1) by implicitly assuming $\\text{div}_{\\Sigma,g} x^T = k$. The paper states $\\text{div}_{\\Sigma, \\tilde{\\rho}^2 g} \\tilde{U}^T = \\frac{1}{\\tilde{\\rho}^2(|x|)} ( 2+ \\langle \\nabla \\tilde{\\rho}(|x|), x^\\top \\rangle_g)$. This should be $\\frac{1}{\\tilde{\\rho}^2(|x|)} ( \\tilde{\\rho}(|x|) \\text{div}_{\\Sigma,g} x^T + \\langle \\nabla \\tilde{\\rho}(|x|), x^\\top \\rangle_g)$. The subsequent derivation leading to $1+|x^\\perp|^2$ is also incorrect. Using the corrected divergence formula (as noted in Problem 2 for Lemma 2.3) yields $\\text{div}_{\\Sigma, \\tilde{\\rho}^2 g} \\tilde{U}^T = 1 + \\frac{|x|^2-1}{2|x|^2} |x^\\perp|^2$. This error undermines the discussion of why the main theorem might not extend to decreasing $\\rho(t)$ using the current proof technique."
      }
    ],
    "token_usage": {
      "input": 9036,
      "thinking": 26439,
      "output": 1821
    }
  },
  {
    "entry_id": 72,
    "retraction_id": "1212.5552v2",
    "paper_id": "1212.5552v1",
    "retraction_comment": "There are signal errors in eqs. (17) to (25)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mischaracterization of the model in the Conclusion section regarding the chemical potential.",
        "Location": "Section 6 (Conclusions), first paragraph.",
        "Explanation": "The Conclusion states: '...chemical potential (acting only on triangle plaquette)'. However, the model defined in Eq. (2) and used for all calculations throughout the paper includes a chemical potential term $-\\mu\\left(\\textbf{n}_{a,i}+\\textbf{n}_{b,i}+\\textbf{n}_{c,i}+\\frac{1}{2}(\\textbf{n}_{d,i}+\\textbf{n}_{d,i+1})\\right)$. This means the chemical potential $\\mu$ acts uniformly on all sites (plaquette sites $a,b,c$ and nodal sites $d$). The calculations, phase diagrams, and specific results like residual entropy values are derived for the model in Eq. (2). If the conclusions are meant for a model where $\\mu$ acts only on the plaquette, then all quantitative results (e.g., values of residual entropy, positions of phase boundaries) presented are incorrect for that model. Conversely, if the results are for the model in Eq. (2) (which they are), then the description of the model in the Conclusion is erroneous. This discrepancy is critical as it misrepresents the system for which the conclusions are drawn."
      }
    ],
    "token_usage": {
      "input": 14199,
      "thinking": 23869,
      "output": 304
    }
  },
  {
    "entry_id": 73,
    "retraction_id": "1612.09148v2",
    "paper_id": "1612.09148v1",
    "retraction_comment": "The second equality in eq. 11 does not hold for the general case. Thus, the conclusion does not follow from the premises and the claim of the paper is not proven",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect symmetry relation asserted in Eq. (10) used to derive the real dynamical matrix.",
        "Location": "Eq. (10), page 2, left column",
        "Explanation": "Eq. (10) states $\\Phi_{i\\alpha}^{i'\\alpha'}(n)=\\Phi_{i'\\alpha'}^{i\\alpha}(n')=\\Phi_{i\\alpha}^{i'\\alpha'}(n')$, where $n'$ refers to the unit cell at position $-\\mathbf{R}_n$. The second part of this equality, $\\Phi_{i'\\alpha'}^{i\\alpha}(n')=\\Phi_{i\\alpha}^{i'\\alpha'}(n')$, is not generally true. In more explicit notation (atom $k$ in cell $L$ is $(L,k)$), this equality translates to $\\Phi_{0i'\\alpha, (-n)i\\alpha} = \\Phi_{0i\\alpha, (-n)i'\\alpha'}$. This would mean the force components are unchanged when swapping the type/position of the first atom (in cell 0) with the type/position of the second atom (in cell $-n$), which is not a general symmetry of force constants. This flawed equality is implicitly used to establish $\\Phi_{i\\alpha}^{i'\\alpha'}(n) = \\Phi_{i\\alpha}^{i'\\alpha'}(-n)$, a key condition for making the dynamical matrix real, thus invalidating the generality of the derivation of Eq. (11) and (12)."
      },
      {
        "Problem": "The conclusion that the dynamical matrix $D(\\mathbf{q})$ is always real (Eq. 12) is incorrect.",
        "Location": "Eq. (12) and surrounding discussion, page 2",
        "Explanation": "The derivation of the real form of $D(\\mathbf{q})$ (Eq. 12) relies on the condition $\\Phi_{i\\alpha}^{i'\\alpha'}(n) = \\Phi_{i\\alpha}^{i'\\alpha'}(-n)$ (i.e., force constants are invariant under inversion of the inter-cell vector $\\mathbf{R}_n$). This condition holds for centrosymmetric crystal structures (where an inversion center maps the crystal onto itself). However, for non-centrosymmetric crystals, this condition is not generally met, and $D(\\mathbf{q})$ is typically complex. The paper's assertion that 'central symmetry of the lattice of unit cells' (a property of all Bravais lattices) is sufficient for this reality is incorrect; it is the centrosymmetry of the entire crystal structure (basis included) that is required."
      },
      {
        "Problem": "The mathematical argument that eigenvectors of a general Hermitian matrix can always be chosen to be real is flawed.",
        "Location": "Page 2, right column, paragraph starting 'Namely, if for non-degenerate eigenvalue $\\lambda$...'",
        "Explanation": "The paper claims that if $A\\mathbf{c}=\\lambda\\mathbf{c}$ for a Hermitian matrix $A$ and complex eigenvector $\\mathbf{c}=\\mathbf{a}+i\\mathbf{b}$, then $A\\mathbf{a}=\\lambda\\mathbf{a}$ and $A\\mathbf{b}=\\lambda\\mathbf{b}$. This property is only true if the matrix $A$ is real. If $A$ (representing $D(\\mathbf{q})$) is a complex Hermitian matrix (as it generally is for non-centrosymmetric crystals), this decomposition is invalid. Therefore, $\\mathbf{a}$ and $\\mathbf{b}$ are not, in general, separately eigenvectors, and $\\mathbf{c}$ cannot typically be made purely real. This error invalidates the paper's 'second derivation' which attempts to prove the reality of $D(\\mathbf{q})$ based on the supposed reality of its eigenvectors."
      },
      {
        "Problem": "The assertion that eigenvectors of the dynamical matrix can always be chosen to be real is an overstatement and misinterprets standard literature.",
        "Location": "Page 2, right column, 'But the set of eigenvectors of the dynamical matrix can be always made real...'",
        "Explanation": "Eigenvectors of the dynamical matrix $D(\\mathbf{q})$ are generally complex if $D(\\mathbf{q})$ itself is complex. This is typically the case for non-centrosymmetric crystals at general $\\mathbf{q}$-vectors. Eigenvectors can be chosen to be real only under specific conditions, such as when $D(\\mathbf{q})$ itself is real (e.g., for centrosymmetric crystals, or at specific high-symmetry points in the Brillouin zone like $\\mathbf{q}=0$). The cited literature (e.g., Born & Huang) does not support the unqualified statement that these eigenvectors can *always* be made real for any $D(\\mathbf{q})$. This incorrect premise is central to the paper's 'second derivation' arguing for the reality of $D(\\mathbf{q})$."
      }
    ],
    "token_usage": {
      "input": 3381,
      "thinking": 15053,
      "output": 1115
    }
  },
  {
    "entry_id": 74,
    "retraction_id": "1205.5450v3",
    "paper_id": "1205.5450v2",
    "retraction_comment": "The paper has been withdrawn due to an error in the maximal norm estimate that we haven't been able to overcome",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 28295,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 75,
    "retraction_id": "1806.09512v2",
    "paper_id": "1806.09512v1",
    "retraction_comment": "The calculations are not strictly correct because the Fermi momenta for protons and neutrons were not scaled correctly",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory treatment of the relativistic effective mass $M^*$: assumed constant per nucleus for scaling, but evidence within the paper suggests it is kinematics-dependent.",
        "Location": "Section II (assumption of constant $m_N^*$ per nucleus), Section IV.D (Figs. 19, 20, Table IV, Eq. 26), Section IV.E (discussion of Fig. Ti48).",
        "Explanation": "The SuSAM* model's core assumption is that a single, constant effective mass $M^*$ (and Fermi momentum $k_F$) per nucleus allows experimental data to collapse onto a universal scaling function $f^*(\\psi^*)$. However, Sections IV.D and IV.E present evidence and arguments that $M^*$ is dependent on energy transfer $\\omega$ or specific kinematics (e.g., $M^*$ for $^{12}$C changing from a global fit value to a different value for JLab kinematics). If $M^*$ is not constant for a given nucleus, the scaling variable $\\psi^*$ is not uniquely defined by a single $M^*$, and the fundamental premise of achieving universal scaling via a constant $M^*$ per nucleus is undermined. The paper acknowledges this as $M^*$ 'favoring an energy dependence' at high momentum transfer, but this is more than an acknowledged limitation if it invalidates the primary fitting assumption for $M^*$."
      },
      {
        "Problem": "The assumption of universal factorization for complex nuclear effects beyond the mean field is not rigorously justified.",
        "Location": "Eq. 4 ($R_K = r_K f^*(\\psi^*)$), Section III (extraction of universal $f^*(\\psi^*)$), Section IV (discussion of data outside bands).",
        "Explanation": "The model assumes that the nuclear response $R_K$ can be factorized into a single-nucleon response $r_K$ (calculated with $M^*$ and $k_F$) and a universal scaling function $f^*(\\psi^*)$. This $f^*(\\psi^*)$ is meant to empirically capture all other nuclear effects (FSI, short-range correlations, MEC components not in $r_K$). While such factorization is inherent in the Relativistic Fermi Gas model, its extension to a phenomenological $f^*(\\psi^*)$ that must universally account for diverse and complex many-body effects across all nuclei (A=2 to 238) and kinematics is a very strong assumption. The paper notes that effects like 'strong final state interactions' can break this factorization, questioning the true universality and the physical basis of $f^*(\\psi^*)$ beyond being a fitting function."
      },
      {
        "Problem": "Potential for methodological bias and circularity in the extraction of the universal scaling function $f^*(\\psi^*)$ and its parameters.",
        "Location": "Section III (Subsections A, B, C describing the iterative fitting and data selection).",
        "Explanation": "The determination of $f^*(\\psi^*)$, its uncertainty band, and the parameters ($M^*, k_F$) involves multiple iterative steps. This includes: initial parameter tuning on specific nuclei, use of 'density criteria' to select 'QE' data (which inherently favors regions of data clustering), and a global fit that maximizes data points within an initially arbitrary fixed width (0.1) around the central $f^*(\\psi^*)$. The final uncertainty band (Band C) is then determined by applying another density criterion to data scaled with globally fitted parameters. This complex, multi-stage procedure, with its data selection and iterative refinement, may guide the analysis towards a self-consistent 'universal' function that is, to some extent, an artifact of the methodology rather than a purely objective feature of the data. This could make the claimed universality less robust."
      },
      {
        "Problem": "The claim of maintained gauge invariance is questionable, especially if $M^*$ is phenomenological or kinematics-dependent.",
        "Location": "Introduction (claim of gauge invariance), Eq. (10) (electromagnetic current definition), Section IV.D and IV.E (evidence for kinematics-dependent $M^*$).",
        "Explanation": "The paper asserts that SuSAM* maintains gauge invariance, an advantage over older models. However, the electromagnetic current in Eq. (10) uses the free nucleon mass $m_N$ in the $F_2$ (Pauli form factor) term, while the Dirac spinors $u_s(\\np)$ incorporate the effective mass $m_N^*$. Such mixing of mass scales in the current operator can be problematic for current conservation ($Q_\\mu J^\\mu = 0$). More critically, $M^*$ is determined phenomenologically by fitting data. If $M^*$ is effectively kinematics-dependent (as suggested in Sec. IV.D, IV.E), ensuring gauge invariance with such an $M^*(\\omega, q)$ within the presented framework is highly non-trivial and likely not satisfied. The paper does not provide a formal proof of current conservation under these conditions."
      }
    ],
    "token_usage": {
      "input": 26133,
      "thinking": 7482,
      "output": 1088
    }
  },
  {
    "entry_id": 76,
    "retraction_id": "2102.11234v2",
    "paper_id": "2102.11234v1",
    "retraction_comment": "In step (3) of the proof of Theorem 1.3. it is claimed that $\\delta^2_{N,N} = 2\\delta$. This is not the only case that can occur and therefore there is a gap in the proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The derivation of Theorem 1.2 (stated as Theorem \\ref{thm:d=3} in the introduction, $g(3,2) \\geq 9$) appears to be flawed.",
        "Location": "Section 2, paragraph 'Numerical experiments', page 5.",
        "Explanation": "The paper presents a numerical example with $g_N^2=9$ and $g_N=6$. Theorem 1.3 (Theorem \\ref{thm:2nb} in text, $g_N^2 \\leq g_N+1$) would imply $g_N \\geq g_N^2-1 = 9-1=8$. This contradicts the paper's claim that this example, in conjunction with other results, establishes $g(3,2) \\geq 9$. The use of Corollary \\ref{cor:structure_max_g2} does not bridge this gap, as the example ($|A_N|=6$) does not satisfy the corollary's condition ($|A_N|=1$) that would apply if $g_N^2=9$ were the true maximum $g^2(3,2)$ and the corollary were true."
      },
      {
        "Problem": "The proof of Theorem 1.3 (stated as Theorem \\ref{thm:2nb} in the introduction, $g_N^2 \\leq g_N+1$) has several unsupported steps and questionable assumptions.",
        "Location": "Section 2, Proof of Theorem \\ref{thm:2nb}, pages 3-4.",
        "Explanation": "The proof relies on Lemma \\ref{lem:hi:part1} for a critical step ($nn_1(N\\alpha)=\\alpha$ if $\\delta^1_{N,N}$ is a new minimum), which itself appears incorrect. Step (1) of the proof ($g^2_N \\leq g^2_{N-1}+1$) does not adequately account for changes in distances for points $i\\alpha, i<N$. Step (2) makes an unsubstantiated claim ($A_{N-1} \\subset A_N$) and its logic is difficult to follow. Step (3) makes specific geometric assumptions (e.g., $\\delta^2_{N,N}=2\\delta$, symmetric point configurations) without justification. These issues undermine the validity of the proof."
      },
      {
        "Problem": "Lemma 2.2 (stated as Lemma \\ref{lem:hi:part1} in text, $h_{1+k}(n+k) = h_1(n)$) seems incorrect as stated or its proof is insufficient.",
        "Location": "Section 2, Lemma \\ref{lem:hi:part1} and its proof, page 2.",
        "Explanation": "The proof of the lemma, which states $h_{1+k}(n+k) = h_1(n)$, relies on a 'pull back' argument. However, the set of candidate neighbors for $(1+k)\\alpha$ in $S_{n+k}$ (indices $\\{-k, \\dots, n-1\\} \\setminus \\{0\\}$) is different from the set for $1\\alpha$ in $S_n$ (indices $\\{1, \\dots, n-1\\}$). This difference is not addressed, making the proof invalid for finite sequences $S_N$. This lemma is described as 'crucial' and used in later proofs (Theorem \\ref{thm:2nb}, Theorem \\ref{thm:1})."
      },
      {
        "Problem": "The recurrence relations for continued fraction denominators and numerators, Equations (2) and (3), are stated incorrectly. The incorrect form for $q_n$ is then used in the 'simple construction' part of Section 3.",
        "Location": "Section 3, page 6 (Eqs. (2), (3)) and page 7 ('A simple construction').",
        "Explanation": "Equations (2) and (3) state $p_n = a_n p_{n-1} + p_{n-1}$ and $q_n = a_n q_{n-1} + q_{n-1}$. The correct recurrences are $p_n = a_n p_{n-1} + p_{n-2}$ and $q_n = a_n q_{n-1} + q_{n-2}$. The 'simple construction' on page 7 explicitly uses the incorrect form $q_i^2 = a_i^2 q_{i-1}^2 + q_{i-1}^2$ (meaning $(a_i^2+1)q_{i-1}^2$). This error invalidates the specific relations derived for $q_i^1, q_i^2$ and Theorem 3.2 (Theorem \\ref{thm:1}) which is based on this construction. Theorem 1.4 (Theorem \\ref{thm:construction:3d}) also relies in part on this 'simple construction'."
      },
      {
        "Problem": "The proofs for theorems claiming $g_N=1$ for infinitely many $N$ (Theorem \\ref{thm:1} and Theorem \\ref{thm:construction:3d}) are unsound.",
        "Location": "Section 3, proof of Theorem \\ref{thm:1} (Theorem 3.2) on page 7, and by extension Theorem \\ref{thm:construction:3d} (Theorem 1.4 / Theorem 3.4).",
        "Explanation": "The argument for $g_N=1$ in Theorem \\ref{thm:1} (Theorem 3.2) relies on Lemma \\ref{lem:hi:part1} to establish that $h_i(N_1) = h_1(N_1)$ for all relevant $i$. As Lemma \\ref{lem:hi:part1} is likely incorrect for finite sequences, this step is invalid. Theorem \\ref{thm:construction:3d} (Theorem 1.4 / Theorem 3.4) combines the 'simple construction' (affected by incorrect CF recurrences, see Problem 4) and the 'more general construction', and its proof also refers to Lemma \\ref{lem:hi:part2} (which seems fine) but the $g_N=1$ property ultimately depends on the argument structure from Theorem \\ref{thm:1} which uses the flawed Lemma \\ref{lem:hi:part1}."
      }
    ],
    "token_usage": {
      "input": 13126,
      "thinking": 22406,
      "output": 1445
    }
  },
  {
    "entry_id": 77,
    "retraction_id": "1303.3756v2",
    "paper_id": "1303.3756v1",
    "retraction_comment": "This paper has been withdrawn by the author because Jarzynski's equality takes also processes into consideration which do not satisfy the 2nd law. Consequently, a modified non-equilibrium thermodynamics has to be developped taking into account the \"anti-irreversible admixtures\"",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The core argument incorrectly assumes that the second law inequality $W_k \\geq \\Delta F$ (work done is greater than or equal to free energy change) holds for every individual microscopic trajectory $k$.",
        "Location": "Section 3.1, derivation of Eq. (26) from Eq. (25), and its use in Section 3.2 to derive Eq. (30) $\\overline{\\exp(-\\beta W)} \\leq \\exp(-\\beta \\Delta F)$.",
        "Explanation": "The derivation of Eq. (26) ($\\Delta F - W_k \\leq 0$) relies on $\\Delta S_{total,k} \\geq 0$ for each trajectory $k$. This is a macroscopic thermodynamic law. Jarzynski's equality, a statistical mechanics result, accounts for fluctuations where individual trajectories can have $W_k < \\Delta F$ (or $\\Delta S_{total,k} < 0$). These 'second law violating' trajectories, though rare, are crucial for the equality $\\overline{\\exp(-\\beta W)} = \\exp(-\\beta \\Delta F)$ to hold. By assuming $W_k \\geq \\Delta F$ for all $k$, the paper incorrectly derives an inequality (Eq. 30) that contradicts Jarzynski's equality for irreversible processes."
      },
      {
        "Problem": "The paper erroneously concludes that Jarzynski's equality is only valid in the reversible limit.",
        "Location": "Section 3.2, sentence 'Consequently, the validity of Jarzynski's equality from a thermodynamical point of view is clear: It is only valid in the reversible limit.' and Section 5, sentence 'for deriving Jarzynski's equality, reversibility must be presupposed'.",
        "Explanation": "Jarzynski's equality is a significant result precisely because it applies to non-equilibrium, irreversible processes. In the reversible limit, where $W_k = \\Delta F$ for all trajectories $k$, Jarzynski's equality becomes the trivial statement $\\exp(-\\beta \\Delta F) = \\exp(-\\beta \\Delta F)$. The paper's conclusion negates the primary utility and meaning of the equality."
      },
      {
        "Problem": "Mischaracterization of the assumptions in Jarzynski's derivation, particularly regarding the system's state during the non-equilibrium process.",
        "Location": "Section 3, paragraph 2 (begins 'Whereas in phenomenological...') stating Jarzynski presupposes the system is in equilibrium during the process, and footnote 5: 'Jarzynski does not consider a general non-equilibrium system, but a thermal fluctuating equilibrium system.'",
        "Explanation": "Jarzynski's derivation requires the system to be in canonical equilibrium *initially*. The subsequent process, driven by changes in an external parameter, explicitly takes the system out of equilibrium. The system is not assumed to remain in equilibrium or follow a canonical distribution during the non-equilibrium evolution. Footnote 5 is misleading; Jarzynski's work is about systems driven out of equilibrium."
      },
      {
        "Problem": "The claim that heat exchange vanishes if the system and controlling heat reservoir initially have the same temperature.",
        "Location": "Section 3, point ii) in the indented list (begins 'if system and controlling heat reservoir have the same (thermostatic) temperature, the heat exchange between them vanishes').",
        "Explanation": "This statement is true only if the system remains in equilibrium with the reservoir. During a non-equilibrium process, the system's state changes, and its effective temperature (if definable) can deviate from the reservoir's temperature, leading to heat exchange. Jarzynski's framework, especially when considering a Hamiltonian for the system plus bath, inherently allows for and describes this heat exchange during the process."
      },
      {
        "Problem": "The assertion that presupposing an initial canonical ensemble implies the process must be reversible.",
        "Location": "Section 5, last sentence ('Also clear is, that by presupposing a canonical ensemble, reversibility follows necessarily').",
        "Explanation": "This is incorrect. The nature of the initial ensemble (e.g., canonical) does not dictate whether the subsequent process is reversible or irreversible. Process reversibility depends on factors like the rate of change of external parameters (requiring a quasi-static change for reversibility). Jarzynski's equality is specifically powerful for irreversible processes that start from an initial canonical equilibrium state."
      }
    ],
    "token_usage": {
      "input": 7746,
      "thinking": 9935,
      "output": 994
    }
  },
  {
    "entry_id": 78,
    "retraction_id": "2002.03104v2",
    "paper_id": "2002.03104v1",
    "retraction_comment": "As pointed out by [REDACTED-NAME] via MO: \"This only shows that there is no trivial, i.e. purely analytic, argument proving that this expression is unbounded. But there might be only finitely many odd perfect numbers, or there might be some relation between n and q, which implies that the ratio is bounded.\"",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The assertion of unboundedness for $S_A = \\frac{\\sigma(q^2)}{n}+\\frac{\\sigma(n)}{q^2}$ is inadequately justified and its application in the paper's core argument is logically flawed.",
        "Location": "Section 3, Preliminaries, (1); and its use in Preliminaries (4a,b,c), Theorem 1, Theorem 3, and the final Theorem in Section 4.1.",
        "Explanation": "The paper states that $S_A = \\frac{\\sigma(q^2)}{n}+\\frac{\\sigma(n)}{q^2}$ is not expected to be bounded from above, drawing an analogy to the function $f(z) = z + 1/z$. This assertion of unboundedness is critical, as it's used to create contradictions throughout the paper. However, this unboundedness is not rigorously proven. More importantly, if there are only finitely many odd perfect numbers (OPNs) – the hypothesis the main theorem attempts to refute – then $q$ and $n$ would be bounded. Consequently, $z = q^2/n$ could only take a finite number of values, implying $S_A$ must be bounded. Thus, the assumption of finitely many OPNs inherently implies that $S_A$ is bounded. The paper's strategy is to show that this assumption leads to $S_A$ being bounded, and then claim this contradicts the ( inadequately justified) general unboundedness of $S_A$. This is a circular argument or relies on an unproven premise. If the unboundedness of $S_A$ itself depends on there being infinitely many OPNs, the argument becomes circular: assuming infinitely many OPNs to prove a property (unbounded $S_A$) which is then used to show there are infinitely many OPNs. This fundamental flaw invalidates the paper's main conclusion and most of its intermediate results."
      },
      {
        "Problem": "The second biconditional in Corollary 2 is mathematically false.",
        "Location": "Section 4, Corollary 2.",
        "Explanation": "Corollary 2 states: 'If $q^k n^2$ is an odd perfect number with special prime $q$, then the biconditionals $q^2 < n \\iff \\sigma(q^2) < \\sigma(n) \\iff \\frac{\\sigma(q^2)}{n} < \\frac{\\sigma(n)}{q^2}$ hold.' The second biconditional, $\\sigma(q^2) < \\sigma(n) \\iff \\frac{\\sigma(q^2)}{n} < \\frac{\\sigma(n)}{q^2}$, can be rewritten as $A < B \\iff A/n < B/q^2$, where $A=\\sigma(q^2)$ and $B=\\sigma(n)$. This is equivalent to $A < B \\iff Aq^2 < Bn$. This general statement is false. For a counterexample, let $A=2, B=3, q^2=10, n=1$. Then $A<B$ (i.e., $2<3$) is true. However, $Aq^2 < Bn$ (i.e., $2 \\cdot 10 < 3 \\cdot 1$, or $20 < 3$) is false. Thus, the biconditional does not hold. While this corollary might not be directly essential for the paper's ultimate conclusion, it is presented as a main result and is incorrect."
      }
    ],
    "token_usage": {
      "input": 4073,
      "thinking": 18495,
      "output": 791
    }
  },
  {
    "entry_id": 79,
    "retraction_id": "1401.5295v2",
    "paper_id": "1401.5295v1",
    "retraction_comment": "This paper has been withdrawn due to non-inclusion of some terms in equation 16",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The mean-field Hamiltonian used does not correspond to the original interaction term.",
        "Location": "Section III, Eq. 1 and Eq. 11 (and associated self-consistency Eqs. 12-13).",
        "Explanation": "The original Hamiltonian (Eq. 1) specifies a nearest-neighbor density-density interaction $V\\sum_{\\langle ij \\rangle}n_i n_j$. However, the mean-field Hamiltonian $H_{MF}$ (Eq. 11), derived using self-consistency conditions in Eqs. 12-13, effectively decouples an interaction of the form $-V \\sum_{\\langle ij \\rangle} |c_i^\\dagger e^{iA_{ij}} c_j|^2$ (a bond-operator interaction), not $V\\sum n_i n_j$. Standard Hartree-Fock decoupling of $n_i n_j$ yields different terms (Hartree site energy shifts and Fock exchange/hopping renormalizations). This fundamental mismatch means the entire analysis addresses a different physical interaction than stated, potentially invalidating all conclusions for the intended model."
      },
      {
        "Problem": "Contradictory and confusing characterization of current patterns.",
        "Location": "Section IV.A, discussion around Eq. 17 and Fig. 6 (especially Fig. 6b).",
        "Explanation": "The paper states that for phase PH1, all bond currents $\\mathscr{J}_{ij}$ (defined in Eq. 17 as proportional to the mean-field parameter $J_{ij}$) are zero. This implies $J_{ij}=0$. However, Fig. 6b depicts non-zero circulating plaquette currents $\\mathcal{J}$ for this same phase PH1. If all bond currents are zero, any current integrated around a closed loop (like a plaquette) must also be zero. Thus, $\\mathcal{J}$ should be zero. Furthermore, the definition relating plaquette current $\\mathcal{J}_{\\alpha}$ to bond current $\\mathscr{J}_{\\alpha}$ via $\\mathcal{J}_{\\alpha}=\\mathscr{J}_{\\alpha}+\\mathcal{J}_{\\alpha+1}$ is unconventional and unclear. These inconsistencies undermine the physical interpretation and characterization of the phases."
      },
      {
        "Problem": "Inconsistent mathematical description of mean-field hopping parameters.",
        "Location": "Section III, Eqs. 11, 14, and 15.",
        "Explanation": "The paper introduces mean-field parameters $\\chi_{ij}$ (Eq. 14) and effective hopping $t'_{ij}$ (Eq. 15). Substituting Eq. 14 into Eq. 15 gives $t'_{ij} = te^{iA_{ij}}(1 - \\epsilon_{ij} + iJ_{ij})$. However, the mean-field Hamiltonian $H_{MF}$ presented in Eq. 11 implies that the coefficient of the term $c_i^\\dagger e^{iA_{ij}} c_j$ is $(t+\\epsilon_{ij}+J_{ij})$. These two expressions for the effective hopping, $te^{iA_{ij}}(1 - \\epsilon_{ij} + iJ_{ij})$ and $(t+\\epsilon_{ij}+J_{ij})e^{iA_{ij}}$, are not generally equivalent. This points to an internal inconsistency in the formulation or presentation of the mean-field theory itself."
      },
      {
        "Problem": "Incorrect claim regarding particle-hole symmetry of the interacting Hamiltonian.",
        "Location": "Section II.C, discussion of Eq. 1.",
        "Explanation": "It is stated that the interacting Hamiltonian given by Eq. 1 is invariant under particle-hole transformation at half-filling. This is incorrect. While the non-interacting part of the Hamiltonian ($H_0$) possesses particle-hole symmetry, the nearest-neighbor interaction term $V\\sum_{\\langle ij \\rangle}n_in_j$ explicitly breaks this symmetry, even at half-filling. This is a factual error concerning a fundamental symmetry of the model Hamiltonian."
      }
    ],
    "token_usage": {
      "input": 15389,
      "thinking": 14818,
      "output": 913
    }
  },
  {
    "entry_id": 80,
    "retraction_id": "1402.6435v2",
    "paper_id": "1402.6435v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in page 20",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Proposition 5.1 appears to contain a fundamental error in the argument for the one-dimensional case, which is the base of an induction.",
        "Location": "Page 10, Proof of Proposition 5.1, the Claim for the one-dimensional case.",
        "Explanation": "Proposition 5.1 is crucial for Corollary 5.2, which in turn is essential for proving the main result Theorem 5.3 (specifically, (c) implies (a)). The proof of Proposition 5.1 proceeds by induction on dimension. In the base case (dim X = 1), the argument relies on constructing an effective adelic $\\RR$-divisor $\\overline{D}_{new} = \\overline{D}+\\delta(\\overline{A}+\\widehat{(\\phi)})$ and claiming that $\\mult_x(D_{new})=0$, where $D_{new} = D+\\delta(A+(\\phi))$. Here, $\\overline{D}$ is an effective adelic $\\RR$-divisor with $\\mult_x(D)=\\delta > 0$, and $\\overline{A}+\\widehat{(\\phi)}$ is also an effective adelic $\\RR$-divisor where $\\phi \\in H^0(X, \\mathcal{O}_X(A)\\otimes\\mathcal{I})$ (so $\\phi$ vanishes at $x$). If $D$ is effective, $A+(\\phi)$ is effective, and $\\delta > 0$: then $D_{new}$ is an effective $\\RR$-divisor. Its multiplicity at $x$ is $\\mult_x(D_{new}) = \\mult_x(D) + \\delta \\mult_x(A+(\\phi))$. Since $\\mult_x(D) = \\delta > 0$ and $\\mult_x(A+(\\phi)) \\ge \\mult_x(A)+1 \\ge 1$ (assuming $\\mult_x(A) \\ge 0$), it follows that $\\mult_x(D_{new}) \\ge \\delta + \\delta \\cdot 1 = 2\\delta > 0$. Thus, $\\mult_x(D_{new})$ cannot be zero. The subsequent argument $h_{\\overline{D}_{new}}(x) \\ge 0$ relies on $x \\notin \\Supp(D_{new})$ (which is equivalent to $\\mult_x(D_{new})=0$ for an effective divisor). If this step is incorrect, Proposition 5.1 is not proven, which may invalidate Corollary 5.2 and parts of Theorem 5.3 and Theorem A."
      }
    ],
    "token_usage": {
      "input": 33159,
      "thinking": 21135,
      "output": 587
    }
  },
  {
    "entry_id": 81,
    "retraction_id": "2210.17003v2",
    "paper_id": "2210.17003v1",
    "retraction_comment": "The main theorems of the paper (Theorem 13 and 17) are wrong. The statements are only valid in R^2",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The argument that the circumcenter $C_T(x)$ is $0$ when $x, R_A(x), R_B(R_A(x))$ are distinct is flawed.",
        "Location": "Proof of Theorem 2.10, page 4, paragraph starting \"If the cardinality of $\\{x, y, z\\}$ is 3...\"; also affects case (i)(b) on page 5, and subsequent arguments relying on this conclusion in cases (ii) and (iii).",
        "Explanation": "The proof states that if $x, y=R_A(x), z=R_B(R_A(x))$ are distinct, then $C_T(x)=0$ because $\\|x\\|=\\|y\\|=\\|z\\|$. While $0$ is equidistant from $x,y,z$ under this condition, for $0$ to be the circumcenter, $0$ must also lie in the affine hull of $x,y,z$. This means $x,y,z$ must be linearly dependent. This linear dependence is not proven for general closed convex cones $A, B$ and may not hold (e.g., counterexamples can be constructed in $\\mathbb{R}^3$). If $x,y,z$ are linearly independent, then $C_T(x) \\neq 0$. This invalidates the claim that $C_T(x)=0$ in this case, and consequently, the branches of the proof relying on this step do not correctly establish convergence to $0 \\in A \\cap B$. This undermines the overall claim of convergence in at most three steps."
      },
      {
        "Problem": "The application of Theorem 2.10 to prove finite convergence for polyhedral sets (Theorem 3.4) is unsound.",
        "Location": "Proof of Theorem 3.4, page 6, particularly the step invoking Theorem 2.10 (Theorem \\ref{main}).",
        "Explanation": "Theorem 3.4 argues that for $x_n$ sufficiently close to $x^* \\in A \\cap B$, the problem is equivalent to finding a point in $A' \\cap B'$, where $A' = ((A \\cap B_r(x^*)) - x^*)$ and $B' = ((B \\cap B_r(x^*)) - x^*)$. Theorem 2.10, which is about closed convex cones, is then applied to $A'$ and $B'$. However, $A'$ and $B'$ are generally not cones. They are intersections of cones with a ball $B_r(0)$ (i.e., $A' = T_A(x^*) \\cap B_r(0)$ and $B' = T_B(x^*) \\cap B_r(0)$, where $T_A(x^*), T_B(x^*)$ are tangent cones). Reflections with respect to such truncated sets (like $A'$ and $B'$) do not generally preserve norm. Specifically, Lemma 2.8 (which states $\\langle p, x-p \\rangle = 0$ for $p=P_C(x)$) relies on $C$ being a cone (such that $2p \\in C$ if $p \\in C$). This property fails for $A'$ and $B'$ if they are bounded. Consequently, Corollary 2.9 (norm preservation of reflections) also fails for $A'$ and $B'$. Thus, the fundamental conditions for Theorem 2.10 are not met by $A'$ and $B'$, making its application invalid."
      }
    ],
    "token_usage": {
      "input": 6465,
      "thinking": 19294,
      "output": 798
    }
  },
  {
    "entry_id": 82,
    "retraction_id": "1503.00700v2",
    "paper_id": "1503.00700v1",
    "retraction_comment": "This preprint was withdrawn because the theoretical discussion of the inferred temperature of qubit couplers assumes an equilibrium distribution, which is not the case during the annealing cycles",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Physical Validity and Oversimplification of the J_ij Correction Model",
        "Location": "Section IV, Eq. (7) (eq:j-expectation), and discussion around Fig. 5 (qq-boltzmann)",
        "Explanation": "The model used to derive J_ij offsets (Eq. 7) treats qubit pairs as independent two-level systems. This is a significant oversimplification, as qubits are part of an interconnected network, and the paper acknowledges this model is not 'physically valid' for coupled qubits. Consequently, the derived J_0l offsets may not represent actual systematic hardware biases but rather artifacts of fitting an inadequate model to complex system behavior, especially since the fitted temperature T_l is acknowledged to be non-physical. This questions the reliability and fundamental interpretation of the J_ij corrections."
      },
      {
        "Problem": "Neglect of Interdependencies between h_i and J_ij Offsets during Calibration",
        "Location": "Section III (Eq. 4, eq:h-expectation), Section IV (Eq. 7, eq:j-expectation), and Section V",
        "Explanation": "The method calibrates h_i offsets assuming programmed J_ij are zero (and vice-versa for J_ij offsets). However, if intrinsic offsets exist for both h_i and J_ij simultaneously, the calibration for one type of parameter will be confounded by the uncorrected offsets of the other type. For example, the h_i offset calculation (Eq. 4) ignores the influence of any true J_0,ij offsets, potentially leading to inaccurate h_0i values. This mutual influence is not fully addressed by the proposed sequential correction, potentially limiting the accuracy of the derived offsets."
      },
      {
        "Problem": "Assumption of Thermal Equilibrium for a Non-Equilibrium Device",
        "Location": "Section III (Eq. 4, eq:h-expectation), Section IV (Eq. 7, eq:j-expectation)",
        "Explanation": "The calibration relies on fitting experimental data to Boltzmann distributions, which describe systems in thermal equilibrium. Quantum annealers are dynamic systems not guaranteed to reach thermal equilibrium. While this assumption might be approximated for h_i calibration (yielding a T_i close to physical temperature), it's acknowledged as problematic for J_ij calibration (where fitted T_l is non-physical). If the QAC's output statistics do not follow a Boltzmann distribution, extracting 'offsets' based on this assumption may not reflect true hardware errors but rather model-dependent parameters, limiting their fundamental validity."
      },
      {
        "Problem": "Lack of Validation on Non-Null Problems",
        "Location": "Section VI (Conclusions and Recommendations)",
        "Explanation": "The calibration method's effectiveness is demonstrated only for the 'null problem' (all programmed h_i=0, J_ij=0). There is no experimental evidence showing these null-problem-derived corrections improve performance for any actual (non-null) optimization problems. The paper acknowledges this ('Predicting how well a correction... apply to other applications it not possible...'), yet draws general conclusions about the method's utility. The effectiveness for general problems, where h_i and J_ij are non-zero and varied, remains speculative, which is a critical gap for a calibration technique intended for general use."
      },
      {
        "Problem": "Potential Insufficiency of Data for Robust Parameter Fitting",
        "Location": "Section III (description of h-sweep and fitting), Section IV (description of J-sweep and fitting)",
        "Explanation": "The offsets h_0i and J_0l are determined by fitting two-parameter models (Eqs. 4 and 7) to only 10 data points from sweeps. Given the inherent stochasticity of QAC outputs, using such a small number of data points for each of the ~500 h_i fits and ~1500 J_ij fits may lead to offset parameters with considerable uncertainty. The paper does not analyze the precision of these individual fitted parameters, making it difficult to assess the robustness and reliability of the derived corrections."
      }
    ],
    "token_usage": {
      "input": 12843,
      "thinking": 6446,
      "output": 902
    }
  },
  {
    "entry_id": 83,
    "retraction_id": "1202.1896v2",
    "paper_id": "1202.1896v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical mistake in the circle graph algorithm",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Algorithm's reliance on \"optimal\" black-and-white coloring (BWC).",
        "Location": "Lemma 1 (page 2), and its use for Theorem 1 (permutation graphs, pages 2-3) and circle graphs (page 4, paragraph 3).",
        "Explanation": "The algorithms for both permutation and circle graphs are based on a structural property described in Lemma 1. The proof of Lemma 1 explicitly assumes the existence of an 'optimal' BWC, where every uncolored vertex must have both a black and a white neighbor. The original BWC problem definition does not require this optimality. If a graph instance admits a BWC but does not admit such an 'optimal' BWC, the structural property derived from Lemma 1 may not hold, and thus the algorithms might fail to find a valid BWC or incorrectly report that none exists. The paper does not demonstrate that any BWC implies an 'optimal' BWC or that Lemma 1 holds for non-'optimal' BWCs."
      },
      {
        "Problem": "Fixed coloring of region R in the circle graph algorithm.",
        "Location": "Section 3, Theorem 2 proof, description of table contents, item (c) (page 5).",
        "Explanation": "In the dynamic programming approach for circle graphs, the state description includes a region $R$ (defined relative to a chain of scanlines $\\Delta$). Item (c) of the table contents states: 'A number $r$ which indicates the number of vertices in $R$. ... All the vertices of $R$ are colored black.' This implies that the algorithm only considers scenarios where this region $R$ is entirely black. A valid BWC might require vertices in $R$ to be white, uncolored, or a mix, which would necessitate further decomposition. By fixing the color of $R$ to black, the algorithm explores only a restricted subset of possible colorings and may fail to find a solution even if one exists."
      },
      {
        "Problem": "Potentially incorrect geometric observation in circle graph algorithm.",
        "Location": "Section 3, Theorem 2 proof, paragraph before table description (page 5).",
        "Explanation": "The paper states an 'important observation' for the circle graph algorithm: 'each chord that crosses $s^{\\prime}$ crosses at most one other scanline of $\\Delta$' (where $s'$ is the maximal scanline in a chain $\\Delta$). This observation appears to be incorrect for a general chain $\\Delta$ of non-crossing scanlines in a circle diagram. A chord crossing $s'$ can, in fact, cross multiple other scanlines in $\\Delta$. If this observation is false, the DP state, particularly item (d) which relies on this count, and the subsequent logic for handling uncolored vertices are likely flawed, potentially leading to an incorrect algorithm."
      },
      {
        "Problem": "Unsubstantiated polynomial time claim for circle graphs due to potentially exponential DP states.",
        "Location": "Section 3, Theorem 2 proof, description of table contents, item (b) (page 5), and general complexity claim.",
        "Explanation": "The dynamic programming state for circle graphs is, in part, characterized by 'a scanline $s^{\\prime}$ which indicates the maximal element of some chain $\\Delta$ in the $\\prec_2$ order' (item b). The paper does not specify how these chains $\\Delta$ are managed or bounded. The number of possible chains $\\Delta$ ending at a given scanline $s'$ can be exponential in the number of vertices or scanlines. If each such chain corresponds to a distinct DP state or requires separate computation, the total number of states or the work per state could become exponential. The paper claims a polynomial-time algorithm but does not provide sufficient detail to confirm that these chains $\\Delta$ can be handled in polynomial time, making the complexity claim unsubstantiated."
      }
    ],
    "token_usage": {
      "input": 6404,
      "thinking": 14834,
      "output": 853
    }
  },
  {
    "entry_id": 84,
    "retraction_id": "1304.5962v2",
    "paper_id": "1304.5962v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Non-standard definition of $d_2$ in the Black-Scholes formula and its impact on the equation for $\\tau^*$.",
        "Location": "Page 5, Remark at the end of Section 2",
        "Explanation": "The paper defines $d_2(S,\\tau)=\\frac{\\log \\frac{S}{K}-(r+\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}}$. The standard Black-Scholes $d_2$ is $d_1 - \\sigma\\sqrt{\\tau} = \\frac{\\log \\frac{S}{K}+(r-\\sigma^2/2)\\tau}{\\sigma \\sqrt{\\tau}}$. The paper's $d_2$ implies that the term $(r-\\sigma^2/2)$ is replaced by $-(r+\\sigma^2/2)$. This non-standard $d_2$ is then used to define $v^E(S,\\tau)$ and subsequently the equation for $\\tau^*$: $v^E(K,\\tau^*)=\\delta$. Specifically, the equation $\\frac{\\delta}{K}=N(\\frac{r+\\sigma^2/2}{\\sigma}\\sqrt{\\tau^*})-e^{-r\\tau^*}N(-\\frac{r+\\sigma^2/2}{\\sigma }\\sqrt{\\tau^*})$ is derived. This equation is only consistent with the standard Black-Scholes formula if $r=0$. If the standard $v^E$ is intended (as suggested by citing Black-Scholes 1973), then this definition of $d_2$ and the resulting equation for $\\tau^*$ are incorrect for $r \\neq 0$. This error is critical as $\\tau^*$ is a fundamental parameter in the model."
      },
      {
        "Problem": "Incorrect formula for Theta (option price sensitivity to time) used in Newton's method for $\\tau^*$.",
        "Location": "Page 5, Remark at the end of Section 2, equation for $\\frac{\\partial v^{E}_{K=1}(K,\\tau)}{\\partial \\tau}$",
        "Explanation": "The paper provides a formula for $\\frac{\\partial v^{E}_{K=1}(K,\\tau)}{\\partial \\tau}$ (Theta) to be used in Newton's method for finding $\\tau^*$. The formula given is $\\frac{\\partial v^{E}_{K=1}(K,\\tau)}{\\partial \\tau}=-\\frac{n(d_1(\\tau))\\sigma}{2\\sqrt{\\tau}}-re^{-r\\tau}N(d_2(\\tau))+N(d_1(\\tau))$. The standard Black-Scholes Theta (derivative with respect to time $t$, so $\\frac{\\partial v^E}{\\partial \\tau} = -\\Theta_{BS}$) for $S=K$ is $K n(d_1(K,\\tau)) \\frac{\\sigma}{2\\sqrt{\\tau}} + r K e^{-r\\tau} N(d_2(K,\\tau)) - rK N(d_1(K,\\tau))$. The paper's formula (with $K=1$) has a term $N(d_1(\\tau))$ instead of $rN(d_1(\\tau))$. This error would lead to incorrect calculation of $\\tau^*$ using the proposed Newton's method."
      },
      {
        "Problem": "Incorrect solution provided for the heat equation on a quarter-plane in Lemma 3.1.",
        "Location": "Page 6, Lemma 3.1",
        "Explanation": "Lemma 3.1 presents a solution for $u_t=c^2u_{xx}$ with $u(x,0)=k$ and $u(0,t)=f(t)$. The solution is given as $u(x,t)=k\\mathrm{erfc}(\\frac{x}{2c\\sqrt{t}})+\\frac{x}{2c\\sqrt{t}}\\int_0^t f(t-\\tau)\\frac{e^{-\\frac{x^2}{4c^2\\tau}}}{\\tau^{3/2}}d\\tau$. The standard solution involves $k \\cdot \\mathrm{erf}(\\frac{x}{2c\\sqrt{t}})$ (or an equivalent formulation like $k + \\int (f(t-\\tau)-k)(\\dots) d\\tau$) for the initial condition term. More critically, the integral term representing the influence of the boundary condition $f(t)$ is missing a $\\sqrt{\\pi}$ factor in the denominator. The correct term should be $\\int_0^t f(t-\\tau) \\frac{x}{2c\\sqrt{\\pi \\tau^3}} e^{-\\frac{x^2}{4c^2\\tau}}d\\tau$. Since this lemma is directly used to derive the main pricing formula (Theorem 3.1), this error invalidates the final result."
      },
      {
        "Problem": "Multiple errors in the derived formula for $\\varepsilon(S,\\tau)$ in Theorem 3.1.",
        "Location": "Page 7, Theorem 3.1, Eq. (\\ref{eq:callback value}) for $S \\neq K$",
        "Explanation": "The formula for $\\varepsilon(S,\\tau)$ (the 'callback value') for $S \\neq K$ appears to have several errors, likely stemming from the incorrect application of Lemma 3.1 and errors in the transformation steps: \n1. Missing factor of $S^{-b}$: The pre-integral factor should likely be $(S/K)^{-b} = S^{-b}K^b$ based on standard transformations, but the formula only shows $K^b$. \n2. Incorrect $\\sqrt{\\tau-\\tau^*}$ term: The denominator outside the integral contains $\\sqrt{2\\sigma^2(\\tau-\\tau^*)}$. The term $\\sqrt{\\tau-\\tau^*}$ should not appear here; the time dependence in the fundamental solution is typically within the integral as $s^{-3/2}$. \n3. Incorrect exponential term in the integral: The term $e^{-a(\\tau-s)}$ inside the integral, where $s$ is the integration variable and $\\tau$ is the current time to maturity, is likely incorrect. Standard transformations usually result in $e^{-as}$. \n4. Missing $\\sqrt{\\pi}$ factor: Carried over from the error in Lemma 3.1, the formula is missing $\\sqrt{\\pi}$ in the denominator. These errors make the central pricing formula incorrect."
      },
      {
        "Problem": "Inconsistent formula for $\\varepsilon(K,\\tau)$ at $S=K$ in Theorem 3.1.",
        "Location": "Page 7, Theorem 3.1, Eq. (\\ref{eq:callback value}), case $S=K$",
        "Explanation": "For $S=K$, the formula states $\\varepsilon(K,\\tau) = v^E(K,\\tau-\\tau^*)-\\delta$. However, by definition in Eq. (\\ref{eq:cb2}), $\\varepsilon(K,\\tau) = v^E(K,\\tau)-\\delta$. Furthermore, Eq. (\\ref{eq:cb3}) states $\\varepsilon(S,\\tau^*)=0$, which implies $\\varepsilon(K,\\tau^*)=0$. The paper's formula for $S=K$ gives $\\varepsilon(K,\\tau^*) = v^E(K,0)-\\delta = (K-K)^+ - \\delta = -\\delta$. This contradicts $\\varepsilon(K,\\tau^*)=0$ unless $\\delta=0$. The condition $v^E(K,\\tau^*)=\\delta$ (definition of $\\tau^*$) means that $\\varepsilon(K,\\tau^*) = v^E(K,\\tau^*) - \\delta = 0$. The formula provided for $S=K$ in Eq. (\\ref{eq:callback value}) is therefore inconsistent with the problem setup and initial/boundary conditions for $\\varepsilon$."
      }
    ],
    "token_usage": {
      "input": 9193,
      "thinking": 19777,
      "output": 1825
    }
  },
  {
    "entry_id": 85,
    "retraction_id": "1908.07349v3",
    "paper_id": "1908.07349v2",
    "retraction_comment": "the results of theorem 2 is not correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Problematic general formulas for Faber polynomials related to inverse function coefficients.",
        "Location": "Section 2, primarily eq. (2.4) and the unnumbered multi-line expansion of $\\mathcal{K}_{n-1}^{-n}$ following eq. (2.5). Also affects eq. (2.3).",
        "Explanation": "The paper defines Faber polynomials $\\mathcal{K}_n^p$ (eq. (2.4)) and provides an explicit expansion for $\\mathcal{K}_{n-1}^{-n}$ (used for coefficients $A_n$ of the inverse function $g=f^{-1}$). These formulas involve terms with factorials of negative integers, such as $(-n)!$ or $1/(-m)!$ in coefficients like $\\frac{-n!}{(-2n+1)!(n-1)!}$. Standard interpretation via the Gamma function would make these terms undefined or infinite. Without a clear, alternative definition or interpretation (e.g., specific conventions for generalized binomial coefficients), these formulas are mathematically unsound as presented, undermining the general framework for $A_n$ calculations."
      },
      {
        "Problem": "Incorrect or misidentified polynomial expansion for composite functions.",
        "Location": "Section 2, eq. (2.17) and its use in eq. (2.15), (2.16), (2.18), (2.19).",
        "Explanation": "The polynomials $\\mathcal{K}_k^p(\\rho_1, \\dots, \\rho_k; B_1, \\dots, B_k)$ defined in eq. (2.17) are used for the expansion of $\\varphi(u(z))$, where $u(z)$ is a Schwarz function and $\\varphi(z)$ defines the class. This formula (2.17) also suffers from ill-defined factorials (e.g., for $p=1, k=2$, the term $\\frac{1!}{(-1)!2!}$ appears). More importantly, for $p=1$, it does not correctly reproduce the known coefficients of the composite function $\\varphi(u(z)) = 1 + B_1 c_1 z + (B_1 c_2 + B_2 c_1^2) z^2 + \\dots$. For instance, $\\mathcal{K}_2^1$ derived from (2.17) (if interpretable) would not be $c_2 + (B_2/B_1)c_1^2$. Additionally, these polynomials are related to coefficients of function composition (often Bell polynomials or Faa di Bruno's formula coefficients), not Faber polynomials in their typical application in univalent function theory (which are usually associated with the inverse function or powers of the function itself)."
      },
      {
        "Problem": "Inconsistent application of signs in the derivation of coefficient estimates.",
        "Location": "Section 3, specifically the transition from the general setup (eq. (2.15), (2.18)) to specific coefficient calculations (eq. (2.28), (2.30)).",
        "Explanation": "Equation (2.15) introduces a minus sign in the expansion of $\\varphi(u(z))$, stating $\\varphi(u(z))=1-\\sum_{n=1}^{\\infty}B_1 \\mathcal{K}_{n}^{1}(c_1,...,c_n;B_1,...,B_n)z^n$. This sign is carried forward to eq. (2.18), which states $\\frac{1+(n-1)(\\lambda+n\\delta)}{\\tau}a_n=-B_{1}\\mathcal{K}_{n-1}^{-1}(c_1,...,c_{n-1};B_1,...,B_{n-1})$ (note: $\\mathcal{K}^{-1}_{n-1}$ here seems to be a typo for $\\mathcal{K}^{1}_{n-1}$ from context of $\\varphi(u(z))$ expansion). However, when specific coefficients are equated for Theorem 3.2, this minus sign is dropped without explanation. For example, eq. (2.28) is $\\frac{1+\\lambda+2\\delta}{\\tau}a_2=B_{1}c_{1}$, not $-B_1 c_1$ (assuming $\\mathcal{K}_1^1=c_1$). If the polynomial $\\mathcal{K}_k^1$ itself were to contribute a compensating minus sign, this is not shown or justified by its definition (2.17). This inconsistency makes the derivation steps for Theorem 3.2 difficult to follow and verify against the paper's own general framework."
      }
    ],
    "token_usage": {
      "input": 13211,
      "thinking": 20166,
      "output": 1051
    }
  },
  {
    "entry_id": 86,
    "retraction_id": "1310.0331v4",
    "paper_id": "1310.0331v3",
    "retraction_comment": "this paper has been withdrawn by the author due to a crucial error in equation 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of Fractional Statistics and its Origin",
        "Location": "Section II, paragraph 1, and throughout Section II",
        "Explanation": "The paper claims that a system of fermions with the proposed pairwise entanglement (Eq. 1) obeys fractional statistics, defining this by the filling factor (e.g., v=2/M for two particles). This is a non-standard definition of fractional statistics, which typically refers to anyonic exchange phases. The wave function in Eq. (1) is explicitly antisymmetric, indicating the particles remain fermions. While Laughlin states (known to involve fractional statistics of quasiparticles) are later discussed, the paper does not derive anyonic exchange statistics from the proposed entanglement structure of the constituent fermions. It seems to conflate a low filling factor with fractional exchange statistics and incorrectly suggests the described pairwise entanglement of fermions is its direct cause."
      },
      {
        "Problem": "Misleading Interpretation of 'Pairwise Entanglement' in N-particle Laughlin States",
        "Location": "Section II, specifically discussions around Eq. (5) and Eq. (7)",
        "Explanation": "The paper asserts that Laughlin states for N>2 particles can be expressed as a sum of terms where 'every two fermions... are entangled' or 'two and only two fermions are entangled' in each term (e.g., Eq. 5). This decomposition, like $\\Psi_i(A)[\\Psi_j(B)\\Psi_k(C)-\\Psi_k(C)\\Psi_j(B)]$, shows one particle in a product state with an antisymmetrized pair. This is not a standard representation of 'pairwise entanglement between every two fermions' in an N-particle system. Laughlin states possess genuine N-partite entanglement, which is oversimplified and potentially misrepresented by this specific interpretation of 'pairwise' structure. The claim of revealing the 'explicit entanglement pattern' of Laughlin states this way is questionable."
      },
      {
        "Problem": "Unphysical Ad-hoc Constraint for Modifying Bose-Einstein/Fermi-Dirac Statistics",
        "Location": "Section III, paragraph 1, and derivation of Eqs. (10)-(15)",
        "Explanation": "The modification to BE/FD statistics is based on the assumption that entanglement between particles in levels $\\epsilon_i$ and $\\epsilon_{i+1}$ implies $n_i = n_{i+1}$ (number of particles in level $i$ equals that in $i+1$). This strict equality is then imposed directly as a constraint on the summation variables in the grand canonical partition function. This is an ad-hoc restriction of the state space, not derived from a microscopic model of entanglement. Standard GCE sums over independent $n_k$. The physical basis for how entanglement enforces this exact equality on particle numbers *before* statistical averaging is absent, making the foundation of the modified statistics unsound."
      },
      {
        "Problem": "Incorrect Claim About Recovering Standard Results at T=0 for Modified Boson Statistics",
        "Location": "Section III, paragraph after Eq. (12)",
        "Explanation": "The paper states that for bosons, 'when we choose the zero temperature limit we see that the results recovers the results without entanglement.' This is incorrect. Standard Bose-Einstein condensation occurs into the single lowest energy level $\\epsilon_{min}$. In the modified system (Eq. 12), condensation would occur into a *pair* of levels $(\\epsilon_k, \\epsilon_{k+1})$ (for odd $k$) that minimizes the sum $\\epsilon_k + \\epsilon_{k+1}$. The chemical potential and the nature of the condensate ground state are fundamentally different from the standard case. This indicates a misunderstanding of the low-temperature implications of the proposed model."
      },
      {
        "Problem": "Lack of Rigorous Derivation Linking Proposed Entanglement Structures to Claimed Statistical Consequences",
        "Location": "General, but particularly Sections II and III",
        "Explanation": "The paper asserts connections between specific entanglement configurations and resulting statistical properties (fractional statistics in Sec. II, modified BE/FD distributions in Sec. III) without providing rigorous derivations. In Section II, 'fractional statistics' is not derived from exchange properties but asserted based on filling factors and an algebraic decomposition of Laughlin states. In Section III, modified distributions stem from an assumed consequence of entanglement ($n_i=n_{i+1}$) rather than being derived from a physical model of how entanglement alters the ensemble or particle interactions. The deductive steps linking the entanglement premises to the statistical conclusions are often missing or based on non-standard definitions/assumptions, weakening the paper's central thesis."
      }
    ],
    "token_usage": {
      "input": 6575,
      "thinking": 6505,
      "output": 1010
    }
  },
  {
    "entry_id": 87,
    "retraction_id": "2308.02854v2",
    "paper_id": "2308.02854v1",
    "retraction_comment": "The assumption that the convex hull of d+2 points in R^d is either a d-simplex or a bi d-simplex is true only in d<4. In higher dimensions, there are more simplical polytopes, among which the cyclic polytope maximalizes the number of facets. As a consequence, there is no simple linear relation between the number of vertices and facets in d>3, from which one could connect the expected values",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The scope of applicability for Theorem 1 regarding dimension $d$ is not correctly specified.",
        "Location": "Theorem 1 (page 1), Abstract (page 1)",
        "Explanation": "Theorem 1 is stated to hold for 'any $d$ dimensions' (Abstract) or implicitly for general $d$ (Theorem 1 statement). However, the formula for $\\expe{\\operatorname{vol}_d(H_{d+1})}$ includes terms like $1/(d-1)$, which makes it undefined for $d=1$. The derivation also relies on $d$-polytope properties that typically assume $d \\ge 2$. The theorem should specify $d \\ge 2$."
      },
      {
        "Problem": "The main result (Theorem 1) conflicts with a previously published formula by Affentranger (1988) for the same quantity, and this discrepancy is not addressed.",
        "Location": "Theorem 1 (page 1), Section 3 (pages 2-3)",
        "Explanation": "Affentranger, F. (1988, Discrete Mathematics, 72(1-3), 3-7) provides a general formula for $\\expe{\\operatorname{vol}_d(H_{n-1})}$. For the specific case $n-1 = d+1$ (i.e., $n=d+2$), Affentranger's formula differs from Theorem 1 for all $d \\ge 2$ except for $d=3$. For example, for $d=2$, Theorem 1 yields $\\expe{\\operatorname{vol}_2(H_3)} = 1 - \\frac{3}{2} \\int (\\Gamma^2 + (1-\\Gamma)^2)$, which matches known results. Affentranger's formula for $d=2$ yields $1 - \\frac{3}{4} \\int (\\Gamma^2 + (1-\\Gamma)^2)$. This discrepancy is critical. If Theorem 1 is correct, it implies Affentranger's widely cited formula is incorrect for $d \\neq 3$. This major conflict must be discussed and resolved for the current paper's conclusions to be validated."
      },
      {
        "Problem": "The paper misrepresents Affentranger's (1988) work regarding the existence of a generalized Efron's formula.",
        "Location": "Introduction (page 1, end of first paragraph) and Final Remarks (page 3, second paragraph)",
        "Explanation": "The paper states: 'It is thus belived there is no analogue of Efron's formula in higher dimensions [Affentranger 1988]' (Final Remarks). This is a misrepresentation, as Affentranger's 1988 paper is titled 'Generalization of Efron’s formula for mean volume of a random simplex' and explicitly provides such a formula (which, as noted in Problem 2, conflicts with Theorem 1). This inaccurate portrayal of existing literature affects the stated motivation and novelty of the paper's contribution."
      },
      {
        "Problem": "The derivation of the linear relation for $f_0(H_{d+2})$ and $f_{d-1}(H_{d+2}) relies on specific properties of $H_{d+2}$ which might conflict with general relations from Dehn-Sommerville equations if not carefully justified.",
        "Location": "Section 3, page 3 (Proof of Theorem 1, specifically the 'crucial observation')",
        "Explanation": "The paper's derivation hinges on the linear relation $(d - 1) f_0(H_{d+2}) - f_{d-1}(H_{d+2}) = (d - 2) (d + 1)$, which is verified for the two almost sure combinatorial types of $H_{d+2}$. Affentranger (1988) uses a different linear relation purportedly derived from Dehn-Sommerville equations: $\\alpha_d f_0(H_n) - f_{d-1}(H_n) = \\delta_d \\alpha_d$ (where $\\alpha_d, \\delta_d$ depend on parity of $d$). For $n=d+2$, these relations are different (except for $d=3$). The current paper's relation appears correct for $H_{d+2}$ based on polytope theory, and Affentranger's general relation seems problematic (e.g., for $d=2$). However, the paper should explicitly state why its specific relation for $H_{d+2}$ is appropriate and, by implication, why a general relation from Dehn-Sommerville as used by Affentranger might lead to different results or be misapplied by Affentranger."
      }
    ],
    "token_usage": {
      "input": 5531,
      "thinking": 17683,
      "output": 1062
    }
  },
  {
    "entry_id": 88,
    "retraction_id": "1501.01153v3",
    "paper_id": "1501.01153v2",
    "retraction_comment": "Submission withdrawn due to the error in equation 35 on dimensional grounds",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency in dual QCD field equations and vector glueball mass definition.",
        "Location": "Section 2, primarily Eqs. (2.9), (2.12), (2.13) and the definition of $m_B$.",
        "Explanation": "The Lagrangian (2.9) defines the covariant derivative $D_\\mu \\phi = (\\partial_\\mu + i \\frac{4\\pi}{g} B_\\mu^{(d)}) \\phi$. This implies a magnetic coupling $e_m = 4\\pi/g = \\sqrt{4\\pi/\\alpha_s}$. The mass term for $B_\\mu^{(d)}$ arising from $|D_\\mu\\phi|^2$ should then be $m_B^2 = e_m^2 \\phi_0^2 = (4\\pi/\\alpha_s) \\phi_0^2$. However, the field equation for $B_\\mu^{(d)}$ (Eq. 2.13) contains the term $-8\\pi\\alpha_s^{-1} B_\\mu^{(d)}\\phi\\phi^*$, implying $m_B^2 = (8\\pi/\\alpha_s) \\phi_0^2$. This value of $m_B^2$ (and the corresponding $m_B=(8\\pi\\alpha_s^{-1})^{1/2} \\phi_0$) is used throughout the paper (e.g., Eq. 2.17, 2.20, 2.21, Table 1). This factor of 2 discrepancy in $m_B^2$ indicates an inconsistency between the Lagrangian (2.9) and the field equation (2.13) from which $m_B$ is effectively defined and used. This affects all subsequent calculations involving $m_B$, including the bag constant $B$ and critical temperatures."
      },
      {
        "Problem": "Sign errors in the dimensionless field equations for the flux tube.",
        "Location": "Section 2, Eq. (2.18).",
        "Explanation": "When deriving the dimensionless field equations (2.18) from the dimensionful equations in cylindrical coordinates (2.15), sign errors appear. Specifically, the term $\\frac{1}{r^2}( n + F)^2 H$ in Eq. (2.18) should be $-\\frac{1}{r^2}( n + F)^2 H$, and the term $\\frac{1}{2} H (H^2 -1)$ should be $-\\frac{1}{2} H (H^2 -1)$ to be consistent with the structure of Eq. (2.15) (where these terms effectively contribute to a potential energy that is subtracted). These sign errors would alter the solutions for the flux tube profiles $H(r)$ and $F(r)$, and consequently affect the calculation of the energy per unit length $k$ (Eq. 2.23), which in turn influences the values of $\\phi_0$ and $m_B$ listed in Table 1."
      },
      {
        "Problem": "Incorrect formula for fermionic pressure contribution and its application to nucleon pressure.",
        "Location": "Section 3, Eq. (3.13); Section 5, Eq. (5.14).",
        "Explanation": "Equation (3.13) for the logarithm of the grand canonical partition function for fermions, $(T \\ln Z)_f$, (and thus the pressure $P_f = T \\ln Z_f / V$) is half the standard expression found in statistical mechanics textbooks for a given degeneracy $g_f$. While this error is coincidentally compensated for the quark-gluon plasma (QGP) pressure in Eq. (4.8) by using a definition of quark degeneracy $g_f=16$ (for 'quark-antiquark pairs') that is twice the standard $g_f=8$ (for quarks of 2 flavors, 2 spins, SU(2) color) in such a formula, the same erroneous Eq. (3.13) is used to calculate the nucleon pressure $P_N$ in Eq. (5.14) with a standard nucleon degeneracy $g_f=4$. This results in the nucleon pressure $P_N$ being half its correct value, which significantly impacts the calculation of the hadron-QGP phase transition involving nucleons."
      },
      {
        "Problem": "Inconsistent derivation of the phase boundary equation for nucleonic matter.",
        "Location": "Section 5, derivation leading to Eq. (5.15) and its use in Eq. (5.16).",
        "Explanation": "The equation for the phase boundary involving nucleons, Eq. (5.15), is stated to be derived by equating nucleon pressure $P_N$ (Eq. 5.14) and plasma pressure $P_p$ (Eq. 4.8). However, Eq. (5.15) actually corresponds to $P_p(\\mu_q) - P_N(\\mu_q) = B$, effectively assuming the nucleon chemical potential $\\mu_N$ is equal to the quark chemical potential $\\mu_q$. This contradicts the established thermodynamic relation $\\mu_N = 3\\mu_q$ for nucleons made of three quarks, which is stated and supposedly used by substituting $\\mu_q = \\mu_c/3$ into Eq. (5.15) to get Eq. (5.16). This inconsistent treatment of chemical potentials makes the derived phase boundary (Eq. 5.16), the critical temperatures $T_{c(N)}^{QGP}$ (Eq. 5.17 and Fig. 2), and the comparison with $T_{c(\\pi)}^{QGP}$ unsound."
      },
      {
        "Problem": "Incorrect formulas for the speed of sound and specific heat of the QGP.",
        "Location": "Section 5, Eqs. (5.11) and (5.12); Section 6, Figs. 5(a) and 5(b).",
        "Explanation": "The formula for the squared speed of sound $c_s^2$ in Eq. (5.11) is given as $P_p/\\epsilon_p$. The correct thermodynamic definition is $c_s^2 = (\\partial P_p / \\partial \\epsilon_p)_S$. For the bag model EoS used (Eqs. 4.7, 4.8), $P_p = (\\epsilon_p - 4B)/3$, which leads to $c_s^2 = 1/3$, a constant. The paper's formula (5.11) yields a temperature-dependent $c_s^2$ that is plotted in Fig. 5(a). Similarly, the formula for specific heat $C_V$ in Eq. (5.12) is incorrect. The standard definition $C_V = (\\partial \\epsilon_p / \\partial T)_V$ for the given $\\epsilon_p$ (Eq. 5.8, with $\\mu_q=0$) yields $C_V/T^3 = 8\\pi^2/3$, a constant. The paper's Eq. (5.12) leads to a temperature-dependent $C_V/T^3$ with a peak (Fig. 5(b)). These incorrect formulas render the discussions about the behavior of $c_s^2$ and $C_V$ near $T_c$, and their physical interpretations, invalid."
      }
    ],
    "token_usage": {
      "input": 21393,
      "thinking": 19547,
      "output": 1694
    }
  },
  {
    "entry_id": 89,
    "retraction_id": "1910.10153v2",
    "paper_id": "1910.10153v1",
    "retraction_comment": "The function \\phi(x) which we define above Eq.8 is infinitely peaked in the thermodynamic limit; the long-time-tail behavior enters through higher derivatives of the entropy",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The predicted temperature dependence of the constant in the generalized Wiedemann-Franz law (Eq. 3/Eq. 7) appears inconsistent.",
        "Location": "Eq. (3), Eq. (7), and their derivation from Eq. (8) and Eq. (10).",
        "Explanation": "The paper claims the constant in the generalized Wiedemann-Franz law, $C = \frac{1}{T}\frac{\\sigma^{LTT}\\overline{\\kappa}^{DC}}{\\alpha^{LTT}\\alpha^{DC}}$, is temperature independent. However, a derivation starting from the paper's expressions for $K_{ij}(\\omega)$ (Eq. 8 for high T, Eq. 10 for low T) and the definitions $\\sigma=K_{11}, \\alpha=K_{12}/T, \\overline{\\kappa}=K_{22}/T$, along with the assumption that $K_{ij}^{LTT}$ and $K_{ij}^{DC}$ are proportional to the same prefactor $P_{ij}(T)$ but different energy integrals, leads to $C \\propto T \\cdot \frac{P_{11}(T)P_{22}(T)}{P_{12}(T)^2}$. For both high-T and low-T expressions of $P_{ij}(T)$ given in the paper, the term $\frac{P_{11}(T)P_{22}(T)}{P_{12}(T)^2}$ appears to be temperature-independent (ignoring $Z(\beta)$ and $\rho(T/2)$ dependencies that might not cancel perfectly but are part of the common factor $F(T)$ in the thought process). This results in $C \\propto T$, contradicting the claim of temperature independence. While the numerical results in Fig. 2 show a fairly flat ratio, this discrepancy with the analytical derivation is critical."
      },
      {
        "Problem": "The Random Matrix Theory (RMT) assumption for electron operator matrix elements (Eq. 5) is potentially too strong.",
        "Location": "Page 2, Eq. (5) and discussion thereof. Supplement Sec. I A.",
        "Explanation": "Eq. (5) assumes that $\\overline{|\\langle m_1|c^\\dagger_1|n_1\rangle|^2}$ is constant for energy differences $|\\epsilon_{m_1}-\\epsilon_{n_1}|$ up to the single-particle bandwidth $U$. Standard Eigenstate Thermalization Hypothesis (ETH) and RMT arguments suggest such energy-independent behavior for matrix elements typically holds for energy differences up to the Thouless energy of the block, $E_{Th,block} \\sim D/\\xi^2 = \\omega$. Since $\\omega \\ll U$ generally, assuming constancy up to $U$ is a significant extrapolation. The paper acknowledges this neglects intra-block diffusion, effectively making it instantaneous. If the actual energy dependence of these matrix elements for $U > |\\Delta E| > \\omega$ is significant, it could alter the functional form of $\\Phi(\beta, z)$ in Eq. (8) and its derivatives, which in turn could affect the LTT coefficients and the Wiedemann-Franz relationship derived from it."
      },
      {
        "Problem": "The approximation for the thermal current operator $J^2$ lacks rigorous justification.",
        "Location": "Supplement, Sec. I B, paragraph starting 'In our derivation, we use an approximate form for the thermal current operator $J^2$...'",
        "Explanation": "The thermal current density $J^2_j$ is approximated as $-\frac{1}{2}[J^1_j,H^R-H^L]$. The motivation involves arguing that $[n_j, J^2_j]$ 'will only add a phase to each matrix element'. Commutators involving number operators typically yield terms proportional to the original operator or related operators, not just a phase modification, unless $J^2_j$ has very specific commutation relations with $n_j$. For example, if $J^2_j$ contains $c_j$ or $c_j^\\dagger$, the commutator $[c_j^\\dagger c_j, J^2_j]$ is generally not trivial. An unsound approximation for $J^2$ would directly impact the calculation of all thermal and thermoelectric coefficients ($K_{12}, K_{21}, K_{22}$), thereby affecting the terms in the generalized Wiedemann-Franz law."
      },
      {
        "Problem": "The structure of the low-temperature transport coefficients (Eq. 10) relies on a strong factorization assumption involving $\\sigma(q, \nu, T=0)$.",
        "Location": "Page 3, Eq. (10) and surrounding discussion. Supplement Sec. I B (Finite T, T << U).",
        "Explanation": "In the low-temperature regime, Eq. (10) incorporates coherence effects by introducing the zero-temperature, non-local conductivity $\\sigma(q=\\xi_T^{-1}, \nu=T, T=0)$ as a prefactor. The crucial step is that this prefactor multiplies an integral structure (involving $\\Phi$ functions) that is identical to the one in the high-temperature result (Eq. 8). This implies that the frequency dependence (leading to LTTs) and the specific energy structure (leading to the Wiedemann-Franz type relations) are governed by this common integral form, irrespective of the temperature regime. The justification for this factorization, particularly how the complex, temperature-dependent matrix elements $\\overline{|\\langle m_1,m_2|J_{\\xi_T}|n_1,n_2\rangle|^2}$ (Supplement Eq. 19) precisely factor into $\\sigma(q,T,0)$ and the original $\\Phi$-integral structure, needs to be more robust. If this factorization is not accurate, the LTT behavior and the generalized WF law might differ in the low-temperature regime from what is predicted by simply changing the prefactor."
      }
    ],
    "token_usage": {
      "input": 20473,
      "thinking": 14412,
      "output": 1308
    }
  },
  {
    "entry_id": 90,
    "retraction_id": "1306.5006v3",
    "paper_id": "1306.5006v2",
    "retraction_comment": "We have decided to withdraw the paper due to a crucial error in equation (9), that is in the definition of the p-value. This invalidates the results reported into the manuscript",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect scaling factor in the Kullback-Leibler divergence estimator",
        "Location": "Section 3.2, Equation (7), page 5",
        "Explanation": "Equation (7) approximates the integral for $\\widehat{\\Delta}_r$ using a sum multiplied by a factor of $10^{-4}$. This factor is presented as if it's the differential area element $dxdy$ for the grid summation. However, the grid is defined based on the data range ($x_{(n)}-x_{(1)}+2a$), and the actual area of each grid cell is $\\left(\\frac{x_{(n)}-x_{(1)}+2a}{99}\\right) \\left(\\frac{y_{(n)}-y_{(1)}+2a}{99}\\right)$. This cell area is generally not equal to $10^{-4}$ and depends on the data's scale and range. Using a fixed $10^{-4}$ means $\\widehat{\\Delta}_r$ as defined is not a consistent or correctly scaled estimator of the true Kullback-Leibler divergence $\\Delta_r$. While p-values from a permutation test might be robust to a consistent mis-scaling for a given dataset (if the scaling factor is constant across permutations), the paper defines $\\widehat{\\Delta}_r$ as an estimator of $\\Delta_r$, and this formulation is erroneous."
      },
      {
        "Problem": "Potentially suboptimal choice and justification of bandwidth for hypothesis testing",
        "Location": "Section 3.1, page 4",
        "Explanation": "The paper uses the likelihood cross-validation bandwidth ($h_{\\text{LCV}}$), which is optimal for density *estimation* under the Kullback-Leibler criterion. It then states, based on a previous study by some of the authors, that this choice is 'appropriate' for *testing* and 'no oversmoothing is needed'. However, the optimal bandwidth for hypothesis testing often differs from that for density estimation, and can significantly impact test power. Relying on $h_{\\text{LCV}}$ without a more thorough justification or sensitivity analysis for its specific use in this testing context makes the robustness and optimality of the KL-ADF's power unclear. The conclusions about power superiority might not be general if $h_{\\text{LCV}}$ is not broadly suitable for testing across diverse types of dependencies."
      },
      {
        "Problem": "Oversimplified bandwidth structure for bivariate kernel density estimation",
        "Location": "Section 3.1, Equation (5), page 4",
        "Explanation": "The bivariate kernel density estimator $\\widehat{f}_r(x,y)$ is defined as a product of two one-dimensional Gaussian kernels using a single, identical bandwidth $h$ (presumably $h_{\\text{LCV}}$ derived from univariate data) for both dimensions $X_i$ and $X_{i+r}$. This is a restrictive simplification (isotropic kernel with scalar bandwidth) that does not account for potential differences in smoothness characteristics between $X_i$ and $X_{i+r}$ (even if marginally identical, their joint structure might differ) or correlations that might be better handled by a more flexible bivariate bandwidth specification (e.g., a diagonal bandwidth matrix or a full bandwidth matrix). This can lead to a suboptimal estimation of the joint density $\\widehat{f}_r$, which in turn could adversely affect the accuracy and power of the estimated Kullback-Leibler divergence and the resulting test."
      }
    ],
    "token_usage": {
      "input": 13097,
      "thinking": 16167,
      "output": 769
    }
  },
  {
    "entry_id": 91,
    "retraction_id": "1704.08680v6",
    "paper_id": "1704.08680v5",
    "retraction_comment": "Algorithm does not terminate. Even if fixed, Claim 9 is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Proof of Proposition 5.2 for partial Steiner nodes is flawed.",
        "Location": "Page 9, Proof of Proposition 5.2",
        "Explanation": "The proof for partial Steiner nodes states that the sum of increments to the $z_v$ coordinates (which determines hitting time $\\tau^r(v)$) behaves as if the growth rate scaling factor $\\frac{|\\Delta^{r-1}(v) \\cap L_v^t|}{|L_v^t|}$ is always 1. Specifically, it claims the sum of increments is $i(t_{i+1}-t_i)$ where $i$ is the number of components $v$ links to. However, for a partial Steiner node, this factor can be less than 1 (as illustrated in the paper's example in Figure 7/Table 1, where the factor is 2/3). If this factor is less than 1, the derived formula $\\tau^r(v) = \\frac{\\sum t_i}{\\delta-1}$ does not hold. This equality is critical for the inductive proof of Theorem 5.1, which compares the cost of edges $\\sum t_i$ with $(\\delta-1)\\tau^r(v)$."
      },
      {
        "Problem": "The proof of Theorem 5.1, specifically for Event Type 2, does not cover all cases of Steiner nodes hitting the simplex.",
        "Location": "Page 9, Proof of Theorem 5.1, Event Type 2",
        "Explanation": "The proof for Event Type 2 (a Steiner node $v$ hits the simplex) explicitly assumes that this node $v$ had a degree $\\delta^{r-1}(v) \\geq 2$ from the previous phase $(r-1)$. However, the algorithm allows for a Steiner node $v$ to hit the simplex in phase $r$ even if it did not hit in phase $r-1$ (i.e., $\\delta^{r-1}(v)=0$). For such nodes, their coordinates $z_v$ would grow according to the normal primal-dual rules. The proof does not address this case. The standard analysis for such nodes (as in Theorem 3.2) yields an inequality $c(D) \\leq 2(\\sum z_j(j)) - \\ell t$, which does not directly lead to the target inequality $c(D) \\leq (\\sum z_j(j)) - t$ of Theorem 5.1 without further justification."
      },
      {
        "Problem": "The feasibility of the dual solution $z$ with respect to original costs $c_1$ is not adequately justified for all edges.",
        "Location": "Page 10, Proof of Theorem 5.3, specifically the argument for condition 2 and the definition of $c_2(u,v)$",
        "Explanation": "The overall 7/6 approximation ratio argument relies on the final dual solution $z=z^r$ (potentially scaled) being feasible for the simplex LP under the original edge costs $c_1$. The proof of Theorem 5.3, part 2, states $d(u,v) \\leq (7/6)c_2(u,v)$, and for edges $(u,v) \\in E \\setminus L$, this relies on the assumption $d(u,v) \\leq c_1(u,v)$ (since $c_2(u,v) = (6/7)c_1(u,v)$ for these edges). However, the algorithm's dual update rules, particularly with variable growth rates and projection, primarily ensure $d(u,v) \\approx c_1(u,v)$ for edges that become tight or are active links (edges in $L$). It is not guaranteed that $d(u,v) \\leq c_1(u,v)$ holds for all other edges in $E \\setminus L$ for the final $z$. If $d(u,v) > c_1(u,v)$ for some edge in $E \\setminus L$, the argument that $z$ (after scaling by 6/7) is feasible for the original LP is undermined."
      },
      {
        "Problem": "Significant ambiguity in the post-processing step's effect on dual variables and recorded values from the primal-dual execution.",
        "Location": "Page 6, Algorithm 2 (\\textsc{Primal-Dual-1}) and Algorithm 3 (\\textsc{Primal-Dual-2}) descriptions of post-processing",
        "Explanation": "The post-processing step describes computing an MST and 'overwriting $(T^1,z^1,\\tau^1,\\Delta^1,\\delta^1)$'. While the primal tree $T^1$ can be overwritten, it is unclear how $z^1$ (dual variable values) and $\\tau^1$ (hitting times), which are outcomes of the continuous primal-dual growth process, could be meaningfully 'overwritten' by an MST computation. The values $\\Delta^1$ (set of links chosen for a Steiner node $v$) and $\\delta^1 = |\\Delta^1(v)|$ are critical as they determine the variable growth rates in the subsequent phase. If these are based on the primal-dual output before the MST step, but $T^1$ (the set of edges in the solution) is then altered by the MST, there's a potential inconsistency. If $\\Delta^1$ and $\\delta^1$ are meant to be updated based on the MST (e.g., reflecting which of $v$'s links $L_v$ are part of the MST), the paper does not specify how this update is performed. This ambiguity could fundamentally alter the behavior of the variable rate mechanism. The paper's example (Figure 7) mentions assuming the post-processing step does not alter the solution, which sidesteps this issue for the example but not for the general algorithm."
      }
    ],
    "token_usage": {
      "input": 20876,
      "thinking": 20078,
      "output": 1330
    }
  },
  {
    "entry_id": 92,
    "retraction_id": "0710.2117v5",
    "paper_id": "0710.2117v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical error in the geometric formulation of the principle of inertial motion",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsupported foundational claim for Euclidean Special Relativity",
        "Location": "Section 2 (especially Eq. 1) and Page 5 ('Minimal set of assumptions')",
        "Explanation": "The paper claims that Special Relativity (SR) and Lorentz transformations can be derived from a 4D Euclidean metric (Eq. 1: d² = Δx² + Δy² + Δz² + c²Δt²) and an assumption that changing an object's speed does not change its 'Euclidean space-time volume.' However, a rigorous derivation is not provided. Standard SR is based on the Minkowski metric, and it's unclear how a positive-definite Euclidean metric can reproduce SR phenomena like length contraction and time dilation without contradicting established physics or requiring unconventional interpretations of coordinates and volumes. This unsubstantiated foundational claim undermines the basis of the proposed framework."
      },
      {
        "Problem": "Arbitrary and inadequately justified Law of Inertial Motion",
        "Location": "Section 3.2, Eq. (6) and Eq. (7)",
        "Explanation": "The proposed Law of Inertial Motion states that a particle's acceleration is directly proportional to the 'acceleration' of local light speeds (Eq. 6: dv/dt = dc/dt, or Eq. 7 involving a parameter K). The physical justification for this direct linkage, especially why massive particles should mimic changes in light speed so precisely, is insufficient. Eq. (7) introduces an undefined weighting factor K (0 ≤ K ≤ 1) without derivation or clear physical meaning, making the law lack predictive power or fundamental grounding. The admission that this law is not generally Lorentz covariant is also a significant weakness for a theory aiming to generalize SR."
      },
      {
        "Problem": "Mathematical errors in the derivation of radial acceleration, leading to a result contradicting the target model",
        "Location": "Section 5.2, specifically the derivation from Eq. (21) through Eq. (28) and its comparison to Broekaert's Eq. (13)",
        "Explanation": "The derivation in Section 5.2 aims to show compatibility between the author's motion law and Broekaert's model for radial acceleration. However, the derivation appears to contain sign errors or inconsistencies. For instance, the derived equation for radial acceleration (Eq. 28, which should be dv₂(r)/dt = +κc²e^(-4κ/r)/r² - 3κv₂(r)²/r² based on the steps shown) yields a repulsive primary gravitational term (+κc²...). This directly contradicts the attractive term (-κc²...) in Broekaert's model (Eq. 13, for radial motion). This mathematical discrepancy invalidates the paper's claim of successfully reinterpreting Broekaert's attractive gravity within its framework."
      },
      {
        "Problem": "Ad-hoc and poorly justified reinterpretation strategy using 'Model 0'",
        "Location": "Section 5.2, particularly the introduction and use of 'Model 0'",
        "Explanation": "The reconciliation of Broekaert's model (Model 2) with the author's framework relies on an intermediate 'Model 0,' which supposedly inherits properties from Model 2 and 'Model 1' (a configuration yielding attraction). The definition of Model 0 is vague, and the justification for its properties and for applying the motion law to it as if it were Model 1 (despite potentially different underlying light speed behaviors, e.g., sign of dc/dr) is not provided. The relationships assumed (e.g., Eq. 19: v₂(r) = v₁(r)e^(-3κ/r), Eq. 24: c₁/v₁ = c₂/v₂) appear to be constructed to achieve a desired outcome rather than derived from fundamental principles of the Euclidean framework, making the reinterpretation seem artificial."
      },
      {
        "Problem": "Ambiguity of 'Euclidean General Covariance' and its mechanism for describing gravity",
        "Location": "Section 3.1, 'The Euclidean principle of general covariance'",
        "Explanation": "The paper proposes a 'Euclidean principle of general covariance' within a 4D Euclidean space-time (++++ signature). It's unclear how this principle, and a fundamentally flat Euclidean geometry, can adequately describe gravity, which in General Relativity involves a curved pseudo-Riemannian manifold. The mechanism by which gravity arises (variable light speeds c(r) and modified cell extensions X(r), T(r) imposed on a Euclidean background) seems more akin to an ether-drift or bimetric theory rather than a truly geometric theory of gravity in the sense of GR. The nature and scope of the allowed 'coordinate transformations between space-time observers' and how they relate to physical gravitational effects are not clearly defined, making the soundness and utility of this covariance principle questionable."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 11091,
      "output": 1064
    }
  },
  {
    "entry_id": 93,
    "retraction_id": "1111.3825v3",
    "paper_id": "1111.3825v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in lemma 3.7",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption of \"real structure\" for the harmonic bundle.",
        "Location": "Introduction, p. 2, the sentence: \"By a result obtained by J. Jost and K. Zuo [JZ] ... we obtain a tame and nilpotent harmonic bundle $(E,\\theta,h)$ with real structure and trivial parabolic structure over $X^*$.\" This assumption then underlies Theorem 1.2 (via this asserted implication) and is an explicit premise for Theorem 3.1.",
        "Explanation": "The paper claims that any reductive representation $\\rho: \\pi_{1}(X^{*}) \\rightarrow GL(V)$ with unipotent local monodromy yields a harmonic bundle that necessarily possesses a \"real structure\", attributing this to Jost-Zuo [JZ]. However, the work of Jost-Zuo [JZ] ensures a tame pluriharmonic metric, leading to a tame (and in this case, nilpotent) harmonic bundle, but it does not generally guarantee that this bundle has a \"real structure\" if the complex representation $\\rho$ itself is not real or conjugate to a real one. The existence of a real structure is a crucial hypothesis for Mochizuki's Purity Theorem (Theorem 3.9 in this paper, citing [M] Thm 9.6), which is a cornerstone of the argument adapting Kashiwara-Kawai's proof. Without a guaranteed real structure for all $\\rho$ covered by Theorem 1.2, this purity theorem may not apply, and the subsequent arguments (e.g., for Proposition 3.10) are unsupported for the stated generality of $\\rho$. This potentially invalidates the main conclusion (Theorem 1.2) for general reductive representations."
      },
      {
        "Problem": "Mismatch in the definition and application of \"trivial parabolic structure\".",
        "Location": "Definition of trivial parabolic structure on p. 5 (unnumbered, under subsection 2.1); use of this property in Lemma 3.5 (proof citing [M] Thm 8.2), Lemma 3.6 (proof citing [M] Thm 9.3), and Theorem 3.9 (citing [M] Thm 9.6).",
        "Explanation": "The paper defines \"trivial parabolic structure\" (page 5) as $C_1\\cdot\\prod_{i=1}^l|z_i|^{\\epsilon} \\leq |s|_h \\leq C_2\\cdot \\prod_{i=1}^l |z_i|^{-\\epsilon}$ for multi-flat sections $s$. Metrics with logarithmic growth (such as those from Jost-Zuo [JZ]) satisfy this definition. However, the cited theorems from Mochizuki's paper [M] (e.g., Thm 8.2, Thm 9.3, Thm 9.6) rely on Mochizuki's own definition of trivial parabolic structure (e.g., Def 2.2.1 in [M]: $C^{-1} \\prod |z_j|^{-\\epsilon_0} \\le |s_k|_h \\le C \\prod |z_j|^{\\epsilon_0}$ for some $\\epsilon_0 > 0$). Logarithmic growth does *not* satisfy Mochizuki's definition of trivial parabolic structure (specifically, the upper bound $|s_k|_h \\le C \\prod |z_j|^{\\epsilon_0}$ is violated by logarithmic growth). This mismatch in definitions means that the conditions for applying Mochizuki's key theorems (on good frames, metric estimates, and purity) are not demonstrably met, even if the Jost-Zuo metric satisfies the paper's own stated definition. This undermines the proofs of Lemmas 3.5, 3.6, and Theorem 3.9, and consequently the main conclusion (Theorem 1.2)."
      }
    ],
    "token_usage": {
      "input": 9988,
      "thinking": 15713,
      "output": 845
    }
  },
  {
    "entry_id": 94,
    "retraction_id": "1711.04838v3",
    "paper_id": "1711.04838v2",
    "retraction_comment": "Lemma 9.1 is incorrect and so the main result is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect reasoning regarding quandle properties in Remark 6.4 (ii).",
        "Location": "Remark 6.4 (ii), Page 6",
        "Explanation": "The remark states: 'If $x*y=x$, then from (i) above $X=T_1$ and the colouring $C$ is trivial. That is $x=y=z$'. This is incorrect. The condition $x*y=x$ for specific elements $x,y$ involved in a coloring does not imply that the quandle $X$ is $T_1$ (a trivial quandle), nor does it force $x=y=z$ in the general quandle setting. This fundamental misunderstanding of quandle algebra affects subsequent proofs."
      },
      {
        "Problem": "The proof of Lemma 8.4 is flawed due to reliance on the incorrect Remark 6.4 (ii).",
        "Location": "Lemma 8.4, Page 8",
        "Explanation": "Lemma 8.4 claims that a specific triple point $T_3$ must be of type (1) (color $(x,x,x)$) because its $b/t$-edges are degenerate. However, other types of triple points, e.g., type (4) $(x,y,x)$ where $x*y=x$, also have both $b/t$-edges degenerate. The proof implicitly uses the erroneous Remark 6.4 (ii) to incorrectly rule out such possibilities by forcing $y=x$. If $T_3$ is not necessarily type (1), its contribution to the cocycle invariant is not necessarily trivial, which undermines Theorem 8.6 for the $t(F)=3$ case."
      },
      {
        "Problem": "Homological arguments in Section 9 are insufficiently justified.",
        "Location": "Section 9, primarily Lemma 9.1 (Page 9) and Theorem 9.2 (Pages 10-11)",
        "Explanation": "Proofs in Section 9, aiming to establish $t(F) \\ge 4$ for genus-one surfaces, make strong assertions about the homology classes of decker curves (e.g., being generators of $H_1(F)$, being null-homologous) and their intersection properties. These assertions often lack rigorous justification and appear to be based on intuitive geometric claims that are not adequately proven for the complex configurations described. For example, claiming curves are generators or null-homologous based on a few intersections or visual intuition is not sufficient."
      },
      {
        "Problem": "The premise of Lemma 5.2 regarding edge types at a triple point is unclear and potentially contradictory.",
        "Location": "Lemma 5.2, Page 4",
        "Explanation": "Lemma 5.2 assumes an edge $e$ is simultaneously 'a $b/t$- and $m/t$-edge at $T$'. An edge is formed by the intersection of two sheets. If $e$ is a $b/t$-edge ($S_b \\cap S_t$) and also an $m/t$-edge ($S_m \\cap S_t$), this implies the bottom sheet $S_b$ and middle sheet $S_m$ are locally identical along $e$. This suggests that $T$ might not be a generic triple point (transverse intersection of three distinct sheets) if two of its defining sheets coincide along an incident edge. The definition or implications of such an edge configuration need clarification."
      },
      {
        "Problem": "The proof that non-degenerate triple points $T_1, T_2$ must have the same color in Lemma 8.2 is incomplete.",
        "Location": "Lemma 8.2, Page 8",
        "Explanation": "In the case where $t(F)=2$ and both triple points $T_1, T_2$ are non-degenerate, Lemma 8.2 asserts they must have the same color. The provided argument for $T_1$ of type (4) and $T_2$ of type (5) or (6) includes the step 'another endpoint of $e_3$ (a $b/m$-edge at $T_1$) is neither $T_1$ nor $T_2$'. The reasoning for why $e_3$ cannot connect to $T_2$ is not sufficiently detailed. A comprehensive edge-chasing analysis covering all combinations of non-degenerate types (4, 5, 6) for both $T_1$ and $T_2$ is needed to robustly establish this claim."
      }
    ],
    "token_usage": {
      "input": 14248,
      "thinking": 12542,
      "output": 1023
    }
  },
  {
    "entry_id": 95,
    "retraction_id": "2010.13204v2",
    "paper_id": "2010.13204v1",
    "retraction_comment": "The conclusion of the paper is likely wrong. The second necessary integration step which is barely mentioned at the end of section B introduces another correlation between the vacuum fluctuations which will negate any gain of the here proposed method. I overlooked this. Thanks to [REDACTED-NAME] for figuring it out",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of roundtrip phase in the feedback loop.",
        "Location": "Page 3, section 2.1, definition of $\\phi_{RT}$ following the equation for $P_{Sig} e^{i\\Omega t}$ as a sum.",
        "Explanation": "The paper defines the roundtrip phase as $\\phi_{RT}=\\Omega\\tau-\\phi_{RF}$, where $\\tau=L/c$. However, the signal $P_{Sig}$ (or rather, the modulation carrying it) travels a roundtrip distance of $2L$ in the optical path of the feedback loop. Therefore, the phase accumulated due to optical propagation should be $2\\Omega\\tau$. The definition $\\phi_{RT} = \\Omega\\tau - \\phi_{RF}$ uses only half the correct optical path phase. This error would lead to incorrect tuning of the system for resonance, preventing the achievement of the maximum claimed gain $1/(1-r)$."
      },
      {
        "Problem": "Multiple errors in the derivation of the Signal-to-Noise Ratio (SNR).",
        "Location": "Page 4, section 2.2, the equation for $SNR(T)$ and its algebraic simplification to the final formula.",
        "Explanation": "There are two sequential errors in the SNR calculation. First, the denominator of the $SNR(T)$ expression (representing noise amplitude) is given as $\\frac{1}{2}\\sqrt{\\frac{n_{LO}}{1-r^{2}}}\\sqrt{T}$. The factor of $1/2$ outside the square root is not justified by the preceding derivation of noise variance $\\langle I_{SN}^{2} \\rangle = \\frac{1}{2}\\frac{n_{LO}}{1-r^{2}}$. The standard deviation should be $\\sqrt{\\langle I_{SN}^{2} \\rangle T}$. Second, the algebraic simplification from this ratio to the final SNR formula $SNR(T)=\\sqrt{\\frac{n_{S}T}{1-r^{2}}}$ is incorrect. Correcting the $1/2$ factor and performing the algebra correctly leads to a different SNR formula ($SNR = \\sqrt{\\frac{2n_S(1+r)T}{1-r}}$ based on the paper's $S$ and $\\langle I_{SN}^2 \\rangle$). These errors invalidate the paper's resulting SNR formula."
      },
      {
        "Problem": "The conclusion of SNR equivalence with a passive regeneration cavity is unsubstantiated.",
        "Location": "Page 4, end of Section 2.2, and Page 4, Section 3 (Summary).",
        "Explanation": "The paper claims that the SNR of the active regeneration system is 'essentially identical' to that of a passive regeneration cavity. This claim is based on the paper's derived SNR formula ($\\sqrt{\\frac{n_S T}{1-r^2}}$), which is shown to be incorrect (see Problem 2). Furthermore, even if that formula were correct, its direct equivalence to standard SNR expressions for optimized passive cavities (e.g., $\\sqrt{\\frac{1+\\rho}{1-\\rho} n_S T}$ for a single-ended cavity) is not generally true by simple substitution of $r=\\rho$. The lack of a correct SNR derivation and a rigorous comparison makes this key conclusion about the system's performance relative to existing methods unsound."
      },
      {
        "Problem": "Confusing and non-standard definition of noise field amplitude.",
        "Location": "Page 3, section 2.2, sentence following the first equation for $E_{PD}$: '$<v_{AM}>=\\frac{1}{\\sqrt{2}}=<v_{PM}>$'.",
        "Explanation": "The paper states that the average amplitude of the noise field quadratures $v_{AM}$ and $v_{PM}$ is $1/\\sqrt{2}$. For a zero-mean stochastic noise process, the average amplitude should be zero. While this might be an attempt to define the RMS value or relate to noise power normalization (e.g. $\\langle v_{AM}^2 \\rangle = 1/2$ or $1$), the statement as written is incorrect and confusing. Although the subsequent noise variance calculation $\\langle I_{SN}^2 \\rangle$ appears to arrive at a standard-looking result (implicitly assuming $\\langle v_{AM}^2(t) \\rangle \\langle \\cos^2(\\zeta(t)) \\rangle = 1/2$), the initial incorrect definition obscures the derivation of the fundamental noise properties."
      }
    ],
    "token_usage": {
      "input": 7354,
      "thinking": 17695,
      "output": 1014
    }
  },
  {
    "entry_id": 96,
    "retraction_id": "2208.11892v3",
    "paper_id": "2208.11892v2",
    "retraction_comment": "Lemma 3.2 does not hold. A counter example is $f \\equiv 1$",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The estimate for the term $\\inner{\\nabla \\vel}{\\nabla w}_\\skin$ (part of $R''_6$) in the proof of Lemma 7.2 (the $W^{-1,p}$-error estimate for velocity $e$) is $C h^{2/p'} \\abs{\\lambda}^{-1} \\Lpnorm{f}{p}{\\Omega} \\Lpnorm{\\nabla \\phi}{p'}{\\Omega}$ when $p \\le 2$. For $p<2$, $2/p' = 2(1-1/p) < 1$. This results in a suboptimal power of $h$ for this term compared to the claimed $O(h)$ contribution to the overall estimate for $\\norm{e}{W^{-1,p}(\\Omega)}$.",
        "Location": "Lemma 7.2, proof, estimate of $R''_6$ for $p \\le 2$, page 16. This affects equation (6.10) / (7.4) (final estimate in Lemma 7.2, $\\norm{e}{W^{-1,p}(\\Omega)}$).",
        "Explanation": "In the proof of Lemma 7.2, for $p \\le 2$, the term $\\abs{\\inner{\\nabla \\vel}{\\nabla w}_\\skin}$ is estimated. The paper's argument leads to a bound $C h^{2(1-1/p)} \\abs{\\lambda}^{-1} \\Lpnorm{f}{p}{\\Omega} \\Lpnorm{\\nabla \\phi}{p'}{\\Omega}$. For $p<2$, the exponent $2(1-1/p)$ is less than 1. This means the $f$-dependent part of the $W^{-1,p}$-error estimate for $e$ is of order $h^{2(1-1/p)} \\abs{\\lambda}^{-1}$, not $h \\abs{\\lambda}^{-1}$ as effectively claimed in equation (6.10) / (7.4) (\\eqref{eq:dual-W1p} in the provided LaTeX)."
      },
      {
        "Problem": "The $W^{-1,p}$-error estimate for velocity $e$ (Theorem 2.2, eq. (2.11)) claims an $O(h)$ factor for the term involving $\\Lpnorm{f}{p}{\\Omega}$. Due to the issue in Problem 1, for $p<2$, this factor should be $O(h^{2(1-1/p)})$, which is a worse rate since $2(1-1/p) < 1$.",
        "Location": "Theorem 2.2, eq. (2.11) (stated as \\eqref{eq:err-v-W-1p}), page 7. Proof in Section 8.4, page 21.",
        "Explanation": "The proof of this estimate directly relies on Lemma 7.2. The suboptimal estimate of the $R''_6$ term (Problem 1) for $p<2$ means that the coefficient of $\\abs{\\lambda}^{-1} \\Lpnorm{f}{p}{\\Omega}$ in the $W^{-1,p}$-error estimate for $e$ is $h^{2(1-1/p)}$, not $h$. This makes the stated error estimate in Theorem 2.2 incorrect for $p<2$ regarding its $h$-dependency on the $f$-term."
      },
      {
        "Problem": "The $L^p$-error estimate for the pressure error $\\rho$ (Theorem 2.2, eq. (2.12)) claims an $O(h)$ factor for $\\Lpnorm{f}{p}{\\Omega}$. For $p<2$, this estimate is derived using Corollary 7.1, which is affected by Problem 1 (via Lemma 7.2). This leads to an actual $f$-dependent term of order $O(h^{2(1-1/p)})$, which is worse than $O(h)$.",
        "Location": "Theorem 2.2, eq. (2.12) (stated as \\eqref{eq:err-p-Lp}), page 7. Proof in Section 8.5, page 21.",
        "Explanation": "The proof of the $L^p$-pressure error estimate uses Corollary 7.1 for $\\Lpnorm{\\tzetah}{p}{\\Omegah}$. For $p<2$, the $f$-dependent term in Corollary 7.1, arising from $\\abs{\\lambda}\\norm{e}{W^{-1,p}(\\Omega)}$, becomes $O(h^{2(1-1/p)} \\Lpnorm{f}{p}{\\Omega})$ due to Problem 2. Consequently, $\\Lpnorm{\\rho}{p}{\\Omegah}$ would be bounded by $C h^{2(1-1/p)} \\Lpnorm{f}{p}{\\Omega}$ for $p<2$, contradicting the claimed $O(h)$ rate."
      },
      {
        "Problem": "The main resolvent estimate for the pressure gradient, $\\Lpnorm{\\nabla \\presh}{p}{\\Omegah} \\le C \\Lpnorm{f}{p}{\\Omega}$ (Theorem 2.1, eq. (1.3)), is likely invalidated for $p<2$. Its proof relies on an $O(h)$ estimate for $\\Lpnorm{\\zeta_h}{p}{\\Omegah}$, which, due to Problem 3, should be $O(h^{2(1-1/p)})$ for $p<2$. This leads to a term $C h^{-1} \\Lpnorm{\\zeta_h}{p}{\\Omegah} \\sim C h^{2(1-1/p)-1} \\Lpnorm{f}{p}{\\Omega} = C h^{(p-2)/p} \\Lpnorm{f}{p}{\\Omega}$. Since $(p-2)/p < 0$ for $p<2$, this term blows up as $h \\to 0$.",
        "Location": "Theorem 2.1, eq. (1.3) (stated as \\eqref{eq:resolvent-h}, specifically the $\\Lpnorm{\\nabla \\presh}{p}{\\Omegah}$ part), page 6. Proof in Section 9, page 22.",
        "Explanation": "The proof of Theorem 2.1 estimates $\\Lpnorm{\\nabla \\presh}{p}{\\Omegah}$ using $\\Lpnorm{\\nabla \\presh}{p}{\\Omegah} \\le C \\Lpnorm{\\nabla \\pres}{p}{\\Omega} + C h^{-1} \\Lpnorm{\\zeta_h}{p}{\\Omegah}$. As established in Problem 3, for $p<2$, $\\Lpnorm{\\zeta_h}{p}{\\Omegah}$ is of order $h^{2(1-1/p)} \\Lpnorm{f}{p}{\\Omega}$. Therefore, the term $C h^{-1} \\Lpnorm{\\zeta_h}{p}{\\Omegah}$ becomes $C h^{(p-2)/p} \\Lpnorm{f}{p}{\\Omega}$. For $p<2$, the exponent $(p-2)/p$ is negative, meaning this term is unbounded as $h \\to 0$. This invalidates the claimed uniform boundedness of $\\Lpnorm{\\nabla \\presh}{p}{\\Omegah}$ for $p<2$."
      }
    ],
    "token_usage": {
      "input": 49582,
      "thinking": 24999,
      "output": 1734
    }
  },
  {
    "entry_id": 97,
    "retraction_id": "1507.00282v2",
    "paper_id": "1507.00282v1",
    "retraction_comment": "This paper has been withdrawn due to a crucial error in the proof of Proposition 14. The authors are very thankful to [REDACTED-NAME] for kindly pointing it out",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition of the Nijenhuis tensor components $N_i$ in Section 6 implicitly implies $N=0$ from the outset.",
        "Location": "Section 6, paragraph 1, page 7",
        "Explanation": "The paper defines $N_{e_i}$ (for $i=1,2,3,4$) as $N_{e_1} = N_1\\rho+N_2J\\rho$, $N_{e_2} = N_2\\rho-N_1J\\rho$, etc. The notation $J\\rho$ is used for the second basis element of $\\Lambda_J^-(M)$, let's call it $\\rho_2$. The operator $J$ acts on $\\Lambda_J^-(M)$ via $(J\\alpha)(X,Y) = -\\alpha(JX,Y)$. For the basis $(\\rho, \\rho_2)$, this means $J\\rho = \\rho_2$ and $J\\rho_2 = -\\rho$. The components $N_X(Y,Z) = g(X, N(Y,Z))$ must satisfy $N_{JX} = JN_X$ due to $J$'s properties and $g$-compatibility (specifically $JN(Y,Z)=-N(JY,Z)$ from Eq. (3) and $g(JX,V)=g(X,JV)$ is not it, rather $g(JX,V)=-g(X,J^{-1}V)$ and $J$ is $g$-orthogonal). The relation $N_{Je_i}=JN_{e_i}$ is $N_{e_2} = JN_{e_1}$. $JN_{e_1} = J(N_1\\rho + N_2\\rho_2) = N_1(J\\rho) + N_2(J\\rho_2) = N_1\\rho_2 - N_2\\rho$. The paper states $N_{e_2} = N_2\\rho - N_1\\rho_2$. Thus, $N_1\\rho_2 - N_2\\rho = N_2\\rho - N_1\\rho_2$, which implies $2N_1\\rho_2 = 2N_2\\rho$. Since $\\rho$ and $\\rho_2$ are linearly independent, this forces $N_1=0$ and $N_2=0$. Similarly, $N_3=0$ and $N_4=0$. This means the setup assumes $N=0$ before attempting to prove it, invalidating the core argument of Section 6."
      },
      {
        "Problem": "Lemma 5.1 (diff_type) is incorrect for general almost-Kähler manifolds.",
        "Location": "Section 5, Lemma 5.1, page 5",
        "Explanation": "Lemma 5.1 states that for $Z\\in T^{1,0}M, \\bar{W}\\in T^{0,1}M$, we have $\\nabla_Z\\bar{W}\\in T^{0,1}M$ and $\\nabla_{\\bar{W}}Z\\in T^{1,0}M$. The paper claims this is a direct consequence of Eq. (6) ($(\\nabla_X J)J = -J(\\nabla_X J)$). This identity implies $(\\nabla_X J)$ maps $T^{1,0}M \\to T^{0,1}M$ and $T^{0,1}M \\to T^{1,0}M$. If $\\bar{W} \\in T^{0,1}M$, then $(\\nabla_Z J)\\bar{W} \\in T^{1,0}M$. Let $V = (\\nabla_Z J)\\bar{W}$. Then $V = \\nabla_Z(J\\bar{W}) - J(\\nabla_Z\\bar{W}) = -i\\nabla_Z\\bar{W} - J(\\nabla_Z\\bar{W})$. If Lemma 5.1 holds (i.e. $\\nabla_Z\\bar{W} \\in T^{0,1}M$), then $J(\\nabla_Z\\bar{W}) = -i\\nabla_Z\\bar{W}$. Substituting this into the expression for $V$ gives $V=0$. So, Lemma 5.1 implies $(\\nabla_Z J)\\bar{W}=0$. This condition, $(\\nabla_X J)Y=0$ if $X,Y$ are of different types, is not true for general almost-Kähler manifolds; it defines a specific subclass (e.g., nearly K\\\"ahler manifolds satisfy $(\\nabla_X J)X=0$, not this). The lemma as stated is characteristic of K\\\"ahler manifolds (where $\\nabla J=0$). If the manifold is K\\\"ahler, the main theorem is trivial as $N=0$ by definition."
      },
      {
        "Problem": "The proof of Proposition 5.3 (first_relation) relies on the incorrect Lemma 5.1.",
        "Location": "Section 5, Proposition 5.3, page 5-6",
        "Explanation": "The derivation of Eq. (9) for $(d\\phi)^{1,2}$ explicitly states 'An application of Lemma~\\ref{diff_type} reduces this expression to...'. Specifically, terms like $\\phi(\\bar{Z}_2,\\nabla_{\\bar{Z}_1}Z_3)$ and $\\phi(\\nabla_{\\bar{Z}_2}Z_3,\\bar{Z}_1)$ must vanish for the subsequent steps in the proof to hold. These terms vanish if $\\nabla_{\\bar{W}}Z \\in T^{1,0}M$ (as stated in Lemma 5.1). However, as argued in the previous point, Lemma 5.1 is incorrect for general almost-Kähler manifolds. If Lemma 5.1 is false, these terms do not necessarily vanish, and the formula for $(d\\phi)^{1,2}$ in Eq. (9), and consequently Proposition 5.3, are not proven in the claimed generality. Proposition 5.3 is crucial for Proposition 6.1 (ratio), which is the main technical result leading to Theorem 1."
      },
      {
        "Problem": "The calculation of $N(J\\phi)(e_2,e_3,e_4)$ in the proof of Proposition 6.1 (ratio) appears incorrect.",
        "Location": "Section 6, Proposition 6.1, Eq. (13), page 8",
        "Explanation": "In the proof of Prop. 6.1, it is stated that $2N(J\\phi)(e_2,e_3,e_4) = 4N_1v - 4N_2 u$. The term $N(J\\phi)(e_2,e_3,e_4)$ is defined as $(J\\phi)(e_2,N(e_3,e_4))+(J\\phi)(e_3,N(e_4,e_2))+(J\\phi)(e_4,N(e_2,e_3))$. Using the definitions of $N(e_i,e_j)$ components from earlier in Section 6 (e.g., $N(e_2,e_3) = N_2 e_1 -N_1 e_2 + N_4 e_3 -N_3 e_4$, and $N(e_3,e_4)=0$), and $J\\phi = -v\\rho+uJ\\rho$, a term-by-term calculation yields $2N(J\\phi)(e_2,e_3,e_4) = 4vN_1$. This differs from the paper's $4N_1v - 4N_2u$. If this calculation is indeed $4vN_1$, then the relation derived in Prop. 6.1 would change from $uN_2=vN_1$ to $3vN_1=uN_2$ (assuming Prop. 5.5 is correct and $N_i$ are well-defined). While the overall structure of the proof of Theorem 1 might survive such a change, this discrepancy points to a significant error in a key calculation. This issue is secondary to the problem with the definition of $N_i$ components, which makes $N_1, N_2$ zero from the start."
      }
    ],
    "token_usage": {
      "input": 12143,
      "thinking": 30883,
      "output": 1921
    }
  },
  {
    "entry_id": 98,
    "retraction_id": "1707.00947v2",
    "paper_id": "1707.00947v1",
    "retraction_comment": "I am so sorry, the hypothesis proposed by this paper would be not appropriate because there is no mechanism on which can be based between money and output value in this paper. The equation maybe more empty",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsupported 'Natural Cycle' Mechanism",
        "Location": "Page 14, Figure 2, Section 'The hypothesis of natural cycle and driving cycle'",
        "Explanation": "The core model (Equation 2) describes convergence to a long-run equilibrium path (e.g., c=q-g). The 'Natural Cycle' hypothesis posits that the economy makes periodic movements *along* this path even when money growth (q) is constant. This cyclical movement along the equilibrium line is not derived from or explained by the mechanics of Equation 2, which details how the economy reaches the line, not how it oscillates along it. This is a critical gap, as the Natural Cycle is a fundamental component of the paper's business cycle theory."
      },
      {
        "Problem": "Empirical Rules Not Derived from Core Model",
        "Location": "Pages 22-23, Section 'The economic cycle of China'",
        "Explanation": "The 'Buffer Rule' (e.g., a buffer period before a Double Drop) and aspects of the 'Sensitivity Rule' (e.g., why an economy is at risk of crisis if q is near g, beyond c being near 0) are presented as outcomes or explanations within the model's framework. However, these rules appear to be primarily empirical observations from Chinese data or qualitative arguments. The core dynamic equation (Equation 2), being a first-order ODE, does not inherently predict such buffer periods or the specific mechanisms of sensitivity described without further assumptions or model extensions."
      },
      {
        "Problem": "Counterintuitive Inflation Dynamics for Non-Exponential Money Growth",
        "Location": "Page 9, conclusion of analysis for M(t)=V₀t, and subsequent generalization",
        "Explanation": "The model predicts that long-run inflation c ≈ -g for any non-exponential money supply growth (e.g., M(t)=constant or M(t)=V₀t). This implies that different forms of sustained, non-exponential money growth (like constant money supply versus linearly increasing money supply) have the same long-run impact on the inflation rate. This is a strong and counterintuitive claim compared to standard monetary theories where persistently faster, even if not exponential, money growth typically leads to higher inflation. While mathematically derived from Equation 2, its general economic soundness is questionable."
      },
      {
        "Problem": "Unexplored Nature and Impact of Parameter 'k'",
        "Location": "Page 5 (definition of k), Pages 10-11 (role in inflation regimes), Pages 12-13 (empirical test)",
        "Explanation": "The parameter 'k', representing the characteristic time for adjustment, is crucial for the model's dynamics. It influences the speed of convergence and determines the threshold (q = -1/k) for different long-run inflation behaviors. The paper does not discuss the determinants of 'k', its stability, or how it might vary with economic conditions (e.g., q, g, or institutional factors). The empirical validation of c=q-g (Figure 1) implicitly assumes q > -1/k for all observations and does not attempt to estimate or control for 'k', potentially limiting the robustness of the empirical support for the claimed c=q-g path."
      },
      {
        "Problem": "Over-interpretation of Model Output as Structural Functions",
        "Location": "Page 12, discussion of Equation (16) P(Y)",
        "Explanation": "Equation (2) is a macroeconomic adjustment model for nominal sales (PY) based on the gap M-PY. The paper interprets its solution, particularly Equation (16) which expresses price P as a function of output Y (derived by substituting time out of P(t) and Y(t)), as 'both a demand function of product and a supply function of product.' This is an overstatement, as the model does not derive these relationships from microeconomic foundations of optimizing agents or market clearing conditions typically associated with structural supply and demand functions. It's an outcome of an aggregate adjustment dynamic."
      }
    ],
    "token_usage": {
      "input": 7606,
      "thinking": 7584,
      "output": 887
    }
  },
  {
    "entry_id": 99,
    "retraction_id": "2212.04536v2",
    "paper_id": "2212.04536v1",
    "retraction_comment": "Thm. A, Cor. B, are incorrect as stated and would require additional assumptions on q (a result of a missing assumption in another paper). Withdrawn until I obtain a working solution",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 12409,
      "thinking": 19385,
      "output": 1
    }
  },
  {
    "entry_id": 100,
    "retraction_id": "1405.2435v10",
    "paper_id": "1405.2435v9",
    "retraction_comment": "lemmas 11 is wrong. The conjecture is not proved.",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Theorem 4 is unsound.",
        "Location": "Theorem 4, p. 12",
        "Explanation": "Theorem 4 claims an improved bound if a letter $\\alpha$ exists such that $|\\Gamma\\alpha| < |\\Gamma|-1$ (i.e., $|N(\\alpha)| \\leq n-2$). The proof states: 'there are at the beginning for the first letter $\\alpha$ at least three linear independent matrices $L_x$... i.e three roots.' This claim is not justified; for a given $\\alpha$, $M_\\alpha L_x = M_s$ defines one minimal $L_x$. The subsequent claim 'Therefore the length of every path is at most $n(n-2)-1$' also appears without justification. The argument from Lemma 12, when applied with $(S,x_{root}) \\leq n-3$ (derived from $|N(\\alpha)| \\leq n-2$), yields $k_{max} = n-2$ levels for $(S,x)$, leading to a length bound of $(n-2)n+1 = (n-1)^2$, which is not an improvement. The reasoning for the tighter bound $n(n-2)$ is missing and seems incorrect based on the provided framework."
      },
      {
        "Problem": "The proof of Corollary 17 is unsound.",
        "Location": "Corollary 17, p. 12",
        "Explanation": "The proof of Corollary 17 states it 'repeats the proof of Theorem t4 for case of two roots.' Since the proof of Theorem 4 is unsound and lacks justification for its claims (particularly the shortened path length), Corollary 17, which relies on the same flawed reasoning, is also not properly established."
      },
      {
        "Problem": "Potentially problematic step in Lemma 11 (v12) regarding $L_x = L_{\\beta y}$.",
        "Location": "Lemma 11 (v12), p. 9, around eq. (3) (xby)",
        "Explanation": "The argument states: 'common $M_u$ and minimality of solutions imply $L_x=L_{\\beta y}$ by Lemma l5.' Lemma l5 discusses $L_x \\sqsubseteq_q L_z$ for solutions of $M_u L_z = M_s$. $L_{\\beta y}$ is notation for an $L$-matrix associated with a hypothetical word '$\\beta y$', which is not well-defined as $y$ is a matrix (representing $L_y$). While the paper later clarifies this to $L_x = M_\\beta L_y$ by arguing $L_x \\sim_q M_\\beta L_y$ and both are $L$-matrices in $W_m$ (sharing the same two active columns and $q$-column definition), the initial phrasing $L_x=L_{\\beta y}$ and its direct attribution to Lemma l5 is confusing and potentially a point of error if $L_{\\beta y}$ was intended differently. The subsequent argument for $L_x = M_\\beta L_y$ seems to resolve this, but the initial step is stated imprecisely."
      },
      {
        "Problem": "The proof of Lemma 2 (v3) is poorly explained and hard to follow.",
        "Location": "Lemma 2 (v3), p. 3",
        "Explanation": "While the statement of Lemma 2 (v3) regarding the dimension of the space of matrices of words with $k$ active columns ($n(k-1)+1$) is a known result in automata theory, the proof provided in this paper is difficult to follow. Specifically, the step '$\\sum V_{i,j} - (m-1)K=T$' is unclear, as $m$ is not well-defined in relation to an arbitrary matrix $T$, and the coefficient of $K$ would generally need to vary per row for this equality to hold. Although the lemma's statement is likely correct, its proof within the paper is not convincing as presented, which could be an issue if subtle variations of this lemma were needed later."
      }
    ],
    "token_usage": {
      "input": 23211,
      "thinking": 25163,
      "output": 939
    }
  },
  {
    "entry_id": 101,
    "retraction_id": "1705.07013v2",
    "paper_id": "1705.07013v1",
    "retraction_comment": "The proofs involve use of structured input states which could not be generalized",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent treatment of the blank state vector under covariance.",
        "Location": "Section II, discussion of covariance (page 2, after Eq. 8) and its use in Eq. 9 and Eq. \ref{eq:nsc}.",
        "Explanation": "The paper's application of covariance (axial symmetry around input state vector $\\vec{m}$) leads to conditions like $b_y=b_z=0$ if $\\vec{m}$ is x-directed, implying the blank state's Bloch vector $\\vec{b}$ must align with $\\vec{m}$. This contradicts the requirement for a universal deletion machine, where the target blank state $|\\Sigma\rangle$ (and its Bloch vector $\\vec{b}$) must be fixed and independent of $\\vec{m}$. This inconsistency is fundamental because it means the derived framework is only valid if the second qubit's output $\\rho_2^{out}$ is the maximally mixed state (i.e., $F_d = 0.5$). However, the paper's analysis and results (e.g., plots in Fig. 1 and 2) consider $F_d > 0.5$. The derivation of constraints in Eq. \ref{eq:nsc} appears to use different effective $\\vec{b}$ vectors for inputs $\\rho^{out}(\\shortrightarrow)$ versus $\\rho^{out}(\\uparrow)$, which is unsound for a single machine with a fixed blank state."
      },
      {
        "Problem": "Unsupported assumption about the machine's output for non-identical inputs.",
        "Location": "Section II, Eq. 11 and the subsequent derivation of Eq. \ref{eq:nsc}.",
        "Explanation": "To apply the no-signaling condition (NCT), the paper considers the deletion machine's action on non-identical input states like $\\rho(\\uparrow)\\otimes\\rho(\\downarrow)$. It assumes that the machine transforms these inputs into pure quantum states (e.g., $U_d \\otimes U_d(\\rho(\\uparrow)\\otimes\\rho(\\downarrow))U^\\dagger_d \\otimes U^\\dagger_d = |\\phi\\rangle\\langle\\phi|$). This assumption is highly restrictive and lacks justification. A general quantum channel, which an imperfect deletion machine represents, would typically map such inputs to mixed states, especially if the inputs themselves can be mixed or if ancillas are involved and traced out. This unsubstantiated pure-state output assumption significantly impacts the derived constraints in Eq. \ref{eq:nsc} and, consequently, the main result on the fidelity bound. Additionally, the notation $U_d \\otimes U_d$ for the transformation of these non-symmetric states is ambiguous, as a deletion machine is typically defined for symmetric inputs $|\\psi\\rangle|\\psi\\rangle$, and its action on other inputs requires careful, general definition."
      },
      {
        "Problem": "Inconsistency or typo in the definition of the output state $\\rho^{out}_{12}(\\shortrightarrow)$ under covariance.",
        "Location": "Section II, Eq. 9 and the preceding covariance conditions on page 2.",
        "Explanation": "The symbolic expression for the output state $\\rho^{out}_{12}(\\shortrightarrow)$ in Eq. 9 includes the term $\\mathbb{I} \\otimes (\\eta_{2}b_z\\sigma_z)$. However, the covariance conditions derived immediately before this equation (for an input state $\\vec{m}$ in the x-direction) state that $b_z=0$ and $b_y=0$. If $b_z=0$, this term should vanish. The matrix representation of $\\rho^{out}_{12}(\\shortrightarrow)$ provided below Eq. 9 includes terms like $b_x\\eta_2$, which suggests the symbolic term should have been $\\mathbb{I} \\otimes (\\eta_{2}b_x\\sigma_x)$. This discrepancy indicates a potential error or inconsistency in constructing the output state form after applying covariance. Such an error would affect the subsequent derivation of constraints in Eq. \ref{eq:nsc}, as different terms in $\\rho^{out}_{12}$ would lead to different algebraic relations when the NCT is applied."
      }
    ],
    "token_usage": {
      "input": 8093,
      "thinking": 15577,
      "output": 942
    }
  },
  {
    "entry_id": 102,
    "retraction_id": "1801.01544v2",
    "paper_id": "1801.01544v1",
    "retraction_comment": "We withdraw the manuscript because Lemma 2.3 is false",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent range for parameter 's' and its impact on proofs.",
        "Location": "Abstract states s in (1/2, 1). Page 2, after Eq. (1.1), states s in (0,1). Theorem 1.2 implicitly assumes s in (0,1) via definition of pc. However, the proof of Theorem 3.1 (a version of Theorem 1.2 for f(u)=u^p) on Page 10, for estimate (3.14), explicitly states 'we have used s > 1/2'.",
        "Explanation": "The paper presents conflicting ranges for the fractional order 's'. The abstract specifies s in (1/2, 1), while the main body often implies s in (0,1) for key definitions and theorems (e.g., Theorem 1.2). A critical step in the proof of the a priori estimates (Theorem 3.1 / Theorem 1.2) explicitly requires s > 1/2 (page 10, derivation of Lipschitz continuity for w_k). If the theorems are meant to hold for s in (0,1), this part of the proof is invalid for s <= 1/2. This ambiguity affects the scope and validity of the main results."
      },
      {
        "Problem": "Unusual and potentially problematic definition of the test function space X_s(Omega).",
        "Location": "Page 4, Definition 1.5, condition (iii).",
        "Explanation": "The definition of the test function space X_s(Omega), used for defining weak solutions (Definition 1.5), includes a highly non-standard condition (iii): 'there exists phi in L^1(Omega, delta^s) and epsilon_0 > 0 such that |(-Delta)^(epsilon/2)_x zeta(x)| <= phi(x) a.e. in Omega, for all epsilon in (0, epsilon_0]'. This condition, requiring a uniform L^1(Omega, delta^s) bound for fractional Laplacians of the test function zeta for a continuous range of small orders epsilon, is very restrictive. It is unclear if this space X_s(Omega) is sufficiently large (e.g., non-trivial beyond the zero function, or dense in any useful larger space) for the theory of weak solutions to be well-posed or standard. If X_s(Omega) is too small, the notion of weak solution might be too weak or ill-defined, which would be a foundational issue for several results relying on this definition (e.g., Theorem 1.7, Theorem 1.8)."
      },
      {
        "Problem": "Flawed derivation of a key estimate in Lemma 4.1 used for Theorem 1.8.",
        "Location": "Page 14, Equations (4.5)-(4.7) in the proof of Lemma 4.1.",
        "Explanation": "Lemma 4.1 provides an L^p estimate for solutions, which is then used in Theorem 1.8 to prove the finiteness of the critical parameter rho*. The derivation of estimate (4.7) from (4.5) and (4.6) is problematic. Specifically, the application of Young's inequality as presented in (4.6) is not standard, and the algebraic steps leading from (4.5) and (4.6) to (4.7) appear incorrect or are at least unclearly justified with the given forms. An error in (4.7) would undermine the proof that rho* is finite in Theorem 1.8, Case I."
      },
      {
        "Problem": "Error in an application of Hölder's inequality and its propagation in the proof of Lemma 4.3.",
        "Location": "Page 16, Equations (4.19), (4.20), and the subsequent algebraic equation for hat(Lambda) in the proof of Lemma 4.3.",
        "Explanation": "In the proof of Lemma 4.3, which establishes existence for an auxiliary problem used in Theorem 1.7, estimate (4.19) incorrectly applies Hölder's inequality (or a related inequality). It states 'integral v^p delta^s dx <= C (integral v^q delta^s dx) ...' where the term (integral v^q delta^s dx) should be raised to the power p/q. This error affects the subsequent estimate (4.20), which should be Q(S_n(v)) <= C(a Q(v)^p + ...)^(1/q) instead of C(a Q(v)^p + ...), and consequently alters the algebraic equation used to find the bound hat(Lambda). While the existence of such a hat(Lambda) might still hold under a corrected derivation, the proof as presented is flawed. Lemma 4.3 is a step towards proving the main existence result Theorem 1.7."
      }
    ],
    "token_usage": {
      "input": 7090,
      "thinking": 19032,
      "output": 1090
    }
  },
  {
    "entry_id": 103,
    "retraction_id": "2101.02111v2",
    "paper_id": "2101.02111v1",
    "retraction_comment": "We have found some data mistakes in our paper. The inverse transition in Section 3 (Figure 3d) and 7.1 (Figure 31) is probably consequence of inappropriate mesh configuration",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and likely incorrect formulation of curvature-induced production terms in Reynolds Stress Transport Equations.",
        "Location": "Section 5.2, Equations (20), (21), (22). Specifically terms denoted $\\mathfrak{G}_1$ and $\\mathfrak{G}_2$.",
        "Explanation": "The Reynolds stress transport equations for $\\overline{u_r'u_r'}$, $\\overline{u_\\theta'u_\\theta'}$, and $\\overline{u_z'u_r'}$ include terms arising from mean circumferential velocity $\\overline{u_\\theta}$ due to pipe curvature. For instance, the term $2 \\overline{u_r' u_\\theta'} \\overline{U_\\theta} / r$ should act as a source for $\\overline{u_r'u_r'}$ and a sink for $\\overline{u_\\theta'u_\\theta'}$, ensuring energy conservation between these components. Equation (20) uses $4\\mathfrak{G}_1$ (where $\\mathfrak{G}_1 = \\overline{u_r'u_\\theta'} \\overline{U_\\theta}/r$) as a source for $\\overline{u_r'u_r'}$, while Equation (21) uses $2\\mathfrak{G}_1$ as a source for $\\overline{u_\\theta'u_\\theta'}$. This is inconsistent in factors and signs, as one should be a sink if the other is a source. Similarly, the term $\\mathfrak{G}_2$ in Equation (22) for the $\\overline{u_z'u_r'}$ budget appears with a factor of 2, which may be incorrect compared to standard derivations (e.g., Pope 2000, Table 7.2). These errors affect the quantitative analysis of inter-component energy transfer and the interpretation of how control modifies individual Reynolds stress components."
      },
      {
        "Problem": "Flawed formulation of the global Turbulent Kinetic Energy (TKE) budget.",
        "Location": "Section 5.3, Equation (25), Equation (26) (third line), and consequently Table 2.",
        "Explanation": "The global TKE budget, as presented in Equation (25) and the third line of Equation (26) ($[\\mathfrak{G}_1]_g + {\\wp}_z + {\\wp}_\\theta  = {\\aleph _u}$), incorrectly includes the term $[\\mathfrak{G}_1]_g$ (defined as $[\\overline{u_r'u_\\theta'} \\overline{u_\\theta}/r]_g$) as a net source for TKE. The term $\\overline{u_r'u_\\theta'} \\overline{U_\\theta}/r$ (or its correctly formulated version) represents an energy transfer between the radial and circumferential Reynolds stress components ($R_{rr}$ and $R_{\\theta\\theta}$). As such, its integrated effect should sum to zero in the budget for the total TKE ($k = (R_{rr}+R_{\\theta\\theta}+R_{zz})/2$) and not appear as a net source or sink. This error means the total TKE production is likely miscalculated, which invalidates the quantitative results for turbulent dissipation $\\aleph_u$ presented in Table 2 and undermines the conclusions drawn about the global energy balance and the relative importance of different energy pathways under control. The Mean Kinetic Energy (MKE) budget for $U_\\theta$ (second line of Eq 26) also appears to mishandle this energy transfer term."
      },
      {
        "Problem": "Speculative and potentially unsound explanation for the effect of control wavelength based on streak instability theory.",
        "Location": "Section 6.1, page 25, last paragraph.",
        "Explanation": "The paper attempts to explain why larger control wavelengths ($\\lambda_z^+$) lead to greater drag reduction by invoking Schoppa & Hussain's (2002) theory on the intrinsic instability of low-speed streaks, which identifies an optimal unstable wavelength around $L_z^+ \\approx 315$. The argument suggests that control forcing at wavelengths far from this optimal (e.g., larger $\\lambda_z^+$) results in less 'active' or more suppressed streaks and hence lower turbulence. This link is tenuous because Schoppa & Hussain's theory pertains to the linear stability of pre-existing, idealized streaks, whereas the current control actively forces and shapes these structures. The dynamics are governed by the forced response to wall motion, not just the intrinsic instability characteristics of an unforced streak at the imposed wavelength. The paper itself acknowledges that this reasoning leads to contradictions for control wavelengths shorter than the optimal streak instability wavelength, and then resorts to arguments based on Spatial Stokes Layer thickness. This indicates that the streak instability argument is not a robust or comprehensive explanation for the observed parametric trend of drag reduction with control wavelength."
      }
    ],
    "token_usage": {
      "input": 45900,
      "thinking": 13859,
      "output": 1088
    }
  },
  {
    "entry_id": 104,
    "retraction_id": "1703.04839v2",
    "paper_id": "1703.04839v1",
    "retraction_comment": "Our discussion omits the dominant tree-level shift (discussed in 1203.0237) of the Higgs quartic coupling in the full theory relative to the Higgs quartic coupling of the low-energy effective Standard Model. This shift can easily the electroweak vacuum. Therefore our conclusions (and upper bound on $f_a$) are invalid",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect term in the Renormalization Group Equation for $\\lambda_{h \\phi}$",
        "Location": "Page 2, Section 2, Eq. (e4)",
        "Explanation": "The RGE for $\\lambda_{h \\phi}$ includes a term $12 \\lambda_{h} \\lambda_{\\phi}$. Based on standard RGEs for similar systems (e.g., a complex scalar coupled to the Higgs), this term should likely be $12 \\lambda_{h} \\lambda_{h \\phi}$. Given that $\\lambda_{\\phi}$ (PQ scalar self-coupling) can be much smaller than $\\lambda_{h \\phi}$ (portal coupling), this discrepancy can lead to a significantly different running for $\\lambda_{h \\phi}$. For instance, using the paper's typical values at $m_t$ ($\\lambda_h \\approx 0.126, \\lambda_{h\\phi} \\approx 0.38, \\lambda_\\phi \\approx 0.03$), the term $12 \\lambda_h \\lambda_\\phi \\approx 0.045$, whereas $12 \\lambda_h \\lambda_{h\\phi} \\approx 0.57$. This order-of-magnitude difference in a key term would substantially alter the evolution of $\\lambda_{h \\phi}$, which in turn affects the stabilization conditions and the derived bound on $f_a$."
      },
      {
        "Problem": "Incorrect coefficient for the PQ scalar contribution to $\\beta_{\\lambda_h}$",
        "Location": "Page 2, Section 2, Eq. (e2)",
        "Explanation": "The one-loop contribution from the PQ scalar $\\Phi$ to the beta function of the Higgs self-coupling $\\lambda_h$ is given as $\\kappa \\Delta \\beta_{\\lambda_{h}} = s_{\\phi} \\lambda_{h \\phi}^{2}$. For a complex scalar field $\\Phi$ coupling to the Higgs via $\\lambda_{h\\phi} |\\Phi|^2 |H|^2$, the standard coefficient for this term is $2 \\lambda_{h \\phi}^{2}$ (assuming $s_\\phi=1$ as a threshold switch). The paper's equation is missing a factor of 2. This means the stabilizing effect of the PQ scalar on the Higgs potential is underestimated by a factor of 2. Consequently, the value of $\\lambda_{h \\phi}$ required to achieve stability would be smaller by a factor of $\\sim 1/\\sqrt{2}$. This would quantitatively affect the derived bounds and parameter values, potentially relaxing the upper bound on $f_a$."
      },
      {
        "Problem": "Sign error in the KSVZ fermion contribution to $\\beta_{g_3}$",
        "Location": "Page 2, Section 2, Eq. (e1)",
        "Explanation": "The one-loop contribution from the KSVZ fermions $Q$ (color triplets) to the beta function of the strong coupling constant $g_3$ is given as $\\kappa \\Delta \\beta_{g_{3}} = -\\frac{2}{3} g_{3}^{3}$. New fermions increase the number of degrees of freedom coupled to gluons, which screens the strong charge and makes the theory less asymptotically free (i.e., $g_3$ runs slower or towards larger values). This corresponds to a positive contribution to $\\beta_{g_3}$ (or a negative contribution to the $b_0$ coefficient $-(b_0^{SM} + \\Delta b_0)$). The standard contribution for one Dirac fermion in the fundamental representation of SU(3) is $\\Delta (\\beta_{g_3}) = +\\frac{2}{3} \\frac{g_3^3}{16\\pi^2}$. Thus, $\\kappa \\Delta \\beta_{g_3}$ should be $+\\frac{2}{3} g_{3}^{3}$. This sign error affects the running of $g_3$, which in turn influences the running of other parameters like the top Yukawa coupling $y_t$ and subsequently $\\lambda_h$, potentially altering the SM instability scale $\\mu_0$ and the conditions for stabilization."
      }
    ],
    "token_usage": {
      "input": 8870,
      "thinking": 17152,
      "output": 948
    }
  },
  {
    "entry_id": 105,
    "retraction_id": "1704.03487v2",
    "paper_id": "1704.03487v1",
    "retraction_comment": "Due to the limitations of the interatomic potential used, it was not possible to ensure the accuracy of some of the results in the paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Orowan Stress Calculation and Interpretation",
        "Location": "Section 4.2, paragraph 3 (page 8); Conclusions, paragraph 2 (page 12)",
        "Explanation": "The Orowan stress $\\tau_O = \\mu b/L$ is calculated using $L = 33 \\text{ nm}$, stated as 'the width of the periodic simulation cell.' This $L$ should represent the inter-precipitate spacing or effective obstacle diameter for dislocation bowing. Using the cell width is incorrect for evaluating the Orowan stress for a single precipitate. A correct calculation (e.g., $L \\approx$ precipitate diameter) would likely yield a much higher $\\tau_O$. The paper's conclusion that the simulated CRSS for shearing is 'higher than the Orowan stress' is therefore based on a flawed premise. This miscalculation critically affects the interpretation of why shearing occurs instead of Orowan looping, as shearing is typically expected when it requires less stress than looping."
      },
      {
        "Problem": "Insufficient Justification for Interatomic Potential Selection",
        "Location": "Section 3.1, paragraph 2 (page 4)",
        "Explanation": "The Mendelev potential was chosen because other potentials (Liu, Kim) reportedly showed 'spurious jog development' where dislocations climbed and slipped along the precipitate/matrix interface instead of fully shearing the precipitate. This behavior was dismissed as an 'artifact' primarily because the jog length scaled with precipitate height. This scaling does not sufficiently prove the behavior is an artifact; it could be a physical mechanism. If interface sliding or complex jog dragging are viable deformation modes, selecting a potential that does not exhibit these behaviors may lead to an incomplete or biased understanding of the dislocation-precipitate interaction, potentially overemphasizing the direct shearing mechanism. The conclusion that precipitates are *always* sheared might be a consequence of this potential choice."
      },
      {
        "Problem": "Inconsistency Regarding Effects of Successive Shearing",
        "Location": "Section 4.1, last paragraph (page 7, describing Fig. 7); Section 4.2, paragraph discussing Fig. 10 (page 10); Conclusions, paragraph 1 (page 12)",
        "Explanation": "The paper reports that successive shearing of precipitates leads to the formation of steps and 'voids due to matrix/interface debonding' (Fig. 7). Such damage at the interface would be expected to alter the interaction strength. However, it is later stated and shown (Fig. 10) that 'multiple cutting of precipitates by the dislocations did not change the CRSS.' These two findings appear contradictory. If significant interfacial debonding and voiding occur, the CRSS for subsequent dislocations should arguably be affected. The paper does not reconcile this apparent inconsistency, which casts doubt on the understanding of damage accumulation and its effect on strengthening."
      },
      {
        "Problem": "Use of Non-Standard Model for Activation Free Energy",
        "Location": "Section 4.3, Equation (4) and its description (page 10); Figure 11 and its discussion (page 11)",
        "Explanation": "The paper uses the phenomenological model $\\Delta F = \\Delta F_0 (1 - \\tau/\\tau_c)^{2/3}$ to describe the stress dependence of the activation free energy. This specific functional form with an exponent of $2/3$ is unusual and differs from more commonly accepted models for thermally activated dislocation motion (e.g., Kocks-Mecking type models often involve exponents like $1$ or $3/2$ for the entire bracket, or different $p,q$ powers). Using a non-standard or potentially incorrect model can lead to inaccurate estimation of the zero-stress activation energy $\\Delta F_0$ and misinterpretation of the thermal sensitivity of the shearing process, particularly when fitting limited MD data and comparing with other material systems."
      }
    ],
    "token_usage": {
      "input": 16979,
      "thinking": 6526,
      "output": 863
    }
  },
  {
    "entry_id": 106,
    "retraction_id": "2402.04633v2",
    "paper_id": "2402.04633v1",
    "retraction_comment": "An auxiliary result (Theorem 2.4) turns out to be wrong. This invalidates the proof of the main result",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 39540,
      "thinking": 21491,
      "output": 1
    }
  },
  {
    "entry_id": 107,
    "retraction_id": "2408.08124v4",
    "paper_id": "2408.08124v3",
    "retraction_comment": "Achieving reliable simulation of closed new domain formation processes using a single phase-field method is unconvincing and requires the use of multiple algorithms for parallel comparison with experiments",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of cutoff frequency (ft)",
        "Location": "Page 3, left column, near end of Section III; Equation (3)",
        "Explanation": "The claimed cutoff frequency of 0.228 THz is inconsistent with the provided transconductance (gm = 2.75 µS) and input capacitance (Cin = 12.10 aF). Using the formula ft = gm / (2π * Cin) from Equation (3), the calculated frequency is approximately 36.17 GHz. This is significantly lower than claimed (by a factor of ~6.3) and not generally considered 'sub-terahertz level' in this context, undermining a primary performance claim of the paper."
      },
      {
        "Problem": "Incorrect Fowler-Nordheim equation parameters (AFN and BFN)",
        "Location": "Page 1, Section I, Equations (2.1)-(2.3)",
        "Explanation": "The Fowler-Nordheim equations (2.1-2.3) for current density JFN use parameters AFN and BFN. The provided `AFN = 1.54 × 10^-6 × φ` (Eq. 2.2) and `BFN = 8.83 × 10^7 × φ^(3/2)` (Eq. 2.3) are incorrect. Standard AFN is proportional to `1/φ` (e.g., `1.54 × 10^-6 / φ  A eV / V^2`), not `φ`. The numerical prefactor in BFN (`8.83 × 10^7`) also differs from the commonly accepted value of `6.83 × 10^7` (for electric field E in V/cm). These inaccuracies in fundamental field emission equations would lead to erroneous simulated emission currents and derived device parameters like transconductance (gm), impacting the overall quantitative validity of the simulations."
      },
      {
        "Problem": "Unsupported claim of 'spontaneous stopping' of sacrificial etch process",
        "Location": "Page 2, Section II, paragraph 2",
        "Explanation": "The paper claims that the sacrificial etching process, critical for forming the vacuum cavity, 'can be stopped spontaneously due to the chemical difference between the cathode material (Lanthanum Hexaboride) and the sacrificial layer medium.' However, the sacrificial material and etchant are not specified, and no data or references are provided to substantiate this claim of highly selective, spontaneous etch stop on LaB6. This is a critical assumption for the proposed fabrication process, and its lack of support raises concerns about feasibility."
      },
      {
        "Problem": "Contradictory statements regarding the necessity of an additional lithography step",
        "Location": "Page 2, Section III, paragraphs 2 and 4; Fig. 2",
        "Explanation": "The paper presents conflicting information regarding an additional lithography step for self-packaging. Initially (paragraph 2), it states that 'an additional step of lithography was additionally considered to obtain tilt-coating steps on reliable self-packaged microcavity formation.' However, later (paragraph 4), it claims this step (illustrated in Fig. 2b vs 2c) 'is nonessential'. This contradiction creates ambiguity about the actual fabrication process and the requirements for achieving reliable self-packaged microcavities. The figures do not sufficiently clarify why this step would be nonessential for reliable cavity sealing."
      },
      {
        "Problem": "Lack of demonstration for claimed stability improvement",
        "Location": "Abstract; Section III (Results and Discussion)",
        "Explanation": "The abstract claims that the self-packaged microcavity improves 'the frequency performance and stability of the device.' While frequency performance (cutoff frequency) is addressed (albeit with calculation errors), there is no specific data, simulation, or discussion presented in Section III (Process and Performance Simulation) to substantiate the claim of improved 'stability.' Stability could refer to reduced noise, less current fluctuation, or robustness to environmental changes, none of which are quantitatively demonstrated for the proposed device."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 6076,
      "output": 901
    }
  },
  {
    "entry_id": 108,
    "retraction_id": "1901.08297v2",
    "paper_id": "1901.08297v1",
    "retraction_comment": "The significance and novelty of the paper were not addressed. There are a couple of errors about calculations: the excitonic decay rates were computed by solving Eq (11), not based on Eq. (13) that was only an initial guess for the decay rate",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified exclusion of states with large vibronic coupling in non-radiative rate calculations.",
        "Location": "Page 10, second paragraph, particularly the statement: \"This means the problematic states are always excluded automatically and shall not change significantly the data analysis.\"",
        "Explanation": "The paper states that electronic states with large vibronic coupling terms |<Φ<sub>i</sub>|∂/∂Q<sub>k</sub>|Φ<sub>j</sub>>| (where the adiabatic approximation is likely to fail) lead to \"artificially large nonradiative relaxation rate W<sub>i->j</sub>\" and are subsequently \"neglected in the MEG analysis, since only small W<sub>i->j</sub> are counted.\" This approach is unsound. If the model predicts large rates due to its own limitations (e.g., breakdown of the adiabatic approximation), selectively ignoring these rates rather than employing a more suitable model or rigorously justifying their exclusion can lead to a significant underestimation of non-radiative relaxation. This could, in turn, result in an overestimation of MEG efficiency and potentially invalidate conclusions drawn from the comparison between inelastic scattering and non-radiative relaxation rates."
      },
      {
        "Problem": "Limited validation of the approximation for excitonic inelastic scattering rates.",
        "Location": "Page 6, Eq. (13) and the justification paragraph below Figure 1.",
        "Explanation": "The calculation of excitonic inelastic scattering rates (Γ<sup>e-e</sup>) relies on an approximation (Eq. 13) that simplifies the dynamic Bethe-Salpeter equation by considering only the first two Feynman diagrams (diagonal elements in Eq. 11, which is misreferenced as Eq. 14 in Fig. 1 caption) and using GW electronic rates. The primary justification is \"good agreement\" with full DBSE results for a Si20 cluster from a previous study (Ref. 14). Extrapolating this agreement from a single, potentially smaller, cluster (Si20) to the Si26 and Si46 clusters studied in this work, across a broad range of high excitation energies crucial for MEG, may not be sufficiently robust without further validation. The accuracy of this approximation is critical for all conclusions regarding excitonic MEG performance, its comparison with electronic MEG, and the derived \"relative phonon bottleneck\" concept."
      },
      {
        "Problem": "Assumption of temperature-independent inelastic scattering rates for both electrons and excitons.",
        "Location": "Page 16, first paragraph (for electronic rates γ<sup>e-e</sup>) and Page 20, first paragraph (implicitly for excitonic rates Γ<sup>e-e</sup>).",
        "Explanation": "The study assumes that both electronic (γ<sup>e-e</sup>) and excitonic (Γ<sup>e-e</sup>) inelastic scattering rates are temperature-independent when evaluating MEG performance at 300 K. All temperature effects are attributed solely to the non-radiative relaxation pathways. However, inelastic electron-electron and exciton-electron scattering processes can exhibit temperature dependence due to factors such as changes in carrier distribution functions (e.g., Fermi-Dirac for electrons involved in scattering or forming excitons) and temperature-dependent screening effects. Neglecting this potential temperature dependence for inelastic rates can lead to an inaccurate assessment of the overall temperature impact on MEG efficiency and the relative importance of competing decay channels at finite temperatures, thereby affecting the conclusions about MEG performance deterioration."
      },
      {
        "Problem": "Potential inaccuracies introduced by the Displaced Potential Surface (DPS) approximation and harmonic approximation in non-radiative rate calculations.",
        "Location": "Page 8, Eq. (23) (harmonic approximation); Page 9, Eq. (28)-(34) and surrounding text describing the DPS approximation.",
        "Explanation": "The calculation of non-radiative relaxation rates (W<sub>i->j</sub>) employs the harmonic approximation (Eq. 23) for potential energy surfaces and the Displaced Potential Surface (DPS) approximation (Eq. 28-34). The DPS model assumes that vibrational frequencies and normal mode characters are identical for the initial and final electronic/excitonic states, neglecting Duschinsky rotation (mode mixing) and changes in vibrational frequencies upon excitation. Anharmonic effects are also neglected. While these are common approximations, their use can lead to inaccuracies in the computed non-radiative rates, especially for systems with significant structural relaxation or changes in vibrational landscape upon excitation. The paper acknowledges the adiabatic approximation as \"crude\" (Page 10), and these additional simplifications further impact the quantitative accuracy of non-radiative rates, which are critical for assessing MEG efficiency by comparison with inelastic scattering rates."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 4705,
      "output": 993
    }
  },
  {
    "entry_id": 109,
    "retraction_id": "1705.01127v2",
    "paper_id": "1705.01127v1",
    "retraction_comment": "Paper has been withdrawn since we find that dust effects have an unignorable impact on our analyses. A part of analyses are reported by arXiv:1809.03715",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Severe Selection Bias and Incompleteness",
        "Location": "Section 2 (especially paragraph 3 and Figure 1 caption), Abstract",
        "Explanation": "The sample selection, relying on AKARI FIR detections, reduces the parent GALEX-SDSS sample by over 98% (from 78,731 to 1,200 initial cross-match). This introduces a strong bias towards IR-bright, likely dustier and higher-SFR galaxies. The stated completeness is extremely low (e.g., 2.6% for SFR_Halpha,corr > 1 Msun/yr overall, 24% for >10 Msun/yr). While acknowledged in the abstract and text, this severe bias and low completeness make it questionable whether the sample is representative of the general star-forming main sequence population. This potentially invalidates the general applicability of the conclusions drawn about main sequence scatter and SFH variability across the broader galaxy population."
      },
      {
        "Problem": "Autocorrelation in the Key Finding (ΔMS vs Hα/UV)",
        "Location": "Section 3 (Figure 3, Equation for ΔMS)",
        "Explanation": "The primary finding of a correlation between ΔMS and the Hα/UV ratio is susceptible to autocorrelation. ΔMS is defined using SFR_Hα,corr in its calculation (log(SFR_Hα,corr) - MS_fit), and the Hα/UV ratio also has SFR_Hα,corr in its numerator (SFR_Hα,corr / SFR_UV+IR). Consequently, variations in SFR_Hα,corr will inherently tend to drive both quantities in the same direction, creating or inflating a correlation. The Jenkins test mentioned addresses common *errors*, not this fundamental mathematical coupling of the *true values*. This makes it difficult to isolate the true physical correlation strength due to SFH variability from this built-in dependency, potentially overstating the significance or misinterpreting the nature of the physical relationship."
      },
      {
        "Problem": "Interpretation of the 0.04 dex Reduction in Main Sequence Scatter",
        "Location": "Section 4.1 (paragraph 3)",
        "Explanation": "The conclusion that SFH variability contributes 0.04 dex to the main sequence (MS) scatter is based on finding that the scatter of log(ΔMS) - γ*log(Hα/UV) is minimized for γ~1. With γ=1, this 'corrected' quantity is approximately log(SFR_UV+IR) - MS_fit(M*) (assuming MS_fit was derived from SFR_Hα,corr). The argument essentially shows that an MS defined by a longer-timescale SFR tracer (SFR_UV+IR, resulting in 0.32 dex scatter) is slightly tighter than one defined by a shorter-timescale tracer (SFR_Hα,corr, 0.36 dex scatter). Attributing this 0.04 dex difference solely and quantitatively to 'SFH variability' is a strong claim that isn't robustly disentangled from other factors, such as differing intrinsic accuracies of the SFR indicators, their respective dust corrections, or the large 0.3 dex uncertainty in SFR_UV+IR."
      },
      {
        "Problem": "Insufficient Consideration of IMF and Stellar Population Synthesis Model Uncertainties",
        "Location": "Section 1 (Kennicutt 1998 reference), Section 4.4 (mention of Meurer 2009)",
        "Explanation": "The interpretation of the Hα/UV ratio as a tracer of recent Star Formation History (SFH) variability relies critically on the Kennicutt (1998) SFR calibrations, which assume a universal Initial Mass Function (IMF) and specific stellar population synthesis (SPS) model outputs (e.g., for continuous SF over 100 Myr). However, the IMF itself might vary with star formation conditions (e.g., becoming more top-heavy in starbursts), or other SPS parameters (e.g., effects of stellar metallicity, binaries, rotation on ionizing flux and UV output) could differ from the standard assumptions. Such variations would also alter the intrinsic Hα/UV luminosity ratio per unit of star formation, independent of SFH changes. While IMF non-universality is briefly mentioned as an alternative interpretation in the conclusions, its potential to confound the primary interpretation of Hα/UV ratios as direct measures of SFH variability is not adequately discussed or constrained throughout the paper."
      },
      {
        "Problem": "Impact of Large SFR_UV+IR Uncertainty on Hα/UV Ratio and Correlations",
        "Location": "Section 2 (paragraph 4), Section 3 (Figure 3 caption)",
        "Explanation": "The reported typical uncertainty for SFR_UV+IR is 0.3 dex. This is a very large uncertainty, comparable to the total observed scatter in the Hα/UV ratio itself (0.28 dex, Figure 1) and the scatter in the key ΔMS vs Hα/UV relation for massive galaxies (0.26 dex, Figure 3). Since SFR_UV+IR is a fundamental component in the denominator of the Hα/UV ratio, such a large uncertainty can dominate the error budget of Hα/UV. The paper asserts that random errors have a minor impact on systematic trends (Section 2), but a quantitative demonstration of this, particularly for the Hα/UV ratio and its derived correlations, is lacking. This large uncertainty could obscure true physical trends or contribute significantly to the observed scatter, weakening the reliability of the conclusions drawn about SFH variability from the Hα/UV ratio."
      }
    ],
    "token_usage": {
      "input": 8320,
      "thinking": 7403,
      "output": 1230
    }
  },
  {
    "entry_id": 110,
    "retraction_id": "2105.03304v2",
    "paper_id": "2105.03304v1",
    "retraction_comment": "Eq (2.4) is not correct and as such this invalidates Theorem 2.3 and consequently all the claimed results on the modulus of the zeros of chromatic polynomial. As fas as we can tell the results for the edge based block polynomials are correct (this concerns Sections 4 and 5). We will probably resubmit this part as part of a new paper at some point in the future",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially unjustified bound in the proof for Fisher zeros of the Ising model.",
        "Location": "Section 5, Proof of Lemma 5.5 (page 12, equation before last)",
        "Explanation": "The proof of Lemma 5.5 aims to bound the sum $\\sum_{H\\in \\mathcal{BP}^*(v,U;G), H \\text{ even}} |z|^{|E(H)|} a^{|V(H)|-1}$. This sum is over block paths $H$ from $v$ to $U$ (where $V(H) \\cap U = \\{u\\}$ for some $u \\in U$, so $u \\ne v$) that are also Eulerian graphs. The paper states this sum can be bounded by $a^{-1}\\sum_{\\ell\\geq 3}W^\\ell_v(|z|a)^\\ell$, where $W^\\ell_v$ is the number of closed walks of length $\\ell$ starting and ending at $v$ with no repeated edges. The justification for bounding the sum over these specific path-like structures ($v \\leadsto u$) by a sum over closed walks ($v \\leadsto v$) is not provided. If this bounding step is incorrect, the conclusion of Lemma 5.5, and consequently Theorem 1.3 regarding Fisher zeros, may not be valid."
      }
    ],
    "token_usage": {
      "input": 21533,
      "thinking": 24393,
      "output": 311
    }
  },
  {
    "entry_id": 111,
    "retraction_id": "1608.03378v2",
    "paper_id": "1608.03378v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in equation 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory outcome from the composite model application.",
        "Location": "Page 5, derivation of beta and discussion of Eq. (10).",
        "Explanation": "The composite cube model is used to explain the lower metallic phase carrier concentration. The derived value of beta=1/4, combined with the stated mu1/mu2=200 and measured n*/n1=0.01 in Eq. (10), implies an intergrain-to-grain resistivity ratio (rho2/rho1) of approximately 0.79. This means the intergrain region is *less* resistive than the metallic grain, which contradicts the model's fundamental assumption that the intergrain region is 'highly resistive' or 'untransitional' (i.e., semiconducting and thus more resistive). This invalidates the quantitative conclusion about the untransitional phase size."
      },
      {
        "Problem": "Neglect of high film roughness effects.",
        "Location": "Table I (page 2) and throughout the transport data interpretation (Pages 3-5).",
        "Explanation": "The XRR data in Table I indicates a VO2 film roughness of 55 Å for a 422 Å thick film, corresponding to over 13% of the film thickness. Such high roughness in an 'ultra-thin' film can lead to non-uniform current distribution, increased surface/interface scattering, and questions the applicability of idealized models (like the composite cube model or even standard Hall analysis assuming uniform films). The paper does not acknowledge or discuss these potential impacts, which could significantly affect the accuracy and validity of the extracted transport parameters and subsequent conclusions."
      },
      {
        "Problem": "Unclear justification for the crucial mobility ratio mu1/mu2.",
        "Location": "Page 5, paragraph 1, and reference to Figure 6.",
        "Explanation": "The calculation of beta=1/4 relies on a grain-to-intergrain mobility ratio (mu1/mu2) of approximately 200, which the paper claims is 'shown in figure 6'. However, Figure 6 does not directly provide the intergrain mobility (mu2), nor does it explicitly show how this ratio is obtained for the grain vs. intergrain material. The origin of this specific ratio is not transparently justified from the presented data, yet it is a critical parameter in the model. If this ratio is an assumed or fitted parameter without clear basis, it undermines the reliability of the derived beta value and the conclusion about the untransitional phase."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 11697,
      "output": 563
    }
  },
  {
    "entry_id": 112,
    "retraction_id": "1709.00434v2",
    "paper_id": "1709.00434v1",
    "retraction_comment": "Some of the content, including the assumption of vanishing vector potential at the interface and the application of the formalism to the gapped Dirac materials, are wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of vanishing vector potential at the interface",
        "Location": "Eq. (18) and its footnote",
        "Explanation": "The assumption $\\bar{\\bm{A}}^{\\pm}(y, z=0) = \\bm{0}$ (vector potential vanishes at the graphene interface) is a very strong condition. It simplifies the in-plane electric field to be purely derived from the scalar potential (i.e., $\\bm{E}_{in} = -\\nabla_{in} \\Phi$). This is effectively a quasi-static approximation for the in-plane field components and neglects magnetic induction effects from $\\partial \\bm{A}/\\partial t$ within the graphene plane. The Coulomb gauge condition (Eq. 10) $\\nabla \\cdot \\bm{A} = 0$ does not, by itself, enforce $\\bm{A}(z=0)=\\bm{0}$. This assumption significantly restricts the generality of the derived dispersion relation, potentially omitting important physical effects, especially at higher frequencies or for materials where coupling to the vector potential is significant. The footnote explains the consequence of the assumption (simplification) rather than acknowledging the limitation it imposes on the results' validity for a 'generalized' theory."
      },
      {
        "Problem": "Sign error in the differential equation for the scalar potential modulation",
        "Location": "Eq. (46), propagating to Eq. (53) and Eq. (59)",
        "Explanation": "There appears to be a sign error in the coefficient of the first derivative term $\\frac{d\\bar{\\Phi}^{\\pm}_{<}}{dy}$ in Eq. (46). Based on the definitions of $\\chi^{\\pm}, \\bar{\\chi}^{\\pm}$ (Eqs. 49-50) and the derivation from Eq. (31) and (44), the term should be $\\pm q(\\chi^{\\pm} + \\bar{\\chi}^{\\pm}) \\frac{d\\bar{\\Phi}^{\\pm}_{<}}{dy}$ instead of $\\mp q(\\chi^{\\pm} + \\bar{\\chi}^{\\pm}) \\frac{d\\bar{\\Phi}^{\\pm}_{<}}{dy}$. This error propagates to the quadratic equation for the decay constant $\\kappa^{\\pm}_{<}/q$ (Eq. 53, affecting the sign of its middle term) and subsequently into the general form of the dispersion relation (Eq. 59). While this sign error fortuitously cancels out in the specific symmetric long-wavelength limit considered (Eq. 63), it would render the general dispersion relation (Eq. 59) incorrect for asymmetric cases (where $\\chi^{\\pm} + \\bar{\\chi}^{\\pm} \\neq 0$)."
      },
      {
        "Problem": "Inconsistent or inadequately justified treatment of boundary conditions at y=0",
        "Location": "Discussion surrounding Eqs. (54)-(57), particularly the interpretation of Eq. (30) at y=0, the role of Eq. (54), and the unsubstantiated Eq. (56).",
        "Explanation": "The paper introduces an averaged derivative (Eq. 54) as a 'remedy' for defining $\\frac{d\\bar{\\Phi}^{\\pm}}{dy}$ at $y=0$ within the expression for the edge charge density $\\bar{\\rho}^{\\pm}_{\\textsc{ED}}$ (Eq. 30). However, the subsequent derivation of the jump condition for $\\frac{d\\bar{\\Phi}^{\\pm}}{dy}$ (Eq. 55) and the resulting expression for $\\kappa_<^{\\pm}/q$ (Eq. 57) effectively use $\\left[\\frac{d\\bar{\\Phi}^{\\pm}_{<}}{dy}\\right]_{y=0^{-}}$ for this derivative term in $\\bar{\\rho}^{\\pm}_{\\textsc{ED}}$. This contradicts the stated purpose or application of Eq. (54). Furthermore, Eq. (56) claims a non-zero contribution from integrating $\\bar{\\rho}^{\\pm}_{\\textsc{2D}}$ across $y=0$. This is highly questionable as $\\bar{\\rho}^{\\pm}_{\\textsc{2D}} \\propto \\Theta(-y)$ and, assuming regular field behavior up to the boundary, should not produce a Dirac delta function contribution at $y=0$. The derivation of Eq. (57) appears to implicitly assume $\\int \\bar{\\rho}^{\\pm}_{\\textsc{2D}} dy = 0$. This inconsistent and poorly justified handling of boundary conditions undermines the derivation of Eq. (57), which is a crucial step for obtaining the final dispersion relation."
      },
      {
        "Problem": "Impact of kernel approximation on the 'generalized' nature of the theory",
        "Location": "Eq. (37) and its use in deriving the local differential operator in Eq. (41) and subsequent equations.",
        "Explanation": "The exact kernel $L(y)$ relating scalar potential and charge density (Eq. 23) is $\\frac{1}{2\\pi} K_0(q|y|)$, corresponding to a non-local pseudo-differential operator $\\sqrt{q^2 - d^2/dy^2}$ in $y$. The paper approximates this with $L_0(y) = \\frac{1}{2\\sqrt{2}} e^{-\\sqrt{2}q|y|}$ (Eq. 37). This $L_0(y)$ is the Green's function of a local differential operator $\\hat{\\mathcal{O}}_{\textsc{\\tiny{0}}}^{y} \\propto (\\frac{d^2}{dy^2} - 2q^2)$ (Eq. 41). This approximation fundamentally changes the mathematical nature of the problem from non-local to local, allowing the integro-differential equation (Eq. 32) to be converted into a local ordinary differential equation (Eq. 43). While this approximation matches certain moments of the exact kernel and simplifies the problem significantly, its impact on the 'generalized' dispersion relation is not discussed. The range of validity of this approximation (e.g., in terms of $q$ or specific material parameters) and how it affects the physics of edge plasmons (e.g., by neglecting non-local effects inherent in the exact kernel) are not acknowledged as limitations, potentially restricting the true generality of the conclusions."
      }
    ],
    "token_usage": {
      "input": 12356,
      "thinking": 16144,
      "output": 1441
    }
  },
  {
    "entry_id": 113,
    "retraction_id": "1610.01669v7",
    "paper_id": "1610.01669v6",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error on linear implication between games",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the rank of a predicative union in Lemma 3.4.4, leading to inconsistency in universe ranks.",
        "Location": "Lemma 3.4.4 (page 20), Definition 3.6.1 (page 21), Corollary 3.6.2 (page 21)",
        "Explanation": "Lemma 3.4.4 states that for a set of strategies $\\mathcal{S}$, the rank of their predicative union $\\mathcal{R}(\\oint \\mathcal{S})$ is $(\\sup(\\{ \\mathcal{R}(\\sigma) \\ | \\ \\sigma \\in \\mathcal{S} \\}))+1$. However, deriving the rank from Definition 3.2.2 (Rank of a game) and Definition 3.4.1 (structure of $\\oint \\mathcal{S}$, specifically $M_{\\oint \\mathcal{S}} = \\sum_{\\sigma \\in \\mathcal{S}} M_\\sigma$) yields $\\mathcal{R}(\\oint \\mathcal{S}) = \\sup_{\\sigma \\in \\mathcal{S}}(\\mathcal{R}(\\sigma)-1) + 1$ (assuming strategies $\\sigma$ are non-empty games, so $\\mathcal{R}(\\sigma) \\ge 1$; if $M_\\sigma$ is empty, $\\mathcal{R}(\\sigma)=1$, so $\\mathcal{R}(\\sigma)-1=0$. This formula simplifies to $\\sup_{\\sigma \\in \\mathcal{S}} \\mathcal{R}(\\sigma)$ if the supremum is achieved by a strategy $\\sigma_{max}$ with $\\mathcal{R}(\\sigma_{max}) \\ge 1$). The incorrect formula in Lemma 3.4.4 leads to $\\mathcal{R}(\\mathcal{U}_k) = k+3$ for the $k$-th universe game. This contradicts Corollary 3.6.2, which claims $\\mathcal{U}_k$ is a $(k+2)$-predicative game (i.e., $\\mathcal{R}(\\mathcal{U}_k)=k+2$). The rank $k+2$ is crucial for consistency with MLTT's universe hierarchy ($U_k$ is $type_{k+2}$ and $En(U_k) : U_{k+1}$). The error in Lemma 3.4.4 makes the subsequent claims about universe ranks and their interpretation unsound."
      },
      {
        "Problem": "Lack of formal mechanism for the claimed \"invisibility\" of initial protocol moves to the Opponent.",
        "Location": "Section 3.3 (end, page 19), Section 3.4 (discussion after Def 3.4.1, page 19-20)",
        "Explanation": "The paper claims that the initial protocol moves in a predicative game (e.g., $q_G$ and Player's choice $\\circled{\\sigma}$) are \"invisible\" to the Opponent, meaning Opponent's moves cannot depend on Player's choice $\\circled{\\sigma}$. This property is important for the semantics of function types ($A \\multimap B$), where Opponent's play in $A$ should not depend on Player's overall strategy for $A \\multimap B$. However, the paper states that no constraint is formally imposed on anti-strategies (Opponent's strategies) to enforce this. Standard game semantic definitions of O-views (implicitly used from Section 2.2.2) would include such protocol moves if they are regular P-moves, allowing Opponent to react to them. The lack of a formal mechanism (e.g., modified view definitions or explicit constraints on anti-strategies) to ensure this invisibility makes the claim unsubstantiated and could potentially undermine the soundness of interpretations relying on this property, such as for function spaces."
      }
    ],
    "token_usage": {
      "input": 106551,
      "thinking": 20140,
      "output": 857
    }
  },
  {
    "entry_id": 114,
    "retraction_id": "1605.05588v2",
    "paper_id": "1605.05588v1",
    "retraction_comment": "It had to be noted that the assumption was made that all sensors have access to all observations and state estimate vectors. In addition, the summations in the DAQKF Algorithm are on all sensors, not just the neighbouring sensors",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Discrepancy between DAQKF algorithm and CAQKF \"mirroring\" claim",
        "Location": "Section III, primarily Algorithm 3 and the text justifying its derivation from CAQKF (e.g., paragraph starting \"Therefore, the operations of the CAQKF can be mirrored...\")",
        "Explanation": "Algorithm 3 (DAQKF) specifies that each node $l$ updates its error covariance inverse $\\hat{\\mathbf{M}}^{a^{-1}}_{l,n|n}$ by summing terms $\\mathbf{H}^{aH}_{m,n}\\mathbf{C}^{{}^{-1}}_{\\mathbf{\\omega}^{a}_{m,n}}\\mathbf{H}^{a}_{m,n}$ only from its local neighborhood $\\mathcal{N}_l$. Similarly, the state update $\\hat{\\mathbf{x}}^{a}_{l,n|n}$ sums $\\Delta\\hat{\\mathbf{x}}^{a}_{m,n}$ only from $\\mathcal{N}_l$. This makes DAQKF a diffusion-type algorithm where local estimates $\\hat{\\mathbf{M}}^{a}_{l,n|n}$ and $\\hat{\\mathbf{x}}^{a}_{l,n|n}$ will generally not be identical to the centralized CAQKF estimates (which require sums over all network nodes $\\mathcal{N}$) at each time step, especially in non-fully-connected networks. The paper's claim that DAQKF \"mirrors\" CAQKF operations and \"forces them to consent to a unique solution\" (implying the centralized optimal solution) is misleading if interpreted as exact step-by-step equivalence for general network topologies."
      },
      {
        "Problem": "Flawed state evolution model in the application",
        "Location": "Section IV, the unnumbered state evolution equation: $\\mathbf{x}_{n}=\\begin{bmatrix}1 & \\Delta T \\\\ 0 & \\Delta T\\end{bmatrix}\\mathbf{x}_{n-1}+\\begin{bmatrix}\\frac{1}{2}(\\Delta T)^{2}\\\\ \\Delta T\\end{bmatrix}\\nu_{n}$",
        "Explanation": "The state transition matrix in the application's state evolution model has its $(2,2)$ element as $\\Delta T$. This implies that the velocity component of the state ($\\partial \\kappa/\\partial t$) evolves as $\\dot{\\kappa}_n = \\Delta T \\dot{\\kappa}_{n-1} + \\Delta T \\nu_n$. For a typical small sampling interval $\\Delta T < 1$ (0.04s is used in simulations), this formulation causes the estimated velocity to diminish artificially quickly towards zero. A standard constant-velocity model would use $1$ as the $(2,2)$ element, leading to $\\dot{\\kappa}_n = \\dot{\\kappa}_{n-1} + \\Delta T \\nu_n$. This flaw in the dynamics model could render the filter unresponsive to actual velocity changes and makes the simulation results used for validation questionable."
      },
      {
        "Problem": "Gimbal lock issue potentially reintroduced through input Euler angles",
        "Location": "Section IV, first paragraph describing $\\kappa = \\text{ln}(e^{i\\alpha}e^{j\\beta}e^{k\\gamma})$; also Abstract and Section I claims about avoiding gimbal lock.",
        "Explanation": "The paper claims that the quaternion-based framework avoids gimbal lock. While quaternion representation of orientation itself is free of gimbal lock singularities, the application section states that the state component $\\kappa$ is derived from Euler angles $\\alpha, \\beta, \\gamma$ (reportedly measured by accelerometers) using the formula $\\kappa = \\text{ln}(e^{i\\alpha}e^{j\\beta}e^{k\\gamma})$. Euler angle representations are subject to gimbal lock when, for example, the pitch angle $\\beta$ approaches $\\pm \\pi/2$. If the input Euler angles are compromised by such singularities, the derived $\\kappa$ will inherit this problem. Thus, the issue of gimbal lock is not fully eliminated from the system but rather shifted to the measurement interpretation stage, contrary to the paper's claims."
      },
      {
        "Problem": "Strong and potentially unrealistic assumptions for the fault detection confidence measure",
        "Location": "Section III, paragraph discussing Equations (7)-(9), specifically the assumptions $\\hat{\\mathbf{M}}^{a}_{n|n}\\approx\\hat{\\mathbf{M}}^{a}_{l,n|n}\\approx\\hat{\\mathbf{M}}^{a}_{m,n|n}$ and $\\hat{\\mathbf{x}}^{a}_{n|n-1}\\approx\\hat{\\mathbf{x}}^{a}_{l,n|n-1}\\approx\\hat{\\mathbf{x}}^{a}_{m,n|n-1}$ \"at convergence\".",
        "Explanation": "The derivation of the confidence measure $\\mathbf{r}^{aH}_{l,m}\\mathbf{C}^{{}^{-1}}_{\\mathbf{r}^{a}_{l,m}}\\mathbf{r}^{a}_{l,m}$ for detecting erroneous sensor updates relies on the assumption that local state estimates and error covariances at neighboring nodes ($l, m$) are very close to each other and to the (hypothetical) global centralized estimates. For a diffusion algorithm like the proposed DAQKF, these local quantities can differ significantly due to network topology, communication constraints, or transient dynamics, even when no sensor is faulty. If these assumptions do not hold, the statistical properties of the measure (e.g., being zero-mean under no-fault conditions) are compromised, potentially leading to unreliable fault detection (false alarms or missed detections) and undermining the claimed robustness."
      },
      {
        "Problem": "Inconsistent use of prior state estimate and error covariance in $\\Delta\\hat{\\mathbf{x}}^{a}_{l,n}$ derivation and implementation",
        "Location": "Section III, discrepancy between the innovation term in Eq. (3) (using global $\\hat{\\mathbf{x}}^{a}_{n|n-1}$ and $\\hat{\\mathbf{M}}^{a}_{n|n}$), the definition of $\\Delta\\hat{\\mathbf{x}}^{a}_{l,n}$ in Eq. (5) (using local $\\hat{\\mathbf{x}}^{a}_{l,n|n-1}$ but global $\\hat{\\mathbf{M}}^{a}_{n|n}$), and its implementation in Algorithm 3 (using local $\\hat{\\mathbf{x}}^{a}_{l,n|n-1}$ and local $\\hat{\\mathbf{M}}^{a}_{l,n|n}$).",
        "Explanation": "The centralized filter update in Eq. (3) uses the global prior estimate $\\hat{\\mathbf{x}}^{a}_{n|n-1}$ and global posterior covariance $\\hat{\\mathbf{M}}^{a}_{n|n}$ for calculating each sensor's contribution to the state update. However, the proposed distributed update increment $\\Delta\\hat{\\mathbf{x}}^{a}_{l,n}$ is defined in Eq. (5) using the local prior $\\hat{\\mathbf{x}}^{a}_{l,n|n-1}$ but still the global $\\hat{\\mathbf{M}}^{a}_{n|n}$. Subsequently, Algorithm 3 computes $\\Delta\\hat{\\mathbf{x}}^{a}_{l,n}$ using both the local prior $\\hat{\\mathbf{x}}^{a}_{l,n|n-1}$ and the local posterior covariance $\\hat{\\mathbf{M}}^{a}_{l,n|n}$. If local priors and local covariances differ from their global counterparts (which is typical in distributed settings before full consensus), then the sum $\\sum \\Delta\\hat{\\mathbf{x}}^{a}_{l,n}$ (even if taken over all nodes) would not match the centralized update. This multi-level deviation in formulae further challenges the claim that DAQKF accurately \"mirrors\" the CAQKF."
      }
    ],
    "token_usage": {
      "input": 10365,
      "thinking": 11445,
      "output": 1780
    }
  },
  {
    "entry_id": 115,
    "retraction_id": "2112.14102v2",
    "paper_id": "2112.14102v1",
    "retraction_comment": "The paper was withdrawn due to a mistake in the proof of Theorem 15, in Section 4. The proposed translation is not equirealizable (the cases for disjunction and Release fail)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory statements regarding the novelty of the main result ($\\SLTL$ realizability is $\\EXP$-complete).",
        "Location": "Abstract, Page 2 (paragraph before Sec 1 structure), and Page 7 (Sec 4.1, first paragraph).",
        "Explanation": "The abstract claims the paper shows $\\SLTL$ realizability is $\\EXP$-complete, 'disproving the existing conjecture of $\\DEXP$-completeness'. Page 2 argues that $\\EXP$-completeness for $\\SLTL$ does not directly follow from prior results on $\\LTLEBRP$. However, page 7 states: 'Recall that the $\\EXP$-completeness for $\\SLTL$ realizability was known, as proven in [cimatti2021extended].' This contradiction makes the paper's primary contribution unclear: if the result was already known and proven by Cimatti et al., then this paper is not disproving the conjecture, but rather offering an alternative proof. The current phrasing in the abstract and introduction overstates the novelty of the $\\EXP$-completeness result itself."
      },
      {
        "Problem": "The inductive step for the Release operator ($\\varphi_2 \\calR \\varphi_1$) in the proof of Theorem 4.1 relies on an unjustified substitution of equirealizable components.",
        "Location": "Page 7, proof of Theorem 4.1, item for $\\varphi = \\varphi_2 \\calR \\varphi_1$.",
        "Explanation": "The proof states: '$\\varphi_2 \\calR \\varphi_1$ is realizable if and only if $\\LTLsquare \\chi_2 \\calR \\LTLsquare \\chi_1$ is realizable'. Here, $\\LTLsquare \\chi_1$ and $\\LTLsquare \\chi_2$ are $\\GX$ formulas equirealizable to $\\varphi_1$ and $\\varphi_2$ respectively, and their construction (Lemma 3.5) introduces new auxiliary environment variables ($r_1, r_2$). Substituting components that are equirealizable via auxiliary variables into an LTL context (like $\\calR$) does not automatically preserve equirealizability of the composite formula. The strategies for $\\LTLsquare \\chi_1$ and $\\LTLsquare \\chi_2$ are defined under specific assumptions about these auxiliary variables, which may not hold when they are freely controlled by the environment in the context of $(\\LTLsquare \\chi_2) \\calR (\\LTLsquare \\chi_1)$. This step requires explicit justification regarding how strategies are composed and auxiliary variables handled, which is currently missing."
      }
    ],
    "token_usage": {
      "input": 18779,
      "thinking": 24540,
      "output": 578
    }
  },
  {
    "entry_id": 116,
    "retraction_id": "1606.07464v6",
    "paper_id": "1606.07464v5",
    "retraction_comment": "The arguments in the Sections 3.2 and 3.3 are not conclusive, and the Markov property is not disproved. Many other statements are though correct, see arXiv:2011.11476v4 (\"Revisiting the stochastic differential equations with multiplicative noise\")",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper's central claim that SDEs with multiplicative noise (specifically Stratonovich, alpha=1/2) are not Markovian is based on a flawed argument regarding the behavior of the propagator's maximum.",
        "Location": "Section 3.2, specifically page 7, the paragraph starting 'By (3.7) it follows that g(x,τ,x̂) must have its maximum at x̂...'",
        "Explanation": "The paper argues that for alpha=1/2, the maximum of the stationary distribution `w_stat` is at `x_hat` where `a(x_hat) = a_sp(x_hat)/2`. It then claims the propagator `g(x, tau, x_hat)` has its maximum at `x_hat - [a_sp(x_hat)/2]tau`. This shift would violate the Chapman-Kolmogorov equation. However, the calculation of the propagator's maximum appears incorrect. The drift term in the Fokker-Planck equation (2.12) is `a_eff = a + (alpha-1)a_sp`. For alpha=1/2, `a_eff = a - a_sp/2`. The maximum of `w_stat` occurs where `a_eff(x_hat) = 0`. The maximum of the short-time propagator `g(x, tau | x_0)` is at `x_0 + a_eff(x_0)tau`. Thus, for `x_0 = x_hat`, the maximum of `g(x, tau | x_hat)` is at `x_hat + a_eff(x_hat)tau = x_hat`. This means the propagator's maximum does not shift, and the condition for Markovian property, as stated by the author, is satisfied for alpha=1/2. This invalidates the disproof for the Stratonovich case and contradicts standard SDE theory."
      },
      {
        "Problem": "Inconsistent application of the Markovian criterion for the alpha=1 (anti-Itô) case.",
        "Location": "Page 7, Section 3.3, and Page 8, first paragraph.",
        "Explanation": "For `alpha=1`, the effective drift in the FPE (2.12) is `a_eff = a`. If a stationary state is peaked at `x_hat` where `a(x_hat)=0`, then `a_eff(x_hat)=0`. According to the paper's own criterion (no shift of the propagator's maximum from `x_hat`), this case should be Markovian. The paper states on page 7 (for `a=0, alpha=1`) that the propagator's maximum is indeed at `x_hat`. However, it then concludes the Markov property is 'only approximate' because the mean `<dX>` is non-zero. This switches the criterion from the propagator's maximum to its mean, which is inconsistent. If the no-shift-of-maximum criterion is key, then `alpha=1` (with `a(x_hat)=0`) should satisfy it, not just be 'approximate'."
      },
      {
        "Problem": "Misleading statements about state-dependent diffusion and the nature of noise-induced drift terms.",
        "Location": "Page 8, 'Comment' section.",
        "Explanation": "The paper claims that 'The Markov property is in fact abolished by the state-dependence of the diffusion.' This is a generally incorrect statement, as standard SDE theory (e.g., Itô or Stratonovich calculus) handles state-dependent diffusion with Markovian solutions. Furthermore, the argument that the noise-generated drift `a_NG` has a 'retarded impact' and is 'absent in the SDE' is confusing and does not align with the standard interpretation where such terms arise from the calculus rules and are part of the instantaneous description of the process evolution."
      },
      {
        "Problem": "Potential misinterpretation of condition (5.9) for the existence of a quiescent steady state.",
        "Location": "Page 11, paragraph starting 'It follows that w(x,t) never reaches...'",
        "Explanation": "The paper suggests that if condition (5.9) (`Div(D Grad phi) = 2 rho`) is not met, the density `w(x,t)` 'moves forever' and never reaches a globally steady state. Condition (5.9) relates to the constancy of the prefactor in the WKB approximation of a stationary distribution and is linked to detailed balance. If not met, non-zero probability currents can exist in a steady state (`w_t = 0`). The conclusion that `w(x,t)` 'moves forever' (implying `w_t != 0`) is too strong if it's meant to exclude any time-independent non-equilibrium steady state. It conflates the existence of currents with the absence of any steady state."
      },
      {
        "Problem": "The 'coarse-graining' argument for alpha=1 yielding an approximate Markov property is unsubstantiated and unconventional.",
        "Location": "Page 8, 'Comment' section and equation (3.8).",
        "Explanation": "The paper argues that on a 'coarse-grained time scale,' the `alpha=1` (anti-Itô) SDE, which has an Itô representation `dX = (a+a_sp)dt + b dW_I`, effectively behaves like `dX = a dt + b dW_I`. This implies the `a_sp` term vanishes under coarse-graining due to a 'retarded impact' of `a_NG`. This justification is hand-wavy and lacks rigorous support. Standard coarse-graining arguments often lead to the Stratonovich interpretation; the proposed transformation from anti-Itô to an Itô-like form by merely dropping a drift term is not conventional."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 16864,
      "output": 1313
    }
  },
  {
    "entry_id": 117,
    "retraction_id": "1806.07478v2",
    "paper_id": "1806.07478v1",
    "retraction_comment": "The results fail to capture the non-simultaneously diagonalizable case",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect stability matrix and conclusions in Example 3.1 and the related example on page 10.",
        "Location": "Page 8, Example 3.1 (Eq. 3.9); Page 10, example after Thm 3.4",
        "Explanation": "The stability matrix $\\mathcal{A}(h;\\beta,\\gamma,\\alpha)$ for the IMEX Euler method in Eq. 3.9 is incorrect. The derivation $X_{m+1} = (I-hS)^{-1}(I+hN)X_m$ leads to a different matrix. With the correct matrix, the conclusion of Example 3.1 (that for $h=2, \\alpha=\\beta=\\gamma=1$, an eigenvalue modulus is $>1$) is false; the system is stable. Similarly, the example on page 10 discussing the limit $\\beta \\to \\infty$ uses this incorrect matrix, and its conclusion about instability is also reversed with the correct matrix. These errors undermine the specific illustrations of non-ST system behavior and limitations of theory."
      },
      {
        "Problem": "Incorrect formula for the perturbation term $\\delta R$ in Theorem 3.2, Part 2.",
        "Location": "Page 9, Theorem 3.2, Part 2",
        "Explanation": "The stated formula for $\\delta R = R(hN, hS) - R(0,hS)$ in Part 2 of Theorem 3.2, specifically the term $(\\hat{D} \\otimes hS)[I_{dr} - \\hat{C} \\otimes hS]^{-1}( D\\otimes hN)[I_{dr}-C \\otimes hN - \\hat{C} \\otimes hS]^{-1}$, involves a matrix product $[I_{dr} - \\hat{C} \\otimes hS]^{-1}( D\\otimes hN)$ that is dimensionally inconsistent. The first matrix is $rd \\times rd$ and the second is $kd \\times rd$, so they cannot be multiplied in this order. A correct derivation yields a different formula for $\\delta R$. While the ultimate conclusion about the limit of $\\delta R(hN, h \\delta^{-1}S)$ might still hold, the stated formula in the theorem is mathematically incorrect."
      },
      {
        "Problem": "Definition and interpretation of $\\mathcal{E}(h)$ are inconsistent with the main perturbation theory (Theorem 3.4).",
        "Location": "Page 10, definition of $\\mathcal{E}(h)$; Section 5.2, application to shallow water model.",
        "Explanation": "Theorem 3.4 shows that eigenvalues of $R(hN, h\\delta^{-1}S)$ are approximated by eigenvalues derived from $R(hU_N, h\\delta^{-1}U_S)$, where $U_N$ is the triangular part of $P_S^{-1}NP_S$ (with $P_S$ triangularizing $S$) and $U_S$ is $P_S^{-1}SP_S$. The diagonal entries $(U_N)_{jj}$ are not generally eigenvalues of $N$. However, $\\mathcal{E}(h)$ is defined using '$\\lambda_1, \\hdots, \\lambda_d$ denote the eigenvalues of $N$'. This is inconsistent with Theorem 3.4. This discrepancy affects the meaning of $\\mathcal{E}(h)$ and the validity of its computed values and interpretations in Section 5.2 (e.g., Table 4.2, Figure 4.4). Additionally, the definition of $\\{\\psi_i(h)\\}_{i=1}^{dk}$ as $\\bigcup_{i,j=1}^{d}eig(R(h\\lambda_i,h\\mu_j))$ implies $d^2k$ eigenvalues, not $dk$, if $d \\neq 1$, creating a cardinality mismatch."
      },
      {
        "Problem": "The limit claim in Theorem 3.2, Part 1, may require an unstated condition.",
        "Location": "Page 9, Theorem 3.2, Part 1",
        "Explanation": "Theorem 3.2, Part 1, states that if $V^2=V$, then $\\lim_{\\delta_0 > \\delta \\rightarrow 0} \\delta R(hN,\\delta^{-1} hS) = 0$, where $\\delta R = R(hN,hS)-R(hN,0)R(0,hS)$. The derivation (Eq. 3.11) for $\\delta R$ involves two terms. When $S$ is replaced by $\\delta^{-1}S$, the second term, $h\\cdot (D\\otimes N)[[I_{dr}-C\\otimes hN -\\hat{C}\\otimes h \\delta^{-1} S]^{-1}-[I_{dr}-C\\otimes hN]^{-1}]((U-UV) \\otimes I_d)$, does not appear to vanish as $\\delta \\rightarrow 0$ unless an additional condition like $U(I_k-V)=0$ holds. This condition is true for standard Runge-Kutta methods (where $V=[1]$ and $U-UV=0$) but not for general GLMs satisfying $V^2=V$. The theorem as stated might be overgeneralized."
      }
    ],
    "token_usage": {
      "input": 35865,
      "thinking": 16790,
      "output": 1202
    }
  },
  {
    "entry_id": 118,
    "retraction_id": "2302.13052v2",
    "paper_id": "2302.13052v1",
    "retraction_comment": "There are some errors and inappropriate writings. Thm 4.16 and don't work well for additive invariants",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unproven claims regarding symmetric monoidal structures.",
        "Location": "Section 5.2, specifically the proposition before Corollary 5.5 (page 26) and Theorem 5.8 (page 27).",
        "Explanation": "The paper claims that the equivalences of functor categories $\\mathrm{Fun}_{\\mathrm{add/loc}}(\\mathscr{P}\\mathrm{r}_{\\mathrm{st}}^{\\mathrm{dual}}, \\D) \\simeq \\mathrm{Fun}_{\\mathrm{add/loc}}(\\mathrm{Cat}_\\infty^{\\mathrm{perf}},\\D)$ (given by $E \\mapsto E \\circ \\mathrm{Ind}$ and $F \\mapsto F_{\\mathrm{cont}}$) restrict to equivalences of symmetric monoidal functor categories. These claims are attributed to L. Hesselholt but are presented without proof or citation to a published source. Specifically, for $F_{\\mathrm{cont}}$ to be symmetric monoidal if $F$ is, it would require $F_{\\mathrm{cont}}(\\C \\otimes \\D) \\simeq F_{\\mathrm{cont}}(\\C) \\otimes F_{\\mathrm{cont}}(\\D)$, which translates to $\\Omega F(\\mathrm{Calk}_\\kappa(\\C \\otimes \\D)^\\omega) \\simeq \\Omega F(\\mathrm{Calk}_\\kappa(\\C)^\\omega) \\otimes \\Omega F(\\mathrm{Calk}_\\kappa(\\D)^\\omega)$. This relies on non-obvious interactions between the Calkin category construction, tensor products, and compact objects. If these foundational propositions are not established, the main conclusions of Section 5.2 (e.g., that $(\\mathcal{U}_{\\mathrm{add/loc}})_{\\mathrm{cont}}$ are symmetric monoidal, $\\mathrm{K}^{\\mathrm{cn}}_{\\mathrm{cont}}, \\mathrm{K}_{\\mathrm{cont}}$ are lax symmetric monoidal, and related initiality results) would be unproven."
      },
      {
        "Problem": "Applicability of results from dg-categories to $\\infty$-categories.",
        "Location": "Section 3, Theorems 3.19 (Efimov-add) and 3.20 (Efimov-loc), cited as [Hoy18, Theorem 10].",
        "Explanation": "The paper cites [Hoy18] (listed as Hoyois, 'Higher Galois theory') for key theorems stating that $E \\mapsto E_{\\mathrm{cont}}$ gives an equivalence between additive/localizing invariants on $\\mathrm{Cat}_\\infty^{\\mathrm{perf}}$ and 'continuous' invariants on $\\mathscr{P}\\mathrm{r}_{\\mathrm{st}}^{\\mathrm{dual}}$. The cited work [Hoy18] primarily deals with dg-categories. While analogous results are often expected to hold in the setting of stable $\\infty$-categories, the paper does not explicitly justify this translation or cite a source that does so for these specific theorems in the $\\infty$-categorical context. If these foundational equivalences do not hold as stated for $\\infty$-categories, the framework for defining and studying $E_{\\mathrm{cont}}$ (including Efimov K-theory via its construction $\\Omega K(\\mathrm{Calk}_\\kappa(-)^\\omega)$) and its universal properties would be weakened."
      }
    ],
    "token_usage": {
      "input": 59439,
      "thinking": 17698,
      "output": 740
    }
  },
  {
    "entry_id": 119,
    "retraction_id": "1511.07171v2",
    "paper_id": "1511.07171v1",
    "retraction_comment": "Error in equation 9",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Omission of a critical convective term in the Boundary Integral Equation (BIE)",
        "Location": "Page 3, derivation of Eq (7) from Eq (4), and subsequent formulation Eq (9) on page 4.",
        "Explanation": "The paper's BIE formulation, as presented in Eq (7) and effectively used in Eq (9), simplifies to a form `c*p = ± ∫ (p dG/dnq - G dp/dnq) dΓq`, where `d/dnq = ∂/∂nq - M∞n (M∞⋅∇q)`. A consistent derivation from the convected Helmholtz equation (Eq 1) and its adjoint operator should yield an additional term, `∫ 4ikM∞n pG dΓq`, in the BIE. The omission of this term, which directly accounts for convection effects involving the normal Mach number `M∞n = M∞⋅n_q`, means that a significant part of the flow physics is not modeled. This would invalidate the method's conclusions for problems involving fluid flow (M∞ ≠ 0)."
      },
      {
        "Problem": "Potentially incorrect definition of the axisymmetric convected Green's function",
        "Location": "Page 2, Equation (2) for Gk and Equation (3) for R*β and r*",
        "Explanation": "The axisymmetric convected Green's function Gk0 is stated to be the integral of Gk given by Eq (2). The definition of Gk involves a convected radius R*β (Eq 3), which in turn depends on r* where `r*² = |mq|² + (mq⋅M*∞)²`. This formulation for the effective distance `r*` in a convected field is non-standard. Typically, Prandtl-Glauert transformations lead to distances scaled by `α = sqrt(1-M∞²)` along the flow direction (e.g., `x_transformed = x/α`). The provided `r*` does not appear to correspond to such standard transformed distances. An incorrect Green's function is a fundamental flaw that would invalidate the entire BEM formulation."
      },
      {
        "Problem": "Unjustified new radiation condition for the axisymmetric cylindrical duct",
        "Location": "Page 5, Equation (10) and its surrounding text.",
        "Explanation": "The paper proposes a new radiation condition for the outlet of the cylindrical duct (Γ+) as `σ_Γ+ = iα² K_z,n p` (Eq 10), where `α² = 1-M∞²` and `K_z,n` is the axial wavenumber. The introduction of the `α²` factor modifying the classical radiation condition is not derived or justified from the physics of wave propagation in a convected medium. Standard radiation conditions for ducts with flow are more complex and depend on the roots of the dispersion relation. An improperly formulated radiation condition will lead to incorrect solutions for the acoustic propagation in the duct."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 13961,
      "output": 662
    }
  },
  {
    "entry_id": 120,
    "retraction_id": "1106.1331v2",
    "paper_id": "1106.1331v1",
    "retraction_comment": "Withdrawn by the authors. Lemma 7.6 is false as stated, and Appendix B is flawed. Corrected and reorganized versions of the material will be posted in papers with different titles",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential flaw in the proof of G=KAH for strongly unimodular spherical pairs.",
        "Location": "Appendix B, proof of Lemma \\ref{KAHprop} (also referred to as Lemma B.1 in Appendix B text), and its use of Lemma B.3.",
        "Explanation": "The proof of $G=KAH$ (Lemma \\ref{KAHprop}) is crucial for establishing 'strong spherical type' (Corollary 7.8), which underlies Theorem \\ref{BAN} (Property (I)). The proof of Lemma \\ref{KAHprop} involves a genericity argument, conjugating a parabolic $P$ to $P_k = kPk^{-1}$ and $L=P \\cap H$ to $L_k = P_k \\cap H$. The original assumption is $L \\subset M_P$. This property is likely lost for $L_k$ (i.e., $L_k \\not\\subset M_{P_k}$). The paper claims $L_k \\subset M_k N_k$. However, Lemma B.2 states $L_k = (H \\cap M_k^{n_k})(H \\cap A_k^{n_k})(H \\cap N_k)$. If the factor $H \\cap A_k^{n_k}$ (where $A_k^{n_k} = n_k A_k n_k^{-1}$) is non-trivial and not contained in $M_k$, then $L_k$ is not a subgroup of $M_k N_k$. This would invalidate a step in the proof of Lemma B.3 (the integration formula used to define analytic functions $f_\\lambda$), specifically where it's assumed $a(l)^{2\\rho}=1$ for $l \\in L_k$. If $a(l) \\neq e$ for some $l \\in L_k$, the integral formula for $\\eta_\\lambda$ or its properties might not hold as stated, potentially undermining the construction of $f_\\lambda$ and the entire proof of $G=KAH$ for this class of spaces."
      },
      {
        "Problem": "Gap in proving VAI fails for all non-reductive types.",
        "Location": "Appendix A, proof of Proposition \\ref{non-red}.",
        "Explanation": "Proposition \\ref{non-red} aims to prove that if $Z=G/H$ is not of reductive type, then VAI fails. The proof involves analyzing the structure of $\\hf$ relative to a maximal parabolic $\\pf_0 = \\nf_0 \\rtimes \\lf_0$ containing $\\hf$. A key part of the argument relies on constructing a map $\\Phi_t$ and showing its Jacobian decays exponentially, which implies the existence of an unbounded smooth $L^p$ function. This Jacobian analysis (starting 'In the sequel we assume that $\\nf_1$ is a proper subspace of $\\nf_0$') explicitly excludes the case where $\\nf_1 = \\nf_0$. The condition $\\nf_1=\\nf_0$ is equivalent to $\\hf \\cap \\nf_0 = \\{0\\}$. If $\\hf \\cap \\nf_0 = \\{0\\}$, the Jacobian estimate $e^{t\\gamma}$ with $\\gamma>0$ (for $t \\to -\\infty$, ensuring volume decay) might fail because the expanding effect of $\\Ad(a_t)^{-1}$ on $\\bar{\\nf}_0$ could be cancelled by its contracting effect on $\\nf_0$, potentially leading to $\\gamma \\le 0$. The paper attempts to handle the $\\hf \\cap \\nf_0 = \\{0\\}$ case by further sub-dividing based on whether $\\hf_0 = \\mathrm{pr}_{\\lf_0}(\\hf)$ is reductive in $\\lf_0$. If $\\hf_0$ is not reductive in $\\lf_0$, an appeal to induction is made. If $\\hf_0$ is reductive in $\\lf_0$, this implies $\\hf$ is a reductive Lie algebra. For $Z$ not to be of reductive type, the Adjoint representation of $H$ on $\\gf$ must not be completely reducible. The argument provided for this subcase ('$\\hf=\\rf$ is abelian... reduces to $\\rf$ is nilpotent') is unclear and seems insufficient to cover all scenarios where $H$ is reductive but its Adjoint action on $\\gf$ is not completely reducible, especially given that the main Jacobian analysis method is not applied here. This leaves a potential gap in the proof that VAI fails for all non-reductive type spaces."
      }
    ],
    "token_usage": {
      "input": 60789,
      "thinking": 21414,
      "output": 1045
    }
  },
  {
    "entry_id": 121,
    "retraction_id": "2106.14209v3",
    "paper_id": "2106.14209v2",
    "retraction_comment": "The paper builds on the wrong statement in the paper \"The quantum twistor bundle\" Theorem 4.2. Therefore the C*-algebra investigated in the present paper is not the one for the quantum symplectic sphere",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The main conclusion that the reduced quantum symplectic sphere $C(S_q^{4n-1})/(x_1=\\dots=x_{n-1}=0)$ (denoted $A'$) is isomorphic to the Vaksman-Soibelman (VS) quantum sphere $C(S_q^{2(n+1)-1})$ as defined on page 2 of the paper appears to be incorrect.",
        "Location": "Abstract, Introduction (page 1, last paragraph), Corollary (page 9)",
        "Explanation": "The paper derives a set of relations (Eqs. 2.1-2.3) for $A'$. These relations are claimed to define an algebra isomorphic to $C(S_q^{2(n+1)-1})$ (VS sphere, parameter $q$) via an intermediate isomorphism with a graph C*-algebra $C^*(L_{2(n+1)-1})$ (Theorem 3.2) and a known result by Hong & Szymański ([hs]) that $C(S_q^{2(n+1)-1}) \\cong C^*(L_{2(n+1)-1})$. However, the derived relations for $A'$ are structurally different from the standard VS relations given on page 2: \n1. Sphere condition: $A'$ has $\\sum y_k^*y_k = 1$, while VS has $\\sum z_k z_k^* = 1$. \n2. Commutation relations for $y_n, y_{n+1}$ involve different powers of $q$ (e.g., $y_{n+1}y_n = q^{-2}y_n y_{n+1}$ in $A'$ vs $z_{n+1}z_n = q z_n z_{n+1}$ for VS) and different coefficients (e.g., $y_n y_n^* - y_n^* y_n = (1-q^4)y_{n+1}^*y_{n+1}$ in $A'$ vs $z_n^*z_n - z_nz_n^* = (1-q^2)z_{n+1}z_{n+1}^*$ for VS). \n3. The general $y_i y_i^* - y_i^* y_i$ relation in $A'$ has a different structure/sign compared to the $z_i^*z_i - z_iz_i^*$ relation in VS. \nIf these sets of relations are not equivalent (which they appear not to be), then $A'$ cannot be isomorphic to the VS sphere as defined on page 2. This would invalidate a central claim of the paper."
      },
      {
        "Problem": "Potential mismatch between the Vaksman-Soibelman sphere definition used by the paper and the one used in the cited work by Hong and Szymański ([hs]).",
        "Location": "Section 1.2, Section 3 (Theorem 3.2 and Corollary)",
        "Explanation": "The argument for $A' \\cong C(S_q^{2(n+1)-1})$ relies on $A' \\cong C^*(L)$ (Thm 3.2) and $C(S_q^{VS}) \\cong C^*(L)$ ([hs]). There are multiple, slightly different definitions of 'the' quantum sphere. The definition of $C(S_q^{2n-1})$ on page 2 is standard. However, if Hong & Szymański [hs] used a different set of relations for the quantum sphere that they proved isomorphic to $C^*(L)$, then the paper's conclusion might be formally correct that $A'$ is isomorphic to *that* [hs] version, but it would be misleading as it's not the version defined on page 2. The paper needs to explicitly verify that the VS algebra from [hs] (which is $C(SU_q(N)/SU_q(N-1))$ in their notation) is identical to the one defined on page 2, up to parameter/index conventions. If they are different, the main conclusion is, at best, imprecise about the target algebra."
      },
      {
        "Problem": "The representation $\\pi$ for $A'$ generators $y_k^*$ appears structurally different from standard representations of VS sphere generators $z_k^*$ (or their graph algebra counterparts from [hs]).",
        "Location": "Page 4 (Lemma before Lemma 2.3), Proof of Theorem 3.2",
        "Explanation": "The representation $\\pi$ (from [dl]) for $y_k^*$ involves state-dependent coefficients, e.g., $\\pi(y_n^*)$ includes $\\sqrt{1-q^{4(k_n+1)}}$ and $\\pi(y_i^*)$ for $i<n$ includes $\\sqrt{1-q^{2(k_i+1)}}$. Standard Fock representations for VS sphere generators (like those related to $\\rho$ in [hs]) typically involve constant coefficients like $\\sqrt{1-q^2}$. For example, $\\rho(S_k)$ in [hs] (their $S_k$ are $z_k^*$-like) has such constant factors. While Theorem 3.2 constructs an explicit isomorphism $\\phi$ such that $\\rho \\circ \\phi = \\pi$, the fundamental difference in the nature of these coefficients in $\\pi$ (being state-dependent) versus those in typical graph algebra representations (being constant) is unusual and warrants careful justification. If $\\pi$ is indeed unitarily equivalent to $\\rho$ (the representation of $C^*(L)$ from [hs]), this implies that $C^*(L)$ must accommodate such state-dependent coefficient structures through the specific (and complex) form of $\\phi(y_k^*)$. This is not impossible but is a subtle point that could hide an issue if the algebras $A'$ and $C(S_q^{VS})$ are indeed non-isomorphic."
      },
      {
        "Problem": "The derivation of relations (2.1)-(2.3) for $A'$ from Definition 2.1 needs careful verification, especially the commutation relations involving $y_n$ and $y_{n+1}$.",
        "Location": "Page 3, equations (2.1), (2.2), (2.3)",
        "Explanation": "The paper states that setting $x_i=0$ for $i=1,...,n-1$ in Definition 2.1 leads to relations (2.1)-(2.3). While a preliminary check suggests these are mostly correct, the complexity of the initial relations in Definition 2.1 means any error in this derivation would propagate. For instance, the relation $y_{n+1}y_n=q^{-2}y_ny_{n+1}$ (meaning $x_n y_n = q^{-2} y_n x_n$) is derived from $y_ix_i=q^{2}x_iy_i+(q^2-1)\\sum_{k=1}^{i-1}q^{i-k}x_ky_k$. For $i=n$ and $x_k=0$ for $k<n$, this gives $y_nx_n=q^{2}x_ny_n$, which is $x_n y_n = q^{-2} y_n x_n$. This seems correct. However, all derived relations in (2.1)-(2.3) are foundational. Their correctness is paramount before attempting to prove isomorphism to another algebra. Any discrepancy here would directly affect the comparison with the VS sphere relations."
      }
    ],
    "token_usage": {
      "input": 15156,
      "thinking": 27350,
      "output": 1698
    }
  },
  {
    "entry_id": 122,
    "retraction_id": "1608.08317v2",
    "paper_id": "1608.08317v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incomplete energy variance expression",
        "Location": "Eq. (14), Eq. (A3), and Appendix A",
        "Explanation": "The expression for energy variance, $\\mathcal{S}[\\Phi]$ (Eq. (A3) in AO basis, Eq. (14) in MO basis), appears to be missing contributions from same-spin double excitations (e.g., $\\alpha\\alpha \\to \\alpha\\alpha$ and $\\beta\\beta \\to \\beta\\beta$ terms like $\\sum_{a<b \\in occ_\\alpha, i<j \\in virt_\\alpha} |\\langle ab||ij \\rangle|^2$). The provided expression only explicitly accounts for single excitations ($|F^s_{ai}|^2$ terms) and mixed-spin double excitations ($|\\langle a_{\\alpha}i_{\\alpha}|b_{\\beta}j_{\\beta} \\rangle|^2$ term in Eq. (14), using chemist's notation for the integral for clarity). If the variance expression is incomplete, the method minimizes an approximation to the true energy variance $\\langle (H-\\langle H \\rangle)^2 \\rangle$. This would fundamentally affect the nature of the solutions and the validity of claims based on true variance minimization."
      },
      {
        "Problem": "Misleading claim about the energy-targeting mechanism",
        "Location": "Introduction, Sec. I, 5th paragraph (starting 'In this work, we instead propose...')",
        "Explanation": "The paper claims its functional $W[\\Psi](\\omega)$ (Eq. 2) 'preserves direct energy-targeting of $\\tilde{\\Omega}[\\Psi](\\omega)$' (Zhao et al.'s functional). However, Zhao et al.'s functional is designed to target the eigenstate with energy immediately *above* the input parameter $\\omega$, while the paper's functional $W[\\Psi](\\omega) = \\langle\\Psi|(\\omega - \\hat{H})^2|\\Psi\\rangle$ targets the eigenstate whose energy is *closest* to $\\omega$, as stated in Eq. (3). This represents a fundamental difference in the targeting behavior which is not accurately conveyed by the claim of 'preserving' the targeting of Zhao's functional."
      },
      {
        "Problem": "Insufficient justification for the 'orbital variance' aufbau principle",
        "Location": "Sec. II.D(2) 'The orbital variance', and Sec. II.D(4)",
        "Explanation": "The \\sscf{} method relies on an aufbau principle where molecular orbitals are occupied based on their 'orbital variances' $s_n$ (eigenvalues of the generalized Fock matrix $\\mathcal{F}$). The crucial property that $s_n < 0$ for occupied orbitals and $s_n > 0$ for virtual orbitals is presented as an empirical observation ('numerical examinations ... suggest') and justified by an analogy to Janak's theorem. A rigorous derivation or proof of this property for the complex $s_n$ expression (Eq. A6) is lacking. If this sign convention for $s_n$ is not universally true, the procedure of constructing the Slater determinant by filling the $N$ orbitals with the lowest $s_n$ values may not consistently lead to stable or physically meaningful mean-field states, undermining the robustness of the method."
      },
      {
        "Problem": "Speculative existence argument for \\sscf{} solutions",
        "Location": "Sec. II.D(4), paragraph starting 'In fact, similar to the existence theorem...'",
        "Explanation": "The paper suggests that an existence theorem for \\sscf{} solutions (obtained by occupying $N$ canonical orbitals with the lowest orbital variances) might hold by analogy to Lions' theorem for Hartree-Fock ground states. This assertion is highly speculative. Lions' proof is specific to energy minimization and the structure of the Hartree-Fock equations. No mathematical support, nor even a plausible argument beyond analogy, is provided for a similar existence theorem for the proposed variance minimization scheme, especially given the complexity of the $\\sigma$-SCF equations and the aforementioned uncertainties regarding orbital variance properties (Problem 3)."
      }
    ],
    "token_usage": {
      "input": 18498,
      "thinking": 10896,
      "output": 923
    }
  },
  {
    "entry_id": 123,
    "retraction_id": "1805.10733v3",
    "paper_id": "1805.10733v2",
    "retraction_comment": "The result (eq. 3) is not correct; therefore, latter part which is derived from this result is not correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unconventional definitions of statistical length (L) and cost (C) leading to misinterpretation.",
        "Location": "Page 3, LHS, equations from $ds^2 = 2\\langle\\Delta \\sigma_{sys}\\rangle$ through Eq. (8) and Eq. (10).",
        "Explanation": "The paper defines the rate of change of statistical length as $ds/dt = (d\\langle\\Delta \\sigma_{sys}\\rangle/dt) / \\sqrt{2\\langle\\Delta \\sigma_{sys}\\rangle}$, where $\\langle\\Delta \\sigma_{sys}\\rangle$ is implicitly treated as $S(t) = D_{KL}(p_0 || p_t)$, the Kullback-Leibler divergence from the initial distribution $p_0$ to the distribution $p_t$ at time $t$. This leads to a statistical length $\\mathcal{L}(\\tau) = \\sqrt{2S(\\tau)}$ (assuming $S(0)=0$) and a cost $\\mathcal{C}(\\tau) = \\int_0^\\tau (dS/dt)^2 / (2S(t)) dt$. This definition of $\\mathcal{L}$ is not the standard information geometric path length ($\\int_0^\\tau \\sqrt{g_{ij}\\dot{\\theta}_i\\dot{\\theta}_j} dt'$), but rather a quantity related to the total KL divergence from the origin (akin to a chord length). Similarly, the cost $\\mathcal{C}$ is derived from this non-standard speed. This deviation from standard definitions undermines the paper's claims of using a general information geometric approach and affects the interpretation of the efficiency $\\eta = \\mathcal{L}^2 / (\\tau \\mathcal{C})$ as a measure of how closely the system follows a path of constant 'speed' defined in this specific, non-standard way."
      },
      {
        "Problem": "Unsupported interpretation of cost (C) as thermodynamic cost.",
        "Location": "Page 3, RHS, section 'A relationship between adaptation speed and rate of thermodynamic cost change', paragraph starting 'As discussed in previous research...'.",
        "Explanation": "The paper claims that its defined cost $\\mathcal{C}$ can be considered 'a total loss rate of the entropy change' and 'a rate of the thermodynamic cost change', referencing Ito 2017. However, Ito 2017 relates the integral of squared geometric speed ($v(t)^2 = g_{ij}\\dot{\\theta}_i\\dot{\theta}_j$) to total entropy production for systems described by master equations. The current paper does not provide a derivation or justification showing that its specific definition of $\\mathcal{C}$ (based on $S(t)=D_{KL}(p_0||p_t)$ as outlined in Problem 1) is equivalent to the actual thermodynamic entropy production for the studied Langevin system. Without this crucial link, the 'thermodynamic' interpretation of the cost and the derived efficiency $\\eta$ is unsubstantiated, making conclusions about thermodynamic limits on adaptation speed questionable."
      },
      {
        "Problem": "Inconsistency in the definition/use of $ds^2/dt^2$ (squared speed).",
        "Location": "Page 3, LHS, end of section 'Information geometry in E. coli sensory adaptation model' (statement 'We noted that $ds^2/dt^2 = \\sum g_{i,j} d\\theta _i/dt d\\theta _j/dt$'), and Fig. 1 (plot of $ds^2/dt^2$).",
        "Explanation": "The paper correctly states that the squared speed can be written as $(ds/dt)^2 = \\sum g_{ij} (d\\theta_i/dt) (d\\theta_j/dt)$, which is the standard definition in information geometry, and implies this quantity is plotted in Fig. 1. However, the analytical expressions for $\\mathcal{L}$ (Eq. 8) and $\\mathcal{C}$ (Eq. 10), which are used for the main results in Figs. 2-4, are derived from the non-standard definition of speed $ds/dt = (dS/dt) / \\sqrt{2S(t)}$ (see Problem 1). If the numerical simulations for Figs. 2-4 indeed use these non-standard formulas for $\\mathcal{L}$ and $\\mathcal{C}$, then the reference to the standard squared speed and its plot in Fig. 1 is potentially disconnected from or inconsistent with the quantities actually used to derive the paper's main conclusions about efficiency. This creates ambiguity regarding which definition of 'speed' underpins the results."
      }
    ],
    "token_usage": {
      "input": 5914,
      "thinking": 11603,
      "output": 1038
    }
  },
  {
    "entry_id": 124,
    "retraction_id": "1912.00541v2",
    "paper_id": "1912.00541v1",
    "retraction_comment": "As several people have pointed out to me, the last sentence of Lemma 5.3 is not justified. This likely counts as a fatal flaw that invalidates the main theorem (Theorem 5.4). I would like to thank those who took the time to read the preprint and send me their feedback. I hereby retract the claimed result",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency in shift definitions leading to flawed model homomorphism property.",
        "Location": "Definition 3.1, Section 2 (Schreier graph definition), Proposition 4.3",
        "Explanation": "Definition 3.1 ('move from x to y via a') implies that an edge $(X,a,Y)$ in a generalized de Bruijn graph $\\Delta_r$ (where $X, Y \\in \\k^{G_r}$) exists if there is a global configuration $Z \\in \\k^G$ such that $X = Z|_{G_r}$ and $Y = (Z_a)|_{G_r}$, where $(Z_a)(g') = Z(ag')$ for $g' \\in G_r$. This is a 'left shift' of coordinates. However, the group action used for $G$-equivariance is $(aX)(g') = X(a^{-1}g')$ (a 'right shift' of coordinates, $S_a X$ in standard notation). Proposition 4.3 claims that if $f:A \\to \\k^G$ is a continuous $G$-equivariant map, then $\\phi: A_r \\to \\Delta_q$ defined by $\\phi(\\pi_{\\infty,r}(x')) = \\pi_{\\infty,q}(f(x'))$ is a homomorphism of $\\AA$-labeled graphs. An edge in $A_r$ is of the form $(\\pi_{\\infty,r}(x'), a, \\pi_{\\infty,r}(ax'))$. For $\\phi$ to be a homomorphism, $(\\pi_{\\infty,q}(f(x')), a, \\pi_{\\infty,q}(f(ax')))$ must be an edge in $\\Delta_q$. Taking $C=f(x')$, this requires $(f(x')_a)|_{G_q} = f(ax')|_{G_q}$, which translates to $f(x')(ag') = f(ax')(g')$ for $g' \\in G_q$. Using $G$-equivariance $f(ax') = S_a f(x')$, this becomes $f(x')(ag') = (S_a f(x'))(g') = f(x')(a^{-1}g')$. This relation $f(x')(ag') = f(x')(a^{-1}g')$ for all $g' \\in G_q$ is not true for arbitrary $f(x')$, unless $ag' = a^{-1}g'$ (i.e., $a^2=e$) or $f(x')$ is constant on these arguments. This makes Prop 4.3, and subsequent results relying on $\\phi$ being a homomorphism for general groups, unsound."
      },
      {
        "Problem": "The argument for non-injectivity of $(\\phi^N)^*$ in the main theorem is flawed.",
        "Location": "Section 5, proof of Theorem (last paragraph)",
        "Explanation": "The proof of the main theorem argues that if $f$ is injective but not surjective, then an associated map $\\phi: \\Delta_q \\to \\Delta_q$ is not surjective, and $(\\phi^*)$ is injective. It then considers iterates $\\phi^n$. Since $\\Delta_q$ is finite, $\\image(\\phi^n)$ stabilizes to a subgraph $\\Delta'$, and for some $N \\ge 1$, the restriction $\\phi^N|_{\\Delta'}$ is an automorphism of $\\Delta'$. The paper incorrectly states that $\\phi^N|_{\\Delta'}$ is the identity map $\\text{Id}:\\Delta' \\to \\Delta'$. The argument for $(\\phi^N)^*$ not being injective relies on this incorrect assumption. Specifically, it considers $\\iota_A = \\iota$ and $\\iota_B = \\phi^N \\circ \\iota$ (where $\\iota(G) \\not\\subseteq \\Delta'$ but $\\phi^N \\circ \\iota (G) \\subseteq \\Delta'$), and claims $(\\phi^N)^*(\\iota_A) = (\\phi^N)^*(\\iota_B)$ because $\\phi^N \\circ (\\phi^N \\circ \\iota_1) = \\phi^N \\circ \\iota_1$ if $\\phi^N|_{\\Delta'}$ is identity. If $\\phi^N|_{\\Delta'} = \\sigma$ is an automorphism other than identity, then $\\phi^N \\circ (\\phi^N \\circ \\iota) = \\sigma \\circ (\\phi^N \\circ \\iota)$, which is generally not equal to $\\phi^N \\circ \\iota$. Thus, the contradiction is not reached."
      },
      {
        "Problem": "The proof of Lemma 5.2 regarding $p$-compatibility is flawed.",
        "Location": "Section 5, proof of Lemma 5.2",
        "Explanation": "Lemma 5.2 states that for a bijective $f:A \\to \\k^G$, there is a model $\\phi:A_r \\to \\Delta_p$ that is $p$-compatible. The proof considers $\\phi_0: A_r \\to \\Delta_q$ (model of $f$) and $\\psi_0: \\Delta_q \\to \\Delta_p$ (model of $f^{-1}$), where $r \\ge q \\ge p$. It correctly shows that $\\phi_0$ is $p$-compatible with the atlas $\\alpha(y)=y$ on $A_r$ (i.e., if $\\phi_0(y_1)=\\phi_0(y_2)$ then $y_1|_{G_p}=y_2|_{G_p}$). It then defines the final model as $\\phi' = \\pi_{q,p} \\circ \\phi_0 : A_r \\to \\Delta_p$. For $\\phi'$ to be $p$-compatible (with atlas $\\alpha(y)=y$ on $A_r$), it must hold that if $\\phi'(y_1)=\\phi'(y_2)$, then $y_1|_{G_p}=y_2|_{G_p}$. This means if $\\pi_{q,p}(\\phi_0(y_1)) = \\pi_{q,p}(\\phi_0(y_2))$, then $y_1|_{G_p}=y_2|_{G_p}$. However, $\\pi_{q,p}(\\phi_0(y_1)) = \\pi_{q,p}(\\phi_0(y_2))$ does not imply $\\phi_0(y_1)=\\phi_0(y_2)$. If $\\phi_0(y_1) \\neq \\phi_0(y_2)$ but their projections to $\\k^{G_p}$ (via $\\pi_{q,p}$) are equal, the $p$-compatibility of $\\phi_0$ does not guarantee $y_1|_{G_p}=y_2|_{G_p}$. Thus, $\\phi'$ is not necessarily $p$-compatible."
      },
      {
        "Problem": "Injectivity argument in Lemma 5.1 requires specific conditions not fully addressed.",
        "Location": "Section 5, proof of Lemma 5.1",
        "Explanation": "Lemma 5.1 aims to prove that $A_r$ is a full model of $A = \\text{image}(f)$. The proof relies on the injectivity of $(\\phi \\circ \\psi)^*$, where $\\phi \\circ \\psi: A_r \\to \\Delta_p$ is a model of $\\text{Id}_A$ and corresponds to $\\pi_{r,p}|_{A_r}$. The induced map $(\\pi_{r,p}|_{A_r})^*$ is $\\iota \\mapsto (\\pi_{r,p}|_{A_r}) \\circ \\iota$. This map takes $\\iota: G \\to A_r$ to $\\iota': G \\to \\Delta_p$ where $\\iota'(g) = \\iota(g)|_{G_p}$. This map is only guaranteed to be injective if $p=r$. If $p < r$, then $\\iota_1(g)|_{G_p} = \\iota_2(g)|_{G_p}$ for all $g$ does not imply $\\iota_1(g) = \\iota_2(g)$, so $(\\pi_{r,p}|_{A_r})^*$ would not be injective. The lemma states $r \\ge q \\ge p$, allowing $p < r$. While one could choose $p=q=r$ to ensure injectivity, the proof as written claims injectivity because $\\pi_{r,p}^*$ is 'equivalent to the identity $\\text{Id}:\\k^G \\to \\k^G$', which is not accurate for $p<r$ and glosses over this requirement."
      }
    ],
    "token_usage": {
      "input": 12105,
      "thinking": 26435,
      "output": 2010
    }
  },
  {
    "entry_id": 125,
    "retraction_id": "2002.11860v4",
    "paper_id": "2002.11860v3",
    "retraction_comment": "Mistake in Lemma 3 changing the announced rate. Withdrawing while fixing the error",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect power of 'n' in the coefficient of the H_0 term in the main convergence rate (Theorem 1).",
        "Location": "Theorem 1, Eq. (11), page 6. Also affects Appendix C.",
        "Explanation": "The paper states the term related to the initial gradient error $H_0$ as $2 n^{7/2} D_2 H_0 / t^2$. However, a derivation following Appendix C and D suggests this term should be $2 n^{5/2} D_2 H_0 / t^2$. Specifically, the sum $C_t = \\sum_{k=1}^t (k+1)(1-1/n)^k$ is bounded by $n^2$ (Appendix D). This sum contributes to $\\Gamma_t$ as $2\\sqrt{n}D_2H_0 C_t \\leq 2n^{0.5} D_2 H_0 n^2 = 2n^{2.5} D_2 H_0$. When divided by $t^2$ (approx. $(t+1)(t+2)$), this yields a term $2n^{2.5} D_2 H_0 / t^2$. The stated $n^{3.5}$ (i.e., $n^{7/2}$) is a factor of $n$ larger, which significantly misrepresents the dependency on $n$ for this part of the convergence rate."
      },
      {
        "Problem": "Unsound deduction of $g_t \\to 0$ in the proof of Theorem 2 for non-convex objectives.",
        "Location": "Appendix F, Proof of Theorem 2, specifically the line 'This implies that $\\hat{g}_u \\xrightarrow[u\\to \\infty]{}0$'.",
        "Explanation": "The proof argues that because $\\sum_{u=1}^t \\gamma_u \\hat{g}_u$ is bounded (in expectation, and then a.s. since terms are non-negative), and $\\gamma_u = \\Theta(1/u)$ is not summable, then $\\hat{g}_u \\to 0$. This deduction is incorrect. From $\\sum \\gamma_u \\hat{g}_u < \\infty$ a.s., it follows that $\\gamma_u \\hat{g}_u \\to 0$ a.s., which means $\\hat{g}_u/u \\to 0$ a.s. This does not imply $\\hat{g}_u \\to 0$ a.s. or in expectation. Standard convergence results for non-convex optimization typically show weaker conditions like $\\liminf \\EE[g_t] = 0$ or average gap convergence. The claim $g_t \\to 0$ is substantially stronger and not supported by the provided argument."
      },
      {
        "Problem": "Incorrect bound referenced for $|g_t - \\hat{g}_t|$ in the proof of Theorem 2.",
        "Location": "Appendix F, Proof of Theorem 2, last sentence.",
        "Explanation": "The proof states: 'Finally, since $|g_t - \\hat{g}_t| \\leq (R_1 + D_2)H_t$ (Appendix \\ref{apx:proof_proxy_gap}), this also implies the true Frank-Wolfe gap goes to 0'. Appendix E (apx:proof_proxy_gap) contains Proposition 1, which states $|g_t - \\hat{g}_t| \\leq 2 R_2 H_t$, where $R_2 = \\max_{\\ww\\in \\CC} \\|\\XX\\ww\\|_2$. The term $(R_1 + D_2)H_t$ uses an undefined constant $R_1$ and different constants than those derived in Proposition 1. This makes the final step of the argument for $g_t \\to 0$ (even if $\\hat{g}_t \\to 0$ were true) rely on an unsubstantiated bound."
      },
      {
        "Problem": "Potentially incorrect coefficient for $H_t$ in the non-convex recursion in Theorem 2 proof.",
        "Location": "Appendix F, Proof of Theorem 2, third line of the proof: $f(\\XX\\ww_t) \\leq ... - \\gamma_t \\hat g_t + \\gamma_tR_2H_t + ...$",
        "Explanation": "The term $\\gamma_t R_2 H_t$ arises from bounding $\\gamma_t\\langle \\nabla f(\\XX\\ww_{t-1}) - \\balpha_t, \\XX(\\sss_t - \\ww_{t-1})\\rangle$. Given $H_t = \\|\\nabla f - \\balpha_t\\|_1$, this inner product is bounded by $\\gamma_t H_t \\|\\XX(\\sss_t - \\ww_{t-1})\\|_\\infty$. Using $D_1 = \\max_i \\max_{\\uu,\\vv} |\\xx_i^\\top(\\uu-\\vv)|$, this becomes $\\gamma_t H_t D_1$. Alternatively, using Cauchy-Schwarz and $\\|A\\|_2 \\leq \\|A\\|_1$, it's bounded by $\\gamma_t H_t \\|\\XX(\\sss_t - \\ww_{t-1})\\|_2 \\leq \\gamma_t H_t \\sqrt{n} D_2$. The use of $R_2 = \\max_{\\ww \\in \\CC} \\|\\XX\\ww\\|_2$ as the coefficient for $H_t$ in this specific step is not clearly justified and seems inconsistent with how similar terms are bounded elsewhere (e.g., Lemma 1 uses $\\sqrt{n}D_2$). This could affect the summability argument for $\\sum \\gamma_u R_2 H_u$ if $R_2$ has a different behavior or magnitude than $D_1$ or $\\sqrt{n}D_2$."
      }
    ],
    "token_usage": {
      "input": 43117,
      "thinking": 18438,
      "output": 1375
    }
  },
  {
    "entry_id": 126,
    "retraction_id": "2109.13007v2",
    "paper_id": "2109.13007v1",
    "retraction_comment": "We found a gap in the claim 1 (we can not solve it)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation in the proof of Proposition 1 for the boundary case.",
        "Location": "Page 4, Proof of Proposition 1",
        "Explanation": "The derivation starting with '$1 = \\langle \\alpha(\\eta_1, \\eta_1), p \\rangle$' aims to show that the normal vectors $\\eta_1$ and $\\eta_2$ must be linearly dependent if the contact point $p$ is on the boundary $\\s^n$. However, the initial equation should be '$-1 = \\langle \\alpha(\\eta_1, \\eta_1), p \\rangle$' (as $\\alpha(X,Y) = -\\langle X,Y \\rangle p$ for $\\s^n$ with outward normal $p$). If corrected, this line of reasoning leads to '$-1 = -1$', which is not a contradiction. Additionally, subsequent steps like '$\\eta_1 \\langle \\eta_1, p \\rangle - 1 = \\langle \\nabla^{\\Sigma_2}_{\\eta_1} \\eta_1, p \\rangle + \\langle \\eta_1, \\nabla^{\\Sigma_2}_{\\eta_1} p \\rangle - 1$' involve terms like $\\nabla^{\\Sigma_2}_{\\eta_1} \\eta_1$ which are not clearly defined or justified when $\\eta_1$ (normal to $\\Sigma_1$) and $\\eta_2$ (normal to $\\rho(\\theta_0, \\Sigma_2)$) are assumed linearly independent. This undermines the argument that $\\eta_1$ and $\\eta_2$ must be linearly dependent."
      },
      {
        "Problem": "The argument in Claim 1 does not cover all 'equatorial semi-disks'.",
        "Location": "Page 5, Proof of Claim 1",
        "Explanation": "Claim 1 states that 'Every equatorial semi-disk must intersect $\\Sigma_1^+$'. The proof assumes that an arbitrary equatorial semi-disk $\\mathcal{D}^+$ can be written as $\\rho(\\theta_1, \\mathcal{D}_+[\nu, \\eta])$ for some $\\theta_1$, i.e., it is a leaf of the specific foliation $\\{\\rho(\\theta, \\mathcal{D}_+[\nu, \\eta])\\}_\\theta$ generated by rotating a base semi-disk $\\mathcal{D}_+[\nu, \\eta]$ (which lies in $\\mathcal{D}[\\nu]$) in the $(\\nu, \\eta)$-plane. This is not true for a general equatorial semi-disk. For example, a semi-disk in an equatorial plane orthogonal to the $(\\nu, \\eta)$-plane would not be part of this family. Thus, the proof only shows the intersection property for semi-disks within this specific foliation, not for all equatorial semi-disks."
      },
      {
        "Problem": "Conflicting definitions and usage of the rotation matrix $\\rho$ in Claim 2.",
        "Location": "Page 6, Proof of Claim 2",
        "Explanation": "The proof of Claim 2 first defines the rotation $\\rho(\\theta, \\cdot)$ as being 'with respect to $\\{\\overline{p}_1, \\overline{p}_2\\}$, an orthonormalization of $\\{p_1, p_2\\}$' (where $p_1 \\in \\Sigma_1^+, p_2 \\in \\Sigma_2^+$ are arbitrary non-collinear vectors). It then states this rotation is 'defined as in \\eqref{matriz}'. Equation \\eqref{matriz} defines a specific rotation in the plane spanned by fixed vectors $\\nu$ and $\\eta$ (where $\\nu$ defines the half-ball $\\mathcal{H}_+[\nu]$). These two definitions of $\\rho$ are generally different. If $\\rho$ is defined by $p_1, p_2$, then the set $\\mathcal{I}[\\overline{p}_1, \\overline{p}_2]$ (orthogonal complement to $p_1, p_2$) is invariant. However, later parts of the argument (e.g., $p_0 = \\rho(\\theta_0 - \\varepsilon_0, p) \\in \\mathcal{H}_+[\nu] \\setminus \\mathcal{D}[\\nu]$) implicitly assume $\\rho$ is the rotation from \\eqref{matriz}. This ambiguity is critical because the invariance of $\\mathcal{I}$ is key to the paper's contradiction argument."
      },
      {
        "Problem": "The contradiction argument in Claim 2 is flawed due to the issues with the rotation $\\rho$.",
        "Location": "Page 6, Proof of Claim 2",
        "Explanation": "The proof of Claim 2 aims to show $\\Sigma_1^+ \\cap \\Sigma_2^+ \\neq \\emptyset$. It assumes they are disjoint and argues that a rotation $\\rho(\\theta_0, \\Sigma_2^+)$ would first touch $\\Sigma_1^+$ leading to $\\Sigma_1^+ = \\rho(\\theta_0, \\Sigma_2^+)$. The contradiction is then derived using the set $\\mathcal{I}[\\overline{p}_1, \\overline{p}_2]$: it's claimed $\\Sigma_2^+ \\cap \\mathcal{I} \\neq \\emptyset$ (from Claim 1), $\\mathcal{I}$ is invariant under $\\rho$, so $\\rho(\\theta_0, \\Sigma_2^+) \\cap \\mathcal{I} \\neq \\emptyset$, implying $\\Sigma_1^+ \\cap \\Sigma_2^+ \\cap \\mathcal{I} \\neq \\emptyset$, which contradicts the initial disjointness. This relies on $\\mathcal{I}$ being invariant under $\\rho$, which is only true if $\\rho$ is the rotation in the $(\\overline{p}_1, \\overline{p}_2)$-plane. However, other parts of the argument, and the general structure of such proofs, suggest $\\rho$ should be the fixed rotation from \\eqref{matriz}. If $\\rho$ is the fixed rotation from \\eqref{matriz}, $\\mathcal{I}$ is not generally invariant, so the contradiction does not follow as stated. The final paragraph of the proof of Claim 2 further confuses this by re-invoking the invariance of $\\mathcal{I}$ for a contradiction."
      },
      {
        "Problem": "Insufficient justification for the proof of the Two-Piece Property (Corollary B).",
        "Location": "Page 6, Proof of Corollary B",
        "Explanation": "The proof of Corollary B states that if $\\Sigma^+ = \\Sigma \\cap \\mathcal{H}_+[\nu]$ is disconnected, say $\\Sigma^+ = \\Sigma_1^+ \\cup \\Sigma_2^+$ (a disjoint union), this would contradict Theorem A (Strong Frankel Property). However, Theorem A applies to 'compact minimal hypersurfaces with free boundary in B'. If $\\Sigma_1^+$ and $\\Sigma_2^+$ are connected components of $\\Sigma \\cap \\mathcal{H}_+[\nu]$, they are minimal, but their boundaries may now include parts lying in the equatorial disk $\\mathcal{D}[\\nu]$ (the boundary of $\\mathcal{H}_+[\nu]$ in $B$). These new boundary parts are not on $\\s^n$ and do not satisfy the free boundary condition in the sense required by the definition on page 1. Therefore, $\\Sigma_1^+$ and $\\Sigma_2^+$ are not necessarily 'free boundary minimal hypersurfaces in B' to which Theorem A can be directly applied. The argument needs further elaboration."
      }
    ],
    "token_usage": {
      "input": 8233,
      "thinking": 17387,
      "output": 1680
    }
  },
  {
    "entry_id": 127,
    "retraction_id": "1305.3218v2",
    "paper_id": "1305.3218v1",
    "retraction_comment": "This paper has been withdrawn by the author. Due to the dependence of f(\\sigma) on z, Lemma 5.3 is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Proposition 4.1 (exponential monotone circuit complexity of Clique) is flawed.",
        "Location": "Section 4, specifically Lemma 4.7 and its use in Proposition 4.1 (page 20-21).",
        "Explanation": "Lemma 4.7 argues that the constructed global term $t(\\mathbf{y})$ contains no $k$-clique (where $k=n^{1/4}$). The argument relies on $t(\\mathbf{y})$ avoiding edges in a set $\\hat{z} = \\bigcup_{j=1}^{q-1} z_j$, where each $z_j \\subset \\binom{y_j}{2}$ (i.e., $z_j$ consists of edges *within* the vertex partition $y_j$). The removal of $z_j$ from $\\binom{y_j}{2}$ makes $y_j$ free of $n^{1/5}$-cliques. The term $t(\\mathbf{y})$ also has no edges in $\\binom{y_q}{2}$. This setup ensures that no $k$-clique can exist *entirely within* any $y_j$. However, it does not prevent a $k$-clique whose vertices span multiple $y_j$'s and whose edges consist of inter-$y_j$ edges (which are not in $\\hat{z}$) and permissible intra-$y_j$ edges (those not in $z_j$ and not forming an $n^{1/5}$-clique within their respective $y_j$). Since $k=n^{1/4}$ is larger than $n^{1/5}$, a $k$-clique cannot be entirely within a $y_j$ that is $n^{1/5}$-clique-free. But the argument fails to rule out $k$-cliques distributed across multiple $y_j$ blocks. This gap makes the conclusion of Lemma 4.7, and therefore Proposition 4.1 as proven in this section, unsupported. While Proposition 4.1 is a known result (Alon-Boppana), this paper claims a 'new approach' in abstract (ii), and this new approach appears flawed for the monotone case as presented."
      }
    ],
    "token_usage": {
      "input": 75496,
      "thinking": 17084,
      "output": 501
    }
  },
  {
    "entry_id": 128,
    "retraction_id": "1502.02299v3",
    "paper_id": "1502.02299v2",
    "retraction_comment": "This paper has been withdrawn by the authors due to a sign error in the last equation of system (2.11). In turn, this implies a change of sign of the last equation in the linearized system (3.1) as well. The linear three annuli property for solutions to the new system (3.1) is no longer valid",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory statement regarding $s_0=0$ as an eigenvalue for eigenfunctions in $W$.",
        "Location": "Proposition 3.5, page 10 (Section 3.4).",
        "Explanation": "Proposition 3.5 states that $s_0=0$ is an eigenvalue of the problem (3.16) for an eigenfunction $\\sigma \\in W$, with the explicit eigenfunction $f_0(\\phi) = c_0 \\sin(\\sqrt{1/4+s_0}(\\phi-\\pi)) = -c_0 \\cos(\\phi/2)$ (normalized by $c_0=1$). However, for $\\sigma \\in W$, it must satisfy the condition (3.13): $\\int_0^{2\\pi} \\sigma(\\phi) \\cos(\\phi/2) d\\phi = -\\pi \\sigma(0)$. Substituting $\\sigma(\\phi) = -c_0 \\cos(\\phi/2)$ into this condition yields $-c_0 \\int_0^{2\\pi} \\cos^2(\\phi/2) d\\phi = -\\pi (-c_0 \\cos(0))$, which simplifies to $-c_0\\pi = c_0\\pi$. This implies $c_0=0$, meaning $\\sigma=0$. Therefore, $s_0=0$ is not an eigenvalue for any non-trivial eigenfunction in $W$. This contradicts the claim in Proposition 3.5."
      },
      {
        "Problem": "The curvature equation in the reparametrized system (2.9) may be missing a factor of 2.",
        "Location": "Equation (2.9) (fourth equation, for curvature), page 6; also Equation (2.19), page 8.",
        "Explanation": "The fourth equation in system (2.9) relates the curvature of the singular set $S_u$ to the jump in energy density terms. Standard derivations for Mumford-Shah minimizers, such as in Bonnet-David (2001) or Ambrosio-Fusco-Pallara (2000), yield a condition of the form $2\\mathbf{k} = [(\\partial_s u)^2]$ or $\\mathbf{k} = \frac{1}{2}[|\nabla u|^2]$ (where $\\mathbf{k}$ is curvature and $[\\cdot]$ denotes the jump). The paper uses a form equivalent to $\\mathbf{k} = [|\nabla u|^2]$ (after transformation to $f, \\vartheta$ variables). This suggests that the curvature term on the LHS of the equation might be missing a factor of 2 (i.e., it should be $2 \times \text{LHS} = \text{RHS}$). Such a factor would propagate through the linearization and affect quantitative aspects of the derived system for $(w, \\lambda)$, notably the relation between coefficients $b_0$ and $b_1$ in Section 4.2."
      },
      {
        "Problem": "Algebraic error in the derived relation between coefficients $b_0$ and $b_1$.",
        "Location": "Page 14, paragraph after equation (4.10) (Section 4.2).",
        "Explanation": "In the analysis of the ODE system (4.9) for $\beta_0, \beta_1, \\lambda$, the paper states that the last equation implies $b_0 = -\frac{\\pi}{8}b_1$. However, a detailed calculation based on the provided equations for $\beta_0(t)=(a_0+b_0t)e^{t/2}$, $\\dot\\lambda = -\\sqrt{\\pi/2}\beta_1(t)$, and $\\ddot\\lambda - \\dot\\lambda = \\sqrt{2/\\pi}(\beta_0 - 2\\dot\beta_0)$ leads to the relation $b_0 = -\frac{\\pi}{16}b_1$. This is a factor of $1/2$ difference. This discrepancy might be linked to the potential missing factor of 2 in the curvature equation (Problem 2); if the curvature equation were $2 \times \text{LHS} = \text{RHS}$, the derived relation would become $b_0 = -\frac{\\pi}{8}b_1$ as stated in the paper."
      }
    ],
    "token_usage": {
      "input": 38489,
      "thinking": 26477,
      "output": 965
    }
  },
  {
    "entry_id": 129,
    "retraction_id": "1901.07856v7",
    "paper_id": "1901.07856v6",
    "retraction_comment": "The proof of the the second inequality of Lemma 7 is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The analysis of MainAlgorithm's (MA) efficiency relies on a probability $p_{rerun}$ (the probability that EC's output is not proper or not 4-acyclic) being a constant less than 1, independent of $m$ (the number of edges). However, the derived bound for $p_{rerun}$ is $1 - (1 - 2/(2+\\epsilon))^m$. For large $m$, this $p_{rerun}$ approaches 1 very quickly (e.g., $1 - c^{-m}$ for some constant $c > 1$). This implies the expected number of MA iterations is approximately $c^m$, making the overall algorithm exponential in $m$, contradicting the claim of polynomial-time execution with high probability.",
        "Location": "Section 3, Analysis of MA (via $\\hat{Q}_n$ in Lemma 3 and its proof), and final complexity claims (Abstract, Theorem*). Specifically, the calculation of $\\Pr[\\text{a random coloring is not strongly proper}]$ in the proof of Lemma 3.",
        "Explanation": "The probability that a random coloring is proper and 4-acyclic, $\\Pr[\\text{strongly proper}]$, is bounded below by $(1 - 2/(2+\\epsilon))^m$. Thus, $p_{rerun} = \\Pr[\\text{not strongly proper}] \\le 1 - (1 - 2/(2+\\epsilon))^m$. If $m$ is part of the input size (not a constant), then $(1 - 2/(2+\\epsilon))^m$ is exponentially small in $m$. So $p_{rerun}$ is of the form $1 - \\delta^m$ where $\\delta < 1$. The number of iterations of MA is geometrically distributed with success probability $1-p_{rerun} = \\delta^m$. The expected number of iterations is $1/(\\delta^m) = (1/\\delta)^m$, which is exponential in $m$. Since each EC call takes at least polynomial time in $m$, the total time complexity would be exponential in $m$. The paper's claim (e.g. in Abstract) of polynomial time seems to be invalidated by this. The phrasing 'l, m and $\\Delta$ ... are considered constant' in Lemma 5 (formerly Thm Main) is problematic if $m$ is an input parameter."
      },
      {
        "Problem": "The interpretation of 'homochromatic edges of the same parity' is ambiguous and critical for the correctness of $\\Pr[V_{\\mathcal{F}}]$ in Lemma 2.",
        "Location": "Section 2.2, EC algorithm, line 4 (while condition); Section 3.2, CV algorithm, line 2 (if condition); Lemma 2 (calculation of $\\Pr[V_{\\mathcal{F}}]$).",
        "Explanation": "The algorithm EC's while loop (line 4) condition is 'a cycle ... having homochromatic edges of the same parity'. The validation algorithm CV's success condition (line 2) is '$C_i^0(e_i)$ and $C_i^1(e_i)$ are both monochromatic'. If EC's condition means '$C_i^0(e_i)$ is monochromatic OR $C_i^1(e_i)$ is monochromatic', then the probability of this event is approximately $2/K^{k_i-1}$ (for large K). However, Lemma 2 calculates $\\Pr[V_{\\mathcal{F}}]$ using the 'AND' condition, yielding $(1/K)^{2k_i-2}$. If EC uses the 'OR' condition, then $\\Pr[V_{\\mathcal{F}}]$ is underestimated, and the subsequent analysis of $R_n$ would be incorrect, potentially affecting the convergence condition $q < 1/2$. While 'bichromatic' often implies the 'AND' condition, the phrasing is ambiguous and should be explicit."
      },
      {
        "Problem": "The bound on the number of cycles used in Lemma 4 for the recurrence $R_n$ might be too high, potentially affecting the constant factor $q$.",
        "Location": "Section 3.3, Proof of Lemma 4 (Recurrence for $R_n$).",
        "Explanation": "The proof of Lemma 4 states: 'observe that there are at most $\\Delta^{2k-2}$ possible cycles with $2k$ edges... that can be the cycle-edge of the root'. This is used to justify the factor $q^{2k-2} = ((\\Delta-1)/K)^{2k-2}$, implying the number of cycles of length $2k$ through a given edge $e$ is bounded by $(\\Delta-1)^{2k-2}$. While $(\\Delta-1)^{L-1}$ is a loose bound for paths of length $L-1$ starting at one endpoint of $e$, the number of simple cycles of length $L$ through a specific edge is typically bounded by expressions like $(\\Delta-1)^{L-1}$ or similar, but $(\\Delta-1)^{2k-2}$ for a $2k$-cycle might be an overestimation if it's not carefully justified (e.g. counting paths of length $2k-2$ between the two neighbors of a specific vertex on the cycle, not involving that vertex). If this count is significantly lower, $q$ might be smaller, which would strengthen the result but means the current analysis might be based on a loose bound. Conversely, if it's an underestimation or incorrect, it could be an issue. This is less critical than the previous points but worth noting for soundness of the specific recurrence coefficients."
      }
    ],
    "token_usage": {
      "input": 12470,
      "thinking": 22207,
      "output": 1266
    }
  },
  {
    "entry_id": 130,
    "retraction_id": "1912.10027v2",
    "paper_id": "1912.10027v1",
    "retraction_comment": "We have found some errors in the methods, in particular two of the methods are not A-stable",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect conditions for achieving $O(\\Delta t^{p+2})$ error after post-processing in Theorem 1.",
        "Location": "Section 3.1, Theorem 1 (page 7) and its proof (pages 8-11), specifically conditions (3b)-(3d) (eqs. 9b-9d) and their use in analyzing term III (page 10).",
        "Explanation": "The proof of Theorem 1 requires that two components of the error sum (term III and term IV in the paper's Duhamel expansion) become $O(\\Delta t^{p+2})$ after applying the EIS conditions. The conditions stated in the theorem, specifically $\\mD(\\mathbf{A}_F+\\mathbf{R}_F)\\boldsymbol{\\tau}_{p+1}=0$ (eq. 9c) and $\\mD(\\mathbf{A}_G+\\mathbf{R}_G)\\boldsymbol{\\tau}_{p+1}=0$ (eq. 9d), are sufficient for term IV. However, for term III (the contribution from $\\Delta t \\mathbf{Q}^{n-1} T_e^{n-2}$), the analysis on page 10 (eq. 11, last line) leads to a term $\\mathbf{F}_y^{n-1} (\\mD\\mathbf{R}_F + \\mathbf{A}_F)\\boldsymbol{\\tau}_{p+1}^{n-1} + \\mathbf{G}_y^{n-1} (\\mD\\mathbf{R}_G + \\mathbf{A}_G)\\boldsymbol{\\tau}_{p+1}^{n-1}$. For this to be zero for arbitrary $\\mathbf{F}_y, \\mathbf{G}_y$, the conditions must be $(\\mD\\mathbf{R}_F + \\mathbf{A}_F)\\boldsymbol{\\tau}_{p+1}=0$ and $(\\mD\\mathbf{R}_G + \\mathbf{A}_G)\\boldsymbol{\\tau}_{p+1}=0$. These are stronger and generally not equivalent to conditions (9c)-(9d). If only (9c)-(9d) are satisfied, term III is not guaranteed to be $O(\\Delta t^{p+2})$, potentially invalidating the theorem's conclusion that $E^n = \\Delta t^{p+1} \\boldsymbol{\\tau}^n_{p+1} + O(\\Delta t^{p+2})$ and thus the foundation for the $p+2$ order post-processor."
      },
      {
        "Problem": "Assumption of scalar Jacobians $F_y, G_y$ in error analysis.",
        "Location": "Section 2.2, Observation 1 (page 5) and Lemma 1 (page 6). Specifically, the proof of Lemma 1 states: '...the terms $F_y^n, G_y^n, F_y^{n+1}, G_y^{n+1}$ are all constant scalars...'",
        "Explanation": "The theoretical derivations, particularly for the error evolution equation (Lemma 1), explicitly state that $F_y$ and $G_y$ (and their time-shifted versions) are treated as scalars. While this simplifies notation and is common for deriving order conditions for scalar ODEs, it is not generally true for systems of ODEs, where $F_y$ and $G_y$ are Jacobian matrices. The numerical examples presented (Van der Pol, Burgers' equation) are systems. If the theory is intended for general systems, the analysis should use matrix Jacobians and Kronecker products where appropriate (e.g., $\\mathbf{R}_F \\otimes J_F(u(t_n))$). Stating they are 'constant scalars' is a critical simplification that may limit the validity of the derived error form and subsequent conditions to scalar ODEs or overly restrictive systems, unless a rigorous argument for extension to systems (maintaining the same final conditions on coefficient matrices) is provided."
      }
    ],
    "token_usage": {
      "input": 36361,
      "thinking": 19147,
      "output": 890
    }
  },
  {
    "entry_id": 131,
    "retraction_id": "1502.05353v3",
    "paper_id": "1502.05353v2",
    "retraction_comment": "This paper has been withdrawn due to some errors. The main error is the wrong spin function of Eq. (5), which makes equations (13) and (14) incorrect, and in turn puts doubts on the final conclusions",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Overestimation of overlap integrals by implicitly assuming atomic orbital overlaps are unity.",
        "Location": "Page 12 (Eq. 17-18), Page 15 (Eq. 21), Page 17 (discussion relating S_ij to c^2)",
        "Explanation": "The calculation of the two-particle overlap integral O_12 ≈ c^4 (leading to J_d = -2ε̃_+ c^4) and the single-particle overlap S_ij ≈ c^2 (leading to τ ≈ -ε̃_+ c^2) implicitly assumes that the underlying atomic orbital overlaps (e.g., S_pp between p-orbitals on adjacent oxygen atoms involved in the bond) are equal to 1. In reality, such atomic overlaps are significantly less than unity (e.g., S_pp ≈ 0.2-0.3). This assumption would lead to a substantial overestimation of O_12 and S_ij, and consequently a significant overestimation of the calculated direct exchange J_d and hopping parameter τ. If J_d is overestimated, its claimed dominance over the indirect exchange and the subsequent conclusions about critical doping would be invalid."
      },
      {
        "Problem": "Unconventional definition of the direct exchange integral J_d.",
        "Location": "Page 10, Eq. (13)",
        "Explanation": "The direct exchange integral is defined as J_d = -2ε̃_+ O_12, where 2ε̃_+ is the diagonal energy of the two-particle state (including direct Coulomb repulsion I) and O_12 is the overlap integral <Ψ_i(1)Ψ_j(2)|Ψ_j(1)Ψ_i(2)>. This definition does not correspond to the standard definition of the direct Coulomb exchange integral, K_ex = <Ψ_i(1)Ψ_j(2)|e²/|r1-r2||Ψ_j(1)Ψ_i(2)>, nor to the full off-diagonal Hamiltonian matrix element H_12 = 2ε_+ O_12 + K_ex which determines the exchange splitting in the Heitler-London approach. The paper's J_d appears to be -(Diagonal Energy Element) * Overlap, which is not the conventional exchange term. This potentially misidentifies the physical origin and the mathematical form of the direct exchange energy, which could lead to incorrect quantitative estimates and conceptual interpretations."
      },
      {
        "Problem": "Inconsistent formulation of the direct exchange term in the proposed modified t-J Hamiltonian.",
        "Location": "Page 19, Eq. (27) compared to Page 10, Eq. (14) and Page 18, Conclusion 2",
        "Explanation": "The derivation of J_d (e.g., Eq. 14) indicates an energy splitting of 2J_d between the triplet (parallel spins, energy 2ε̃_+ + J_d) and singlet (anti-parallel spins, energy 2ε̃_+ - J_d) states. This would correspond to an effective Heisenberg interaction term of the form 2J_d S_i·S_j. However, the proposed modified t-J Hamiltonian in Eq. (27) includes a direct exchange term written as 4J_d ΣSᵢ·Sⱼ. This term implies an energy of +J_d for parallel spins (S_i·S_j = 1/4) and -3J_d for anti-parallel spins (S_i·S_j = -3/4), leading to a splitting of 4J_d. This factor of 2 discrepancy in the magnitude of the exchange interaction term is inconsistent with the earlier derivation and undermines the quantitative analysis based on the proposed Hamiltonian, such as the calculation of critical doping."
      },
      {
        "Problem": "Approximations in the evaluation of the overlap integral O_12.",
        "Location": "Page 12, leading to Eq. (17)",
        "Explanation": "The paper simplifies the full expression for O_12 (Eq. 16) by claiming that only the first term, (c² P_1x1 P_2x2)², is dominant and that other terms either vanish due to symmetry or are negligibly small. The argument for vanishing terms (e.g., based on anti-symmetry of P_1x1 P_2x2 integrands) appears flawed, as P_x is an odd function, making P_1x1 P_2x2 an even function if x1 and x2 are coordinates of different particles. Furthermore, the neglecting of terms involving d-orbitals (e.g., (b²D₁D₂)²) as 'negligibly small' requires more rigorous justification than provided. If these neglected or incorrectly dismissed terms are significant, the resulting approximation O_12 ≈ ∫d³r1 d³r2 (c² P_1x1 P_2x2)² and subsequently O_12 ≈ c^4 would be inaccurate, impacting the calculation of J_d."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 15673,
      "output": 1127
    }
  },
  {
    "entry_id": 132,
    "retraction_id": "1808.08722v2",
    "paper_id": "1808.08722v1",
    "retraction_comment": "We find the polarization degrees of freedom of the squeezed light had not been treated properly in our analysis, which would affect our results significantly especially in the case of dissipative quantum walks. A new analysis is currently underway. We thank [REDACTED-NAME] for help in clarifying these issues",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mischaracterization of error correction failure for the unitary QW scheme.",
        "Location": "Sec. II.A, Page 3, Right column, Last paragraph",
        "Explanation": "The paper states that for the unitary QW codewords, 'the key drawbacks ... reside in their momentum distributions ... which would render the correction for p-errors ineffective.' However, GKP p-errors (momentum shifts) are typically corrected by position measurements, leveraging the position-space comb structure of the codewords. Figure 2(a) shows that $|0\\rangle_{\\rm QW}$ and $|1\\rangle_{\\rm QW}$ do possess the necessary position-space combs. Conversely, x-errors (position shifts) are corrected by momentum measurements on the superpositions $|+\\rangle_{\\rm QW}$ and $|-\\rangle_{\\rm QW}$. The problematic momentum distributions (featureless Gaussians for $|0/1\\rangle_{\\rm QW}$ in Fig. 2b, and broad peaks for $|+/- \\rangle_{\\rm QW}$ in Fig. 2d) would primarily hinder the correction of x-errors or indicate a fundamental deviation from the GKP structure where both bases should exhibit comb-like structures in both position and momentum representations. The stated ineffectiveness for 'p-errors' appears to be a misattribution."
      },
      {
        "Problem": "The practical implications of low success probability for the dissipative QW scheme are not fully elaborated.",
        "Location": "Sec. II.B, particularly around Eq. 19 and Eq. 21",
        "Explanation": "The dissipative QW scheme relies on projections, leading to a heralded state generation with success probability $Z_N$ (for $|0\\rangle_{\\rm dQW}$) or $Z_{N+1}$ (for $|1\\rangle_{\\rm dQW}$), where $Z_N \\approx 1/(2\\sqrt{\\pi N})$. For $N=8$, this is roughly 10%. While the normalization factor $\\mathcal{N}$ in Eq. 21 accounts for this probabilistically, the paper does not extensively discuss the significant practical challenge this low and $N$-dependent success rate poses for generating codewords, especially when comparing performance against GKP states whose generation challenges are different and not factored into this specific comparison. This omission could underrepresent the true resource cost or difficulty of the proposed dQW scheme in a practical scenario."
      },
      {
        "Problem": "Potentially misleading comparison due to differing momentum spike widths between dQW and GKP states.",
        "Location": "Sec. II.B, discussion around Fig. 4 and choice of parameters $e^{-r}=1/\\sqrt{N\\pi}$",
        "Explanation": "The comparison in Fig. 4 sets the dQW parameter $e^{-r} = 1/\\sqrt{N\\pi}$, which matches the position spike width $\\Delta_x$ of the reference GKP state (where $\\Delta_x = \\Delta_p = 1/\\sqrt{N\\pi}$). However, the dQW state's momentum wavefunction $\\propto \\cos^N(p\\Delta x)$ results in momentum spikes whose effective width is approximately $\\sqrt{2/N}/\\Delta x = \\sqrt{2/(N\\pi^2)}$ (for $\\Delta x = \\sqrt{\\pi}$). This is narrower than the GKP momentum spike width $\\Delta_p = 1/\\sqrt{N\\pi}$ by a factor of $\\sqrt{2/\\pi} \\approx 0.8$. Thus, the dQW states being compared have effectively better momentum squeezing for their individual spikes than the GKP states, for the same position spike width. This structural difference, which could contribute to the dQW states' slightly better performance in $P_{\\text{no error}}$, is not explicitly highlighted or discussed as a factor in the comparison, potentially making the 'outperformance' claim less direct than implied."
      }
    ],
    "token_usage": {
      "input": 14519,
      "thinking": 23878,
      "output": 881
    }
  },
  {
    "entry_id": 133,
    "retraction_id": "2406.11623v4",
    "paper_id": "2406.11623v3",
    "retraction_comment": "Some errors appeared in the article that seem difficult to correct. For example, the Green function $G_R(o,x)$ for the geodesic ball $B(R)$ was misunderstood to satisfy the Dirichlet boundary condition on the geodesic sphere $\\partial B(R)$, however, this is not the case",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Conclusion of Picard's Theorem (Corollary 1.4 / Corollary 5.6) is not fully justified.",
        "Location": "Page 3 (Corollary 1.4 statement), Page 18 (Corollary 5.6 statement and derivation)",
        "Explanation": "The argument for Picard's Theorem correctly deduces that if a non-constant meromorphic function $f: M \\to \\mathbb{P}^1$ omits 3 distinct values, then its characteristic function $T_f(r)$ must satisfy $T_f(r) = O(\\log r)$ for $r$ outside an exceptional set of finite measure. However, the conclusion that $f$ must be constant relies on the assertion that $T_f(r) = O(\\log r)$ implies $f$ is constant for the class of manifolds $M$ considered (complete K\\\"ahler, non-negative Ricci curvature, positive global Green function). This implication is true for $M=\\mathbb{C}^m$, but not necessarily for all manifolds in the specified class. For example, if $M = N \\times \\mathbb{C}$ where $N$ is a compact K\\\"ahler manifold with non-negative Ricci curvature, then $M$ satisfies the conditions, but $f(n,z) = z$ is a non-constant meromorphic function with $T_f(r) \\sim \\log r$. Thus, the conclusion that $f$ must be constant is an overstatement without further conditions on $M$ or $f$."
      },
      {
        "Problem": "Potentially flawed derivation step in the proof of the Logarithmic Derivative Lemma (Theorem 4.6).",
        "Location": "Page 13, Proof of Theorem 4.6 (Logarithmic Derivative Lemma)",
        "Explanation": "In the proof of Theorem 4.6, the term $\\int_{\\partial\\Delta(r)}\\log\\left(1+\\log^2|\\psi|\\right)d\\pi_r$ is bounded. The paper states this is less than or equal to $\\log\\int_{\\partial\\Delta(r)}\\Big{(}\\log^+|\\psi|+\\log^+\\frac{1}{|\\psi|}\\Big{)}d\\pi_r +O(1)$. This step is not correct. A correct derivation using Jensen's inequality and properties of logarithms (e.g., $\\log(1+X^2) \\le 2\\log^+ X + \\log 2$) would lead to a bound of the form $O(\\log^+ T(r,\\psi)) + O(1)$. While the final coefficient for $\\log^+ T(r,\\psi)$ in Theorem 4.6 appears to be standard and likely correct, the specific intermediate derivation step shown is unsound. This affects the rigor of the proof, though the lemma statement itself might hold by other arguments or if this step is corrected."
      },
      {
        "Problem": "Assumption on the limit of ratio of distances in heat kernel estimates.",
        "Location": "Page 7, Proof of Theorem 2.2 (Theorem \\ref{hhh}) and Page 10, Proof of Theorem 4.4 (Theorem \\ref{hhhh})",
        "Explanation": "The proofs of Theorem 2.2 and Theorem 4.4 rely on estimating the limit $\\lim_{t\\to r}\\frac{r-t}{\\rho_{t, \\vec{\\nu}}(x)}$, where $\\rho_{t, \\vec{\\nu}}(x)$ is the Riemannian distance between $x \\in \\partial\\Delta(r)$ and $x_{t, \\vec{\\nu}} \\in \\partial\\Delta(t)$ along a normal line. It is asserted that this limit is bounded by $1+\\epsilon_0/2$ (or approaches 1 as $r \\to R$ or $r \\to \\infty$). This relies on the smoothness and geometric behavior of the level sets $\\partial\\Delta(r)$. While plausible for well-behaved level sets, this geometric property is asserted without detailed justification for the specific construction of $\\Delta(r)$ via heat kernels on a general K\\\"ahler manifold. A more rigorous justification of this limit behavior would strengthen the argument."
      }
    ],
    "token_usage": {
      "input": 26566,
      "thinking": 22767,
      "output": 943
    }
  },
  {
    "entry_id": 134,
    "retraction_id": "2108.09325v2",
    "paper_id": "2108.09325v1",
    "retraction_comment": "Several sections, particularly Section 5, contain an error interpreting the mutual inclination directly as the obliquity",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of the $\\epsilon_{\\rm GR}$ range for perpendicular outcomes",
        "Location": "Section 3, paragraph 1 (describing $\\epsilon_{\\rm GR}$ ranges) and Figure 3 (colored bands)",
        "Explanation": "The paper defines a 'GR-reduced HEM' regime leading to perpendicular orbits ($60^\\circ < i_{\\rm min} < 120^\\circ$) and provides corresponding $\\epsilon_{\\rm GR}$ ranges for different initial semi-major axes ($a_{\\rm in}$). For example, for $a_{\\rm in}=0.19$ AU, the stated range is $\\epsilon_{\\rm GR} \\in [0.8, 2.9]$. However, recalculating using the paper's Eq. (1) and the condition $i_{\\rm min} \\ge 60^\\circ$ (i.e., $\\cos^2 i_{\\rm min} \\le 0.25$) yields a lower bound of $\\epsilon_{\\rm GR} \\approx 1.68$, not $0.8$. Similar discrepancies appear for other $a_{\\rm in}$ values. This error means the true parameter space (the colored bands in Fig. 3) for producing perpendicular planets via this mechanism is significantly narrower than claimed, which would reduce the predicted efficiency of the mechanism and alter the interpretation of which observed systems fall into this regime."
      },
      {
        "Problem": "Observational support from HAT-P-11 system is inconsistent with the paper's theory",
        "Location": "Section 3, Figure 3 caption, and discussion of observed systems (page 4)",
        "Explanation": "The paper presents the HAT-P-11 system (a perpendicular planet with a known companion) as observational evidence supporting the GR-reduced HEM scenario, plotting it within or near the favorable parameter space in Figure 3. However, calculating $\\epsilon_{\\rm GR}$ for the HAT-P-11 system using the paper's Eq. (2) and its known parameters ($a_{\\rm in} \\approx 0.05$ AU, $m_\\star \\approx 0.8 M_\\odot$, companion $m_{\\rm out} \\approx 2 M_J, a_{\\rm out} \\approx 4$ AU) yields $\\epsilon_{\\rm GR} \\approx 273$. This value is vastly greater than the paper's stated quenching limit of $\\epsilon_{\\rm GR} > 6$ (Section 2). According to the paper's own criteria, Kozai-Lidov oscillations in HAT-P-11b should be completely quenched by GR effects from its companion, preventing HEM. This contradicts the claim that this system supports the proposed mechanism and undermines the observational validation."
      },
      {
        "Problem": "Potential oversimplification by neglecting octupole-level terms for relevant companion parameters",
        "Location": "Section 2 (underlying assumptions for Eq. 1), Section 4 (discussion of outer planet eccentricity)",
        "Explanation": "The analysis primarily relies on quadrupole-level Kozai equations modified by GR (Eq. 1). While octupole effects are briefly discussed in Section 4, they are dismissed as insignificant unless the outer companion's eccentricity $e_{\\rm out}$ is very high or $a_{\\rm in}/a_{\\rm out}$ is very small. However, for 'warm' Jupiters ($a_{\\rm in} \\sim 0.1-0.6$ AU) with some 'common' planetary companions considered (e.g., $a_{\\rm out} \\sim 1-5$ AU, as per Fig. 3), the ratio $a_{\\rm in}/a_{\\rm out}$ can be relatively large (e.g., 0.04 to 0.2 or higher). For these configurations, even moderate companion eccentricities ($e_{\\rm out} \\sim 0.3-0.5$) can lead to non-negligible octupole terms ($\\epsilon_{\\rm oct} \\sim (a_{\\rm in}/a_{\\rm out}) e_{\\rm out} / (1-e_{\\rm out}^2)$ can be $\\sim 0.05-0.15$). Such octupole terms can significantly alter the eccentricity evolution, minimum inclination, and even cause orbital flips, potentially invalidating the quantitative predictions derived from the simpler quadrupole+GR model for a relevant portion of the parameter space explored for warm Jupiters."
      },
      {
        "Problem": "Ambiguous or potentially incorrect statement regarding $i_{\\rm min}$ calculation in population synthesis",
        "Location": "Section 3, paragraph describing population synthesis methodology (page 5)",
        "Explanation": "The paper states: 'We compute the minimum mutual inclination from Eqn. \\ref{eqn:imin} and assume the final mutual inclination equals the minimum mutual inclination.' Equation (4) (referred to as Eqn. \\ref{eqn:imin}) is $\\cos^2 i_{\\rm min} \\approx \\cos^2 i_0 / (1-e_{\\rm max}^2)$. This equation, derived from $L_z$ conservation, relates the initial inclination ($i_0$), minimum inclination ($i_{\\rm min}$), and maximum eccentricity ($e_{\\rm max}$). It does not, by itself, determine $i_{\\rm min}$ when GR effects are significant; $i_{\\rm min}$ in the GR-reduced regime is primarily governed by Eq. (1), which includes $\\epsilon_{\\rm GR}$. While the description of Figure 2 implies a correct combined usage of Eq. (1) and Eq. (4), this specific statement about the population synthesis method is misleading. If Eq. (4) was used in isolation or incorrectly prioritized over Eq. (1) to determine $i_{\\rm min}$ for the population synthesis, the resulting distributions of final inclinations (Fig. 4) could be flawed."
      }
    ],
    "token_usage": {
      "input": 8151,
      "thinking": 16596,
      "output": 1337
    }
  },
  {
    "entry_id": 135,
    "retraction_id": "1705.00151v2",
    "paper_id": "1705.00151v1",
    "retraction_comment": "We apologize that in the results and algorithms of Section 4.1, Proposition 4.1 and Lemma 4.2, there are some missing conditions and assumptions on the hypergraphs. Hence we want to withdraw the manuscript. Moreover, we want to work out more results, and merge this manuscript together to write a publishable paper",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound justification for the collapsing heuristic for embedded homology.",
        "Location": "Proposition 5.3, Lemma 5.4, Algorithm 5 (Section 'Heuristics to compute the embedded homology: collapsing hyperedges', pp. 10-12 of the provided PDF, which corresponds to Section 5.4 in the LaTeX source's apparent section numbering).",
        "Explanation": "The proof of Proposition 5.3, which aims to justify the heuristic in Algorithm 5 (simplifying a hypergraph $\\mathcal{H}$ to $\\mathcal{H}^{d(v)}$ by removing hyperedges containing a vertex $v$), relies on Lemma 5.4. The application of Lemma 5.4 requires a specific homotopy equivalence ($K \\simeq K'$) under certain conditions. The conditions stated in Prop. 5.3 (related to $\text{Lk}_{K_\\mathcal{H}}\\sigma$ for a simplex $\\sigma$) are not sufficient or are mismatched with what would typically be required for such an equivalence (which usually involves the link of the vertex $v$ within $K$). Algorithm 5 itself uses conditions on $\text{Lk}_{K_\\mathcal{H}}v$, which differs from the premise of Prop. 5.3. More fundamentally, even if a homotopy equivalence $K_\\mathcal{H} \\simeq K_{\\mathcal{H}^{d(v)}}$ (for associated simplicial complexes) were established, its extension to an isomorphism of embedded homology groups $H_*(\\mathcal{H}) \\cong H_*(\\mathcal{H}^{d(v)})$ is not made clear by the argument structure involving Lemma 5.4. The lemma's conditions and applicability in this context are not rigorously established, making the soundness of this core heuristic questionable."
      },
      {
        "Problem": "Incorrect claim used to justify torsion bounds for embedded homology.",
        "Location": "Section 'Estimations for the upper bounds of the torsions' (labeled 4.3, likely Section 7, pp. 15-16 of the PDF), specifically the argument for Algorithm 10.",
        "Explanation": "The paper's argument for applying Soulé's torsion bound to the embedded homology $H_n(\\mathcal{H})$ (via $H_n(\\mathcal{H}(n))$ in Algorithm 10) depends on the assertion that the hypergraph $\\mathcal{H}(n) = \\mathcal{H}_n \\cup \\mathcal{H}_{n+1}$ always satisfies condition (6.3), i.e., $\\partial_{n+1}(\\mathbb{Z}((\\mathcal{H}(n))_{n+1})) = \\partial_{n+1}(\\mathbb{Z}((K_{\\mathcal{H}(n)})_{n+1}))$. This claim is false. The set of $(n+1)$-hyperedges of $\\mathcal{H}(n)$, denoted $(\\mathcal{H}(n))_{n+1}$, consists only of actual $(n+1)$-dimensional hyperedges from the original $\\mathcal{H}$. However, $(K_{\\mathcal{H}(n)})_{n+1}$, the set of $(n+1)$-simplices in the associated complex of $\\mathcal{H}(n)$, can include $(n+1)$-dimensional subsets of hyperedges in $\\mathcal{H}(n)$ that have dimension greater than $n+1$. Thus, $\\mathbb{Z}((\\mathcal{H}(n))_{n+1})$ can be a proper subspace of $\\mathbb{Z}((K_{\\mathcal{H}(n)})_{n+1})$, and their images under $\\partial_{n+1}$ may not be equal. This invalidates the direct application of Soulé's bound as argued for embedded homology."
      },
      {
        "Problem": "Non-standard definition of the star of a simplex.",
        "Location": "Section 'Heuristics to compute the embedded homology: collapsing hyperedges' (p. 10 of the PDF, Section 5.4).",
        "Explanation": "The paper defines the star of a simplex $\\sigma$ in a simplicial complex $K$ as $\text{St}_K\\sigma = \\{\tau \\in K \\mid \tau \\cup \\sigma \text{ is a simplex of } K\\}$. This definition is non-standard; the standard definition of a closed star typically involves all simplices in $K$ that have $\\sigma$ as a face (and their faces). While the paper uses this definition consistently with its definition of a link, relying on this non-standard definition of a star without deriving its properties, and potentially applying results or intuitions from literature (e.g., [BM]) that use standard definitions, can lead to incorrect conclusions. This is particularly relevant for arguments about collapsibility or other topological properties used in heuristics like Proposition 5.3, potentially compounding the issues with its justification."
      }
    ],
    "token_usage": {
      "input": 32306,
      "thinking": 21474,
      "output": 1046
    }
  },
  {
    "entry_id": 136,
    "retraction_id": "1701.02653v2",
    "paper_id": "1701.02653v1",
    "retraction_comment": "This paper has been withdrawn to an error in Proposition 8 when moving from the quenched to the annealed measure. Thus, it is not a straightforward adaptation of the theorem cited",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The bound $\\E[N_s^\\gamma(v) \\mid \\gamma] \\leq 1$ (and similarly $\\E[N_{s^-}^\\gamma(X_s) \\mid \\gamma] \\leq 1$) used in the proof of Proposition 9 is incorrect.",
        "Location": "Proof of Proposition 9 (stated as Proposition on page 5, thlabel lem:clusbnd), pages 5-6",
        "Explanation": "The quantity $N_s^\\gamma(v)$ is the number of particles at site $v$ (where $v \\neq X_s$) at time $s$ in the $\\xi(\\gamma)$ process. These particles originate from all sites $y \\in V \\setminus \\{\\rho\\}$ at time $0$. Thus, $N_s^\\gamma(v) = \\sum_{y \\in V \\setminus \\{\\rho\\}} \\mathbf{1}(\\xi_s^y(\\gamma)=v)$. Its expectation, $\\E[N_s^\\gamma(v) \\mid \\gamma] = \\sum_{y \\in V \\setminus \\{\\rho\\}} \\P(\\xi_s^y(\\gamma)=v \\mid \\gamma)$, can be much larger than 1. The paper's justification for the bound $\\E[N_s^\\gamma(v) \\mid \\gamma] \\leq 1$ is via a voter model duality, claiming $\\E[N_s^{\\gamma}(v) \\mid \\gamma] = \\E[|\\zeta_s|]$ where $\\zeta_0 = \\{v\\}$ (so $|\\zeta_0|=1$) and then arguing $|\\zeta_r|$ is a supermartingale. This voter model argument for $|\\zeta_s|$ with $|\\zeta_0|=1$ would correspond to the expected number of ancestors of a single particle, not the sum over all possible starting particles. This incorrect bound invalidates the central inequality $\\Eu_\\rho^G[ |\\zeta_t^{(\\rho)}| ] \\leq 1 + 2\\int_0^t \\Eu_\\rho^G[\\deg(X_s)]ds$ in Proposition 9, which is crucial for the main theorem."
      },
      {
        "Problem": "The proof of Theorem 3 establishes $\\Eo[\\int_0^\\infty \\Pu_\\rho^G(O_t(\\rho)) dt] = \\infty$, which is insufficient to conclude site recurrence for $\\Po$-almost every $(G,\\rho)$.",
        "Location": "Proof of Theorem 3 (page 7) and its reliance on Proposition 7 (page 4)",
        "Explanation": "Proposition 7 states that Theorem 3 holds if $\\int_0^\\infty p_t dt = \\infty$, where $p_t = \\P(O_t(\\rho)) = \\Eo[\\Pu_\\rho^G(O_t(\\rho))]$ is the probability that the root $\\rho$ is occupied by a particle in CRW at time $t$. The proof of Theorem 3 demonstrates that this condition holds. However, Proposition 7 refers to a result from [crw] (Proposition 1.1) which states that for a *fixed* graph, CRW is site recurrent if and only if $\\int_0^\\infty \\Pu_x^G(x \\text{ is occupied at time } t) dt = \\infty$ for some/all $x$. To prove site recurrence for $\\Po$-almost every realization of $(G,\\rho)$, one needs to show that $\\int_0^\\infty \\Pu_\\rho^G(O_t(\\rho)) dt = \\infty$ for $\\Po$-almost every $(G,\\rho)$. The current argument only shows that the *expectation* (over $(G,\\rho)$) of this integral is infinite. This does not preclude the possibility that the integral is finite for a set of $(G,\\rho)$ with positive $\\Po$-measure. The derivation of the bound on $p_t$ involves averaging $\\deg(X_s)$ over $(G,\\rho)$ (using Lemma 8), rather than establishing a per-graph bound that ensures the integral diverges for almost every graph."
      }
    ],
    "token_usage": {
      "input": 7986,
      "thinking": 22551,
      "output": 957
    }
  },
  {
    "entry_id": 137,
    "retraction_id": "2011.07585v2",
    "paper_id": "2011.07585v1",
    "retraction_comment": "The article contains wrong idea. There was mistake in the H3 assumption",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of $\\delta_k$ in Lemma 2, impacting the Catalyst framework's applicability.",
        "Location": "Section 2, Lemma 2, page 3 (and its use in Appendix 4.1, page 9)",
        "Explanation": "Lemma 2 claims $\\delta_k = (1 + \\frac{L}{\\mu + \\kappa})\\varepsilon_{k - 1}$. This derivation relies on the assumption $f(x_{k-1}) - f^{\\star} \\leq \\frac{L}{\\mu + \\kappa} \\mathbb{E}[H_{k-1}(x_{k-1}) - H_{k-1}^{\\star}] \\leq \\frac{L}{\\mu + \\kappa} \\varepsilon_{k-1}$. This inequality is not generally true, as $f(x_{k-1}) - f^{\\star}$ can be much larger than $\\varepsilon_{k-1}$ (the accuracy of the previous subproblem). The correct definition for $\\delta_k$ based on the paper's setup should be $\\delta_k = \\varepsilon_k + \\mathbb{E}[f(x_{k-1}) - f^{\\star}]$. Using the paper's flawed $\\delta_k$ in the Catalyst convergence (Eq. \\eqref{eq:Alg_convergence}) makes the analysis of the sum $\\sum (1-\\sqrt{q})^{-j} \\delta_j$ and the overall outer loop convergence rate unsound."
      },
      {
        "Problem": "The heterogeneity term $\\bar{\\zeta}_H^2$ for the subproblems in the decentralized setting is not properly analyzed.",
        "Location": "Section 3.3, \"Ускорение\", page 6",
        "Explanation": "When applying DSGD to the auxiliary function $H_k(x)$ (or rather, $\\tilde{H}_k(X)$), the corresponding heterogeneity term $\\bar{\\zeta}_H^2 = \\frac{1}{n}\\sum \\|\\nabla f_i(x_H^{\\star}) - \\nabla f(x_H^{\\star}) + \\kappa(\\bar{y}^{k-1} - y_i^{k-1}) \\|^2$ depends on the consensus error of $y_i^{k-1}$, i.e., $\\|\\bar{y}^{k-1} - y_i^{k-1}\\|^2$. The iterates $Y_k$ (which define $y_i^k$) are updated based on $X_k^{\\star}$ and $X_k$. If $X_k^{\\star}$ is $\\overline{X}_{k-1}$ (where $\\overline{x}_{k-1}$ is the average of non-consensual $x_i^{k-1}$ from the previous step) or if $X_k$ is not perfectly consensual, $Y_k$ may not be consensual. A large consensus error in $Y_{k-1}$ could make $\\bar{\\zeta}_H^2$ significantly larger than $\\bar{\\zeta}^2$ (the term for the original function $f$), potentially negating the benefits of acceleration. The paper implicitly assumes $\\bar{\\zeta}_H^2 \\approx \\bar{\\zeta}^2$ without justification."
      },
      {
        "Problem": "Miscalculation of coefficients in the final claimed complexity for accelerated DSGD.",
        "Location": "Section 3.3, Equation \\eqref{eq:Alg2_convergence_2}, page 7",
        "Explanation": "The coefficient of the second term in the main result, Eq. \\eqref{eq:Alg2_convergence_2}, specifically the powers of $L$ and $\\mu$, appears incorrect. The paper states this part of the term as $\\frac{L^{\\frac{1}{4}}(\\bar{\\zeta} \\tau+\\bar{\\sigma} \\sqrt{p \\tau})}{\\mu^{\\frac{3}{4}}p \\sqrt{ \\varepsilon}}$. However, a careful derivation based on substituting $L_H = 2L-\\mu$, $\\mu_H = L$, and $q=\\mu/L$ into the expression $\\frac{\\sqrt{L_H}(\\dots)}{\\mu_H p q^{1/4} \\sqrt{\\varepsilon}}$ (derived from the sum $\\sum 1/\\sqrt{\\varepsilon_k}$ and DSGD complexity for $H_k$) yields $\\frac{\\sqrt{2L-\\mu} L^{1/4}}{L p \\mu^{1/4} \\sqrt{\\varepsilon}} = \\frac{\\sqrt{2L-\\mu}}{L^{3/4} p \\mu^{1/4} \\sqrt{\\varepsilon}}$. This has different powers for $L$ and $\\mu$ ($L^{-3/4} \\mu^{-1/4}$ vs paper's $L^{1/4} \\mu^{-3/4}$), significantly altering the interpretation of the acceleration achieved for this term."
      },
      {
        "Problem": "Underestimation of the number of inner loop iterations ($t_k$) by neglecting logarithmic factors.",
        "Location": "Appendix 4.1 (page 9-10) and Appendix 4.3 (page 11)",
        "Explanation": "The analysis of the number of inner loop iterations $t_k$ (for both the generic method M and DSGD) claims that $t_k$ is effectively constant (e.g., $\\tilde{O}(1/a)$ or $\\tilde{O}(1/(a_h \\eta_k))$) by absorbing a logarithmic term $\\log((H_k(x_{start}) - H_k^{\\star}) / \\varepsilon_k)$ into $\\tilde{O}$. However, as the target accuracy $\\varepsilon_k$ for the subproblem $H_k$ decreases with outer iterations $k$ (e.g., $\\varepsilon_k \\sim (1-\\rho)^k$), the term $\\log(1/\\varepsilon_k)$ grows linearly with $k$. This implies $t_k$ should grow with $k$. Ignoring this growth leads to an underestimation of the total complexity. The assumption that $H_k(x_{start}) - H_k^{\\star}$ decreases exactly as fast as $\\varepsilon_k$ to keep the log-term constant is not rigorously justified (e.g. the bound $H_k(x_{k-1})-H_k^{\\star} \\le (S+1)\\varepsilon_{k-2}$ in App 4.1 and 4.3)."
      }
    ],
    "token_usage": {
      "input": 13754,
      "thinking": 17281,
      "output": 1492
    }
  },
  {
    "entry_id": 138,
    "retraction_id": "1803.09392v2",
    "paper_id": "1803.09392v1",
    "retraction_comment": "This paper is withdrawn as the proof of Lemma 2.4 is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misapplication of Chinburg-Kim formula for Ω(N/F,2)",
        "Location": "Proposition 2.4 and its citation of Kim [K91]; Section 3, proof of Theorem 1.5",
        "Explanation": "Proposition 2.4 presents a formula for Chinburg's invariant Ω(N/F,2). However, the module ℒ, central to this formula, is defined in this paper based on 𝒜_{N/F} = α · A_{N/F}, whereas the original Chinburg-Kim formula (e.g., Kim [K91], Prop 2.4) uses a module ℒ constructed from O_N. Chinburg's invariant Ω(N/F,2) is intrinsically defined relative to O_N. Altering the foundational module for ℒ (and consequently for related terms like Ω_v and Ũ_v(1)) from O_N to 𝒜_{N/F} would typically yield a different invariant or would require a rigorous proof that the formula still computes the original Ω(N/F,2). The paper's assertion that the proof of this modified formula is 'identical' to Kim's original proof is insufficient to bridge this gap. This directly undermines the derivation in Section 3 that Ω(N/F,2) = (ℒ) = (α · A_{N/F}) for tame extensions."
      },
      {
        "Problem": "Unjustified equality of classes (α · A_{N/F}) and (A_{N/F})",
        "Location": "Section 3, final step in the proof of Theorem 1.5",
        "Explanation": "In Section 3, the argument, if Proposition 2.4 were to hold as stated with the paper's ℒ, would lead to the conclusion Ω(N/F,2) = (α · A_{N/F}) in Cl(ℤG) for tame extensions (where ℒ = α · A_{N/F}). The paper then states the main result, Theorem 1.5, as Ω(N/F,2) = (A_{N/F}). This implicitly assumes that the class (α · A_{N/F}) is equal to (A_{N/F}) in Cl(ℤG). However, α is an integer in O_F chosen such that α · A_{N/F} ⊆ O_N. For many such choices of α (e.g., if α is not a unit in ℤ or its action does not preserve the isomorphism class), the ℤG-modules α · A_{N/F} and A_{N/F} are not necessarily isomorphic, nor are their classes in Cl(ℤG) necessarily equal. This step is not justified."
      }
    ],
    "token_usage": {
      "input": 8305,
      "thinking": 19864,
      "output": 817
    }
  },
  {
    "entry_id": 139,
    "retraction_id": "1709.04340v2",
    "paper_id": "1709.04340v1",
    "retraction_comment": "A problem with the proofs of Propositions 2 and 3 (a gap or fault in the reasoning used to claim that the expression in (3.9) is dominated by that in (3.11)); a similar problem with the proof of Proposition $1'$ (it is hard to justify the particular application of the Bourgain-Guth reduction theory implicit in a paragraph above Proposition $1'$). Theorems 1, 2 and 3 lose their status as theorems",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Discrepancy in the derivation of estimate (5.23)",
        "Location": "Section 5, equation (5.23), page 7",
        "Explanation": "The derivation of the bound (5.23) for the sum S, when p=4, appears to have incorrect powers for H, N, and R. My recalculation, assuming the provided estimate for A_4 (from '[H03, Lemma 3.1]') is $A_4 \\ll H^6 N^4 Q^4 (\\log N) R^{-14}$, yields $S \\ll (\\log H)^2 (\\log N)^{9/4} M H^{11/6} R^{-5/3} Q^{-1/2} (1+Q/Q_3)^{1/4}$. The paper's (5.23) is $S \\ll (\\log H)^2 (\\log N)^{9/4} M (H/N)^{1/2} (R/Q)^{1/2} (H/R)^{1/3} (1+Q/Q_3)^{1/4}$, which is $M H^{5/6} N^{-1/2} R^{1/6} Q^{-1/2}$. The powers of H (11/6 vs 5/6), R (-5/3 vs 1/6), and N (0 vs -1/2) are substantially different. This discrepancy would make the paper's bound (5.23) significantly stronger than my derived bound. If (5.23) is incorrect, the definition of $Q_5$ (derived from comparing (5.22) and (5.23)) would change, potentially invalidating the subsequent argument that restricts $Q < Q_5$ and affecting the final bounds in Theorem 3, and consequently Theorem 2."
      },
      {
        "Problem": "The $A_4$ estimate used in the derivation of (5.23) is not standard or its origin is unclear.",
        "Location": "Section 5, page 7, derivation of (5.23)",
        "Explanation": "The estimate for $A_4$ stated in the derivation of (5.23) is $A_4 \\ll H^6 N^4 Q^4 (\\log N) R^{-14}$. This is attributed to '[H03, Lemma 3.1]'. However, Lemma 3.1 in Huxley's 2003 paper provides a bound for a sum of fourth powers of single sums, and its form $S_4 \\ll (M_0 N_0)^2 (1 + K^2 L X_0^2 / N_0)^{-1/2} \\log N_0$ does not directly translate to the $A_4$ used here, which is an integral of a fourth power of a double sum. The specific form $H^6 N^4 Q^4 (\\log N) R^{-14}$ is unusual (e.g. high powers of H and N). If this $A_4$ estimate is incorrect or misapplied, the bound (5.23) would be affected, which is critical as noted in the first problem."
      },
      {
        "Problem": "Potentially incorrect comparison of bounds leading to the definition of $Q_5$.",
        "Location": "Section 5, page 7, paragraph after (5.24)",
        "Explanation": "The paper states that the bound (5.24) (which is (5.23) evaluated at $Q=Q_5$) 'is stronger, by a factor $\\gg (\\log N)^{3/4}$, than the very best that (5.22) can lead to if $Q=R$'. My check suggests that (5.24) using the paper's (5.23) is actually stronger by $(\\log N)^{11/4}$ (since $(\\log N)^{9/4}$ vs $(\\log N)^5$). While the direction (stronger) is the same, the factor is different. More importantly, this comparison relies on the correctness of (5.23)/(5.24). If (5.23) is actually weaker (as per Problem 1), then this comparison and the subsequent logic for choosing $Q_5$ and partitioning the range of $Q$ would need re-evaluation."
      },
      {
        "Problem": "Calculation of exponents $\\alpha_1, \\alpha_2$ for $\\nu=6$ in Section 7.",
        "Location": "Section 7, page 11, paragraph starting 'We shall utilise only two cases...'",
        "Explanation": "For $\\nu=6$, the paper states $q=q_6=84/19$ and $\\alpha_2/\\alpha_1 = 247/792$. My calculation yields $\\alpha_1 = 33/350$ and $\\alpha_2 = -5491/8400$. This means $\\alpha_1 > 0$ and $\\alpha_2 < 0$. The ratio $\\alpha_2/\\alpha_1$ is negative. The paper correctly notes that the term $(H/M)^{\\alpha_1}T^{\\alpha_2}$ is $O(1)$ under these conditions. However, the specific positive value $247/792$ mentioned for $\\alpha_2/\\alpha_1$ actually corresponds to the ratio for the term $(H/M)^{99/25}T^{247/200}$, not $(H/M)^{\\alpha_1}T^{\\alpha_2}$. This is a minor confusion in presentation but doesn't seem to affect the argument that the term is $O(1)$."
      },
      {
        "Problem": "Discrepancy in exponents in the derivation of the second line of (8.7).",
        "Location": "Section 8, equation (8.7), page 14",
        "Explanation": "The transformation from the first line of (8.7) to the second line is $S^*/M \\ll B_T + A_1 B_T + A_2 B_T$, where $B_T, A_1 B_T, A_2 B_T$ are the three terms implied by expanding $(1+A_1+A_2)B_T$. The paper writes the second line as $B_T + (1 + A_1/A_2) A_2 B_T$. My check confirms that $A_1/A_2 = (M/H)^{58/255} T^{-149/2040}$. The term $A_2 B_T$ has $(H/M)^{951/850} T^{7159/20400 + 1.01\\epsilon}$. This part is correct. The issue was my initial misinterpretation of how the terms were combined. The paper's combination is arithmetically sound: $B_T + (1+A_1/A_2)A_2B_T = B_T + A_2B_T + A_1B_T$. This point is therefore not an error."
      }
    ],
    "token_usage": {
      "input": 34028,
      "thinking": 27499,
      "output": 1645
    }
  },
  {
    "entry_id": 140,
    "retraction_id": "1106.5292v3",
    "paper_id": "1106.5292v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The central claim of mathematical inequivalence of equations of motion (EoMs) appears to be based on a misunderstanding of how EoMs relate under field redefinitions.",
        "Location": "Section 3.3, specifically the comparison between Eq. (17) and Eq. (21), and the statement that their difference is 'independent of (J2)'.",
        "Explanation": "The paper correctly shows that the Einstein frame action $S_E[g]$ and the Jordan frame action $S_J[\\bar{g}, \\phi]$ (Eq. 9) differ by a boundary term. Standard field theory dictates that if two actions are related this way, their respective Euler-Lagrange equations must be equivalent. This means that the set of equations derived from $S_E$ (i.e., Eq. (21) and its trace) must be equivalent to the set derived from $S_J$ (i.e., Eq. (17) and Eq. (18)). The authors state that the trace of Eq. (21) is proportional to Eq. (18) (the scalar field EoM). Therefore, Eq. (21) (the transformed Einstein metric EoM) must be equivalent to Eq. (17) (the Jordan frame metric EoM) once Eq. (18) is taken into account. That is, the difference between the LHS of Eq. (21) and Eq. (17) should be proportional to the LHS of Eq. (18) (possibly involving derivatives or multiplication by field-dependent tensors). The paper's assertion that this difference is 'independent' of Eq. (18) is a strong claim that contradicts established understanding and, if incorrect, invalidates the paper's main conclusion. The likely scenario is that the EoMs are equivalent, and the apparent difference vanishes when the scalar field EoM (Eq. 18) is imposed."
      },
      {
        "Problem": "The argument in Section 4.1, drawing an analogy with Yang-Mills gauge fixing, is based on an incorrect premise about the conformal invariance of the Jordan frame action $S_J$.",
        "Location": "Section 4.1, page 4, the statement: 'It is well known [...] that the Jordan frame action $S_J[\\bar g_{ab}, \\phi]$ is invariant under conformal transformations of the fields, $\\bar g_{ab}\\rightarrow \\Omega^{2} \\bar g_{ab}, \\phi \\rightarrow \\Omega^{-\\Delta}\\phi, \\Delta=(n-2)/2$.'",
        "Explanation": "The specific Jordan frame action $S_J$ given in Eq. (10) is a general scalar-tensor theory action. It is not, in general, invariant under the stated conformal transformations of $\\bar{g}_{ab}$ and $\\phi$. For $S_J$ to be conformally invariant, its terms (e.g., $\\phi^2 \\bar{R}$, $(\\nabla\\phi)^2$, and the potential term) would need to combine in a very specific way that is not apparent for the general form in Eq. (10). Since the premise of conformal invariance of $S_J$ is likely false, the subsequent analogy to Yang-Mills theory, where the action *is* gauge invariant and the Einstein frame is treated as a 'gauge-fixed' version, is unsound."
      },
      {
        "Problem": "The argument regarding total divergence terms in Section 4.2 is potentially misleading.",
        "Location": "Section 4.2, page 5, statement: 'The total divergence in Einstein frame needs not be a total divergence in Jordan frame'.",
        "Explanation": "A total divergence term in an action, such as $\\int d^n x \\sqrt{-g} \\nabla^{(g)}_c V^c$, can be rewritten as $\\int d^n x \\partial_c (\\sqrt{-g} V^c)$. When changing field variables from $g$ to $(\\bar{g}, \\phi)$, this expression becomes $\\int d^n x \\partial_c (\\sqrt{-\\bar{g}} e^{n\\Phi/2} V^c_g(\\bar{g},\\phi))$. This is still manifestly a total divergence (a boundary term). While the choice of boundary counter-terms (like the Gibbons-Hawking-York term) is crucial for a well-posed variational principle with fixed boundary data, it does not alter the bulk equations of motion derived assuming variations vanish at the boundary. If two actions differ by a boundary term (as $S_E$ and $S_J$ do, per Eq. 9), their bulk EoMs are equivalent. The argument that $\\delta_1 S_E$ (Eq. 13) 'will not completely drop off' when changing frames seems incorrect if standard boundary conditions for variation are assumed."
      }
    ],
    "token_usage": {
      "input": 8351,
      "thinking": 20330,
      "output": 1073
    }
  },
  {
    "entry_id": 141,
    "retraction_id": "1903.00526v2",
    "paper_id": "1903.00526v1",
    "retraction_comment": "An error occurs in Section 5. Post-measurement results in the RTO experiment are improperlystated to directly apply to the entangled measurement state itself. This puts the conclusions stated in the abstract into question",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental Misinterpretation of Product States",
        "Location": "Abstract; Page 1, Introduction (e.g., paragraph 4); Page 5, first paragraph.",
        "Explanation": "The proposed interpretation of a product state |A1>|B1> as 'A has property |A1> if and only if B has property |B1>' is inconsistent with the established definition and role of product states in quantum mechanics. Product states like |A>|B> describe statistically independent (uncorrelated) subsystems, where subsystem A is in state |A> and subsystem B is in state |B> independently. The 'if and only if' (iff) construction imposes a strict, inherent correlation between the properties of A and B, which is characteristic of entangled states, not product states. This redefinition alters the fundamental meaning of how states of composite systems are constructed."
      },
      {
        "Problem": "Flawed Justification for Reinterpreting Product States from Entangled State Behavior",
        "Location": "Page 4, discussion of RTO experiment and Table 1; Page 5, first paragraph.",
        "Explanation": "The paper argues that the behavior of subsystems in entangled states (e.g., in RTO experiments, individual photons are in mixed states while their joint correlations show interference) necessitates a reinterpretation of product state terms like |A1>|B1> as correlations themselves ('A1 iff B1'). This justification is logically flawed. Standard quantum mechanics already explains these phenomena without redefining product states; the entanglement and its observable consequences arise from the superposition of product states (as conventionally understood), not from an inherent correlational meaning within each product state term."
      },
      {
        "Problem": "Failure to Resolve the Measurement Problem Regarding Outcome Selection",
        "Location": "Abstract; Page 1, last paragraph; Page 5, first paragraph; Page 7, Conclusion.",
        "Explanation": "The paper claims its reinterpretation of product states resolves the problem of definite outcomes and the measurement problem. However, it fails to adequately explain the crucial step of how a single, specific measurement outcome is actualized from a superposition. Interpreting an entangled state like (|A1>|B1> + |A2>|B2>)/√2 as a superposition of 'correlations' (e.g., 'A1 iff B1' and 'A2 iff B2') does not inherently make the overall state 'definite' nor does it provide a mechanism for why one specific correlation (and thus one specific pair of outcomes like A1, B1) is realized upon measurement over the other. The core issue of outcome selection remains unaddressed."
      },
      {
        "Problem": "Mischaracterization of the Standard Interpretation of Entangled States",
        "Location": "Page 1, paragraph 3; Page 4, paragraph starting 'The conventional physical interpretation...'.",
        "Explanation": "The paper misrepresents the standard interpretation of entangled states, creating a strawman argument. It claims the conventional interpretation of an entangled state like (|A1>|B1> + |A2>|B2>)/√2 means 'A and B have properties |A1> and |B1> respectively AND they also have properties |A2> and |B2> respectively.' This is incorrect. Standard quantum mechanics describes this as a superposition of possibilities, where subsystems A and B do not possess definite properties corresponding to these terms simultaneously before measurement. This mischaracterization incorrectly motivates the need for the proposed new interpretation of product states."
      },
      {
        "Problem": "The Reinterpretation Does Not Remove the Paradox of Macroscopic Superpositions",
        "Location": "Page 1, paragraph 3; Page 5, paragraph 1; Page 7, Conclusion.",
        "Explanation": "The paper asserts that its reinterpretation renders the entangled measurement state (which can involve macroscopic detectors) 'non-paradoxical.' However, rewriting an entangled state like (|A_micro>|B_macro1> + |A_micro'>|B_macro2>)/√2 as a superposition of correlations (e.g., 'A_micro iff B_macro1' and 'A_micro' iff B_macro2') does not eliminate the core conceptual difficulty of macroscopic superpositions. The detector (B) is still described as being part of a quantum superposition involving its macroscopically distinct states (|B_macro1> and |B_macro2>). The 'iff' linkage does not alter the fact that the detector's state is not a single, definite macroscopic state prior to the selection of one outcome, which is central to the paradox."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 9282,
      "output": 1004
    }
  },
  {
    "entry_id": 142,
    "retraction_id": "1503.07411v2",
    "paper_id": "1503.07411v1",
    "retraction_comment": "This paper has been withdrawn due to a gap in the proof of Proposition 2.19",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect reasoning for $n \\ge 1$ in Lemma 3.3.",
        "Location": "Page 9, Proof of Lemma 3.3",
        "Explanation": "The proof states that $X_0/\\mbP^1$ is not a del Pezzo fibration because $\\pi$ is not an extremal contraction. However, for $X_0 = \\mbP^1 \\times S$ (where $S$ is a dP2 surface), the projection $\\pi: X_0 \\to \\mbP^1$ is an extremal contraction and $X_0/\\mbP^1$ is a Mori fiber space. The actual reason $n=0$ (and $n=1$) are often excluded in rigidity studies is that $X_0$ and $X_1$ are known to be rational and therefore not birationally rigid in the typical sense."
      },
      {
        "Problem": "The calculation of an intersection number in the proof of Lemma 3.5 is unsubstantiated and likely incorrect.",
        "Location": "Page 10, Proof of Lemma 3.5",
        "Explanation": "The proof states $(-K_Y \\cdot \\tilde{S}_{\\lambda} \\cdot \\tilde{F}_i) = (-\\varphi^*K_X - \\frac{1}{2} E)^2 (\\varphi^*F - 2 E) = 2 - \\frac{2}{4} \\times 4 = 0$. There are several issues here: \n1. The divisor $\\tilde{S}_{\\lambda}$ (strict transform of $S_\\lambda \\in |H|$) is $\\varphi^*H - m_E(H)E$, not $(-\\varphi^*K_X - \\frac{1}{2} E)$. Since $H \\sim -K_X + (n-2)F$, these are different unless $n=2$ and $m_E(H)$ corresponds to $m_E(-K_X)$.\n2. The multiplicity $m_E(F_i)$ (where $\\tilde{F}_i = \\varphi^*F_i - m_E(F_i)E$) is claimed to be 2 (from $\\varphi^*F - 2E$). For a terminal $\\frac{1}{2}(1,1,1)$ singularity and a Cartier divisor $F_i$ passing through it transversely, one would typically expect $m_E(F_i)=1$. If $m_E(F_i)=2$ holds, it needs justification from the specific geometry.\n3. The numerical calculation $2 - \\frac{2}{4} \\times 4 = 0$ is not derived. A direct calculation using standard intersection theory for blow-ups suggests a non-zero result (e.g., $2+m_E(F_i)/8$ under certain assumptions if $\\tilde{S}_{\\lambda}$ was correctly used). If this intersection number is not zero (or not $\\le 0$), Lemma 2.19 cannot be applied to exclude singular points as weak maximal centers, which is critical for applying Theorem 1.1."
      },
      {
        "Problem": "Contradictory statements regarding the definition of singular points $\\msp_i$ and properties of $f$. (Resolved during analysis but initially a major confusion point)",
        "Location": "Page 8, definitions around Condition 3.1",
        "Explanation": "Initially, it appeared there was a contradiction: $\\msp_i$ are defined as $(x_0=x_1=x_2=0)$ on fibers $F_i$ where $a=0$. For $\\msp_i$ to be on $X_n$, $f(x_0,x_1,x_2)$ must be zero at these $x_j$ values. If $f$ is homogeneous in $x_j$ of degree 4, then $f(0,0,0)=0$ is always true. The fiber $F_i$ (where $a=0$) is $f(x_0,x_1,x_2)=0$ in $\\mbP(1,1,1,2)$. This is a cone over the plane curve $C_f=V(f)\\subset\\mbP^2$, with vertex $P_y=(0:0:0:1)$. So $\\msp_i=P_y$. Condition 3.1(2) states $C_f$ is nonsingular. This setup is consistent. The initial confusion arose from interpreting $f(0,0,0)=0$ for a plane curve. This is not a critical error in the paper but highlights a point that could be clarified for readability."
      }
    ],
    "token_usage": {
      "input": 25934,
      "thinking": 34752,
      "output": 1063
    }
  },
  {
    "entry_id": 143,
    "retraction_id": "1602.03949v2",
    "paper_id": "1602.03949v1",
    "retraction_comment": "This paper has been withdrawn by the author due to the different description of second-order correlation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially Invalid SNR Metric due to Lack of Output Image Normalization",
        "Location": "Equation (1), Section 2 (page 1), Fig. 2, Fig. 3",
        "Explanation": "The SNR definition (Eq. 1) calculates error between the reconstructed image O(x,y) and the binary object pattern S(x,y). Ghost imaging reconstructions O(x,y) are typically correlation values whose scale, offset, and range (e.g., potentially including negative values) are not inherently matched to the binary [0,1] range of S(x,y). The paper does not specify any normalization or scaling of O(x,y) prior to SNR calculation. This mismatch can lead to arbitrary or misleading SNR values, as the error term (S(x,y) - O(x,y))^2 would be highly dependent on this scaling. This could invalidate all reported quantitative SNR results, comparisons between filter performances, and the primary conclusions drawn from them."
      },
      {
        "Problem": "Unaddressed Background Noise in the Reference Arm",
        "Location": "Fig. 1 (Experimental setup), Section 1 (page 1, rationale for single-arm filtering), Section 2 (page 1, setup description)",
        "Explanation": "The experimental setup indicates that broadband background light is mixed with the signal light before the beamsplitter (BS1) and thus contaminates both the object arm and the reference (idler) arm. While the object arm (leading to the bucket detector) is filtered, the reference arm (providing spatial patterns for correlation) is not. Significant, unfiltered background noise in the reference arm will degrade the quality of the reference patterns I_R(x,y). Since ghost imaging relies on the correlation between the bucket signal and these reference patterns, noise in I_R(x,y) will inherently limit the achievable SNR of the reconstructed image, potentially undermining the claimed effectiveness and upper limit of SNR improvement attributed solely to filtering the object arm."
      },
      {
        "Problem": "Ambiguity and Questionable Validity of Direct Imaging SNR Assessment",
        "Location": "Fig. 3, discussion on page 2",
        "Explanation": "The paper claims that filtering has an 'insignificant and irregular' effect on direct imaging SNR (Fig. 3), which shows consistently high SNR values. Firstly, if Equation (1) is used for direct imaging SNR, it suffers from the same potential normalization flaw as Problem 1. Secondly, the 'irregular' behavior is unexplained and could indicate measurement instability or an inappropriate metric. Thirdly, if direct imaging SNR is indeed very high and largely unaffected by the background that filters target, it might imply that the simulated background conditions are not sufficiently challenging to robustly demonstrate GI's advantages or the benefits of filtering, or that the SNR metric is insensitive to the specific noise characteristics. This makes it difficult to properly contextualize the improvements seen in GI."
      },
      {
        "Problem": "Unclear Control and Impact of Iris in Reference Arm",
        "Location": "Fig. 1 (Experimental setup), Section 2 (page 1, sentence 'Adjusting the iris...')",
        "Explanation": "An iris is shown in the reference arm path in Fig. 1, and the text states it is used for controlling the 'portion of background light getting to the camera'. It is not specified whether the iris setting is kept constant across all experiments (with different filters in the object arm) or if it is adjusted. If adjusted (e.g., to maintain a certain light level or signal-to-background ratio in the reference arm), this introduces a confounding variable that is not discussed and could significantly affect the correlations and thus the GI results. If it is fixed, its specific setting and its effect on the reference arm's signal and background levels are not detailed, making it hard to assess the reference arm's quality and its impact on the overall GI performance, especially in relation to Problem 2."
      }
    ],
    "token_usage": {
      "input": 640,
      "thinking": 7965,
      "output": 860
    }
  },
  {
    "entry_id": 144,
    "retraction_id": "2203.01307v2",
    "paper_id": "2203.01307v1",
    "retraction_comment": "Lemma 2.1 is true for Heisenberg type groups, but in general not for M_tivier groups, cf. Eq. (2.4) of M_ller and Stein [MS94]",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect claim about operators $H^\\mu$ and $L_0^{|\\mu|}$ coinciding on radial functions, leading to misapplication of sub-elliptic estimate.",
        "Location": "Section 5, Proof of Proposition 5.1, paragraph after eq. (5.2)",
        "Explanation": "The proof of the weighted Plancherel estimate (Proposition 5.1) relies on the sub-elliptic estimate (5.2) for the Hermite operator $H^\\mu = -\\Delta_z + |z|^2|\\mu|^2$. The paper then claims that $H^\\mu \\varphi_k^{|\\mu|} = [k]|\\mu| \\varphi_k^{|\\mu|}$. The justification given in parentheses is: \"Alternatively, one might use (2.8) by exploiting the fact that $\\varphi_k^{|\\mu|}$ is radial-symmetric [...] and that the operators $H^\\mu$ and $L_0^{|\\mu|}$ coincide on such functions.\" However, $L_0^{|\\mu|}$ on radial functions is $-\\Delta_z + \\frac{|\\mu|^2}{4}|z|^2$, while $H^\\mu = -\\Delta_z + |\\mu|^2|z|^2$. These operators do not coincide; their potential terms differ by a factor of 4. Since $\\varphi_k^{|\\mu|}$ are eigenfunctions of $L_0^{|\\mu|}$ (with eigenvalue $[k]|\\mu|$ when restricted to radial functions), they are not eigenfunctions of $H^\\mu$ with the same eigenvalue. This invalidates the step where $(H^\\mu)^{\\alpha/2}$ acting on $\\sum F_\\ell \\varphi_k^{|\\mu|}$ is replaced by $\\sum F_\\ell ([k]|\\mu|)^{\\alpha/2} \\varphi_k^{|\\mu|}$ in eq. (5.3) (implicit step to get to (5.4)). This is a critical step for the weighted Plancherel estimate, which is essential for controlling kernel localizations in the main proof (Section 6, Step 4)."
      },
      {
        "Problem": "Potentially insufficient justification for an $L^2$-norm estimate in the main proof.",
        "Location": "Section 6, Proof of Proposition, Step (4), derivation of eq. (6.6)",
        "Explanation": "In estimating $\\norm{g_{\\le \\iota}^{(2)}}_2$, the paper uses the triangle inequality $\\norm{g_{\\le \\iota}^{(2)}}_2 \\le \\sum_{\\ell=-1}^\\iota \\sum_{m=1}^{M_{\\ell}} \\Vert g_{m}^{(\\ell)}\\Vert_2$ (eq. (6.5) refers to $g_m^{(\\ell)}$ not $(1-\\chi_m^{(\\ell)})g_m^{(\\ell)}$ but the context implies the latter). The functions $g_m^{(\\ell)}$ (or $(1-\\chi_m^{(\\ell)})g_m^{(\\ell)}$) may not have disjoint supports or be orthogonal, making the direct sum of norms an upper bound that might be too large. Subsequently, the estimate $\\norm{g_{\\le \\iota}^{(2)}}_2 \\lesssim 2^{\\iota(1+\\tilde\\delta+d_1/2)} \\norm{F^{(\\iota)}}_2 \\norm{f}_2$ (eq. (6.6)) is derived using $(\\iota+2)M_\\ell^{1/2}$, where $M_\\ell$ depends on $\\ell$. The argument seems to replace $M_\\ell$ with its maximum value (e.g., $M_{-1}$ or $M_0$), which is $2^{\\iota d_1/2}$. While this term is ultimately shown to be negligible via interpolation due to a strong $L^1$ estimate, the $L^2$ estimate itself appears loosely justified. A clearer argument for controlling the sum over $m$ and $\\ell$ for the $L^2$ norm would be needed for full rigor."
      }
    ],
    "token_usage": {
      "input": 28428,
      "thinking": 28756,
      "output": 930
    }
  },
  {
    "entry_id": 145,
    "retraction_id": "2112.10980v2",
    "paper_id": "2112.10980v1",
    "retraction_comment": "There is an error in the proof of the co-primality statement in Proposition 6. The author has constructed examples of knots with integer surgeries so that the orders of the groups generated by these knots and their surgery duals have a non-trivial common factor, so in fact the co-primality statement in Proposition 6 is false",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Condition for $[\\hat{\\Sigma}_K]$ to be a generator of $H_2(W)$ implies a strong restriction on $K$, or alters subsequent calculations.",
        "Location": "Page 2 (last paragraph, definition of $a, b, |\\lambda_M|, |K|$) and Page 3 (Proof of Proposition 4).",
        "Explanation": "The paper states that the order of $[K]$ in $H_1(Y)$, denoted $|K|$, is equal to $a \\cdot |\\lambda_M|$. Here, $a$ is the coefficient of the framing curve $\\lambda$ in the expression for the primitive rational longitude $[\\lambda_M]=a[\\lambda]+b[\\mu]$, and $|\\lambda_M|$ is the order of $[\\lambda_M]$ in $H_1(M)$ (where $M=Y \\setminus N(K)$). Standard literature defines the order of $[K]$ in $H_1(Y)$ as $|a|$. If the paper's formula $|K|=a|\\lambda_M|$ is an assertion about this order, then consistency with the standard $|K|=|a|$ implies $|\\lambda_M|=1$ (assuming $a \\neq 0$). This means the rational longitude $\\lambda_M$ must be null-homologous in $M$, a condition not met by many knots (e.g., non-trivial torus knots). The proof of Proposition 4 uses $i([\\hat \\Sigma_K]) = (a|\\lambda_M|) [c(H), \\partial c(H)]$ and claims $[\\hat \\Sigma_K]$ generates $H_2(W)$ because $a|\\lambda_M|=|K|$. If $|K|=|a|$ (standard) and $|\\lambda_M|>1$, then $i([\\hat \\Sigma_K]) = (\\pm |K| |\\lambda_M|) [c(H), \\partial c(H)]$. This means $[\\hat{\\Sigma}_K]$ would represent $|\\lambda_M|$ times a generator of $H_2(W)$, not necessarily a generator itself. This would multiply $\\iota(\\hat{\\Sigma}_K, \\hat{\\Sigma}_K)$ in Proposition 6 by a factor of $|\\lambda_M|^2$."
      },
      {
        "Problem": "Incorrect calculation of intersection numbers in the co-primality argument of Proposition 6.",
        "Location": "Page 4, Proof of Proposition 6 (paragraph starting 'By Poincar\\'e-Lefschetz duality...').",
        "Explanation": "The proof that $|K|$ and $|K^*|$ are co-prime relies on the statements $PD[\\chi, -K][\\hat\\Sigma_{K^*}] = \\iota(\\chi, \\hat\\Sigma_{K^*}) = |K^*|$ and $PD[\\chi^*, K^*][\\hat\\Sigma_K] = \\iota(\\chi^*, \\hat\\Sigma_K) = |K|$. Here, $\\chi$ is a disk in the trace $W$ bounded by $K \\subset Y$ (described as 'union of $K \\times [0,1]$ and the core of the 2-handle $H$') and $\\hat{\\Sigma}_{K^*}$ is the capped rational Seifert surface for $K^*$. The intersection number $\\iota(\\chi, \\hat{\\Sigma}_{K^*})$, which is $\\iota(D_K, F_{K^*} \\cup D_{K^*})$ where $D_K$ is the core of the handle on $K$ and $D_{K^*}$ is the core of the handle on $K^*$, is typically $\\pm 1$ (representing the algebraic intersection of the core and co-core of the handles, perhaps plus a linking term $\text{lk}_{Y^*}(K, K^*)$ if $K$ is taken as $\\partial D_K \\cap Y^*$). It is not generally $|K^*|$. If these intersection numbers are $\\pm 1$, the resulting equation $n(\\pm 1) + n^*(\\pm 1) = 1$ does not imply that $|K|$ and $|K^*|$ are co-prime. The co-primality is essential for Theorem 7."
      },
      {
        "Problem": "The derivation of $|\\iota(\\hat{\\Sigma}_K, \\hat{\\Sigma}_K)| = |K||K^*|$ in Proposition 6 implicitly assumes a vanishing torsion component without justification.",
        "Location": "Page 4, Proof of Proposition 6 (first part, deriving the value of $p$).",
        "Explanation": "The proof of Proposition 6 states that the map $A: H_2(W) \to H_2(W,\\partial W)$ sends $[\\hat{\\Sigma}_K]$ to $(p, \\alpha)$, where $p = \\iota(\\hat{\\Sigma}_K, \\hat{\\Sigma}_K)$ and $\\alpha \\in H_1(W)$ (using the identification $H_2(W,\\partial W) \\cong \\mathbb{Z} \\oplus H_1(W)$). The subsequent argument relating $|p|$ to orders of homology groups via the exact sequence $H_2(W) \\xrightarrow{A} H_2(W,\\partial W) \\xrightarrow{B} H_1(\\partial W) \\xrightarrow{C} H_1(W)$ leads to the relation $|p| \\cdot |H_1(W)/\\langle \\alpha \rangle| = |\\mathrm{Im}(B)| = |K||H_1(Y^*)|$. This implies $|p| = (|K||H_1(Y^*)| \\cdot |\\langle \\alpha \rangle|) / |H_1(W)| = |K||K^*||\\langle \\alpha \rangle|$. The paper's conclusion that $|p| = |K||K^*|$ requires $|\\langle \\alpha \rangle|=1$, meaning $\\alpha=0$. However, no justification is provided for why this torsion component $\\alpha$ must be zero. If $\\alpha \neq 0$, then $|\\langle \\alpha \rangle| > 1$, altering the formula for $\\iota(\\hat{\\Sigma}_K, \\hat{\\Sigma}_K)$. This modified formula would propagate to Theorem 7, potentially affecting its conclusion."
      }
    ],
    "token_usage": {
      "input": 6388,
      "thinking": 19038,
      "output": 1361
    }
  },
  {
    "entry_id": 146,
    "retraction_id": "2006.16461v2",
    "paper_id": "2006.16461v1",
    "retraction_comment": "withdrawn due to an error in Lemma 4.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The recurrence relation for $N(n,p,q)$ derived in Lemma 4.2 implies $N(1,p,q) = 2N(0,p,q)$. Using the paper's definitions $N(1,p,q)=r$ and $N(0,p,q)=s$ (derived from the continued fraction of $-p/q$), this means $r=2s$. This condition $r=2s$ translates to $r_k=-2$ (where $r_k$ is the last coefficient in the continued fraction of $-p/q$), which is not true for general $p,q$. Therefore, the central recurrence relation that forms the basis of the proof of the main theorem does not hold for $N(n,p,q)$ in general, specifically for $n=1$.",
        "Location": "Lemma 4.2 (page 10), definitions of $r,s$ (page 2), and final proof of Theorem 1.1 (page 12)",
        "Explanation": "The recurrence $N(n,p,q)=\\sum_{k=1}^n(-1)^{k+1}a_{k,n}N(n-k,p,q)$ for $n=1$ becomes $N(1,p,q) = a_{1,1}N(0,p,q)$. Since $a_{1,1} = \frac{2(1)}{2(1)-1}\\binom{2(1)-1}{1} = 2$, this implies $N(1,p,q) = 2N(0,p,q)$. Substituting $N(1,p,q)=r$ and $N(0,p,q)=s$, we get $r=2s$. The definitions of $r = |(r_0+1)\\dots(r_{k-1}+1)r_k|$ and $s = |(r_0+1)\\dots(r_{k-1}+1)(r_k+1)|$ mean $r=2s$ iff $|r_k|=2|r_k+1|$. Since $r_i \\le -2$, this implies $r_k=-2$. This is not true for all $p,q$ (e.g., $-p/q = [-3]$ gives $r_0=-3$, $r=3, s=2$, so $3 \ne 2(2)$). This fundamental inconsistency invalidates the main proof."
      },
      {
        "Problem": "The main formula in Theorem 1.1, $N(n,p,q)=C_n((r-s)n+s)$, contradicts a known result for the special case $(p,q)=(1,1)$. For $(p,q)=(1,1)$, the parameters are $r=1, s=0$, so the formula yields $N(n,1,1)=nC_n$. However, Theorem 3.2 (citing Honda, Kazez, Matić [honda2002convex]) states that $N(n,1,1)=C_n$. The paper's formula is therefore incorrect for this established special case when $n>1$.",
        "Location": "Theorem 1.1 (page 2), Theorem 3.2 (page 6)",
        "Explanation": "The paper's main formula $N(n,p,q)=C_n((r-s)n+s)$ should be consistent with known results. For $(p,q)=(1,1)$, $r=1, s=0$. The formula gives $N(n,1,1) = C_n((1-0)n+0) = nC_n$. However, the paper itself quotes (in Theorem 3.2) a result from Honda, Kazez, and Matić (2002) that $N(n,1,1)=C_n$. For $n>1$, $nC_n \ne C_n$. This indicates that the main theorem is incorrect."
      },
      {
        "Problem": "The argument that $Y_n = C_n((r-s)n+s)$ satisfies the recurrence from Lemma 4.2 is flawed because it relies on Lemma 4.3 and Corollary 4.5, which claim that $C_n$ and $nC_n$ satisfy this recurrence. Lemma 4.3, $C_n=\\sum_{k=1}^n(-1)^{k+1}a_{k,n}C_{n-k}$, is false for $n=1$ if $C_0=1$ (the standard definition of the Catalan number $C_0$).",
        "Location": "Lemma 4.3 (page 11), Corollary 4.5 (page 12), Proof of Theorem 1.1 (page 12)",
        "Explanation": "The proof of Theorem 1.1 relies on showing that $C_n((r-s)n+s)$ satisfies the same recurrence as $N(n,p,q)$ with the same base cases. This relies on Lemma 4.3 ($C_n$ satisfies the recurrence) and Corollary 4.5 ($nC_n$ satisfies the recurrence). However, Lemma 4.3 is $C_n=\\sum_{k=1}^n(-1)^{k+1}a_{k,n}C_{n-k}$. For $n=1$, this gives $C_1 = a_{1,1}C_0$. As $a_{1,1}=2$ and $C_0=1$, this implies $C_1=2$. But $C_1=1$. This error invalidates Lemma 4.3 for $n=1$, and thus the subsequent argument that $C_n((r-s)n+s)$ is the solution to the recurrence derived in Lemma 4.2."
      },
      {
        "Problem": "The existence of the specific interior bypass on $\\partial M$ (the torus boundary) with the properties required for Proposition 3.5 is not rigorously established. This bypass is crucial for the inductive step that changes $(n,-p,q)$ to $(n-1,-p,q)$ or $(1,-p',q')$.",
        "Location": "Proposition 3.5 (pages 7-8)",
        "Explanation": "Proposition 3.5 claims that $\\partial M$ admits an interior bypass whose attachment reduces $n$ or performs a Dehn twist. The proof refers to Proposition 2.10 (bypass-abundance theorem) applied to the meridian disk $D$. Proposition 2.10, when applied to $D$, guarantees a bypass attached to $D$ (i.e., the bypass disk intersects $D$ along its straight edge). It is not explained how this implies the existence of an interior bypass attached to $\\partial M$ (the boundary of the solid torus) along an arc of $\\partial D$ (the boundary of the meridian disk), with the specific properties (e.g., how its attaching arc intersects $\\Gamma_{\\partial M}$) needed to ensure the claimed change in $(n,p,q)$. This step is critical for the entire bypass induction strategy."
      }
    ],
    "token_usage": {
      "input": 16585,
      "thinking": 15409,
      "output": 1616
    }
  },
  {
    "entry_id": 147,
    "retraction_id": "1811.02204v3",
    "paper_id": "1811.02204v2",
    "retraction_comment": "Some arguments in the proof of Thm. 2.3.3 are erroneous. One of the faulty arguments lies in the estimate on the first line of page 24. The author mistakenly treats the orthogonal decomposition with respect to the unweighted inner product as the one with respect to the weighted one. Contents which are free from irreparable errors are contained in arXiv:1912.08076",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The argument for the congruence property of the extended section F seems flawed for higher codimension lc centers (σ ≥ 2).",
        "Location": "Proof of Theorem 3.2.1 (thm:extension-from-lc-of-any-codim), primarily page 21, the paragraph starting 'The section s_eps is smooth...' and the subsequent paragraph on the convergence of F_{eps_mu_k} - s_{eps_mu_k} to F_V.",
        "Explanation": "The proof claims that the constructed solution $u_\\varepsilon$ (and an auxiliary solution $s_\\varepsilon$) vanishes on the log-canonical center $\\mathcal{I}_{\\text{lc}_X^\\sigma(S)}$ (i.e., belongs to $\\text{smooth}_X \\otimes \\mathcal{J}(\\phi_L) \\cdot \\mathcal{I}_{\\text{lc}_X^\\sigma(S)}$). This vanishing property is crucial for establishing that the final extension $F$ satisfies $F \\equiv f \\pmod{\\mathcal{J}(\\phi_L) \\cdot \\mathcal{I}_{\\text{lc}_X^\\sigma(S)}}$. However, the $L^2$ estimates for $u_\\varepsilon$ (and $s_\\varepsilon$) involve weights of the form $e^{-\\phi_L-\\psi}/|\\psi|^{\\sigma-\\sigma\\varepsilon}(\\dots)$. An $L^2$-bound with this weight does not necessarily imply vanishing on $\\text{lc}_X^\\sigma(S)$. For vanishing to be forced by an $L^2$ condition $\\int |h|^2 w < \\infty$, the weight $w$ must be sufficiently singular (i.e., $w^{-1}$ not locally integrable). Here, $w^{-1} = e^{\\phi_L+\\psi} |\\psi|^{\\sigma-\\sigma\\varepsilon}(\\dots)$ appears to be locally integrable near $\\text{lc}_X^\\sigma(S)$ (codimension $\\sigma$) because $\\sigma-\\sigma\\varepsilon < \\sigma$. If $u_\\varepsilon$ (and $s_\\varepsilon$) do not vanish on $\\text{lc}_X^\\sigma(S)$, the claimed congruence for $F$ may not hold, affecting a key part of the theorem's conclusion about the nature of the extension."
      }
    ],
    "token_usage": {
      "input": 84934,
      "thinking": 22089,
      "output": 533
    }
  },
  {
    "entry_id": 148,
    "retraction_id": "1303.6535v2",
    "paper_id": "1303.6535v1",
    "retraction_comment": "Crucial flaw in proof of Theorem 3. The argument only gives a lower bound, not purity as claimed (the latter most likely does not hold except for in small rank)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Discrepancy in Homology Calculation for Affine Spaces",
        "Location": "Page 1, formula for Ext groups, and first (unlabeled) Corollary proof",
        "Explanation": "The paper states $\\mathrm{Ext}^{\\bullet}(\\Delta_v, \\Delta_w) = H_c^{\\bullet +\\ell(w)-\\ell(v)}(C^v\\cap C_w)$. For $\\mathrm{Hom}(\\Delta_v, \\Delta_w)$, this is $H_c^{\\ell(w)-\\ell(v)}(C^v\\cap C_w)$. It's also stated that $C^v\\cap C_w$ is affine and smooth, diffeomorphic to $\\mathbb{C}^d$ where $d = \\ell(w)-\\ell(v)$. For $\\mathbb{C}^d$, $H_c^k(\\mathbb{C}^d; \\mathbb{C})$ is non-zero only for $k=2d$, where it is $\\mathbb{C}(-d)$. Thus, $H_c^d(\\mathbb{C}^d)$ would be zero if $d \\neq 2d$, i.e., if $d \\neq 0$. This implies $\\mathrm{Hom}(\\Delta_v, \\Delta_w)=0$ if $v < w$. This contradicts the known fact that $\\dim \\mathrm{Hom}(\\Delta_v, \\Delta_w) = 1$ if $v \\leq w$. This fundamental discrepancy affects the subsequent arguments relying on these Hom groups being $\\mathbb{Q}^H$."
      },
      {
        "Problem": "Flawed Proof of Hom Purity",
        "Location": "Page 1, proof of first (unlabeled) Corollary after Proposition 1.1",
        "Explanation": "The proof that $\\mathrm{Hom}(\\Delta_v, \\Delta_w)$ is pure of weight 0 encounters a contradiction. In situation (ii) of Proposition 1.1 ($vs>v, vs \\not\\leq ws$), $C^v\\cap C_w \\simeq (C^v\\cap C_{ws}) \\times \\mathbb{C}^*$. Applying the Künneth formula with $H_c^1(\\mathbb{C}^*) = \\mathbb{Q}^H(-1)$ (pure of weight 2) and $H_c^0(\\mathbb{C}^*)=H_c^2(\\mathbb{C}^*)=0$, one gets $\\mathrm{Hom}(\\Delta_v, \\Delta_w) \\simeq \\mathrm{Hom}(\\Delta_v, \\Delta_{ws})(-1)$. If $\\mathrm{Hom}(\\Delta_v, \\Delta_{ws})$ is pure of weight 0 (by induction), then $\\mathrm{Hom}(\\Delta_v, \\Delta_w)$ would be pure of weight 2. This contradicts the claim that it is pure of weight 0 (unless it's zero, which is not true if $v \\le w$). This error undermines the foundation for Theorem 2.3 (purity of Ext^1)."
      },
      {
        "Problem": "Incompatibility of Ext^1 Purity with Recursive Relations",
        "Location": "Theorem 2.3 (Purity) proof and its reliance on Corollary 2.2",
        "Explanation": "Theorem 2.3 states $\\mathrm{Ext}^1(\\Delta_v, \\Delta_w)$ is pure of weight 2. The proof uses Corollary 2.2, which is derived from Proposition 1.1. For example, in Proposition 1.1(2) (adapted for $ws>w$, relevant to Cor 2.2(ii)), $C^v \\cap C_{ws} \\simeq (C^v \\cap C_w) \\times \\mathbb{C}^*$. This implies $\\mathrm{Ext}^1(\\Delta_v, \\Delta_{ws}) \\simeq \\mathrm{Ext}^1(\\Delta_v, \\Delta_w)(-1)$ (assuming $H_c^2(\\mathbb{C}^*)=0$). If $\\mathrm{Ext}^1(\\Delta_v, \\Delta_{ws})$ is pure of weight 2 (by induction hypothesis in Theorem 2.3 proof), then $\\mathrm{Ext}^1(\\Delta_v, \\Delta_w)(-1)$ must be pure of weight 2. This means $\\mathrm{Ext}^1(\\Delta_v, \\Delta_w)$ would be pure of weight 0. This contradicts the theorem's main claim (unless $\\mathrm{Ext}^1=0$). The formula in Cor 2.2(ii) attempts to resolve this by adding a $\\mathbb{Q}^H(-1)$ term, but its derivation is unclear and potentially flawed."
      },
      {
        "Problem": "Questionable Formula in Corollary 2.2(ii)",
        "Location": "Page 2, Corollary 2.2(ii)",
        "Explanation": "Corollary 2.2(ii) states: If $vs>v$ and $vs\\not\\leq w$ (and $ws>w$), then $\\mathrm{Ext}^1(\\Delta_v, \\Delta_w)\\oplus \\mathbb{Q}^H(-1)\\simeq \\mathrm{Ext}^1(\\Delta_v, \\Delta_{ws})$. Proposition 1.1(2) (with $w \\to ws$, $ws \\to w$) gives $C^v \\cap C_{ws} \\simeq (C^v \\cap C_w) \\times \\mathbb{C}^*$. Using $H_c^1(\\mathbb{C}^*) = \\mathbb{Q}^H(-1)$ and $H_c^2(\\mathbb{C}^*)=0$, the Künneth formula yields $\\mathrm{Ext}^1(\\Delta_v, \\Delta_{ws}) \\simeq \\mathrm{Ext}^1(\\Delta_v, \\Delta_w)(-1)$. The paper's formula $\\mathrm{Ext}^1(\\Delta_v, \\Delta_w) \\oplus \\mathbb{Q}^H(-1) \\simeq \\mathrm{Ext}^1(\\Delta_v, \\Delta_w)(-1)$ is not a direct consequence and appears incorrect. The justification 'Künneth formula yields (ii)' is insufficient for this specific form, which is critical for the proof of Theorem 2.3."
      },
      {
        "Problem": "Unjustified Source of '+1' in Dimension Formula (Corollary 2.4(ii))",
        "Location": "Page 2, Corollary 2.4, case 2",
        "Explanation": "Corollary 2.4 gives $\\dim \\mathrm{Ext}^1(\\Delta_v,\\Delta_w) = 1+\\dim \\mathrm{Ext}^1(\\Delta_v, \\Delta_{ws})$ if $vs>v$ and $vs\\not\\leq ws$ (and $ws<w$). This case corresponds to Proposition 1.1(ii): $C^v\\cap C_w \\simeq (C^v\\cap C_{ws}) \\times \\mathbb{C}^*$. The Künneth formula for $H_c^{\\bullet + \\ell(w)-\\ell(v)}((C^v\\cap C_{ws}) \\times \\mathbb{C}^*)$ gives two terms: $\\mathrm{Ext}^1(\\Delta_v, \\Delta_{ws}) \\otimes H_c^1(\\mathbb{C}^*)$ and $\\mathrm{Hom}(\\Delta_v, \\Delta_{ws}) \\otimes H_c^2(\\mathbb{C}^*)$. For the '+1' to appear, $\\mathrm{Hom}(\\Delta_v, \\Delta_{ws})$ must be 1-dimensional (true if $v \\le ws$) and $H_c^2(\\mathbb{C}^*)$ must be 1-dimensional. However, $H_c^2(\\mathbb{C}^*;\\mathbb{C})=0$. If $H_c^2(\\mathbb{C}^*)=0$, the '+1' term vanishes, contradicting the corollary which claims known results for R-polynomials."
      }
    ],
    "token_usage": {
      "input": 5477,
      "thinking": 24285,
      "output": 1813
    }
  },
  {
    "entry_id": 149,
    "retraction_id": "1204.0036v3",
    "paper_id": "1204.0036v2",
    "retraction_comment": "This paper has been withdrawn by the authors because Lemma 11, for p>1, is incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified surjectivity claim in transversality proof for homotopy well-definedness.",
        "Location": "Section 2, Proof of Lemma 2.3, page 9",
        "Explanation": "The proof of Lemma 2.3, which is crucial for Proposition 1 (well-definedness of the homotopy path $\\Phi$), relies on a transversality argument. This argument requires a map $F_2(\\cdot, \\zeta, w, s): \\mathcal{H}_{(d)} \\to \\overline{K}_w$ (or its restriction to $\\mathcal{V}_\\zeta$) to be surjective. Specifically, the paper states: 'In particular, since $\\zeta_0 \\neq 0$, the restriction $F_2(\\cdot,\\zeta,e_0,s):\\mathcal{V}_\\zeta\\to \\overline{K}_{e_0}$ is surjective, concluding the claim.' This surjectivity is asserted without explicit proof or reference. While such surjectivity claims are often true in similar contexts due to the high dimensionality of polynomial spaces, its validity (especially for all degrees $d_i \\ge 1$, including the 'tight' case where $\\dim \\mathcal{V}_\\zeta = \\dim \\overline{K}_{e_0}$, e.g., all $d_i=1$) is critical. If this map were not surjective, the transversality argument would fail, potentially undermining Proposition 1 and, consequently, the entire analysis that builds upon it."
      }
    ],
    "token_usage": {
      "input": 31232,
      "thinking": 26510,
      "output": 337
    }
  },
  {
    "entry_id": 150,
    "retraction_id": "2111.11437v6",
    "paper_id": "2111.11437v5",
    "retraction_comment": "There is an error. In section 3.4, the author identifies $Hom_Q(M, _M)$ with the set $Mat_{r \\times r}$ through the decomposition of M into a direct sum of indecomposable modules, and discusses nilpotent matrices in $Mat_{r \\times r}$. This is misleading because here we do not have a natural ring structure on $Mat_{r \\times r}$",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified reduction of the operator $r_{a,b}$ to a matrix commutator $Af-FB$ and potentially flawed \"$\\tau(f)=f$\" assumption.",
        "Location": "Section 3.4, p.10, Assumption (labeled 'Assumption:' before Lemma 3.7, also referred to as Assumption \\ref{assum_main}), and the subsequent application of Lemma 3.7 in Theorem 3.9.",
        "Explanation": "The paper defines the operator $r_{a,b}(f) = \\tau(f)a - bf$. It then claims this operator can be represented by the matrix operation $Af-FB$ (where $A, B, F$ are matrices of scalars corresponding to $a,b,f$) for $\\tau$-orbit Kostant partitions and specific choices $a=M_\\lambda^*, b=M_\\kappa^*$. This crucial transition is not adequately justified for two main reasons:\n1. The assumption \"$\\tau(f)=f$\" (page 10), stated as a consequence of $\\tau$-orbit Kostant partitions having no projective roots, is not rigorously justified. $\\tau$ is the Auslander-Reiten translation functor, so $\\tau(f)$ maps $\\tau M \\to \\tau N$, while $f$ maps $M \\to N$. While components $\\tau M_i$ might be isomorphic to $M_{i-1}$ (with an index shift), this implies $\\tau(f)$ is $f$ with shifted indices/components, not $f$ itself. The precise mechanism of this identification and its impact on the formula for $r_{a,b}$ are not elaborated.\n2. The derivation of the specific matrix form $Af-FB$ (as used in Lemma 3.7) from the operator definition $\\tau(f)a - bf$ is missing. The matrix product form of $\\tau(f)a - bf$ would naively be $F_{shifted}A' - B'F$ or a similar expression, depending on matrix conventions for $a,b$ and the effect of $\\tau$ on $f$. Lemma 3.7, which calculates $\\dim \\Ker(Af-FB)$, is then applied without a clear proof that $r_{a,b}$ indeed takes this specific matrix commutator form. This gap potentially invalidates Theorem 3.9 (Thm. \\ref{them:tworegularpartitions} in paper) and all subsequent results relying on it (Theorems 3.8/1.1, 1.5, 4.2, 4.3)."
      },
      {
        "Problem": "The equivalence between the product of quantum minors being in $q^{\\mathbb{Z}}\\mathbf{B}^*$ and quasi-commutation is assumed without sufficient justification for the general setting considered.",
        "Location": "Theorem 4.2 (also Theorems 1.5 and 4.3), page 18.",
        "Explanation": "The paper aims to find conditions for $\\mathbf{b}_1 \\mathbf{b}_2 \\in q^{\\mathbb{Z}}\\mathbf{B}^*$, where $\\mathbf{b}_1, \\mathbf{b}_2$ are quantum minors. The main theorems (e.g., Thm 1.5, Thm 4.2) provide conditions equivalent to $\\Ext^1_\\Lambda(\\mathcal{M}_1, \\mathcal{M}_2)=0$ and $\\Ext^1_\\Lambda(\\mathcal{M}_2, \\mathcal{M}_1)=0$. This pair of conditions is known to be equivalent to quasi-commutation: $\\mathbf{b}_1 \\mathbf{b}_2 = q^n \\mathbf{b}_2 \\mathbf{b}_1$. The paper implicitly relies on the Berenstein-Zelevinsky conjecture that $\\mathbf{b}_1\\mathbf{b}_2\\in q^{\\mathbb{Z}}\\mathbf{B}^* \\iff \\mathbf{b}_1\\mathbf{b}_2=q^n\\mathbf{b}_2\\mathbf{b}_1$. However, the paper itself notes this conjecture is false in general. While this equivalence holds for quantum Plücker coordinates in type $A_n$, its validity for the specific generalized quantum minors $D(b,d)$ (from Geiss-Leclerc-Schröer) in arbitrary Dynkin quivers is not established or cited. The proof of Theorem 4.2 states that if $\\mathbf{b}_1, \\mathbf{b}_2$ quasi-commute, their product is $q^k \\delta_{\\mathcal{M}_1 \\oplus \\mathcal{M}_2}$. For this to be in $q^{\\mathbb{Z}}\\mathbf{B}^*$, $\\mathcal{M}_1 \\oplus \\mathcal{M}_2$ must be an indecomposable rigid module, which is only possible if one of $\\mathcal{M}_1$ or $\\mathcal{M}_2$ is zero. Thus, the paper primarily establishes conditions for quasi-commutation, and the claim that these are sufficient for the product to be a *single* dual canonical basis element (up to $q$-power) is not fully justified in the general context of the paper."
      },
      {
        "Problem": "Ambiguity in the definition of the dual representation $M^*$.",
        "Location": "Definition 2.1, page 6.",
        "Explanation": "Definition 2.1 states: \"$M^* \\Seteq{\\eta \\in D\\Ext_Q^1(M,M)}{\\eta \\le \\eta' \\quad \\forall \\eta' \\in D\\Ext_Q^1(M,M)}$\". The order is given by $\\eta \\le \\eta' \\iff \\mathcal{O}_{\\eta'} \\subset \\overline{\\mathcal{O}_\\eta}$, meaning $M^*$ would be an element in a *closed* orbit (a minimal element under this partial order). However, the subsequent explanatory sentence says: \"...there is only one unique $\\mathcal{O}_\\eta$ such that $\\overline{\\mathcal{O}_\\eta} \\cap D\\Ext_Q^1(M,M) = D\\Ext_Q^1(M,M)$\", which describes the unique *open dense* orbit (a generic element). A representation cannot generally be in both a closed orbit and an open dense orbit unless the space $D\\Ext_Q^1(M,M)$ consists of a single orbit. Later usage in the paper (e.g., Theorem 3.6(3) concerning $(T,T^*)$ and Lemma 3.8 for $M_\\lambda^*$) implies that $M^*$ (or $T^*$) is chosen from this generic, open dense orbit. This initial ambiguity in a key definition, while perhaps resolved by contextual clues later, is a point of confusion and imprecision."
      }
    ],
    "token_usage": {
      "input": 42503,
      "thinking": 22271,
      "output": 1530
    }
  },
  {
    "entry_id": 151,
    "retraction_id": "0912.4084v3",
    "paper_id": "0912.4084v2",
    "retraction_comment": "This paper has been withdrawn by the author. Paper is withdrawn. On review the paper contributes nothing of significance. The runtime analysis of the algorithms presented, while correct in terms of number of operations, does not represent the complexity of the algorithms in terms of \"bits input\". A naive mistake in reasoning",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misleading Definition of Polynomial Time and Complexity Metric",
        "Location": "Abstract; Page 2, Paragraph 2; and throughout all complexity analyses (e.g., Page 3, Page 5, Page 6)",
        "Explanation": "The paper claims polynomial time complexity where 'n' is the *magnitude* of the integer to be factored. Standard cryptographic and algorithmic complexity for integer factorization is measured in terms of the *bit length* of 'n' (i.e., log n). An algorithm that is polynomial in the value 'n' is exponential in its bit length, rendering it inefficient for large numbers typically considered in factoring. This fundamental misrepresentation of 'polynomial time' invalidates the significance of the claimed complexity bounds (e.g., O(n^2.5), O(n^1.5 log10n)) as efficient solutions in the accepted sense."
      },
      {
        "Problem": "Incorrect Cost of Arithmetic Operations in Complexity Analyses",
        "Location": "Page 3, Section 2.1.1 (Algorithm 1); Page 5, Section 3.2.2 (Algorithm 2 Sieve); Page 6, Section 3.2.3 (Algorithm 2 Filter)",
        "Explanation": "Throughout the paper, the complexity analyses incorrectly assume that arithmetic operations (like addition or comparison) on numbers of magnitude 'n' take O(n) or O(log10 n) time related to the value 'n' itself, rather than being polynomial in the number of bits (log n). For instance, page 3 states arithmetic operations take 'O(n) in the number of bits of the operands' which is then seemingly interpreted as a factor proportional to 'log10 n' (value) or even 'n' (value) in subsequent derivations (e.g. Loop 3 and Loop 5 of Algorithm 2, Filter Process of Algorithm 2). This consistently inflates and invalidates the derived time complexities."
      },
      {
        "Problem": "Flawed Complexity Analysis of Algorithm 1 (Difference Expression)",
        "Location": "Page 3, Section 2.1.1",
        "Explanation": "The derivation of O(n log10 n) for Algorithm 1 (decomposition) is unsound. The bound for Loop 2 iterations (inner loop) is claimed as O(n^0.5 * (ln n^0.5 + gamma)), which is not clearly justified for the described operations in a worst-case scenario. The algorithm essentially performs trial division. Combined with the incorrect arithmetic cost (see Problem 2), the resulting complexity is not credible. The algorithm is expected to be exponential in the bit length of n."
      },
      {
        "Problem": "Unsound Complexity Analysis for Algorithm 2 (Sieve and Filter Processes)",
        "Location": "Page 5, Section 3.2.2 (Sieve Process); Page 6, Section 3.2.3 (Filter Process)",
        "Explanation": "The O(n^2.5) complexity derived for Algorithm 2's Sieve Process (e.g., Loop 3 and Loop 5 analysis) and Filter Process is based on flawed assumptions. Beyond the incorrect arithmetic cost (Problem 2), the multiplication of loop iteration bounds appears problematic. For example, Loop 3's complexity on page 5 starts with an unjustified 'O(n * ...)' factor, and Loop 5's complexity is claimed as 'O(n * sqrt(n) * sqrt(n) * sqrt(n))'. A standard sieve to sqrt(N) is much faster, and trial division (Filter Process) with these primes would not reach O(N^2.5) if analyzed with correct arithmetic costs and standard loop analyses."
      },
      {
        "Problem": "Incorrect Analysis of Recursive Application for Prime Factoring (Algorithm 1)",
        "Location": "Page 4, Section 2.1.2",
        "Explanation": "The paper claims that prime factoring using recursive application of Algorithm 1 involves a maximum of sqrt(n) executions of the decomposition algorithm. This is incorrect. The number of prime factors of 'n', and thus the number of recursive calls to find all prime factors, is bounded by O(log n), not O(sqrt(n)). This error, combined with the flawed base complexity of Algorithm 1, invalidates the claimed O(n^1.5 log10 n) complexity for prime factoring."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 6820,
      "output": 978
    }
  },
  {
    "entry_id": 152,
    "retraction_id": "2106.04691v2",
    "paper_id": "2106.04691v1",
    "retraction_comment": "Theorem 1.7 is established only under a restrictive hypothesis, not the generality that the authors assert",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper's central new results, particularly Theorem 1.6 (existence and properties of $\\hatPT$) and the geometric interpretation of extension data (e.g., equation (3.20) relating $\\sL_M$ to normal bundles), are stated to be from or rely heavily on proofs in a separate work ([GGRhatPT]). While this is typical for a progress report, the soundness of this paper's main conclusions is critically dependent on the validity of these deferred proofs.",
        "Location": "Throughout, e.g., p. 2 (Theorem 1.6), p. 6 (Proof of Theorem 1.6), p. 13 (Equation 3.20 and related discussion in Section 3.5.3)",
        "Explanation": "The current paper provides an overview and applications of a framework developed in more detail elsewhere. For instance, the construction of the proper holomorphic map 'f' essential for Theorem 1.6 is sketched in Section 3.1 with key details (like the simplification of monodromy $\\Gamma_1$) deferred. Similarly, the crucial formula (3.20) underpinning applications in Section 3.6 is presented as part of the framework. Without access to the proofs in [GGRhatPT], a full assessment of soundness is limited. This is a structural comment on the paper's nature rather than a specific error within its presented arguments."
      },
      {
        "Problem": "The claim in Remark 3.22 that the map $\\sF \\to \\sF^2$ is finite relies on Lemma 3.18(ii) implying that higher-level extension data (level $\\ge 3$) is 'constant' if lower-level data is fixed. The argument for finiteness (successive etale maps between compact spaces) seems plausible but hinges on the precise interpretation of 'constant' and the properties of the involved quotient spaces for extension data of LMHS.",
        "Location": "p. 3 (Section 1.2.2) and p. 13 (Remark 3.22, referring to Lemma 3.18 on p. 12)",
        "Explanation": "Lemma 3.18(ii) states that if a map $\\psi^\\ell : \\sZ \\to \\cE^\\ell_{\\s,F}$ (for $\\ell \\ge 2$) has its projection to $\\cE^{\\ell-1}_{\\s,F}$ constant, then $\\psi^\\ell$ is constant. This implies $\\sF^k \\to \\sF^{k-1}$ is unramified for $k \\ge 2$. Since these are maps between compact complex spaces (images of the compact fibre $A$), unramified implies finite. The argument appears sound, but the properties of $F^{-1}\\tExt_\\ell(\\s,F)$ (especially the 'no compact factor' claim for $\\ell \\ge 2$) are critical and standardly non-trivial results in Hodge theory."
      },
      {
        "Problem": "In the proof of Proposition 3.26 (related to Conjecture 3.25), the step from $(\\sum \\langle M,N_i \\rangle[Z_i])^2 = 0$ and $\\|Z_i\\cdot Z_j\\|$ being negative definite to $\\langle M,N_i\\rangle = 0$ for all $i$ requires the set of curves $\\{Z_i\\}$ to form a basis for the vector space they span over $\\mathbb{Q}$ (or $\\mathbb{R}$). If there are linear dependencies among the $[Z_i]$ as cycles, this conclusion might not hold directly without further argument on the structure of the quadratic form.",
        "Location": "p. 14 (Proof of Proposition 3.26)",
        "Explanation": "If $x = (\\langle M,N_1 \\rangle, \\dots, \\langle M,N_\\nu \\rangle)$ and $Q = (Z_i \\cdot Z_j)$, then $x^T Q x = 0$. If $Q$ is negative definite, this implies $x=0$, i.e., $\\langle M,N_i\\rangle = 0$ for all $i$. This step is standard. The negative definiteness of $Q$ is cited from [GGLR, Lemma 3.1.1], which requires $Z = \\cup Z_i$ to be connected and $\\Le \\cdot Z_i = 0$ with $\\Le$ nef and big. These conditions seem met under the proposition's hypotheses (generic local Torelli for $\\Le$ big, $Z=\\fibrezero$ for $\\Le \\cdot Z_i=0$, and assuming $\fibrezero$ is connected). The subsequent step 'As $M$ is arbitrary, this is a contradiction' relies on $\\check{\\bfN}_Z$ being sufficiently rich to imply $N_i=0$ (or relevant parts), which is standard. The argument seems fine under these standard assumptions."
      },
      {
        "Problem": "The discussion of I-surfaces in Section 5.2, particularly Remark 5.6, makes a strong assertion: 'The mapping $\\PhiT$ is locally 1-1 on the data $(X,\\widetilde C,\\{q_i\\})$. One may check that its image is locally isomorphic to the blowup of $\\cN_2 \\subset \\olM_I$.' This suggests $\\PhiT$ provides a specific desingularization. While plausible and illustrative of the framework's power, this is a significant geometric claim presented as something 'one may check', implying it's considered established but without providing the check.",
        "Location": "p. 20 (Remark 5.6)",
        "Explanation": "This claim describes the behavior of the maximal completion $\\PhiT$ on a specific boundary stratum of a moduli space. The parameter space for $(X,\\widetilde C,\\{q_i\\})$ is 27-dimensional, mapping to the 20-dimensional stratum $\\cN_2$. If $\\PhiT$ is locally 1-1 on this 27-dimensional space, its image is a 27-dimensional variety that would be a candidate for a partial desingularization of $\\olM_I$ along $\\cN_2$. This is a powerful application of the theory, but its verification is substantial and not detailed in this report."
      }
    ],
    "token_usage": {
      "input": 57278,
      "thinking": 20767,
      "output": 1438
    }
  },
  {
    "entry_id": 153,
    "retraction_id": "1308.2817v2",
    "paper_id": "1308.2817v1",
    "retraction_comment": "The paper has been withdrawn because Eq.(4) is incorrect (isospin CG coefficients have been omitted). The corrected results change some of the discussion for 48Ca while the conclusions for 208Pb are hardly effected. A revised manuscript is under preparation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect isospin-dependent factor in Eq. (4)",
        "Location": "Page 2, Eq. (4) and the paragraph describing its derivation.",
        "Explanation": "The derivation of the factor $\\frac{2T_i-1}{2T_i+1}$ in Eq. (4), which relates $\\hat{\\sigma}_{M1_{\\sigma \\tau}}$ and $\\hat{\\sigma}_{GT}$, appears questionable. The paper states this factor arises from the $1/(2T_f+1)$ term in their definition of $B$-values (Eq. 3) and the fact that $\\hat{\\sigma}_{GT}$ is calibrated for $T_f = T_i-1$ transitions while $M1$ transitions are to $T_f = T_i$ states. If $B \\propto |\\mathcal{M}|^2 / (2T_f+1)$ and the unit cross section $\\hat{\\sigma} \\propto \\sigma/B \\propto (2T_f+1)$, then the ratio $\\hat{\\sigma}_{M1} / \\hat{\\sigma}_{GT}$ should be proportional to $\\frac{2T_i+1}{2T_i-1}$, the inverse of the paper's factor. If this factor is inverted, the extracted $B(M1)$ strength for $^{48}$Ca would change from $3.3 \\,\\mu_N^2$ to approximately $1.996 \\,\\mu_N^2$ (using $B_{new} = B_{old} \\times ( (2T_i-1)/(2T_i+1) )^2$). This would invalidate the main conclusion that the $^{48}$Ca result agrees with the $(e,e')$ experiment and is significantly different from it."
      },
      {
        "Problem": "Inconsistent definitions of B-values for unit cross sections",
        "Location": "Page 2, Eq. (3), Eq. (4), Eq. (5), and surrounding text.",
        "Explanation": "The unit cross section $\\hat{\\sigma}_{GT}$ (Eq. 5) is taken from Sasano et al. [40], which is based on the Taddeucci et al. [36] formalism. This formalism typically uses a standard definition of $B(GT)$ that does not include a $1/(2T_f+1)$ scaling factor. However, the paper's derivation of the relationship between $\\hat{\\sigma}_{M1}$ and $\\hat{\\sigma}_{GT}$ (Eq. 4) explicitly relies on their own definition of $B$-values given in Eq. (3), which includes a $1/(2T_f+1)$ factor. Using $\\hat{\\sigma}_{GT}$ calibrated with one definition of $B(GT)$ to derive $\\hat{\\sigma}_{M1}$ based on a different definition of $B(M1_{\\sigma\\tau})$ (and $B(GT)$) is inconsistent. If standard $B$-value definitions (without the $1/(2T_f+1)$ factor) were used consistently for both GT and M1, the $T_i$-dependent factor in Eq. (4) would likely be absent, leading to $\\hat{\\sigma}_{M1}/\\hat{\\sigma}_{GT} = 1/2$. This would change the extracted $B(M1)$ for $^{48}$Ca to $3.3 \\times \\frac{2T_i-1}{2T_i+1} \\approx 2.57 \\,\\mu_N^2$, which would also challenge the agreement with the $(e,e')$ result."
      },
      {
        "Problem": "Misleading validation of Eq. (4) using $^{12}$C data",
        "Location": "Page 2, paragraph: 'It has been experimentally verified ... for the case of $^{48}$Ca.'",
        "Explanation": "The paper claims Eq. (4) is experimentally verified by a comparison of $(p,p')$ and $(p,n)$ reactions on $^{12}$C [38]. However, Eq. (4) as written is problematic for $T_i=0$ nuclei like $^{12}$C, as it yields $(1/2) \\times (-1/1) = -1/2$. Furthermore, the derivation of the $T_i$-dependent factor in Eq. (4) assumes that $\\hat{\\sigma}_{GT}$ is determined from states with $T_f = T_i-1$. For $^{12}$C ($T_i=0$), the relevant GT transitions (e.g., to $^{12}$N g.s.) are to $T_f=1$ states (i.e., $T_f=T_i+1$). The M1 transition in $^{12}$C (15.11 MeV) is also to a $T_f=1$ state. Thus, the conditions under which the $T_i$-dependent part of Eq. (4) was derived do not apply to $^{12}$C. The $^{12}$C data from Dozono et al. [38] likely only supports the $1/2$ component of Eq. (4) (related to the ratio of $\\tau_z$ vs $\\tau_{\\pm}$ interaction strengths), not the full $T_i$-dependent expression."
      }
    ],
    "token_usage": {
      "input": 9584,
      "thinking": 20626,
      "output": 1215
    }
  },
  {
    "entry_id": 154,
    "retraction_id": "1412.0982v2",
    "paper_id": "1412.0982v1",
    "retraction_comment": "This paper has been withdrawn by the authors. As pointed out to us by [REDACTED-NAME], [REDACTED-NAME] and [REDACTED-NAME], Theorem 3.1 is incorrect, namely, the zero locus should be larger than that in Theorem 3.1. We are sincerely grateful to them for their valuable comments. Nevertheless, the metrics we constructed have positive sectional curvature almost everywhere on the Gromoll-Meyer sphere and on the homotopy (not diffeomorphic) RP^7",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the gradient of F and its squared norm.",
        "Location": "Section 4, Equations (4.2) and (4.3), page 9.",
        "Explanation": "The paper defines a function $F(A) = |c|^2-|d|^2$ on $Sp(2)$. Equation (4.2) gives an expression for its gradient $\\nabla F$ with respect to the metric $g_r$: $\\nabla F|_A=A\\Big(\\begin{smallmatrix} 0&-4\\bar{c}d\\\\ 4\\bar{d}c&0 \\end{smallmatrix}\\Big)$. Equation (4.3) states its squared norm is $|\\nabla F|^2_{g_r}=4(1-F^2)$. \n1. The formula for $\\nabla F$ in (4.2) does not depend on the parameters $r_1, r_2$ of the metric $g_r$, which is highly unlikely for a non-bi-invariant metric. A calculation shows that (4.2) is not the correct gradient of $F$ for the general metric $g_r$ defined in (2.1). For instance, the $y$-component of the gradient (at the identity, for $A$) should be $Y_y$ such that $2\\text{Re}(\\overline{Y_y}y)$ matches the $y$-dependent terms in $dF_A(A\\xi)$. The expression in (4.2) does not satisfy this for arbitrary $r_1, r_2$. \n2. Even if (4.2) were correct, its squared norm under $g_r$ would be $|-4\\bar{c}d|^2 + |4\\bar{d}c|^2 = 16|c|^2|d|^2 + 16|c|^2|d|^2 = 32|c|^2|d|^2$. Equating this to $4(1-F^2) = 4(1-(|c|^2-|d|^2)^2)$ gives $8|c|^2|d|^2 = 1-(|c|^2-|d|^2)^2$. This identity is false (e.g., for $|c|^2=|d|^2=1/2$, it yields $2=1$). These errors invalidate the claim that $F$ is a transnormal function with these properties for $g_r$, and subsequently, the entire conformal deformation argument in Lemma 4.2 and Theorem 4.1, as well as claims about $F$ being isoparametric in Proposition 5.1."
      },
      {
        "Problem": "The claim that $\\nabla F$ is $\\pi$-horizontal is likely incorrect and unsubstantiated.",
        "Location": "Section 4, page 9, paragraph after Eq. (4.2).",
        "Explanation": "The paper states that $\\nabla F$ is 'clearly $\\pi$-horizontal'. For a function $F = f \\circ \\pi$ on the total space $Sp(2)$ of a submersion $\\pi: Sp(2) \\to \\Sigma^7$, its gradient $\\nabla F$ is horizontal if and only if $F$ is constant along the fibers (i.e., $f$ is constant) or by a special geometric configuration. $F$ is invariant under the $\\mathbb{S}^3$-action, meaning $f$ is well-defined on $\\Sigma^7$, but $F$ itself is not necessarily constant along fibers of $\\pi$ if $\\pi$ is different from the quotient map for the action that $F$ is invariant under. More importantly, $F$ is not constant on $Sp(2)$. The gradient $\\nabla F$ being horizontal means its projection to the vertical space is zero. No justification is provided for this claim. If $\\nabla F$ is not horizontal, then $|\\nabla f|^2_{\\tilde{g}_r} = |(\\nabla F)^H|^2_{g_r} < |\\nabla F|^2_{g_r}$ (unless $(\\nabla F)^V=0$). This would affect the statement that $f$ is transnormal on $(\\Sigma^7, \\tilde{g}_r)$ with $|\nabla f|^2_{\\tilde{g}_r}=4(1-f^2)$ if this was derived from $|\nabla F|^2_{g_r}=4(1-F^2)$ and the (incorrect) assumption of horizontality."
      },
      {
        "Problem": "Missing derivation for horizontality conditions in the analysis of zero-curvature planes.",
        "Location": "Section 3, Equations (3.6), (III.1)-(III.3), pages 7-8.",
        "Explanation": "In Section 3, the paper analyzes conditions under which zero-curvature planes in $(Sp(2), g_r)$ project to zero-curvature planes in $(\\Sigma^7, \\tilde{g}_r)$. This requires the plane's spanning vectors $\\xi_1, \\xi_2$ and their Lie bracket $[\\xi_1, \\xi_2]$ to be horizontal with respect to the submersion $\\pi$. For the general case where $A = \\Big(\\begin{smallmatrix} a&b\\\\c&d \\end{smallmatrix}\\Big)$ has $ab \\neq 0$ (Case II.1 and Case III.3), the paper states specific algebraic conditions (e.g., (3.6): $ay_2\\bar{b} \\in \\mathbb{R}$, $ax_1y_2\\bar{b} \\in \\mathbb{R}$, etc., and (III.1)-(III.3)) without derivation. The vertical space is correctly identified in (3.4), but the derivation of these subsequent conditions from the orthogonality with (3.4) (using the metric $g_r$) is omitted. While the conclusions for $a=0$ or $b=0$ (which define $\\Omega_\\pm$) might align with existing literature, the paper's internal logic for dismissing the $ab \\neq 0$ cases relies on these unjustified conditions. This makes the argument for Theorem 3.1 not self-contained and potentially flawed if these conditions are incorrect for the given setup."
      }
    ],
    "token_usage": {
      "input": 21487,
      "thinking": 23056,
      "output": 1403
    }
  },
  {
    "entry_id": 155,
    "retraction_id": "1402.3490v2",
    "paper_id": "1402.3490v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error of the combination rule",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental Misalignment in Handling Non-Exclusive Elements",
        "Location": "Section 3 (Definition 3.1, Definition 3.3) and Section 4 (Example 1, Figure 2)",
        "Explanation": "The theory claims to handle non-exclusive elements in the set $\\Theta$ by relaxing the mutual exclusivity requirement of a Frame of Discernment. However, the D-numbers combination rule (Definition 3.3) employs standard set intersection ($B_1 \\cap B_2 = B$) on subsets of $\\Theta$, where elements of $\\Theta$ are defined as distinct labels ($F_i \\neq F_j$). If elements like 'High' and 'Medium' are distinct in $\\Theta$, their intersection as singleton sets (e.g., $\\{High\\} \\cap \\{Medium\\}$) is the empty set. This leads to the scenario in Example 1 (combining $D_1(High)=1$ and $D_2(Medium)=1$) resulting in $K_D=1$ because $D_1(\\{High\\})D_2(\\{Medium\\})$ would contribute to the sum for $K_D$, making the combination rule's normalization factor $1/(1-K_D)$ undefined. This directly contradicts the paper's stated outcome $D(High \\cap Medium)=1$. The mathematical formalism provided does not support the interpretation of non-exclusive conceptual overlap (as depicted in Figure 2) using standard set operations on distinct labels unless the intersection operator or the nature of $\\Theta$ is fundamentally redefined, which is not done. This undermines a key claimed advantage of the theory."
      },
      {
        "Problem": "Increased Fragility of Combination Rule due to Incompleteness",
        "Location": "Section 3 (Definition 3.3, Equations 13, 14, 15)",
        "Explanation": "The conflict factor $K_D$ in the D-numbers combination rule is defined as $K_{DS} / (Q_1 Q_2)$, where $K_{DS} = \\sum_{B_1 \\cap B_2 = \\emptyset} D_1(B_1)D_2(B_2)$ is the sum of products of conflicting masses, and $Q_1, Q_2$ are the total masses (degrees of completeness) of the D-numbers $D_1, D_2$. If information is incomplete (i.e., $Q_1 Q_2 < 1$), $K_D$ becomes larger than $K_{DS}$. This can cause $K_D \\ge 1$ (making the combination rule's normalization factor $1/(1-K_D)$ undefined or non-positive) even when $K_{DS} < 1$ (a situation where the standard Dempster-Shafer rule would be applicable). Specifically, if all products $D_1(B_1)D_2(B_2)$ correspond to disjoint sets $B_1, B_2$, then $K_{DS} = Q_1 Q_2$, leading to $K_D=1$. This makes the rule highly sensitive to incompleteness when conflict is present, potentially failing more often than the standard DS rule. This significant limitation and its implications for the rule's robustness are not discussed."
      },
      {
        "Problem": "Unjustified and Potentially Counter-Intuitive Aggregation of Incompleteness",
        "Location": "Section 3 (Definition 3.3) and Section 4 (Example 2, and its comparison with DS theory)",
        "Explanation": "The D-numbers combination rule implies that the new degree of completeness $Q_{new}$ is the product of the initial degrees of completeness, i.e., $Q_{new} = Q_1 Q_2$. Consequently, the degree of incompleteness $U = 1-Q$ combines as $U_{new} = 1 - (1-U_1)(1-U_2) = U_1+U_2-U_1U_2$. This specific mathematical model for aggregating incompleteness, which is analogous to calculating the probability of the union of two independent failure events, is presented without explicit justification for its general appropriateness in evidence theory. This can lead to potentially counter-intuitive outcomes; for instance, combining two pieces of incomplete but corroborating evidence (e.g., $D_1(A)=0.5, D_2(A)=0.5$) results in a significantly weaker combined belief ($D(A)=0.25$) and a much larger degree of overall incompleteness ($1-0.25=0.75$). The paper's claim that this handling of incompleteness is 'more natural and reasonable' (Example 2) is not sufficiently substantiated, and this behavior contrasts sharply with other uncertainty management frameworks, potentially limiting its general applicability and the validity of its claimed advantages in handling incomplete information."
      }
    ],
    "token_usage": {
      "input": 10249,
      "thinking": 10536,
      "output": 1081
    }
  },
  {
    "entry_id": 156,
    "retraction_id": "1504.06694v3",
    "paper_id": "1504.06694v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a logical fallacy was made in transition from equation (46) to equations (47)-(50)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified inference of polynomial identity from numerical equality.",
        "Location": "Section 3.1 (page 4) and Section 3.2 (page 4-5), specifically the transition from numerical equations like $6(5)^{n-4} = 5r+25r^2$ to polynomial identities like $\\sum_{k=0}^{n-4} 6 \\cdot |S^{(k)}(n-4)| x^k= 5 \\sum_{k=0}^{\\frac{n}{2}-2} a_k x^k+5^2\\cdot \\sum_{k=0}^{n-4} \\sum_{i+j=k} a_i \\cdot a_j x^{k}$ (Eq. EQ1 in 3.1) and the subsequent coefficient comparison.",
        "Explanation": "The paper derives numerical equations that must hold for $x=5$ (e.g., $6(5)^{n-4} = 5r+25r^2$ where $r$ is an integer). It then assumes that these equations imply corresponding polynomial identities must hold for a variable $x$ (e.g., $6(x)^{n-4} = 5r(x)+25(r(x))^2$ where $r(x) = \\sum a_k x^k$). An equality holding for a specific numerical value $x=5$ does not imply that the equality must hold for all $x$ as a polynomial identity. Therefore, the subsequent step of equating coefficients of powers of $x$ to derive relations for $a_k$ is not justified and forms the main flaw in the proof."
      },
      {
        "Problem": "Incorrect algebraic formulation of the asserted polynomial identity.",
        "Location": "Section 3.1 (Eq. EQ1 and following system of equations) and Section 3.2 (Eq. EQ1 and following system of equations).",
        "Explanation": "Even if assuming a numerical equality implies a polynomial identity (which is Problem 1), the specific polynomial identity chosen by the paper is incorrect. The equation $6(5)^{n-4} = 5r+25r^2$ (where $r$ is an integer representing $s$ in $m=1+10s$ or $m=9+10s$) should translate to $6(x)^{n-4} = x r(x) + x^2 (r(x))^2$ if $x$ were a variable and $r(x)$ a polynomial such that $r(5)=r$. Instead, the paper analyzes $6(x)^{n-4} = 5 r(x) + 25 (r(x))^2$ (and similarly for Section 3.2: $6(x)^{n-4} = 20 + 45 r(x) + 25 (r(x))^2$). This misformulation means that the coefficients $5$ and $25$ (or $20, 45, 25$) are treated as constants independent of $x$, whereas they originate from $x$ and $x^2$ (or constants and $x, x^2$) if $x=5$. This structural error in setting up the polynomial equations invalidates the subsequent analysis of coefficients $a_k$."
      },
      {
        "Problem": "Proof methodology is restricted to even values of n, leaving odd n unaddressed.",
        "Location": "Section 3.1 (page 4) and Section 3.2 (page 5), specifically the definition of $r = \\sum_{k=0}^{\\frac{n}{2}-2} a_k x^k$ and the ensuing statement \"This means that $n$ must be even.\"",
        "Explanation": "The polynomial $r(x)$ representing the integer $r$ is defined as a sum where the upper limit is $\\frac{n}{2}-2$. This limit requires $n$ to be an even integer for it to be an integer itself. The paper explicitly states this restriction. Consequently, the proof method, even if its internal logic were sound, can only apply to even $n \\ge 8$. It does not cover cases where $n$ is odd (e.g., $n=9, 11, \\dots$). Since the Brocard-Ramanujan equation has known solutions for odd $n$ (like $n=5, 7$), and the problem asks for all solutions, a proof that omits infinitely many cases (all odd $n \\ge 9$) cannot be considered complete or conclusive for the general statement that there are no solutions for $n \\ge 8$."
      }
    ],
    "token_usage": {
      "input": 5614,
      "thinking": 18358,
      "output": 1041
    }
  },
  {
    "entry_id": 157,
    "retraction_id": "1502.02090v5",
    "paper_id": "1502.02090v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 3.15",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified vanishing of a term in Lemma 3.9, leading to incorrect conclusion about $\\ud_A^\\ast \\psi_A$",
        "Location": "Page 6, Proof of Lemma 3.9",
        "Explanation": "The proof of Lemma 3.9 claims $\\Pi_1^3([A, F_A^{14}])=0$ by arguing that $\\ast([A\\wedge\\ast\\phi,F^{14}_{A}])=0$. This relies on $[\\ast(A\\wedge\\ast\\phi),F^{14}_{A}]=0$. However, $\\ast(A\\wedge\\ast\\phi)$ being in $\\Lambda^2_7 \\otimes \\mathfrak{g}$ and $F_A^{14}$ in $\\Lambda^2_{14} \\otimes \\mathfrak{g}$ does not guarantee their Lie bracket vanishes when $\\mathfrak{g}$ is non-abelian. If $\\Pi_1^3([A, F_A^{14}]) \\neq 0$, then $\\Pi_1^3(\\ud_A F_A^7) \\neq 0$. This, in turn, implies $\\ud_A^\\ast \\psi_A \\neq 0$ (contrary to the statement after Lemma 3.9, page 6), invalidating subsequent arguments that depend on $\\ud_A^\\ast \\psi_A = 0$, such as the application of the Weitzenböck formula in (3.13) and the derivation of (3.14)."
      },
      {
        "Problem": "Incorrect application or form of the Weitzenböck formula",
        "Location": "Page 7, Equation (3.13)",
        "Explanation": "Equation (3.13) states $\\|\\ud_{A}\\psi_{A}\\|^{2}_{L^{2}}=\\|\na_{A}\\psi_{A}\\|^{2}_{L^{2}}+2\\langle F_{A},\\psi_{A}\\wedge\\psi_{A}\rangle$, assuming $\\ud_A^\\ast \\psi_A=0$ and $Ric=0$. This implies that the curvature term in the Weitzenböck formula (2.1), $\\langle \\ast[\\ast F_{A},\\psi_A], \\psi_A \rangle$, is equal to $2\\langle F_{A},\\psi_{A}\\wedge\\psi_{A}\rangle$. This specific identity, $\\int \\mathrm{Tr}(\\ast[\\ast F_A, \\psi_A]\\wedge \\ast \\psi_A) = 2 \\int \\mathrm{Tr}(F_A \\wedge \\psi_A \\wedge \\psi_A)$, is not standard for general 1-forms $\\psi_A$ in 7 dimensions and requires justification. If this identity is incorrect, equation (3.13) is invalid, and so is (3.14) which leads to the crucial conclusion $\\nabla_A \\psi_A = 0$."
      },
      {
        "Problem": "Use of an incorrect stability condition",
        "Location": "Page 7, Equation (3.15) and its use in the proof of Theorem 1.1",
        "Explanation": "The paper states that $A$ is a 'stability Yang-Mills connection', implying non-negativity of the second variation of the Yang-Mills functional: $0 \\leq \\|\\ud_{A}\\eta\\|^{2}+\\langle F_{A},\\eta\\wedge\\eta\\rangle$ (from (p3), page 3). However, the proof of Theorem 1.1 (page 7-8) uses a different inequality (3.15): $0\\leq\\|\\Pi^{7}_{2}(\\ud_{A}\\eta)\\|^{2}+2\\langle F^{7}_{A},\\eta\\wedge\\eta\\rangle$. This latter condition is related to the stability of the functional $L(A)=\\|F_A^7\\|^2$, not the Yang-Mills functional $YM(A)$. Using this incorrect stability condition invalidates the subsequent deductions, including $\\langle F^{7}_{A},\\psi_{A}\\wedge\\psi_{A}\rangle \\ge 0$ and the argument involving variations of the form $t\\psi_A \\pm t^{3/2}\\omega$."
      },
      {
        "Problem": "Erroneous deduction from a vanishing Lie bracket",
        "Location": "Page 8, Derivation of Equation (3.17) from (3.16)",
        "Explanation": "Equation (3.16) states $[\\ast F^{7}_{A},\\psi_{A}]=0$. With $\\ast F_A^7 = \\psi_A \\wedge \\ast\\phi$, this means $(\\psi_A \\wedge \\ast\\phi) \\wedge \\psi_A + \\psi_A \\wedge (\\psi_A \\wedge \\ast\\phi) = 0$. The paper then claims this implies $\\ast F^{7}_{A}\\wedge\\psi_{A}=0$ (Equation (3.17)), which means $(\\psi_A \\wedge \\ast\\phi) \\wedge \\psi_A = 0$. This deduction is flawed: if $X+Y=0$, it does not imply $X=0$ and $Y=0$ separately. This step would only be correct if, for example, $\\psi_A \\wedge (\\psi_A \\wedge \\ast\\phi)$ was already known to be zero or proportional to the first term with a positive coefficient, which is not established."
      },
      {
        "Problem": "Unjustified identities and contradictory statements in the final step of the proof of Theorem 1.1",
        "Location": "Page 8, Final paragraph of the proof of Theorem 1.1",
        "Explanation": "The argument uses $C(\\ast F^{7}_{A})\\wedge\\psi_{A}-\\ast F^{7}_{A}\\wedge C(\\psi_{A})=0$. It substitutes $C(\\psi_{A})=F^{7}_{A}$. Then it introduces an unjustified identity $\\ast\\ud_{A}\\ast F^{7}_{A}=\\psi_{A}$. This identity is equivalent to $\\mp \\ud_A^\\ast F_A^7 = \\psi_A$. However, earlier arguments (page 5, assuming Lemma 3.9 holds) showed $\\ud_A^\\ast F_A^7 = 0$, which would imply $\\psi_A=0$ and $F_A^7=0$ immediately. If $\\psi_A \neq 0$, this is a contradiction. The subsequent claim $\\|\\psi_{A}\\|^{2}=\\|F^{7}_{A}\\|^{2}$ based on this is unsubstantiated and contradicts the correctly established $G_2$-identity $3\\|\\psi_{A}\\|^{2}=\\|F^{7}_{A}\\|^{2}$ (unless $F_A^7=0$, which is what is being proved). This makes the final conclusion $F_A^7=0$ unsound."
      }
    ],
    "token_usage": {
      "input": 13642,
      "thinking": 20900,
      "output": 1572
    }
  },
  {
    "entry_id": 158,
    "retraction_id": "1611.05964v2",
    "paper_id": "1611.05964v1",
    "retraction_comment": "Algorithm 1 is inefficient since line 2 is processed n 3 times need to be changed There are inconsistent notations throughout the manuscript [REDACTED-NAME] are not defined",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between L-subproblem and its proposed solution in ADMM",
        "Location": "Algorithm 2, steps 6-9 (Page 5); Eq. 28 (Page 5); Sections III.B & III.C (Page 6).",
        "Explanation": "The update rule for the tensor L in Algorithm 2 (specifically steps 6-9, detailed in Sections III.B and III.C) does not correctly solve the stated L-subproblem (Eq. 28) of the ADMM framework. Eq. 28 is a weighted tensor nuclear norm proximal problem. The standard solution involves soft-thresholding the singular values of the input tensor with thresholds scaled by the weights. However, the paper's method first multiplies the singular values by the weights (Eq. 33, Section III.B) and then applies a standard soft-thresholding operator D_tau (Section III.C, Eq. 34-35) to this weight-scaled tensor. This sequence of operations is mathematically different from the correct solution of the proximal operator for Eq. 28. This discrepancy means the algorithm may not be minimizing the stated objective function L_rho in Eq. 27."
      },
      {
        "Problem": "Insufficient iterations and unclear conditions for comparative evaluation",
        "Location": "Section IV, paragraph 2, page 6 ('ten iterations are performed').",
        "Explanation": "The proposed algorithm is run for a fixed 10 iterations. This is a small number for ADMM-based methods, especially those involving reweighting which changes the optimization landscape at each outer loop. No convergence plots or justification for this low number are provided. Furthermore, the paper does not specify the stopping criteria or iteration counts used for the baseline methods (GTNN, TMAC, TC). If baselines were also arbitrarily limited or run under different convergence conditions, the comparison's fairness and validity are questionable, as the reported performance might be from a premature stage of optimization."
      },
      {
        "Problem": "Empirical and insufficiently justified formula for regularization parameter epsilon",
        "Location": "Section III.D, Eq. 36 and subsequent paragraph, page 6.",
        "Explanation": "The weight update rule (Eq. 36) uses a parameter epsilon, which is critical for stability and performance in reweighted schemes. The paper proposes a specific, complex formula for epsilon: 'epsilon = exp(-alpha * P_missing / 0.02)', where P_missing is the percentage of missing entries and 0.02 is a constant. The derivation or justification for this specific functional form and the constant 0.02 is absent. Additionally, no sensitivity analysis regarding the parameter 'alpha' or the constant '0.02' is provided. This lack of analysis makes the method appear heuristic and potentially difficult to generalize or tune for new datasets/scenarios, despite the paper's claim that this choice improves recovery."
      },
      {
        "Problem": "Unspecified threshold parameter `tau` in L-update step of Algorithm 2",
        "Location": "Algorithm 2, step 9 (Page 5); Eq. 34-35 (Page 6).",
        "Explanation": "Algorithm 2, step 9, specifies the L-update as L(k+1) = D_tau[L_tilde(k+1)], where D_tau is the singular value soft-thresholding operator with threshold `tau` (defined in Eq. 34-35). However, the value or method for determining `tau` at this specific step is not specified in Algorithm 2 or its accompanying description. While Eq. 31 suggests a threshold of 1/rho for a related update, it's not explicitly linked to `tau` in step 9 of Algorithm 2. This omission makes a key step of the algorithm incompletely defined and not fully reproducible without assumptions."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 9751,
      "output": 863
    }
  },
  {
    "entry_id": 159,
    "retraction_id": "2206.04913v2",
    "paper_id": "2206.04913v1",
    "retraction_comment": "I really apologize the audience for this withdrawal. The last section has some errors, because the proof of Lemma 4.2 is not true. Also other sections should be improved",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of exactness for the short exact sequence in Lemma 4.2 is flawed, and the sequence itself may not hold for general monomial ideals as used in the paper.",
        "Location": "Lemma 4.2, page 9",
        "Explanation": "The proof of Lemma 4.2 states that $\\mathrm{Im}\\phi = \\mathrm{Ker}\\psi$. For this to hold, specifically for $s=1$ (where $I_m = I_{m-1} + \\langle u_m \\rangle$), it would require that if $w_1 \\in I_m^{t-1}(-d)$ and $u_m w_1 \\in I_{m-1}^t$, then $w_1 \\in I_{m-1}^t(-d)$. This means $w_1 \\in (I_{m-1}^t : u_m)$. So, it requires $(I_{m-1}^t : u_m) \\cap I_m^{t-1}(-d) = I_{m-1}^t(-d)$. This equality relies on $(I_{m-1}^t : u_m) = I_{m-1}^t$, which means $u_m$ is a non-zerodivisor on $R/I_{m-1}^t$. This is not true for arbitrary monomials $u_m$ and monomial ideals $I_{m-1}^t$. Since $u_k$ represent edges (monomials, not necessarily variables), this condition may fail. If Lemma 4.2 is incorrect, then Proposition 4.3, Proposition 4.4 (labelled Theorem2 in the text), and Corollary 4.5 (labelled Corollary2.6 in the text, a main result) which rely on this sequence, are not proven."
      },
      {
        "Problem": "The lower bound for Betti numbers in Theorem 3.7 Part 2, specifically the factor of 'i', is not justified.",
        "Location": "Theorem 3.7 Part 2, page 7",
        "Explanation": "Theorem 3.7 Part 2 claims that if $\\mathcal{H}$ is $d$-uniform and $s$ is the number of self semi-induced matchings of type $(i,j)$, then $\\beta_{i,d(t-1)+j}(R/(I(\\mathcal{H})^t)) \\ge si$ for $t>1$. The proof refers to Part 1, which constructs, for a single self semi-induced matching $\\mathcal{S}=\\{S_1, \\dots, S_i\\}$, $i$ distinct faces $\\tau_\\ell = \\{S_\\ell^{t-1}S_k : 1\\le k \\le i\\}$ for $\\ell=1, \\dots, i$. While these $i$ faces $\\tau_\\ell$ (and their corresponding chain complex elements $\\overline{e_{\\tau_\\ell}}$) are distinct, the proof does not establish that these $i$ elements are linearly independent in homology for a single $\\mathcal{S}$. Furthermore, it does not establish that all $s \\times i$ such elements (arising from $s$ distinct matchings) are linearly independent in homology. Standard results usually provide a lower bound of $s$. The additional factor of $i$ is a strong claim requiring a more detailed proof of linear independence."
      },
      {
        "Problem": "The statement and proof of the unnumbered Proposition before Section 4 are flawed.",
        "Location": "Page 8, before Section 4",
        "Explanation": "The proposition relates the vanishing of certain Betti numbers to the degrees of faces in the complex $\\mathbb{L}^t(I)$. Condition 1 states: 'for each $\\tau \\in \\mathbb{L}^t(I)$ with $\\dim \\tau =s-1$ or $\\dim \\tau = s+1$, we have $\\mathrm{deg}\\tau\\neq r$'. Faces of dimension $s-1$ correspond to basis elements of $F_s$ in the resolution, and faces of dimension $s+1$ correspond to basis elements of $F_{s+2}$. So, condition 1 implies $(F_s)_r=0$ and $(F_{s+2})_r=0$. If $(F_s)_r=0$, then $\\mathrm{Ker}\\overline{\\partial}_s$ in degree $r$ is zero, which means $\\beta_{s,r}(I^t)=0$. This directly contradicts the proposition's conclusion that $\\beta_{s,r}(I^t)\\neq 0$. Furthermore, the proof constructs a face $\\tau'$ with $\\dim \\tau' =s$ and $\\mathrm{deg} \\tau' =r$. This means $e_{\\tau'} \\in F_{s+1}$ and $(F_{s+1})_r \\neq 0$. The argument involving Peeva's Theorem 7.5 about minimality also seems misapplied in this context. The proposition appears to confuse homological degree with face dimensions or misinterprets the implications of the conditions."
      }
    ],
    "token_usage": {
      "input": 34071,
      "thinking": 24824,
      "output": 1150
    }
  },
  {
    "entry_id": 160,
    "retraction_id": "1705.06716v2",
    "paper_id": "1705.06716v1",
    "retraction_comment": "This study needs many major modifications. Majority of the study includes mistakes. For example, all the plots and the numbers that are generated using ALPGEN MC generator in the tables are not correct. In addition, the selected factorization and renormalization scales do not define the correct form of the interaction. Even the title of the study must be changed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Invalid validation of Alpgen for W+jets predictions",
        "Location": "Section 3, discussion related to Table 8 and Figure 3(b); Conclusion (Section 4)",
        "Explanation": "The paper claims Alpgen LO predictions for W+jets at 7 TeV 'match well' with ATLAS data when systematic errors are considered. However, for W+2 jets, Alpgen is 50% higher (approx. 5 sigma discrepancy from ATLAS data), and for W+3 jets, it's 73% higher (approx. 5.5 sigma discrepancy). These large deviations are inadequately acknowledged and misrepresent the generator's performance, undermining the claimed validation of Alpgen for its subsequent W+jets predictions at various energies."
      },
      {
        "Problem": "Unphysical energy dependence in Alpgen Z+jets predictions",
        "Location": "Section 3, Table 9; Conclusion (Section 4)",
        "Explanation": "Alpgen's predictions for Z+jets exhibit unphysical energy dependence for higher jet multiplicities. For example, the Z+4 jets cross section at 14 TeV ($0.94 \\pm 0.28$ pb) is predicted to be significantly lower than at 13 TeV ($1.81 \\pm 0.32$ pb), with their 1-sigma statistical error bands not overlapping. This contradicts expected physics trends of increasing cross sections with energy. The Z+6 jets prediction at 8 TeV is also anomalously low. This questions the reliability of Alpgen for these specific multi-jet predictions."
      },
      {
        "Problem": "Omission of theoretical uncertainties for Alpgen W/Z+jets predictions",
        "Location": "Section 3 (Alpgen predictions); Conclusion (Section 4)",
        "Explanation": "The paper presents W/Z+jets predictions using the LO generator Alpgen without estimating or discussing associated theoretical uncertainties, such as those from renormalization/factorization scale variations or PDF choices (beyond using a single, dated LO PDF). LO predictions are known to have significant dependencies on these choices, and the scales used in Alpgen were also tuned to ATLAS data for specific jet multiplicities. Without quantifying these uncertainties, the robustness of the 14 TeV predictions and claims like '10% more W/Z+jets events' cannot be properly assessed."
      },
      {
        "Problem": "Misleading summary of multi-generator comparison for W+jets in Table 6",
        "Location": "Section 3, discussion of Table 6",
        "Explanation": "When comparing Alpgen (LO), MCFM (NLO), and ATLAS data for W+jets at 7 TeV (Table 6), the paper states that 'Alpgen, MCFM and ATLAS results are close to each other and most of the results are same within the statistical uncertainty.' This statement is incorrect for Alpgen's W+2 jets prediction, which is 50% higher than ATLAS data and deviates by approximately 5 standard deviations of the experimental uncertainty. This misrepresents Alpgen's performance in this initial three-way comparison."
      }
    ],
    "token_usage": {
      "input": 13858,
      "thinking": 11982,
      "output": 686
    }
  },
  {
    "entry_id": 161,
    "retraction_id": "1604.05964v2",
    "paper_id": "1604.05964v1",
    "retraction_comment": "equation no. 16 17 and 18 have flaws, result of which final outage derivation is not converging",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect structure of outage probability derivation",
        "Location": "Eq. (14), Section III.A",
        "Explanation": "The derivation of the primary user outage probability ($P_{OP}$) in Eq. (14) incorrectly separates the expectation $E_{r_1}[E_{r_m|r_1}[\\mathcal{L}_{I_{red,P}}(s)] E_{k}[\\mathcal{L}_{I_{one,S_i}}(s)]]$. It appears to be structured as $1 - E_{r_1,r_m}[\\mathcal{L}_{I_{red,P}}(s)] \\times E_{k,r_1'}[\\mathcal{L}_{I_{one,S_i}}(s')]$, where $s=\\Theta r_1^{\\alpha}$ and $s'=\\Theta (r_1')^{\\alpha}$, implying $r_1'$ is an independent random variable. However, the $r_1$ (distance to the tagged primary BS) that determines $s$ should be the same for both Laplace transforms within the outer expectation $E_{r_1}[\\cdot]$. This structural error likely invalidates Eq. (14) and all subsequent equations (15-18, 23) that depend on it."
      },
      {
        "Problem": "Error in the derived expression for the first integral term after change of variables",
        "Location": "Eq. (16), Section III.A",
        "Explanation": "The first integral term in Eq. (16), which results from integrating with respect to $t$ (distance $r_1$) after a change of variables, contains the factor $(\\beta-1)^{m-1}$. Based on the precursor term $t^{2m}\\beta(\\beta^2-1)^{m-1}$ in Eq. (15) (where $\\beta=r_m/r_1$), the correct factor should be $(\\beta^2-1)^{m-1}$. This discrepancy means a factor of $(\\beta+1)^{m-1}$ is missing, which would significantly alter the numerical results, especially for $m>1$."
      },
      {
        "Problem": "Error in the derived expression for the second integral term after change of variables",
        "Location": "Eq. (16), Section III.A",
        "Explanation": "The second integral term in Eq. (16), resulting from integration with respect to $p$ (another distance variable after change of variables), is given as $\\frac{4d^2\\xi}{(d +\\xi^2)^2}$. The derivation involves an integral of the form $\\int_0^\\infty p^3 \\exp(-B p^2) dp$ with $B = \\pi(\\lambda_S\\xi^2 + \\lambda_P)$. Combined with the constants from Eq. (15) (assuming $(2\\pi\\lambda_S)(2\\pi\\lambda_P)$ or similar), the resulting expression should be $\\frac{2d}{(d\\xi^2+1)^2}$ where $d=\\lambda_S/\\lambda_P$. The expression in the paper has different coefficients and a different denominator structure ($d+\\xi^2$ instead of $d\\xi^2+1$), indicating an algebraic error."
      },
      {
        "Problem": "Error in variable substitution for the second integral",
        "Location": "Eq. (17), Section III.A",
        "Explanation": "In Eq. (17), a substitution (e.g., $1 + \\xi^2/D = \\epsilon$, where $D$ could be $d$ or $d^2$) is used to simplify the second integral from Eq. (16). The resulting expression contains $d^{-\\alpha} \\Theta (\\epsilon-1)^{\\frac{-\\alpha}{2}}$. If this term originates from $\\Theta \\xi^{-\\alpha}$, and $\\xi$ is related to $(\\epsilon-1)^{1/2}$ and $d$ (e.g., $\\xi = \\sqrt{d(\\epsilon-1)}$), then the factor involving $d$ should be $d^{-\\alpha/2}$, not $d^{-\\alpha}$. The numerator of the transformed expression $\\frac{2d^2}{\\epsilon^2}$ also appears inconsistent with the likely starting point from correcting Eq. (16) (e.g. $\\frac{2d}{\\epsilon^2}$ might be expected if starting from $\\frac{2d}{(d\\xi^2+1)^2}$ and using $\\epsilon = d\\xi^2+1$). These errors affect the final outage probability formula."
      },
      {
        "Problem": "Contradiction between system model assumption and simulation parameters",
        "Location": "Section II (System Model) and Section IV (Results)",
        "Explanation": "The system model in Section II states that primary and secondary base stations are distributed with intensities $\\lambda_P$ and $\\lambda_S$ such that $\\lambda_P \\ll \\lambda_S$, which is characteristic of Heterogeneous Networks (HetNets). However, the simulation results in Section IV use a parameter $d=1$. In the derivation (e.g., discussion leading to Eq. (16)), $d$ is defined effectively as the ratio $\\lambda_S/\\lambda_P$. Thus, $d=1$ implies $\\lambda_S = \\lambda_P$, contradicting the core assumption $\\lambda_P \\ll \\lambda_S$. This makes the presented numerical results unrepresentative of the intended HetNet scenario and potentially misleading regarding the performance gains in such systems."
      }
    ],
    "token_usage": {
      "input": 8675,
      "thinking": 15730,
      "output": 1264
    }
  },
  {
    "entry_id": 162,
    "retraction_id": "1010.6286v5",
    "paper_id": "1010.6286v4",
    "retraction_comment": "This paper has been withdrawn by the author due to the map described in Thorem 2.4 is not injective",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Corollary 3.4 regarding homomorphisms from odd-connected Artin groups to RAAGs.",
        "Location": "Page 7, Proof of Corollary 3.4",
        "Explanation": "The proof incorrectly claims that if $\\phi: A \\to \raa{\\Gamma}$ is a homomorphism and $s, t$ are generators of $A$ connected by an odd edge, then $\\langle \\phi(s), \\phi(t) \\rangle$ cannot be isomorphic to $F_2$ because $\\phi$ is a homomorphism. This step is false, as an Artin relation (like $sts=tst$) can be satisfied by elements generating an $F_2$. The subsequent deduction that $\\langle \\phi(s), \\phi(t) \\rangle \\iso \\mathbb{Z}^2$ is therefore unsupported. While the corollary's conclusion (that $\\phi(s)=\\phi(t)$) is a known result for RAAGs, the provided proof has a significant gap because it fails to correctly handle the $F_2$ case or soundly eliminate the $\\mathbb{Z}^2$ case based on the provided arguments. Specifically, the argument should be: (1) $\\langle \\phi(s), \\phi(t) \\rangle$ is $\\mathbb{Z}^2, \\mathbb{Z},$ or $F_2$. (2) The Artin relation for odd $m_{st}$ implies $\\epsilon(\\phi(s)) = \\epsilon(\\phi(t))$. (3) The $\\mathbb{Z}^2$ case is incompatible with the Artin relation (it implies $(m_{st}+1)/2 = (m_{st}-1)/2$, which is false). (4) The $\\mathbb{Z}$ case implies $\\phi(s)=\\phi(t)$. (5) The $F_2$ case also implies $\\phi(s)=\\phi(t)$ in a RAAG (a non-trivial step/citation omitted in the paper)."
      },
      {
        "Problem": "Unsound proof for the corollary stating that a subgroup generated by linearly independent words in a RAAG is itself a RAAG.",
        "Location": "Page 8, Proof of Corollary (unnumbered, follows Definition of Linearly independent subgroups, should be Cor 3.6)",
        "Explanation": "The proof attempts to show that any relation $r(w_1, \\dots, w_n)=1$ among linearly independent words $w_i$ must be a consequence of commutators $[w_i, w_j]=1$. The argument relies on a projection $q_I$ which maps $w_i \\mapsto w_i$ for $i \\in I$ and $w_j \\mapsto 1$ for $j \notin I$. The claim that $q_I$ is a homomorphism is not justified. Furthermore, the statement 'Since $r$ is cycically reduced, there exists some $i \\neq j$ such that $w_i$ and $w_j$ do not commute and $[w_i, w_j] \\subseteq q_{\\{i,j\\}}(r)'$ is unclear, particularly the meaning of $[w_i, w_j] \\subseteq q_{\\{i,j\\}}(r)$. The concluding contradiction '$r = 1 \\neq q_{\\{i,j\\}}(r)$' is also not necessarily true, as $q_{\\{i,j\\}}(r)$ could be 1 if $r=1$. The corollary's statement is a known property of RAAGs, but the proof provided is hand-wavy and contains unjustified steps."
      },
      {
        "Problem": "Incorrect claim that $F_2$ contains $F_k$ for general $k$.",
        "Location": "Page 3, Section 2.1, paragraph starting 'Just using this...'",
        "Explanation": "The paper states: '...we take neighboring pairs $\\langle \\psi_{3j},  \\psi_{3j+1} \\rangle \\iso F_2$ (which contains $F_{k_i}$) ...'. While $F_2$ contains $F_1$ (isomorphic to $\\mathbb{Z}$) and $F_2$, it does not contain $F_k$ for $k > 2$. This mathematical error invalidates the specific construction proposed in that paragraph for embedding RAAGs of the form $\\bigsqcup_{i=1}^m K_{k_i}$ (interpreted as $\\prod F_{k_i}$) if any $k_i > 2$. Although this construction is presented as a preliminary example and later dismissed as insufficient for the paper's main goal, the factual inaccuracy is a flaw."
      }
    ],
    "token_usage": {
      "input": 10081,
      "thinking": 24311,
      "output": 1041
    }
  },
  {
    "entry_id": 163,
    "retraction_id": "0811.2430v4",
    "paper_id": "0811.2430v3",
    "retraction_comment": "The author revised the article and considers that the proof is not rigorous. The main counter-argument is that one should not draw conclusions from a truncated wave-function",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Symmetrization Procedure and Definition of Particle Interchange",
        "Location": "Page 2, discussion of particle interchange below Eq. (6); Page 3, Equations (8) and (9).",
        "Explanation": "The paper defines particle interchange inadequately (e.g., swapping detector outcomes for source-labeled particles like replacing `|D1>L |D2>R` with `|D2>L |D1>R`) rather than swapping particle labels in the quantum state `ψ(x1, x2)` to `ψ(x2, x1)`. Consequently, the construction of symmetric and antisymmetric states in Equations (8) and (9) is flawed. For example, a term like `|D1>L|D'1>R + |D'1>L|D1>R` represents a superposition of two distinct states of the source-labeled particle pair (L,R) – specifically, (particle L in D1 and particle R in D'1) and (particle L in D'1 and particle R in D1) – rather than the correct symmetrization of a single state with respect to the exchange of indistinguishable particles. This fundamentally undermines the derivation of the probabilities in Eqs. (10) and (11)."
      },
      {
        "Problem": "Problematic Initial State Formulation for Indistinguishable Particles",
        "Location": "Page 2, Equation (1).",
        "Explanation": "Equation (1), `|ψ> = 1/2 ( |A> − |A'>)( |B> – e^(iφ)|B'>)`, is presented as the initial state. This represents a product state `|ψ_L>|ψ_R>` where L and R act as distinguishable labels for particles from the two sources. If the particles are truly identical and indistinguishable from the outset, the symmetrization postulate requires the initial state to be explicitly (anti)symmetrized with respect to abstract particle labels (e.g., `N[|ψ_L(1)>|ψ_R(2)> ± |ψ_L(2)>|ψ_R(1)>]`). Starting with an effectively distinguishable product state and then attempting to derive symmetrized components later based on measurement outcomes is a conceptual error that conflates distinguishability by source with fundamental particle identity."
      },
      {
        "Problem": "Assumption of Coherence Between Independent Sources",
        "Location": "Page 2, Equation (1); Page 3, Equations (10), (11).",
        "Explanation": "The derivation, starting from Equation (1) which includes a relative phase `φ` between terms associated with source L and source R, implicitly assumes a stable phase relationship between the two independent particle sources. For truly independent sources, such a phase relationship does not generally exist; their relative phase would be random. This would typically lead to the washing out of the interference fringes predicted in Equations (10) and (11) unless specific measures (e.g., phase-locking the sources, or stringent temporal post-selection as in Hong-Ou-Mandel experiments with independent sources, as discussed in the cited Yurke and Stoler paper) are implemented. The paper does not discuss how such coherence is achieved or maintained."
      },
      {
        "Problem": "Misleading Conception of Symmetrization as a Dynamically Induced Effect",
        "Location": "Abstract (lines 6-9); Page 1, Introduction (last paragraph); Page 4, Section 3 (Discussion, paragraph 1).",
        "Explanation": "The paper repeatedly suggests that the wavefunction *becomes* non-factorizable and (anti)symmetrical 'at-a-distance' as a result of creating a configuration where 'one cannot tell anymore which particle came from which source,' even if the particles never meet. Quantum statistics (symmetrization/antisymmetrization) is a fundamental postulate for identical particles, meaning their joint wavefunction *must* possess the appropriate symmetry if they are indistinguishable. It is not an effect that is dynamically 'produced' or 'agreed upon' by particles due to the experimental setup or their (non-)interaction. The indistinguishability dictates the use of an (anti)symmetrized state from the start, and non-local correlations are then consequences of measurements on such a state."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 9305,
      "output": 941
    }
  },
  {
    "entry_id": 164,
    "retraction_id": "2201.05255v2",
    "paper_id": "2201.05255v1",
    "retraction_comment": "Our definition of the higher Toda brackets is not effective, i.e. not well defined, in the category of pointed spaces",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Failure to establish a key structural property for the defined Toda brackets.",
        "Location": "Introduction (Japanese comment), Lemma 2.3(3), Remark 2.4.",
        "Explanation": "The authors state in the introduction (in Japanese) that a goal of this version was to define brackets such that the property in Lemma 2.3(3) holds, but they did not succeed. Lemma 2.3(3) posits that if an n-fold bracket $\\{f_n,\\dots,f_1\\}_{(m_n,\\dots,m_1)}$ is non-empty, then various lower-order brackets $\\{f_k,\\dots,f_\\ell\\}_{(m_k,\\dots,m_\\ell)}$ (for $n \\ge k > \\ell \\ge 1, (k,\\ell) \ne (n,1)$) must contain 0. The proof attempt for this lemma is incomplete, and Remark 2.4 highlights a specific instance for $n=5$ (namely, whether $\\{f_5,f_4,f_3,f_2\\}$ contains 0 if the 5-fold bracket is non-empty) as unknown. Such properties are often fundamental to the structure and interpretation of higher Toda brackets (e.g., relating to iterated null-homotopies). The failure to establish this property, or its potential falsehood for these definitions, may indicate that the brackets do not behave as commonly expected for higher order operations or that the theory is incomplete in a critical aspect. This could limit the utility or theoretical strength of the proposed bracket systems, even if the other theorems proven in the paper (which do not rely on Lemma 2.3(3)) are technically correct under the given definitions."
      }
    ],
    "token_usage": {
      "input": 58438,
      "thinking": 35661,
      "output": 382
    }
  },
  {
    "entry_id": 165,
    "retraction_id": "1601.01217v3",
    "paper_id": "1601.01217v2",
    "retraction_comment": "There is an important mistake in the definition of the global smoothing operator preserving the presymplectic form",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Sign error in a key formula for the coboundary operator.",
        "Location": "Page 15, Equation (4.7) (Proof of Lemma 4.7)",
        "Explanation": "Equation (4.7) states that $\\delta_1(\\rho - \\sigma)(\\xi_1\\wedge\\xi_2)=\\big[ (\\rho - \\sigma)(\\xi_1) , (\\rho - \\sigma)(\\xi_2)\\big]$. Based on the definition of $\\delta_1$ (Page 9) and the fact that $\\rho$ and $\\sigma$ are Lie algebra homomorphisms, the correct formula should be $\\delta_1(\\rho - \\sigma)(\\xi_1\\wedge\\xi_2)= - \\big[ (\\rho - \\sigma)(\\xi_1) , (\\rho - \\sigma)(\\xi_2)\\big]$. While this sign error is a formal inaccuracy in a significant step of the proof of Lemma 4.7 (which establishes the quadratic convergence crucial for the Nash-Moser scheme), it does not affect the subsequent norm estimate $\\| h_1\\circ \\delta_1 (\\rho - \\sigma)\\|_{k,r} \\leq \\tilde{C} \\| \\rho - \\sigma\\|^2_{k+s+1,r}$, as the norm of a term is the same as the norm of its negative. Thus, this error is unlikely to invalidate the lemma's conclusion or the main theorems."
      },
      {
        "Problem": "Implicit assumption about coordinates for local smoothing operator.",
        "Location": "Page 11 (Proof of Theorem 4.1) and Page 17 (Section 5.1, Proposition 5.2)",
        "Explanation": "The proof of Theorem 4.1 (local rigidity) relies on the SCI-space $\\mathcal{H}$ of local presymplectic vector fields being closed under the smoothing operator $S_t$. This is justified by Proposition 5.2, which states $i_{S_t(X)}\\omega = S_t(i_X\\omega)$. However, Proposition 5.2 holds if the presymplectic form $\\omega$ is constant (i.e., in Darboux form $\\sum dx_i \\wedge dx_{q+i}$) in the coordinates used to define the smoothing operator $S_t$ (typically by convolution of components). If $S_t$ is defined using standard Cartesian coordinates on $\\mathbb{R}^n$ and these are not Darboux coordinates for $\\omega$, then $S_t(f\\alpha) \\neq S_t(f)\\alpha$ for a function $f$ and form $\\alpha$ with non-constant coefficients, and $i_{S_t(X)}\\omega = S_t(i_X\\omega)$ would generally not hold. The Darboux Theorem (Thm 2.3) guarantees the existence of such coordinates around the fixed point 0. The paper should ideally make explicit that all local arguments (including norms and smoothing) are carried out in a chosen Darboux coordinate system where $\\omega$ is constant. This is a standard practice in similar contexts but its omission could lead to misunderstanding. This is more a point of necessary clarification than a flaw that invalidates the conclusion, assuming this standard practice is followed."
      }
    ],
    "token_usage": {
      "input": 48793,
      "thinking": 21610,
      "output": 742
    }
  },
  {
    "entry_id": 166,
    "retraction_id": "1412.3838v2",
    "paper_id": "1412.3838v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the statement according to which the volume element does not depend on the choice of the time orientation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The core claim of independence of the volume element from the auxiliary time orientation $t(x)$ is generally false.",
        "Location": "Section 3, paragraph '2) At a given point x...' and subsequent Remark; Section 4, paragraph '2) At a given point x...' and Remark 1 after Eq. (15); Abstract.",
        "Explanation": "The paper defines the integration domain for the $y$ variables, $\\mathbb{B}_n(x)$, as the unit ball of an auxiliary Riemannian metric $g^t(x) = g_{ij}(x,t(x))$ (in Section 3 for positive definite Finsler metrics) or $g^{t,+}(x)$ (derived from $g^t(x)$, in Section 4 for Lorentzian Finsler spacetimes). For a general Finsler metric $F(x,y)$ where the fundamental tensor $g_{ij}(x,y)$ genuinely depends on $y$, both $g^t(x)$ and $g^{t,+}(x)$ will depend on the choice of the vector field $t(x)$. Consequently, their unit balls $\\mathbb{B}_n(x)$ (which define the integration domain in Eqs. (8) and (14)) will also generally depend on $t(x)$. The integral $\\int_{\\mathbb{B}_n(x)} |\\det(g_{ij}(x,y))| dy$ will therefore depend on $t(x)$, because the domain of integration changes with $t(x)$, and the integrand is a non-trivial function of $y$. This contradicts the paper's central assertion that the proposed volume element $\\mathbf{\\omega}$ is independent of the choice of $t(x)$. The specific cases where $t$-independence is recovered (e.g., pseudo-Riemannian metrics or the Berwald-Moor example) rely on special properties (integrand independent of $y$, or $\\det(g_{ij}(x,y))$ being constant) that do not hold for general Finsler metrics."
      },
      {
        "Problem": "The $hv$-metric $G$ on $TM \\setminus \\{0\\}$ in Section 4 is generally pseudo-Riemannian, not Riemannian.",
        "Location": "Section 4, paragraph introducing the $hv$-metric $G$ before equation $\\Omega^t := \\dots$.",
        "Explanation": "In Section 4, for Finsler spacetimes, the $hv$-metric $G$ is defined as $G = g_{ij}(x,y)dx^i \\otimes dx^j + g_{~ij}^{t,+}(x)\\delta y^i \\otimes \\delta y^j$. Here, $g_{ij}(x,y)$ is the Finsler metric tensor with Lorentzian signature (e.g., $(+---)$), and $g_{~ij}^{t,+}(x)$ is a positive definite Riemannian metric. A block-diagonal metric constructed this way, where one block ($g_{ij}(x,y)$) is pseudo-Riemannian and the other ($g_{~ij}^{t,+}(x)$) is Riemannian, results in $G$ itself being a pseudo-Riemannian metric on $TM \\setminus \\{0\\}$ (e.g., of signature $(+---++++)$ if $n=4$). It is not a Riemannian metric as claimed. While one can still define $\\sqrt{|\\det G|}$, asserting that $G$ is Riemannian is a significant conceptual error in the construction and could lead to incorrect assumptions if properties specific to Riemannian metrics were to be used for $G$."
      },
      {
        "Problem": "The definition of a Finsler spacetime and the regularity assumptions for $L$ and $g_{ij}$ are unclear and potentially inconsistent.",
        "Location": "Section 4, definition of Finsler spacetime.",
        "Explanation": "The paper defines a Finsler spacetime $(M,L)$ such that the Finsler metric tensor $g_{ij} = \frac{1}{2}Hess_y(L)$ is 'well-defined, $\\mathcal{C}^{\\infty}$-smooth and has Lorentzian signature for *almost all* $(x,y)$ with $y \neq 0$'. This implies that $L$ itself may not be $C^2$ (let alone $C^\\infty$) everywhere on $TM \\setminus \\{0\\}$. If $L$ lacks sufficient regularity, $g_{ij}$ and its determinant $\\det(g_{ij})$ may be ill-defined or behave erratically on sets that are not negligible for the proposed integration. The subsequent assumption that '$\\det(g_{ij})$ can still be constructed by continuous extension' where $g_{ij}$ is not defined is a strong condition whose general validity is not discussed. While Remark 2 in Section 4 suggests restricting integration to domains where $g$ is well-defined, the initial definition lacks the precision required for a rigorous foundation, especially concerning the assumed smoothness of $L$ versus the 'almost everywhere' smoothness of $g_{ij}$."
      }
    ],
    "token_usage": {
      "input": 12500,
      "thinking": 16693,
      "output": 1094
    }
  },
  {
    "entry_id": 167,
    "retraction_id": "1301.0396v3",
    "paper_id": "1301.0396v2",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in Lemma 2.9",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed compatibility argument in the proof of the main preservation lemma (Lemma 2.8).",
        "Location": "Page 8, proof of Lemma 2.8, the step claiming 'There is $i < 2^{b(r_k)}$ such that $s'=w_{r_k,i}$'.",
        "Explanation": "The proof aims to show that a condition $q'$ is compatible with some $p_{n(r_k,i),m(r_k,i)}$. The argument relies on $s' = s \\cup (\bigcup \bc_{\\eps(1)} \\cap [0, \\ell_j))$ being equal to one of the $w_{r_k,i}$, where $w_{r_k,i}$ are subsets of $b(r_k) = \\max(c^+_{\\delta,r_k-1})+1$. However, $s'$ is constructed from an arbitrary initial part $s$ of $c(q)$ and initial blocks of $\bc_{\\eps(1)}$. These blocks of $\bc_{\\eps(1)}$ are condensations of blocks of $\bc_\\eps$, which are of the form $c^+_{\\delta,r_m} \\cup c^+_{\\delta,r_{m+1}}$. The integers in $c^+_{\\delta,r_m}$ can be much larger than $b(r_k)$ if $r_m \\ge r_k-1$. Thus, $s'$ is not necessarily a subset of $b(r_k)$ and therefore cannot be assumed to be equal to any $w_{r_k,i}$. This invalidates the subsequent compatibility argument ($p_{n(r_k,i),m(r_k,i)} \\le q'$) as it's based on this specific choice of $i$. This lemma is crucial for establishing property (I5) in the main iteration."
      },
      {
        "Problem": "Insufficient justification for induction hypothesis (I4) in the proof of the Induction Lemma (Lemma 4.2).",
        "Location": "Page 12, proof of Lemma 4.2, case (c), derivation of (I4).",
        "Explanation": "The proof of (I4), which states $\bP_{\beta+1} \\Vdash (s_\beta \not\\subseteq^* R(s_\\gamma))$, argues as follows: Since $\\Phi(\\cU_\\gamma)$ is countably block-splitting (c.b.s.), $R[\\Phi(\\cU_\\gamma)]$ is c.b.s. Therefore, for the block sequence defining $s_\beta$, there exists some $X \\in \\Phi(\\cU_\\gamma)$ such that $R(X)$ splits $s_\beta$. This implies $s_\beta \not\\subseteq^* R(X)$. The proof then concludes $s_\beta \not\\subseteq^* R(s_\\gamma)$ by asserting $s_\\gamma \\subseteq^* \\set(\bc_{\\gamma,\\eps})$ (where $\\set(\bc_{\\gamma,\\eps})$ is presumably related to $X$). The issue is that $s_\\gamma$ is a specific element of $\\Phi(\\cU_\\gamma)$ (the generic real added by $\\M(\\cU_\\gamma)$). The existence of *some* $X \\in \\Phi(\\cU_\\gamma)$ such that $s_\beta \not\\subseteq^* R(X)$ does not imply that this holds for $X=s_\\gamma$. The argument does not establish why $R(s_\\gamma)$ itself must split $s_\beta$, or why $s_\beta \not\\subseteq^* R(s_\\gamma)$ must hold for $s_\\gamma$. Property (I4) is essential for showing that the constructed semifilter $\\cS$ is not comeagre and not ultra by finite-to-one, which are key to the main theorem's claim that SFT fails."
      }
    ],
    "token_usage": {
      "input": 26812,
      "thinking": 19172,
      "output": 853
    }
  },
  {
    "entry_id": 168,
    "retraction_id": "1808.04792v3",
    "paper_id": "1808.04792v2",
    "retraction_comment": "The velocities in the radiative transfer analysis for each snapshot of the simulated collapsing core are a factor of 1.732 (the square root of 3) smaller along each of the three dimensions. This error is currently being rectified",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Overgeneralization of quantitative infall speed underestimation from a highly idealized velocity profile.",
        "Location": "Section 2.1 (Simulation Setup), Section 4.1 (Main Claim: 'This implies that the standard modeling...underestimates...by factors of up to ~3--4'), Section 6 (Conclusions).",
        "Explanation": "The paper concludes that observed infall speeds are systematically underestimated by factors of up to 3-4. This quantitative conclusion is derived from synthetic observations of a velocity profile generated by a spherically symmetric, non-turbulent, non-magnetic, isothermal simulation with specific initial conditions (a small perturbation in a uniform, globally unstable background). The specific characteristics of this 'outside-in' velocity profile (e.g., the radial location and magnitude of peak infall, the density distribution in the envelope) are direct consequences of these idealizations. It is uncertain whether such a specific profile and the resultant large underestimation factors are representative of the diverse conditions and more complex, turbulent velocity fields expected in real low-mass cores. Thus, the general applicability of this quantitative underestimation to all low-mass cores may be overstated."
      },
      {
        "Problem": "The assumption of a strictly isothermal gas may oversimplify the radiative transfer and the interpretation of self-absorption features.",
        "Location": "Section 2.1 (Simulation Setup: 'isothermal, and initially at rest, with a uniform density...and a kinetic temperature, Tk = 11.4 K'), Section 5.1 (Self-absorption discussion), Figure 10b.",
        "Explanation": "The model assumes a constant kinetic temperature (11.4 K) throughout the collapsing core. This influences the excitation conditions and opacities. The paper argues that self-absorption is primarily due to low-velocity, high-opacity material near the core center. However, real prestellar cores can exhibit temperature gradients, with outer regions potentially being cooler than the center, especially as collapse progresses. Such temperature gradients, neglected in the isothermal model, could lead to significant absorption by cooler, outer infalling gas, altering the line profile shapes (e.g., the depth and width of the self-absorption dip, Tb/Tr ratios) and consequently affecting the inferred infall velocities. This simplification could impact the conclusion that the observed subsonic speeds are solely an artifact of the velocity profile's density weighting."
      },
      {
        "Problem": "The crucial role of the 'uniform, globally gravitationally unstable background' in driving the specific collapse dynamics limits the generalizability of the findings.",
        "Location": "Section 2.1 (Simulation Setup: 'uniform density', 'entire numerical box is Jeans-unstable'), Section 1.1 (Paper I description).",
        "Explanation": "The simulation's initial condition of a small density perturbation embedded in a uniform, globally unstable background is a highly specific scenario. This background actively collapses and feeds the central core, defining the 'outside-in' flow with extended infall motions and cloud-to-core accretion. While this may represent certain 'conveyor-belt' environments, many low-mass cores are thought to form via turbulent fragmentation or other mechanisms within structured, non-uniform molecular clouds that may not feature such a globally unstable, uniform feeding zone. The resulting velocity field and the extent of the 'infalling envelope' are strongly tied to this idealized background. Therefore, conclusions drawn about infall signatures and speed underestimation might not apply broadly to cores forming in more complex and diverse astrophysical environments where the driving mechanism for collapse and accretion differs significantly."
      },
      {
        "Problem": "The complete neglect of turbulence may render the simulated velocity field and emergent line profiles unrepresentative of real, turbulent prestellar cores.",
        "Location": "Abstract ('without a turbulent component'), Section 5.1 (discussion of Z92), Section 5.5 (discussion of P10).",
        "Explanation": "The simulation is explicitly non-turbulent. However, prestellar cores are observed to possess significant non-thermal motions, typically interpreted as turbulence. Turbulence can (a) fundamentally alter the core's density and velocity structure, potentially disrupting the smooth, spherically symmetric 'outside-in' profile seen in the simulation; (b) introduce additional velocity components along the line of sight, directly affecting line broadening, peak intensities, and asymmetry parameters (e.g., Delta_v_thin in delta_v); and (c) create density inhomogeneities that affect radiative transfer. While the paper argues its non-turbulent model can explain some observations (e.g., P10), the absence of this key physical ingredient makes it difficult to assess whether the derived systematic underestimation of infall speeds would hold in realistic, turbulent cores where the interplay between ordered infall and chaotic motions shapes the line profiles."
      }
    ],
    "token_usage": {
      "input": 37082,
      "thinking": 8169,
      "output": 1021
    }
  },
  {
    "entry_id": 169,
    "retraction_id": "1306.2988v2",
    "paper_id": "1306.2988v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The result claiming a factor 0.56 algorithm is invalid because of a crucial bug in Claim 2 which was brought to our attention by [REDACTED-NAME], [REDACTED-NAME], and [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially unsound pivotal lemma (Lemma 7) for LP formulation",
        "Location": "Page 6, Lemma 7 (proof sketch on Page 6); LP constraint (3) on Page 7",
        "Explanation": "The proof of Lemma 7, which relates non-monotone events ($\\Gamma$) to good events ($Good_1, Good_2$), is critical for the main result. The derivation, particularly the term $\\frac{n \\sum_{s \\leq t} g_s}{t}$, involves mappings between different permutation spaces ($\rho, \rho', \rho''$) and unclear counting/overcounting arguments. For example, it's not clear how $\\sum_{\rho} Good_k(t, \rho')$ (sum over one set of permutations) is related to $\\sum_{\rho} Good_k(t, \rho)$ (sum over a different set or all permutations) or the averaged $h_t$ and $g_s$ variables. If this lemma is incorrect, the LP formulation and the claimed 0.56 factor are undermined."
      },
      {
        "Problem": "Potentially flawed proof of LP scaling (Lemma 9 / LP-OPT)",
        "Location": "Page 8, Lemma 9; Appendix, Pages 12-14, specifically Claim labeled 'claim:gamma' (proof of LP constraint (3) for scaled variables) on page 13.",
        "Explanation": "Lemma 9, stating $\\text{LP-OPT}(k) \\leq \\text{LP-OPT}(n)$, allows generalizing results from $LP(400)$ to any $n$. Its proof in the appendix (Claim for constraint (3)) seems to incorrectly handle the averaging of the term $\\frac{n}{s} \\sum_{t \\leq s} g_t^n$. The derivation appears to replace $1/s$ with an average like $1/n$ or make approximations (e.g., $\\sum_{s:\\lfloor s/q \\rfloor = i}  \\sum_{t \\leq s} g^n_t / (qn)$ instead of $\\frac{1}{q} \\sum_{s:\\lfloor s/q \\rfloor = i} \\frac{n}{s} \\sum_{t \\leq s} g_t^n$) that may not hold, especially for small $s$ (i.e., small $i$). An error here would mean the $0.56$ factor is not proven for general graphs."
      },
      {
        "Problem": "Unclear or potentially flawed proof for the general randomized upper bound (Theorem 3)",
        "Location": "Page 8, Theorem 3; Appendix, Page 15",
        "Explanation": "The proof for the $19/24 \\approx 0.7916$ upper bound on any randomized algorithm relies on Yao's Lemma for a 4-vertex graph $H$. The argument for the case where the first queried edge is a non-edge is confusing. For instance, the claim 'if the first edge ... is not present then it will imply that there is an edge connecting the other pair of vertices' is not true for the specified graph $H$. This makes the subsequent probabilistic calculation for this branch suspect, potentially invalidating the claimed $19/24$ bound."
      },
      {
        "Problem": "Inconsistent or flawed explanation in the proof of Lemma 12 (Claim 15) for the 0.75 VI upper bound",
        "Location": "Page 10, Lemma 12; Appendix, Page 16, Claim labeled 'claim:v in c' and Figure 7",
        "Explanation": "The proof of Lemma 12, analyzing the \\rr~algorithm on graph $\\Gamma$, provides a confusing explanation in Claim 'claim:v in c' and Figure 7 for the case when the chosen vertex $v$ is from the clique $C$. The description of $v$'s actions (e.g., $v$ causing another $P$-vertex to be 'revealed', or $v$ acting after being matched in Figure 7) is inconsistent with the standard greedy \\rr~algorithm and the structure of graph $\\Gamma$ (where $v \\in C$ is only adjacent to its partner $v^* \\in P$ and other vertices in $C$). While the $0.75$ factor might be correct, the provided reasoning is flawed."
      },
      {
        "Problem": "Potentially weak argument for simulating VI algorithms with revealing-algorithms (Lemma 11)",
        "Location": "Page 9, Lemma 11; Appendix, Page 15",
        "Explanation": "The proof of Lemma 11 argues that a deterministic 'revealing-algorithm' (${\\mathcal A}$) performs at least as well as an optimal deterministic vertex-iterative algorithm (${\\mathcal O}$). The simulation rule states that if ${\\mathcal O}$ queries an edge involving a vertex already inactive by ${\\mathcal A}$'s rules, ${\\mathcal A}$'s current vertex 'immediately gives up.' This 'giving up' strategy might be suboptimal if ${\\mathcal O}$ could have found a match. The argument does not sufficiently establish that ${\\mathcal A}$'s performance is non-inferior under all circumstances, which is crucial for the 0.75 upper bound for VI algorithms."
      }
    ],
    "token_usage": {
      "input": 24720,
      "thinking": 15178,
      "output": 1194
    }
  },
  {
    "entry_id": 170,
    "retraction_id": "1901.07086v3",
    "paper_id": "1901.07086v2",
    "retraction_comment": "The claim of Main Theorem 1 is wrong. The prime counting function on the complex plan does not satisfy the inequality. The prime number Theorem contradicts the claim",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misapplication of Proposition 7 (Generalized Bertrand's Postulate for integers)",
        "Location": "Proof of Main Theorem, Case I, Page 4 (sentence: \"So, from proposition~\\ref{prop7} we can say that there exist at least $(k-1)$ many primes between ${z_1}^2+{z_2}^2$ and ${(kz_1)}^2+{(kz_2)}^2$.\")",
        "Explanation": "Proposition 7 states that for $n \\ge f(k)$, there are at least $(k-1)$ primes in the interval $[n, kn]$. The paper applies this to the interval of squared norms $[N, k^2N]$ (where $N=z_1^2+z_2^2$). If Proposition 7 were applicable, it would imply at least $(k^2-1)$ primes (if $N \\ge f(k^2)$), not $(k-1)$ primes. The argument incorrectly maps the structure of Proposition 7 to the interval of norms, invalidating the claimed number of primes."
      },
      {
        "Problem": "Unjustified assumption that identified Gaussian primes lie on the specific line segment",
        "Location": "Proof of Main Theorem, Case I, Page 4 (sentence: \"So, there are at least $\\frac{k-1}{2}$ Gaussian primes between the gap$[(z_1,z_2), (kz_1,kz_2)]$ for all $k\\geq2$.\")",
        "Explanation": "The proof attempts to count rational primes $p$ whose norms fall in a certain range, and then selects those $p \\equiv 1 \\pmod 4$ to correspond to Gaussian primes $a+bi$ (where $a^2+b^2=p$). However, there is no justification or argument provided to show that these Gaussian primes $a+bi$ must lie on the specific line segment defined as the \"gap\" $[(z_1,z_2), (kz_1,kz_2)]$. The theorem's conclusion is about primes *on this segment*, but the proof does not establish this location property."
      },
      {
        "Problem": "Incorrect statement in the definition of Gaussian Primes",
        "Location": "Definition 2.1 (labelled as Definition \\ref{gprime}), part (2), Page 2.",
        "Explanation": "Part (2) of the definition states: \"If $a=0$, then $bi$ is a Gaussian prime iff $|b|$ is an ordinary prime and $|b|\\equiv1\\pmod{4}$.\" This is incorrect. If $|b|$ is an ordinary prime and $|b| \\equiv 1 \\pmod 4$, then $|b|$ splits in $\\mathbb{Z}[i]$ (e.g., $5=(1+2i)(1-2i)$), so $bi$ (where $|b|=5$) is not a Gaussian prime. For $bi$ to be a Gaussian prime (when $a=0$), $|b|$ must be an ordinary prime such that $|b| \\equiv 3 \\pmod 4$. This foundational error affects arguments concerning primes on the axes (Case II of the main theorem)."
      },
      {
        "Problem": "Misuse of Chebyshev's Bias for a strict lower bound",
        "Location": "Proof of Main Theorem, Case I and Case II, Pages 4-5.",
        "Explanation": "Chebyshev's Bias describes an asymptotic tendency for primes to be distributed among residue classes (e.g., $\\pi(x;4,1) \\sim \\pi(x;4,3)$). The paper uses this to claim that if there are $M$ primes in an interval, then a specific fraction (e.g., half) of them will belong to a particular residue class, yielding a strict lower bound like \"$\\frac{k-1}{2}$ many complex Gaussian primes\". This is an invalid application of an asymptotic result to deduce a rigorous lower bound for a finite, potentially small, number of primes."
      },
      {
        "Problem": "The role and justification of the condition $\\gcd(z_1, z_2) = f(k)$ are unclear in relation to Proposition 7's requirements",
        "Location": "Main Theorem statement (Page 4) and its proof (Page 4).",
        "Explanation": "Proposition 7 requires its starting point $n$ to satisfy $n \\ge f(k)$ (for an interval $[n, kn]$). The main theorem imposes the condition $\\gcd(z_1, z_2) = f(k)$. In Case I, the argument effectively uses $N = z_1^2+z_2^2$ as the starting point for an interval of norms. The connection between the condition $\\gcd(z_1, z_2) = f(k)$ and ensuring that $N$ satisfies the hypothesis $N \\ge f(K_{effective})$ (where $K_{effective}$ would be $k^2$ for the interval $[N, k^2N]$ used in the proof) is not established or explained. This makes the applicability of Proposition 7 (even if its interval structure were correctly applied) questionable."
      }
    ],
    "token_usage": {
      "input": 7975,
      "thinking": 9561,
      "output": 1160
    }
  },
  {
    "entry_id": 171,
    "retraction_id": "2204.01118v2",
    "paper_id": "2204.01118v1",
    "retraction_comment": "In the proof of Theorem 5, page 10, line 1O, a term was missing in the r.h.s, that is \\|f''\\|_p^p",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of the finite difference operator $\\Delta_h$.",
        "Location": "Notation section (definition of $\\Delta_h$) vs. Equation (1) and Lemma 3 (Section 9.1).",
        "Explanation": "The Notation section defines $(\\tau_hf)(x):= f(x+h)-f(x)$ and then $\\Delta_hf:=\\tau_{-h}f-f$, which implies $\\Delta_h f(x) = (f(x-h)-f(x)) - f(x) = f(x-h)-2f(x)$. However, Equation (1) presents the formula for the $m$-th power of the standard forward difference operator, i.e., $(\\Delta_h^mf)(x)= \\sum_{k=0}^m \\binom{m}{k} (-1)^{m-k} f(x+kh)$, which corresponds to a first difference $\\Delta_h f(x) = f(x+h)-f(x)$. The proof of Lemma 3 also implicitly uses this standard forward difference. This fundamental inconsistency makes any results relying on $\\Delta_h$ (like Lemma 3, Lemma 4, and Theorem 8) ambiguous or based on an operator different from the one initially defined."
      },
      {
        "Problem": "Flawed argument in the proof that a function $g$ does not belong to $W^m_p(\\R^n)$ under certain homogeneity conditions.",
        "Location": "Appendix, Proof of Proposition 8 (referred to as Lemma 1 in the main text), specifically the second part concerning $g \\notin W^m_p(\\R^n)$. The critical step is the choice of the multi-index $\\alpha$.",
        "Explanation": "To prove $g = \\varphi F \\notin W^m_p(\\R^n)$ (where $F$ is homogeneous of degree $\\lambda \\notin \\N$, $\\varphi(0)\\neq 0$, and $\\lambda \\leq m-(n/p)$), the argument aims to show that $\\varphi F^{(\\alpha)} \\notin L_p(\\R^n)$ for some suitable multi-index $\\alpha$. The proof selects $\\alpha$ such that $\\lambda - n/p \\leq |\\alpha| < \\lambda - n/p + 1$. This implies the homogeneity degree of $F^{(\\alpha)}$, $d = \\lambda-|\\alpha|$, satisfies $n/p-1 < d \\leq n/p$. For $\\varphi F^{(\\alpha)}$ to not be in $L_p$ near the origin, $d$ must satisfy $dp+n \\leq 0$. However, the chosen range for $d$ leads to $dp+n \\in (2n-p, 2n]$. For typical $n,p$ (e.g. $2n>p$), this interval is positive, meaning $\\varphi F^{(\\alpha)}$ would be in $L_p$ near the origin, contradicting the desired conclusion. This lemma is foundational for Proposition 9 and subsequently Theorem 1 (Dahlberg theorem)."
      },
      {
        "Problem": "Insufficient justification for the norm estimate of $\\theta_j$ in Lemma 2 for the case $m=n/p, p>1$.",
        "Location": "Section 9.1, Proof of Lemma 2, the argument for $m=n/p$ and $1<p<+\\infty$.",
        "Explanation": "The proof constructs $\\theta_j(x) := \\frac{1}{j}\\sum_{k=1}^{j}\\rho(2^kx)$ and estimates its $W^m_p$-norm. The calculation of $\\|\\theta_j^{(\\alpha)}\\|_p^p$ involves a sum of integrals over disjoint annuli $S_k := 2^{-k+1} Q\\setminus 2^{-k}Q$. The proof claims that for $x \\in S_k$, $|\\theta_j^{(\\alpha)}(x)|=\\frac{1}{j}2^{mk}|\\rho^{(\\alpha)}(2^kx)|$. This implies that for $x \\in S_k$, only the $l=k$ term in the sum $\\theta_j^{(\\alpha)}(x)=\\frac{1}{j}\\sum_{l=1}^{j} (2^l)^m \\rho^{(\\alpha)}(2^l x)$ is non-zero. Given that $\\rho(x)=1$ on $Q=[-1/2,1/2]^n$ and $\\mathrm{supp}\\,\\rho \\subset 2Q$, the supports of the individual terms $\\rho^{(\\alpha)}(2^l x)$ are not structured in a way that trivially simplifies the sum to a single term when $x \\in S_k$. The argument provided is too sketchy and does not adequately justify this simplification, which is crucial for the subsequent norm estimate. While the final estimate for $\\|\\theta_j\\|_{W^m_p}$ is a known result for such constructions, the proof steps given are problematic."
      }
    ],
    "token_usage": {
      "input": 18371,
      "thinking": 23524,
      "output": 1142
    }
  },
  {
    "entry_id": 172,
    "retraction_id": "2001.10956v2",
    "paper_id": "2001.10956v1",
    "retraction_comment": "The second equation (2.22) is incorrect. The follow-up of the correct equation demands new developments, which I shall provide in a new version soon. wh",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Lemma 3.2 appears flawed.",
        "Location": "Page 6, Lemma 3.2",
        "Explanation": "The proof of the first part of Lemma 3.2 estimates an integral involving a Schwartz function $h(Y_1, Y_2)$ by analyzing $\\int (ax^2-2bx+c)^{\\alpha-1}dx$. This implicitly treats $h(Y_1, Y_2)$ as if it were $(Y_1^2+Y_2^2)^{\\alpha-1}$. However, for $0 < \\alpha < 1/2$, the function $(Y_1^2+Y_2^2)^{\\alpha-1}$ is not a Schwartz function as it is singular at the origin and does not decay rapidly if $\\alpha-1$ is not a large negative integer. A bound for an integral of a Schwartz function should rely on its rapid decay properties, e.g., $|h(Y_1,Y_2)| \\le C_K (1+Y_1^2+Y_2^2)^{-K}$ for any $K$. The lemma's conclusion might hold via other arguments (e.g. integration by parts involving $e^{2i\\pi x}$), but the provided proof is unsound."
      },
      {
        "Problem": "The crucial estimate for $I_{n,m}(-4\\pi^2\\E^2 h^q)$ in the proof of Proposition 3.1 is not adequately justified.",
        "Location": "Page 7, End of proof of Proposition 3.1, around eq. (3.22)",
        "Explanation": "The proof of Proposition 3.1 relies on bounding terms $I_{n,m}((\\E^2 h)^q)$. Equation (3.22) gives $I_{n,m}(-4\\pi^2\\E^2 h^q) = -\\frac{4\\pi^2q^2}{m^2} I_{n,m}(\\{ K_1 h \\}^q) + \\text{lower order term}$. Assuming Lemma 3.2 provides a bound of $C a^{-\\alpha}$ for $I_{n,m}(\\{ K_1 h \\}^q)$ (where $a = \\frac{m^2}{q^2}+q^2n^2$), the main term is bounded by $C \\frac{q^2}{m^2} a^{-\\alpha}$. The paper then states this is bounded by $a^{-1-\\alpha}$ 'after one has taken advantage of the possibility to exchange $m$ and $n$'. This step is critical for the convergence of the sum $\\sum I_{n,m}$ to obtain the desired overall bound in Prop 3.1. However, the mechanism for this 'exchange' to effectively neutralize the $q^2/m^2$ prefactor (or replace it with $1/a$) is not provided or justified. If this step is incorrect, the bound for $I_{n,m}((\\E^2 h)^q)$ would be $C \\frac{q^2}{m^2} a^{-\\alpha}$, which can be large (e.g., $O(q^{2-2\\alpha})$ if $m$ is small and $q$ is large) and would likely invalidate the conclusion of Proposition 3.1."
      },
      {
        "Problem": "Potential mismatch in the required decay for $I_{1,0}((\\E^2 h)^q)$ and $I_{0,1}((\\E^2 h)^q)$ for small $q$.",
        "Location": "Page 7, Proof of Proposition 3.1, discussion of $n=0$ or $m=0$ terms, and Page 8, final summation argument.",
        "Explanation": "The paper states that $q I_{0,1}(h^q)$ and $q I_{1,0}(h^q)$ remain bounded (for $h \\in (\\pi^2\\E^2)\\mathcal{S}(\\R^2)$), implying $I_{0,1}(h^q), I_{1,0}(h^q)$ are $O(1/q)$. The overall bound sought for $\\sum I_{n,m}(h^q)$ (where $h = (\\E^2 \\tilde{h})$) is $O(q^{-1}(q+q^{-1})^\\epsilon)$. For small $q$, this is $O(q^{-1-\\epsilon})$. An $O(1/q)$ behavior for individual terms is $O(q^{-1})$. This is consistent if $\\epsilon=0$. However, the final step of the proof of Prop 3.1 requires $\\sum a^{-1-\\alpha} \\le C q^{-1}(q+q^{-1})^{\\epsilon}$. The paper shows $(q^2+q^{-2})^{(\\epsilon-1)/2} \\le q^{-1}(q+q^{-1})^\\epsilon$. For small $q$, LHS is $q^{1-\\epsilon}$ and RHS is $q^{-1-\\epsilon}$. The inequality $q^{1-\\epsilon} \\le q^{-1-\\epsilon}$ holds for small $q$. This part seems correct. The main issue remains the $a^{-1-\\alpha}$ bound for $mn \\neq 0$ terms."
      }
    ],
    "token_usage": {
      "input": 21310,
      "thinking": 22593,
      "output": 1191
    }
  },
  {
    "entry_id": 173,
    "retraction_id": "1407.6492v2",
    "paper_id": "1407.6492v1",
    "retraction_comment": "This paper has been withdrawn by the main author due to the Table 1 and equation 2 errors",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Critical Ambiguity and Inconsistency in Feature Definitions",
        "Location": "Section 2 (Feature Extraction), specifically Sections 2.1 (Angle Features), 2.2 (Distance Feature), and 2.3 (Transit Feature)",
        "Explanation": "The definitions of the three core features (angle, distance, transit) are critically ambiguous, inconsistent, and lack sufficient detail for replication. \n1. Angle Feature (Sec 2.1): The term 'angle of white pixel to block horizontal level' is undefined; it's unclear how θk is calculated, what the reference points are, or whether it pertains to contour pixels (mentioned in Sec 2 intro), 'white pixels' (Sec 2.1), or foreground pixels. \n2. Distance Feature (Sec 2.2): The description is contradictory, referring to 'distance of white pixel' and then 'Euclidean distances from foreground pixel'. The 'agent point of block' is undefined, and the reference for distance measurement (e.g., 'left and bottom coroner of block') is vague. \n3. Transit Feature (Sec 2.3): The feature is described as a 'ratio' of Run Length Counts, but the specific ratio (e.g., horizontal RLC / vertical RLC, or sum of RLCs normalized by some factor) is not defined. \nThis lack of clarity and consistency in defining the fundamental features makes the proposed method irreproducible and its soundness difficult to assess."
      },
      {
        "Problem": "Major Inconsistency in Reported Test Dataset Size",
        "Location": "Abstract (page 1), Section 3 (page 4, paragraph 1), and Table 1 (page 4)",
        "Explanation": "There is a significant and unexplained discrepancy in the reported size of the test dataset. The abstract and the main text (page 4, first paragraph of Section 3) state that for one experiment, 15,000 samples were used for training and 5,000 samples for testing, achieving 99.82% accuracy. The text also mentions a total dataset of 20,000 samples for cross-validation. However, Table 1 (page 4) lists the test set size for 'Our proposed method' (achieving 99.82%) and 'Our proposed method With 4 subset' (achieving 99.90%) as 50,000 samples. This is a tenfold increase from the 5,000 test samples mentioned elsewhere and exceeds the stated total dataset size of 20,000 used for experiments. This major inconsistency makes it impossible to ascertain the true scale of the evaluation and casts serious doubt on the reliability and comparability of the reported performance figures."
      },
      {
        "Problem": "Misleading Presentation of Performance on Training Data",
        "Location": "Section 3 (page 4, paragraph 1) and Table 1 (page 4)",
        "Explanation": "The paper presents accuracy on the training data in a potentially misleading manner. It states, 'From the experiment, we got an accuracy of 100% when the 20,000 data were used as training and the same data set was used for testing.' While testing on training data can be a sanity check, reporting this 100% accuracy as a key experimental result is misleading because it does not reflect the model's generalization performance on unseen data. Furthermore, Table 1 includes a 'Train Acc' column where 'Our proposed method' and 'Our proposed method With 4 subset' are listed with 100% accuracy. Presenting this training set accuracy alongside test accuracies for other methods, without strong caveats, can inflate the perceived performance of the proposed method, as it's not a standard measure of generalization capability."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 4960,
      "output": 834
    }
  },
  {
    "entry_id": 174,
    "retraction_id": "1802.06370v4",
    "paper_id": "1802.06370v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial explanation error of redundancy",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misleading claim about \"producing the same equation of motion\"",
        "Location": "Abstract (line 3), Introduction (e.g., p.1 para 1, p.2 para 2, p.2 para 4), Section 5 Concluding summary (para 1)",
        "Explanation": "The paper repeatedly claims that the derived Hamiltonians (and Lagrangians) produce the 'same equation of motion' as the standard one (e.g., Eq. 1.2: $\\ddot{x}=-\\frac{1}{m}dV(x)/dx$). However, the constructed Hamiltonians $H_j$ are functions of the standard Hamiltonian $H_N$ (i.e., $H_j = f_j(H_N)$). Such Hamiltonians are known to generate the same phase-space trajectories as $H_N$, but with a re-parameterized (scaled) time $t_j$, where $dt_j/dt_0 = 1/f_j'(H_N)$. The equation $m\\ddot{x}=-dV/dx$ is only recovered with respect to this new time $t_j$. Stating that they produce the 'same equation of motion' without consistently clarifying that this refers to a rescaled time is misleading, as it implies $m d^2x/dt_0^2 = -dV/dx$ for the flow of $H_j$ using the original time $t_0$, which is not true. While Remark 5 and Section 4 touch upon time rescaling, the dominant claim throughout the paper is stronger and potentially incorrect if interpreted strictly."
      },
      {
        "Problem": "Incorrect general condition for Hamiltonians in the concluding summary",
        "Location": "Section 5, Concluding summary, page 13, the equation: $\\mathcal F^\\prime -\\dot p=\\dot p\\frac{\\partial H}{\\partial p}+\\frac{p}{m}\\frac{\\partial H}{\\partial x}$",
        "Explanation": "The paper concludes that 'for every function $\\mathcal F^\\prime=-dV(x)/dx$ there exist infinite Hamiltonians of equation $\\mathcal F^\\prime -\\dot p=\\dot p\\frac{\\partial H}{\\partial p}+\\frac{p}{m}\\frac{\\partial H}{\\partial x}$'. If $\\dot p$ here refers to $\\dot p_H = -\\partial H/\\partial x$ (the momentum rate from Hamiltonian $H$), this equation becomes $\\mathcal F^\\prime = (\\partial H/\\partial x) [ (p/m) - (\\partial H/\\partial p) - 1 ]$. This condition is not generally satisfied by the Hamiltonians derived in the paper, such as $H_1 = C e^{k H_0}$. For this equation to hold, it would require specific, non-general conditions on $H_0$ or the constants. Thus, presenting this as a general equation satisfied by the 'infinite Hamiltonians' seems incorrect and undermines the summary of the findings."
      },
      {
        "Problem": "Error in the harmonic oscillator example for the Lagrangian hierarchy",
        "Location": "Section 4, page 12, Eq. (3.10) and surrounding text",
        "Explanation": "In the harmonic oscillator example, it is stated that the $k$-th Lagrangian $L_k$ in the hierarchy (derived from the series expansion of $L_\\lambda$) yields the equation of motion $d^2x/dt_k^2 = -(k/m)x$. The text specifies '$k=1,2,3,...$' referring to the index of $L_k$. If $k$ is indeed the summation index, this implies that different $L_k$ components yield equations of motion with different effective 'spring constants' or masses (scaled by $k$). This contradicts the expectation that each $L_k$, in its respective time $t_k$, should describe the same physical harmonic oscillator, i.e., $m d^2x/dt_k^2 = -(K_0/m)x$, where $K_0$ is the fixed spring constant of the system. This suggests an inconsistency in how the Lagrangian hierarchy relates to the physical system's EOM."
      }
    ],
    "token_usage": {
      "input": 28694,
      "thinking": 23804,
      "output": 955
    }
  },
  {
    "entry_id": 175,
    "retraction_id": "1403.0340v2",
    "paper_id": "1403.0340v1",
    "retraction_comment": "This paper has been withdrawn by the author because of Projection measurement tacit usage (while generalized one should have been used)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and normalization of stochastic qubit/qudit basis states derived from Generalized Coherent States (GCS).",
        "Location": "Eq. (7), Eq. (11), Eq. (13), tables in Section 3 (comparison between $J=1/2$ and $J=3/2$ cases), and subsequent use in Sections 4 and 5.",
        "Explanation": "Equation (7) and its specialization in Eq. (11) define the GCS states $\\left|\\eta_{\\xi_{q,p}}^{jlJM}\\right\\rangle$ with a prefactor $1/\\sqrt{2J+1}$. This implies these states are not normalized to unity; their squared norm is $1/(2J+1)$, assuming the underlying spin and detector states are orthonormal. However, these $\\left|\\eta\\right\\rangle$ states are subsequently used as if they form an orthonormal basis, particularly for $J=1/2$ (Squbit cases). For example, Eq. (13) presents a general Squdit state as a superposition $\\sum_M \\alpha_{\\frac{1}{2}lJM} \\left|\\eta_{\\xi_{q,p}}^{\\frac{1}{2}lJM}\\right\\rangle$ with the normalization condition $\\sum_M |\\alpha_{\\frac{1}{2}lJM}|^2 = 1$, which requires the basis states $\\left|\\eta\\right\\rangle$ to be orthonormal (including being normalized to 1). The tables in Section 3 further exemplify this inconsistency: for $J=1/2$ cases (both $l=0$ and $l=1$), the explicit expressions provided for $\\left|\\eta\\right\\rangle$ are normalized to 1 (effectively omitting the $1/\\sqrt{2J+1} = 1/\\sqrt{2}$ factor from Eq. (11)). In contrast, for the $J=3/2$ case (Squdit with $l=1$), the expressions in the table include the $1/\\sqrt{2J+1} = 1/2$ factor, and are thus not normalized to 1. This inconsistent definition and handling of normalization for the fundamental Squbit/Squdit states undermines the quantitative validity of derived results, including the properties of stochastic Bell states (Section 4) and the teleportation protocol (Section 5), as probabilities and state norms would be incorrectly calculated."
      }
    ],
    "token_usage": {
      "input": 16046,
      "thinking": 32111,
      "output": 548
    }
  },
  {
    "entry_id": 176,
    "retraction_id": "2106.01585v2",
    "paper_id": "2106.01585v1",
    "retraction_comment": "The proof of Lemma 3.1 has a gap. While there is exponential mixing for Holder functions, the rate of the mixing depends on the Holder exponent of the function. This leads to a vicious circle",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Critical error in the proof of Lemma 3.10 (estimate for the main error term component)",
        "Location": "Page 9, Proof of Lemma 3.10 (formerly lm:c0-3)",
        "Explanation": "The lemma aims to estimate $\\|R_{\\lambda}(a, x) - (\\omega_\\lambda (\rho_0(a)x) -\rho_0(a) \\omega_\\lambda (x) )\\|_{C^0}$, which is $R_\\lambda(a,x) + \\Delta_a \\omega_\\lambda(x)$. The proof (lines 2-3) equates this to an expression of the form $S_{a_\\lambda}(Q) = \\sum (1+\\beta(\\epsilon))^{-i-1} \\rho_0(-(i+1)a_\\lambda) Q \\circ \\rho_0 (i a_\\lambda)$, where $Q = L_{a , a_\\lambda}(R_{\\lambda}(a, \\cdot), SR_\\lambda) +\\beta(\\epsilon) \\rho _0 (a_{\\lambda}) R_\\lambda (a, \\cdot)$. This equality relies on the implicit assumption $R_\\lambda(a,x) = S_{a_\\lambda}(\\tilde{\\Delta}_{a_\\lambda} R_{\\lambda}(a, \\cdot))$, where $S_{a_\\lambda}$ is the solution operator for the coboundary equation involving $a_\\lambda$, and $\\tilde{\\Delta}_{a_\\lambda} F = (1+\\beta(\\epsilon))\\rho_0(a_\\lambda)F - F \\circ \\rho_0(a_\\lambda)$. This assumption means $R_\\lambda(a,x)$ must satisfy $R_\\lambda(a,x) \\circ \\rho_0(a_\\lambda) = (1+\\beta(\\epsilon))\\rho_0(a_\\lambda)R_\\lambda(a,x)$, which is an unjustified and highly restrictive condition on the error term $R_\\lambda(a,x)$. Without this equality, the quantity estimated in the proof is not the required $R_\\lambda(a,x) + \\Delta_a \\omega_\\lambda(x)$, invalidating a key step in controlling the error term in the KAM iteration."
      },
      {
        "Problem": "Insufficient justification for the $C^k$ norm estimate of the new error term $R^{(1)}$",
        "Location": "Page 11, Lemma 3.13 (formerly lm:ck-norm), estimate for $\\|R^{(1)}(a, \\cdot)\\|_{C^{\\bar k+\\tilde k}}$",
        "Explanation": "The proof of the estimate $\\|R^{(1)}(a, \\cdot)\\|_{C^{\\bar k+\\tilde k}} \\ll J^{\\sigma+\\bar k} \\|R\\|_{C^{\\tilde k}}$ states: 'we can use the same argument as in the error estimate for the inductive step \\cite[Section 5.2]{Damjanovic-Katok-Annals} to conclude that...'. The cited work deals with toral automorphisms and heavily relies on Fourier analysis. Transferring such estimates for derivatives of the error term to the nilmanifold setting is non-trivial due to the more complex geometric and analytic structure (e.g., behavior of derivatives, properties of function spaces, Baker-Campbell-Hausdorff formula interactions with differentiation). A mere reference to an argument in a different context (tori vs nilmanifolds) is insufficient for such a crucial estimate, which governs the behavior of higher-order norms in the KAM scheme. A detailed derivation adapted to nilmanifolds is necessary."
      },
      {
        "Problem": "Contradictory definitions or use of $\\omega_\\lambda^+$ versus $\\omega_\\lambda^-$ for solving the coboundary equation",
        "Location": "Page 7, after Lemma 3.6, and Page 8, proof of Lemma 3.8 (formerly lm:norm-estimate)",
        "Explanation": "On page 7, it is stated: 'Henceforth we let $\\omega_\\lambda = \\omega_\\lambda^+ = \\omega_\\lambda^-$ and set $\\omega = \\sum_{\\lambda \\in \\Phi} \\omega_{\\lambda} =\\sum_{\\lambda \\in \\Phi} \\omega_{\\lambda} ^+.' This implies $\\omega_\\lambda^+$ (series over $i \\ge 0$) is always used. However, in the proof of Lemma 3.8 on page 8, it is argued: 'We can assume that $|\\prod_{j=1}^{|\\alpha|}\\chi_j(a_\\lambda)| \\le 1$, without loss of generality. Indeed, if the opposite inequality holds, by Lemma 3.6 we can use the expression $\\omega_{\\lambda}^- $ for $\\omega_{\\lambda}$ and iterate backwards.' This introduces a conditional use of $\\omega_\\lambda^-$ (series over $i < 0$) based on the signs of character values $\\chi_j(a_\\lambda)$, contradicting the earlier declaration. While Lemma 3.6 shows $\\omega_\\lambda^+ = \\omega_\\lambda^-$ as distributions, their specific series representations are used to establish regularity (e.g., being H\\\"older). The convergence and H\\\"older property of $\\omega_\\lambda^+$ relies on $\\lambda(a_\\lambda) \\ge 0$ (due to the choice of $a_\\lambda$). If $\\omega_\\lambda^-$ is used, its convergence to a H\\\"older function under the condition $\\sum \\chi_j(a_\\lambda) > 0$ must be separately justified, and the overall definition of $\\omega$ becomes ambiguous."
      }
    ],
    "token_usage": {
      "input": 32866,
      "thinking": 21772,
      "output": 1275
    }
  },
  {
    "entry_id": 177,
    "retraction_id": "1509.00106v3",
    "paper_id": "1509.00106v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (21)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory conditions for parameters $k_0$ and $\\bar{c}$ for the optimal $\\gamma_0$ choice in Theorem 3.1.",
        "Location": "Theorem 3.1, page 11, and Lemma 2.1 (referred to as Lemma 3.4 in thought process, actual Lemma 5 on page 10 in paper, re-labeled as Lemma 3.4 in PDF structure)",
        "Explanation": "Theorem 3.1 presents an optimal choice for $\\gamma_0$ as $\\gamma_0 := \\frac{\\bar{c}R_0\\sqrt{k_0+1}}{k_0\\sqrt{2D_{\\Uc_A}(k_0-\\bar{c})}}$. This choice requires $k_0 - \\bar{c} > 0$, i.e., $k_0 > \\bar{c}$. However, Theorem 3.1 also states its results hold 'Under the condition $\\bar{c} \\geq k_0$' (this condition is stated to ensure $\\tau_0 \\geq 1$, as per Lemma 5/3.4). These two conditions, $k_0 > \\bar{c}$ and $\\bar{c} \\geq k_0$, are contradictory. This invalidates the specific optimal $\\gamma_0$ and the derived worst-case complexity rate \\eqref{eq:worst_case2} that depends on it. While the more general bound \\eqref{eq:convergence_rate} might still hold for $k > \\bar{c}-k_0$ with any $\\gamma_0 > 0$, the claimed optimal complexity is not established."
      },
      {
        "Problem": "Underestimation of complexity in the 'Over-complete linear operator' case (Section 4.3).",
        "Location": "Section 4.3, page 14, equations \\eqref{eq:bar_c2}, \\eqref{eq:worst_case3} and subsequent complexity claim.",
        "Explanation": "In Section 4.3, for an over-complete matrix $\\Ab$, the constant $\\bar{c}$ is updated to $\\bar{c}_1 := \\max\\set{1+k_0^{-1}, L_{b}\\mathrm{cond}(\\Ab^T\\Ab)}$ (Eq. \\eqref{eq:bar_c2}). The derived convergence rate in \\eqref{eq:worst_case3} is proportional to this $\\bar{c}_1$. However, the final stated worst-case iteration-complexity is $\\mathcal{O}\\left(\\frac{L_b\\norm{\\Ab}R_0\\sqrt{D_{\\Uc}}}{\\varepsilon}\\right)$. This complexity omits the $\\mathrm{cond}(\\Ab^T\\Ab)$ factor that arises from $\\bar{c}_1$ when $L_{b}\\mathrm{cond}(\\Ab^T\\Ab)$ is the dominant term in the max. If $\\mathrm{cond}(\\Ab^T\\Ab)$ is large, this is a significant underestimation of the complexity, and the claim that this complexity is 'the same as in Nesterov (2005c) ... up to a constant' can be misleading if this 'constant' (i.e. $\\mathrm{cond}(\\Ab^T\\Ab)$) is large."
      },
      {
        "Problem": "Inconsistency in the diameter notation ($D_{\\Uc}$ vs $D_{\\Uc_A}$) in Theorem 5.1 (Primal Recovery).",
        "Location": "Theorem 5.1, page 16, equation \\eqref{eq:primal_recovery}, and its proof in Appendix B.",
        "Explanation": "Theorem 5.1 provides convergence guarantees for a primal averaging scheme. The rate in \\eqref{eq:primal_recovery} uses the diameter $D_{\\Uc}$. The proof in Appendix B relies on estimates (like \\eqref{eq:key_est1} via \\eqref{eq:key_estimate2}) that involve the diameter $D_{\\Uc_A} := \\sup\\set{b(\\Ab\\ub) : \\ub\\in\\Uc}$ when the smoothing from Section 2 (i.e., $f_{\\gamma}(\\xb) := \\max\\set{ \\iprods{\\Ab\\ub, \\xb} - \\varphi(\\ub) - \\gamma b(\\Ab\\ub) : \\ub\\in\\Uc}$) is used, which is necessary to have $\\bar{L}_f=1$ as implicitly assumed in the rate. Using $D_{\\Uc}$ instead of $D_{\\Uc_A}$ is only correct if $\\Ab=I$ or if the prox-function $b$ is chosen such that $b(\\Ab\\ub)$ relates directly to a diameter over $\\Uc$. Otherwise, it's an inconsistency that could affect the bound's correctness or interpretation."
      },
      {
        "Problem": "The Lipschitz constant $\\bar{L}_f=1$ claim in Lemma 2.1 relies on a specific interpretation of smoothing.",
        "Location": "Lemma 2.1, page 6, and definition of $b$ on page 5.",
        "Explanation": "Lemma 2.1 states that for $f_{\\gamma}(\\xb) := \\max\\set{ \\iprods{\\Ab\\ub, \\xb} - \\varphi(\\ub) - \\gamma b(\\Ab\\ub) : \\ub\\in\\Uc}$, the gradient $\\nabla f_\\gamma(\\xb)$ is Lipschitz with $L_{f_\\gamma} = \\gamma^{-1}\\bar{L}_f$ where $\\bar{L}_f=1$. This holds if $b(z)$ is 1-strongly convex w.r.t $z=\\Ab u$, and the 'matrix' in the standard smoothing theory is effectively identity. If $b(\\Ab u)$ were considered as a prox term $d(u)$ for variable $u$, its strong convexity w.r.t $u$ would be $\\gamma \\lambda_{\\min}(\\Ab^T\\Ab)$ (for $b(z)=\frac{1}{2}\\|z\\|^2$), leading to $L_{f_\\gamma} = \\|\\Ab\\|^2 / (\\gamma \\lambda_{\\min}(\\Ab^T\\Ab)) = \\mathrm{cond}(\\Ab^T\\Ab)/\\gamma$. The paper's interpretation (that $b$ is a prox function for $\\Uc_A$ and the argument of $b$ is $\\Ab u$) makes $\\bar{L}_f=1$ plausible. However, this distinction is crucial and could be a source of confusion, especially when comparing with Section 4.3 where a different smoothing $b_{\\Uc}(u)$ leads to $\\bar{L}_f = \\|\\Ab\\|^2$. While not necessarily an error if the interpretation is consistently held for Sec 2, its subtlety and contrast with Sec 4.3 could be problematic for the reader and application of theorems."
      }
    ],
    "token_usage": {
      "input": 36241,
      "thinking": 31414,
      "output": 1579
    }
  },
  {
    "entry_id": 178,
    "retraction_id": "1905.01749v2",
    "paper_id": "1905.01749v1",
    "retraction_comment": "There is a serious flaw with Theorems 2-4 which makes their results incorrect. We are working on fixing the issue and uploading a new version of this paper. This flaw, however, does not in any way affect the correctness of evaluations and the gains obtained using the proposed approach",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially flawed proof for Theorem 1",
        "Location": "Section 4, Theorem 1, Proof",
        "Explanation": "Theorem 1 claims that partitioning which groups consecutive receivers (sorted by downlink rates) is Pareto-optimal for minimizing completion times in the relaxed topology. The provided proof by contradiction relies on a specific swap operation ('swapping the fastest receiver in P2 and j1'). The argument that this operation universally leads to a Pareto improvement (improving one partition's rate while keeping others the same or better) is not sufficiently rigorous or clear for all non-consecutive configurations. A weakness in this proof could undermine the 'provably minimizes' claim associated with the relaxed model analysis, even if the heuristic inspired by it performs well empirically."
      },
      {
        "Problem": "Unclear definition or incorrect update of edge weight $W_e$ as a persistent state",
        "Location": "Algorithm 4, line 10; Algorithm 1, line 1; Section 5.1",
        "Explanation": "Algorithm 1 defines edge weight $W_e = L_e + \\frac{\\mathcal{V}_{R}}{B_e}$ for routing a specific request $R$. This $W_e$ appears to be a temporary calculation. However, Algorithm 4, line 10, updates $L_e$ (persistent load) and also $W_e$ as if $W_e$ is a persistent state variable ($W_e \\gets W_e + \\frac{\\mathcal{V}_R}{B_e}$). If $W_e$ is persistent, its definition $L_e + \\frac{\\mathcal{V}_{R}}{B_e}$ is problematic as it would depend on the $\\mathcal{V}_R$ of the request that last defined it, not the current request. If $W_e$ is temporary, updating it in Algorithm 4 is incorrect. This ambiguity or error in handling $W_e$ could mean the described algorithm differs from the implementation or relies on a flawed weighting logic update."
      },
      {
        "Problem": "Sensitivity of performance to accuracy of future bandwidth predictions ($B_e(t)$)",
        "Location": "Section 5.2 (Algorithm 2), Section 6.2 (Simulations)",
        "Explanation": "The core of Iris, including receiver ranking (Algorithm 3) and hierarchical partitioning (Algorithm 4), depends on `MinimumCompletionTimes` (Algorithm 2). This algorithm simulates transfers using estimates of future available bandwidth $B_e(t)$. While the paper acknowledges $B_e(t)$ is estimated and mentions prior work on 'safe estimation', it does not evaluate the sensitivity of Iris's performance to inaccuracies in these predictions. Significant errors in $B_e(t)$ estimates, common in dynamic WAN environments, could lead to suboptimal decisions and substantially degrade Iris's actual performance compared to simulated results, potentially invalidating conclusions about its effectiveness in real-world scenarios."
      },
      {
        "Problem": "Generalizability of reported computational performance for Iris",
        "Location": "Section 6.3 (Mininet Emulations, Running Time), Section 5 (Algorithms 2 and 4)",
        "Explanation": "Iris's computation involves Algorithm 4 calling `MinimumCompletionTimes` (Algorithm 2) multiple times. Algorithm 2 simulates slot-by-slot progress and computes max-min fair rates, which can be computationally intensive, especially for large networks or many flows/partitions. The paper reports a promising sub-5ms computation time per request in Mininet emulations. However, the specific conditions (e.g., maximum number of receivers, network size, number of concurrent flows) under which this performance was achieved are not detailed. Without a complexity analysis or performance results across a wider range of scales, the claim of efficient computation might not generalize, potentially limiting Iris's applicability in larger, more complex inter-datacenter networks."
      }
    ],
    "token_usage": {
      "input": 17581,
      "thinking": 15377,
      "output": 862
    }
  },
  {
    "entry_id": 179,
    "retraction_id": "1312.6644v4",
    "paper_id": "1312.6644v3",
    "retraction_comment": "This paper has been withdrawn by the author because Eqs. (7) and (8) are not correct. An update with corrected expressions and plots will follow soon",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The mathematical formulas for the covariance matrix (Eq. 7) and heat current (Eq. 8) appear inconsistent with their cited source [method] and possess questionable mathematical structures.",
        "Location": "Page 2-3, Section II, Equations (5), (7), (8)",
        "Explanation": "The paper presents expressions for the Green's function $\\hat G(s)$ (Eq. 5), the asymptotic covariance matrix $\\sigma^{(j,k)}$ (Eq. 7), and the heat current $\\dot Q$ (Eq. 8). These equations are central to the paper's results. However, Eq. 5 for $\\hat G(s)$ has an unusual $s_\\alpha$ factor in the numerator and its overall form for residue matrices $s_\\alpha r_\\alpha r_\\alpha^T$ is non-standard. More critically, the final expressions for $\\sigma^{(j,k)}$ (Eq. 7) and $\\dot Q$ (Eq. 8) differ significantly from the corresponding detailed derivations in the cited reference [method] (Freitas & Paz, PRE 93, 032127 (2016), e.g., Eq. (26) and Eq. (30) therein). Specific discrepancies include the matrix structure of the terms in the sum for $\\sigma^{(j,k)}$ (e.g., $r_\\alpha r_\\beta^T$ vs. $(r_\\alpha r_\\alpha^T) M (r_\\beta r_\\beta^T)$ type terms), different powers of complex frequencies $\\omega_\\alpha, \\omega_\\beta$, different arguments for the thermal population/difference terms, and the absence of eigenvector normalization factors present in [method]. If these core formulas are incorrect, the quantitative numerical results for temperature profiles, heat currents, and thermal conductivities throughout the paper would be invalid."
      },
      {
        "Problem": "The claim that disordered 2D (zig-zag) ion crystals become 'heat insulators' is not adequately supported by the presented data and potentially misuses established terminology.",
        "Location": "Abstract (Page 1), Results (Page 3, Fig. 2b), Discussion (Page 4)",
        "Explanation": "The paper asserts that disordered 2D ion crystals act as 'heat insulators', with thermal conductivity $\\kappa$ 'rapidly approaching a vanishingly small value'. However, Fig. 2b, which shows $\\kappa$ vs. system length $L$ for 2D crystals, indicates that for finite disorder (e.g., $d=0.01, 0.05$), $\\kappa$ becomes small and largely independent of $L$. Length-independent $\\kappa$ typically characterizes a normal (diffusive) conductor, where Fourier's law holds. An 'insulator' in the context of thermal transport usually implies that $\\kappa(L) \\to 0$ as $L \\to \\infty$ (e.g., exponentially or as a power law). The data presented does not demonstrate such behavior. Standard theoretical results for disordered 2D harmonic crystals predict either normal conduction (finite $\\kappa$) or a logarithmically divergent $\\kappa$, not strong insulating behavior. Thus, this conclusion may be an over-interpretation of the numerical findings or a non-standard use of the term 'insulator', potentially misrepresenting the actual physical transport regime."
      },
      {
        "Problem": "The conclusion that high-frequency modes provide the largest contribution to heat transport is questionable due to its reliance on the potentially incorrect heat current formula (Eq. 8).",
        "Location": "Page 4, Section III, discussion of Eq. 9 and Fig. 3b",
        "Explanation": "The paper deduces from Eq. 9 (which is derived from Eq. 8) and Fig. 3b that 'the largest contributions [to heat current] come from the modes with higher frequencies'. This is a significant physical claim about the mechanism of heat transport. However, as outlined in Problem 1, Eq. 8 for the heat current has several discrepancies compared to its source derivation [method]. If Eq. 8 is indeed incorrect, then Eq. 9 and the subsequent analysis of modal contributions (Fig. 3b) are also unreliable. Anomalous heat transport in low-dimensional systems is often attributed to low-frequency, long-wavelength modes. The stated dominance of high-frequency modes, particularly the $\\omega_\\alpha^3$ factor in Eq. 8 and 9, would need robust theoretical backing, which is compromised if the underlying formula is flawed."
      }
    ],
    "token_usage": {
      "input": 8978,
      "thinking": 13342,
      "output": 1021
    }
  },
  {
    "entry_id": 180,
    "retraction_id": "2103.11473v2",
    "paper_id": "2103.11473v1",
    "retraction_comment": "The proof of the cluster property (E4) for the superposition is wrong. [REDACTED-NAME] and [REDACTED-NAME] gave a counterexample s.t. the statement of cluster property can't hold in its full generality",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of the cluster property (E4) is flawed, and the property likely does not hold for non-trivial mixing measures $\\varrho$.",
        "Location": "Proof of Theorem 2.6, pages 5-6 (specifically the argument for (E4))",
        "Explanation": "The cluster property (E4) is equivalent to the uniqueness of the vacuum state, i.e., the eigenspace of the Hamiltonian $H^\\varrho$ for eigenvalue 0 being one-dimensional, spanned by $[\\Omega]_\\varrho$. The proof correctly shows that an invariant vector $\\Psi \\in \\mathcal{H}_\\varrho$ decomposes under the isometry $U$ into $(U\\Psi)(m) = c(m)[\\Omega]_m$ for $\\varrho$-a.e. $m$, where $c(m)$ is some complex-valued function and $[\\Omega]_m$ is the vacuum in the Hilbert space $\\mathcal{H}_m$ for a free field of mass $m$. However, the proof then incorrectly concludes that $\\Psi$ must be a multiple of $[\\Omega]_\\varrho$ (i.e., $c(m)$ must be constant $\\varrho$-a.e.). For $U\\Psi$ to correspond to an element in $\\mathcal{H}_\\varrho$ that is a multiple of $[\\Omega]_\\varrho$, $c(m)$ must be constant. The argument that $c(m)$ must be constant for any invariant $\\Psi$ is missing and likely incorrect. If $c(m)$ can be non-constant, then the vacuum eigenspace is larger, and (E4) fails. In fact, for a mixture of free fields $\\mu_\\varrho = \\int \\mu_m d\\varrho(m)$, the cluster property $\\lim_{t\\to\\infty} \\langle A T_t(B) \\rangle_\\varrho = \\langle A \\rangle_\\varrho \\langle B \\rangle_\\varrho$ is generally violated if $\\varrho$ is not a delta measure. Instead, one typically finds $\\lim_{t\\to\\infty} \\langle A T_t(B) \\rangle_\\varrho = \\int \\langle A \\rangle_m \\langle B \\rangle_m d\\varrho(m)$, which differs from $\\langle A \\rangle_\\varrho \\langle B \\rangle_\\varrho = (\\int \\langle A \\rangle_m d\\varrho(m)) (\\int \\langle B \\rangle_m d\\varrho(m))$. This failure of (E4) is critical as it's a cornerstone of the OS axioms for theories with a unique vacuum."
      }
    ],
    "token_usage": {
      "input": 17512,
      "thinking": 21976,
      "output": 589
    }
  },
  {
    "entry_id": 181,
    "retraction_id": "1303.6851v2",
    "paper_id": "1303.6851v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a loophole in the argument of the classical bound",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of the classical CHSH bound and local realism",
        "Location": "Section III.A, particularly around Eq. (13) and the subsequent discussion.",
        "Explanation": "The paper argues that a 'new classical model' can achieve the Tsirelson bound of $2\\sqrt{2}$ for the CHSH inequality, and concludes that this implies 'nonlocality can also exist classically' and 'the notion of nonlocality becomes trivial'. This fundamentally misinterprets Bell's theorem and the significance of the classical CHSH bound of 2. The bound of 2 is derived for local hidden variable (LHV) theories, where for each event, all observables have definite, pre-determined values. The paper's derivation of $2\\sqrt{2}$ for its 'classical model' uses Cauchy-Schwarz inequalities on averages of classical random variables, similar to the quantum derivation. However, this mathematical exercise does not show that an LHV model can achieve $2\\sqrt{2}$. If a model, classical or otherwise, yields a CHSH value greater than 2, it is, by definition, not compatible with local realism as formulated by Bell. The paper's argument does not trivialize quantum nonlocality but rather describes a non-LHV classical model."
      },
      {
        "Problem": "Incorrect example for saturation of Tsirelson's bound",
        "Location": "Section II, paragraph following Eq. (10).",
        "Explanation": "The paper claims that the Tsirelson bound of $2\\sqrt{2}$ is saturated for the singlet state with operators $A_\\alpha=Z\\otimes I$, $A_\\beta=X\\otimes I$, $B_\\alpha=-\\frac{\\sqrt{2}}{2}I\\otimes(Z+X)$, $B_\\beta=\\frac{\\sqrt{2}}{2}I\\otimes(Z-X)$, using the CHSH operator $\\mathfrak{B}= A_\\alpha(B_\\alpha+B_\\beta)+ A_\\beta(B_\\alpha-B_\\beta)$. For these operators, $B_\\alpha+B_\\beta = -\\sqrt{2}(I\\otimes X)$ and $B_\\alpha-B_\\beta = -\\sqrt{2}(I\\otimes Z)$. Thus, $\\mathfrak{B} = Z\\otimes(-\\sqrt{2}X) + X\\otimes(-\\sqrt{2}Z) = -\\sqrt{2}(Z\\otimes X + X\\otimes Z)$. For the singlet state $|\\psi^-\\rangle$, the expectation value $\\langle Z\\otimes X \\rangle_{\\psi^-} = 0$ and $\\langle X\\otimes Z \\rangle_{\\psi^-} = 0$. Therefore, $\\langle \\mathfrak{B} \\rangle_{\\psi^-} = -\\sqrt{2}(0+0) = 0$, not $2\\sqrt{2}$. The provided example fails to saturate the bound as claimed, which is a significant mathematical error in demonstrating a key result."
      },
      {
        "Problem": "Incorrect representation of mixed quantum states",
        "Location": "Section II, paragraph following Eq. (3).",
        "Explanation": "The paper states: 'It is much convenient to employ the method of \"wave function of ensemble state\", namely, define the wave function for $\\mathcal{S}_A$ as $|\\Psi_A\\rangle$, and $\\rho_A=|\\Psi_A\\rangle\\langle\\Psi_A|$, $|\\Psi_A\\rangle=\\sum_i \\gamma_i |\\psi_i\\rangle$, $|\\gamma_i|^2=p_i$', where $\\rho_A = \\sum_i p_i |\\psi_i\\rangle\\langle\\psi_i|$ is the density matrix. This representation of a general mixed state $\\rho_A$ as a projector onto a single state $|\\Psi_A\\rangle\\langle\\Psi_A|$ is incorrect. A density matrix can only be written as such if it represents a pure state. For a mixed state (a statistical ensemble of pure states), $\\rho_A^2 \\neq \\rho_A$ in general, whereas for $|\\Psi_A\\rangle\\langle\\Psi_A|$ (with $\\langle\\Psi_A|\\Psi_A\\rangle=1$), the square is itself. While the Schrödinger uncertainty relation (Eq. 4) ultimately derived is correct for mixed states, this specific step in its 're-deduction' reflects a misunderstanding of how mixed states are described."
      },
      {
        "Problem": "Argument against PR box physicality relies on assumptions that also challenge quantum mechanics",
        "Location": "Section III.B.",
        "Explanation": "The paper argues the Popescu-Rohrlich (PR) box is 'inconsistent' and 'not physical' because its correlations imply a contradiction if one assumes simultaneous definite values for counterfactual observables (e.g., $B$ and $B'$ corresponding to Bob's outcomes for different settings). This argument (citing Rastall) essentially shows that PR boxes are incompatible with a strong form of realism (outcome realism or non-contextuality for all potential measurements). However, quantum mechanics itself is known to be incompatible with such strong realism (e.g., Kochen-Specker theorem). Therefore, using this incompatibility to single out PR boxes as 'not physical' or 'counterfactual' without acknowledging that quantum theory faces similar challenges with such strong realism criteria weakens the argument. The conclusion that 'the physical foundation for the existence of nonlocality is falsified' based on this specific critique of PR boxes is an overstatement."
      },
      {
        "Problem": "Mischaracterization of Bohmian mechanics",
        "Location": "Section IV, discussion on 'Hidden variable theories'.",
        "Explanation": "The paper states: 'Strictly speaking, Bohmian mechanics is not a kind of HVT, since the position does not determine the wave function and related randomness, on the contrary, the wave function...determine the position. Position is rather one external classical parameter than hidden variable.' This mischaracterizes Bohmian mechanics. In Bohmian mechanics, particle positions are precisely the 'hidden variables' (or additional variables) that complete the state description provided by the wave function. They have definite values at all times, their evolution is governed by the guidance equation (which involves the wave function), and they determine the outcomes of measurements. The fact that the wave function guides the particles does not mean their positions are not hidden variables in the context of Bell's theorem or discussions about the completeness of quantum mechanics."
      }
    ],
    "token_usage": {
      "input": 10697,
      "thinking": 19664,
      "output": 1453
    }
  },
  {
    "entry_id": 182,
    "retraction_id": "1208.2556v2",
    "paper_id": "1208.2556v1",
    "retraction_comment": "This paper has been withdrawn by the author due to some nodes in the graph have not been taken into account",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incomplete exploration of inverse paths (branching in cycle reconstruction).",
        "Location": "Section 3, pervasive. For example, on page 5, case $k=9q+1$, path (i) considers $m_{i-4} = \\tau^{-1}(m_{i-3})$ and then $m_{i-5}=\\tau^{-1}(m_{i-4})$. The alternative $m_{i-5}=\\kappa^{-1}(m_{i-4})$ (if $m_{i-4}$ allows) is not explored. Similar omissions occur in other cases.",
        "Explanation": "When reconstructing a cycle backwards, each element $X$ can have predecessors $2X$ or $(X-1)/3$ (if $X$ is an odd output of $3n+1$, or an even $X$ such that $(X-1)/3$ is odd). The proof frequently selects one predecessor path (e.g., $2X$) without systematically exploring all valid alternatives or justifying their exclusion. To prove no cycle exists, all possible backward paths must be shown to lead to a contradiction."
      },
      {
        "Problem": "Erroneous condition check for an inverse sequence.",
        "Location": "Page 5, analysis for $k=9q+1$, path (ii). Similar errors likely exist for other $k$ values (e.g., page 6, $k=9q+2$, path (ii) for $m_{i-7}$; page 7, $k=9q+4$, path (ii) for $m_{i-7}$; page 8, $k=9q+5$, for $m_{i-5}$; page 9, $k=9q+7$, for $m_{i-5}$; page 10, $k=9q+8$, path (ii) for $m_{i-7}$ and path (iii) for $m_{i-10}$).",
        "Explanation": "In the analysis for $k=9q+1$, path (ii), $m_{i-7}$ is derived from $m_{i-4} = \\kappa^{-1}(m_{i-3})$ by three applications of $\\tau^{-1}$ (meaning $m_{i-4}$ is divided by 2 three times: $m_{i-4} \\xrightarrow{/2} m_{i-5} \\xrightarrow{/2} m_{i-6} \\xrightarrow{/2} m_{i-7}$). This requires $m_{i-4}$ to be an odd integer divisible by 8. However, $m_{i-4}=(16k+5)/3$. Since $16k+5 \\equiv 5 \\pmod 8$, $m_{i-4}$ cannot be divisible by 8. Thus, this path is impossible for a reason the paper does not identify, invalidating the subsequent argument about $m_{i-7} > m_0$ for this path."
      },
      {
        "Problem": "Incorrect modular arithmetic and resulting state assignment in the modulo 9 system.",
        "Location": "Page 5, analysis for $k=9q+1$, path (ii). Similar errors occur for other $k$ values (e.g., page 6, $k=9q+2$, path (ii), calculation of $m_{i-5}$; page 7, $k=9q+4$, path (ii), calculation of $m_{i-4}$; page 9, $k=9q+8$, path (ii) and (iii)).",
        "Explanation": "In the analysis for $k=9q+1$, path (ii), $m_{i-4}=(16k+5)/3$ is calculated as $48q+7$. The paper then states $m_{i-4} = 9(\\frac{16q}{3})+7 = 9a+7 \\equiv \\text{Node L}$. This assignment to $9a+7$ (and thus Node L) is only valid if $q$ is a multiple of 3. If $q \\not\\equiv 0 \\pmod 3$, $m_{i-4}$ will belong to a different state (e.g., $9a+1$ or $9b+4$). The subsequent reasoning depends on this specific node assignment, making the argument incomplete or incorrect for $q$ not divisible by 3."
      },
      {
        "Problem": "Imprecise reasoning regarding elements being multiples of 3.",
        "Location": "Page 4, analysis for $k=9q$; Page 6, $k=9q+3$; Page 7, $k=9q+6$.",
        "Explanation": "For $k=9q$ (and similarly for $k=9q+3, k=9q+6$), the argument correctly implies that $m_{i-2}$ would be a multiple of 3 (since $m_{i-1}$ is $9b+1$, so $m_{i-2}=(m_{i-1}-1)/3 = 3b$). This prevents $m_{i-2}$ from being in a cycle other than $\\{4,2,1\\}$. However, the paper phrases the contradiction as 'There is no $m_{i-2}=\\kappa^{-1}(n)$ for \\textcircled{\\SMALL{H}} as required from Lemma \\ref{lemmax}.' This phrasing is imprecise. The issue is not primarily about the graph structure or Lemma 2.1's requirements for $m_{i-2}$'s parity (which is odd, and $3b$ can be odd), but that $m_{i-2}$ is a multiple of 3."
      },
      {
        "Problem": "Potential oversimplification or lack of justification for the universality of Lemma 2.1's cycle structure.",
        "Location": "Section 2, Lemma 2.1 and its proof.",
        "Explanation": "Lemma 2.1 states that *any* normalized cycle (not $\\{4,2,1\\}$) has a very specific arithmetic structure for its elements ($d_0=36k+16$, etc.) and a fixed sequence of Collatz operations connecting $d_{i-3}$ to $d_2$. While the derivation of local properties (like $d_0$ being even, $d_i$ being odd) is standard, the proof that *all* cycles must conform to this exact numerical form $36k+16$ and the specific $E \\to O \\to E \\to O \\to E \\to E \\to E/O$ operational sequence (from $d_{i-3}$ to $d_2$) might not be sufficiently general or might miss some cycle configurations. The entire main proof relies on this specific structure."
      }
    ],
    "token_usage": {
      "input": 9730,
      "thinking": 27595,
      "output": 1519
    }
  },
  {
    "entry_id": 183,
    "retraction_id": "1804.05635v2",
    "paper_id": "1804.05635v1",
    "retraction_comment": "Theorem 1 is questionable and needs revision. Others parts should also be modified accorrdingly. Before the new version is ready, this version should not be referred",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Consistency with Centralized Greedy (Theorem 4) may be flawed.",
        "Location": "Page 7, Section III.C, Theorem 4 and its proof.",
        "Explanation": "Theorem 4 claims the decentralized algorithm identifies the same set of winners as a centralized greedy algorithm (Algorithm 1) using truthful bids ($b'_i=v_i$). The proof argues by induction. For the inductive step $x'_{k'}=0 \\implies x_{k'}=0$: if $a_{k'}$ loses in centralized ($x'_{k'}=0$) because its valuation $v_{k'}$ is less than its critical value $c'_{k'}$ (determined by higher-ranked agents bidding $v_j$), it's possible that in the decentralized game, $v_{k'}$ is greater than its critical value $c_{k'}$ (determined by actual bids $b_j \\le v_j$ from its key predecessor). This could lead to $x_{k'}=1$ in decentralized while $x'_{k'}=0$ in centralized, contradicting the theorem. The proof's argument that $x'_{k'}=0$ implies a hard resource constraint violation (Eq. 20-21) might not cover all cases where $x'_{k'}=0$ (e.g., losing due to a bid value not being high enough, without exhausting all resources)."
      },
      {
        "Problem": "Incorrect calculation of Key Successor in Algorithm 4, leading to incorrect payments.",
        "Location": "Page 8, Section III.D, Algorithm 4 (key_successor), specifically lines 12-13 and their impact on line 15.",
        "Explanation": "Algorithm 4 aims to find an agent $a_i$'s key successor to determine $a_i$'s payment. The payment should reflect the externality $a_i$ imposes. When checking if a lower-ranked, non-winning bid $(\\mathbf{s}_j,b_j)$ (where $x_j=0$) could have won if $a_i$ were absent (Line 15), the available resources (`total_unit`) should only account for winners ranked *higher* than $a_i$. However, Lines 12-13 of Algorithm 4 update `total_unit` by adding resources $s_l^k$ from agents $a_l$ that are winners ($x_l=1$) but rank *lower* than $a_i$ (i.e., $(\\mathbf{s}_i,b_i) \\prec (\\mathbf{s}_l,b_l)$). This is incorrect, as these lower-ranked agents win *despite* $a_i$'s presence and should not influence the calculation of $a_i$'s specific externality on bids that $a_i$ itself crowded out. This will likely lead to incorrect (potentially inflated) payments."
      },
      {
        "Problem": "The claim of strategy-proofness for the pricing scheme is likely incorrect in the dynamic setting.",
        "Location": "Page 2, Section I.A (Contributions) and general discussion of critical-value-based payment.",
        "Explanation": "The paper claims the critical-value-based payment is 'strategy-proof, meaning that no winner can decrease her payment by unilaterally manipulating her own bid.' In a dynamic auction where bids influence ranks and other agents react, this is unlikely to hold. A winner $a_i$ paying $p_i$ (based on key successor $k_s$ and its bid $b_{k_s}$) might raise its own bid $b_i$. This could improve $a_i$'s rank such that $k_s$ is no longer the key successor, or the new key successor is $a_i$ itself (payment 0), or a different agent $k'_s$ with a lower bid. Any of these scenarios could lead to a decreased payment for $a_i$. While critical-value payments are strategy-proof in sealed-bid (static) auctions under certain conditions, this property does not directly extend to this dynamic, iterative setting where bids are adjustable and affect rankings."
      },
      {
        "Problem": "Mismatch between the textual definition of 'Key Predecessor' and its computation in Algorithm 3.",
        "Location": "Page 5, Section III.B, Definition of Key Predecessor, and Algorithm 3 (key_predecessor).",
        "Explanation": "The textual definition states: 'If $a_i$ cannot win..., $a_i$'s key predecessor is $a_k$ if $(\\mathbf{s}_k,b_k)$ is the request that ranks the lowest among all winning requests whose absence *alone* would make $(\\mathbf{s}_i,b_i)$ granted.' However, Algorithm 3 identifies the *highest-ranked* winning competitor $(\\mathbf{s}_j,b_j)$ (among $a_i$'s neighbors) that, in conjunction with other winners ranked even higher than $j$, causes $a_i$ to face a resource conflict. Removing this $j$ alone might not be sufficient for $a_i$ to win if other conflicts exist with winners ranked between $j$ and $i$. This discrepancy could mean that the calculated critical value $c_i$ (based on $k$ from Algorithm 3) does not correspond to the standard notion of a critical bid tied to the 'absence alone' condition, potentially affecting the theoretical underpinnings of agent decisions and system properties."
      },
      {
        "Problem": "The model's integrity relies on an unspecified and strong assumption about penalizing misreported win declarations ($x_i$).",
        "Location": "Page 4, Section III.A, discussion of agent utility and $x_i$ declaration.",
        "Explanation": "The paper states that an agent $a_i$ has no incentive to declare $x_i=1$ if $b_i < c_i$ (i.e., $a_i$ should lose) because 'Any agent $a_j$ with $s_j^k>0$ can detect this. We assume that there is some penalty imposed...'. In a decentralized system, for 'any agent $a_j$' to detect such a misdeclaration by $a_i$, $a_j$ would need global information about $a_i$'s bid, its rank relative to all others, and the status ($x_l$) of all agents $a_l$ ranking higher than $a_i$. Implementing such detection and an agreed-upon penalty mechanism in a decentralized fashion is non-trivial and is not detailed. Without a robust mechanism for ensuring $x_i$ declarations are correct (or incentivized to be correct), agents might strategically misreport $x_i$, invalidating the auction's outcome and behavior as described."
      }
    ],
    "token_usage": {
      "input": 26716,
      "thinking": 13728,
      "output": 1500
    }
  },
  {
    "entry_id": 184,
    "retraction_id": "1503.01380v2",
    "paper_id": "1503.01380v1",
    "retraction_comment": "incomplete and inaccurate, requesting withdrawal immediately. the ranking method is not correct",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory Final Model Specification",
        "Location": "Page 2 (Section 2, last paragraph), Page 3 (NOTE), Page 6 (SUMMARY OUTPUT, ANOVA table), Page 7 (Regression equation)",
        "Explanation": "The paper states that a Principal Component based Multiple Linear Regression (PCMLR) model is developed, where PCA is applied to a reduced set of variables and MLR is performed on the retained principal components (Page 2, Page 3 NOTE). However, the final 'SUMMARY OUTPUT' (Page 6) and the 'Regression equation' (Page 7) are presented in terms of the original predictor variables (Quarter, H-index, etc.), not principal components. The ANOVA table (Page 6) shows 5 degrees of freedom for regression, corresponding to the 5 original variables in the equation. This contradicts the claim of using an MLR model on principal components, making the actual final model structure and the role of PCA in deriving it fundamentally unclear and inconsistent."
      },
      {
        "Problem": "Flawed Variable Selection and Misapplication of PCA",
        "Location": "Page 4 (Analysis Phase-I), Page 5 (Analysis Phase-II, III, Principal Component Analysis), Page 6 (Table: Principal Component Analysis and its Inference)",
        "Explanation": "The variable selection process is multi-staged and contains flaws. Initially, variables are removed iteratively based on p-values (>0.05) and correlation coefficients (<0.4 with SJR score) (Pages 4-5). Then, PCA is supposedly used. The 'Table: Principal Component Analysis' (Page 6) incorrectly attributes 'Percentage of Variation Explained' to individual *original variables* within a PCA context. Based on this misinterpretation, original variables like 'Total Cites(3years)' and 'Citable Docs. (3years)' are removed because they 'explain only 2.5%'. Using PCA output in this manner to filter original variables for a subsequent direct MLR (as implied by the final equation) is a misapplication of the technique. This flawed process makes the final set of chosen predictors lack robust justification."
      },
      {
        "Problem": "Arbitrary and Poorly Justified 'Quarter' Predictor Variable",
        "Location": "Page 2 (Section 2, paragraph on 'Quarter'), Page 6 (Regression Output for 'Quarter'), Page 7 (Regression equation)",
        "Explanation": "The inclusion of 'Quarter' as a predictor variable for journal influence is inadequately justified. The paper posits an intuition that journals evaluated in the first quarter have greater influence (Page 2), but this is unsubstantiated and lacks a theoretical basis in bibliometrics. Furthermore, the final regression equation (Page 7) shows a negative coefficient for 'Quarter' (-0.14076). If 'Quarter' is coded 1, 2, 3, 4, this implies journals in later quarters have higher predicted influence, contradicting the initial stated intuition. This variable likely introduces noise or captures spurious correlations rather than genuine influence factors."
      },
      {
        "Problem": "Unsubstantiated K-Means Clustering for 'National' vs. 'International' Journal Classification",
        "Location": "Page 3 (NOTE), Page 8 ('Classification Process'), Page 9 ('K-Means Clustering' section)",
        "Explanation": "The paper proposes using K-Means clustering (K=2) on the derived Journal Influence Score (JIS) to classify journals into 'National' and 'International' categories. This approach is problematic because K-Means is an unsupervised algorithm that will partition data regardless of underlying truth. There is no ground truth or external validation provided to support that the resulting clusters meaningfully correspond to an objective or recognized distinction of 'National' versus 'International' journal status or scope. The labeling of clusters is arbitrary, and the practical utility of this classification beyond the JIS ranking itself is not demonstrated, making the claim of a useful classification scheme unsound."
      },
      {
        "Problem": "Ambiguity of the Target Variable in Regression Analysis",
        "Location": "Abstract, Page 1 (last paragraph), Page 2 (Section 2.2), Page 4 ('Analysis Phase-I')",
        "Explanation": "The paper is not explicit about the precise nature of the dependent variable 'y' (referred to as Journal Influence Score or benchmarked against SJR) used in the regression model. While it's stated that the model is validated against SCImago Journal Rank (SJR) and variable selection uses correlation with 'SJR Score', it's unclear if the regression predicts the raw SJR values, their ranks, a logarithmic transformation, or some other metric. This ambiguity is critical because the choice of target variable affects the interpretation of model performance metrics like R-squared, the appropriateness of linear regression assumptions, and the overall meaning of the generated 'Journal Influence Score'."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 5690,
      "output": 1060
    }
  },
  {
    "entry_id": 185,
    "retraction_id": "1711.11197v4",
    "paper_id": "1711.11197v3",
    "retraction_comment": "Theorem 4.3 is false as states and it requires a completely different approach. Section 5 is completely correct but it will developed separately",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect step in the proof of Lemma 4.1.",
        "Location": "Page 11, Proof of Lemma 4.1",
        "Explanation": "The proof of Lemma 4.1 states: '$^b\\widetilde{N}\\approx Blup_{r,s}(^b\\widetilde{N},N_V)$ where $^b\\widetilde{N}$ and $N_V$ are considered as unit groupoids'. If $N_V$ is a proper submanifold of $^b\\widetilde{N}$ (or $N_V \\times \\{0\\}$ is a subbundle of $^b\\widetilde{N}|_V \\cong N_V \\times \\mathbb{R}$), then $Blup_{r,s}(^b\\widetilde{N},N_V)$ refers to the geometric blow-up of the space $^b\\widetilde{N}$ along the subspace $N_V$. In general, the blow-up of a manifold along a submanifold is not diffeomorphic to the original manifold. This assertion is a key step in the chain of Morita equivalences used to prove Lemma 4.1. If this step is incorrect, the proof of Lemma 4.1 is invalid. Since the definition of the topological index $^bInd_t$ (Definition 4.2) relies on the Morita equivalence stated in Lemma 4.1, this is a critical issue for the foundation of Theorem 4.3."
      },
      {
        "Problem": "Assumption of amenability for general foliation groupoids.",
        "Location": "Page 5, Section 2.4, C*-algebras paragraph",
        "Explanation": "The paper states: 'Since in this paper all the groupoids considered are amenable we will be denoting by $C^*(\\gr)$ the maximal and hence reduced $C^*$-algebra of $\\gr$'. Holonomy groupoids of general foliations, such as $\\mathcal{H}(\\overset{\\:\\circ}{M},\\overset{\\:\\circ}{\\mathcal{F}})$ or $^b\\mathcal{H}(M,\\mathcal{F})$, are not necessarily amenable. If the groupoids are not amenable, their maximal and reduced $C^*$-algebras differ ($C^*(\\gr) \\neq C_r^*(\\gr)$), and their K-theories can also differ. While the main index definitions use $C_r^*$, some intermediate results or tools (like Proposition 2.10 regarding the Connes-Thom isomorphism, which cites results for amenable groupoids) might rely on this assumption. If non-amenable groupoids are involved, the arguments need to ensure they hold for $C_r^*$ or that the distinction is properly handled."
      },
      {
        "Problem": "Unclear term and isomorphism in the proof of Lemma 4.1.",
        "Location": "Page 11, Proof of Lemma 4.1, line after eq (4.2)",
        "Explanation": "In the proof of Lemma 4.1, the expression '$Blup_{r,s}(\\widetilde{U}\\times_\\pi \\widetilde{U},W\\times_\\pi W\\times \\mathbb{R}^ 2)$' is used. The term '$W\\times_\\pi W\\times \\mathbb{R}^ 2$' and its subsequent stated isomorphism '$(\\widetilde{U}\\times_\\pi \\widetilde{U})|_{\\widetilde{U}|_{N_V}}$' are not clearly justified. $\\widetilde{U}\\times_\\pi \\widetilde{U}$ is Morita equivalent to $\\mathcal{H}(\\widetilde{M}\\times \\mathbb{R}^N,\\mathcal{F}\\times \\mathbb{R}^N)|_{\\widetilde{U}}$, and $W\\times_\\pi W$ is Morita equivalent to $\\mathcal{H}(V\\times \\mathbb{R}^{N-1},\\mathcal{F}_V\\times \\mathbb{R}^{N-1})|_{W}$. The relationship between the restriction of the former groupoid to units over $N_V$ and the latter groupoid (potentially product with $\\mathbb{R}^2$ or similar) is not evident and needs careful derivation. This lack of clarity affects a crucial step in the Blup construction argument within the proof of Lemma 4.1."
      }
    ],
    "token_usage": {
      "input": 31906,
      "thinking": 23934,
      "output": 954
    }
  },
  {
    "entry_id": 186,
    "retraction_id": "2301.09693v2",
    "paper_id": "2301.09693v1",
    "retraction_comment": "An important technical mistake in the set-up of this variant of generalization to Seiberg-Witten equations was pointed out to the author. In particular, the equations are not elliptic as claimed. As a result, any statement about (or uses) regularity and transversality of the moduli space has to be disregarded. However, the moduli space is still compact",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent adjointness in Weitzenböck formula and curvature equation",
        "Location": "Proposition 1.1, Remark 1.2, Equation (1.1), Equation (1.5)",
        "Explanation": "The paper defines $\\rho(F_B^+)$ as an operator on $W^+_{\\mathfrak{s}} \\otimes E$ (Proposition 1.1). If $F_B^+$ is an $\\mathfrak{su}(n)$-valued self-dual 2-form (as $B$ is an $SU(n)$ connection), and $\\rho$ is the standard Clifford action on $W^+_{\\mathfrak{s}}$, then $\\rho(F_B^+)$ (as defined by $(\\rho \\otimes \\mathbf{1}_E) \\circ (\\mathbf{1} \\otimes F_B^+)$) is skew-adjoint. Remark 1.2 incorrectly states it is self-adjoint. This has two critical consequences: \n1. The Weitzenböck formula (1.1) typically involves self-adjoint curvature terms. If $\\rho(F_B^+)$ is skew-adjoint, formula (1.1) is incorrect. \n2. The main curvature equation (1.5) is $\\rho(F^+_A) + \\rho(F^+_B) = \\mu_{0,\\delta}(\\psi)$. Both $\\rho(F^+_A)$ (for $F_A^+$ purely imaginary) and $\\mu_{0,\\delta}(\\psi)$ are self-adjoint. If $\\rho(F_B^+)$ is skew-adjoint, this equation can only hold if $\\rho(F_B^+) = 0$ (which implies $F_B^+=0$) and $\\rho(F_A^+) = \\mu_{0,\\delta}(\\psi)$. This would fundamentally change the proposed equations and restrict $B$ to be ASD. Most subsequent results, including $C^0$-bounds (Lemma 2.3), compactness (Theorem 2.11), and the specific formulation in the K\\\"ahler case (Section 5), depend on the stated Weitzenböck formula and curvature equation, and the (incorrect) self-adjointness of $\\rho(F_B^+)$."
      },
      {
        "Problem": "Flawed surjectivity argument for transversality",
        "Location": "Proof of Lemma 3.4, page 10",
        "Explanation": "The proof of Lemma 3.4, which establishes surjectivity of the linearized operator $d\\tilde{\\mathscr{F}}$ (crucial for transversality and the smoothness/dimension of the moduli space), relies on the claim that a map $\\dot{\\tau} \\mapsto \\dot{\\tau}\\psi$ is surjective. This map is from $L^2_k(\\Lambda^1 \\otimes \\mathfrak{su}(E))$ to $L^2_{k-1}(W^-_{\\mathfrak{s}}\\otimes E)$. The fiberwise argument for this surjectivity states that for $\\omega \\in E_x \\setminus \\{0\\}$, the map $\\xi \\mapsto \\xi \\omega$ from $\\mathfrak{su}(E_x)$ to $E_x$ is surjective. This is false for $n>1$. For instance, if $\\omega \\in \\mathbb{C}^n$, the set $\\{\\xi \\omega : \\xi \\in \\mathfrak{su}(n)\\}$ is the tangent space to the $SU(n)$-orbit of $\\omega$. This orbit is typically a sphere $S^{2n-1}$ (if normalized), so its tangent space has real dimension $2n-1$, while $E_x \\cong \\mathbb{C}^n$ has real dimension $2n$. If this map is not surjective, $d\\tilde{\\mathscr{F}}$ may not be surjective, which could mean that $0$ is not a regular value or the dimension of the moduli space is not as claimed, potentially invalidating the construction of the invariant $SW^E(\\mathfrak{s})$."
      },
      {
        "Problem": "Inconsistent formulation of equations in the K\\\"ahler case",
        "Location": "Equation (5.1) and surrounding discussion, page 16",
        "Explanation": "The specialization of the main equations (1.5) to K\\\"ahler surfaces, presented as system (5.1), appears to suffer from the same adjointness issue as in Problem 1, or makes unstated assumptions. The term $\\rho(F_B^+)$ from (1.5) is effectively replaced by components $2i L^*_{\\omega}F_B$ and $-2F^{0,2}_B$ in (5.1). If $F_B$ is a general $SU(n)$ connection, its self-dual part $F_B^+$ includes $F_B^{2,0}$, $F_B^{0,2}$ and the primitive part of $F_B^{1,1}$. The corresponding Clifford action terms $\\rho(F_B^{0,2})$ (tensored with an $\\mathfrak{su}(n)$ matrix) would not be self-adjoint. Equation (5.1) equates self-adjoint terms with self-adjoint terms and skew-adjoint with skew-adjoint. This decomposition is only straightforward if $F_B$ is of type (1,1) (so $F_B^{2,0}=F_B^{0,2}=0$), making $\\rho(F_B^+)$ effectively $iL^*_{\\omega}F_B^{1,1}$ (which is self-adjoint acting on $W^+_{\\mathfrak{s}}$ and $i\\mathfrak{su}(n)$-valued). The paper deduces $F_B^{0,2}=0$ after Proposition 5.1, but the initial formulation of (5.1) seems to require this as an assumption for consistency with (1.5) and its adjointness properties. This affects the derivation of equation (5.7), which is central to Theorem 0.4 relating the invariant to $\\phi$-stability."
      }
    ],
    "token_usage": {
      "input": 57623,
      "thinking": 16290,
      "output": 1366
    }
  },
  {
    "entry_id": 187,
    "retraction_id": "1609.01275v2",
    "paper_id": "1609.01275v1",
    "retraction_comment": "There is a serious error 3 lines below \"Step (II)\". It is not true that \"It follows that the set C' of all oriented colourings for ... is equal to the set of extension colourings.. .\" (In fact they only account for half of the extension colourings.)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Zero Polynomial Propagation",
        "Location": "Section 5 (Proof of Lemma 5.3), building on Section 1 (Example 1.1) and Section 3 (Lemma 3.1)",
        "Explanation": "The paper establishes that the base origami (1-joint motif, from which all others are claimed to be constructible via Lemma 3.1) has an identically zero origami polynomial $p_\\O(z)=0$ (Example 1.1). The inductive proof of the palindrome property (Lemma 5.3) relates the local sums $X^{\\lambda'}$ in the new origami $\\O'$ to sums $X^\\lambda$ in the original origami $\\O$ by multiplicative factors (e.g., $X^{\\lambda'_{0,j}} = d_j X^{\\lambda_1}$). If all $X^\\lambda$ are zero for $\\O$ (which is true if $p_\\O(z)=0$, as $p_\\O(z) = \\sum_\\lambda X^\\lambda$ for any fixed joint), then this implies all $X^{\\lambda'}$ for $\\O'$ will also be zero. Consequently, $p_{\\O'}(z)=0$. This suggests that all origami polynomials derived from the base case would be identically zero. This contradicts the paper's aim to explain a 1-dimensional mode spectrum, which requires $p_\\O(z)$ to be non-zero but (anti-)palindromic."
      },
      {
        "Problem": "Constructibility from Base Origami (Lemma 3.1)",
        "Location": "Section 3, Lemma 3.1",
        "Explanation": "Lemma 3.1 states that every generic 2-periodic triangulated origami is constructible from a base origami by a sequence of periodic joint-splitting moves. The proof sketch relies on reversing this process by edge contraction. The argument for the existence of such a contractible edge in a general triangulated torus graph (that it preserves the 'triangulated torus graph' property or leads to a simpler valid graph) is brief and draws an analogy to sphere triangulations. Torus topology is more complex, admitting, for example, irreducible triangulations that cannot be simplified by single edge contractions while remaining in the class of triangulations. If Lemma 3.1 does not hold for all generic cases, the scope of the main theorem would be limited to only those origami constructible by the described process."
      },
      {
        "Problem": "Determination of Palindromic vs. Antipalindromic Type",
        "Location": "Conclusion of Section 1, statement in Theorem 2.1's discussion, and Section 5",
        "Explanation": "The paper asserts that $p_\\O(z)$ is palindromic if the quotient graph $G_\\O$ has an even number of loop edges, and antipalindromic if odd. Lemma 5.3 primarily shows the preservation of *being* (anti)palindromic. The specific type (palindromic or antipalindromic) of $p_{\\O'}(z)$ depends on the type of $p_\\O(z)$ and the palindromic nature of the effective multiplicative factor $q(z)$ arising from the joint-splitting move. The argument needs to explicitly track how changes in the global loop edge count upon joint splitting correlate with the palindromic type of $q(z)$ to substantiate this claim. Given Problem 1 (zero polynomial propagation), this issue is secondary but would be critical if $p_\\O(z)$ were non-zero."
      },
      {
        "Problem": "Initial Palindromic Type for Induction",
        "Location": "Section 5, interaction with Example 1.1",
        "Explanation": "The inductive argument for the specific palindromic type (palindromic or antipalindromic) requires a well-defined type for the base case. The base origami has $p_\\O(z)=0$, which is technically both palindromic and antipalindromic. For the induction to determine a specific type for subsequent non-zero polynomials (if they were non-zero, see Problem 1), the base case's type (e.g., antipalindromic due to its 3 loop edges, as suggested by the general rule) must be carefully defined and justified as the starting point for tracking type changes."
      },
      {
        "Problem": "Claim about Increasing Loop Edges",
        "Location": "End of Section 2, page 5",
        "Explanation": "The paper states: 'It is straightforward to see that in general it is possible for a vertex-splitting move to increase the number of loops by 1.' However, the defined periodic joint-splitting move (Figure 2, page 4) introduces a new vertex $v_0$ and new edges $v_0v_1, v_0v_2, v_0v_3$ which connect distinct vertex classes and thus are not loops. Carried edges $v_0v_j$ replacing $v_1v_j$ also do not appear to create new loops from non-loops, and may remove loops (e.g. if $v_1v_j$ was a loop at $v_1$). If the defined move cannot increase loop count, this statement is inaccurate for that specific move. While potentially a minor point for the main argument if other types of splits are allowed, it affects the discussion on loop edge counts."
      }
    ],
    "token_usage": {
      "input": 16473,
      "thinking": 19205,
      "output": 1216
    }
  },
  {
    "entry_id": 188,
    "retraction_id": "2106.14795v2",
    "paper_id": "2106.14795v1",
    "retraction_comment": "Proof of Threorem 17, part 2 not correct as displayed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Lemma 3.10, which estimates the error of the jump coefficients $c^i$ and the constant part $a$ of the control, contains an unjustified (and likely incorrect) equality: $| (\\bar{u} - \\bar{u}_{h}, P_h (g'))_{L^2(\\Omega)} | = | (\\bar{u}, P_h(g')-g')_{L^2(\\Omega)} | + | \\int_{ \\Omega} (\\bar{y} -\\bar{y}_h) g'' \\, d x |$. This equality is central to bounding one of the terms by $O(h)$. Without a correct derivation for this step, the $O(h)$ estimate for coefficient errors, and consequently the main $L^1$-error estimate for the control $u$, are not rigorously established.",
        "Location": "Page 14, Proof of Lemma 3.10",
        "Explanation": "The derivation of the error estimate for the control coefficients relies on an equality that is not standard and appears to be incorrect or at least lacks proper justification. This step is crucial for proving the $O(h)$ convergence rate for these coefficients, which in turn is essential for the final $L^1$ error estimate of the optimal control. A flaw here undermines a key theoretical result of the paper."
      },
      {
        "Problem": "The reported numerical convergence orders in Table 1 (Example 1) and Table 2 (Example 2) show several anomalies where the error appears to increase with mesh refinement, indicated by negative convergence orders. For instance, in Table 1, for the refinement from $h_1=0.0156$ to $h_2=0.0078$, the error for the state $y$ (in $L^2$) has a computed order of -0.1603, and the error for the multiplier $\\Phi$ (in $L^\\infty$) has an order of -2.0774. Similar issues are present in Table 2.",
        "Location": "Page 18, Table 1; Page 20, Table 2",
        "Explanation": "Negative convergence orders suggest that for certain mesh refinement steps, the numerical error increases rather than decreases. This contradicts the theoretical convergence claims and could indicate problems with the numerical implementation, the calculation of errors/orders, or that the experiments are not in the asymptotic convergence regime for those mesh sizes. Such discrepancies cast doubt on the numerical validation of the paper's theoretical findings."
      }
    ],
    "token_usage": {
      "input": 35607,
      "thinking": 23929,
      "output": 567
    }
  },
  {
    "entry_id": 189,
    "retraction_id": "2108.05981v2",
    "paper_id": "2108.05981v1",
    "retraction_comment": "The article has been withdrawn due to incorrect model formulation. Particularly, introducing the so-called \"field with two elements\" was a mistake that made the main equation (observation) of the paper incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified derivation of boson mass from Klein-Gordon equation.",
        "Location": "Page 3, Eq. (2) to Eq. (3)",
        "Explanation": "Assuming a time-independent field (ω=0) in the Klein-Gordon dispersion relation Eq. (2) (ω² - (2π/q)² = mq²) implies mq² = -(2π/q)², representing a tachyonic mass or instability. However, Eq. (3) states (2π/qc)² = mqc², which is equivalent to mq² = (2π/q)², arbitrarily changing the sign or misinterpreting the static condition. This invalidates the fundamental mass relation |mqc| = 2π/qc (Eq. 4) used throughout the paper."
      },
      {
        "Problem": "Incorrect formula for the order of the symmetry group SU₂(q²).",
        "Location": "Page 2, Table 1 and text; Page 4, Eq. (7); Page 5, Eq. (9)",
        "Explanation": "The paper states the order of SU₂(q²) is q³-q, where q is the order of the underlying finite field Fq. This formula is not standard for special unitary groups (e.g., the order of SU(2,Q) is Q(Q²-1) if Q is the field order). This incorrect order is used to estimate the group size based on qc (Eq. 7) and subsequently to derive q* from the Monster group's order (Eq. 9), making q* and dependent calculations unreliable."
      },
      {
        "Problem": "Flawed derivation of mass dependence on spatial dimensions D.",
        "Location": "Page 6, derivation leading to Eq. (13)",
        "Explanation": "When generalizing the mass formula to D spatial dimensions for a static solution, the paper states mqc² = -D(2π/qc)² (if wavenumbers are equal). This implies an imaginary mass. The paper then effectively uses a linear factor of D in its final mass formula (Eq. 13, where MH/Mp = D * mq*/m2), rather than √D which would arise if mqc² were Dk₀², or properly addressing the negative sign. This step is crucial for obtaining the numerical result for the Higgs mass."
      },
      {
        "Problem": "Ad-hoc introduction and interpretation of m₂ = π.",
        "Location": "Page 5, paragraph after Eq. (11), leading to Eq. (12)",
        "Explanation": "The mass m₂ = π, attributed to a 'field with 2 elements', is obtained by extrapolating the already problematic Eq. (3) (mqc = 2π/qc) to qc=2. The physical basis for this extrapolation, the specific value π, and its role as a fundamental mass scale (m₂) used in the final formula (Eq. 12 and 13) are unsubstantiated and appear chosen to simplify mq*/m₂ to 2/q*, facilitating the numerical outcome."
      },
      {
        "Problem": "Unsupported central conjecture equating finite group order with Monster group order.",
        "Location": "Page 5, Eq. (8) and surrounding text",
        "Explanation": "The paper's 'main observation' hinges on the conjecture that the critical order of the proposed SU₂(q*²) group is exactly equal to the order of the Monster group. This assumption is primarily justified by a rough numerical similarity (10⁵¹ vs 10⁵³) derived from initial calculations that themselves rely on problematic formulae (the boson mass formula Eq. 4 and the group order formula). This leap from approximate similarity to exact equality is a significant, unsubstantiated assumption driving the paper's main numerical result."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 6622,
      "output": 842
    }
  },
  {
    "entry_id": 190,
    "retraction_id": "2209.07447v2",
    "paper_id": "2209.07447v1",
    "retraction_comment": "Theorem 11.1 is false : the kernel is not trivial as stated",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 40604,
      "thinking": 22552,
      "output": 1
    }
  },
  {
    "entry_id": 191,
    "retraction_id": "1305.2623v2",
    "paper_id": "1305.2623v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in the calculation of Equation (28)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof for asymptotic independence between different users under random walk mobility (Lemma 3(1-b)).",
        "Location": "Appendix, Page 10, section 'Proof of property (1-b)', specifically the derivation for random walk mobility.",
        "Explanation": "The derivation of $\\mathcal{P}_{b1} = P(1_{i_1j_1}=0, 1_{i_2j_2}=0)$ for random walk mobility involves an integral expression for $\\mathcal{P}_{b1}$. This expression (the multi-line formula involving $\\int S_\\phi d\\phi$) appears to incorrectly mix probabilities with geometric areas (e.g., terms like $(1-\\text{Area})^{n^d} \\times S_\\phi$, where $S_\\phi$ is defined as an area). This dimensional inconsistency makes the subsequent arguments, such as $\\mathcal{Y} \\to 0$ and $\\mathcal{P}_{b1} / \\mathcal{P}_b \\to 1$, unsound. Lemma 3(1-b) is crucial for Lemma 3(1-c, 1-d, 1-e), which are then used to prove the main results for random walk under weak parameter conditions (Theorems 1 and 2). If this lemma is not correctly proven, the foundation for these theorems is weakened."
      },
      {
        "Problem": "Flawed proof step for asymptotic independence for the same user over different time slots under i.i.d. mobility (Lemma 3(1-a)).",
        "Location": "Appendix, Page 10, section 'Proof of property (1-a)', sub-case '(2.o) under i.i.d. mobility with weak parameters condition'.",
        "Explanation": "In proving $P(1_{ij_1}=0, 1_{ij_2}=0) \\sim P(1_{ij_1}=0)P(1_{ij_2}=0)$ for i.i.d. mobility, the paper presents the inequality: $\\mathcal{P}_{a1} \\leq (1- \\pi r^2)^{n^d}\\pi r^2 + (1- 2\\pi r^2)^{n^d}$. The first term on the right-hand side, $(1- \\pi r^2)^{n^d}\\pi r^2$, is a probability multiplied by an area ($\\pi r^2$), which is not a valid probability term. This specific step in the proof is incorrect. While the claim of Lemma 3(1-a) for i.i.d. mobility might ultimately be true under the given conditions (e.g., if $n^d (\\pi r^2)^2 \\to 0$), the provided justification in the appendix is flawed, affecting the rigor of the results for i.i.d. mobility under weak conditions (Theorem 3)."
      },
      {
        "Problem": "Ambiguous definition of $v_*$ in the statement of Theorem 2.",
        "Location": "Page 6, Section 5.3, statement of Theorem 2.",
        "Explanation": "Theorem 2 states that for the random walk model with 'velocity model with constant number of intervals', the critical transmission range uses $v_* = \\min\\{\\frac{v_1^{(y)}}{\\alpha_y}|{y=1,2, \\ldots ,u}\\}$. However, the term $v_1^{(y)}$ is not defined in Section 2.2.1 where this velocity model is introduced. Section 2.2.1 defines the velocity intervals as $[v^{(y)}, v_a^{(y)}]$ and $v_*$ (for heterogeneous velocity models in general under random walk) as $\\min\\{\\frac{v^{(y)}}{\\alpha_y}\\}$. This discrepancy creates ambiguity regarding the precise definition of $v_*$ for Theorem 2. It is likely a typographical error where $v_1^{(y)}$ should be $v^{(y)}$ (the lower bound of the velocity interval)."
      }
    ],
    "token_usage": {
      "input": 51086,
      "thinking": 15955,
      "output": 902
    }
  },
  {
    "entry_id": 192,
    "retraction_id": "0909.5521v3",
    "paper_id": "0909.5521v2",
    "retraction_comment": "Manuscript withdrawn, because results are incorrect. If phi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be expressed as a universal Horn sentence in ESO (NOT even when the structure is ordered)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption 1 is false and its application is critical to the argument.",
        "Location": "Assumption 1, page 2; Section 3.1, page 5; its use in Section 2.1, page 3.",
        "Explanation": "Assumption 1 states: 'if $\\ds \\bigwedge_{i=1}^n C_i$ is equivalent to a Horn formula, then each $C_i$ ($1 \\le i \\le n$) must be a Horn clause.' This is false. For a counterexample, let $C_1 = (A \\lor B)$ (non-Horn if $A, B$ are positive SO predicates) and $C_2 = (\\neg B)$ (Horn). Their conjunction $(A \\lor B) \\land \\neg B$ is equivalent to $A \\land \\neg B$, which is a Horn formula. However, $C_1$ is not a Horn clause. This assumption is crucially used to argue that if a problem in P (represented as BFC $\\land$ OFC) is ESO-ord-$\\Pi_1$-Horn, then its OFC part, when isolated, must also be a conjunction of Horn clauses. This step is essential for the paper's subsequent claim that OFCs for NP-complete problems are Horn."
      },
      {
        "Problem": "Unsubstantiated and problematic claim about OFC expressibility for NP-complete problems.",
        "Location": "Remark 3, page 3; Section 2.1, page 3; its application in Sections 2.2 and 2.3.",
        "Explanation": "The paper claims that the Objective Function Constraint (OFC), such as $|S| \\ge K$, for NP-complete problems like Clique and Vertex Cover can be expressed by an ESO-ord-$\\Pi_1$-Horn formula. This assertion relies on (1) the flawed Assumption 1 to derive Horn OFCs from P-time problems, and (2) the idea that such Horn OFCs are universally reusable. There is no proof provided for such general Horn expressibility of cardinality constraints in FO logic, especially for arbitrary $K$ (which can be part of the input). Expressing such constraints is non-trivial in FO logic, let alone universal Horn FO. The paper itself cites Dawar's result (Section 3.1) which reportedly states that OFC cannot be expressed in ESO-ord-$\\Pi_1$-Horn, directly contradicting this claim."
      },
      {
        "Problem": "Misinterpretation of Grädel's Theorem regarding the properties of sub-formulas.",
        "Location": "Corollary 1, page 2; Section 2.1, page 3.",
        "Explanation": "Grädel's Theorem (P $\\equiv$ ESO-ord-$\\Pi_1$-Horn) concerns the expressibility of an entire decision problem. The paper incorrectly extends this to imply that if a problem (formulated as BFC $\\land$ OFC) is in P and expressible in this logic, then its 'natural' constituent parts (like the OFC), when syntactically separated, must also individually be expressible in ESO-ord-$\\Pi_1$-Horn. Furthermore, it's claimed this property is retained for reuse across different problems. Grädel's theorem does not inherently guarantee such decomposition while preserving the specific logical form (universal Horn FO) for arbitrary sub-formulas, nor their general reusability."
      },
      {
        "Problem": "The paper's argument regarding Grädel's Theorem is self-defeating.",
        "Location": "Abstract; Section 3.1, page 6.",
        "Explanation": "The paper's main conclusion (that Clique and Vertex Cover are solvable in polynomial time under the given conditions) is explicitly predicated on 'assuming that Grädel's 1991 results are correct'. However, in Section 3.1, the author argues that Dawar's result (OFC not expressible in ESO-ord-$\\Pi_1$-Horn), combined with Assumption 1, implies that Grädel's Theorem is likely incorrect ('Grädel's theorem ... will be proved to be incorrect, and we believe this is the likely scenario.'). This creates a fundamental inconsistency: the paper relies on a theorem for its main result while simultaneously arguing that this foundational theorem is probably false. If Grädel's Theorem is indeed incorrect as the author speculates, the entire basis for the paper's primary claim collapses."
      }
    ],
    "token_usage": {
      "input": 6051,
      "thinking": 8770,
      "output": 993
    }
  },
  {
    "entry_id": 193,
    "retraction_id": "1810.09527v2",
    "paper_id": "1810.09527v1",
    "retraction_comment": "Appears that the three transitions interpreted as blueshifted molecular emission from methanol and methanimine are recombination line transitions with similar rest frequencies Paper being withdrawn while this is confirmed",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory statements regarding the angular/physical size of the 6.7 GHz methanol emission.",
        "Location": "Abstract (line 5 of abstract) vs. Section 4.1, paragraph 3 (page 4, left column)",
        "Explanation": "The abstract states, 'The methanol emission is resolved on scales smaller than 40~pc'. This implies that the emission's extent is less than 40 pc or that features smaller than 40 pc are resolved. However, Section 4.1, in discussing observations using baselines to antenna 6 (which probe small angular scales), states, 'When we form spectra using only baselines to antenna 6 we do not detect any significant emission ... showing that the majority (perhaps all) of the emission is resolved out on angular scales of around 2 arcsec (corresponding to linear scales of 40~pc).' Being 'resolved out' on long baselines means that the emission structures are predominantly *larger* than the angular scale probed (2 arcsec or 40 pc), not smaller. This contradiction critically affects the interpretation of the emission's morphology (i.e., its diffuseness). If the emission is predominantly on scales >40 pc (as suggested by the main text), it strengthens the argument for a 'diffuse' maser and makes it less likely to be a collection of compact Galactic-style masers. If it were <40 pc (one interpretation of the abstract), the 'diffuse' characteristic would be less clear."
      }
    ],
    "token_usage": {
      "input": 19523,
      "thinking": 13715,
      "output": 336
    }
  },
  {
    "entry_id": 194,
    "retraction_id": "1603.01872v4",
    "paper_id": "1603.01872v3",
    "retraction_comment": "This paper contains an error: the diagram (13) in the proof of Proposition 6.5 does not strictly commute as claimed. See this https URL for more details. The authors would like to thank [REDACTED-NAME] and [REDACTED-NAME] for finding this error and bringing it to their attention",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and usage of the map $\\widetilde{/H}$ in Section 6.",
        "Location": "Section 6, Proof of Proposition 6.3, specifically the discussion related to diagrams (6.1), (6.2), and (6.4).",
        "Explanation": "The map $\\widetilde{/H}$ in the main diagram (6.1) is from $(D_+F \\sma F_+)^{hH}$ to $(D_+F)^{hH} \\sma (F_+)_{hH}$. Let's call this $\\widetilde{/H}_{(6.1)}$. This map is crucial for the diagram to represent the desired composition of transfers. The proof of Proposition 6.3 analyzes subdiagrams of (6.1). For the triangle involving $\\Delta_E$ (expanded as diagram (6.2)), the map $\\widetilde{/H}$ (which should correspond to $\\widetilde{/H}_{(6.1)}$ possibly composed with equivalences mapping to $D_+E \\sma E_+$) is given a definition: 'We define it just as $/H$ was defined earlier...'. The map $/H$ is defined as $X^{hH} \\to \\Sph^{hH} \\sma X_{hH}$. If this definition is applied to $\\widetilde{/H}$, it would map $(D_+F \\sma F_+)^{hH}$ to $\\Sph^{hH} \\sma (D_+F \\sma F_+)_{hH}$. This target is different from the target of $\\widetilde{/H}_{(6.1)}$ (even after equivalences) and different from $D_+E \\sma E_+$ as shown in (6.2). This discrepancy means the map being analyzed in the proof (via its given definition) is not the map appearing in the main diagram (6.1) whose commutativity is being asserted. This undermines the proof that diagram (6.1) commutes."
      },
      {
        "Problem": "Claim of strict commutativity for diagram (6.5) involving non-strict maps.",
        "Location": "Section 6, Proof of Proposition 6.3, discussion of diagram (6.5).",
        "Explanation": "Diagram (6.5) is claimed to commute because 'both routes ... commute as strict maps of spectra.' However, this diagram is constructed using the dualizing spectrum $\\cal D_H$ and involves norm maps $\\eta$ (or their homotopy inverses). The norm map $\\eta: \\mathcal{D}_H \\sma_{hH} X \\to X^{hH}$ is, in general, only a weak equivalence of spectra, not an isomorphism (cf. Klein, 'The dualizing spectrum of a topological group,' Thm. D). If $\\eta$ (and other maps denoted by '$\\sim$' or '$\\cong$' that are only weak equivalences, such as assembly or collapse maps involved in its definition) is only a weak equivalence, then diagrams involving it would typically only commute up to homotopy. Claiming strict point-set commutativity of a diagram built with representatives of such maps requires careful justification (e.g., by working in a specific model category framework where these equivalences are strictified, or by showing the homotopies are trivial), which is not provided. Without such justification, the deduction of homotopy commutativity from this claimed strict commutativity is unsound."
      },
      {
        "Problem": "Potentially problematic definition of $\\widetilde{/H}$ for the left rectangle of diagram (6.4).",
        "Location": "Section 6, Proof of Proposition 6.3, discussion of diagram (6.4).",
        "Explanation": "When analyzing the trapezoid region of (6.1) (expanded as (6.4)), the text states: 'We define the new map $\\widetilde{/H}$ so that the left rectangle of (6.4) commutes'. The map $\\widetilde{/H}$ in this context is the left vertical arrow in (6.4), mapping $(D_+F \\sma F_+)^{hH}$ to $D_+E \\sma E_+$. If this map is indeed the one from diagram (6.1) (i.e., $\\widetilde{/H}_{(6.1)}$ composed with the standard equivalences $(D_+F)^{hH} \\simeq D_+E$ and $(F_+)_{hH} \\simeq E_+$), then its properties are fixed, and the commutativity of the left rectangle of (6.4) must be *proven*. Defining the map by the commutativity it is supposed to satisfy is circular. If this 'new map $\\widetilde{/H}$' is distinct from $\\widetilde{/H}_{(6.1)}$, then the argument for (6.1) fails. While the underlying maps might make the rectangle commute, the phrasing suggests a potential gap in the argument structure."
      }
    ],
    "token_usage": {
      "input": 19676,
      "thinking": 20026,
      "output": 1072
    }
  },
  {
    "entry_id": 195,
    "retraction_id": "2404.01980v6",
    "paper_id": "2404.01980v5",
    "retraction_comment": "There is a flaw in the proof of Theorem 3.3 that the A at t=0 and A at t=T cannot be guaranteed to be identical, thus the key inequality fails",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear and potentially incorrect formulation of the diffusion term in Hamilton's evolution equation for the isoperimetric ratio.",
        "Location": "Page 2, Section 2, Eq. (2.4) / Theorem 2.2",
        "Explanation": "The evolution equation for $I_A^2$ is given as $\\frac{\\partial}{\\partial t}\\ln I_A^2=\\frac{\\partial^2}{\\partial r^2}\\ln I_A^2+\\frac{A^2+(4\\pi-A)^2}{A(4\\pi-A)}[1-I_A^2]$, where $r$ is described as 'the normal direction of the curve $\\Lambda$'. The isoperimetric ratio $I_A$ is a function of area $A$ and time $t$, i.e., $I(A,t)$. Standard formulations of this evolution equation (e.g., Hamilton, \\cite{H2}) involve a diffusion term with respect to a parameter $s(A)$ derived from the area $A$ (e.g., $\\frac{\\partial^2}{\\partial s(A)^2}$). A spatial derivative like $\\frac{\\partial^2}{\\partial r^2}$ is not appropriate for a quantity $I_A$ that depends on $A$ globally, not on a specific point or direction on a curve. If this term is incorrect or its meaning not properly established in this context, the subsequent application of the maximum principle in Proposition 3.1 may be invalid."
      },
      {
        "Problem": "A crucial step in the proof of the main theorem (Theorem 3.2) relies on an inadequately justified assertion concerning the 'tightness' of an inequality for small area $A$.",
        "Location": "Page 3, Section 3, Proof of Theorem 3.2 (paragraph beginning 'On the other hand...')",
        "Explanation": "The proof asserts that 'since the inequality (2.3) is tight for $A\\rightarrow 0$, we can choose $A$ sufficiently small such that $\\frac{4\\pi A-\\kappa(T)A^2}{4\\pi A-A^2}\\geq\\frac{1}{1+e^{-B(A)T-C(A, \\kappa(0))}}$'. Inequality (2.3) is $I_A^2 \\ge \\frac{4\\pi A-\\kappa A^2}{4\\pi A-A^2}$. Tightness for $A \\to 0$ means $I_A^2(T)$ is approximately equal to $\\frac{4\\pi A-\\kappa(T)A^2}{4\\pi A-A^2}$ for small $A$. However, this approximation does not directly imply the stated inequality. A rigorous argument would require careful handling of error terms (e.g., $I_A^2(T) \\le (1+\\epsilon)\\frac{4\\pi A-\\kappa(T)A^2}{4\\pi A-A^2}$ for small $A$). The paper's current reasoning contains a logical gap at this step, which is essential for deriving the subsequent inequality (3.3) (labeled (2.7) in the paper)."
      },
      {
        "Problem": "The final contradiction in the proof of Theorem 3.2 is derived using an incorrect limit evaluation and subsequent flawed reasoning.",
        "Location": "Page 4, Section 3, Proof of Theorem 3.2 (last paragraph)",
        "Explanation": "The paper claims that taking the limit $A \\to 0$ in inequality (3.3) (labeled (2.7) as $\\text{eq7}$ in the text: $e^{-B(A)T}\\cdot\\frac{4\\pi A-\\kappa(T)A^2}{4\\pi A-\\kappa(0)A^2}\\geq \\frac{\\kappa(T)-1}{\\kappa(0)-1}$) yields '$e^{-2T}\\geq e^{-BT}\\cdot 1\\geq \\frac{\\kappa(T)-1}{\\kappa(0)-1}>e^{-2T}$'. This is incorrect. As $A \\to 0$, the term $B(A) = \\frac{A^2+(4\\pi-A)^2}{A(4\\pi-A)} \\sim \\frac{4\\pi}{A} \\to \\infty$, so $e^{-B(A)T} \\to 0$. The ratio $\\frac{4\\pi A-\\kappa(T)A^2}{4\\pi A-\\kappa(0)A^2} \\to 1$. Thus, the limit of the left-hand side of (3.3) is $0 \\cdot 1 = 0$. The correctly derived inequality should be $0 \\geq \\frac{\\kappa(T)-1}{\\kappa(0)-1}$. While this still leads to a contradiction with the assumption that $\\frac{\\kappa(T)-1}{\\kappa(0)-1} > e^{-2T} > 0$, the paper's derivation of the contradiction '$e^{-2T} \\ge \\dots > e^{-2T}$' is based on the erroneous claim that $\\lim_{A \\to 0} e^{-B(A)T} \\ge e^{-2T}$ (or that $e^{-B(A)T}$ can be bounded below by $e^{-2T}$ in the limit in this fashion)."
      }
    ],
    "token_usage": {
      "input": 5007,
      "thinking": 16445,
      "output": 1226
    }
  },
  {
    "entry_id": 196,
    "retraction_id": "1105.1572v2",
    "paper_id": "1105.1572v1",
    "retraction_comment": "This was withdrawn because the key distribution figures Figure 1 and 3 in the paper are technically incorrect",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated and misleading claim about data decryption security linked to QKD.",
        "Location": "Page 2, Section II, paragraph 1",
        "Explanation": "The paper states, 'It has been proved that the chances of decrypting the data by an eavesdropper without the key is reduced to zero in such a situation [4],' citing a popular science article [4] as proof. This claim is an overstatement of QKD's direct role (which is key distribution) and the nature of 'proof' for such absolute security. QKD aims to secure the key; data security then depends on the encryption algorithm used. Attributing 'zero chance' of data decryption based on a non-rigorous source for a commercial system's claim is unsound and misrepresents the security guarantees."
      },
      {
        "Problem": "Incorrect statement regarding information leakage during error reconciliation in QKD.",
        "Location": "Page 5, 'Privacy Amplification (extension of BB84)' section, first sentence of the second paragraph of this subsection",
        "Explanation": "The paper claims, 'During the reconciliation phase, Oscar did not gain any information, since the last bit of each parity-check block was discarded.' This is false. Public discussion of parities during error reconciliation inherently leaks information to an eavesdropper (Oscar) about the remaining bits in the block, even if one bit per block is discarded. This leakage is precisely why privacy amplification is a necessary subsequent step. The statement demonstrates a misunderstanding of a fundamental aspect of QKD post-processing."
      },
      {
        "Problem": "The description of the quantum Byzantine Agreement protocol is critically unclear and appears to contain inconsistencies.",
        "Location": "Page 8-9, Section VI.A, 'Byzantine Agreement Problem,' particularly steps 1-6 of the protocol description and the subsequent explanatory paragraph.",
        "Explanation": "The paper attempts to describe a quantum protocol for a modified Byzantine Agreement using qutrits. However, the description is muddled, appears to conflate the binary message to be agreed upon with qutrit measurement outcomes (e.g., S's role in Step 1), and the logic for consistency checks and detection of dishonesty (e.g., Step 6 with vague conditions like 'almost all') is not coherently or correctly explained. This makes it impossible to assess the soundness of the claimed solution from the provided text, undermining the paper's discussion of this application."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 5471,
      "output": 539
    }
  },
  {
    "entry_id": 197,
    "retraction_id": "2003.05595v3",
    "paper_id": "2003.05595v2",
    "retraction_comment": "Equation (24) was wrong: algebraic cancellations of this type are invalid in general",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect algebraic step in the derivation of the compatibility condition for $\\Xi$.",
        "Location": "Page 5, derivation leading to Eq. (4.5)",
        "Explanation": "In the proof of Theorem 1.1, the derivation of $Pd\\Xi = - P\\Xi \\wedge \\Xi$ (which implies $d\\Xi + \\Xi \\wedge \\Xi = 0$) contains an algebraic error. Specifically, the step from $-(P\\Xi -\\Omega P) \\wedge \\Xi - \\Omega \\wedge P\\Xi$ to $- P\\Xi \\wedge \\Xi$ requires that $\\Omega P \\wedge \\Xi - \\Omega \\wedge P\\Xi = 0$. This identity, which can be written as $(A B) \\wedge C - A \\wedge (BC) = 0$ where $A=\\Omega$, $B=P$, $C=\\Xi$, is not generally true for matrix-valued differential forms. While the resulting equation $d\\Xi + \\Xi \\wedge \\Xi = 0$ is correct (it follows from standard gauge transformation properties of the curvature, $F_\\Xi = P^{-1} F_\\Omega P = 0$), the paper's specific derivation is flawed. This is a significant error in the presented proof of the main theorem."
      },
      {
        "Problem": "Incorrect assertion of regularity for the connection form $\\Omega^\\epsilon$ in the proof of the weak compactness theorem.",
        "Location": "Page 8, Proof of Theorem 6.1, first paragraph",
        "Explanation": "The proof of Theorem 6.1 states: 'Since $\\{\\iota^\\epsilon\\}$ is uniformly bounded in $W^{2,2}_\\loc$, one may infer that $\\{\\Omega^\\epsilon\\}$ is uniformly bounded in $W^{1,2}_\\loc$.' This inference is incorrect. If $\\iota^\\epsilon$ is uniformly bounded in $W^{2,2}_\\loc$, then the corresponding connection forms $\\Omega^\\epsilon$ (which involve first derivatives of the metric $g^\\epsilon$ and the second fundamental form $\\two^\\epsilon$) are generally only uniformly bounded in $L^2_\\loc$, not $W^{1,2}_\\loc$. A $W^{1,2}_\\loc$ bound on $\\Omega^\\epsilon$ would require uniform $W^{3,2}_\\loc$ bounds on $\\iota^\\epsilon$. Although the subsequent argument for the convergence $P^\\epsilon \\weak \\overline{P}$ seems to rely only on the $L^2_\\loc$ boundedness of $\\Omega^\\epsilon$, the misstatement of regularity for $\\Omega^\\epsilon$ is an error."
      }
    ],
    "token_usage": {
      "input": 12361,
      "thinking": 21657,
      "output": 614
    }
  },
  {
    "entry_id": 198,
    "retraction_id": "1609.00445v2",
    "paper_id": "1609.00445v1",
    "retraction_comment": "Withdrawn due to an error in the numerical code, used to obtain the numerical results",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect classical energy expression for the 3-in-1-out chiral order.",
        "Location": "Fig. 2 (caption and values) and 'Analytic results' section.",
        "Explanation": "The paper presents the ground-state energy for the 3-in-1-out chiral order as $E_{3i1o} = S^2(J_0 - 3J_1 \\pm 6\\sqrt{2}D_1)$ per tetrahedron. However, a standard calculation for Ising spins on pyrochlore local axes, using the paper's definitions for $J_{\\mathbf{i}\\mathbf{j}}$ (Eq. 2, where bonds $(\\mathbf{1},\\mathbf{2}), (\\mathbf{1},\\mathbf{3}), (\\mathbf{1},\\mathbf{4})$ have exchange $J_0+J_1$ and bonds $(\\mathbf{2},\\mathbf{3}), (\\mathbf{2},\\mathbf{4}), (\\mathbf{3},\\mathbf{4})$ have $J_0-J_1$), yields a Heisenberg energy component of $S^2(J_0 + 2J_1)$. The discrepancy in the coefficient of $J_1$ ($-3J_1$ vs $+2J_1$) is significant ($5J_1S^2$). This error would alter the conditions under which the $J_1$ interaction (a key 'new multiorbital effect') stabilizes the 3-in-1-out phase and potentially change the conclusions regarding its stability relative to other phases."
      },
      {
        "Problem": "Claim of macroscopic degeneracy persisting with Dzyaloshinsky-Moriya (DM) interactions in the Kagome limit.",
        "Location": "'Numerical results' section (discussion of Fig. 4a,b, black circles) and 'Discussion' section (new mechanism for SL).",
        "Explanation": "The paper claims that in the Kagome lattice limit (achieved when $J_1=-J_0$ and $D_1=-D_0$), macroscopic degeneracy persists even with finite DM interactions ($D_0 \neq 0$). This is a key finding supporting a new mechanism for spin liquid (SL) stabilization. This degeneracy is attributed to 'degeneracy of the orders for $q_x=q_y=q_z$' found in the Mean Field Approximation (MFA). However, DM interactions on a Kagome lattice typically lift the extensive classical degeneracy of the pure Heisenberg model and select a specific ordered state (often a $\\mathbf{q}=0$ structure). The persistence of macroscopic degeneracy in the presence of DM interactions is an unconventional result. While not impossible within a specific model, it requires robust justification, such as a detailed analysis of the eigenvalues of the Fourier-transformed interaction matrix $J(\\mathbf{q})$, to ensure the claim is sound and not an artifact of the specific MFA setup or interpretation."
      }
    ],
    "token_usage": {
      "input": 12447,
      "thinking": 16256,
      "output": 632
    }
  },
  {
    "entry_id": 199,
    "retraction_id": "1810.09697v2",
    "paper_id": "1810.09697v1",
    "retraction_comment": "We get more general results in Theorem 1.1. Corollary 5.27 and Theorem 1.3 are false",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lemma 3.2.iii is false, and this error propagates to subsequent results.",
        "Location": "Page 5, Lemma 3.2.iii; Page 6, Corollary after Lemma 3.2; Page 6, Lemma 3.4",
        "Explanation": "Lemma 3.2.iii states: 'If $j \\notin \\{2,3\\}$, then $\\sigma^{**}(M_j^4)$ has a non Mersenne irreducible divisor.' This is false for $j=1,4,5$. For example, for $j=1$, $M_1=x^2+x+1$. $\\sigma^{**}(M_1^4) = (1+M_1)^2 \\sigma(M_1^2) = (x(x+1))^2 x(x+1)M_1 = x^3(x+1)^3 M_1$. The only odd irreducible factor is $M_1$, which is Mersenne. Similar results hold for $M_4$ and $M_5$. This error makes the restriction '$h_j \\neq 4$ if $j \\notin \\{2,3\\}$' (i.e., for $M_1, M_4, M_5$) in the Corollary following Lemma 3.2 and in Lemma 3.4.i and 3.4.ii unfounded. Lemma 3.4.iii also restricts exponents for $M_1, M_4, M_5$ to $\\{0,1,2\\}$, likely due to the same flawed reasoning. These restrictions on $h_j$ mean the search space for the Maple computations used to establish Theorem 1.1 (and consequently Theorems 1.2 and 1.3) might have been too small, potentially rendering the list of polynomials $C_1, \\ldots, C_{15}$ incomplete."
      },
      {
        "Problem": "Lemma 5.9 incorrectly claims a reducible polynomial is irreducible, invalidating a case in the proof of Theorem 1.3.",
        "Location": "Page 11, Lemma 5.9; Page 13, Section 5.2.1; Page 14, Corollary 5.12",
        "Explanation": "Lemma 5.9 states: 'If $Q = \\sigma(P^{2m})$ for some $m \\geq 1$, then $P=\\sigma(x^2)$ and $Q \\in \\{\\sigma(P^2), \\sigma(P^4)\\}$.' The proof then claims: 'If $P=\\sigma(x^2)$ and $Q=\\sigma(P^2)$, then $Q=1+x(x+1)P$ is irreducible.' Let $P=M_1=x^2+x+1$. Then $Q = 1+x(x+1)M_1 = 1+M_1^2 = (1+M_1)^2 = (x(x+1))^2 = x^2(x+1)^2$. This polynomial is reducible, not irreducible. Therefore, $Q=\\sigma(P^2)$ cannot be an irreducible factor as required by the context ($Q$ is an irreducible factor of $A$). This error invalidates the $Q=\\sigma(P^2)$ case in the analysis of Section 5.2.1 (Case $Q = \\sigma(P^{2m})$) and Corollary 5.12, which are used to argue that no bi-unitary perfect polynomials exist when $Q$ is not Mersenne."
      },
      {
        "Problem": "The argument in Lemma 3.1 might be incomplete for the $r=0$ case.",
        "Location": "Page 5, Lemma 3.1",
        "Explanation": "Lemma 3.1 states 'One has: $a \\neq 2^n-1$ or $b \\neq 2^n-1$'. The proof argues that if $a=2^n-1$ and $b=2^m-1$, then $B = \\prod_j P_j^{h_j}$ must be bi-unitary perfect. It then states this contradicts Lemma 2.6 (nombreminimal) because $B$ is odd. This is true if $B$ is non-constant (i.e., $r \\ge 1$). However, if $r=0$, then $B=1$. In this case, $A=x^{2^n-1}(x+1)^{2^m-1}$. This is bi-unitary perfect if and only if $n=m$. These polynomials ($x^{2^n-1}(x+1)^{2^n-1}$) are known bi-unitary perfect polynomials. Theorem 1.1 lists polynomials $C_1, \\ldots, C_{15}$ which all have $r \\ge 1$. The lemma implicitly assumes $r \\ge 1$ for the contradiction to hold. While the main theorem concerns cases where $r \\ge 1$, the lemma as stated should handle the $r=0$ case or explicitly exclude it."
      }
    ],
    "token_usage": {
      "input": 32493,
      "thinking": 27295,
      "output": 1146
    }
  },
  {
    "entry_id": 200,
    "retraction_id": "1309.2621v7",
    "paper_id": "1309.2621v6",
    "retraction_comment": "This paper was withdrawn because the author did not prove that the function lambda_0(t) = gamma(t) on page 14 is strictly increasing. This is why we cannot make the crucial time change that proves the main theorem about infinite dimensional SRBM",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially insufficient argument for tightness in infinite dimensions for SRBM construction.",
        "Location": "Section 2.2, Proof of Theorem 2.1 (BARthm), pages 11-12.",
        "Explanation": "The proof of Theorem 2.1, which is crucial for establishing stationary distributions, involves showing that a sequence of processes $(\\eta^{(n)})$ is relatively compact in $C([0, T], \\mathbb{R}^{\\infty})$. The argument relies on componentwise compact containment and then claims that this implies compact containment in the $\\rho_{\\infty}$ metric for $\\mathbb{R}^{\\infty}$ ('It is straightforward to show...'). This step from componentwise tightness to tightness in the specific Polish space $C([0, T], \\mathbb{R}^{\\infty})$ (with $\\mathbb{R}^{\\infty}$ having the product topology induced by $\\rho_{\\infty}$) requires careful control of the tail behavior of components (i.e., $\\sum_{i=M}^{\\infty} 2^{-i} (E[|\\eta_i^{(n)}(t)| \\wedge 1])$ must be uniformly small for large $M$). This uniform control is not explicitly demonstrated. If this step is not fully justified, the existence of the limiting process $\\eta$ as a solution to the patchwork martingale problem in the correct space is not guaranteed, potentially undermining Theorem 2.1 and subsequent results (Theorems 2.2, 1.1, 1.2)."
      },
      {
        "Problem": "Inconsistent notation for the SDE of competing Brownian particles.",
        "Location": "Equation (1) on page 2 vs. Definition 1.1 (iv) on page 3.",
        "Explanation": "The SDE for $Y_n(t)$ is given in the Introduction (Equation (1)) as $Y_n(t) = g_n t + \\sigma_n W_n(t) + q^+_nL_{n-1}(t) - q^-_{n-1}L_{n}(t)$. However, Definition 1.1 (iv) states $Y_k(t) = g_kt + \\sigma_kW_k(t) + q^+_kL_{k-1}(t) - q^-_kL_k(t)$. The coefficient of $L_n(t)$ (or $L_k(t)$) differs ($q^-_{n-1}$ vs $q^-_k$). The derivation of the reflection matrix $R$ for the gap process (Equation (10)) and the subsequent verification of the skew-symmetry condition (Lemma 3.3) appear to be consistent with Definition 1.1 (iv) (using $q^-_k L_k(t)$) and the collision parameter condition $q^+_{k+1} + q^-_k = 1$. If Equation (1) were used, the reflection matrix and potentially the CBP skew-symmetry condition (Eq. 2) would change. This is likely a typo in Eq. (1) but creates significant ambiguity regarding the model definition."
      },
      {
        "Problem": "Potentially incorrect justification for density argument using Stone-Weierstrass theorem.",
        "Location": "Lemma 2.7 (help2)(i), page 14.",
        "Explanation": "Lemma 2.7(i) states that $\\mathcal{TC}^2_c(S)$ (functions on $S = \\mathbb{R}^{\\infty}_+$ depending on finitely many variables with compact support in that finite-dimensional projection) is dense in $C_0(S)$ (continuous functions on $S$ vanishing at infinity). The proof cites Folland's book (Theorem 4.52), which is the Stone-Weierstrass theorem for locally compact Hausdorff (LCH) spaces. However, $S = \\mathbb{R}^{\\infty}_+$ is not LCH. While the density claim itself might be true and provable by other means (e.g., first approximating by functions of finitely many variables, then applying Stone-Weierstrass on $\\mathbb{R}^N_+$), the provided justification via direct application of Folland Thm 4.52 is not appropriate for a non-LCH space. This is a minor foundational issue but indicates a lack of precision in citing supporting results for infinite-dimensional spaces."
      }
    ],
    "token_usage": {
      "input": 35518,
      "thinking": 18254,
      "output": 968
    }
  },
  {
    "entry_id": 201,
    "retraction_id": "0811.0505v2",
    "paper_id": "0811.0505v1",
    "retraction_comment": "This paper has been withdrawn by the author since there were errors in the calculus of the defect coefficient in Page 11. The corrected calculus gives actually zero which do not lead to a contradiction on the continuity of the flow-map of the Benjamin-Ono equation. The author warmly thank [REDACTED-NAME] G_rard for having pointing out this error to him",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of a key limit related to the $L^2$ norm of initial data.",
        "Location": "Equation (4.3) on page 7, and usage on page 7, line 14.",
        "Explanation": "The paper states that $\\lim_{n\\to\\infty} \\int_{\\T} |u_{0,n}|^2 = \\int_{\\T} |u_0|^2 + 2\\pi$. Given $u_{0,n} = \\tilde{u}_{0,n} + \\cos(nx)$ where $\\tilde{u}_{0,n} \\to u_0$ strongly in $L^2(\\T)$, the calculation should be $\\lim_{n\\to\\infty} \\int_{\\T} |u_{0,n}|^2 = \\lim_{n\\to\\infty} (\\int_{\\T} |\\tilde{u}_{0,n}|^2 + \\int_{\\T} |\\cos(nx)|^2 + 2\\Re \\int_{\\T} \\tilde{u}_{0,n} \\cos(nx) dx)$. Since $\\int_{\\T} |\\cos(nx)|^2 dx = \\pi$ (not $2\\pi$) and $2\\Re \\int_{\\T} \\tilde{u}_{0,n} \\cos(nx) dx \\to 0$, the limit is $\\int_{\\T} |u_0|^2 + \\pi$. This means the quantity $\\alpha^2 - \\|u_0\\|_{L^2(\\T)}^2$ used in the contradiction argument should be $\\pi$, not $2\\pi$."
      },
      {
        "Problem": "Inconsistent definition or incorrect calculation of a key limit related to the $L^2$ norm of the gauge transform of initial data.",
        "Location": "Lemma 4.3 (equation (4.4) and its proof) on page 7, and usage on page 7, line 17.",
        "Explanation": "The gauge transform is defined as $w = -\\frac{i}{2} P_+(e^{-iF/2} u)$ (Eq. (3.4)). Lemma 4.3 aims to compute $\\lim_{n\\to\\infty} \\int_{\\T} |w_{0,n}|^2$. The proof of Lemma 4.3 calculates $\\lim \\int_{\\T} |P_+(u_{0,n}e^{-iF_{0,n}/2})|^2 - \\int_{\\T} |P_+(u_0 e^{-iF_0/2})|^2 = \\pi/2$. If $w_{lemma} = P_+(u e^{-iF/2})$, then $\\|w_{true}\\|^2 = \\|-\\frac{i}{2} w_{lemma}\\|^2 = \\frac{1}{4} \\|w_{lemma}\\|^2$. Therefore, the quantity $a(0) - \\|w(0)\\|_{L^2(\\T)}^2 = \\lim \\|w_{0,n}\\|^2 - \\|w_0\\|^2$ should be $\\frac{1}{4}(\\pi/2) = \\pi/8$, not $\\pi/2$. The statement of Lemma 4.3 defines $w_{0,n}$ as $\\partial_x P_+(e^{-iF_{0,n}/2})$, but the proof does not follow this definition."
      },
      {
        "Problem": "The main contradiction argument relies on a coefficient being non-zero, but corrections from identified errors make this coefficient zero, invalidating the proof of Theorem 1.1.",
        "Location": "Page 7, lines 10-13, and the overall contradiction argument based on Proposition 4.1.",
        "Explanation": "The contradiction in the proof arises from showing that the limit gauge transform $w(t)$ must satisfy two different equations, implying that a 'defect term' must be zero. This defect term is $C \\cdot w(t)$, where $C = \\frac{i}{8\\pi} ( (\\alpha^2-\\|u_0\\|_{L^2(\\T)}^2) - 8 (a(t)-\\|w(t)\\|_{L^2(\\T)}^2) )$. At $t=0$, the paper's values give $C = -\\frac{i}{4}$. Using the corrected value $\\alpha^2-\\|u_0\\|_{L^2(\\T)}^2 = \\pi$ (from Problem 1) and the corrected value $a(0)-\\|w(0)\\|_{L^2(\\T)}^2 = \\pi/8$ (from Problem 2), the coefficient at $t=0$ becomes $C = \\frac{i}{8\\pi} (\\pi - 8(\\pi/8)) = \\frac{i}{8\\pi} (\\pi - \\pi) = 0$. If this coefficient is zero, the equation $C \\cdot w(0)=0$ is trivially satisfied and does not lead to a contradiction, even if $w(0) \\neq 0$. This invalidates the central argument for ill-posedness."
      }
    ],
    "token_usage": {
      "input": 33579,
      "thinking": 21636,
      "output": 1168
    }
  },
  {
    "entry_id": 202,
    "retraction_id": "1404.7350v2",
    "paper_id": "1404.7350v1",
    "retraction_comment": "The paper has been withdrawn by the author since Lemma 3.27 is wrong. The author thanks [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Failure of CH at stages $\\alpha \\ge \\omega_1$",
        "Location": "Throughout, critically for Theorem 2.11 (p.10, proof on p.15), Proposition 4.11 (p.22), and their use in the overall iteration in Section 5 (Lemmas 5.5, 5.6).",
        "Explanation": "The construction of the Milliken-Taylor ultrafilters $\\mathcal{U}_\\alpha$ (via Theorem 2.11) and the selective ultrafilters $\\mathcal{R}_{i,\\alpha}$ at limit stages $\\alpha$ with countable cofinality (via Proposition 4.11) explicitly assume the Continuum Hypothesis (CH) holds in the model $\\mathbf{V}_\\alpha$ where these objects are constructed. However, the paper describes a countable support iteration of $\\sigma$-centred forcings $\\mathbb{P}_{\\omega_2}$ of length $\\omega_2$. Such an iteration typically forces $2^{\\aleph_0} = \\aleph_2$ (e.g., if the ground model satisfies GCH or $2^{\\aleph_0} < \\aleph_2, 2^{\\aleph_1}=\\aleph_2$). Thus, CH ($2^{\\aleph_0}=\\aleph_1$) will fail in $\\mathbf{V}_\\alpha$ for stages $\\alpha \\ge \\omega_1$. This means the premises for Theorem 2.11 and Proposition 4.11 are not met for $\\alpha \\ge \\omega_1$, invalidating the construction of iterands $\\mathbb{Q}_\\alpha = \\mathbb{M}(\\mathcal{U}_\\alpha)$ and the limit step arguments for $\\mathcal{R}_{i,\\alpha}$ for these stages. The paper's assertion (p.22) that CH holding for $\\alpha < \\omega_1$ is sufficient to 'go up to $\\mathbb{P}_{\\omega_2}$' appears to overlook this issue."
      },
      {
        "Problem": "Potential misapplication of Eisworth's P-point preservation theorem due to non-standard definition of Rudin-Blass order.",
        "Location": "Definition 2.9 (Rudin-Blass order, p.9), Theorem 3.3 and 3.4 (Eisworth's theorem, p.16), and its application in Property (P1) (p.23) for $\\Phi(\\mathcal{U}) \\not\\leq_{\\rm RB} \\mathcal{E}$ and subsequent preservation of $\\mathcal{E}$ (Property P2).",
        "Explanation": "The paper defines $\\mathcal{F} \\leq_{\\rm RB} \\mathcal{G}$ (Definition 2.9) as 'iff there is a finite-to-one $f$ such that $f(\\mathcal{F}) \\subseteq f(\\mathcal{G})$', which translates to $f_*(\\mathcal{F}) \\subseteq f_*(\\mathcal{G})$. Theorem 3.3 (and 3.4) state that a P-point $\\mathcal{W}$ is preserved by $\\mathbb{M}(\\mathcal{U})$ iff $\\mathcal{W} \\not\\geq_{\\rm RB} \\Phi(\\mathcal{U})$ (using the paper's definition, this means $\\neg \\exists f (f_*(\\mathcal{W}) \\subseteq f_*(\\Phi(\\mathcal{U})))$). However, the cited results from Eisworth (Theorem 4 and Proposition 2.4 in TAMS 1999, not Corollary 2.5 as stated for the '$\\leftarrow$' direction) use the Rudin-Keisler order condition $\\mathcal{W} \\not\\geq_{\\rm RK} \\Phi(\\mathcal{U})$ (i.e., $\\neg \\exists g (g_*(\\Phi(\\mathcal{U})) = \\mathcal{W})$). The paper's $\\leq_{\\rm RB}$ definition is non-standard, and the condition $\\mathcal{W} \\not\\geq_{\\rm RB} \\Phi(\\mathcal{U})$ derived from it is not clearly equivalent to Eisworth's $\\mathcal{W} \\not\\geq_{\\rm RK} \\Phi(\\mathcal{U})$. If the condition used for preservation is incorrect, the argument that the P-point $\\mathcal{E}$ is preserved throughout the iteration (Property P2) may be invalid, which would be fatal to the overall construction."
      }
    ],
    "token_usage": {
      "input": 63295,
      "thinking": 18925,
      "output": 1006
    }
  },
  {
    "entry_id": 203,
    "retraction_id": "1612.01576v2",
    "paper_id": "1612.01576v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error in the inductive proof of Theorem 3.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper claims to provide a combinatorial proof for the optimal $O(n \\log n)$ mixing time of Glauber dynamics (Theorem 1.1 / Theorem 3.1), but the presented proof appears to establish a mixing time of $O(n (\\log n)^2)$.",
        "Location": "Page 7, Proof of Theorem 3.1, and statement of Theorem 1.1 / 3.1.",
        "Explanation": "The inductive proof for Theorem 3.1 concludes that the coupling time $\\Tprod$ (defined as time for $\\max_v \\Pr[X_T(v) \\neq Y_T(v)] \\le 1/(4n)$, which implies $\\Tcoup(1/4)$) is bounded by $c n (\\log n)^2$. The paper then states: 'A standard boosting argument then gives that the mixing time of the Glauber dynamics on $G$ is $O(n \\log n)$', citing Theorem 5.2 from Dyer, Sinclair, Vigoda, and Weitz (DSVW). However, DSVW Theorem 5.2 has a specific hypothesis about coupling time on small subgraphs ($L_0^{d+1}/\\log L_0$) that is not directly met by the $O(n (\\log n)^2)$ intermediate result. If the $O(n (\\log n)^2)$ is the tightest bound on $\\Tcoup(1/4)$ from this proof, then the claim of achieving the optimal $O(n \\log n)$ bound is not fully substantiated by the provided argument or reference. This would mean the new proof yields a suboptimal bound."
      },
      {
        "Problem": "In the proof of Theorem 4.2 (monotone systematic scan), the bounding of $\\Pr[W_T^\\mu(v) \\neq Z_T^\\mu(v)]$ relies on an inequality that may not hold for the specific coupling generated by the dynamics.",
        "Location": "Page 11, Proof of Theorem 4.2 (last paragraph of the proof).",
        "Explanation": "The proof argues that $W_0^\\mu(B)$ and $Z_0^\\mu(B)$ are sampled from their respective stationary distributions ($\\pi_W, \\pi_Z$) and coupled monotonically. Thus, $W_T^\\mu(v) \\sim \\pi_{W,v}$, $Z_T^\\mu(v) \\sim \\pi_{Z,v}$, and $W_T^\\mu(v) \\succeq Z_T^\\mu(v)$ (monotonically ordered). The proof then claims $\\Pr[W_T^\\mu(v) \\neq Z_T^\\mu(v)] \\le 2q {\\|\\pi_{W,v}-\\pi_{Z,v}\\|}_{\\textsc{tv}}$. While such inequalities hold for optimal (TV-minimizing) couplings or specific scenarios (e.g., $q=2$ spins), it's not generally true that a dynamically generated monotone coupling (even between stationary distributions) satisfies this upper bound related to the total variation distance of its marginals with this specific constant $2q$. The validity of this step is crucial for the $O(\\log n (\\log \\log n)^2)$ bound for general monotone systematic scans."
      }
    ],
    "token_usage": {
      "input": 33735,
      "thinking": 25099,
      "output": 748
    }
  },
  {
    "entry_id": 204,
    "retraction_id": "1501.05036v2",
    "paper_id": "1501.05036v1",
    "retraction_comment": "Eq. (9) only implies correlation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The justification for Assumption (H) (continuous exponential length decay of an LCS segment) based on the provided LCS definition is insufficient, potentially limiting the generality of the main theorem.",
        "Location": "Assumption (H) on page 5, its use in the proof of Theorem 1 on page 6, and the motivation for Assumption (H) on pages 4-5.",
        "Explanation": "Theorem 1, the central result of the paper, states that the path-averaged scalar $\\bar{f}$ becomes uniform along a hyperbolic LCS for large $T$. Its proof relies critically on Assumption (H), which posits that the length $\\ell(t)$ of an LCS segment (initially $\\ell(t_0)$) decays as $\\ell(t) \\le \\ell(t_0)e^{-\\lambda (t-t_0)}$ for all $t \\in [t_0, t_0+T]$ (for a repelling LCS). Hyperbolic LCSs are defined via conditions (A)-(D) (page 4), which are based on properties of the Cauchy-Green strain tensor $C_{t_0}^{t_0+T}$ (i.e., deformation over the full interval $[t_0, t_0+T]$). The paper motivates Assumption (H) by referring to the general shrinking nature of LCSs. However, it does not rigorously prove or cite a proof that satisfying conditions (A)-(D) for $C_{t_0}^{t_0+T}$ necessarily implies that $\\ell(t) = \\text{length}(\\phi_{t_0}^t(\\mathcal{R}(t_0)))$ exhibits such continuous exponential decay for all intermediate times $t$. The length $\\ell(t)$ depends on how the intermediate-time Cauchy-Green tensor $C_{t_0}^t$ acts on the initial tangent vectors of the LCS (which are aligned with $\\bxi_1(C_{t_0}^{t_0+T})$). This relationship is not shown to guarantee the specific exponential decay form of Assumption (H). If Assumption (H) does not hold for all LCSs defined by (A)-(D), then Theorem 1 and the main conclusion of the paper (that hyperbolic LCSs align with contours of path-averaged scalars) are not proven in their stated generality, but only for the subset of LCSs that additionally satisfy Assumption (H)."
      },
      {
        "Problem": "The theoretical justification for the observed alignment of general strainlines (not necessarily LCSs) with contours of the path-averaged scalar is overstated.",
        "Location": "Section 4.2, page 9, in the discussion of Figure 5(a).",
        "Explanation": "The paper presents numerical results (Figure 5(a)) showing a strong alignment between general strainlines and the contours of the path-averaged scalar $\\bar{f}$. The paper states: 'This strong alignment is only explained by the length-shrinking property of strainlines (Proposition 1) and Theorem 1.' However, Proposition 1 only guarantees that the length of a strainline at the final time $t_0+T$ is less than or equal to its initial length (i.e., $\\ell(t_0+T) \\le \\ell(t_0)$), which is true if $\\lambda_2 \\ge 1$. This does not ensure significant shrinkage for all strainlines, nor does it dictate the behavior of $\\ell(t)$ for intermediate times $t \\in (t_0, t_0+T)$. Theorem 1, on the other hand, is specifically proven for hyperbolic LCSs that satisfy the stronger Assumption (H) (exponential decay). General strainlines may not satisfy Assumption (H) or have consistently large enough $\\lambda_2$ values along them to ensure that the time integral of their length, divided by $T$, vanishes as $T \\to \\infty$. Therefore, the provided theoretical arguments (Proposition 1 and Theorem 1) do not sufficiently explain why $\\bar{f}$ should be nearly uniform along general strainlines to the same degree of rigor as argued for LCSs satisfying Assumption (H)."
      }
    ],
    "token_usage": {
      "input": 16828,
      "thinking": 12398,
      "output": 910
    }
  },
  {
    "entry_id": 205,
    "retraction_id": "1208.6493v2",
    "paper_id": "1208.6493v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in a claim about singular supports in the proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of Paley-Wiener-Schwartz theorem leading to a false claim about the decay of sample values $f(n)$.",
        "Location": "Page 2, Section 2, Proof of Theorem 1.2, third paragraph. (Specifically, the sentence starting \"Also, by the Payley-Wiener-Schwartz theorem...\" and the subsequent deduction \"In particular, $|f(n)|\\leq C(1+|n|)^{-N}$...\")",
        "Explanation": "The paper states that for $F \\in \\calE'(\\mR)$ with support in $(-\\pi,\\pi)$, its inverse Fourier transform $f(z)$ satisfies $|f(z)|\\leq C (1+|z|)^{-N} e^{\\pi  |\\textrm{Im}(z)|}$, leading to the claim that $f(n)$ decays polynomially ($|f(n)|\\leq C(1+|n|)^{-N}$). This is incorrect. The Paley-Wiener-Schwartz theorem implies that $f(z)$ is an entire function of exponential type $\\pi$ with polynomial growth, i.e., $|f(z)|\\leq C (1+|z|)^{M} e^{\\pi  |\\textrm{Im}(z)|}$ for some $M \\ge 0$. Thus, $f(n)$ can grow polynomially, not necessarily decay. This error makes the provided justification for the convergence of the series $\\sum_{n\\in \\mZ} f(n)e^{-in\\omega}$ in $\\calS'(\\mR)$ unsound. While the series does converge in $\\calS'(\\mR)$ (because $f(n)$ are coefficients of a periodic tempered distribution $\\widetilde{F}$), the reason (decay of $f(n)$) given in the paper is false. Example 3.2, where $F=\\delta'$, results in $f(n)=-in/(2\\pi)$, which grows linearly and directly contradicts the paper's assertion of decay for $f(n)$."
      },
      {
        "Problem": "Incorrect description of the support of the periodized distribution $\\widetilde{F}$.",
        "Location": "Page 2, Section 2, Proof of Theorem 1.2, fourth paragraph. (Specifically, the sentence \"We have that the singular support of $\\widetilde{F}$ is contained in its support, which is furthermore included in the set $\\bigcup_{n\\in\\mZ}(n\\pi,(n+1)\\pi)$.\")",
        "Explanation": "The paper claims that the support of $\\widetilde{F}=F\\ast \\sum_{n\\in\\mZ} \\delta_{2\\pi n}$ is included in the set $\\bigcup_{n\\in\\mZ}(n\\pi,(n+1)\\pi)$, which is equivalent to $\\mR \\setminus \\pi\\mZ$ (the real line excluding all integer multiples of $\\pi$). This is false. Since $\\text{supp}(F) \\subset (-\\pi,\\pi)$, $\\text{supp}(\\widetilde{F}) = \\text{supp}(F) + 2\\pi\\mZ$. If $0 \\in \\text{supp}(F)$ (e.g., if $F=\\delta_0$), then $2\\pi k \\in \\text{supp}(\\widetilde{F})$ for all integers $k$. These points ($2\\pi k$) are integer multiples of $\\pi$ and are thus not in $\\mR \\setminus \\pi\\mZ$. For $F=\\delta_0$, $\\text{supp}(\\widetilde{F}) = 2\\pi\\mZ$, which contradicts the paper's claim. While this specific misstatement does not invalidate the argument that $\\textrm{sing supp } \\1_{[-\\pi,\\pi]}\\bigcap \\textrm{sing supp } \\widetilde{F}=\\emptyset$ (which is crucial for the product $\\1_{[-\\pi,\\pi]} \\widetilde{F}$ to be well-defined and relies on $\\text{supp}(F)$ being strictly within $(-\\pi,\\pi)$), it is a significant error in describing the properties of $\\widetilde{F}$."
      }
    ],
    "token_usage": {
      "input": 5534,
      "thinking": 19304,
      "output": 939
    }
  },
  {
    "entry_id": 206,
    "retraction_id": "1909.06350v2",
    "paper_id": "1909.06350v1",
    "retraction_comment": "The proof contained an error in the definition of the coupling in (4.8) that the authors currently cannot fix. The authors thank [REDACTED-NAME] for pointing this error out to them",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unusual $n$-dependent assumption on entry distribution",
        "Location": "Assumption 2.2 (page 4), Remark 2.3 (page 4), Lemma 3.3 (page 7)",
        "Explanation": "Assumption 2.2 states that the probability density $g$ of the entry $\\chi$ satisfies $\\|g\\|_{1+\\alpha} \\le n^\\beta$. If $\\beta > 0$, this is a strong and unusual assumption, implying that the entry distribution can become 'less regular' as $n$ increases. Universality results typically assume $n$-independent properties for the entry distribution. Remark 2.3 and Lemma 3.3 state this assumption is used for bounding $\\mathbb{E}|I_2^{(j)}|$ via [MR3770875, Prop 5.7]. However, Proposition 5.7 in [MR3770875] (Bao-Erdos-Schnelli 2017, for Wigner matrices) does not appear to use or support such an $n$-dependent bound on the density norm. If $n^\\beta$ with $\\beta>0$ is essential, it severely restricts the generality of the matrices. If it's not essential (e.g., if $\\beta=0$ is sufficient), the assumption is misstated."
      },
      {
        "Problem": "Potentially incorrect error bounds in the estimate of $I_3(t_1) - \\tilde{I}_3(t_1)$",
        "Location": "Eq. (4.7) (page 10) and its derivation",
        "Explanation": "The estimation of $\\mathbb{E}|I_3^{(i_1)}(t_1)-\\widetilde{I}_3^{(i_1)}(t_1)|$ in Eq. (4.7) involves summing contributions from different eigenvalue regimes. The bounds for these sums, such as $n^{\\bar{\\omega}}/(n^{1+\\omega_u}\\eta_0)$ for the first sum, rely on approximations of a kernel function $\\frac{\\eta (\\lambda+\\mu)}{(\\lambda^2+\\eta^2)(\\mu^2+\\eta^2)}$ and eigenvalue distributions. There are potential issues: (a) The exponent $\\omega_u$ (from $t_u=n^{-1+\\omega_u}$ in Prop 2.9) appears in the denominator, but the eigenvalue difference bound from Prop 2.9 is $n^{-1-\\omega_b}$. These exponents $\\omega_u, \\omega_b$ are distinct in Prop 2.9. (b) The kernel estimation might not capture the true worst-case over $i \\in [1, n^{\\bar{\\omega}}]$ and $\\eta \\in [\\eta_0, \\eta_1]$. For instance, if $\\lambda_i \\sim 1/n$ and $\\eta \\sim \\eta_1 = n^{-1+\\delta_1}$, the kernel can be as large as $n^{2+\\delta_1}$, potentially leading to a different overall exponent. An error in these crucial estimates could render the total error term non-negligible, affecting the argument in Lemma 4.3."
      },
      {
        "Problem": "Clarity and correctness of the error estimate for $E_1$ in Lemma 5.2",
        "Location": "Proof of Lemma 5.2 (page 13-14), specifically the bound for $E_1$",
        "Explanation": "Lemma 5.2 bounds the error from the stochastic advection equation. The estimation of the term $E_1$ (a stochastic integral involving differences between true singular values $\\lambda_i^z$ and their deterministic approximations $\\gamma_i^z$) is critical. The paper states: 'by Schwarz inequality we can bound the quadratic variation of $E_1$ by $\\left(n\\int_{\\eta_1}^{\\eta_2} \\frac{n^\\xi}{n^2\\eta^2}\\, d\\eta\\right)^2\\lesssim \\frac{n^\\xi}{(n\\eta_1)^2}$'. This step is unclear: 'quadratic variation of $E_1$' is non-standard as $E_1$ itself is not written as a martingale, and the application of Schwarz inequality to arrive at this specific squared form needs justification. An alternative derivation suggests $\\mathbb{E}|E_1| \\lesssim n^{\\xi/2-\\delta_1}$, while the paper's result implies $\\mathbb{E}|E_1| \\lesssim n^{\\xi-1-\\delta_1}$ (via BDG from their variance estimate). If the paper's bound is incorrect and a tighter bound is actually needed, this could be problematic for the proof of Lemma 5.2, which is essential for relating $I_4$ to resolvents at a larger spectral scale $\\eta_2$."
      },
      {
        "Problem": "Possible typo in the definition of the Dyson Brownian Motion flow",
        "Location": "Eq. (4.5) (page 9)",
        "Explanation": "Equation (4.5) defines a Dyson Brownian Motion (DBM) flow as $d\\widehat{X}_t= \\frac{d\\widehat{B}_t}{n}$. Standard DBM scalings for matrix entries usually involve a $1/\\sqrt{n}$ factor, i.e., $d\\widehat{X}_t= \\frac{d\\widehat{B}_t}{\\sqrt{n}}$, if $d\\widehat{B}_t$ represents a matrix of standard Brownian motions. The SDE for singular values given in Eq. (4.6) with a diffusion term $\\sqrt{\\frac{2}{\\beta n}} d\\frak{b}_i$ corresponds to this $1/\\sqrt{n}$ scaling for matrix entries. If $d\\widehat{X}_t= \\frac{d\\widehat{B}_t}{n}$ is intentional, the variance of the added noise is $t/n^2$ rather than $t/n$. This would affect the time parameter $t_u$ used in Proposition 2.9, which relies on a standard DBM scaling. While likely a typo, if it's not, the connection to Proposition 2.9 needs to be re-evaluated."
      }
    ],
    "token_usage": {
      "input": 37523,
      "thinking": 17929,
      "output": 1432
    }
  },
  {
    "entry_id": 207,
    "retraction_id": "0904.3281v2",
    "paper_id": "0904.3281v1",
    "retraction_comment": "The integrality statement is false. See the publication \"A norm compatible system of Galois cohomology classes for GSp(4)\" of the author for a correct statement and proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Clarity of the trace argument in Proposition 3.2",
        "Location": "Section 3, Proof of Proposition 3.2, page 6-7",
        "Explanation": "The proof of Proposition 3.2 states that $tr(E^k_{1/N', 0}) = E^k_{1/N, 0}$. The argument relies on factoring the trace map $Tr_{N',N}$ for the cover $f_{N'N}: \\g{Y}(N') \\rightarrow \\g{Y}(N)$ into $Tr_1 = Tr_{\\g{Y}(N')/\\g{Y}(N,N')}$ and $Tr_2 = Tr_{\\g{Y}(N,N')/\\g{Y}(N)}$. The paper explicitly argues $Tr_1(E^k_{1/N',0}) = E^k_{1/N,0}$ (class on $\\g{Y}(N,N')$) using Lemma 3.1(ii). However, the argument for $Tr_2(E^k_{1/N,0}|_{\\g{Y}(N,N')}) = E^k_{1/N,0}|_{\\g{Y}(N)}$ is not detailed. If $X_{Y(N,N')} = g^* X_{Y(N)}$ (where $g: \\g{Y}(N,N') \\to \\g{Y}(N)$ is the covering map), then $g_* g^* X_{Y(N)} = (\\text{deg } g) X_{Y(N)}$. This would introduce an extraneous factor $\\text{deg } g$. The proof implicitly assumes this degree factor is 1 or that the trace behaves as $g_* E^k_s = E^k_{g(s)}$. While this is often true for such 'motivic' classes due to their distribution relations (as implied by Lemma 2.6 and Lemma 3.1.ii), a more explicit justification for why $Tr_2$ does not introduce a degree factor would strengthen the argument, especially concerning integrality if division by degree were required."
      },
      {
        "Problem": "Assumption in Lemma 2.6 regarding triviality of a torsor",
        "Location": "Section 2.4, page 4",
        "Explanation": "Lemma 2.6 assumes that for an isogeny $f: E' \\rightarrow E$ and a torsion section $t: S \\rightarrow E$, the fiber product $E'_t = E' \\times_{E,t} S$ is a trivial $Z$-torsor over $S$ (where $Z = \\text{Ker } f$), meaning it is isomorphic to $\\coprod_{g \\in G} S$. This is stated as '$f$ is trivial over $S$, or in other terms, that we have a cartesian square...'. This triviality is equivalent to $H^1_{et}(S, Z)=0$. While this condition is satisfied in the application in Section 3 (where $S=\\g{Y}(N)$ and $Z=E[a]$ because the sections $t'_g$ are explicitly given by linear combinations of the universal $N$-torsion sections $e_1, e_2$), the lemma is stated more generally. It might be beneficial to state the condition $H^1_{et}(S, Z)=0$ or the existence of global sections $t'_g: S \\to E'$ explicitly as a hypothesis for Lemma 2.6."
      },
      {
        "Problem": "Potential confusion in notation for Eisenstein classes",
        "Location": "Section 3, page 5, definition of $E_{\\alpha, \\beta}^k$",
        "Explanation": "The Eisenstein class $E_{\\alpha, \\beta}^k$ is defined for $(\\alpha, \\beta) \\in (\\mathbb{Q} / \\mathbb{Z})^2$. If $N\\alpha=N\\beta=0$, one writes $(\\alpha, \\beta)=(a/N, b/N)$ and defines $E_{\\alpha, \\beta}^k=E^k_{(a e_1+ b e_2)}$. This means the class is associated with the $N$-torsion section $a e_1+ b e_2$. Later, $E^k_{1/N, 0}$ is used. With the established notation, this means $\\alpha=1/N, \\beta=0$, so $a=1, b=0$, and the section is $1 \\cdot e_1 + 0 \\cdot e_2 = e_1$. This is consistent. However, in some literature, $X_{a/N, b/N}$ might refer to a section $P$ such that $NP = ae_1+be_2$. The paper's notation is internally consistent but careful reading is required. This is a minor point of potential confusion rather than an error."
      }
    ],
    "token_usage": {
      "input": 16311,
      "thinking": 25747,
      "output": 1104
    }
  },
  {
    "entry_id": 208,
    "retraction_id": "1705.03737v2",
    "paper_id": "1705.03737v1",
    "retraction_comment": "This paper contains a flaw that the proposed methods were overfitted thus the experimental results were not suitable. At this point, we do not want to update this article bu are developing a quite new approache where the authors are different from this paper,, and the title of our paper will be changed. 8 pages, 6 figures",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous Architecture and Output Specification for DeepView_dec",
        "Location": "Section 3 (paragraph 'Decoupled network', Figure 3), and Section 5.1 (paragraph 'Implementation details', sentence 'For DeepView_dec, the number of filter in the last convolution layer is 1 as its input and output are Y or CbCr.')",
        "Explanation": "The paper does not explicitly state the mechanism by which DeepView_dec generates the right view (e.g., direct pixel regression vs. disparity-based rendering like DeepView_ren). Figure 3 suggests direct regression as it lacks a rendering network component. More critically, the description of the chrominance network's output layer (specified as having 1 filter in Sec 5.1) contradicts the need to produce two distinct chrominance channels (Cb and Cr) for proper YCbCr to RGB conversion, as implied by Figure 3 ('Chrominance Network (Cb, Cr)') and the goal of color image generation. This makes the architecture for DeepView_dec, particularly its chrominance processing, unclear or incorrectly specified, potentially impacting the validity and reproducibility of its reported high accuracy."
      },
      {
        "Problem": "Undefined 'DeepView_rec' Architecture",
        "Location": "Section 5.3 (text referring to 'DeepView_rec', Table 2 caption, Figure 4/5 caption 'Qualitative performance of DeepView_rec'), and Table 5 (in Section 6.3, table header and data rows for 'DeepView_rec').",
        "Explanation": "The term 'DeepView_rec' is used multiple times in the experimental sections (5.3 for spatial scalability, Table 5 for computation efficiency) but is never defined in the paper. It is unclear if 'DeepView_rec' is a typo for DeepView_ren, a different variant, or a generic FCN baseline. Without a clear definition, the results attributed to 'DeepView_rec' (including key efficiency comparisons against the state-of-the-art and scalability analysis) are ambiguous, making it difficult to validate the specific performance claims for the proposed architectures."
      },
      {
        "Problem": "Unclear Upsampling Mechanism due to Non-Standard Terminology",
        "Location": "Section 3 (paragraph 'FCN with rendering network', sentence 'In order to secure large receptive fields... we propose to use multiple down-scaling and up-scaling convolution (deconvolution) layers with strides of 2 and 0.5, respectively.')",
        "Explanation": "The paper describes using 'up-scaling convolution (deconvolution) layers with strides of ... 0.5'. While a standard convolution with a fractional stride of 0.5 can perform upsampling, using this stride value for 'deconvolution layers' (typically referring to transposed convolutions) is non-standard and confusing. Transposed convolutions usually achieve upsampling with integer strides (e.g., stride 2 for 2x upsampling). This ambiguous terminology obscures the precise architecture of the upsampling paths in both DeepView_ren and DeepView_dec, hindering reproducibility and clear understanding of the network structure."
      }
    ],
    "token_usage": {
      "input": 9845,
      "thinking": 10131,
      "output": 691
    }
  },
  {
    "entry_id": 209,
    "retraction_id": "2307.01627v2",
    "paper_id": "2307.01627v1",
    "retraction_comment": "The proof of Theorem 2.6 is incorrect. Without this theorem the main claim of the paper becomes unproven",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially incorrect application of Turull's Theorem 1.3",
        "Location": "Proof of Theorem 2.5, step (3), page 5.",
        "Explanation": "The proof of Theorem 2.5 asserts that a character $\\mu = \\lambda \\otimes \\lambda_1$ is a constituent of $\\chi_{QA_0}$ because 'at most one irreducible $QA_0$-character is missing', based on Turull's Theorem 1.3(iii). However, if $\\mu$ itself is this specific 'missing' character $\\zeta_0$ from Turull's theorem, then $\\mu$ would not be a constituent of $\\chi_{QA_0}$. This could invalidate the subsequent summation argument $\\Sigma_{i=1}^n\\eta_i \\subseteq \\chi_{QA}$ and the final conclusion that $\\chi_A$ contains the regular $A$-character, as it relies on all constructed $\\mu_i$ being constituents."
      },
      {
        "Problem": "Insufficient justification for $P=E$",
        "Location": "Proof of Theorem 2.6, page 6, paragraph following 'Thus we have $Z(E)=\\Phi(P)=P^{\\prime}$.'",
        "Explanation": "In the proof of Theorem 2.6, after establishing $P/\\Phi(P) = Z(P)/\\Phi(P) \\oplus E/\\Phi(P)$ and showing $E$ would be extraspecial if $Z(E)=\\Phi(P)$, the argument states 'So it holds by induction that $P=E$'. This conclusion implies $Z(P)/\\Phi(P)$ is trivial (i.e., $Z(P)=\\Phi(P)$). However, the justification for this step, presumably from hypothesis (i) ($P=[P,B]^G$), is not provided or made clear, leaving a gap in the argument that $P$ must be extraspecial."
      },
      {
        "Problem": "Unjustified chain of centralizations in the A-tower",
        "Location": "Section 3, Proof of The Theorem, step (2), page 7.",
        "Explanation": "In step (2) of the main theorem's proof, it is argued that if a subgroup $B \\leq A$ (with $\\ell(B) \\geq 1$) centralizes $Q/(\\Phi(Q)Q_0)$ (related to $P_{h-2}/\\Phi(P_{h-2})$), then 'It follows that $[P_i,B]=1$ for each $i < h-2$'. This assertion implies that centralization by $B$ propagates downwards through the A-tower (from $P_k/\\Phi(P_k)$ to $P_{k-1}/\\Phi(P_{k-1})$, etc.). This 'reverse' influence is not a standard property of such towers (e.g., Turull's irreducible A-towers) and is not justified in the text. The properties of the tower usually describe how $S_i$ acts on $P_{i+1}$, not how $C_A(P_{i+1})$ relates to $C_A(P_i)$."
      },
      {
        "Problem": "Application of a subgroup-based theorem to sections",
        "Location": "Section 3, Proof of The Theorem, step (4), pages 7-8.",
        "Explanation": "The proof of the main theorem applies Theorem 2.6 to the setup where $P=P_{h-1}$ and $Q=S_{h-2}$. Theorem 2.6 is formulated for groups $P, Q$ which are subgroups of $GA$, with specific normality conditions like $P \\unlhd GA$ and $QC_G(P/P') \\unlhd GA$. However, in the main theorem's context, $P_{h-1} = S_{h-1}/T_{h-1}$ is a section, and $S_{h-2}$ acts on this section. These sections/actors do not generally satisfy the subgroup normality conditions (e.g., $P_{h-1}$ is not necessarily a normal subgroup of $XA$). Applying a theorem designed for specific subgroup structures to sections requires careful justification or re-formulation, which is absent."
      }
    ],
    "token_usage": {
      "input": 10197,
      "thinking": 20873,
      "output": 973
    }
  },
  {
    "entry_id": 210,
    "retraction_id": "1907.08721v2",
    "paper_id": "1907.08721v1",
    "retraction_comment": "A wrong fact on Hochschild homology was used in the proof of the main result (section 2, Theorem 2.0.4)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear construction and unsubstantiated injectivity of a key map in the proof of Theorem 2.0.4.",
        "Location": "Page 5, Proof of Theorem 2.0.4 (labelled 'Proof of Theorem 2.0.4' in the text, but refers to Theorem labeled 2.0.4 in section 2, which is also called 'main1' in the text). Specifically, the diagram and the subsequent deduction of injectivity.",
        "Explanation": "The proof of Theorem 2.0.4 claims an injective morphism $\\mathfrak{I}_{X,v}^{\\bullet} \\hooklongrightarrow H^{\\bullet}(\\tilde{X}, \\omega_{\\tilde{X}})$. This relies on constructing a map $\\psi_a: L \\to L \\otimes \\omega_{\\tilde{X}}[k]$ (denoted $\\LL \\pi^*(i_{\\RR \\pi_*(L)}(a)) \\oplus 0$ in the paper) for each $a \\in \\mathfrak{I}_{X,v}^k$. The construction of $\\psi_a$ via the commutative diagram is not sufficiently detailed, particularly how it relates to $\\LL \\pi^*(i_{\\RR \\pi_*(L)}(a))$. A critical step involves the transition from sheaves twisted by $\\pi^*\\omega_X$ (associated with $\\LL\\pi^*$) to sheaves twisted by $\\omega_{\\tilde{X}}$ (the target cohomology). The relationship $\\omega_{\\tilde{X}} \\cong \\pi^*\\omega_X \\otimes \\mathcal{O}(K_{\\tilde{X}/X})$ and the properties of the map $\\pi^*\\omega_X \\to \\omega_{\\tilde{X}}$ (e.g., if $K_{\\tilde{X}/X}$ is effective) are not discussed, nor is their impact on the asserted injectivity of $a \\mapsto \\psi_a$. The claim that $\\psi_a$ is non-zero if $a \\neq 0$ is not adequately justified by the diagram."
      },
      {
        "Problem": "Ambiguity in the definition of the 'dual homological unit' $\\mathfrak{I}_X^{\\bullet}$.",
        "Location": "Page 3, Definition 2.0.2; Page 2, last sentence of Introduction; Page 4, Remark 2.0.3(1).",
        "Explanation": "The 'dual homological unit' $\\mathfrak{I}_X^{\\bullet}$ is defined as a 'graded algebra' in Definition 2.0.2. However, its proposed realization for a smooth projective variety $X$, $H^{\\bullet}(X, \\omega_X)$, is naturally a graded vector space (or $H^{\\bullet}(X, \\mathcal{O}_X)$-module), not an algebra. The introduction (page 2) also refers to it as a 'graded sub-vector space'. The definition does not specify an algebra product for $\\mathfrak{I}_X^{\\bullet}$, and no algebra structure is used in its properties. This is compounded by the maximality condition in Remark 2.0.3(1), which states: 'for any algebra $\\mathfrak{B}^{\\bullet}$ satisfying the conditions, any graded vector spaces injective morphism $r^{\\bullet} : \\mathfrak{I}_X^{\\bullet} \\hooklongrightarrow \\mathfrak{B}^{\\bullet}$ is necessarily an isomorphism.' If $\\mathfrak{I}_X^{\\bullet}$ is an algebra, this should refer to an algebra isomorphism. If $\\mathfrak{I}_X^{\\bullet}$ is a vector space, then its being a subspace of an 'algebra $\\mathfrak{B}^{\\bullet}$' that also satisfies the properties does not make sense in the context of maximality via a vector space injection leading to an isomorphism of potentially different structure types. This foundational definition needs to be precise and consistent."
      }
    ],
    "token_usage": {
      "input": 10752,
      "thinking": 22497,
      "output": 867
    }
  },
  {
    "entry_id": 211,
    "retraction_id": "1608.07104v2",
    "paper_id": "1608.07104v1",
    "retraction_comment": "This paper has been withdrawn due to errors in the crucial estimates in Lemma 1 and Theorem 5",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and incorrect definition of the symbol $p_k$.",
        "Location": "Section 2, page 3, definition of $p_k$ below equation for $(\\widehat{A_s f})_k$.",
        "Explanation": "The operator $A_s = D^2 + 2s(e^1+ie^2)\\cdot D$ acting on functions expanded in the $\\tilde{\\chi}_k$ basis (where $D$ acts as multiplication by $K=k+e^2/2$) should have the symbol $p_K = |K|^2 + 2s(e^1+ie^2)\\cdot K = |k+e^2/2|^2 + 2s(k_1 + i(k_2+1/2))$. The paper defines $p_k = |k+e^2/2| + 2s(k_1+ik_2)+is$. This definition has three issues: (1) $|k+e^2/2|$ instead of $|k+e^2/2|^2$. (2) $2s(k_1+ik_2)$ instead of $2s(k_1+i(k_2+1/2))$. The imaginary part $s(2k_2+1)$ is correct, but the real part and the $k_1, k_2$ terms are inconsistent with the operator $A_s$. While the proof of Lemma 2 implicitly uses the correct form for $p_K$ in the denominator of $S_k$, the explicit definition of $p_k$ is flawed, affecting the definition of $X_s^b$ norms and subsequent arguments relying on this explicit $p_k$ or its properties."
      },
      {
        "Problem": "The proof of the second estimate in Lemma 2 is flawed.",
        "Location": "Section 2, page 4, Lemma 2, proof of $\\norm{Du}_{b,s} \\leq 2\\norm{u}_{b+1/2,s}$.",
        "Explanation": "The proof requires showing $S_k = |k+e^2/2|^2 / |p_k| \\leq 4$. The argument for the case $\\kappa < 4s$ (where $\\kappa = |k+e^2/2|$) states $S_k \\leq \\frac{4s}{2s|k_2+1/2|} \\leq 4$. This relies on $\\kappa^2 \\leq 4s$ (which is not implied by $\\kappa < 4s$, e.g. if $s=1, \\kappa=3$, then $\\kappa < 4s$ but $\\kappa^2=9 > 4s=4$) and $|k_2+1/2| \\geq 1/2$. If, for example, $k_2=0$, then $|k_2+1/2|=1/2$. The estimate becomes $S_k \\leq \\kappa^2/s$. If $\\kappa^2 > 4s$ (but still $\\kappa < 4s$), then $S_k$ is not bounded by 4. For instance, if $s=1, k=(3,0,0,\\dots)$, then $\\kappa \\approx 3$. $\\kappa < 4s$ holds. $S_k \\approx 3^2/|3^2+2(1)(3)| = 9/15$ if $p_k = K^2+2sK_1$. Using the paper's $p_k$ from $S_k$ definition: $p_k = |K|^2+2sk_1+is(2k_2+1)$. If $k_2=0$, $\\text{Im}(p_k)=s$. Then $|p_k| \\geq s$. $S_k \\leq \\kappa^2/s$. If $\\kappa^2/s > 4$, the bound fails. E.g. $s=1, \\kappa=3$, $S_k \\leq 9$. This estimate is crucial for the properties of $X_s^b$ spaces, including Lemma 3."
      },
      {
        "Problem": "Misapplication of periodic function spaces and Fourier basis.",
        "Location": "Section 2, page 3, definition of $\\tilde{\\chi}_k(x)$.",
        "Explanation": "The functions $\\tilde{\\chi}_k(x) = \\exp(ix_2/2)\\chi_k(x)$ are used as an orthonormal basis. However, $\\exp(ix_2/2)$ is not periodic on $\\mathbb{T}^n = \\mathbb{R}^n/(2\\pi\\mathbb{Z})^n$; it is anti-periodic in $x_2$ for $2\\pi$ shifts (i.e., $e^{i(x_2+2\\pi)/2} = -e^{ix_2/2}$). This means that the spaces $X_s^b$ constructed are for functions on $Q=(-\\pi,\\pi)^n$ with specific (anti-)periodic boundary conditions in $x_2$, not for functions in $\\mathcal{D}(\\mathbb{T}^n)$ (smooth functions on the torus) as stated. This affects arguments involving functions like $u=\\mathbb{1}$ (the constant function), which is not representable in the standard way in this basis if strict (anti-)periodicity is enforced (its projection would be zero). This is a foundational issue for the setup of the problem on the torus."
      },
      {
        "Problem": "The argument for $\\norm{r}_{1/2,s} \\to 0$ is unsound.",
        "Location": "Section 3, page 6, proof of Theorem 6.",
        "Explanation": "The proof of CGO solutions relies on $\\norm{r}_{1/2,s} \\leq \\frac{1}{1-\\|qG_s\\|_{\\text{op}}} \\norm{q}_{-1/2,s}$. For $\\norm{r}_{1/2,s}$ to tend to 0 as $s \\to \\infty$, $\\norm{q}_{-1/2,s}$ must tend to 0 (or be controllable by $\\alpha$ which can be made small). The paper claims (page 6, after bilinear estimate) that if $s > R(\\alpha)$, then 'by setting $u=\\mathbb{1}$ we therefore have $q \\in X^{-1/2}_s$ with $\\norm{q}_{-1/2,s} \\leq \\alpha$'. This inference is incorrect. The bilinear estimate $\\abs{\\dual{q,uv}} \\leq \\alpha \\norm{u}_{1/2,s}\\norm{v}_{1/2,s}$ does not directly yield $\\norm{q}_{-1/2,s} = \\sup_{\\norm{v}_{1/2,s}=1} |\\dual{q,v}| \\leq \\alpha$. Taking $u=\\mathbb{1}$ (if valid in these spaces, see Problem 3) would give $|\\dual{q,v}| \\leq \\alpha \\norm{\\mathbb{1}}_{1/2,s} \\norm{v}_{1/2,s}$, so $\\norm{q}_{-1/2,s} \\leq \\alpha \\norm{\\mathbb{1}}_{1/2,s}$. The norm $\\norm{\\mathbb{1}}_{1/2,s}$ is not necessarily 1 or bounded in a way that makes this useful. A correct argument would require showing $\\sum |p_k|^{-1}|\\hat{q}_k|^2 \\to 0$, which typically needs $q \\exp(ix_2/2)$ to be in $L^2(Q)$, an assumption not justified for $q=\\Delta\\rho/\\rho$ with $\\rho \\in W^{1,p}$."
      },
      {
        "Problem": "Incorrect construction of complex vectors $z^1, z^2$ for proving $\\widehat{q}(k)=0$.",
        "Location": "Section 4, page 10, Step 5.",
        "Explanation": "To show $\\dual{q, \\chi_k}=0$ (i.e., $\\widehat{q}(k)=0$), the argument uses CGO solutions $u^1_m \\approx e^{iz^1_m \\cdot x}$ and $u^2_m \\approx e^{iz^2_m \\cdot x}$ such that $u^1_m u^2_m \\approx e^{ik \\cdot x}$. This requires $z^1_m+z^2_m = k$. The paper defines $z^1 = -k/2 + t\\eta_1 + is\\eta_2$ and $z^2 = k/2 + t\\eta_1 - is\\eta_2$, where $k, \\eta_1, \\eta_2$ are mutually orthogonal. With these definitions, $z^1+z^2 = 2t\\eta_1$. For $u^1_m u^2_m$ to approximate $e^{ikx}$, one would need $2t\\eta_1 = k$. Since $\\eta_1$ and $k$ are orthogonal, this implies $k=0$ (or $t=0$, which also leads to issues). Thus, the argument as presented can only show $\\widehat{q}(0)=0$, not for arbitrary $k \\in \\mathbb{Z}^n$. This invalidates the conclusion that $q_1=q_2$."
      }
    ],
    "token_usage": {
      "input": 13838,
      "thinking": 20610,
      "output": 2180
    }
  },
  {
    "entry_id": 212,
    "retraction_id": "2401.17112v2",
    "paper_id": "2401.17112v1",
    "retraction_comment": "Bug. Lemma 1 is incorrect. The lemma needs the sets to be closed under subtraction which they are not",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lemma 1 is false, which invalidates the proof of Theorem 2.",
        "Location": "Section 2, Lemma 1 and Theorem 2",
        "Explanation": "Lemma 1 states that if vectors $v_1, \\ldots, v_m$ are $\\mathcal{H}$-independent, then $\\Sigma_{i=1}^m\\alpha_i v_i = \\Sigma_{i=1}^m \\beta_i v_i$ (where $\\alpha_i, \\beta_i \\in S_i$) implies $\\alpha_i = \\beta_i$ for each $i$. The paper claims this 'follows from the previous definition by rearranging terms.' This would mean $\\Sigma_{i=1}^m (\\alpha_i - \\beta_i)v_i = 0$, and then applying $\\mathcal{H}$-independence to $\\delta_i = \\alpha_i - \\beta_i$. However, $\\delta_i$ is not necessarily in $S_i$, even if $S_i$ contains 0 and is symmetric (i.e., $x \\in S_i \\implies -x \\in S_i$). For example, if $S_i = \\{0, 1, 2, 4, 5\\}$ in $\\mathbb{Z}_6$ (this is $S_u$ from Section 3), then $1 \\in S_i, 2 \\in S_i$, but $1-(-2) = 1+2=3 \\notin S_i$. \nA specific counterexample to Lemma 1: Let $R=\\mathbb{Z}_6$, $n=1$, $m=1$. Let $v_1 = (3)$. Let $S_1 = \\{0,1,5\\}$ (this set contains 0 and is symmetric: $-1\\equiv 5$, $-5\\equiv 1$). The vector $v_1$ is $S_1$-independent because $a_1 v_1 = 0 \\pmod 6$ (i.e., $3a_1 \\equiv 0 \\pmod 6$) for $a_1 \\in \\{0,1,5\\}$ implies $a_1=0$. However, if we take $\\alpha_1=1 \\in S_1$ and $\\beta_1=5 \\in S_1$: $\\alpha_1 v_1 = 1 \\cdot (3) = (3)$, and $\\beta_1 v_1 = 5 \\cdot (3) = (15) \\equiv (3) \\pmod 6$. So, $\\alpha_1 v_1 = \\beta_1 v_1$ but $\\alpha_1 \\neq \\beta_1$. This contradicts Lemma 1. \nTheorem 2, which states $\\Pi_{i=1}^m |S_i| \\leq |R|^t$, is claimed to be 'immediate from the lemma above.' This typically means that all $\\Pi |S_i|$ sums $\\Sigma \\alpha_i v_i$ are distinct, hence must be less than or equal to the size of the codomain $|R|^t$. Since Lemma 1 is false, this proof of Theorem 2 is invalid. While Theorem 2 itself might be a known result (e.g., Cohen-Tverberg-Visser theorem), the paper provides a specific (and flawed) proof for it. This invalidates the paper's logical chain for its main result (Theorem 3), which relies on Theorem 2."
      },
      {
        "Problem": "The definition of $S_i$ in Theorem 4 (Diagonal Criterion) is inconsistent with the framework's requirements.",
        "Location": "Section 4, Theorem 4",
        "Explanation": "Theorem 4 (Diagonal Criterion) defines $S_i = R \\setminus \\{r: r \\cdot (v_i \\cdot v_i) = 0\\}$. The framework for $\\mathcal{H}$-independence, established in Section 2, requires that $0 \\in S_i$ for each $i$. However, the definition in Theorem 4 implies $0 \\notin S_i$ whenever $v_i \\cdot v_i \\neq 0$ (since $0 \\cdot (v_i \\cdot v_i) = 0$, so $0$ would be in the set being excluded from $R$). For example, if $R=\\mathbb{Z}_6$ and $v_i \\cdot v_i = 1$, then $S_i = \\mathbb{Z}_6 \\setminus \\{0\\} = \\{1,2,3,4,5\\}$, which does not contain $0$. This makes Theorem 4, as stated, incompatible with the definitions used in Section 2 and Section 3 (e.g., $S_u, S_v$ both contain 0). While Claim 1 uses specific sets $S_u, S_v$ that do satisfy $0 \\in S_i$, Theorem 4 is presented as a general summary of the 'key concept', but its formulation is flawed in the context of the paper's own definitions."
      }
    ],
    "token_usage": {
      "input": 3676,
      "thinking": 17809,
      "output": 1160
    }
  },
  {
    "entry_id": 213,
    "retraction_id": "1710.01525v2",
    "paper_id": "1710.01525v1",
    "retraction_comment": "We can not prove Lemma 1 in Sect 2.4, and Terras did not prove it either, we misunderstood Terras's result here. Thus our proof about Theorem 2 is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Theorem 1 is false for all even integers n > 1.",
        "Location": "Theorem 1 (page 3), and its proof (page 5-6)",
        "Explanation": "For any even integer n > 1, the Collatz sequence starts n, n/2, ... . Since n/2 < n, the Glide G(n) = 1. In this case, the number of odd steps O(n) = 0 and the number of even steps E(n) = 1. Substituting these into the inequality of Theorem 1, $2^{E(n)-1} < 3^{O(n)} < 2^{E(n)}$, yields $2^{1-1} < 3^0 < 2^1$, which simplifies to $1 < 1 < 2$. This is false because $1 < 1$ is false. The proof of Theorem 1 also fails for this case: if O(n)=0, then Res(n)=0 (as defined in Lemma 3, the sum is empty). The inequality $(\\frac{1}{2}-\\frac{3^{O(n)}}{2^{E(n)}})L<Res(n)$ in the proof becomes $(\\frac{1}{2}-\\frac{1}{2})L < 0$, which is $0 < 0$, a false statement. Furthermore, Lemma 3, which states $Res(n) < O(n)/3$, becomes $0 < 0/3$ or $0 < 0$, also false."
      },
      {
        "Problem": "The proof for the right-hand inequality of Theorem 1 ($3^{O(n)} < 2^{E(n)}$) is missing.",
        "Location": "Proof of Theorem 1 (page 6)",
        "Explanation": "The proof of Theorem 1 concludes by stating that $2^{E(n)-1} < 3^{O(n)}$, and then claims this implies the full inequality $2^{E(n)-1} < 3^{O(n)} < 2^{E(n)}$ (Eq. 3). However, no argument or derivation is provided in the proof of Theorem 1 to establish the right-hand part, $3^{O(n)} < 2^{E(n)}$. While this inequality is true for O(n) >= 1 (it can be derived from $K<n$ and $K = n \\cdot \\frac{3^{O(n)}}{2^{E(n)}} + Res(n)$ with $Res(n)>0$), the paper does not present this derivation."
      },
      {
        "Problem": "The justification for $Res(n) < O(n)/3$ in Lemma 3 is incomplete for the first term when n is odd.",
        "Location": "Proof of Lemma 3 (page 5)",
        "Explanation": "The proof of $Res(n) < O(n)/3$ relies on showing each term $\\frac{3^{O(n)-1-i}}{2^{\\lambda(i)}}$ is less than $1/3$. This, in turn, relies on the argument that $s_{u[i]}>n$ and $K<n$ imply $\\frac{3^{O(n)-i}}{2^{\\lambda(i)}}<1$. However, if $n$ is odd, the first odd term in the sequence is $s_{u[0]}=n$. For this $i=0$ term, the condition $s_{u[i]}>n$ is not met. The validity of $\\frac{3^{O(n)-1}}{2^{\\lambda(0)}} < 1/3$ (which means $3^{O(n)} < 2^{\\lambda(0)} = 2^{E(n)}$) needs the inequality $3^{O(n)} < 2^{E(n)}$, which is part of Theorem 1's conclusion and is not proven before or within Lemma 3's proof. While this term's bound does hold if $3^{O(n)} < 2^{E(n)}$ is separately established (see Problem 2), the paper's current proof structure for Lemma 3 does not adequately address this specific case for the $i=0$ term."
      }
    ],
    "token_usage": {
      "input": 9860,
      "thinking": 18758,
      "output": 962
    }
  },
  {
    "entry_id": 214,
    "retraction_id": "2011.05544v2",
    "paper_id": "2011.05544v1",
    "retraction_comment": "Comments are welcome. There is a problem with the Theorem 4.7. Which could be fixed by taking double duals (category of reflexive sheaves) but it ruins the double deformation construction",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of Horrocks' Theorem.",
        "Location": "Corollary 4.X.4 (stated as Corollary after Thm 4.X.3, used in Prop 4.7)",
        "Explanation": "Horrocks' Theorem (Thm 4.X.2) applies to 2-dimensional regular local rings. Corollary 4.X.4 uses it to argue about vector bundles on Spec(A) x (A^2 - {0}). The proof sketch mentions localizing $\\widetilde{E}$ at a maximal ideal $\\mathfrak{m}$ corresponding to $(0,0)$ and applying Horrocks to $A_{\\mathfrak{m}}$. If $A_{\\mathfrak{m}}$ refers to the local ring of $Spec(A) \\times \\mathbb{A}^2$ at a point $(x, (0,0))$, this ring is $(\\mathcal{O}_{A,x}[T,S])_{(T,S)}$, which has dimension $dim(\\mathcal{O}_{A,x}) + 2$. This is not 2-dimensional if $dim(A)>0$ (i.e. $dim(X)>0$). A correct argument might involve a fiber-wise application or a different theorem. This corollary is crucial for Proposition 4.7, which claims $C_{A,B}$ is in $(B^q)^n Vect(X \\times \\mathbb{A}^2)$."
      },
      {
        "Problem": "The proof of A1-invariance for K-theory of n-binary complexes (Prop 2.5) is insufficiently justified.",
        "Location": "Proposition 2.5, Section 2",
        "Explanation": "Proposition 2.5 claims $K((B^q)^n Vect(X))$ is $\\mathbb{A}^1$-invariant. The proof uses induction and the exact sequence (2.1). Firstly, the derivation of (2.1) itself is not fully detailed, especially the surjection $K_i((B^q)^{n-i-1}\\mathcal{N}) \\rightarrow K_i((B^q)^{n-i-1}C^q\\mathcal{N})$ which seems based on a $K_0$ argument. Secondly, using an exact sequence of K-groups to deduce $\\mathbb{A}^1$-invariance of the middle term from the invariance of the end terms is non-standard for proving $\\mathbb{A}^1$-invariance of K-theory spectra; such proofs usually require more machinery (e.g., resolution or localization arguments). This proposition is critical as it justifies simplifying the Grayson fibration's middle term in (3.2)."
      },
      {
        "Problem": "The recursive argument in Proposition 4.8 lacks necessary details and rigor.",
        "Location": "Proposition 4.8, Section 4",
        "Explanation": "Proposition 4.8 aims to show $\\pi_1(|d \\mapsto K_0^{\\oplus}((B^q)^n Vect(X\\times \\mathbb{A}^d))|)$ is trivial using a recursive argument. Several points are unclear: (1) The initial simplification in Remark 4.5 is not explicitly derived. (2) The step transforming an element $[\\alpha]-[\beta]$ to an expression involving deformations of a quotient object (e.g., $[B^{l_2}]-[B^{l_1}]$) relies on Remark 4.6.1 and the properties of the 'double deformation' $C_{A,A}$. The claim that the resulting extensions $l_1'$ and $l_2'$ for $B_0$ have matching middle and right terms needs clearer justification. (3) The 'rank decreasing' argument for termination needs to specify what rank is used for $n$-binary complexes and why it strictly decreases at each step to ensure termination."
      },
      {
        "Problem": "The proof of Lemma 4.3 regarding the triviality of extended objects is unsubstantiated.",
        "Location": "Lemma 4.3, Section 4",
        "Explanation": "Lemma 4.3 states that for an extended object $\\tilde{A}$ (pulled back from $X$ to $X \\times \\mathbb{A}^1$), its class $[\tilde{A}]$ in $\\pi_1(|d \\mapsto K_0^{\\oplus}((B^q)^n Vect(X\\times \\mathbb{A}^d))|)$ is trivial. The proof asserts that 'Triangular relations imply that $3[\\tilde{A}]=0$. Square relations imply that $4[\\tilde{A}]=0$, so $[\\tilde{A}]=0$'. It is not explained how these specific numerical consequences arise from the (unspecified) relations for elements in $H_1$ of this simplicial group of $K_0^{\\oplus}$-groups. Standard arguments for $K_1(R)$ are not directly applicable without justification. This lemma is used in Proposition 4.8."
      },
      {
        "Problem": "The homology relations in (4.1) are not clearly defined or derived.",
        "Location": "Equation (4.1) and surrounding text, Section 4",
        "Explanation": "The argument for $\\pi_1(|d \\mapsto K_0^{\\oplus}((B^q)^n Vect(X\\times \\mathbb{A}^d))|)$ being trivial relies on showing elements are zero using homology relations. Equation (4.1) lists 'triangular relations' $C|_{S=0}+C|_{T+S=1}+C|_{T=0}$ and 'square relations' $C|_{S=0}+C|_{T=1}+C|_{S=1}+C|_{T=0}$. The precise definition of these restrictions (e.g., face maps $d_i C$) and how these sums (without clear signs or coefficients corresponding to a boundary operator) represent relations in $H_1$ of the simplicial abelian group $d \\mapsto K_0^{\\oplus}((B^q)^n Vect(X\\times \\mathbb{A}^d))$ is missing. This makes it difficult to verify arguments based on these relations, such as in Lemma 4.3."
      }
    ],
    "token_usage": {
      "input": 12881,
      "thinking": 14288,
      "output": 1367
    }
  },
  {
    "entry_id": 215,
    "retraction_id": "1301.3486v2",
    "paper_id": "1301.3486v1",
    "retraction_comment": "Withdrawn because certain correction terms that arise in the Lace expansion of Section 3 were not identified and taken into account in the subsequent derivation. A new version with these correction terms included is in preparation",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Circular reasoning in the proof of $\\hat{\\Tau}_z(k) \\ge 0$",
        "Location": "Proposition 4.2 (ii), page 7",
        "Explanation": "To prove $\\hat{\\Tau}_z(k) \\ge 0$, the argument relies on $1-z p_c \\hat D(k) \\hat \\Pi_z (k)$ being non-zero for $z \\in [0,1)$. The proof for this non-vanishing property (equation (4.10) and surrounding text) uses the bound $\\lvert \\hat{\\Tau}_z(k) \\rvert \\ge \\frac{\\lvert \\hat{\\Pi}_z(k) \\rvert}{C}(1-z)$, which is derived from $\\hat{\\Tau}_z(k) \\le C/(1-z)$. This latter bound itself relies on $\\hat{\\Tau}_z(k) \\ge 0$ (as it's used in $\\hat{\\Tau}_z(k) \\le \\lvert \\hat{\\Tau}_z(0) \\rvert$). This constitutes a circular argument. Establishing the non-vanishing of $1-z p_c \\hat D(k) \\hat \\Pi_z (k)$ independently is crucial for the proof that $\\hat{\\Tau}_z(k)$ maintains a constant sign."
      },
      {
        "Problem": "Incorrect denominator factorization in the proof of the infrared bound for $\\hat{\\Tau}_z(k)$",
        "Location": "Proposition 4.2 (ii), page 8, last equation block",
        "Explanation": "In proving $\\hat{\\Tau}_z(k) \\le C'/[1-\\hat D(k)]$, the paper bounds $\\left\\lvert \\frac{\\hat{\\Pi}_z(0)}{1-z p_c \\hat D(k) \\hat{\\Pi}_z(0)}\\right\\rvert$. The denominator $1-z p_c \\hat D(k) \\hat{\\Pi}_z(0)$ is then claimed to be bounded from below by $(1-\\hat D (k))(1 +  (1-z)\\lvert 1 -z p_c  c' \\beta^{1/2}\\rvert)$. This factorization is incorrect. The term $1-z p_c \\hat D(k) \\hat{\\Pi}_z(0)$ should be analyzed as $(1-\\hat D(k)) + \\hat D(k)(1-z p_c \\hat{\\Pi}_z(0))$. The presented factorization does not hold generally and undermines the derivation of this specific form of the infrared bound for $\\hat{\\Tau}_z(k)$ for $z \\in [0,1)$."
      },
      {
        "Problem": "Flawed inequality used to relate $\\psi_m$ diagrammatic bounds to $\\pi_m$ bounds",
        "Location": "Proposition 4.4, page 9, last paragraph (proof of right-hand bound of (4.28))",
        "Explanation": "The proof of the bound for $\\sum_{x,m} m^{1+\\vep} |\\psi_m(x)|$ relies on the inequality $\\sum_x B_3 (s,t,x,u,v;z) \\le 2 B_1(s,t,u,v;z)$. This comparison effectively requires $z p_c (D * \\Tau_1)(v-t) \\le 2 \\tautt(v-t) = 4z p_c^2 (D * \\Tau_z)(v-t)$, which simplifies to $(D * \\Tau_1)(v-t) \\le 4 p_c (D * \\Tau_z)(v-t)$ (assuming $\\tau(x)$ in $B_3$ is $\\Tau_1(x)$ as suggested by diagrams). Since $\\Tau_z(x) = \\sum z^m \\tau_m(x) \\le \\sum \\tau_m(x) = \\Tau_1(x)$ for $z \\in [0,1)$ (assuming $\\tau_m \\ge 0$), the inequality $(D * \\Tau_1) \\le 4 p_c (D * \\Tau_z)$ is generally false. This error invalidates the stated bound for $\\psi_m$ coefficients, which impacts results relying on $\\Psi_z(k)$ estimates, such as the analysis of $\\hat{\\rho}_n(k)$ in Theorem 1.2."
      },
      {
        "Problem": "Use of $|1-\\cos(a)\\cos(b)| \\le 2|a|^\\delta + 2|b|^\\delta$ inequality",
        "Location": "Proposition 4.6, page 12, eq. (4.46) and (4.47)",
        "Explanation": "The proof of Proposition 4.6, specifically when bounding the second term in (4.44) (the difference $\\hat\\pi_{|I|}(0) - \\hat{\\underline\\pi}_{(\\dots)}(k_n^{(N-1)}, k_n^{(N)})$), states 'We also use $\\left|1-\\cos(a)\\cos(b)\\right|\\le 2|a|^\\delta + 2|b|^{\\delta}$ for all $\\delta \\in [0,2]$ to get for $m \\le n$, (4.47)'. This inequality for $1-\\cos(a)\\cos(b)$ is not standard and seems incorrect. The typical bound related to Fourier series differences involves $|1-e^{i\\phi}| \\le |\\phi|^\\delta$ (for $\\delta \\in [0,1]$) or $|1-\\cos\\phi| \\le |\\phi|^\\delta/2$ (for $\\delta \\in [0,2]$). While the resulting form in (4.47) might be achievable with correct inequalities, the stated one is problematic and could lead to an incorrect coefficient or argument if strictly followed."
      },
      {
        "Problem": "Justification for $\\hat\\Pi_z(0)-\\hat\\Pi_z(\\uv) \\le C\\, [1-\\hat D (\\uv)]$ in Theorem 1.3 proof",
        "Location": "Section 6 (Proof of Theorem 1.3), page 14, paragraph after eq. (6.7)",
        "Explanation": "In the proof of Theorem 1.3 (Mean-$r$ displacement), when bounding the first integral in (6.6), it is stated that 'Observe that it follows from (2.16) that $\\hat\\Pi_z(0)-\\hat\\Pi_z(\\uv) \\le C\\, [1-\\hat D (\\uv)]$'. Equation (2.16) (referred to as eqMain2 in the thought process, which is Prop 5.2 in the provided text) gives this type of behavior for $\\hat\\Pi_1(k)$ (i.e., for $z=1$). The extension of this property to $\\hat\\Pi_z(k)$ for general $z \\in [0,1)$ is not trivial and requires separate justification, as $1-\\hat D(\\uv)$ can be much smaller than $1-z$. Without this justification, the subsequent bound on the integral is not fully supported."
      }
    ],
    "token_usage": {
      "input": 82183,
      "thinking": 16923,
      "output": 1695
    }
  },
  {
    "entry_id": 216,
    "retraction_id": "2101.07819v3",
    "paper_id": "2101.07819v2",
    "retraction_comment": "We are withdrawing because of a significant error. The category Weil used to define tangent structures is too strict for the construction of our main example. In particular the map alpha in 7.19 is not well-defined. To resolve this we will replace Weil with a suitable $\\infty$-category and post a new version when possible. We are grateful to [REDACTED-NAME] and [REDACTED-NAME] for pointing out this error",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 101803,
      "thinking": 17075,
      "output": 1
    }
  },
  {
    "entry_id": 217,
    "retraction_id": "1711.07883v3",
    "paper_id": "1711.07883v2",
    "retraction_comment": "The paper has some problems on the Poisson homomorphism from the motivic Hall algebra to the motivic quantum torus",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of Poisson bracket on the motivic quantum torus.",
        "Location": "Section 2.2, paragraph labeled 'Poisson:bracket:motivic:quantum:torus' (immediately preceding Theorem 4.16 in the source, which is Theorem 2.2.6 in the PDF structure, defining the integration map).",
        "Explanation": "The paper defines the Poisson bracket $\\{x^{\\alpha}, x^{\\beta}\\}$ with two expressions stated to be equal. The first involves $\\sum_{i=0}^{3}(-1)^{i+1}\\ll^{\\dim\\ext^{i}(\\alpha,\\beta)}$, and the second (standard) one involves $\\frac{\\ll^{\\chi(\\alpha,\\beta)}-1}{\\ll-1}$. These two expressions are not generally equal. For instance, if $\\dim\\Ext^0=1, \\dim\\Ext^1=2$, and higher Exts are zero, then $\\chi(\\alpha,\\beta)=-1$. The first expression gives $-\\ll + \\ll^2$, while the second gives $\\ll^{-1}-1$. This inconsistency in a fundamental definition is critical."
      },
      {
        "Problem": "Unjustified vanishing of Poisson brackets in the proof of the motivic DT/PT correspondence.",
        "Location": "Section 2.4, paragraph 'Finishing the proof', specifically the step $I_{\\Lambda}(\\srH_{\\leq 1})=I_{\\Lambda}(\\srH_{0})\\cdot I_{\\Lambda}(\\srH^{\\#}_{\\leq 1})$.",
        "Explanation": "The proof claims that after applying the motivic integration map $I_{\\Lambda}$ to the identity $\\srH_{\\leq 1}=\\srH_{0}\\cdot \\exp(\\{\\eta_{\\infty},-\\}) (\\srH_{\\leq 1}^{\\#})$, the Poisson bracket term $\\exp(\\{I_{\\Lambda}(\\eta_{\\infty}),-\\}$) effectively becomes trivial (i.e., acts as identity). This requires $\\{I_{\\Lambda}(\\eta_{\\infty}), I_{\\Lambda}(\\srH_{\\leq 1}^{\\#})\\} = 0$. This in turn relies on $\\chi(\\alpha, \\beta)=0$ for classes $\\alpha$ from $\\eta_\\infty$ (related to 0-dimensional sheaves) and $\\beta$ from $\\srH_{\\leq 1}^{\\#}$ (related to stable pairs/1-dimensional sheaves). This condition $\\chi(\\alpha, \\beta)=0$ is not generally true (e.g., for $A=\\mathcal{O}_x$ and $B$ a line bundle on a curve). This invalidates a key step in the proof of Theorem 1.2.1."
      },
      {
        "Problem": "Unjustified vanishing of Poisson brackets in the proof of the motivic flop formula.",
        "Location": "Section 3.4, paragraph 'Finishing the proof', specifically the step $I_{\\Lambda}(\\srPH_{\\leq 1})=I_{\\Lambda}(\\dd^\\prime(\\srH_{\\exc}^{\\#})\\cdot I_{\\Lambda}(\\srH_{\\leq 1}))$.",
        "Explanation": "Similar to the DT/PT proof, the derivation of the flop formula involves simplifying an expression $\\exp(\\{\\eta,-\\})(A)$ to $A$ after applying the integration map $I_\\Lambda$. This step, $I_{\\Lambda}(\\srPH_{\\leq 1})=I_{\\Lambda}(\\dd^\\prime(\\srH_{\\exc}^{\\#})\\cdot I_{\\Lambda}(\\srH_{\\leq 1}))$, relies on the vanishing of certain Poisson brackets. The justification provided is '$\\Ext^i(E,F)=0$ since $\\dim(\\supp E)\\leq 1, \\dim(\\supp F)\\leq 1$'. This statement about Ext groups is false (e.g. $\\Ext^1(L,L)$ for a line bundle $L$ on a curve). Consequently, the vanishing of the relevant Poisson bracket term is not justified, undermining the proof of Theorem 1.3.2."
      },
      {
        "Problem": "The derived motivic flop formula in Section 3.4 does not match the statement of Theorem 1.3.2.",
        "Location": "Section 3.4, comparison of the derived formula $I_{\\Lambda}(\\srPH_{\\leq 1})=I_{\\Lambda}(\\dd^\\prime(\\srH_{\\exc}^{\\#}))\\cdot I_{\\Lambda}(\\srH_{\\leq 1})$ with Theorem 1.3.2 in the introduction.",
        "Explanation": "Theorem 1.3.2 presents the flop formula as $\\Phi_{\\star}\\left(\\sS^{\\phi}_{\\DT}(Y)\\cdot \\frac{\\sS_{\\DT_{\\exc}}^{\\phi\\vee}(Y)}{\\sS^{\\phi}_{\\DT_{0}}(Y)}\\right)=\\sS^{\\phi}_{\\DT}(Y^\\prime)\\cdot \\frac{\\sS_{\\DT_{\\exc}}^{\\phi \\vee}(Y^\\prime)}{\\sS^{\\phi}_{\\DT_0}(Y^\\prime)}$. The formula derived in Section 3.4 (assuming vanishing Poisson brackets) is $\\sS_{\\DT}^{\\phi p}(Y)=I_{\\Lambda}(\\dd^\\prime(\\srH_{\\exc}^{\\#}))\\cdot \\sS^{\\phi}_{\\DT}(Y)$. The connection between $I_{\\Lambda}(\\dd^\\prime(\\srH_{\\exc}^{\\#}))$ and the term $\\frac{\\sS_{\\DT_{\\exc}}^{\\phi\\vee}(Y)}{\\sS^{\\phi}_{\\DT_{0}}(Y)}$ is not established, and the crucial factor $\\sS^{\\phi}_{\\DT_{0}}(Y)$ (degree zero DT invariants) is missing from the derivation. This makes the proof incomplete for the stated theorem."
      },
      {
        "Problem": "Unclear derivation of the prefactor in the higher rank DT/PT correspondence.",
        "Location": "Section 4.4, derivation of the main theorem of this section (unnumbered, concerning $\\sS_{\\DT}^{\\phi}(r,D)$ and $\\sS_{\\PT}^{\\phi}(r,D)$) from the Hall algebra identity in equation (4.4.1) ($\\delta_{\\DT}(r,D)\\star \\delta(\\cC_{\\infty})=\\delta(\\cC_{\\infty})\\star\\delta_{\\PT}(r,D)$).",
        "Explanation": "The Hall algebra identity $\\delta_{\\DT}(r,D) = \\delta(\\cC_{\\infty})\\star\\delta_{\\PT}(r,D) \\star \\delta(\\cC_{\\infty})^{-1}$ should, after applying the integration map $I$, lead to $\\sS_{\\DT}^{\\phi}(r,D) = I(\\delta(\\cC_{\\infty})) \\star \\sS_{\\PT}^{\\phi}(r,D) \\star I(\\delta(\\cC_{\\infty}))^{-1}$ in the quantum torus. The paper claims this results in $\\sS_{\\DT}^{\\phi}(r,D)= \\exp\\left(\\sum_{n>0}\\ll^{nr-1}\\frac{\\ll^{rn}-1}{\\ll-1}[\\sN_n]x^n\\right)\\cdot \\sS_{\\PT}^{\\phi}(r,D)$. The derivation of how $I(\\delta(\\cC_{\\infty})) \\star (\\cdot) \\star I(\\delta(\\cC_{\\infty}))^{-1}$ (a conjugation) becomes multiplication by this specific exponential factor is not provided and is non-trivial. The presence of the term $\\ll^{nr-1}$, where $r$ is the rank of DT/PT objects rather than objects in $\\cC_\\infty$, is particularly obscure."
      }
    ],
    "token_usage": {
      "input": 32803,
      "thinking": 12398,
      "output": 1788
    }
  },
  {
    "entry_id": 218,
    "retraction_id": "1603.02912v3",
    "paper_id": "1603.02912v2",
    "retraction_comment": "The calculation of the apparent charge density in this paper was wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of Lorentz Transformation of Densities as a 'Two-Step Process'",
        "Location": "Page 1, paragraph 3, and subsequent discussion leading to Eq. (5)",
        "Explanation": "The paper incorrectly describes the Lorentz transformation of a charge-current density as a two-step process. It claims Eq. (1) is only the first step, and a second step of transforming space-time coordinates $(t, \\mathbf{r})$ to $(t', \\mathbf{r}')$ is needed to get the 'complete' transformation. In standard relativity, the transformation of density components (like Eq. 1) already yields the density $\\rho'$ at a specific spacetime point $(\\mathbf{r}', t')$ in the new frame, implicitly using the transformed coordinates to relate $\\rho'(\\mathbf{r}', t')$ to $\\rho(\\mathbf{r}, t)$ and $\\mathbf{j}(\\mathbf{r}, t)$. There is no subsequent, separate coordinate transformation step that alters the value of $\\rho'$."
      },
      {
        "Problem": "Unsubstantiated Claim that the Induced Charge Density Vanishes",
        "Location": "Eq. (5) and the paragraph preceding it ('If the Lorentz transformation ... is completed ...')",
        "Explanation": "The paper asserts that 'completing the Lorentz transformation' (the supposed second step) modifies Eq. (1) such that the induced charge density $\\rho'(\\mathbf{r}',t')$ becomes zero (Eq. 5). However, no mathematical derivation or rigorous physical argument is provided to show how this 'second step' (transforming coordinates) would cause the non-zero term $\\gamma \\mathbf{V} \\cdot \\mathbf{j}$ to vanish. This is the central, unsupported claim that leads to the paper's main conclusion."
      },
      {
        "Problem": "Flawed 'Miscounting' Argument for Induced Charge",
        "Location": "Page 2, paragraphs discussing Fig. 1 and the footnote",
        "Explanation": "The paper argues that the induced charge density $\\rho'$ (from Eq. 1) is an artifact of 'miscounting' electrons because the counting in the S frame is not done at a fixed time $t'$ of the S' frame. This misinterprets the origin of the induced charge. The standard derivation of $\\rho'$ inherently accounts for the relativity of simultaneity (i.e., that a spatial volume at a fixed $t'$ in S' corresponds to events at different times $t$ in S). This relativistic effect is precisely what *causes* the induced charge density; it is a physical consequence, not an accounting error that disappears upon 'correct' counting."
      },
      {
        "Problem": "Incorrect Transformation Formula for Current Density $\\mathbf{j}'$",
        "Location": "Eq. (2)",
        "Explanation": "Equation (2) states $\\mathbf{j}'(\\mathbf{r},t) = \\gamma \\mathbf{j}(\\mathbf{r},t)$. This formula is generally incorrect. For an initial state with $\\rho=0$, the correct transformations are $\\mathbf{j}'_\\parallel = \\gamma \\mathbf{j}_\\parallel$ (component parallel to $\\mathbf{V}$) and $\\mathbf{j}'_\\perp = \\mathbf{j}_\\perp$ (component perpendicular to $\\mathbf{V}$). Eq. (2) is only valid if the current $\\mathbf{j}$ is entirely parallel to the velocity $\\mathbf{V}$. This error indicates a misunderstanding of the Lorentz transformation of the four-current vector."
      },
      {
        "Problem": "Implicit Rejection of Standard Four-Vector Transformation of Charge-Current Density",
        "Location": "Throughout the paper, especially the conceptual framework of the 'two-step process' and the argument for $\\rho'=0$.",
        "Explanation": "The paper's entire argument implies that the charge-current four-vector $J^\\mu = (\\rho, \\mathbf{j})$ does not transform according to the standard rule $J'^\\mu = \\Lambda^\\mu_\\nu J^\\nu$, or that its physical components in the new frame (like $\\rho' = J'^0$) are not directly obtained from this transformation. By introducing an ad-hoc 'completion' step that fundamentally changes the outcome, the paper contradicts the well-established principle in special relativity that four-vectors transform linearly and their components in any inertial frame are given directly by this transformation."
      }
    ],
    "token_usage": {
      "input": 2395,
      "thinking": 7355,
      "output": 995
    }
  },
  {
    "entry_id": 219,
    "retraction_id": "2205.10165v2",
    "paper_id": "2205.10165v1",
    "retraction_comment": "It is not proved that the function $S$ is in fact an inner function",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect claim about contraction mapping properties.",
        "Location": "Remark 1.1 (page 1) and Remark 1.3 (page 2)",
        "Explanation": "The paper claims that for a fixed $z \\in U$, the map $h(t) = \\exp\\left(-\\frac{1+z \\cdot t}{1-z \\cdot t}\\right)$ is a contraction with respect to $t$, and specifically that the absolute value of its $t$-derivative is 'smaller or equal to $4 \\cdot e^{-2}$' (approx 0.541). This claim is false. The derivative is $h'(t) = \\exp\\left(-\\frac{1+zt}{1-zt}\\right) \\cdot \\frac{-2z}{(1-zt)^2}$. The modulus $|h'(t)| \\le \\frac{2|z|}{e(1-|zt|^2)}$. This bound is not uniformly less than 1 (nor less than $4e^{-2}$) for all $z \\in U$ and $t \\in U$. For instance, as $|z| \\to 1$ (e.g., with $t=0$), the bound $\\frac{2|z|}{e}$ approaches $2/e \\approx 0.736$. While $2/e < 1$, it is not always $\\le 4e^{-2}$. More importantly, the expression $\\frac{2|z|}{e(1-|zt|^2)}$ can be made arbitrarily large if $|zt|$ is close to 1, or $\\frac{2|z|}{e(1-|z|^2)}$ if $t$ is chosen to maximize $|zt|$ for a given $z$, which tends to infinity as $|z| \\to 1$. Specifically, the claim $|h'(t)| \\le 4e^{-2}$ requires $\\frac{2|z|}{e(1-|zt|^2)} \\le 4e^{-2}$, which implies $\\frac{|z|}{1-|zt|^2} \\le \\frac{2}{e}$. This inequality does not hold for all $z, t \\in U$; for example, it fails if $|z| > (\\sqrt{e^2+16}-e)/4 \\approx 0.529$ (taking $y=|t| \\to 1$). The failure of this uniform contraction claim undermines the stated justification for the uniqueness of the fixed-point $S(z)$ via the Banach fixed-point theorem, although the existence of such an $S(z)$ via the normal family argument is not affected."
      }
    ],
    "token_usage": {
      "input": 4683,
      "thinking": 18483,
      "output": 580
    }
  },
  {
    "entry_id": 220,
    "retraction_id": "1511.00570v2",
    "paper_id": "1511.00570v1",
    "retraction_comment": "This paper has been withdrawn because the analysis therein completely oversimplified the physics during primordial nucleosynthesis",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect thermal averaging of interaction rate for attractive potentials.",
        "Location": "Eq. (11)",
        "Explanation": "The formula for the thermally averaged effective interaction rate for charged particles, specifically in the attractive case ($q_i V(R_X) < 0$), appears to be $\\langle\\s_\\text{X,eff}v_i\\rangle = \\sX (1 - q_iV(R_X)/T)\\langle v_i \\rangle$. The correct factor, when properly averaging $1 - q_iV(R_X)/E_i$ over a Maxwell-Boltzmann distribution, should be $(1 - q_iV(R_X)/(2T))$ multiplying $\\langle v_i \\rangle$. The paper's formula overestimates the enhancement from an attractive potential by a factor of up to 2 in the potential term. This would make the derived constraints on $\\sX/\\MX$ for $V(R_X) < 0$ (attractive to protons) artificially stronger (i.e., lower upper limits) than they should be."
      },
      {
        "Problem": "Neglect of Macro evolution due to baryonic accretion.",
        "Location": "Section II, implicit in the definitions of $\\Gamma_{iX}$ (Eq. 9, 11) and their use in Eqs. (13-16)",
        "Explanation": "The analysis assumes that Macro properties (mass $\\MX$, cross-section $\\sX$, and surface potential $V(R_X)$) remain constant throughout the BBN epoch. However, in regions of parameter space where derived constraints are set (e.g., for $V(R_X)=0$ or near the 'dip' at $V(R_X) \\approx 0.01 \\text{ MeV}$), a significant fraction of primordial baryons (10-50% as indicated by dashed lines in figures) could be absorbed by Macros. Such substantial accretion would alter the Macros' mass, charge (if absorbing charged particles like protons), and consequently their surface potential and cross-section. This feedback mechanism is not modeled, potentially invalidating the calculated interaction rates and the derived constraints in regimes where absorption is significant."
      },
      {
        "Problem": "The highlighted 'vanishing constraint' occurs in a parameter region acknowledged as unreliable.",
        "Location": "Figure 2, and discussion on page 4 regarding $V(R_X) \\simeq 0.01 \\text{ MeV}$",
        "Explanation": "The paper discusses an interesting phenomenological feature where the constraint on $\\sX/\\MX$ becomes very weak ('essentially vanish') around $V(R_X) \\simeq 0.01 \\text{ MeV}$. However, Figure 2 shows that this region of very weak constraints (e.g., $\\sX/\\MX \\gtrsim 10^{-7} \\text{ cm}^2/\\text{g}$) lies above the dashed line indicating >50% neutron absorption. The paper states, 'at present, we do not trust the constraint above this line.' This means the conclusion about a vanishing constraint is drawn from a part of the parameter space where the underlying calculation method (e.g., perturbative approach, stability of $T_B$) is admittedly not robust, making the claim about this specific feature unsound within the presented framework."
      },
      {
        "Problem": "Validity of perturbative calculation of $\\Delta X_4$ for key results.",
        "Location": "Eq. (13), Figure 2 (constraint at $V(R_X)=0$), Abstract and Discussion of neutral Macro effects.",
        "Explanation": "The calculation of $\\Delta X_4^\\text{Macro}$ (Eq. 13) is based on a first-order perturbative expansion in Macro interaction effects (terms $a, b, c$). This approach is valid only if these integrated effects are small (i.e., fractional changes are $\\ll 1$). The derived constraint for neutral Macros ($V(R_X)=0$) is $\\sX/\\MX \\sim 10^{-9} \\text{ cm}^2/\\text{g}$. At this value, a substantial fraction of neutrons (estimated to be $\\sim 25\\%$) would be absorbed during BBN. Such a high absorption rate challenges the perturbative assumption underlying Eq. (13). This potentially undermines the quantitative accuracy of the constraint for neutral Macros, which is presented as an important new result of the paper. While the qualitative effect from neutral Macros is plausible, its derived quantitative constraint may not be reliable due to the calculation method reaching its limit of validity."
      }
    ],
    "token_usage": {
      "input": 7799,
      "thinking": 17813,
      "output": 1027
    }
  },
  {
    "entry_id": 221,
    "retraction_id": "1911.02706v2",
    "paper_id": "1911.02706v1",
    "retraction_comment": "A missing sign in the argument to prove Lemma 2 renders the proof incorrect. The note is withdrawn since we are unable to provide a corrected proof that works with the stated generality",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Lemma 2.4 (that $s_g$ is constant) is unsound.",
        "Location": "Page 4, Proof of Lemma 2.4",
        "Explanation": "The proof considers variations $h_\\varphi = \\nabla_g d\\varphi$. If $g$ is a critical point, then $\\nabla_g S = \\lambda_g g$. The first variation in the direction $h_\\varphi$ is $\\int (\\nabla_g S, h_\\varphi)_g d\\mu_g = \\int (\\lambda_g g, \\nabla_g d\\varphi)_g d\\mu_g = \\lambda_g \\int \\Delta_g \\varphi d\\mu_g$. Since $\\int \\Delta_g \\varphi d\\mu_g = 0$ for any $\\varphi$ on a closed manifold, this expression is identically zero. Thus, these specific variations $h_\\varphi$ do not provide any new information about $s_g$ beyond what is already known from $\\nabla_g S = \\lambda_g g$. The paper's derivation of the variational expression as $-4 \\int s_g (\\nabla_g d)^*(\\nabla_g d) \\varphi d\\mu_g$ (which is $-4 \\int s_g L^* \\varphi d\\mu_g$) appears incorrect. The step referred to as 'simple dualization' is not justified, and the resulting expression for the variation does not match a direct calculation. Furthermore, even if the expression $-4 \\int s_g L^* s_g d\\mu_g = 0$ were correct, the subsequent conclusion that this implies 'the squared $L^2$-norm of $\\nabla_g d s_g$ vanishes' (i.e., $\\nabla_g d s_g = 0$) is not justified from the provided form of $L^*s_g$. This invalidates the proof that $s_g$ is constant, which is a crucial step for Theorem 2.5."
      },
      {
        "Problem": "Incorrect coefficient in the trace equation for $s_g$.",
        "Location": "Page 3, Equation (2.7) (also labelled as (id))",
        "Explanation": "Equation (2.7) states $(2n-2)\\Delta_g s_g +\\frac{n-4}{2}(s_g^2- \\pi_g(s_g^2)) = 0$. The correct coefficient for $\\Delta_g s_g$ should be $(2n+2)$. This can be derived by taking the trace of equation (2.5) ($\nabla_g S = \\lambda_g g$) which is $(2n+2)\\Delta_g s_g + \\frac{n-4}{2}s_g^2 = n\\lambda_g$, and substituting the expression for $\\lambda_g$ from (2.6) ($\\lambda_g = \\frac{n-4}{2n}\\pi_g(s_g^2)$). This error affects the subsequent discussion relying on this equation, for example, the $n=2$ case analysis."
      },
      {
        "Problem": "Sign error in the expression for $\\Delta^2 s_g$ in the $n=2$ case discussion.",
        "Location": "Page 3, paragraph following eq. (2.7)",
        "Explanation": "In the discussion for $n=2$, the paper states '$\\Delta^2 s_g=s_g\\Delta s_g- (\\nabla s_g, \\nabla s_g)$'. This is derived from $2\\Delta s_g= s_g^2-\\pi_g s_g^2$. If $C = \\pi_g s_g^2$ (a constant), then $2\\Delta s_g = s_g^2 - C$. Applying $\\Delta$ to both sides: $2\\Delta^2 s_g = \\Delta(s_g^2) = \\text{div}(2s_g \\nabla s_g) = 2s_g \\Delta s_g + 2(\\nabla s_g, \\nabla s_g)_g$. Therefore, $\\Delta^2 s_g = s_g \\Delta s_g + (\\nabla s_g, \\nabla s_g)_g$. The sign of the $(\\nabla s_g, \\nabla s_g)_g$ term is incorrect in the paper. This error impacts the subsequent derivation of equation (2.8)."
      }
    ],
    "token_usage": {
      "input": 8729,
      "thinking": 20400,
      "output": 1031
    }
  },
  {
    "entry_id": 222,
    "retraction_id": "1806.06939v2",
    "paper_id": "1806.06939v1",
    "retraction_comment": "The objective in (8) allows for trivial solutions e.g. the prior",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potentially unsound derivation of the importance sampling objective function.",
        "Location": "Section 3.3, Eq (8); Appendix A, Eq (S1) and (S3)",
        "Explanation": "The derivation of the training objective involving importance sampling (Eq. 8, detailed in Appendix A) relies on inequalities (S1 and S3) that do not hold in general. For instance, Eq (S1) implies $\\int q \\log p \\ge \\int \\log(qp)$, which simplifies to $0 \\ge \\int \\log q d\\omega$. This is not generally true for a probability density $q$. Similarly, Eq (S3) implies $- \\int \\log(q/\\bar{q}) d\\omega \\le - \\int \\bar{q} \\log(q/\\bar{q}) d\\omega$, which is also not generally true. If these intermediate steps are incorrect, the final objective function is not guaranteed to be a valid upper bound on the KL divergence it aims to minimize, potentially making the theoretical justification for the optimization procedure unsound."
      },
      {
        "Problem": "Mismatch between the assumed Gaussian observation model and the training loss function.",
        "Location": "Section 3.2 (Eq. 5, 6) and Section 3.3 (description of the log-likelihood term/loss function after Eq. 7)",
        "Explanation": "The paper states that observation uncertainty is modeled by predicting the mean ($\\mu_f$) and variance ($\\sigma_f$) of a per-pixel diagonal Gaussian distribution (Eq. 5). However, the loss function used for training (described in Section 3.3 as proportional to $- \\log p(s_f | s_p, \\omega)$) is an L1 difference between the ground truth $s_f$ and a *sample* $\\hat{s}_f = \\mu_f + z \\sigma_f$ from this Gaussian, plus a gradient difference term. This L1-based loss on a sample is not the negative log-likelihood (NLL) of $s_f$ under the predicted Gaussian distribution $\\mathcal{N}(\\mu_f, \\sigma_f^2)$. Consequently, the parameters $\\mu_f$ and particularly $\\sigma_f$ are not optimized to be maximum likelihood estimates for the claimed Gaussian model, which undermines the principled modeling of observation uncertainty."
      },
      {
        "Problem": "Misleading comparison of model space complexity for the proposed dropout scheme.",
        "Location": "Section 3.1, paragraph discussing Eq. (4)",
        "Explanation": "In motivating their dropout scheme (Eq. 4), the paper compares it to Gal (2016) by stating: 'In \\cite{Gal2016Bayesian} a Bernoulli variational distribution defined over each convolutional patch was proposed... number possible models is exponential in the number of patches... In contrast, in our approach (\\ref{eq4}), the number possible models is exponential in the number of weight parameters, a much smaller number.' This comparison is problematic because: (a) The characterization of Gal's (2016) method as using 'convolutional patch' dropout is non-standard and potentially inaccurate. (b) The claim that the number of models from 'exponential in the number of weight parameters' is 'much smaller' than from 'exponential in the number of patches' is generally false, as the total number of weights in a typical CNN far exceeds the number of possible patches. This misrepresents the scale of the model space and the motivation for their approach."
      },
      {
        "Problem": "Validity of Conditional Log-Likelihood (CLL) and calibration results may be compromised.",
        "Location": "Section 4 (Evaluation of predicted uncertainty, Medium term uncertainty calibration, Tables 2 & 3, Fig. 3)",
        "Explanation": "The CLL metric and uncertainty calibration are crucial for supporting the paper's claims about its Bayesian treatment. These evaluations depend on the predicted observation model $p(s_f | s_p, \\omega)$ being Gaussian (Eq. 5) with appropriately learned parameters $\\mu_f$ and $\\sigma_f$. Due to the mismatch between the assumed Gaussian model and the actual training loss (as highlighted in Problem 2), the learned $\\mu_f$ and especially $\\sigma_f$ may not accurately represent the parameters of the intended Gaussian distribution. Therefore, the reported CLL values and calibration results, which are calculated based on this Gaussian form, might not reflect the performance of a correctly specified and trained probabilistic model, potentially affecting conclusions about uncertainty quantification."
      }
    ],
    "token_usage": {
      "input": 17999,
      "thinking": 10289,
      "output": 1014
    }
  },
  {
    "entry_id": 223,
    "retraction_id": "1310.8031v2",
    "paper_id": "1310.8031v1",
    "retraction_comment": "The solution for the NS equations provided can only be constant or very small magnitude",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Error in the derivation of the crucial estimate for the nonlinear term.",
        "Location": "Page 7, equations (34)-(36), leading to (27)",
        "Explanation": "The derivation of the bound for the nonlinear term `b(u,u,A^r u)` involves Sobolev embeddings and interpolation inequalities. In equation (34), the interpolation exponents for `||u(t)||_{k+1/2}` and `||u(t)||_{r+2-k}` are used to bound these terms. When these are substituted into (33) to get (35), the resulting exponent for `||u(t)||_{r+1}` appears to be `1/(2r)`. However, a recalculation suggests the exponent should be `1+1/(2r)`. Specifically, if `||u||_{k+1/2} \\le C ||u||_1^{1-\theta_1} ||u||_{r+1}^{\theta_1}` and `||u||_{r+2-k} \\le C ||u||_1^{1-\theta_2} ||u||_{r+1}^{\theta_2}`, where `\theta_1 = (k-1/2)/r` and `\theta_2 = (r+1-k)/r`, then the combined power of `||u||_{r+1}` in (33) becomes `\theta_1 + \theta_2 = (r+1/2)/r = 1 + 1/(2r)`. This error in the exponent of `||u||_{r+1}` in (35) would significantly alter the subsequent application of Young's inequality in (36) and the final form of the differential inequality (27), which is fundamental to the paper's main argument."
      },
      {
        "Problem": "The assumption (38) on initial data is overly restrictive and likely implies the trivial solution.",
        "Location": "Page 7, equation (38), and its use in Page 8, equation (43)",
        "Explanation": "Assumption (38) states `sup_{k<∞} ||u_0||_k = K_3 < ∞`. The norms `||u||_k` are defined (e.g., page 3, implicitly by (7)) as `||u||_k^2 = \\sum_j \\lambda_j^k |\\hat{u}_j|^2`, where `\\lambda_j` are eigenvalues of the Stokes operator and `\\lambda_j \to \\infty`. If `u_0` has any non-zero Fourier coefficient `\\hat{(u_0)}_j` for an eigenvalue `\\lambda_j > 1` (which is true for any non-zero function as `\\lambda_1 = 4\\pi^2 > 1`), then `\\lambda_j^k |\\hat{(u_0)}_j|^2` would grow unboundedly with `k`. Thus, for `sup_k ||u_0||_k` to be finite, `u_0` must be zero. If `u_0=0`, the global existence of a smooth solution `u(t)=0` is trivial and does not address the Navier-Stokes problem. The paper's core argument that the blow-up time `T` in (43) tends to infinity as `r \to \\infty` relies critically on `K_3` (representing `||u_0||_r`) being uniformly bounded, which is a consequence of this assumption."
      },
      {
        "Problem": "Inconsistent forms of the key differential inequality for H^r norms.",
        "Location": "Page 6, Eq. (27); Page 8, Eq. (39); Page 8, Eq. (40) first line",
        "Explanation": "The fundamental differential inequality governing `d/dt ||u(t)||_r^2` is presented in several different forms throughout the paper, which is problematic for a rigorous proof. \n1. Equation (27) states: `d/dt ||u(t)||_r^2 + \nu ||u(t)||_{r+1}^2 \\le \\dots + c ||u(t)||_r ||u(t)||_1^{4r/(2r-1)}`. \n2. Equation (39) (for `f=0`) states: `d/dt ||u(t)||_r^2 + \nu ||u(t)||_{r+1}^2 \\le c ||u(t)||_1 ||u(t)||_r^{4r/(2r-1)}`. \n3. The first line of equation (40) implies (by dropping the `\nu ||u||_{r+1}^2` term from (39)): `d/dt ||u(t)||_r^2 \\le c ||u(t)||_1^2 ||u(t)||_r^{4r/(2r-1)}` (note the `||u||_1^2` here vs `||u||_1` in (39)). \nThese expressions differ in how norms `||u||_1` and `||u||_r` appear and their powers. Such inconsistencies in the starting point of the Gronwall-type argument (40)-(43) undermine the validity of the subsequent steps and conclusions."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 18246,
      "output": 1204
    }
  },
  {
    "entry_id": 224,
    "retraction_id": "0904.3516v4",
    "paper_id": "0904.3516v3",
    "retraction_comment": "This paper has been withdrawn by the authors. The present version has several results that are correct, but, there is a problem in the use of sections 7 and 8 to derive generic properties for the set of analytic potentials g. All sections before this are OK",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and use of W(w,x) related to H_\\infty(w,x) and V*(w).",
        "Location": "Page 9, last paragraph, and propagation into Section 6 (page 10).",
        "Explanation": "At the end of Section 5 (page 9), W(w,x) is defined as H_\\infty(w,x) - V*(w). The paper then states that the expression for V(x) used in Section 6 will be sup [W(w,x) - V*(w) - I*(w)], and that this is more convenient than sup [H_\\infty(w,x) - I*(w)]. For these two expressions for V(x) to be equivalent, it must be that H_\\infty(w,x) - I*(w) = W(w,x) - V*(w) - I*(w), which implies W(w,x) = H_\\infty(w,x) + V*(w). This contradicts the explicit definition W(w,x) = H_\\infty(w,x) - V*(w). This sign error in the definition of W(w,x) makes the subsequent formulas in Section 6, particularly the rewriting of H_\\infty(w,x) - I*(w) on page 10 (line -4), inconsistent with the given definition of W(w,x) and the standard formula for I*(w). If W(w,x) were defined as H_\\infty(w,x) + V*(w), the formulas would align."
      },
      {
        "Problem": "Potentially flawed counterexample for the 'goodness' of R*.",
        "Location": "Section 6, Example 6.1 (Leplaideur's example), pages 10-12.",
        "Explanation": "The example aims to show a case where R*(w_0)=0 for w_0 not in the support M of the maximizing measure, but with sigma(w_0) in M. Several parts of the example's construction and claims are unclear or appear incorrect. For instance, the claim d(sigma^{2n}(z_n), w_0) = 2^{-2(n+1)} (page 11) does not seem to follow from the definitions of z_n and w_0. More critically, the justification for the central claim 'Note that R*(w_0)=0' (page 12, line -3) is missing or insufficient. The example's validity hinges on this claim. While a flawed example doesn't invalidate the main theorems (which assume 'goodness' or prove it generically), it weakens the motivation for this assumption if the provided counterexample is not sound."
      },
      {
        "Problem": "Clarity of the argument for Varadhan's Lemma application in Section 5.",
        "Location": "Page 9, paragraph after Corollary 5.2.",
        "Explanation": "The paper states V(x) = lim (1/beta_n) log phi_{beta_n}(x) = sup_w (H_\\infty(w,x) - I*(w)). The eigenfunction phi_{beta_n}(x) is identified with rho_v(x) = int h_{beta_n}(w,x) d mu_{beta_n}(w) from Theorem 2.3. For Varadhan's Lemma to yield the supremum with I*(w) (the deviation function for A_\\infty^*), the measure mu_{beta_n} must relate appropriately to the Gibbs states for beta A_\\infty^* or a similar limiting process. The connection between mu_{beta_n} (defined via (v_{beta_n} tilde(mu)_{beta_n})(I_gamma)) and the measures typically used in large deviation principles for I*(w) is not explicitly established, potentially relying on unstated results from cited works ([LOT], [BLT])."
      }
    ],
    "token_usage": {
      "input": 67159,
      "thinking": 19225,
      "output": 893
    }
  },
  {
    "entry_id": 225,
    "retraction_id": "1509.01802v3",
    "paper_id": "1509.01802v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equations 22 and 23",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation of the limiting behavior of amplitude term $A_c$",
        "Location": "Section 2.3.1, Equations (23)-(25), page 6-7",
        "Explanation": "The derivation of the limiting form of the amplitude term $A(1^-2^-3^-4^+5^+6^+7^+)|_c$ (denoted $A_c$) in Eq. (25) relies on a crucial step in Eq. (23) and the subsequent cancellation described before Eq. (24). Specifically, it assumes that for an on-shell external gluon $p_2$ (with $p_2^2=0$), spinor products like $[22]$ can be taken as $\\sqrt{p_2^2} \\times \\text{phase}$. This is used to argue that factors of $p_2^2$ cancel between the numerator and denominator. However, for any on-shell (massless) momentum $p_2$, the spinor product $[22]$ is identically zero by definition of spinor brackets (e.g., $[ij] = -[ji]$, so $[ii]=-[ii] \\implies [ii]=0$). If $[22]=0$ and $p_2^2=0$, the ratio $p_2^2/[22]^2$ (or similar constructs that appear in the derivation) becomes an indeterminate $0/0$ form. The paper's argument for cancellation by treating $[22]$ as proportional to $\\sqrt{p_2^2}$ is therefore unsound for an on-shell gluon. Consequently, the actual behavior of $A_c$ in the specified collinear limit (where internal propagators $P_{345}$ and $P_{671}$ become on-shell and collinear to $p_2$) is not correctly established. This potentially invalidates the conclusion that $A_c$ is finite and suppressed as shown in Eq. (25), and therefore undermines the paper's main argument regarding the contribution of this term to Double Parton Interactions."
      }
    ],
    "token_usage": {
      "input": 13061,
      "thinking": 21809,
      "output": 455
    }
  },
  {
    "entry_id": 226,
    "retraction_id": "2312.05804v3",
    "paper_id": "2312.05804v2",
    "retraction_comment": "Error in the derivation of equation 11 in section 4.3.1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Matching Loss Formulation for Body-Clothing Alignment",
        "Location": "Section 4.3.2, Equation 13",
        "Explanation": "The matching loss $\\mathcal{L}_{\\mathit {match }}=\\mathcal{L}_{\\mathit {huber }}\\left(I_{\\mathit {mask }}^{\\mathit {cloth }}+I_{\\mathit {smpl }}^{\\mathit {cloth }}-I_{\\mathit {smpl }}^{\\mathit {body }}\right)$ is intended to ensure the body fits within the clothing. However, its formulation appears incorrect. For instance, in pixels where the body is correctly inside the clothing (e.g., $I_{\\mathit {mask }}^{\\mathit {cloth }}=1, I_{\\mathit {smpl }}^{\\mathit {cloth }}=1, I_{\\mathit {smpl }}^{\\mathit {body }}=1$), the expression inside Huber loss becomes $1+1-1=1$, incorrectly penalizing a desired state. This formulation does not robustly enforce the constraint $I_{\\mathit {smpl }}^{\\mathit {body }} \\subseteq (I_{\\mathit {mask }}^{\\mathit {cloth }} \\cup I_{\\mathit {smpl }}^{\\mathit {cloth }})$, and could lead to suboptimal or incorrect body deformations."
      },
      {
        "Problem": "Potentially Overstated Claims Regarding 'Clothing Transfer' and 'Reusability'",
        "Location": "Abstract, Introduction (Fig 1 caption), Section 1 (Contributions), Section 5.2 (Clothing Transfer)",
        "Explanation": "The paper claims 'free transfer and reuse of clothing' and that clothing can be 'exchanged between digital avatars'. However, the described mechanism (SID Net, Sec 4.3.2) deforms the *body* to fit a fixed, pre-generated clothing item, rather than adapting the clothing geometry itself to a new body shape. While the Limitations section acknowledges this one-way 'fitting of the body to clothing', the primary claims throughout the paper imply a more general and bidirectional clothing adaptability that is not fully supported by the described method. This limits the 'freeness' of transfer and 'reusability' of the clothing asset itself on arbitrary new bodies without significant body deformation."
      },
      {
        "Problem": "Ambiguities and Underspecified Components in 3D Semantic Confidence Network",
        "Location": "Section 4.3.1",
        "Explanation": "The 3D Semantic Confidence Network's description lacks crucial details, making its soundness and contribution difficult to assess. Specifically: (1) The 'pre-trained semantic-aware network $F_{sa}(.)$' is described as a 'cascaded text-guided semantic segmentation network,' but its architecture, training data, and assumed capabilities for segmenting diverse clothing from potentially noisy NeRF renders are not detailed. (2) The supervision for the 3D semantic weight network $F_{sw}(.)$ via $\\mathcal{L}_{\\mathit {confidence }}=\\mathcal{L}_{\\mathit {huber }}\\left(s_c-f_s\right)$ is unclear, as $f_s$ are 'features of the clothing' (presumably 2D) while $s_c$ is a ray-based 3D semantic confidence; the mapping or comparison between these is not defined. (3) The role and application of Gaussian noise $\\mathbf{N}$ as an input to $F_{sw}$ are vaguely described."
      },
      {
        "Problem": "Questionable 'Physically-Decoupled' Generation due to Body-Centric Clothing Prior",
        "Location": "Section 4.2 (Layered Geometric Prior), Abstract, Section 1 (Contributions)",
        "Explanation": "The claim of achieving 'truly physically-decoupled' generation of body and clothing is challenged by the nature of the clothing prior, $\\mathcal{M}_{\\mathit {cloth }}^{\\mathit {prior }}$. This prior is defined as the SMPL model excluding head, hands, and feet, which is still fundamentally a body shape. Initializing clothing density based on such a body-centric prior may significantly bias the subsequent diffusion-based generation towards clothing that conforms to this underlying body structure, rather than allowing for the generation of truly independent and diverse clothing geometries (e.g., wide skirts, capes, complex silhouettes not closely following a torso). This strong initial coupling could limit the extent to which the clothing generation is 'physically-decoupled' from a body form."
      }
    ],
    "token_usage": {
      "input": 24931,
      "thinking": 5488,
      "output": 972
    }
  },
  {
    "entry_id": 227,
    "retraction_id": "1401.1766v5",
    "paper_id": "1401.1766v4",
    "retraction_comment": "This paper has been withdrawn by the author due to errors in figure 1",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsubstantiated Ontology Coverage Claim and Incorrect Citation",
        "Location": "Page 5, Section 'Ontology-graph construction', last paragraph",
        "Explanation": "The paper claims that four specific UMLS ontologies (MeSH, SNOMEDCT, CSP, AOD) 'cover all senses of the target words in NLM database [18]'. However, reference [18] ('Chvatal V: A greedy heuristic for the set-coving problem') is entirely unrelated to ontology coverage or the NLM database. This critical claim about the comprehensiveness of the constructed ontology graph, which is foundational to the system's query expansion capabilities, is therefore unsubstantiated by the provided citation and potentially incorrect. The actual extent of coverage is not justified."
      },
      {
        "Problem": "Weak Evaluation Methodology Relying on Subjective Judgments with Potentially Problematic Criteria",
        "Location": "Page 16, Section 'Results', bullet points defining categories of comparison",
        "Explanation": "The performance comparison between G-Bean and PubMed relies exclusively on subjective judgments from 20 graduate students. The criteria for categorizing outcomes (e.g., 'G-Bean is definitely better than PubMed') use thresholds like '(n_a - n_b)/n_a >= 25%'. Using n_a (votes for G-Bean) as the denominator can make the 'definitely better' classification sensitive to small absolute numbers of votes. More importantly, the primary condition for results being 'similar' (n_c >= 10, i.e., at least half the students find them similar) can overshadow actual differences, potentially masking scenarios where one system is moderately preferred by a plurality but not overwhelmingly so. This methodology may not robustly support the strength of the conclusions drawn."
      },
      {
        "Problem": "Absence of Objective Evaluation Metrics Using Standard Test Collection",
        "Location": "Page 15-17, Section 'Results'",
        "Explanation": "The paper uses the OHSUMED benchmark queries, a dataset that typically includes relevance judgments for documents. However, the evaluation does not employ any standard, objective Information Retrieval (IR) metrics such as Precision, Recall, Mean Average Precision (MAP), or Normalized Discounted Cumulative Gain (NDCG). Relying solely on subjective student opinions when objective measures could have been calculated makes the performance claims less rigorous, harder to compare with other systems, and potentially less reliable. This is a significant omission for an IR system evaluation."
      },
      {
        "Problem": "Insufficient Detail on User Intention Discovery Mechanism",
        "Location": "Page 11, Section 'Document retrieval', paragraph 2; and Page 2, Abstract, Methods point (3)",
        "Explanation": "One of G-Bean's three claimed innovations is 'Retrieval and re-ranking of documents based on user's search intention'. The paper states G-Bean 'can form a new query using the key concepts automatically obtained from all articles that are interested by the user'. However, the methodology for how these 'key concepts' are extracted from user-selected articles and how they are subsequently used to 'form a new query' is not adequately described. This lack of detail makes it difficult to assess the soundness, novelty, or effectiveness of this core component, thereby weakening the claims about its advantages."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 6534,
      "output": 729
    }
  },
  {
    "entry_id": 228,
    "retraction_id": "2011.03931v2",
    "paper_id": "2011.03931v1",
    "retraction_comment": "There is a error in the experimental EBSD map of albite due to pseudosymmetry. The two parts A and B are actually linked by a 180_ rotation around b-axis. The theory remains valid to my point of view, but the EBSD map of albite cannot be used as an \"experimental proof\". I would like to apologize to the readers of the first versions deposited on Arxiv",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Oversimplified correspondence matrices for 180° axial heterotwins in triclinic/monoclinic systems.",
        "Location": "Page 25, Table 3 (and related calculations in Section 5.1.2)",
        "Explanation": "The correspondence matrices C^(2->1) (representing the twin operation) for 180° axial heterotwins in feldspars (e.g., albite, which is triclinic) are presented in Table 3 as simple diagonal matrices like diag(1,-1,-1). Such matrix forms are generally valid only if the crystal axis of rotation is orthogonal to the other two basis vectors and these vectors themselves form an orthogonal set, or if the matrix represents the operation in a basis aligned with Cartesian axes where the crystal axis of rotation is also aligned. For a triclinic system like albite, these conditions are not met. The actual matrix C^(2->1), as defined by Eq. (1) (C^(2->1) = B_super2 * (B_super1)^-1, where B_super are matrices of supercell vectors in a common Cartesian frame), would be more complex and dependent on the actual triclinic cell parameters and the specific supercell vectors (e.g., from Table 2). This simplification would lead to incorrect distortion matrices F^1 (Eq. 4) and generalized strain values sg, which are central to the paper's predictions."
      },
      {
        "Problem": "Inconsistent or inadequately justified misorientation and its geometric interpretation for the non-180° b-axial heterotwin in albite.",
        "Location": "Page 26, Section 5.1.3 (description of Table 4 results)",
        "Explanation": "For the predicted non-180° b-axial heterotwin in albite ((101) || (001) interface), the paper states that the misorientation matrix T found by the software is a 'rotoinversion of 180° around the axis ~[201]'. The subsequent geometric interpretation of this [201] axis as being 'normal to axis b' (the common invariant direction u) is generally not true for a triclinic crystal unless specific, restrictive metric conditions (2ab*cos(gamma) + bc*cos(alpha) = 0) are met, which is not stated. Furthermore, the term 'rotoinversion of 180°' is ambiguous; if it implies a standard S2 operation (inversion), it's a simple inversion. If it means a 180° rotation followed by inversion, the relationship of this complex operation (around an axis ~[201] that is not u=b) to the general theory of non-180° axial heteroplanes (which describes a rotation around the common axis u by the inter-planar angle alpha, as per page 15) is unclear and not justified. This makes the nature of the predicted 'unconventional twin' and its formation mechanism obscure."
      }
    ],
    "token_usage": {
      "input": 12766,
      "thinking": 16517,
      "output": 667
    }
  },
  {
    "entry_id": 229,
    "retraction_id": "1501.02643v7",
    "paper_id": "1501.02643v6",
    "retraction_comment": "This article has been withdrawn due to error in Eq. 8",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistency between the described physical setup (single SMM impurity) and the theoretical model used (translationally invariant Hamiltonian).",
        "Location": "Figure 1, text description 'A nanoparticle (e.g SMM with giant spin S) in form of a quantum dot (red spot) is deposited on the surface...', versus the k-space Hamiltonian in Eq. (7) and subsequent band structure analysis (Eqs. 8-16).",
        "Explanation": "The paper describes a system with a single, localized SMM quantum dot on the TI surface (as depicted in Fig. 1). However, the theoretical analysis employs a k-space Hamiltonian (Eq. 7) that assumes translational invariance. Such a Hamiltonian is appropriate for a periodic array of SMMs or a uniform SMM-like effective medium, not for a single localized impurity. Conclusions based on 2D band structures, k-space Chern numbers, and a quantized spin Hall conductivity for the entire surface (as in Eq. 16) are not directly applicable to a single impurity scenario. A single impurity would instead lead to local scattering of surface states and potentially localized bound states, rather than a global modification of the band structure resulting in a surface-wide quantized Hall effect."
      },
      {
        "Problem": "Misleading interpretation of non-quantized pseudo-spin Chern numbers as defining a 'topological phase' when SMM tunneling ($\\Delta_x$) is present.",
        "Location": "Page 3, Section 'Effects of Tunneling', specifically the discussion surrounding Eq. (20) and the statement 'which defines a nontrivial topological spin Hall phase provided that $\\Delta_x/\\lambda \\ll 1$'.",
        "Explanation": "When SMM tunneling is included ($\\Delta_x \neq 0$), the paper calculates pseudo-spin Chern numbers $\\mathscr{C}^{\\pm}$ (Eq. 20) which are generally not quantized but vary continuously with the ratio $\\Delta_x/\\lambda$. While these numbers approach $\\pm 1/2$ in the limit $\\Delta_x/\\lambda \\ll 1$, describing the system as being in a 'nontrivial topological spin Hall phase' based on these non-quantized (or approximately quantized) numbers is problematic. Topological phases are typically characterized by strictly quantized topological invariants that remain constant under continuous deformations of parameters as long as the relevant energy gap does not close. The continuous variation of $\\mathscr{C}^{\\pm}$ suggests the absence of such topological robustness for arbitrary finite $\\Delta_x$."
      },
      {
        "Problem": "The simplification of the s-d exchange interaction term $H_{int}$ to an Ising-like form relies on unstated assumptions that limit its generality.",
        "Location": "Page 2, transition from Eq. (6) ($H_{int}= -\\lambda\\sum_{\\bold{k}}\boldsymbol{\\mathcal{S}}\\cdot c^{\\dagger}_{\\bold{k}}\boldsymbol{\\sigma}c_{\\bold{k}}$) to the interaction term $-\\lambda\tau_z\\sigma_z$ in Eq. (7), and the accompanying justification 'we have assumed interaction in the $z$-direction for simplicity'.",
        "Explanation": "The paper starts with an isotropic s-d exchange interaction $\boldsymbol{\\mathcal{S}}\\cdot\boldsymbol{\\sigma}$ but then uses an effective Ising-like interaction $-\\lambda\tau_z\\sigma_z$ within the two-level SMM approximation. This simplification is reasonably justified for SMMs with large spin $S > 1/2$ (like Fe8, Mn12 mentioned) if one considers only direct projection onto the $\\{\\ket{S_z=S}, \\ket{S_z=-S}\\}$ subspace, as transverse spin components $\\mathcal{S}_x, \\mathcal{S}_y$ have vanishing matrix elements within this subspace at first order. However, this should be explicitly stated as a condition. If $S=1/2$, or if higher-order processes (virtual transitions via other SMM levels) generate significant effective $\tau_x\\sigma_x$ or $\tau_y\\sigma_y$ interaction terms, these would couple the two pseudo-spin sectors even when the intrinsic SMM tunneling $\\Delta_x$ is zero. This would invalidate the derivation of the quantized spin Hall effect (Eq. 16), which relies on the decoupling of these sectors."
      }
    ],
    "token_usage": {
      "input": 10585,
      "thinking": 19951,
      "output": 949
    }
  },
  {
    "entry_id": 230,
    "retraction_id": "1903.02670v2",
    "paper_id": "1903.02670v1",
    "retraction_comment": "We can not use fixed-point theorem in the spaces defined in section 4.",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of local well-posedness for the Kuramoto-Sivashinsky (KS) equation in $H^s(\\mathbb{R})$ for $s>0$ (Theorem 4.3, localzero) appears to be valid only for $s>1/2$, not the entire $s>0$ range.",
        "Location": "Section 4, Proposition 4.2 (pro4zero), specifically the estimate for the $t^{(1-s)/2}\\|\\partial_x I(t)\\|_{L^2}$ component of the $\\mathcal{Z}_T^s$ norm for the integral term $I(t)$. Equation (4.6) addresses this part of the norm.",
        "Explanation": "Equation (4.6) incorrectly estimates $t^{(1-s)/2}\\|I(t)\\|_{L^2}$ instead of $t^{(1-s)/2}\\|\\partial_x I(t)\\|_{L^2}$ as required by the definition of the $\\mathcal{Z}_T^s$ norm (Equation 4.2). A correct estimate for $t^{(1-s)/2}\\|\\partial_x I(t)\\|_{L^2}$ (derived from applying $\\partial_x$ to the integral term and using estimates for the resulting kernel, similar to calculations in Section 3 or Section 2) seems to yield a factor of $T^{s/2-1/4}$ in the bilinear estimate. For the contraction mapping argument to work, this exponent must be positive, i.e., $s/2-1/4 > 0$, which implies $s>1/2$. If $0 < s \\le 1/2$, the exponent $s/2-1/4$ is non-positive, and the contraction argument fails because $T^{s/2-1/4}$ does not tend to zero as $T \\to 0$. This undermines the claim of Theorem 4.3 (localzero) for the range $0 < s \\le 1/2$."
      },
      {
        "Problem": "The proof of local well-posedness for the KS equation in $H^s(\\mathbb{R})$ for $s>1/2$ (Theorem 3.3, localmeio) contains flawed estimates in the key bilinear Proposition 3.6 (pro4 on page 10).",
        "Location": "Section 3, Proposition 3.6 (pro4 on page 10), specifically equations (3.10), (3.11), and (3.12).",
        "Explanation": "The $\\mathcal{Y}_T^s$ norm, defined in (3.6), includes a term $t^{(1-s)/2}\\|\\partial_x u(t)\\|_{L^2}$. When estimating this for the integral term $I(t)$, equation (3.12) incorrectly computes $t^{(1-s)/2}\\|I(t)\\|_{L^2}$ instead of the required $t^{(1-s)/2}\\|\\partial_x I(t)\\|_{L^2}$. Furthermore, the powers of $T$ derived for the $H^s$ part of the norm also appear inconsistent with the proposition's claim: (3.10) for the $\\dot{H}^s$ part yields $T^{s/2-1/4}$ (requiring $s<3/2, s>0$), and (3.11) for the $L^2$ part yields $T^{s-1/4}$ (the paper states $T^{s-1/2}$, which also seems to be a miscalculation from $t^{s-1/4}$ by a factor of $t^{-1/4}$). A corrected estimate for the $t^{(1-s)/2}\\|\\partial_x I(t)\\|_{L^2}$ term would also yield $T^{s/2-1/4}$. The proposition's claimed overall power $T^{s/2+1/4}$ is not justified by these calculations; the bottleneck appears to be $T^{s/2-1/4}$. While Theorem 3.3 might still hold for $s>1/2$ (as $s/2-1/4 > 0$), the presented proof is erroneous."
      },
      {
        "Problem": "The continuity arguments for the nonlinear terms in Proposition 2.5 (prop3) and Proposition 3.7 (prop3meio) misstate the rate of convergence of certain integrals when $t \\to t_0 > 0$.",
        "Location": "Section 2, Proposition 2.5 (prop3), page 7, estimate of $\\varphi_2(t,t_0)$; Section 3, Proposition 3.7 (prop3meio), page 11, estimate of $B(t,t_0)$ (which is part of $\\psi_2(t,t_0)$).",
        "Explanation": "The proofs estimate integrals of the form $K(t,t_0) = \\int_{t_0}^t (t-\\tau)^{-\\alpha} \\tau^\\beta d\\tau$. The paper's derivation of the power of $(t-t_0)$ (e.g., $(t-t_0)^{(s-\\lambda)/2+1/4}$ in Prop 2.5, $(t-t_0)^{(s-\\lambda)/2+1/4}$ in Prop 3.7 which comes from $(t-t_0)^{(s-\\lambda)/2-1/4}$ in (3.14) after multiplication by $(t-t_0)^{1/2}$ or similar factor) effectively assumes $t_0=0$, leading to an exponent of $(t-t_0)^{1-\\alpha+\\beta}$. However, for $t \\to t_0 > 0$, $\\tau^\\beta \\approx t_0^\\beta$, so $K(t,t_0) \\approx t_0^\\beta (t-t_0)^{1-\\alpha}/(1-\\alpha)$. The exponent of $(t-t_0)$ is $1-\\alpha$, which is different from $1-\\alpha+\\beta$ if $\\beta \\ne 0$. For instance, in Prop 2.5, $\\alpha = (s+\\lambda+1)/2+1/4$ and $\\beta=s$. The actual exponent for $t_0>0$ should be $1-\\alpha = 1/4-(s+\\lambda)/2$. While this corrected exponent is positive under the propositions' conditions (so continuity likely holds), the specific rate of convergence is misstated. This could be an issue for the $H^\\infty$ smoothing argument if the precise rate were important, although typically any positive power suffices for continuity."
      }
    ],
    "token_usage": {
      "input": 27901,
      "thinking": 21163,
      "output": 1523
    }
  },
  {
    "entry_id": 231,
    "retraction_id": "1408.0367v2",
    "paper_id": "1408.0367v1",
    "retraction_comment": "This paper has been withdrawn by the author. The paper only considers the omega>k regime, but the undamped modes have omega<k",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Approximation for sourced fluctuations might be incorrect, potentially overestimating the sourced magnetic field strength.",
        "Location": "Eq. (28) and (29), Section 4",
        "Explanation": "The approximation $G_R\\Pi_SG_{Aij}(\\eta,\\eta)\\approx \\pi_{ij}{a^4\\Pi_S^T(\\eta,\\eta)/ (k^2+a^2m_A^2)^2}$ (Eq. 28) appears to correspond to using a static Green's function squared. For a damped system subject to a stochastic source, the steady-state power spectrum is typically $G_S \\propto \\Pi_S / ((a\\sigma)(k^2+a^2m_A^2))$, where $a\\sigma$ is the damping coefficient. The paper's expression for $G_S$ (and thus $P_B$ in Eq. 29) is larger by a factor of $(k^2+a^2m_A^2)/(a\\sigma) \\approx 1/p_1$, where $p_1 \\approx a m_A^2/\\sigma$. This means the paper's formula potentially overestimates the sourced magnetic fields. While a smaller sourced term would strengthen the paper's overall conclusion of decay, using an inadequately justified or incorrect formula for a central quantitative estimate is a soundness concern."
      },
      {
        "Problem": "Missing factor of 2 in the exponent for the decay of free fluctuations.",
        "Location": "Eq. (24), Section 3.3",
        "Explanation": "Eq. (24) states $G_S^{(0)} \\approx \\frac{1}{2}k^{-1}(k\\tau_r)^{2\\epsilon}e^{-(am_A^2/\\sigma)(\\eta-\\eta_r)}$. Since $G_S^{(0)}(k,t,t) = |u(k,t)|^2$ (from Eq. 13 for equal times) and the mode $u(k,t)$ is argued to decay as $e^{-p_1(\\eta-\\eta_r)}$ with $p_1 \\approx am_A^2/\\sigma$, then $G_S^{(0)}(k,t,t)$ should decay as $e^{-2p_1(\\eta-\\eta_r)}$. The missing factor of 2 in the exponent means the calculated decay rate of unsourced fluctuations is underestimated by half (decay is actually faster). This is a quantitative error in a key result for free evolution."
      },
      {
        "Problem": "Assumption of strong damping for scalar field fluctuations may not be universally justified.",
        "Location": "Section 4.2, paragraph after Eq. (33)",
        "Explanation": "The argument for the exponential decay of sourced magnetic fields relies on the premise that the source current correlation $\\Pi_S^T$ itself decays. This is attributed to the exponential decay of the charged scalar field modes $v$. The paper states that $v$ decays with an exponent of order $e^4T/H$, similar to photon modes. This assumes that the scalar field's damping coefficient $\\sigma_\\phi$ and effective mass $m_\\phi$ behave analogously to those of the electromagnetic field (i.e., $a\\sigma_\\phi \\sim e^{-2}aT$ and $am_\\phi \\sim eaT$). This strong assumption about the scalar field's properties (its couplings and interactions with the plasma) needs robust justification, potentially on a model-by-model basis for the scalar fields (e.g. those in Calzetta et al.). If $\\sigma_\\phi$ or $m_\\phi$ are significantly smaller for the relevant scalar fields, the decay of the source term $\\Pi_S^T$ might be much slower, weakening the argument for the rapid disappearance of sourced magnetic fields."
      }
    ],
    "token_usage": {
      "input": 7233,
      "thinking": 16304,
      "output": 870
    }
  },
  {
    "entry_id": 232,
    "retraction_id": "1809.01643v2",
    "paper_id": "1809.01643v1",
    "retraction_comment": "Error in proof for efficiency bound. Variation of time variable is not taken into account",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The primary semiparametric estimator $\\hat{\\theta}_k$ in Eq. (2.3) is specified using unit-level differences $Y_{i,k}(1)-Y_{i,k}(0)$ and $\\hat{\\mathbb{E}}[Y_{i,k}(1)-Y_{i,k}(0)|X_{i,k},D_{i,k}=0]$. These terms are only computable if panel data (observing the same unit $i$ in both period 0 and 1) are available.",
        "Location": "Eq. (2.3) (page 5), Assumption 2.1 (page 3), Section 3.1 (page 8)",
        "Explanation": "Assumption 2.1 states that the data are 'Two iid cross-sections'. However, the estimator $\\hat{\\theta}_k$ in Eq. (2.3) requires observing $Y_i(1)$ and $Y_i(0)$ for the same unit $i$, which is characteristic of panel data, not repeated cross-sections. The estimator form in Eq. (2.3) is similar to the panel data estimator presented later in Section 3.1. This makes the main proposed semiparametric estimator in Section 2.2 incomputable with the data structure assumed in Section 2.1."
      },
      {
        "Problem": "The identification of ATET(1) in the linear model (Lemma 2.2) as $\\beta_1$ relies on an implicit and strong restriction that $\\beta_2=0$, meaning no baseline difference in outcome levels related to treatment status.",
        "Location": "Lemma 2.2 (page 6), Assumption 'ATET(0)=0' (page 3, after Ass. 2.3), Assumption 2.8 (page 6), Eq. (2.4) (page 6)",
        "Explanation": "The potential outcome model in Assumption 2.8 is $Y^d(t)=\\beta_0+t\\beta^d_1+d\\beta_2+x\\beta_3+tx\\beta_4+\\epsilon(t)$. From this, ATET(1) = $\\mathbb{E}[Y^1(1)-Y^0(1)|D=1] = (\\beta_1^1 - \\beta_1^0) + \\beta_2$. Letting $\\beta_1 = \\beta_1^1 - \\beta_1^0$, ATET(1) = $\\beta_1 + \\beta_2$. Lemma 2.2 states ATET(1) = $\\beta_1$, which implies $\\beta_2=0$. This implication stems from the earlier unnumbered assumption that ATET(0)=0, which translates to $\\mathbb{E}[Y^1(0)-Y^0(0)|D=1]=\\beta_2=0$ in this linear model. If $\\beta_2=0$, the $d\\beta_2$ term in the regression model Eq. (2.4) should be absent. This is a strong restriction, not typical for DiD models, and its necessity for interpreting $\\beta_1$ as ATET(1) is not clearly discussed."
      },
      {
        "Problem": "The variance formula for the linear estimator coefficient $\\hat{\\beta}_1(t)$ in Theorem 2.2 is incorrect.",
        "Location": "Theorem 2.2 (page 7)",
        "Explanation": "The variance component $\\sigma(t)^2$ is given as $\\mathbb{E}[D_i(t)-p(x_i(t))]^{-1}\\mathbb{E}[(D_i(t)-p(x_i(t)))^2(Y_i(t)-\\mathbb{E}[Y_i(t)|X_i(t)])^2]\\mathbb{E}[D_i(t)-p(x_i(t))]^{-1}$. The term $\\mathbb{E}[D_i(t)-p(x_i(t))]$ is $\\mathbb{E}[D_i(t)-\\mathbb{E}[D_i(t)|X_i(t)]] = 0$. Division by zero makes this formula incorrect. The outer terms in such sandwich variance formulas should typically be $\\mathbb{E}[(D_i(t)-p(x_i(t)))^2]^{-1}$ or its sample analog."
      },
      {
        "Problem": "Assumption 2.7 on prediction quality makes unrealistic statements about population error moments, or the proof of Theorem 2.2 relies on unstated, very strong ML estimator convergence rates.",
        "Location": "Assumption 2.7 (page 4), Proof of Theorem 2.2 (Appendix A.4, page 15)",
        "Explanation": "Assumption 2.7 states $\\lVert \\epsilon \\rVert_1=o(1/\\sqrt{N})$ and $\\lVert \\delta \\rVert_1=o(1/\\sqrt{N})$, where $\\epsilon = D-p(X)$ and $\\delta = Y-E[Y|X]$ appear to be population error terms. The $L_1$ norms of such population quantities are $O(1)$, not $o(N^{-1/2})$. The proof of Theorem 2.2 (Appendix A.4) uses these conditions in crucial steps, e.g., to show $\\sqrt{N(0)_k}\\lVert p_{k-1}(x_{ik})-\\hat{p}_{k-1}(x_{ik})\\rVert_{\\infty}\\times\\lVert\\delta_{ik}\\rVert_1 = o(1)$. If $\\lVert\\delta_{ik}\\rVert_1 = O(1)$ (as is standard), this step would require $\\lVert p-\\hat{p}\\rVert_{\\infty} = o(N^{-1/2})$. This is a very strong uniform convergence rate for ML estimators, not listed as required in Assumption 2.7's other conditions (which are $L_2$ rates or $O(1)$ for $L_q$) and not generally satisfied by common ML methods (e.g., Lasso) under typical high-dimensional scalings."
      },
      {
        "Problem": "There is a critical inconsistency regarding the semiparametric estimator: Eq. (2.3) defines it for panel data, while the theoretical setup (Section 2.1), the efficiency proof (Appendix A.2.1), and the empirical application (Section 4 using CPS data) are for repeated cross-sections.",
        "Location": "Eq. (2.3) (page 5), Section 2.1 (page 3), Appendix A.2.1 (page 11), Section 4 (page 8)",
        "Explanation": "As stated in Problem 1, Eq. (2.3) defines $\\hat{\\theta}_k$ using unit-level differences, suitable for panel data. However, the paper's context for this estimator is repeated cross-sections (Assumption 2.1). The application in Section 4 uses CPS data (repeated cross-sections), meaning Eq. (2.3) as written could not have been directly implemented. The efficiency bound derivation in Appendix A.2.1 is based on moment conditions that are appropriate for repeated cross-sections (using $Y$ and $\\mathbb{E}[Y|X,D=0]$, not their differences). This suggests that the estimator intended or used in the application might be a corrected version suitable for repeated cross-sections. However, the paper explicitly presents Eq. (2.3) as the estimator for which Theorem 2.1 (including the efficiency claim) holds, creating a significant disconnect and lack of clarity."
      }
    ],
    "token_usage": {
      "input": 21906,
      "thinking": 17840,
      "output": 1738
    }
  },
  {
    "entry_id": 233,
    "retraction_id": "1203.2581v2",
    "paper_id": "1203.2581v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 2",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inadequate Effective Model for 3D Features and $k_z$-dependent Pairing",
        "Location": "Page 3, definition of $\\varepsilon_k^{a}$ (Eq. (1) vicinity); Fig. 3 and its caption. Contrast with DFT results in Fig. 1b and discussion of Z-point pocket (Page 2, first paragraph of Sec. II results).",
        "Explanation": "The paper highlights significant 3D characteristics of the Fermi surface, notably a pocket near the Z point with strong Fe-$3d_{z^2}$ orbital character. However, the effective four-band model used for pairing calculations employs purely 2D electronic dispersions ($\\varepsilon_k(k_x, k_y)$) fitted only to the $k_z=0$ cross-section of the Fermi surface. This model does not explicitly include the Z-pocket or its 3D dispersion. Consequently, the model lacks the intrinsic $k_z$-dependence of the electronic structure, which is critical for reliably assessing the stability of $k_z$-dependent pairing symmetries (like the proposed $S_{x^2+y^2} + S_{z^2}$ state) and the formation of nodes along the $k_z$ direction. Conclusions drawn about such 3D pairing features from an effectively 2D band model are unsound."
      },
      {
        "Problem": "Ambiguous and Non-Standard Definition of Pairing Interactions and Symmetry Basis Functions",
        "Location": "Page 3, paragraph discussing pairing symmetry factors $\\phi^1_k, \\phi^2_k, \\phi^{\\perp}_k$ following Eq. (2) and their relation to $V_1, V_2, V_{\\perp}$.",
        "Explanation": "The paper associates single phenomenological interaction parameters ($V_1$, $V_2$) with multiple, distinct pairing symmetry basis functions simultaneously (e.g., $V_1$ with both $\\cos k_x \\cos k_y$ and $\\sin k_x \\sin k_y$; $V_2$ with both $(\\cos k_x + \\cos k_y)/2$ and $(\\cos k_x - \\cos k_y)/2$). This is non-standard, as a specific interaction term usually drives pairing in a particular symmetry channel, or a general interaction $V(k,k')$ is decomposed. The mechanism for how these different symmetries, supposedly driven by the same $V_i$, compete or are selected in the self-consistent calculation and energy minimization is not clarified. This ambiguity undermines the reliability of the calculated phase diagram (Fig. 4) and the conclusions about which pairing symmetry is favored under different interaction strengths."
      },
      {
        "Problem": "Unjustified Equivalence of Magnetic Exchange Couplings and Pairing Potentials",
        "Location": "Page 4, final paragraph of the main text.",
        "Explanation": "The paper proposes to directly substitute calculated magnetic exchange couplings ($J_1, J_2, J_{\\perp}$) for the phenomenological pairing potentials ($V_1, V_2, V_{\\perp}$) within the same BCS gap equation framework (Eq. 3) and using the same predefined pairing form factors ($\\phi^i_k$). This is a significant oversimplification. While magnetic exchange interactions can mediate superconductivity via spin fluctuations, the resulting effective pairing potential is not generally equivalent to the $J_i$ values themselves, nor would it necessarily couple to the pre-assumed phenomenological form factors $\\phi^i_k$. A proper derivation of pairing from spin fluctuations involves a more complex relationship (e.g., via spin susceptibility). This direct substitution lacks theoretical justification and renders the conclusion that $S_{x^2+y^2}$ symmetry (with form factor $\\cos k_x \\cos k_y$) would be stable under these $J_i$-derived interactions unsound."
      }
    ],
    "token_usage": {
      "input": 8240,
      "thinking": 9540,
      "output": 860
    }
  },
  {
    "entry_id": 234,
    "retraction_id": "1912.11842v3",
    "paper_id": "1912.11842v2",
    "retraction_comment": "There is a serious mistake in the section 4 in this paper. The paper concludes that there is new particle production in the system due to the plasma oscillation. However, the fact that the imaginary part of the self-energy will always be zero in the nonrelativistic limit indicates no new particle created",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Non-transversality of the background polarization tensor $\\Pi_{bac}^{\\mu\\nu}$",
        "Location": "Eq. (103a) and discussion on page 8, right column",
        "Explanation": "The derived background polarization tensor $\\Pi_{bac}^{\\mu\\nu}$ is proportional to $g^{\\mu\\nu}$ (Eq. 103a). This form is not transverse, meaning $k_\\mu \\Pi_{bac}^{\\mu\\nu}(k) \\neq 0$. Since the vacuum polarization $\\Pi_{vac}^{\\mu\\nu}$ is transverse, the total polarization tensor $\\Pi^{\\mu\\nu}$ would also be non-transverse. This typically violates gauge invariance in the effective theory for the fluctuation photon field $\\mathcal{A}_\\mu$, which is a fundamental issue in a theory of electromagnetism. Physical observables could become gauge-dependent. The paper's justification that this is acceptable because 'there is no external on-shell fermion' is insufficient for a photon self-energy, which must be transverse to maintain gauge invariance of the photon propagator."
      },
      {
        "Problem": "Inconsistencies in the derivation of dispersion relations from the effective action",
        "Location": "Section IV, specifically matrix Eq. (117a) and its relation to Eqs. (118a) and (119a)",
        "Explanation": "The elements of the matrix in Eq. (117a), which is central to deriving the dispersion relations, appear inconsistent with its stated origin from $D^{\\mu\\nu} = (-k^2 g^{\\mu\\nu} + k^\\mu k^\\nu)(1+i\\Pi_{vac}) - B g^{\\mu\\nu}$. For example, components $M_{03}$ and $M_{33}$ in Eq. (117a) feature unexpected coefficients (e.g., factors of 2 for $i\\Pi_{vac}$ in $M_{03}$ and for $B$ in $M_{33}$, and a sign flip for $i\\Pi_{vac}$ in $M_{33}$). Furthermore, the stated dispersion relations (Eqs. 118a and 119a) do not seem to follow directly from setting the determinant of the provided matrix (117a) to zero. For instance, the transverse mode from $M_{11}=0$ (using (117a)) would be $k^2(1+i\\Pi_{Tvac,2}(k))+B(\\omega,|\\textbf{k}|)=0$, which differs from the equations used to derive the main physical results (e.g., Eq. (119a) has $2B$). These inconsistencies undermine the validity of the derived wave properties."
      },
      {
        "Problem": "Questionable physical basis and derivation of 'particle production induced by plasma oscillation'",
        "Location": "Section IV.A.1, Eq. (122c), Figure 1, and related discussions in Abstract and Introduction",
        "Explanation": "A major new claim is the production of electron-positron pairs induced by plasma oscillation (Eq. 122c). This is derived by interpreting a correction term $\\epsilon = \\omega_p^2/(4m^2)$ to the plasma frequency as an effective change in particle number density $\\delta n/n_0 = \\epsilon$. However, in the regime considered (e.g., $n_0 \\le 10^{30} \\text{ cm}^{-3}$), the plasmon energy $\\hbar\\omega_p$ is significantly less than $2mc^2$, making pair production by individual plasmons energetically forbidden. The paper does not provide a clear alternative physical mechanism for this production within a thermal equilibrium framework (TFD). The effect might be a re-interpretation of a quantum/relativistic correction modifying how $n_0$ enters the plasma frequency, rather than an actual change in the number of real particles. The validity of this conclusion also depends on the correctness of the underlying dispersion relations (see Problem 2)."
      },
      {
        "Problem": "Inconsistent treatment of classical field expansion coefficients as Grassmann numbers",
        "Location": "Section III.A.1, page 6, specifically Eqs. (62a-64a) and their use in Eqs. (70a), (71a)",
        "Explanation": "The 'classical limit method' expands the classical background spinor field $\\psi_0$ using coefficients $\\bar{c}^s(t,\\textbf{p})$ and $\\bar{d}^s(t,\\textbf{p})$, which are explicitly stated to be Grassmann numbers (page 6, paragraph after Eq. 64a). However, expressions like $\\sum_s|\\bar{c}^s(t,\\textbf{p})|^2$ are then equated to c-number particle number densities $N_0^{(+)}(t,\\textbf{p})$ (Eq. 70a). If $\\bar{c}^s$ are true Grassmann numbers, $(\\bar{c}^s)^* \\bar{c}^s$ would be an anticommuting element of the Grassmann algebra (or zero if not part of a Berezin integral), not a positive c-number representing a particle density. This suggests a fundamental conceptual inconsistency in the definition or mathematical treatment of these 'classical' background field coefficients, which are essential for calculating the background polarization tensor $\\Pi_{bac}^{\\mu\\nu}$."
      }
    ],
    "token_usage": {
      "input": 38759,
      "thinking": 14390,
      "output": 1223
    }
  },
  {
    "entry_id": 235,
    "retraction_id": "2212.07368v2",
    "paper_id": "2212.07368v1",
    "retraction_comment": "There is an error in the use of Corollary 1 in our Paper, which does not apply in our case",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unclear handling of $K_\\Sigma$ (number of unique Diracs in the sum signal) and reliance on potentially ground-truth $K_\\Sigma$ in experiments.",
        "Location": "Algorithm 1 (input $K_\\Sigma$), Section 5.C (Numerical Experiments, e.g., Fig. 4 caption where $K_1=3, K_2=3$), Section 5.E (Real Data Experiment).",
        "Explanation": "Algorithm 1 requires $K_\\Sigma$ as an input. For simulations (e.g., Fig. 4b, Fig. 5, Fig. 6), it's not specified if the true $K_\\Sigma$ for each random realization is used, or if $K_\\Sigma$ is estimated or set to an upper bound (e.g., $K_1+K_2$). Using the true $K_\\Sigma$ would be an optimistic assumption. For the real data experiment (Section 5.E), the paper states $K_\\Sigma$ is from \"extracted spike counts,\" implying use of ground-truth electrophysiology. This is a strong assumption that may not hold in practical scenarios where such ground truth is unavailable. The paper does not adequately discuss the sensitivity of the method to errors in $K_\\Sigma$ or how $K_\\Sigma$ would be estimated in a truly blind setting. This makes it difficult to assess the method's performance under more realistic conditions where $K_\\Sigma$ itself is an estimate, potentially impacting the practical significance of the presented results."
      },
      {
        "Problem": "Inconsistent or unexplained constraint $K_\\Sigma > 2$ for Algorithm 1.",
        "Location": "Algorithm 1 (input $K_\\Sigma > 2$), Captions of Fig. 5 and Fig. 6 (using $K_1=2, K_2=2$).",
        "Explanation": "Algorithm 1 specifies $K_\\Sigma > 2$ as a condition on its input parameter. However, the experimental setups described for Figure 5 (Benchmark) and Figure 6 (Refinement) use $K_1=2, K_2=2$. In these setups, if the two signals share all their spike times, $K_\\Sigma$ would be 2. If they share one spike time, $K_\\Sigma$ would be 3. If they share no spike times, $K_\\Sigma$ would be 4. Thus, it is possible for $K_\\Sigma=2$ in these experiments, which violates the stated condition $K_\\Sigma > 2$. This inconsistency raises questions about: (a) whether the constraint $K_\\Sigma > 2$ is strictly necessary for the algorithm to function correctly (if not, it should be clarified or removed), or (b) if the experiments involving $K_\\Sigma=2$ were performed with a modified algorithm or if these specific results might be unreliable. If the method indeed fails for $K_\\Sigma \\le 2$, this would be a significant limitation for signals with fewer components, which is not discussed."
      }
    ],
    "token_usage": {
      "input": 30173,
      "thinking": 17738,
      "output": 690
    }
  },
  {
    "entry_id": 236,
    "retraction_id": "1104.1920v2",
    "paper_id": "1104.1920v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 42, 50, 51",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent handling of initial source correlation (α²) between Reverse Reconciliation (RR) and Direct Reconciliation (DR) bounds.",
        "Location": "Comparison of Page 15 (RR bounds independence of α²) and formulas in Section III (e.g. Eq 34, 40, 41 lacking α²) with Page 23 (DR bounds dependence on α²) and formulas in Appendix (e.g. Eq 47, 49-51 containing α²). Also, concluding remarks on Page 19.",
        "Explanation": "The paper claims that its new bounds for Reverse Reconciliation (RR) in Section III are independent of the initial source correlation/mixedness parameter α² (effectively assuming a pure source with α²=1). This is justified by stating these bounds are identical to those for a maximally entangled case. However, the bounds derived in the Appendix for Direct Reconciliation (DR), using ostensibly the same formalism, explicitly depend on the actual α² of the source. This is a critical inconsistency. The physical source and Eve's interaction are the same for both RR and DR. If the security principle for RR allows assuming α²=1 (attributing source mixedness to Eve) to obtain the tightest secure key rate, the same principle should apply to DR. Conversely, if DR correctly accounts for actual source mixedness (α² > 1), then RR bounds should also reflect this, and the Section III RR bounds would not be general for any α² but specific to α²=1, potentially overestimating security if the actual source has α² > 1 and this mixedness is exploitable beyond the α²=1 case."
      },
      {
        "Problem": "Restriction to phase-insensitive Gaussian attacks while claiming generality.",
        "Location": "Page 10, Eq (21) and its justification (C=Y=0 from Iwasawa decomposition); Page 13, assumption 'Tx=Tp=T and χx=χp=χline'.",
        "Explanation": "The derivation of the 'optimal bounds' in Section III (and the Appendix) relies on the assumption that Eve's symplectic transformation S is phase-insensitive. This is explicitly stated by setting S=diag(Sx,Sp) (Eq 21), which implies that the off-diagonal blocks C and Y in the general Iwasawa decomposition (Eq 20) are zero, and further by assuming identical transmission and noise for X and P quadratures (Tx=Tp, χx=χp). While this is characteristic of some channels like fiber optics, it restricts the generality of Eve's attack. A security proof against 'all possible collective Gaussian attacks' (as claimed on page 9) should consider general Gaussian unitaries, including phase-sensitive ones, unless it is rigorously proven that these reduce to the phase-insensitive case for the Holevo bound under all relevant conditions. The paper does not provide sufficient justification for this restriction covering all general Gaussian attacks."
      },
      {
        "Problem": "Flawed reasoning for the 'non-tightness' of previous bounds, which motivates the new bounds.",
        "Location": "Page 9, paragraph starting 'It is clear that the Holevo bound...'.",
        "Explanation": "The paper argues on page 9 that the bounds from Section II (based on Eve purifying ρ_AB) are 'not tight'. The reasoning is that Eve's Holevo information (XBE) is non-zero if the source is imperfect (e.g., characterized by α² > 1, indicating mixedness or non-maximal entanglement) even with a perfect channel (T=1, no channel-induced noise). The paper states this 'disagree[s] with our initial assumption... any attempt of intercepting the quantum channel by Eve will obviously induce some noises into the channel.' This reasoning is flawed. If the source itself is imperfect, Eve can legitimately gain information from this source imperfection without interacting with or inducing noise in the quantum channel. A non-zero XBE in such a scenario reflects actual information available to Eve due to the source characteristics, not necessarily a flaw in the bound formalism making it 'not tight'. While the new bounds presented in Section III might indeed be tighter due to established extremality arguments in CVQKD security (e.g., assuming an effective α²=1 for RR), the specific motivation provided on page 9 for the 'non-tightness' of prior bounds is based on a misunderstanding of how information leakage from imperfect sources is accounted for."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 14402,
      "output": 967
    }
  },
  {
    "entry_id": 237,
    "retraction_id": "1406.6450v2",
    "paper_id": "1406.6450v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a gap in the inequality of (2.7)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Invalid application of Lemma 2.2 (Lemma \\ref{backext}) for deriving equation (\\ref{*}).",
        "Location": "Page 7, Proof of Theorem \\ref{Ans-Lubin}(ii), derivation of equation (\\ref{*})",
        "Explanation": "The derivation of the condition $\\epsilon \\le 5/12$ for the subnormality of $(T_1,T_2)|_{\\mathcal{N}}$ (equation (\\ref{*})) appears to be critically flawed. The argument attempts to apply Lemma 2.2 (Subnormal backward extension). The resulting inequality, $2\\epsilon (\\frac{1}{5}\\delta_{1/2}(t) + \\frac{4}{5}\\delta_1(t)) \\le \\frac{1}{3}\\delta_{1/2}(s) + \\frac{2}{3}\\delta_1(s)$, compares a measure on variable $t$ (left side) with a measure on variable $s$ (right side). Such a comparison is mathematically ill-defined. This condition is essential for establishing that $T_1+T_2$ is subnormal in the range $0 < \\epsilon \\le 5/12$, which in turn is crucial for the paper's main conclusion."
      },
      {
        "Problem": "Incorrect or unsubstantiated formula for the extremal measure $(\\mu_{\\mathcal{M}\\cap N})_{ext}^{Y}$.",
        "Location": "Page 7, Proof of Theorem \\ref{Ans-Lubin}(ii), text preceding equation (\\ref{co0})",
        "Explanation": "In the derivation of equation (\\ref{*}), the paper states $(\\mu_{\\mathcal{M}\\cap N})_{ext}^{Y}=\\frac{1}{5}\\delta_{\\frac{1}{2}}+\\frac{4}{5}\\delta_{1}$. The definition of an extremal measure $(\\mu)_{ext}$ is given in Section 2(ii). Standard calculation of $((\\mu_{\\mathcal{M}\\cap N})_{ext})^Y$ (the Y-marginal of the extremal measure of $\\mu_{\\mathcal{M}\\cap N}$) yields $\\frac{1}{3}\\delta_{1/2} + \\frac{2}{3}\\delta_1$. The paper's formula seems to be $t \\cdot (\\xi_a)_{\\mathcal{L}_1}(dt)$ normalized, which is not derived from the provided definition of extremal measures. This incorrect measure is then used in the flawed comparison mentioned in Problem 1."
      },
      {
        "Problem": "Potentially incorrect derivation of the subnormality condition for $(T_1,T_2)$ in Theorem \\ref{Ans-Lubin}(iii).",
        "Location": "Page 9, Proof of Theorem \\ref{Ans-Lubin}(iii), equation (\\ref{co2}) and subsequent derivation",
        "Explanation": "The derivation of the condition $\\epsilon \\le 3/8$ for the subnormality of $(T_1,T_2)$ uses equation (\\ref{co2}) for $d(\\mu_{\\mathcal{M}})_{ext}^X$. This formula, $d(\\mu_{\\mathcal{M}})_{ext}^{X}=\\left\\Vert \\frac{1}{t}\\right\\Vert_{L^{1}(\\mu_{\\mathcal{M}})}^{-1}\\left( \\frac{1}{3t}\\right) d\\mu_{\\mathcal{M}}\\left( \\delta_{\\frac{1}{2}}+2\\delta_{1}\\right)$, is non-standard and appears ill-defined, as $d\\mu_{\\mathcal{M}}$ is a measure on $X \\times Y$ and its evaluation on $(\\delta_{1/2}+2\\delta_{1})$ (presumably a measure on $Y$) is unclear. A standard application of Lemma 2.2 with the definition of extremal measure from Section 2(ii) leads to a different condition, potentially $\\epsilon \\le 1/4$. If the $3/8$ bound is incorrect, the claimed interval $(3/8, 5/12]$ for the counterexample would be affected."
      },
      {
        "Problem": "Lemma 2.2 (Subnormal backward extension) may not be applicable as used for equation (\\ref{*}).",
        "Location": "Page 7, Proof of Theorem \\ref{Ans-Lubin}(ii), derivation of equation (\\ref{*})",
        "Explanation": "Lemma 2.2 describes adding a single '0-th row' (indexed by $k_2=0$) to a shift defined for $k_2 \\ge 1$. In the argument for equation (\\ref{*}), the paper attempts to establish subnormality for $(T_1,T_2)|_{\\mathcal{N}}$ (where $k_1 \\ge 1, k_2 \\ge 0$) by extending from $(T_1,T_2)|_{\\mathcal{M} \\cap \\mathcal{N}}$ (where $k_1 \\ge 1, k_2 \\ge 1$). This involves adding the 'row' $\\{(k_1,0) : k_1 \\ge 1\\}$. The '$\\beta_{00}$' term from Lemma 2.2 would correspond to multiple weights $\\beta_{(k_1,0)}$ ($k_1 \\ge 1$), and the '$\\xi_0$' measure for the $T_1$ part on this 'row' would be for the shift $(\\alpha_{(1,0)}, \\alpha_{(2,0)}, \\dots)$. It is not clear that Lemma 2.2 directly applies to this setup without modification or justification, as it is formulated for a single $\\beta_{00}$ and a single 0-th row $T_1$ shift."
      }
    ],
    "token_usage": {
      "input": 18589,
      "thinking": 27257,
      "output": 1310
    }
  },
  {
    "entry_id": 238,
    "retraction_id": "1510.05979v4",
    "paper_id": "1510.05979v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (39)",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The primary equation of motion for the continuous system, Eq. (SC) / (EO2), involves a divergent integral.",
        "Location": "Section 2, Eq. (SC) (also denoted (EO) on page 6); Section 3, Eq. (EO2) (page 8)",
        "Explanation": "The equation of motion $v^2y''(\\tilde{\\xi})=\\int_0^1\\varphi(y(\\tilde{\\xi})-y(\\xi))d\\xi$ with $\\varphi(w)=-\\sigma w/\\|w\\|^{2+\\sigma}$ is ill-defined. For a $C^1$ path $y$, the integrand behaves as $1/|\\tilde{\\xi}-\\xi|^{1+\\sigma}$ when $\\xi \\approx \\tilde{\\xi}$. This integral diverges at $\\xi = \\tilde{\\xi}$ for $\\sigma \\ge 0$. The paper assumes solutions $y$ are $C^2$ (due to $y''$), which implies they are $C^1$. The analysis is for $0 < \\sigma \\le 1$ (or $0 < \\sigma < 1$ in Sec. 3), where this divergence occurs. If solutions are only $H^1$, the integral converges for $\\sigma < 1$ but diverges for $\\sigma = 1$. This fundamental issue with the governing equation invalidates subsequent results based on it."
      },
      {
        "Problem": "The action functional minimized in Theorem 3.1 (Eq. (AC)) does not correspond to the stated equation of motion (EO2).",
        "Location": "Section 3, Eq. (AC) (page 8) and Theorem 3.1 (page 8)",
        "Explanation": "The paper aims to find solutions to Eq. (EO2), which is the Euler-Lagrange equation of $S(y) = \\int_0^1[\\frac{v^2}{2}\\|\\dot{y}\\|^2 + \\frac{1}{2}\\int_0^1 \\|y(s)-y(s')\\|^{-\\sigma}ds']ds$. However, Theorem 3.1 proves the existence of a minimizer for $\\mathcal{A}^\\sigma(y)=\\int_0^1\\frac{v^2}{2}\\|\\dot{y}(s)\\|^2 ds +\\int_0^1 \\frac{ds}{\\|y(s)-y(0)\\|^\\sigma}$ (Eq. (AC)). This functional (AC) is derived from $S(y)$ (or a variant of it) using the step $\\int_0^1\\int_0^1\\|y(s')-y(s)\\|^{-\\sigma}ds' ds=\\int_0^1\\|y(s')-y(0)\\|^{-\\sigma}ds'$, which is not valid for general functions $y \\in \\Lambda$ but only for specific symmetric paths. Therefore, the minimizer found by Theorem 3.1 is not guaranteed to be a solution of the intended continuous system Eq. (EO2)."
      },
      {
        "Problem": "The claim that the circle is a continuous choreography (Proposition 3.1) is invalid.",
        "Location": "Section 3.2, Proposition 3.1 (page 9)",
        "Explanation": "Proposition 3.1 states that $y(s)=e^{i2\\pi s}$ is a solution of Eq. (EO2) if $v^2 = \\frac{1}{(2\\pi)^2} \\int_0^1 \\sigma \\frac{1-y(u)}{|1-y(u)|^{2+\\sigma}}du$. For this to hold, the integral must be a real, positive constant. However, the imaginary part of this integral is proportional to $\\int_0^\\pi \\cos x (\\sin x)^{-(1+\\sigma)} dx$, which diverges for $0 < \\sigma < 1$ (it is of the form $\\infty - \\infty$). Thus, $v^2$ cannot be a real constant, meaning the circle, as described, cannot satisfy Eq. (EO2). This is a specific manifestation of the general divergence issue identified in Problem 1, applied to the circular path."
      }
    ],
    "token_usage": {
      "input": 14826,
      "thinking": 23664,
      "output": 968
    }
  },
  {
    "entry_id": 239,
    "retraction_id": "1202.0569v2",
    "paper_id": "1202.0569v1",
    "retraction_comment": "Due to a flaw in Lemma 9, the paper has been withdrawn",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lemma 3.1 incorrectly states that all classes U must have size at least 2.",
        "Location": "Lemma 3.1 and its proof; subsequently affects Lemma 3.2, Step 3.",
        "Explanation": "Lemma 3.1 states that for any non-empty class $U \\in \\mathcal{U}$, $|U| \\ge 2$. A class $U$ is defined as $U_i = \\{ v \\in V(K) : H(v) = H_i \\}$, where $H_i$ are connected components of $G - E(\\mathcal{C})$ and $V(K)=V(\\mathcal{C})$. If a vertex $v \\in V(\\mathcal{C})$ has degree 2 in $G$ (and all vertex degrees are assumed to be 2 or 3), then both edges incident to $v$ belong to $E(\\mathcal{C})$. Thus, $v$ is an isolated vertex in $G - E(\\mathcal{C})$, meaning its component $H(v)$ is just $\\{v\\}$. This forms a class $U=\\{v\\}$ of size 1, contradicting the lemma. The proof of Lemma 3.1 implicitly assumes that any vertex $u \\in U$ (with $|U|=1$) must have degree 3 in $G$ by stating there is 'exactly one edge $e=uv$ with $v \\in H(u)$' (which must be an edge not in $E(\\mathcal{C})$). This error is critical because the algorithm in Lemma 3.2 (Step 3) relies on Lemma 3.1 to guarantee the existence of a type 0 vertex in classes $U_1$ and $U_{\\ell+1}$ (when $\\deg_M(U_1)=1$). If $|U_1|=1$, its only vertex is necessarily matched and thus not type 0, potentially halting the algorithm or making its subsequent steps invalid."
      },
      {
        "Problem": "Lemma 3.4 fails to guarantee that the constructed set A' is non-empty and a strict subset of A.",
        "Location": "Lemma 3.4 and its proof.",
        "Explanation": "Lemma 3.4 states that if $G-A$ has bridges $B$, there exists a *non-empty* set $A' \\subset A$ such that $G-A'$ is bridge-free. The construction defines $A' = A \\setminus \\{e'_1, \\dots, e'_\\ell\\}$, where $\\ell = |B|$ and each $e'_i \\in A$. For $A'$ to be non-empty, $A$ must contain at least one edge not in $\\{e'_1, \\dots, e'_\\ell\\}$. The proof claims $A' \neq \\emptyset$ because $\\{e''_1, \\dots, e''_\\ell\\} \\subseteq A'$, implying $e'_i \neq e''_j$. However, if $A$ consists of a single edge path (e.g., if $M$ in Lemma 3.2 has one edge, and this edge corresponds to a single edge in $G$ after undoing contractions), say $A=\\{a_1\\}$, and $G-A$ has one bridge $b_1$, then $e'_1$ must be $a_1$. In this case, $A' = A \\setminus \\{a_1\\} = \\emptyset$, contradicting the 'non-empty' requirement. Furthermore, for $A'$ to be a *strict* subset of $A$, $A$ cannot be empty (which is true by definition of $\\mathcal{C}$-augmenting set) and $\\{e'_1, \\dots, e'_\\ell\\}$ must be non-empty (i.e., $B \neq \\emptyset$). If $A=\\{a_1\\}$, no strict non-empty subset $A'$ exists. This failure impacts Lemma 3.5 (Step 2), which relies on Lemma 3.4."
      },
      {
        "Problem": "The definition and properties of the final augmenting set in Lemma 3.5 are unclear and potentially incorrect.",
        "Location": "Lemma 3.5, particularly Step 3, Step 4, and the concluding proof arguments.",
        "Explanation": "Lemma 3.5 describes an algorithm to find a $\\mathcal{C}$-augmenting set $A'$ such that $G-A'$ is bridge-free. The algorithm iteratively constructs sets $A_0, A_1, \\dots, A_i$. $A_0 \\subseteq E(\\mathcal{C})$, but $A_j \\subseteq E(\\mathcal{C}'_{j-1})$ for $j \\ge 1$, where $\\mathcal{C}'_{j-1}$ can contain edges not in $E(\\mathcal{C})$. The final set of edges removed from $G$ to make it bridge-free is effectively $A_{total} = A_0 \\cup A_1 \\cup \\dots \\cup A_i$. The graph $G-A_{total}$ (denoted $G'_i$ in the proof's last iteration) is bridge-free and has a circulation $\\mathcal{C}'_i$. However, a $\\mathcal{C}$-augmenting set must be a subset of $E(\\mathcal{C})$. So, Step 4 defines the returned set as $A' = A_{total} \\cap E(\\mathcal{C})$. The proof claims $G-A'$ is bridge-free because $G-A' \\supseteq G-A_{total}$ and $G-A_{total}$ is bridge-free. This part is correct. The critical issue is whether $A'$ is $\\mathcal{C}$-augmenting with $\\mathcal{C}'_i$ as the resulting circulation. This requires $E(\\mathcal{C}'_i) \\supset E(\\mathcal{C}) \\setminus A'$. The algorithm's termination condition (Step 3) ensures $E(\\mathcal{C}) \\setminus A_i^{last} \\subseteq E(\\mathcal{C}'_i)$ where $A_i^{last}$ is the version of $A_j$ used in that iteration. The proof's final lines argue $E(\\mathcal{C}) \\setminus (A_0 \\cup \\dots \\cup A_i \\cup E(\\mathcal{C}'_i)) = \\emptyset$, which means $E(\\mathcal{C}) \\setminus A_{total} \\subseteq E(\\mathcal{C}'_i)$. It is not shown that this implies $E(\\mathcal{C}) \\setminus (A_{total} \\cap E(\\mathcal{C})) \\subseteq E(\\mathcal{C}'_i)$ and, crucially, that the strict superset condition $E(\\mathcal{C}'_i) \\supset E(\\mathcal{C}) \\setminus (A_{total} \\cap E(\\mathcal{C}))$ holds. The circulation $\\mathcal{C}'_i$ is in $G-A_{total}$, not $G-(A_{total} \\cap E(\\mathcal{C}))$, and its construction is tied to $A_{total}$."
      }
    ],
    "token_usage": {
      "input": 14519,
      "thinking": 18690,
      "output": 1547
    }
  },
  {
    "entry_id": 240,
    "retraction_id": "2111.02352v2",
    "paper_id": "2111.02352v1",
    "retraction_comment": "The previous to the last sentence of Section 4, namely that \"This means that $\\hat{Q}$ and, by Lemma 6, $\\hat{Q}$ too, is less than 1.\" is wrong",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misstatement about graph size parameters being constant.",
        "Location": "Page 2, Section 2.1 Preliminaries, 1st paragraph",
        "Explanation": "The paper states: 'Let G=(V,E) be a (simple) graph with l vertices and m edges (both l and m are considered constants)'. If l (number of vertices) and m (number of edges) are constants, the problem of acyclic coloring becomes trivial for a fixed constant, as the graph itself would be from a finite set of graphs. The results, particularly those concerning asymptotic behavior with respect to maximum degree $\\Delta$, imply that l and m are parameters of the graph that can be arbitrarily large. While this might be a terminological issue (meaning 'fixed for a given graph instance'), it can be misleading. The subsequent analysis (e.g., Lemma 4 bounding main loop repetitions by l, and the sum for $P_n$ involving $l$ terms) seems to treat $l$ as a general parameter, not a universal constant."
      },
      {
        "Problem": "The justification for $\\hQ < 1$ is terse and could be elaborated.",
        "Location": "Page 9, paragraph proving Fact 2",
        "Explanation": "The argument for $\\hQ < 1$ (and thus $Q < 1$) is: 'By Lemma 5, the produced coloring at the end of any execution of VV is random. Also, by Lemma 2, the probability that a random coloring is $\\alpha$-specially proper is positive. This means that $\\hQ$ and, by Lemma 6, $Q$ too, is less than 1.' While plausible, this inference is quite condensed. Lemma 5 states that the coloring is random conditional on VV($\\F$) not failing (i.e., succeeding). If $E_{VV\\_succeeds}$ is the event that VV($\\F$) succeeds for some $\\F$, and $C_{final}$ is the resulting coloring, the argument implies $\\Pr[C_{final} \\text{ is not } \\alpha \\text{-sp } | E_{VV\\_succeeds}] = 1-p_{sp}$ (where $p_{sp}>0$ is the probability a random coloring is $\\alpha$-sp). Then $\\hQ = \\Pr[C_{final} \\text{ is not } \\alpha \\text{-sp } | E_{VV\\_succeeds}] \\Pr[E_{VV\\_succeeds}] = (1-p_{sp})\\Pr[E_{VV\\_succeeds}]$. Since $\\Pr[E_{VV\\_succeeds}] \\le 1$, $\\hQ \\le 1-p_{sp} < 1$. This more detailed reasoning makes the claim stronger; the paper's current phrasing is very brief for this crucial step."
      },
      {
        "Problem": "Inequality in Equation (7) definition of q.",
        "Location": "Page 7, Equation (7)",
        "Explanation": "Equation (7) defines $q:= \\frac{1}{\\alpha{\\Delta}^{4/3}} > \\frac{1}{\\lceil \\alpha{\\Delta}^{4/3}\\rceil + \\D +1}$. While the inequality $\\alpha{\\Delta}^{4/3} < \\lceil \\alpha{\\Delta}^{4/3}\\rceil + \\D +1$ is true (assuming $\\Delta \\ge 0$), which implies the stated inequality for $q$, the actual palette size is $K = \\lceil \\alpha{\\Delta}^{4/3}\\rceil + \\D +1$. The probability of, for example, two specific vertices having the same color is $1/K$. The analysis uses $q$ as an upper bound for $1/K_{eff}$ where $K_{eff}$ is related to $K$. Specifically, $1/K < q$. Thus, the probability of a 4-cycle being 'badly colored' is $1/K^2 < q^2$. This is correctly used later as $\\Pr[V_F] \\le ||\\F||$. The issue is not with the mathematical correctness of the inequality itself but that $q$ is defined based on $\\alpha\\Delta^{4/3}$ rather than $K$. The statement $q > \\frac{1}{K}$ is true. The phrasing could be clearer that $q$ is an approximation related to the dominant term of $K$ and serves as an upper bound for probabilities like $1/K^2 < q^2$."
      }
    ],
    "token_usage": {
      "input": 14237,
      "thinking": 22059,
      "output": 1009
    }
  },
  {
    "entry_id": 241,
    "retraction_id": "2207.08480v2",
    "paper_id": "2207.08480v1",
    "retraction_comment": "Errors in the method to determine the S-transformation coefficients, because the characters for the surfaces are not simply the product of characters for cylinders. Errors in the linear spaces assigned to surfaces in string vertices this http URL concrete definition for open sector linear spaces also required",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous Definition of Open Sector Linear Space $V_{\\mu_1 \\mu_2}^{\\mu_3}$",
        "Location": "Section 3.1.2, Equation (3.10)",
        "Explanation": "The open sector linear space $V_{\\mu_1 \\mu_2}^{\\mu_3}$ is defined as being $V_{\\mu_3 \\mu_1}^{\\omega(P_2)}$ when the equal-time curve is in region 'a', and $V_{\\mu_3 \\mu_2}^{\\omega(P_1)}$ when in region 'b'. A linear space is typically a fixed algebraic structure. Defining it piece-wise based on 'region' or 'time' is unconventional and makes the nature of $V_{\\mu_1 \\mu_2}^{\\mu_3}$ itself ambiguous. If $V_{\\mu_3 \\mu_1}^{\\omega(P_2)}$ and $V_{\\mu_3 \\mu_2}^{\\omega(P_1)}$ (which are defined via tensor products involving $\\mathcal{H}_P$) are distinct spaces, then $V_{\\mu_1 \\mu_2}^{\\mu_3}$ is not a single, well-defined linear space. Even if they are isomorphic (as implied by Eq. 3.8), the definition obscures what $V_{\\mu_1 \\mu_2}^{\\mu_3}$ is as an abstract space of couplings. This definition conflates the physical state configuration on the surface with the definition of the abstract linear space."
      },
      {
        "Problem": "Unconventional Form of Partition Function on $C_{0,0,\\tilde{3}}$ for $V_{\\mu_1 \\mu_2}^{\\mu_3}$",
        "Location": "Section 3.3.1, equation for $P_{\\mu_1 \\mu_2}^{\\mu_3}$ (unnumbered, after Eq. 3.16)",
        "Explanation": "The partition function proposed for the surface $C_{0,0,\\tilde{3}}$ assigned with $V_{\\mu_1 \\mu_2}^{\\mu_3}$ is $P_{\\mu_1 \\mu_2}^{\\mu_3} = n_{\\mu_3 \\mu_2}^{\\omega(P_1)} \\chi_{\\omega(P_1)}(q_a) \\times n_{\\mu_3 \\mu_1}^{\\omega(P_2)} \\chi_{\\omega(P_2)}(q_b)$. This product form, involving characters from two different 'regions' (a and b) with potentially different moduli $q_a$ and $q_b$, is highly unusual for a partition function associated with a single, connected worldsheet geometry or a single interaction space. Standard partition functions are typically sums (traces) over states in a single channel. This form resembles a product of disconnected amplitudes, making the subsequent modular invariance condition (Eq. 3.18) and its role in constraining S-transformation coefficients difficult to interpret within standard CFT frameworks."
      },
      {
        "Problem": "Restrictive Applicability Condition $n_{\\mu_3\\mu_1}^{\\omega(P_2)}=n_{\\mu_3\\mu_2}^{\\omega(P_1)}=N_{P_1P_2}^{P_3}$",
        "Location": "Section 3.1.2, Equation (3.8)",
        "Explanation": "The entire framework, particularly the isomorphism $V_{P_1 P_2}^{P_3} \\cong V_{\\mu_1 \\mu_2}^{\\mu_3}$ and the equality of dimensions of the total interaction spaces (Eq. 3.13), hinges on the condition $n_{\\mu_3\\mu_1}^{\\omega(P_2)}=n_{\\mu_3\\mu_2}^{\\omega(P_1)}=N_{P_1P_2}^{P_3}$ (where $P_i = x(\\mu_i)$). This is stated as a condition for CFTs to be 'applicable'. While this relation is known for diagonal RCFTs (often as a consequence of Cardy's condition), its general validity for broader classes of CFTs (e.g., non-diagonal, non-rational CFTs like Liouville theory, which is mentioned as a future direction) is not established or justified in the paper. If this condition is not widely met, the proposed S-transformation's scope is severely limited, potentially to cases where such closed-open channel equalities are already understood, thereby reducing the novelty and general applicability of the definition."
      },
      {
        "Problem": "Disconnect Between Geometric Motivation and Algebraic Definition of S-Transformation",
        "Location": "Section 2 (e.g., 2.1.3, 2.2.3) versus Section 3.2 (Equation 3.14)",
        "Explanation": "Section 2 argues that changing the time evolution vector field by a factor of $i$ (e.g., $f(z)$ to $if(z)$) acts as a 'global S-transformation' because it locally transforms modular parameters $\\tau_j \\to -1/\\tau_j$ in decomposed ring domains of $C_{0,0,\\tilde{3}}$. However, the main definition of the S-transformation in Section 3.2 is an algebraic linear mapping from closed sector linear spaces (assigned to $C_{0,3,\\tilde{0}}$) to open sector linear spaces (assigned to $C_{0,0,\\tilde{3}}$). The paper does not adequately establish a clear and rigorous connection showing how the geometric operation of 'rotating time' on a surface (which, if an S-transformation, would typically act within a given sector) logically leads to or justifies this specific algebraic definition of S as a map *between* closed and open sector spaces. The geometric argument in Sec 2.1.3 is for $C_{0,0,\\tilde{3}}$ (a surface with boundaries), while the S-transformation of Sec 3.2 maps from a space associated with $C_{0,3,\\tilde{0}}$ (no boundaries) to one for $C_{0,0,\\tilde{3}}$."
      },
      {
        "Problem": "Insufficient Justification for 'Unconventional Open Sector Sewing'",
        "Location": "Section 3.4, particularly around Equations (3.22) and (3.24)",
        "Explanation": "The paper introduces an 'unconventional open sector sewing' based on the completeness of boundary states ($I = \\int d\\mu_i \\vert \\mu_i \\rangle \\langle \\mu_i \\vert$). It's stated that for this sewing, 'The directions of time evolution are parallel to the sewing boundaries.' This is atypical for sewing operations, which usually involve identifying boundaries transverse to the time evolution (i.e., forming a propagator). The physical and mathematical interpretation of sewing along boundaries parallel to time flow, and how it leads to the construction of linear spaces for more complex surfaces (e.g., $V_{\\mu_1\\mu_2}^{\\mu_4\\mu_5}$ in Eq. 3.24), is not sufficiently clear or justified. The subsequent generalizations and derivations, such as $n$ forming a matrix representation of the fusion algebra (Eq. 3.27, which relies on unproven assumptions as noted in the text), depend on the validity and interpretation of this sewing procedure."
      }
    ],
    "token_usage": {
      "input": 50119,
      "thinking": 6700,
      "output": 1661
    }
  },
  {
    "entry_id": 242,
    "retraction_id": "2302.04323v3",
    "paper_id": "2302.04323v2",
    "retraction_comment": "The first statement on page 9 is not necessarily true. Roughly speaking, the problem is that the indices \"i_s\" and \"r\" are competing with each other and therefore what I believed to be immediate, as happens naturally in the case of a single index, and as can be seen in the proof of Theorem 6.7 of the FHHMZ reference, is in fact not immediate in the situation where double indices are involved",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of suppression 1-unconditionality for the spreading model $(\\mathfrak{s}_k)$ is flawed.",
        "Location": "Pages 7-9, specifically the argument from Eq (3.9) to the end of the unconditionality proof.",
        "Explanation": "The main theorem's proof relies on constructing a sequence $(\\vartheta_k)$ in $[X]$ and then showing its spreading model $(\\mathfrak{s}_k)$ is suppression 1-unconditional. This unconditionality is crucial for deducing that $(\\mathfrak{s}_k)$ is equivalent to the standard $\\ell_1$ basis. The proof of unconditionality (pages 7-9) considers representatives $y^i_s = \\frac{1}{2}(x_{n_{i+1}} + x_{n_{i+2k_s}})$. The argument requires selecting indices $\\tilde{s}_j$ such that for a fixed functional $f$ and a fixed large $i_0 = \\kappa_i^{s^{|\\Lambda|}}$, the terms $f(y^{i_0}_{\\tilde{s}_j})$ are arbitrarily small. However, for a fixed $i_0$, the sequence $(y^{i_0}_s)_s$ converges weakly to $\\frac{1}{2}x_{n_{i_0+1}}$ as $s \\to \\infty$. Since $(x_n)$ is a semi-normalized sequence, $x_{n_{i_0+1}}$ is generally not zero. Thus, $f(y^{i_0}_s)$ converges to $\\frac{1}{2}f(x_{n_{i_0+1}})$, which is not necessarily small for the chosen $f$ (norming functional for a sum of other terms). The argument on page 8 (middle paragraph, 'We now observe that...') proves a property for $y^i_s$ where $i$ varies and tends to infinity ($i > \\tilde{s}_2$), for which $y^i_{\\tilde{s}_2} \\to 0$ weakly. This is not the regime used on page 9, where $i$ is fixed ($i_0 = \\kappa_i^{s^{|\\Lambda|}}$) and $s$ varies. The failure to establish unconditionality means the subsequent claim that $(\\mathfrak{s}_k)$ is equivalent to the $\\ell_1$ basis (page 9, bottom) is unsupported. This invalidates the Main Theorem, and consequently, its main applications, including Theorem 3.5 (super-reflexive spaces have FPP)."
      }
    ],
    "token_usage": {
      "input": 22298,
      "thinking": 18894,
      "output": 585
    }
  },
  {
    "entry_id": 243,
    "retraction_id": "1911.03748v2",
    "paper_id": "1911.03748v1",
    "retraction_comment": "Unfortunately, our proof contains a serious flaw. Specifically, Lemma 5.3 does not prove the assertion it claims to prove and this collapses the entire argument. We thank [REDACTED-NAME] for pointing out the flaw, and apologize to the community for posting an eventually incorrect proof",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of Poincare-type inequality in junta approximation argument.",
        "Location": "Section 4, Proof of Proposition 4.5",
        "Explanation": "The proof of Proposition 4.5 states: $\\norm{f''}_2^2 \\leq 3^d\\norm{T_{1/\\sqrt{3}} f''}_2^2 \\leq 3^d \\sum_{i \\notin T} \\norm{D_i T_{1/\\sqrt{3}} f''}_2^2$. The second inequality, $\\norm{T_{1/\\sqrt{3}} f''}_2^2 \\leq \\sum_{i \\notin T} \\norm{D_i T_{1/\\sqrt{3}} f''}_2^2$, is incorrect. The function $f''$ (and thus $T_{1/\\sqrt{3}} f''$) can depend on variables $i \\in T$ (e.g., if a Fourier coefficient $\\hat{f}(S)$ is non-zero for $S$ such that $S \\not\\subseteq T$ but $S \\cap T \\neq \\emptyset$). The Poincare inequality (or related sum-of-influences bounds) requires summing over all variables on which the function depends, i.e., $\\sum_{i \\in [n]} \\norm{D_i T_{1/\\sqrt{3}} f''}_2^2$. Restricting the sum to $i \\notin T$ is not justified and invalidates the subsequent step that uses $\\max_{i \\notin T} I_i(f)$ to achieve the desired $\\sqrt{\\delta}$ factor. This proposition is crucial for removing the $\\log(n)$ dependency in the decision tree depth claimed in Theorem 1.1(2)."
      },
      {
        "Problem": "Flawed argument in establishing the existence of an influential coalition due to misapplication of expectation properties.",
        "Location": "Section 5.2, Proof of Lemma 5.3",
        "Explanation": "The proof of Lemma 5.3 aims to show that for $g(y) = f(x_J, 0_{S\\sm J}, y_{\\bar{S}}) = \\mathbb{E}_{z_{S \\sm J}}[f(x_J, z_{S \\sm J}, y_{\\bar{S}})]$, one has $\\mathbb{E}_{y_{\\bar{S}}}[g(y)^2] \\geq \\mathbb{E}[f^2]-\\epsilon$. The proof correctly establishes $h_S(x_J, 0_{S \\sm J}) \\geq \\mathbb{E}[f^2]-\\epsilon$, where $h_S(x_J, 0_{S \\sm J}) = \\mathbb{E}_{z_{S \\sm J}} [ \\mathbb{E}_{y_{\\bar{S}}} [ f(x_J, z_{S \\sm J}, y_{\\bar{S}})^2 ] ]$. However, $\\mathbb{E}_{y_{\\bar{S}}}[g(y)^2] = \\mathbb{E}_{y_{\\bar{S}}}[ (\\mathbb{E}_{z_{S \\sm J}}[f(x_J, z_{S \\sm J}, y_{\\bar{S}})])^2 ]$. By Jensen's inequality, $(\\mathbb{E}_z[X_z])^2 \\leq \\mathbb{E}_z[X_z^2]$, which implies $\\mathbb{E}_{y_{\\bar{S}}}[g(y)^2] \\leq h_S(x_J, 0_{S \\sm J})$. Thus, $h_S(x_J, 0_{S \\sm J})$ being large does not guarantee that $\\mathbb{E}_{y_{\\bar{S}}}[g(y)^2]$ is large as required. This lemma is a critical step in the iterative construction of influential coalitions (Proposition 5.4) and subsequently the decision tree (Lemma 6.1)."
      },
      {
        "Problem": "The iterative construction of an influential coalition in Proposition 5.4 is unsound.",
        "Location": "Section 5.2, Proof of Proposition 5.4",
        "Explanation": "Proposition 5.4 relies on iterative applications of Lemma 5.3. Specifically, it requires that $\\mathbb{E}[f_{i+1}^2] \\geq \\mathbb{E}[f_i]^2 - \\text{small_error}$, where $f_{i+1}$ is an averaged version of $f_i$. As Lemma 5.3's proof does not correctly establish such a property for the squared averaged function (see Problem 2), the argument for Proposition 5.4 is invalid. This proposition is essential for the main decision tree construction argument in Lemma 6.1."
      },
      {
        "Problem": "The main conclusions of the paper (Theorem 1.1) are not adequately supported.",
        "Location": "Section 6, Proofs of Theorem 1.1(1) and 1.1(2)",
        "Explanation": "Theorem 1.1(2), which claims that any bounded low-degree function can be approximated by a decision tree of depth $\\mathrm{poly}(d, 1/\\epsilon)$, relies on Proposition 4.5 (for $n$-independence) and Lemma 6.1 (for the core tree construction). Lemma 6.1 itself relies on Proposition 5.4. Due to the identified critical issues in Proposition 4.5 (Problem 1) and Lemma 5.3/Proposition 5.4 (Problems 2 and 3), the proof of Theorem 1.1(2) is not sound. Since Theorem 1.1(1) (the Aaronson-Ambainis conjecture) is derived from Theorem 1.1(2), its proof is also invalidated."
      }
    ],
    "token_usage": {
      "input": 25792,
      "thinking": 24481,
      "output": 1330
    }
  },
  {
    "entry_id": 244,
    "retraction_id": "2212.12846v2",
    "paper_id": "2212.12846v1",
    "retraction_comment": "We found an error in Lemma 3.5.--which is used in the subsequent analysis to establish the rate of convergence. Since the error is not fixable, we would like to withdraw the article",
    "checker_model": "Gemini 2.5 Pro",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent statement and application of Lemma 3.5, which estimates $\\mathbb{E}[\\Delta x \\sum_{j}\\int_0^t |D_+u_j(r)|^2dr]$.",
        "Location": "Lemma 3.5 (page 10), and its applications in Section 4 (pages 15-17 for terms $\\mathfrak{J}_{1}, \\mathfrak{J}_{2}, \\mathfrak{J}_{3}, \\Hat{\\mathcal{J}}_{4,1}$ and page 21 for term $\\mathcal{J}_{9,1}$).",
        "Explanation": "1. The statement of Lemma 3.5, $\\mathbb{E}[\\Delta x \\sum_{j}\\int_0^t |D_+u_j(r)|^2dr ] \\leq C\\frac{\\Delta x}{\\epsilon}$, appears to have an extraneous $\\Delta x$ factor on the right-hand side. The derivation suggests the constant $C$ on the RHS should depend on initial data $u_0$ (including the size of its support $L_{supp}$ and $\\|u_0\\|_{L^\\infty}$) but not on $\\Delta x$, leading to $\\mathbb{E}[\\Delta x \\sum_{j}\\int_0^t |D_+u_j(r)|^2dr ] \\leq \\frac{C_{u_0}}{\\epsilon}$.\n2. In Section 4, the estimates for error terms $\\mathfrak{J}_{1}, \\mathfrak{J}_{2}$ (page 15, e.g., $\\mathfrak{J}_{1} \\le C\\frac{(\\Delta y)^2}{\\delta\\epsilon}$) and $\\mathfrak{J}_{3}, \\Hat{\\mathcal{J}}_{4,1}$ (pages 15-16, e.g., $\\mathfrak{J}_{3} \\le C\\frac{(\\Delta y)^2}{\\delta\\xi\\epsilon}$) rely on the stated (incorrect) form of Lemma 3.5, effectively using $\\mathbb{E}[\\Delta y \\sum |D_+u_j|^2 ds] \\sim (\\Delta y)^2/\\epsilon$. If the corrected form of Lemma 3.5 (RHS $\\sim \\Delta y / \\epsilon$) were used, these error terms would be $C\\frac{\\Delta y}{\\delta\\epsilon}$ and $C\\frac{\\Delta y}{\\delta\\xi\\epsilon}$ respectively, which are of a lower order in $\\Delta y$.\n3. Conversely, the estimation of term $\\mathcal{J}_{9,1}$ (page 21, $\\mathcal{J}_{9,1} \\le C\\frac{\\Delta y}{\\xi}$) appears to use the correct form of Lemma 3.5 (i.e., $\\mathbb{E}[\\Delta y \\sum |D_+u_j|^2 ds] \\sim \\Delta y / \\epsilon$, since $\\frac{\\epsilon}{\\xi} \\cdot \\frac{\\Delta y}{\\epsilon} = \\frac{\\Delta y}{\\xi}$). This creates an internal inconsistency in how Lemma 3.5 is applied.\nWhile the final convergence rate of $(\\Delta x)^{1/7}$ might coincidentally remain the same after correcting these derivations (as other terms become dominant), the unsound derivation of several key error bounds constitutes a critical flaw in the argument's rigor."
      }
    ],
    "token_usage": {
      "input": 68719,
      "thinking": 20117,
      "output": 772
    }
  }
]