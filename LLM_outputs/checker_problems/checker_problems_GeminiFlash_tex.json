[
  {
    "entry_id": 0,
    "retraction_id": "2303.17613v10",
    "paper_id": "2303.17613v9",
    "retraction_comment": "The theoretical structure, in particular the existence of the Riemannian metric, was flawed and will be resubmitted after reconsideration",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent geometric framework regarding metric and distance.",
        "Location": "Sections 2.2, 2.4, 2.5, 2.6, 2.7, Appendix A",
        "Explanation": "The paper uses Riemannian geometry concepts like distance squared ($d^2$) and its gradient ($\nabla d^2$) as the basis for PGA optimization, deriving $\nabla_a d^2(a,b) = -2\\Log_a(b)$ in Appendix A. This relies on the manifold being Riemannian and $d$ being the Riemannian distance. The relation $\\Log_a(b) = a \\log(a^{-1}b)$ used for signatures holds for a left-invariant metric. However, the paper states that a bi-invariant metric doesn't exist for signature space and implies it works \"without using a metric\". This creates a fundamental inconsistency: the optimization minimizes a distance function whose existence and properties (like the gradient formula) are not clearly justified by a specified Riemannian metric compatible with the assumed Cartan-Schouten connection."
      },
      {
        "Problem": "Heuristic and potentially incorrect gradient projection for optimization.",
        "Location": "Section 3.3, Appendix C",
        "Explanation": "The gradient descent algorithm calculates gradients in the embedded Euclidean space $\\mathbb{R}^N$. To ensure updates stay within the Lie algebra $T_eG$, the paper projects the Euclidean gradient using $P=C^\\dagger C$, where $C$ is the covariance matrix of the *data's* log-signatures. Using a data-dependent matrix derived from the sample distribution as the projection operator onto the tangent space (Lie algebra) is not a standard or rigorously justified method for optimization on manifolds. The correct projection should be based on the geometric structure of the Lie algebra itself, not the specific data points. This heuristic projection may lead to incorrect gradient directions and convergence issues."
      },
      {
        "Problem": "Unclear justification for using $a \\log(a^{-1}b)$ as the Riemannian logarithm map.",
        "Location": "Appendix A",
        "Explanation": "Appendix A derives $\\Log_a(b) = a \\log(a^{-1}b)$ for signatures. This relation holds if the Riemannian metric is left-invariant. While the paper assumes the Cartan-Schouten connection, it does not explicitly state or justify that this connection is the Levi-Civita connection of a left-invariant Riemannian metric on the signature space. Without this justification, using $a \\log(a^{-1}b)$ as the Riemannian logarithm map $\\Log_a(b)$ (the initial velocity of the geodesic from $a$ to $b$ under the Riemannian metric) is not rigorously supported, undermining the gradient formula $\\nabla_a d^2(a,b) = -2\\Log_a(b)$ and the entire optimization setup."
      }
    ],
    "token_usage": {
      "input": 16422,
      "thinking": 3303,
      "output": 633
    }
  },
  {
    "entry_id": 1,
    "retraction_id": "2103.13332v3",
    "paper_id": "2103.13332v1",
    "retraction_comment": "The notion of stabilizing ordinal is not well-defined, i.e., Definition 14 is flawed. As a consequence the results presented in the paper are either incorrect or remain unproved",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed example for non-monotonicity of Kripke jump",
        "Location": "Example 1, Lemma 1(i) proof",
        "Explanation": "The example provided to demonstrate the non-monotonicity of the semantics appears incorrect. Based on the semantics provided, the sentence $\\sbel Pt$ seems to be true in world $w$ under both interpretation functions $I$ and $J$, despite $I \\leq J$. Similarly, the truth-teller example in the proof of Lemma 1(i) also seems to result in $\\sbel\\tau$ being true under both evaluation functions $f$ and $j$. While the semantics is indeed non-monotone, the provided examples fail to demonstrate this."
      },
      {
        "Problem": "Flawed example for non-increasing sequence of Kripke jump iterations",
        "Location": "Lemma 1(ii) proof",
        "Explanation": "The example provided to show that iterative applications of $\\K$ over the minimal evaluation function $g$ do not necessarily lead to an increasing sequence appears incorrect for similar reasons as the non-monotonicity example. The calculation for $\\sbel\\sigma$ being in $[\\K(g)](w)$ but not in $[\\K(\\K(g))](w)$ seems to contain an error based on the semantics of $\\sbel$. While the sequence $\\K^\\alpha(g)$ is indeed not guaranteed to be increasing, the provided example does not correctly demonstrate this."
      },
      {
        "Problem": "Overstated scope of generated fixed points",
        "Location": "Proposition 1(iv), Lemma 4",
        "Explanation": "The paper claims that the set of all fixed points ${\\sf Fix}_M$ is equal to the set of fixed points generated by applying $\\K^{\\xif}$ to prefixed points (or postfixed points). However, the definition of prefixed/postfixed points includes a strong condition (Definition 9(i), 10(i)) that requires sentences with undefined stabilizing ordinals (relative to the initial valuation $f$ or $\\overline{f}$) to behave in a specific way throughout the iteration. This condition is not guaranteed for arbitrary fixed points, suggesting that not all fixed points are necessarily prefixed or postfixed points, and thus not all fixed points are generated by this method. The inclusion $\\{\\K^{\\xif}(f)\\,|\\,f\\in{\\sf Prefix}_M\\} \\subseteq {\\sf Fix}_M$ is correct, but the equality is likely false."
      },
      {
        "Problem": "Unusual definition of Stabilizing Ordinal",
        "Location": "Definition 8",
        "Explanation": "The definition of the stabilizing ordinal $\\rho_{f(w)}(\\varphi)$ assigns ordinal 0 to any sentence in the base set ${\\sf Base}_w = f(w) \\cup f^-(w) \\cup \\dots$, regardless of its internal structure or potential self-referential nature. While this definition appears to function correctly in the subsequent proofs (Lemmas A.0, A.2) for the specific case of $f=g$, its general philosophical motivation and behavior for arbitrary $f$ (especially fixed points) is less clear and deviates from standard definitions of grounding or stratification ordinals which are typically defined purely structurally or based on the iteration process itself, not the initial valuation's content. This might require further justification or clarification."
      },
      {
        "Problem": "Lack of clarity on the nature and bound of the ordinal $\\xif$",
        "Location": "Definition 8, Lemma 7",
        "Explanation": "The ordinal $\\xif$ is defined as the supremum of all defined stabilizing ordinals $\\rho_f(\\varphi)$ for all evaluation functions $f$ and all sentences $\\varphi$. While Lemma 7 states that $\\xif$ exists and is countable if the language is countable, the set of evaluation functions $\\mathsf{Val}_F$ is uncountable if the domain or set of worlds is infinite. The supremum of ordinals assigned based on potentially uncountable initial valuations might be larger than $\\omega_1$. The proof sketch for Lemma 7 is very brief and does not fully justify that $\\xif$ is countable or bounded by $\\omega_1$ in the general case of infinite frames/domains. This impacts the understanding of the iteration length $\\K^{\\xif}$."
      }
    ],
    "token_usage": {
      "input": 29276,
      "thinking": 21708,
      "output": 976
    }
  },
  {
    "entry_id": 2,
    "retraction_id": "1602.07129v2",
    "paper_id": "1602.07129v1",
    "retraction_comment": "this paper has been withdrawn due to minor error in the calculation of dielectric constant",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of TEM-ED data regarding structural disorder",
        "Location": "Page 4, Results and Discussion, Figure 2(b)",
        "Explanation": "The text states that the 'Absence of the superlattice reflection at [1/2,1/2,1/2] in the SAD confirms the antisite disorder'. However, Figure 2(b) clearly shows a spot at the [1/2,1/2,1/2] position (encircled), which is indicative of ordering, not disorder. This contradicts the conclusion about the disordered Pm-3m structure based on TEM."
      },
      {
        "Problem": "Incorrect interpretation of AC magnetic susceptibility data regarding spin-glass behavior",
        "Location": "Page 5, Results and Discussion, Figure 3(b)",
        "Explanation": "The authors claim a 'clear absence of frequency dispersion' in the AC susceptibility data (Fig 3b) to discard spin-glass behavior. However, the peak position appears to shift slightly to higher temperatures with increasing frequency (e.g., comparing 0.3Hz and 966Hz curves), which is a characteristic signature of spin-glass or cluster-glass systems."
      },
      {
        "Problem": "Flawed or inconsistently described specific heat analysis and magnetic entropy calculation",
        "Location": "Page 5, Results and Discussion, Figure 4(a), Figure 4(b), Equations (1), (2), (3)",
        "Explanation": "The method for separating the magnetic contribution (Cmag) from the lattice contribution (Clatt) by fitting a polynomial (Eq 1) to Cp/T vs T² data in the 20-40K range is non-standard and likely inaccurate for determining Clatt up to 40K. The resulting magnetic entropy change (Smag = 0.5 J/mole-K) is significantly lower than the theoretical value (11.5 J/mole-K), leading to interpretations about suppressed moments. While a Debye fit is mentioned yielding a value closer to theoretical, the text states this fit is unphysical above 50K, creating confusion about which analysis supports the conclusions. The overall specific heat analysis and Smag calculation are questionable and impact the interpretation of the magnetic transition."
      }
    ],
    "token_usage": {
      "input": 4252,
      "thinking": 3812,
      "output": 507
    }
  },
  {
    "entry_id": 3,
    "retraction_id": "2006.00175v4",
    "paper_id": "2006.00175v3",
    "retraction_comment": "In eq 38, misses a d^2 phi term, breaking down the results of the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound definition of quantum symmetry based on path integral of field equations.",
        "Location": "Section I, specifically the argument starting 'To see this, once again make $\\epsilon$ a function of x...'.",
        "Explanation": "The central argument that an action change of the form $\\int d^4 x \\epsilon f \\frac{dL}{d\\psi}$ implies quantum symmetry is based on the incorrect assumption that the path integral of $e^{-iS/\\hbar} \\times (\\text{something proportional to field equations})$ is zero. The Euler-Lagrange equations $\\frac{\\delta L}{\\delta\\psi}=0$ hold on shell, not for arbitrary field configurations integrated over in the path integral measure."
      },
      {
        "Problem": "Incorrect derivation of Ward identities and symmetry generators.",
        "Location": "Section IB.",
        "Explanation": "The derivations of the Ward identities (Eq. 10) and the proposed symmetry generators $Q'(t)$ are based on the flawed premise from Section I regarding the path integral of $f \\frac{dL}{d\\psi}$. The standard derivations require the action to be invariant up to a total derivative under the transformation with a spacetime-dependent parameter $\\epsilon(x)$, which is not the case assumed here."
      },
      {
        "Problem": "Derived conditions on potential terms and conclusions about theory properties are unfounded.",
        "Location": "Sections II, IV, VI (e.g., Eq. 15, Eq. 26, Eq. 34 and subsequent text).",
        "Explanation": "The specific forms derived for the potential terms ($W_1, W_2$) and the conclusions about the properties of the resulting theories (e.g., non-holomorphic $W_2$, negative vacuum energy) are direct consequences of requiring the action change $\\delta S$ to fit the form assumed in the flawed Section I argument. Since the underlying mechanism for quantum symmetry is unsound, these derived properties are not supported."
      }
    ],
    "token_usage": {
      "input": 20324,
      "thinking": 3188,
      "output": 449
    }
  },
  {
    "entry_id": 4,
    "retraction_id": "2108.05829v5",
    "paper_id": "2108.05829v4",
    "retraction_comment": "There is a mistake in the proof. The second term of the last equation in Lemma 2.2 does not have the desired asymptotic behavior. I am grateful with [REDACTED-NAME] for pointing out this mistake",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of the pushforward vector field in Lemma 2.2.",
        "Location": "Lemma 2.2, Proof, first paragraph of 'Construcción del campo local'",
        "Explanation": "The pushforward of the vector field $\tilde{V}_p = \\sum w_i \\partial_{w_i}$ under the blow-up map $\\sigma$ is not given by the expression $\\sum (w_i \\circ \\sigma^{-1}) \\partial_{(w_i \\circ \\sigma^{-1})}$. The latter represents a vector field in terms of pullback coordinates, but it is not the definition of the pushforward. This fundamental error invalidates the subsequent analysis of the vector field $V_p$ on $M$."
      },
      {
        "Problem": "Flawed calculation of the metric contraction $\\langle v, \\nabla_v V \\rangle$ in Lemma 2.2.",
        "Location": "Lemma 2.2, Proof, second paragraph of 'Construcción del campo local'",
        "Explanation": "The calculation of $\\langle v, \\nabla_v V_p \\rangle$ relies on the incorrect expression for $V_p$ and assumes properties of the metric and coordinates that are not generally true. The coordinates $w'_i = w_i \\circ \\sigma^{-1}$ are not linear coordinates on $M$, and the pullback metric is generally singular at $x_0$. The step $g_{ab}\\,v^{a}\\,v^{c}\\,\\partial_c V_p^{b} = g_{ab}\\,v^{a}\\,v^{b}$ is incorrect as it assumes $\\partial_c V_p^b = \\delta_c^b$, which is not implied by the form of $V_p$ in non-linear coordinates. This invalidates the crucial property $\\langle v, \\nabla_v V \\rangle = (1+o(1))\\|v\\|^2$ near $x_0$."
      },
      {
        "Problem": "Unjustified claim about the extension and boundedness of the vector field $V$.",
        "Location": "Lemma 2.2, Proof, third paragraph of 'Construcción del campo local' and first paragraph of 'Construcción del campo global'",
        "Explanation": "The claim that the pushforward field $V_p$ extends continuously to $x_0$ as the zero vector is not justified by the construction. The pushforward of a vector field on $\\tilde{M}$ is generally not well-behaved on $M$ near the exceptional divisor. Consequently, the boundedness of the global field $V$ on the compact set $\\overline{W} \\cap [U \\le E]$ (used in the proof of the conjecture) is not guaranteed, especially if this set includes points where $V$ is not defined or is unbounded."
      },
      {
        "Problem": "The core inequality in the proof of the conjecture relies on a flawed result from Lemma 2.2.",
        "Location": "Proof of the conjecture, second paragraph",
        "Explanation": "The inequality $\\langle \\dot{\\gamma}, \\nabla_{\\dot{\\gamma}}V \\rangle \\ge 0$, which is essential for showing that $\\dot{F}$ is bounded below by a positive constant, directly depends on the property $\\langle v, \\nabla_v V \\rangle \\ge 0$ for $v = \\dot{\\gamma}$. This property is derived from the $(1+o(1))\\|v\\|^2$ result in Lemma 2.2, which is based on incorrect calculations and assumptions about the vector field $V$. Without this inequality, the contradiction $F(t) \\to \\infty$ cannot be established."
      }
    ],
    "token_usage": {
      "input": 7913,
      "thinking": 4611,
      "output": 833
    }
  },
  {
    "entry_id": 5,
    "retraction_id": "2403.19848v2",
    "paper_id": "2403.19848v1",
    "retraction_comment": "We're withdrawing our paper from arXiv due to a critical error in our review methodology, which excluded key studies on sustainable road freight transport. This oversight could mislead the scientific community. We plan to correct this, ensuring comprehensive study inclusion, and will resubmit our paper for a more accurate review",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of a clearly defined systematic review methodology",
        "Location": "Section 2. Methodology",
        "Explanation": "The paper states it uses a 'systematic review methodology' but fails to provide essential details such as the search strategy, databases used, inclusion/exclusion criteria for selecting studies, or the process for screening and selecting relevant literature. This lack of methodological rigor makes the review's findings potentially incomplete and subject to selection bias."
      },
      {
        "Problem": "Insufficient analysis and synthesis of the reviewed literature",
        "Location": "Section 2. Methodology, Section 3. Results and discussion, Table 1",
        "Explanation": "The paper does not adequately describe how the selected studies were analyzed or synthesized to arrive at the conclusions. Table 1 provides a basic summary, but the discussion section primarily lists examples without explaining the analytical process used to identify key themes, compare findings across studies, or assess the collective evidence base."
      },
      {
        "Problem": "Unclear description of data handling and analysis from literature",
        "Location": "Page 1 (Abstract), Page 3 (Introduction), Page 4 (Methodology)",
        "Explanation": "The paper contains vague and confusing statements about using 'the same data presented by the literature' and attempting to 'visualize the study of the available data.' This suggests a potential misunderstanding of how to analyze and synthesize findings from existing research papers in a literature review context."
      },
      {
        "Problem": "Potential for selection bias due to undefined scope and criteria",
        "Location": "Section 2. Methodology, Table 1",
        "Explanation": "Without clear inclusion/exclusion criteria and a defined search scope (beyond 'indifferent dates'), it is impossible to determine if the studies included in the review, particularly those listed in Table 1, represent the breadth of relevant literature on sustainable road freight transport. This raises concerns about potential selection bias influencing the findings."
      },
      {
        "Problem": "Weak link between presented literature and broad conclusions",
        "Location": "Section 3. Results and discussion, Section 4. Conclusion",
        "Explanation": "Due to the lack of detailed analysis and synthesis, the broad conclusions drawn about the state of research, the relative development of different sustainability dimensions, and future research directions appear not to be strongly supported by a rigorous examination of the specific findings, methodologies, or limitations of the individual studies reviewed."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 2183,
      "output": 534
    }
  },
  {
    "entry_id": 6,
    "retraction_id": "2210.14117v3",
    "paper_id": "2210.14117v2",
    "retraction_comment": "Error in formulation of Bronold-Fehske model. The plots shown are actually in terms of E' + chi, shifted incorrectly by a factor of the electron affinity. The apparent perfect reflection region is therefore nonphysical",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified use of material parameter C for Boron Nitride",
        "Location": "Section II.A, Eq. 6, Fig. 2",
        "Explanation": "The fitting parameter C, representing surface disorder in the Bronold-Fehske model, is taken as C=2 based on experimental data for Magnesium Oxide (MgO) and applied to Boron Nitride (BN). C is a material-dependent parameter. Using a value fitted for MgO for BN leads to an incorrect calculation of the reflection function for BN, directly impacting the calculated electron gain and the conclusion about BN forming a space-charge limited (SCL) sheath."
      },
      {
        "Problem": "Lack of steady state due to simulation artifact",
        "Location": "Section III, Fig. 7",
        "Explanation": "The paper acknowledges that collision-driven cooling, caused by the source term adding particles at initial temperature while the plasma cools from wall losses, prevents the simulation from reaching a steady state. The electron gain γ is shown to increase over time. Conclusions about the sheath type (SCL vs monotonic) are drawn from a transient state at a specific time snapshot, not a stable equilibrium, making the conclusions about the material's effect on the steady-state sheath type potentially unsound."
      },
      {
        "Problem": "Arbitrary spatial profile for collision frequency",
        "Location": "Section II.C, Eq. 14, Fig. 4",
        "Explanation": "An artificial sigmoid function with unphysical parameters is used for the spatially-varying collision frequency profile. While intended to mimic a larger system (collisional presheath, collisionless sheath), the specific arbitrary shape and parameters are not physically derived and could introduce artificial gradients or effects that influence the sheath structure and particle distributions, potentially affecting the comparison between materials."
      },
      {
        "Problem": "Neglect of critical secondary electron emission mechanisms",
        "Location": "Section III, Limitations paragraph",
        "Explanation": "The model only includes elastic reflection. It neglects true secondary electron emission (SEE), rediffusion, and ion impact SEE. The results show significant electron acceleration towards the wall in the SCL case. These accelerated electrons would likely cause substantial true SEE and rediffusion, which are energy-dependent processes. These neglected mechanisms could significantly increase the total electron gain γ, potentially pushing it above 1 and leading to an inverse sheath, thus invalidating the conclusion that BN forms an SCL sheath."
      },
      {
        "Problem": "Inconsistent symmetry assumption",
        "Location": "Section II.B, Problem setup description",
        "Explanation": "A perfect reflection boundary condition is used on the left side, assuming perfect symmetry of the full domain. However, the source term is applied asymmetrically near this boundary (0 ≤ x ≤ Lsrc), violating the symmetry assumption. This inconsistency could affect the presheath profile near the left boundary and its interaction with the sheath."
      }
    ],
    "token_usage": {
      "input": 8838,
      "thinking": 3533,
      "output": 644
    }
  },
  {
    "entry_id": 7,
    "retraction_id": "1902.09447v2",
    "paper_id": "1902.09447v1",
    "retraction_comment": "We have to change the simulations section since the authors of the RANA method do not agree that we did fair comparisons with their method",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed and Underspecified Initialization Matrix Construction",
        "Location": "Algorithm 2, Line 9",
        "Explanation": "Algorithm 2 constructs a matrix X_0^(t) by setting its diagonals (diag(X_0^(t), ell)) to independently computed vectors x_ell^(t). A matrix is not uniquely determined by its diagonals in general, and there is no guarantee that the resulting matrix will be Hermitian, positive semidefinite, or rank-1, as required for it to represent w^(t)w^(t)H. The method for constructing this matrix from potentially inconsistent diagonal vectors is not specified, making this core step of the initialization procedure mathematically unsound."
      },
      {
        "Problem": "Theoretical Convergence Proof Issues with Smoothing Parameter",
        "Location": "Theorem 1, Lemma 1 (Proof Appendix C)",
        "Explanation": "The proof of the Lipschitz property (Lemma 1, part 3) for the gradient of the smoothed objective function yields a Lipschitz constant (U, derived from r_k,p and s_k,p) that depends inversely on powers of the smoothing parameter mu (e.g., 1/mu^2 in Eq. 28). As the algorithm drives mu -> 0 (as claimed by Theorem 1), this Lipschitz constant becomes unbounded. Standard convergence guarantees for stochastic gradient descent rely on a bounded Lipschitz constant, suggesting the proof of Theorem 1 may not hold as mu approaches zero."
      },
      {
        "Problem": "Potential Division by Zero in Gradient Analysis",
        "Location": "Eq. 6, Eq. 7, Lemma 1 (Proof Appendix C)",
        "Explanation": "The gradient calculation (Eq. 6, 7) involves terms divided by phi_mu(|f_k^H g_p(z)|). While Lemma 2 claims |f_k^H g_p(z)| > 0 for almost all z, the algorithm might encounter points where this term is zero. Although phi_mu(0) = mu > 0 for mu > 0, the analysis in Lemma 1 (parts 3 and 4) involves terms like 1/mu^2 and 1/mu derived from the derivative of phi_mu, which become problematic as mu -> 0. The proof does not adequately address the behavior of the gradient and its properties as mu approaches zero, especially near points where |f_k^H g_p(z)| is small or zero."
      },
      {
        "Problem": "Limited Theoretical Scope (L=1 only)",
        "Location": "Theorem 1",
        "Explanation": "The main theoretical result (Theorem 1) is explicitly stated and proven only for the case where the delay step L=1. The paper presents numerical results and an initialization algorithm for L>1, suggesting the method is applicable and performs well in these cases, but lacks any theoretical justification for L>1. This leaves a significant gap between the theoretical analysis and the empirical evaluation presented."
      }
    ],
    "token_usage": {
      "input": 48956,
      "thinking": 4414,
      "output": 661
    }
  },
  {
    "entry_id": 8,
    "retraction_id": "1610.03889v2",
    "paper_id": "1610.03889v1",
    "retraction_comment": "There is a serious gap about the tangent space of the dimension 2 foliations induced by a linear pull-back. I do not know if the scheme is reduced and so it is possible that the dimension of the tangent space of this scheme is bigger than his topological dimension",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition of the Poisson structure is ill-posed.",
        "Location": "Section 1.3, definition of $\\Pi$",
        "Explanation": "The bivector field $\\Pi=\\dbyd{}{X_{n}}\\wedge Y$ is defined using the coordinate vector field $\\dbyd{}{X_n}$ on the ambient space $\\mathbb{C}^{n+1}$ and a vector field $Y$ on $\\mathbb{P}^{n-1}$. This construction does not generally yield a well-defined bivector field on the projective space $\\mathbb{P}^n$ as a section of $\\bigwedge^2 T\\mathbb{P}^n$. Standard definitions require bivector fields on $\\mathbb{P}^n$ to satisfy specific homogeneity and contraction conditions with the Euler vector field, which are not satisfied by this form of $\\Pi$. This fundamental issue invalidates the existence of the claimed Poisson structure on $\\mathbb{P}^n$."
      },
      {
        "Problem": "The claim about the tangent sheaf of the associated foliation is incorrect.",
        "Location": "Section 1.3, description of the foliation $\\mathcal{F}$",
        "Explanation": "The paper states that the tangent sheaf of the dimension 2 foliation $\\mathcal{F}$ induced by $\\Pi$ is $T\\mathcal{F}=\\cal{O}_{\\mathbb{P}^{n}}(-1)\\oplus\\cal{O}_{\\mathbb{P}^{n}}(1)$. For $n \\geq 1$, the space of global sections $H^0(\\mathbb{P}^n, T\\mathbb{P}^n(-1))$ is zero. This implies that $\\mathcal{O}_{\\mathbb{P}^{n}}(-1)$ cannot be the tangent sheaf of a non-zero rank 1 foliation on $\\mathbb{P}^n$. The subsequent argument relies on the foliation splitting into two rank 1 foliations with these tangent sheaves, which is impossible if one of the components must be the zero foliation. Furthermore, for a generic quadratic vector field $Y$ on $\\mathbb{P}^{n-1}$, the pullback foliation is not expected to have such a specific split tangent sheaf."
      },
      {
        "Problem": "The proof that Poisson deformations are necessarily foliation deformations is flawed.",
        "Location": "Proof of the Theorem \\ref{Thm:Pullbackcomponent}, Section 4",
        "Explanation": "The proof attempts to show that any bivector field $\\xi$ in the tangent space of Poisson structures at $\\Pi$ must satisfy $\\xi \\wedge \\Pi = 0$, which is the condition for $\\xi$ to be in the tangent space of foliations. This relies on showing that a component $\\alpha_0$ of $\\xi$ (in an affine chart) satisfies $\\alpha_0 \\wedge Y = 0$. The argument uses Proposition \\ref{Prop: kernel Delta} (a local result near a singularity) and claims that $\\alpha_0 \\wedge Y$ vanishes on an integral curve of the linearized vector field $Y$. This local vanishing on a single curve is then incorrectly extended to a global vanishing using a Zariski density argument. A single integral curve is not Zariski dense in $\\mathbb{P}^{n-1}$ for $n \\geq 4$. The local condition $[\\alpha_0, Y] \\wedge Y = 0$ does not imply $\\alpha_0 \\wedge Y = 0$ globally or even in a neighborhood, as shown by the non-zero kernel terms in Proposition \\ref{Prop: kernel Delta}."
      }
    ],
    "token_usage": {
      "input": 7740,
      "thinking": 15130,
      "output": 802
    }
  },
  {
    "entry_id": 9,
    "retraction_id": "1208.1540v2",
    "paper_id": "1208.1540v1",
    "retraction_comment": "This paper has been withdrawn because there is a gap in the construction of the canonical quadratic refinement on a mapping torus",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Divisibility requirement for the functorial lift on the boundary",
        "Location": "Section 3.3, Definition of relative lift",
        "Explanation": "The construction of the relative lift $\\check{\\lambda} = \\check{\\nu} - 2\\check{\\mu}$ requires the existence of a reduced differential cohomology class $\\check{\\mu}$ on the boundary $\\partial W$ such that $2\\check{\\mu} = \\check{\\nu}|_{\\partial W}$. This implies that the functorial lift $\\check{\\nu}$ must be divisible by 2 in $\\check{R}^{2\\ell+2}(\\partial W)$. While the Wu class $\\nu_2$ vanishes on $\\partial W$ (a $4\\ell+3$ manifold), implying $a(\\check{\\nu})|_{\\partial W}$ is 2-torsion and $\\omega(\\check{\\nu})|_{\\partial W}$ has 2-torsion periods, this does not guarantee that the differential lift $\\check{\\nu}|_{\\partial W}$ is divisible by 2 in reduced differential cohomology. This assumption is critical for the existence of the relative lifts used throughout the paper."
      },
      {
        "Problem": "Misapplication of Brumfiel-Morgan Theorem in Arf invariant calculation",
        "Location": "Section 4.4, Proof of Theorem 4.4",
        "Explanation": "The proof of the formula for the Arf invariant of $\\mathsf{Q}^c$ (Eq 4.7) relies on Theorem 2.6 (Brumfiel-Morgan Theorem 4.3). Theorem 2.6 involves an element $b \\in H^{2\\ell+2}_{\\rm tors}(\\partial W,\\mathbbm{Z})$ defined by $\\mathcal{Q}(z|_{\\partial W}) = L_{\\partial W}(z|_{\\partial W}, b)$ for $z \\in H^{2\\ell+2}_{\\rm tors}(W,\\mathbbm{Z})$. The proof claims $b=0$ because $\\mathsf{Q}^c(z)$ vanishes for $z$ a torsion class. However, $\\mathsf{Q}^c$ is defined on $F^\\ast/F$, where $F^\\ast$ is a subgroup of $H^{2\\ell+2}_{\\rm free}(W,\\mathbbm{Z})$. $\\mathsf{Q}^c$ is not defined for torsion classes $z \\in H^{2\\ell+2}_{\\rm tors}(W,\\mathbbm{Z})$. Therefore, the argument that $b=0$ is not justified, invalidating the derivation of Eq 4.7."
      },
      {
        "Problem": "Lack of rigorous justification for pairings on non-compact manifolds in compatibility proof",
        "Location": "Section 5.4, Proof of Lemma 5.4",
        "Explanation": "The proof of Lemma 5.4, which is crucial for Theorem 5.3 (compatibility of $Q^c$ and $\\mathcal{Q}^c$), relies on evaluating pairings of cocycles on a non-compact manifold $T$ obtained by gluing tubular neighborhoods. Specifically, it uses $\\langle \\hat{z} \\cup (\\hat{z} - \\hat{\\lambda}^c), [T] \\rangle$. While $\\hat{z}$ is compactly supported, $\\hat{\\lambda}^c$ is not. The pairing with the fundamental class $[T]$ for a non-compact manifold is not standardly defined in this context, and the claim that this pairing is an integer modulo 1 requires further rigorous justification. Furthermore, the property that $\\hat{\\lambda}^c$ represents an integral lift of the Wu class on $T$ relies on $T$ being in the category of manifolds with functorial lifts, which is unlikely for a non-compact manifold."
      },
      {
        "Problem": "Unjustified claim of topological invariance for $Q^c$",
        "Location": "Section 5.3, Discussion of topological invariant",
        "Explanation": "The definition of a functorial lift (Section 3.2) implies dependence on a differential structure (e.g., a Riemannian metric for spin manifolds). The canonical quadratic refinement $Q^c$ is constructed using a functorial differential lift $\\check{\\lambda}^c$. While the space of Riemannian metrics is contractible, the argument that $Q^c$ is a topological invariant requires showing that the construction of $Q^c$ is independent of the choice of metric, which is not explicitly proven. The argument given (contractibility of metric space) is insufficient without demonstrating this independence."
      },
      {
        "Problem": "Incorrect mathematical comparison with Witten's quadratic function",
        "Location": "Section 7.2, Relation to the original construction",
        "Explanation": "The mathematical comparison between the canonical quadratic refinement $Q^c$ and the quadratic function defined by Witten (Eq 7.3) appears incorrect. The formula for $Q^c(x)$ involves $\\int_W \\underline{z} \\wedge (\\underline{z} - \\underline{\\lambda}^c)$, while Witten's formula is given as $\\frac{1}{2} \\int_W \\underline{z} \\wedge (\\underline{\\nu} + \\underline{z})$. The claimed relation between these two expressions relies on $\\int_W \\underline{z} \\wedge \\underline{\\nu} \\in \\mathbbm{Z}$, which is not generally true for the forms involved. This impacts the interpretation of the results in the context of previous work on the M5-brane."
      }
    ],
    "token_usage": {
      "input": 37854,
      "thinking": 11284,
      "output": 1257
    }
  },
  {
    "entry_id": 10,
    "retraction_id": "1708.09822v3",
    "paper_id": "1708.09822v2",
    "retraction_comment": "incorrect example (Example 5)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 28483,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 11,
    "retraction_id": "2011.04373v3",
    "paper_id": "2011.04373v2",
    "retraction_comment": "paper withdrawn since dimension reduction might not hold in the parabolic setting",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of the Test function lemma (Lemma 2.3) to a space-time integral.",
        "Location": "Section 3, Equation (3.7)",
        "Explanation": "Lemma 2.3 provides an estimate for a spatial integral $\\int_{B_{\rho_2}} |v||\nabla \\eta|^s\\,dx$. Equation (3.7) applies this lemma to estimate a space-time integral $\\iint_{Q_i}(u-k_{i+1})^q_{+}|\nabla\\zeta_i|^q\\,dz$. The lemma's conclusion, which involves integrating over radial shells $S_r$, is not directly applicable to the time-dependent function $(u-k_{i+1})_+$ integrated over time, as performed in (3.7). This invalidates the subsequent estimates for the third term."
      },
      {
        "Problem": "Flawed application of H\"older's inequality or an unjustified intermediate step in estimating the third term.",
        "Location": "Section 3, Equation (3.10), step marked (a)",
        "Explanation": "The step marked (a) in Equation (3.10) attempts to bound an integral of a product raised to the power $\\delta$ by a product of integrals involving supremum over time for one factor and integration over time for the other, before applying H\"older w.r.t. the radial variable $dr$. This intermediate inequality, $\\int (\\int A B dt)^\\delta dr \\leq C \\int (\\sup_t A)^{1-\\delta} (\\int_t B dt)^\\delta dr$, is not a standard or justified application of H\"older's inequality or any other common inequality, rendering the subsequent steps in (3.10) and the estimate for the third term unsound."
      },
      {
        "Problem": "Missing condition for the application of the Sphere Embedding Lemma (Lemma 2.2).",
        "Location": "Section 3, derivation involving $q_0$ and Lemma 2.2 (around Equations (3.8)-(3.9))",
        "Explanation": "The Sphere Embedding Lemma (Lemma 2.2) is applied to $(u-k_{i+1})_+$ with exponent $q_0 = q_* \frac{N-1}{N-1-q_*}$. For this embedding to be valid, the exponent $q_*$ must be less than $N-1$. $q_* = q\frac{N-1}{N+1}$. The condition $q_* < N-1$ is equivalent to $q < N+1$. However, the main assumption (H1) only requires $q < p\frac{N+1}{N-1}$. If $p \\geq N+1$, then $p\frac{N+1}{N-1} \\geq N+1$, meaning $q$ could be greater than or equal to $N+1$ under the paper's assumptions. Thus, the application of Lemma 2.2 is not guaranteed to be valid for the full range of parameters claimed in the theorem."
      },
      {
        "Problem": "Unusual and potentially restrictive assumption on the solution (Hypothesis H5).",
        "Location": "Section 1, Hypothesis H5 (Hypothesis 2.2) and Section 3, Equation (3.10)",
        "Explanation": "Hypothesis H5 states that $\\sup_{-\theta<t<\theta}\\int_{B_{\rho}}|u|^2\\,dx\\geq \\int_{0}^{\rho}\\sup_{-\theta<t<\theta}\\int_{S_r}|u|^2\\,d\\mch^{N-1}\\,dr$. This inequality is unusual and appears to be the reverse of what might be expected from standard integration properties (e.g., Fubini's theorem and properties of supremum). It is not a standard property of weak solutions for this class of equations. Its necessity for the argument (specifically in Equation (3.10)) suggests it might be a strong, possibly unjustified or highly restrictive, assumption required to overcome difficulties in the proof, limiting the applicability of the main theorem to a potentially smaller class of solutions than standard weak solutions."
      }
    ],
    "token_usage": {
      "input": 20460,
      "thinking": 6567,
      "output": 922
    }
  },
  {
    "entry_id": 12,
    "retraction_id": "2401.02488v3",
    "paper_id": "2401.02488v2",
    "retraction_comment": "Lemma 3.4 on page 7 is incorrect. This is crucial to the argument. The problem that could not be fixed is if there are parts of hilden subgroup elements that contain parts of powers of the garside element",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unproven claim that the Garside element is in the Hilden subgroup.",
        "Location": "Lemma 3.1 proof, Section 5",
        "Explanation": "The proof of Lemma 3.1, which asserts the existence of a positive representative in every double coset, relies on the claim that the Garside element $\\Delta$ is in the Hilden subgroup $H_n$. This claim is not proven or adequately referenced, and its validity is essential for the subsequent arguments, including the existence of $\\gamma_0$ and the non-example in Section 5."
      },
      {
        "Problem": "Flawed argument for length additivity in Lemma 3.2.",
        "Location": "Lemma 3.2 proof",
        "Explanation": "Lemma 3.2 claims that if $A\\alpha B = P$ where $\\alpha, P$ are positive words with no $\\Delta$ in their Garside form, and $A, B \\in H_n$, then $Len(A\\alpha B) = Len(A) + Len(\\alpha) + Len(B) = Len(P)$. The argument that $A, B$ must be positive and that length is additive for braid words under concatenation is incorrect. This invalidates the use of length to bound the search space for $A, B$."
      },
      {
        "Problem": "Procedure for finding the minimal positive representative is not shown to terminate.",
        "Location": "Section 3.1, Proof of Theorem 2.5",
        "Explanation": "The procedure to find the minimal positive representative $\\gamma_0$ in a double coset relies on being able to decide in finite time if $A\\alpha B = P$ for given positive $\\alpha, P$ and some $A, B \\in H_n$. The proposed method for this decision problem (checking finitely many $A, B$ based on length) is based on the flawed Lemma 3.2. Without a valid method to bound the search for $A, B$, the termination of the procedure is not guaranteed, rendering the proof of the main theorem unsound."
      }
    ],
    "token_usage": {
      "input": 8347,
      "thinking": 4595,
      "output": 476
    }
  },
  {
    "entry_id": 13,
    "retraction_id": "1208.2556v8",
    "paper_id": "1208.2556v7",
    "retraction_comment": "This paper has been withdrawn by the author because (k+1)n<k(n+2) is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 4462,
      "thinking": 34132,
      "output": 1
    }
  },
  {
    "entry_id": 14,
    "retraction_id": "1905.08897v3",
    "paper_id": "1905.08897v2",
    "retraction_comment": "Although the quasi-nodal surface has been identified in our preprint, there is a tiny band gap (millivolt-level) in the non high symmetry k-line (e.g.,K1-K5). In this regard, the proposed bct-C40 should be a nodal net semimetal based on the strict definition of topological semimetal. We would like to withdraw this work to avoid misleading the readers from Arxiv",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect topological classification of bct-C40.",
        "Location": "Abstract, Introduction, and Conclusion of Ref [1] (as discussed throughout the Comment).",
        "Explanation": "The original paper [1] claims bct-C40 is a nodal-net semimetal. The comment demonstrates through re-calculations that the nodal structure forms surfaces in the Brillouin zone, classifying it as a nodal surface semimetal instead."
      },
      {
        "Problem": "Misrepresentation of the geometry of nodal lines.",
        "Location": "Fig. 3(c) in Ref [1], discussed on Page 1-2 of the Comment (Fig. 1b, 1c).",
        "Explanation": "The original paper [1] depicts straight lines connecting nodal points to form a 'boxed-asterisk' net. The comment shows that the actual nodal lines between key points (e.g., 0-1, 0-2) are wavy, not straight, invalidating the claimed geometry."
      },
      {
        "Problem": "Failure to identify all existing nodal points.",
        "Location": "Fig. 3(c) in Ref [1], discussed on Page 2-3 of the Comment (Fig. 1d, 1e).",
        "Explanation": "The original paper [1] only identified nodal points belonging to their proposed nodal net. The comment found additional Dirac nodal points (like Dg and others in Fig. 1e) that lie outside this proposed structure, indicating the nodal structure is more extensive or different than described."
      },
      {
        "Problem": "Incorrect description of the overall nodal structure in 3D momentum space.",
        "Location": "Fig. 3(c) in Ref [1], discussed on Page 3 of the Comment (Fig. 2).",
        "Explanation": "The original paper [1] concluded the nodal points form a network of lines. The comment's calculations in the full 3D BZ reveal that the nodal points actually form extended surfaces, which is the defining characteristic of a nodal surface semimetal."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 2235,
      "output": 476
    }
  },
  {
    "entry_id": 15,
    "retraction_id": "1712.07752v2",
    "paper_id": "1712.07752v1",
    "retraction_comment": "Based on the numerous reviews I have received, the figures illustrated in the paper are highly incorrect and vague. This might guide a novice reader towards a wrong direction and lead to improper understanding of the subject. Also, the paper covers a diverse range of topics but doesn't get into the details of any and hence the proposals remain pragmatically irrelevant",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Feasibility of UIRB-AI's Economic Power and Independence",
        "Location": "Section 3.3, Section 4.2, Figure 2",
        "Explanation": "The paper argues that the proposed UIRB-AI, under the UN, needs to be economically superior to its member states (specifically, richer than the richest country) to effectively govern and maintain peace. It proposes 'AI Tax' and 'Robot Tax' as revenue sources. However, it fails to provide a credible mechanism for how a UN body could realistically collect sufficient revenue from sovereign nations and powerful multinational corporations to achieve this level of economic superiority or enforce such a global tax system against potential non-compliance."
      },
      {
        "Problem": "Lack of Credible Enforcement Mechanism for Regulations",
        "Location": "Section 3.3, Section 5, Section 5.2",
        "Explanation": "The paper proposes that the UIRB-AI should regulate AI development, including potentially requiring registration of labs and approval for significant advancements before public release. Yet, it acknowledges the UN's current weakness in enforcing rules against member states ('any strong rules... can be easily overthrown by any single nation'). The paper does not detail how the UIRB-AI would overcome this fundamental challenge of sovereignty and enforcement, especially given the decentralized and rapidly evolving nature of AI technology."
      },
      {
        "Problem": "Undefined and Impractical Global Taxation Scheme",
        "Location": "Section 3.3",
        "Explanation": "The proposed 'AI Tax' aims to generate revenue by taxing organizations for job displacement caused by AI. The paper acknowledges hurdles like defining 'AI' for taxation and distinguishing job replacement from complementation but does not offer solutions. Implementing such a complex, global tax system across diverse legal, economic, and political landscapes, ensuring fairness, and preventing avoidance (e.g., relocation) presents massive, unaddressed practical challenges that undermine the feasibility of this core revenue generation plan."
      },
      {
        "Problem": "Unrealistic Assumption of Global Unanimity and Cooperation",
        "Location": "Section 3.2, Section 3.3, Section 4.1, Conclusion",
        "Explanation": "The paper's central argument for an 'unanimous international regulatory body' relies heavily on the assumption that nations and citizens will abandon nationalism and cooperate fully under the UN. While acknowledging current geopolitical competition and nationalism, the paper does not provide a credible or pragmatic path to achieving this necessary level of global unity and willingness to cede significant economic and regulatory sovereignty, making the proposed UIRB-AI structure appear highly idealistic and impractical in the current world order."
      },
      {
        "Problem": "Oversimplified Model of Governance Strength Based Solely on Economic Superiority",
        "Location": "Section 4.2, Figure 2",
        "Explanation": "The argument that the strength and stability of a union or federation is directly correlated with its economic superiority over its members (illustrated by comparing budgets) is a simplistic and unsound model. The power and stability of governance structures depend on a complex interplay of factors including legal frameworks, political institutions, shared identity, and distribution of powers, not solely on the central budget size relative to members. This weakens the justification for the proposed UIRB-AI's required economic structure."
      }
    ],
    "token_usage": {
      "input": 9028,
      "thinking": 2587,
      "output": 723
    }
  },
  {
    "entry_id": 16,
    "retraction_id": "2110.09901v3",
    "paper_id": "2110.09901v2",
    "retraction_comment": "It relies on maximizing the distance over an intersection of balls to a given point. The used algorithm for this however, is not able to solve the class of problem the SSP generates",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound geometric claim about the boundary of the ball intersection.",
        "Location": "Lemma 3.4a, Claim 2, Page 6",
        "Explanation": "The claim that a point on the boundary of the set $\tilde{Q}_{\rho}$ (the intersection of balls approximating the unit hypercube) that is also on the boundary of the ball $\bar{\\mathcal{B}}(\frac{1}{2} 1_{n \times 1}, \frac{\\sqrt{n}}{2})$ must be a corner of the unit hypercube is not generally true. The boundary of the intersection of balls can touch the boundary of the enclosing ball at points other than the vertices of the inscribed shape (the hypercube)."
      },
      {
        "Problem": "Incorrect application of Lemma A.1 (Lemma 3.1).",
        "Location": "Lemma 3.4a, Claim 3 Proof, Page 6",
        "Explanation": "The proof applies Lemma A.1 to a configuration of balls ($\bar{\\mathcal{B}}(C_s, r_s)$, $\bar{\\mathcal{B}}(\frac{1}{2} 1_{n \times 1}, \frac{\\sqrt{n}}{2})$, and $\bar{\\mathcal{B}}(C, \\|C - x_1\\|)$) whose centers are collinear and whose boundaries share points (like an RSSP solution $x_1$). However, the geometric setup and proof of Lemma A.1 require the shared boundary to be a sphere centered at the origin of the subspace orthogonal to the axis containing the centers, which is not the case for points like $x_1$ relative to the line through $C_s$, $\frac{1}{2} 1_{n \times 1}$, and $C$."
      },
      {
        "Problem": "Unjustified claim about maximizer properties.",
        "Location": "Lemma 3.4a, Claim 4 Proof, Page 6",
        "Explanation": "The proof claims that if $x^{\\star}_{\rho}$ is a maximizer of $\\|x-C\\|^2$ over $\\mathcal{Q}_{\rho}$, then it must satisfy $\\|C_s - x^{\\star}_{\rho}\\| = r_s$ and $\\|x^{\\star}_{\rho} - \frac{1}{2} 1_{n \times 1}\\| = \frac{\\sqrt{n}}{2}$. While a maximizer over an intersection of sets must lie on the boundary of the intersection (and thus on the boundary of at least one constituent set), it is not guaranteed to lie on the boundary of specific constituent sets like $\bar{\\mathcal{B}}(C_s, r_s)$ and $\bar{\\mathcal{B}}(\frac{1}{2} 1_{n \times 1}, \frac{\\sqrt{n}}{2})$. This assumption is critical for the subsequent steps in the proof."
      },
      {
        "Problem": "Unsound proof of the corollary.",
        "Location": "Corollary Proof, Page 8",
        "Explanation": "The proof that $\tilde{R}^{\\star}_{\rho,C} = R^{\\star}_{\rho,C}$ (the equality between the smallest $R$ for which $\\mathcal{P}_{\rho,R^2,C} \\subseteq \\mathcal{P}$ and the smallest $R$ for which $\\mathcal{P}_{\rho,R^2,C} \\subseteq \\mathcal{Q}_{\rho}$) relies on the unsound claims from Lemma 3.4a, specifically the properties attributed to the maximizers over $\\mathcal{Q}_{\rho}$ and the assumption that RSSP solutions lie on the boundary of $\\mathcal{P}_{\rho,(R^{\\star}_{\rho,C})^2,C}$. Since the premises are not soundly established, the conclusion that $\tilde{R}^{\\star}_{\rho,C} = R^{\\star}_{\rho,C}$ is not supported."
      },
      {
        "Problem": "Algorithm correctness depends on unproven claims.",
        "Location": "Section 3.4, Page 8-9",
        "Explanation": "The proposed algorithm for solving RSSP relies on finding $\tilde{R}^{\\star}_{\rho,C}$ and analyzing the corresponding point. The correctness of this approach hinges on the equality $\tilde{R}^{\\star}_{\rho,C} = R^{\\star}_{\rho,C}$ when an RSSP solution exists, and the property that the maximizer over $\\mathcal{Q}_{\rho}$ (corresponding to $R^{\\star}_{\rho,C}$) is an actual RSSP solution. As detailed in other points, the proofs for these crucial claims (Lemma 3.4a and the Corollary) are unsound, invalidating the conclusion that the algorithm correctly solves the RSSP."
      }
    ],
    "token_usage": {
      "input": 39062,
      "thinking": 8716,
      "output": 1035
    }
  },
  {
    "entry_id": 17,
    "retraction_id": "2001.09967v3",
    "paper_id": "2001.09967v2",
    "retraction_comment": "This paper is withdrawn because there is an error in the last section: the algebraic identities, in the limit n-> \\infty, all collapse to the first conservation law. One could wonder whether this can be fixed via a suitable renormalization scheme but at present, the argument is incomplete",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The paper assumes the existence and properties of a limiting density function u(t,x) for the roots of iterated polynomial derivatives.",
        "Location": "Abstract, Introduction, Proof of Theorem 1",
        "Explanation": "The rigorous existence of a smooth, compactly supported density u(t,x) arising from the limit of discrete root distributions of iterated derivatives is a non-trivial problem and is not proven in the paper. The entire framework of continuous conservation laws for u(t,x) relies on this unproven assumption about the nature of the limit."
      },
      {
        "Problem": "The derivation of continuous conservation laws involves replacing discrete sums over polynomial roots with integrals of the assumed limiting density u(t,x).",
        "Location": "Proof of Theorem 1",
        "Explanation": "The step from discrete algebraic identities involving sums of roots (like Vieta's formulas or power sums) to continuous integral identities for u(t,x) requires a rigorous limiting argument showing the convergence of these sums to the corresponding integrals. This crucial step is not mathematically justified in the paper."
      },
      {
        "Problem": "The Hilbert transform identities are derived based on the assumption that the conjectured nonlocal PDE accurately models the evolution of the root density u(t,x).",
        "Location": "Section 2.2, Section 4",
        "Explanation": "The PDE itself is acknowledged to be based on non-rigorous arguments from a previous work and is presented as a conjecture (Conjecture B). Therefore, the derived Hilbert transform identities are conditional on this unproven conjecture about the dynamics of u(t,x) and are not established as independent mathematical identities."
      }
    ],
    "token_usage": {
      "input": 17528,
      "thinking": 22736,
      "output": 373
    }
  },
  {
    "entry_id": 18,
    "retraction_id": "2003.01493v2",
    "paper_id": "2003.01493v1",
    "retraction_comment": "Theorem 3.3 is not true in general. If it holds, for example, when n=2, we infer that all 2-cluster tilting subcategories are 2Z-cluster tilting, but it can't hold in general",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition and codomain of the connecting map X* are incorrect for n > 1.",
        "Location": "Section 2.4, Definition of X*",
        "Explanation": "The map X*: A(A,X^{n+1})->nE^{1}(A,X^0) is defined by f|->[Y] where Y is the pullback of the n-exact sequence X: X^0 -> ... -> X^{n+1} along f: A -> X^{n+1}. The pullback Y is an n-exact sequence Y^0 -> ... -> Y^n -> A, which is an n-extension of A by Y^0. For X*(f) to be in nE^1(A, X^0), it must be shown that Y^0 is isomorphic to X^0. This is not generally true for n-abelian categories when n > 1, as the first object of the pullback sequence depends on the map f and the entire sequence X, not just X^0."
      },
      {
        "Problem": "The definition and codomain of the maps (alpha^j)^{*,i} are incorrect for n > 1.",
        "Location": "Section 2.4, Definition of (alpha^j)^{*,i}",
        "Explanation": "The maps (alpha^j)^{*,i}: nE^i_A(A,X^{j})->nE^i_A(A,X^{j+1}) are defined by [S]|->alpha^j.[S]. For [S] in nE^i(A, X^j), S is an i-fold n-extension A -> ... -> X^j. The multiplication alpha^j.[S] is defined as the pushout of S along alpha^j: X^j -> X^{j+1}. This pushout is an i-fold n-extension A -> ... -> X^{j+1}. Thus, alpha^j.[S] is in nE^i(X^{j+1}, A). For the codomain to be nE^i(A, X^{j+1}), it must be shown that X^{j+1} is isomorphic to A. This is not true in general."
      },
      {
        "Problem": "The definition and codomain of the maps (alpha^j)_{*,i} are incorrect for n > 1.",
        "Location": "Section 2.4, Definition of (alpha^j)_{*,i}",
        "Explanation": "The maps (alpha^j)_{*,i}: nE^i_A(X^{j+1},A)->nE^i_A(X^{j},A) are defined by [S]|->[S].alpha^j. For [S] in nE^i(X^{j+1}, A), S is an i-fold n-extension X^{j+1} -> ... -> A. The multiplication [S].alpha^j is defined as the pullback of S along alpha^j: X^j -> X^{j+1}. This pullback is an i-fold n-extension X^j -> ... -> A. Thus, [S].alpha^j is in nE^i(A, X^j). For the codomain to be nE^i(X^j, A), it must be shown that A is isomorphic to X^j. This is not true in general."
      },
      {
        "Problem": "The definition of the connecting maps X^{*,i} is incorrect.",
        "Location": "Section 2.4, Definition of X^{*,i}",
        "Explanation": "The maps X^{*,i}:nE^i_A(A,X^{n+1})->nE^{i+1}_A(A,X^0) are defined by [S]|->[X]o[S]. For [S] in nE^i(A, X^{n+1}), S is an i-fold n-extension A -> ... -> X^{n+1}. X is an n-exact sequence X^0 -> ... -> X^{n+1}. The composition [T]o[S] is defined by splicing when S ends where T starts. The composition [X]o[S] is not defined by splicing X and S in this order according to the definition of composition of m-fold n-extensions (Section 2.4)."
      },
      {
        "Problem": "The definition of the connecting maps X_{*,i} is incorrect.",
        "Location": "Section 2.4, Definition of X_{*,i}",
        "Explanation": "The maps X_{*,i}:nE^i_A(X^0,A)->nE^{i+1}_A(X^{n+1},A) are defined by [S]|->[S]o[X]. For [S] in nE^i(X^0, A), S is an i-fold n-extension X^0 -> ... -> A. X is an n-exact sequence X^0 -> ... -> X^{n+1}. The composition [S]o[X] is not defined by splicing S and X in this order according to the definition of composition of m-fold n-extensions (Section 2.4)."
      }
    ],
    "token_usage": {
      "input": 25602,
      "thinking": 25658,
      "output": 1175
    }
  },
  {
    "entry_id": 19,
    "retraction_id": "2005.08379v2",
    "paper_id": "2005.08379v1",
    "retraction_comment": "Figure 1 is incorrect. Will be updated in the revision",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between data timeframe and country selection criteria",
        "Location": "Section 2, Table 1, Section 3.1",
        "Explanation": "Countries are selected based on their COVID-19 case count on April 19, 2020, to represent 'most affected' vs 'less affected'. However, the Twitter data analyzed only covers the period up to April 5, 2020. Comparing Twitter activity up to April 5th with the spread status on April 19th introduces a temporal inconsistency that weakens the claimed correlation between early/high Twitter activity and lower spread."
      },
      {
        "Problem": "Unsound grouping of countries for comparative analysis",
        "Location": "Section 3.1, Table 1, Section 4",
        "Explanation": "The case study groups countries into S1 (higher spread) and S2 (lower spread) based on their status. However, based on the paper's own data for April 5th, Belgium (in S2) had significantly more cases (~100k) than Italy (in S1, ~18k) and a comparable number to Spain (in S1, ~132k). This contradicts the premise that S2 countries consistently had lower spread than S1 countries during the data collection period, invalidating the comparison and conclusions drawn from it."
      },
      {
        "Problem": "Potential issues with data collection reliability and completeness",
        "Location": "Section 2",
        "Explanation": "Relying on scraping Twitter's scroll loader functionality across multiple countries and months, while acknowledging rate limiting, is prone to issues like incomplete data retrieval, changes in Twitter's interface, or potential blocking. This raises concerns about whether the collected tweet volume and content truly represent the full Twitter activity, potentially affecting the validity of volume-based comparisons and content analysis."
      },
      {
        "Problem": "Limitations of keyword-based identification of COVID-19 content",
        "Location": "Section 2, Section 3.2, Section 3.3",
        "Explanation": "Identifying COVID-19 related trends and tweets solely based on matching a curated list of keywords (even with translation) may miss relevant discussions using different terminology or include irrelevant content where keywords are used out of context. This limitation affects the accuracy of the reported volumes, topic distributions, and sentiment analysis results."
      },
      {
        "Problem": "Lack of controls for confounding factors when linking Twitter activity to spread",
        "Location": "Abstract, Introduction, Section 4",
        "Explanation": "The paper suggests a correlation between higher Twitter activity and lower pandemic spread. However, the analysis does not account for numerous other critical factors (e.g., government policies, timing/strictness of lockdowns, public health campaigns via traditional media, cultural factors, population density) that significantly influence pandemic spread and public behavior. Attributing differences in spread or public response even partially to Twitter activity without controlling for these variables is speculative."
      }
    ],
    "token_usage": {
      "input": 15010,
      "thinking": 4194,
      "output": 661
    }
  },
  {
    "entry_id": 20,
    "retraction_id": "2408.09172v3",
    "paper_id": "2408.09172v2",
    "retraction_comment": "The model diagram in Figure 1 on page 3 of the paper has significant ambiguities. It may lead readers to mistakenly believe that the experiments were conducted in a multi-turn dialogue format. Therefore, we request the withdrawal of this submission",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Measurement of Uncertainty",
        "Location": "Section 3.1, Section 3.2",
        "Explanation": "The classification of LLM uncertainty relies on consistency across three prompts, including those with injected right/wrong labels. The effectiveness of the prompt designed to mitigate sycophancy (\"do not change your stance so easily\") is not verified, meaning the model's responses might reflect prompt following rather than genuine internal uncertainty. This could lead to a misclassification of instances and undermine the validity of the \"uncertainty\" signal used."
      },
      {
        "Problem": "Empirical and Potentially Unstable Example Selection",
        "Location": "Section 5.1, Section 5.2",
        "Explanation": "The method selects in-context examples by empirically choosing the single uncertainty category (from Unc-TTP) that yields the best performance on the validation set and applying examples from this category to all test instances. There is no theoretical basis provided for why one specific wavering pattern should be universally optimal, and the stability of this validation-based selection process is not analyzed, especially given the uneven distribution of instances across categories."
      },
      {
        "Problem": "Misleading Comparison with Retrieval Methods",
        "Location": "Section 5.1, Section 5.2",
        "Explanation": "The paper compares its \"one-example-for-all\" ICL selection strategy to retrieval-based methods (BM25, Similarity) which select different examples for each test instance. This fundamental difference in approach (global vs. per-instance optimization) and computational cost during inference is not adequately distinguished, making direct performance comparisons based solely on average accuracy potentially misleading regarding the general effectiveness of the uncertainty signal versus query-specific retrieval."
      }
    ],
    "token_usage": {
      "input": 20607,
      "thinking": 4310,
      "output": 390
    }
  },
  {
    "entry_id": 21,
    "retraction_id": "1207.2800v2",
    "paper_id": "1207.2800v1",
    "retraction_comment": "This paper has been withdrawn by the authors because the proof of Lemma 3.3 has a gap. More precisely, the claim \"If R has a pylonic vertex, v, incident with at least two cables, the pylonicity of v is destroyed by the splitting of any corner\", as stated, is unjustified and looks false in whole generality; the authors overlooked some cases",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 3.4 regarding the structure of irreducible triangulations of punctured surfaces.",
        "Location": "Section 3, Lemma 3.4 Proof",
        "Explanation": "The proof relies on an undefined operation of 'closing the triangular hole' to obtain a triangulation Î of the closed surface S from an irreducible triangulation T of S-D when the boundary length is 3. The argument that this Î belongs to Ξ₁ or Ξ₂ based on the number of cables in the boundary is unclear and lacks formal justification, undermining the classification of irreducible triangulations of S-D and the subsequent finiteness theorem (Theorem 3.5)."
      },
      {
        "Problem": "Misapplication of results about the projective plane to the Möbius band.",
        "Location": "Section 5",
        "Explanation": "The justification for restricting the analysis of irreducible Möbius band (N₁-D) triangulations to cases (i) and (ii) of Lemma 3.4 is based on Corollaries 4.4 and 4.5, which describe properties of triangulations of the projective plane (N₁), a different surface. This misapplication means the argument for excluding cases (iii) and (iv) of Lemma 3.4 for N₁-D is unsound, potentially leading to an incomplete list of irreducible triangulations in Theorem 5.1."
      },
      {
        "Problem": "Unsound proofs of key lemmas for the pinched torus.",
        "Location": "Section 6, Lemma 6.1 and Lemma 6.2 Proofs",
        "Explanation": "The proofs of Lemma 6.1 and Lemma 6.2, which aim to characterize the vertex set and edge properties of irreducible triangulations of the pinched torus S₀[2], contain significant logical gaps and unclear steps. For example, the proof of Lemma 6.2 is difficult to follow and makes unsubstantiated claims about edges becoming cables, rendering the proofs unreliable and undermining Theorem 6.3."
      },
      {
        "Problem": "Fundamentally flawed representation and interpretation of pinched torus triangulations.",
        "Location": "Section 6, Fig. 4 and Theorem 6.3 Proof",
        "Explanation": "The paper uses a spherical model with two vertices s₁ and s₂ to represent the singular point s of the pinched torus S₀[2], stating that s₁ and s₂ are identified. The figures and description imply that edges incident to s₁ and s₂ in the spherical model become loops at the identified vertex s in S₀[2]. This results in a graph that is not simple (contains loops), contradicting the standard definition of a triangulation as a 2-cell embedding of a simple graph, which is used elsewhere in the paper. This invalidates the analysis and the list of irreducible triangulations provided in Theorem 6.3."
      }
    ],
    "token_usage": {
      "input": 3994,
      "thinking": 7561,
      "output": 625
    }
  },
  {
    "entry_id": 22,
    "retraction_id": "2212.04565v2",
    "paper_id": "2212.04565v1",
    "retraction_comment": "There is an error. Some cases were not considered in the proof of Theorem 1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the set difference of neighborhoods in the strong product.",
        "Location": "Corollary 2.2, page 3",
        "Explanation": "The set $N[(g_k,h_k)] \\setminus \\cup_{i=1}^{k-1}N[(g_i,h_i)]$ consists of pairs $(c,d)$ such that $(c,d) \\in N[(g_k,h_k)]$ and $(c,d) \\notin N[(g_i,h_i)]$ for all $i \\in \\{1, \\ldots, k-1\\}$. This means $c \\in N[g_k]$, $d \\in N[h_k]$, and for all $i$, ($c \\notin N[g_i]$ or $d \\notin N[h_i]$). The corollary claims this set is equal to $\\{(c,d) : c \\in N[g_k]\\setminus \\cup_{i=1}^{k-1}N[g_i], d\\in N[h_k]\\} \\cup \\{(c,d) : c \\in N[g_k], d\\in N[h_k]\\setminus \\cup_{i=1}^{k-1}N[h_i]\\}$. This equality is incorrect because the condition 'for all $i$, ($c \\notin N[g_i]$ or $d \\notin N[h_i]$)' is not equivalent to '($c \\notin \\cup N[g_i]$ or $d \\notin \\cup N[h_i]$)'. A counterexample can be constructed."
      },
      {
        "Problem": "Incorrect inequality for the size of the set difference.",
        "Location": "Corollary 2.3, page 3",
        "Explanation": "The inequality $|N[(g_k,h_k)] \\setminus \\cup_{i=1}^{k-1}N[(g_i,h_i)]| \\leq |(N[g_k]\\setminus \\cup_{i=1}^{k-1}N[g_i])| \\times |N[h_k]| + |(N[h_k]\\setminus \\cup_{i=1}^{k-1}N[h_i])| \\times |N[g_k]|$ is derived directly from the incorrect equality in Corollary 2.2 using the triangle inequality. Since the equality is false, the resulting inequality is also not guaranteed to hold. A counterexample shows that the claimed upper bound can be smaller than the actual size of the set difference, invalidating the inequality."
      },
      {
        "Problem": "Proof of the main conjecture relies on incorrect results.",
        "Location": "Section 2.1, page 4",
        "Explanation": "The proof of Conjecture 1.1 attempts to show that the size of the neighborhood difference $N[(g_k,h_k)] \\setminus \\cup_{i=1}^{k-1}N[(g_i,h_i)]$ is zero when $k > \\gamma_{gr}(G)\\gamma_{gr}(H)$. This deduction is based on the incorrect inequality stated in Corollary 2.3 and the subsequent flawed reasoning that the terms on the right-hand side must be zero. This renders the proof invalid."
      },
      {
        "Problem": "Flawed reasoning about the neighborhood conditions of component sequences.",
        "Location": "Section 2.1, page 4",
        "Explanation": "The proof assumes that the condition $N[(g_k,h_k)] \\setminus \\cup_{i=1}^{k-1}N[(g_i,h_i)] = \\emptyset$ is implied by the conditions $N[g_k]\\setminus \\cup_{i=1}^{k-1}N[g_i]= \\emptyset$ and $N[h_k]\\setminus \\cup_{i=1}^{k-1}N[h_i]=\\emptyset$. This implication is not generally true. Furthermore, the argument for why these component conditions should hold when $k > \\gamma_{gr}(G)\\gamma_{gr}(H)$ is based on a misapplication of the Grundy definition to sequences of components $(g_i)$ and $(h_i)$ rather than sequences of unique vertices in the respective graphs $G$ and $H$ that satisfy the Grundy property in $G$ and $H$ respectively."
      }
    ],
    "token_usage": {
      "input": 8419,
      "thinking": 10821,
      "output": 986
    }
  },
  {
    "entry_id": 23,
    "retraction_id": "2209.08741v2",
    "paper_id": "2209.08741v1",
    "retraction_comment": "This manuscript has been withdrawn by the authors. Condition (B) needs to be modified for the proofs to work",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect dimension formula for the target ball.",
        "Location": "Theorem 1.3, Theorem 1.4, Corollary 1.2, Corollary 1.3 (statement $n = 2c^{-2}-1$)",
        "Explanation": "For a ball $\\mathbb B^n$ with the Bergman metric, the constant holomorphic sectional curvature is $-(n+1)$. If the curvature is $-c^2$, then $c^2 = n+1$, which implies $n = c^2-1$. The stated dimension $n = 2c^{-2}-1$ appears inconsistent with the standard curvature calculation for the Bergman metric on a ball."
      },
      {
        "Problem": "Flawed proof for bounding second derivatives of the Bergman kernel in Theorem 1.4.",
        "Location": "Proof of Theorem 1.4",
        "Explanation": "The proof uses Cauchy estimates to bound $|\\partial^2 K(z, t)/\\partial z_j \\partial \bar t_\\alpha|_{t=p}|$. This requires bounding $\\sup_{t \\in U} |\\partial K(z, t)/\\partial z_j|$. By symmetry, this is $\\sup_{t \\in U} |\\partial K(t, z)/\\partial \bar t_j|$. Condition (1.6) provides bounds on $|\\partial K(z, p)/\\partial z_j|$ and $|K(z, p)|$, but does not directly provide the required bound on $|\\partial K(t, z)/\\partial \bar t_j|$ for $t \\in U$ and all $z \\in \\Omega$. The argument does not establish the necessary bound."
      },
      {
        "Problem": "Flawed proof for the boundedness of the Bergman representative coordinate in Proposition 4.1.",
        "Location": "Proof of Proposition 4.1",
        "Explanation": "The proof bounds $|\\partial_{\bar t_j}|_{t=p} K(z, t)| \\leq \frac{\\mathcal C}{r_p} |K(p, z)|$ using condition (4.1). To show the term $K(z, p)^{-1} \\partial_{\bar t_j}|_{t=p} K(z, t)$ is bounded, the proof requires the ratio $|K(p, z)|/|K(z, p)|$ to be bounded for all $z \\in \\Omega$. This boundedness is not shown to follow from condition (4.1) and is not generally true for arbitrary domains, invalidating the conclusion that the Bergman representative coordinate is bounded."
      }
    ],
    "token_usage": {
      "input": 25413,
      "thinking": 10051,
      "output": 575
    }
  },
  {
    "entry_id": 24,
    "retraction_id": "1603.02871v2",
    "paper_id": "1603.02871v1",
    "retraction_comment": "Problems in the proof....specifically maximal pivotality. The estimates on the number of pivotal edges is fine",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound argument for positive probability of a pivotal edge.",
        "Location": "Proof of Lemma 1",
        "Explanation": "The proof claims that starting from an event related to infinite clusters outside a large box $B_M$, one can 'change the configuration inside $B_M$' to obtain a positive probability for a specific edge $e_0$ being pivotal for the event $A=\\{N=1\\}$. This step lacks a rigorous probabilistic formulation or construction, relying instead on a non-specific modification of the configuration. A proper argument is needed to show that the assumption $\\mathbb{P}_p(N=2) > 0$ implies $\\mathbb{P}_p(e_0 \text{ is pivotal for } A) > 0$ and $\\mathbb{P}_p(\\{e_0 \text{ is pivotal for } A\\} \\cap \\{N = 2\\}) > 0$."
      },
      {
        "Problem": "Incorrect claim about the relationship between pivotal edges and maximally jointly pivotal sets.",
        "Location": "Lemma 2(i) and its proof",
        "Explanation": "The lemma asserts that if the configuration $\\omega$ has $N=2$ infinite clusters and the maximally pivotal set $\\mathcal{P}_e(\\omega)$ containing edge $e$ is non-empty, then $\\mathcal{P}_e(\\omega)$ is equal to the set of all pivotal edges $\\mathcal{E}_n(\\omega)$ in $B_n$. A pivotal edge is defined by the effect of flipping its state individually, while a jointly pivotal set is defined by the effect of flipping the states of multiple edges simultaneously (all closed vs. at least one open). These are distinct concepts, and the claimed equality is generally false. This invalidates the subsequent steps that rely on properties of jointly pivotal sets applying to the set of all pivotal edges."
      },
      {
        "Problem": "Incorrect claim of independence between a maximally pivotal set event and edge states.",
        "Location": "Lemma 2(ii) and its proof",
        "Explanation": "The lemma states that for any fixed set of edges $\\{e_1,...,e_k\\}$, the event that this set is the maximally pivotal set containing $e$ is independent of the state of the edges in $\\{e_1,...,e_k\\}$. The definition of a jointly pivotal set (and thus a maximally pivotal set) inherently depends on how the percolation outcome (specifically, the event $A=\\{N=1\\}$) changes when the states of the edges within that set are varied. Therefore, the event that a set is maximally pivotal is strongly dependent on the states of the edges in that set. This independence assumption is false and is critical for the main probability calculation used to derive the contradiction, thus invalidating the argument."
      }
    ],
    "token_usage": {
      "input": 13645,
      "thinking": 6975,
      "output": 604
    }
  },
  {
    "entry_id": 25,
    "retraction_id": "1110.2623v5",
    "paper_id": "1110.2623v4",
    "retraction_comment": "This paper has been withdrawn since a necessary condition for the existence of an asymptotically cylindrical Calabi-Yau metric on W_1 is in fact not satisified",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The constructed threefold $\\overline{W}$ is not a Calabi-Yau manifold, and the divisor $D$ is not anti-canonical.",
        "Location": "Section 6.1, argument following equation (6.3)",
        "Explanation": "The argument claims $K_{S \\times \\mathbb{P}^1} \\otimes L(S \\times \\{x\\}) \\cong \\overline{\\mathbb{C}}$, which is incorrect. $K_{S \\times \\mathbb{P}^1} \\cong \\mathcal{O}_S \\boxtimes \\mathcal{O}_{\\mathbb{P}^1}(-2)$ and $L(S \\times \\{x\\}) \\cong \\mathcal{O}_S \\boxtimes \\mathcal{O}_{\\mathbb{P}^1}(1)$, so their tensor product is $\\mathcal{O}_S \\boxtimes \\mathcal{O}_{\\mathbb{P}^1}(-1)$. Furthermore, the canonical bundle of the orbifold $Z = (S \\times \\mathbb{P}^1) / (\\rho \\times \\psi)$ is trivial since $\\langle \\rho \\times \\psi \\rangle \\subset SL(S \\times \\mathbb{P}^1)$. A crepant resolution $\\overline{W}$ of $Z$ is a Calabi-Yau manifold, $K_{\\overline{W}} \\cong \\mathcal{O}_{\\overline{W}}$. The divisor $D$ is the strict transform of the image of $S \\times \\{x\\}$, whose corresponding line bundle on $Z$ pulls back to $\\mathcal{O}_S \\boxtimes \\mathcal{O}_{\\mathbb{P}^1}(p)$ on $S \\times \\mathbb{P}^1$. For $p \\geq 3$, this is not trivial, so $L(D)$ is not trivial. Thus $D \\notin |-K_{\\overline{W}}|$. This violates a key requirement for an admissible pair in Theorem 2.4. The erratum attempts to fix this but introduces new inconsistencies regarding canonical bundles and line bundles on the covering space."
      },
      {
        "Problem": "The constructed threefold $\\overline{W}$ is not simply connected.",
        "Location": "Lemma 6.2",
        "Explanation": "The proof claims $\\overline{W}$ is simply connected because the map $\\widetilde{W} \\to \\Wbar$ has degree $p$ and $\\widetilde{W}$ is simply connected. However, if $\\widetilde{W}$ is simply connected and covers $\\Wbar$ with degree $p$, then $\\pi_1(\\Wbar) \\cong \\mathbb{Z}_p$. Thus, $\\overline{W}$ is not simply connected for $p \\geq 2$. Simple connectedness of $\\overline{W}$ is required by Theorem 2.4. Simple connectedness of $W = \\overline{W} \\setminus D$ is required by Theorem 2.4, and the proof for $\\pi_1(W)=0$ in Lemma 6.2 relies on $\\overline{W}$ being simply connected, which is false. The erratum's claim of simple connectedness for the new manifold $\\overline{W}'$ is not rigorously proven."
      },
      {
        "Problem": "The construction of a matching between admissible pairs appears flawed.",
        "Location": "Section 7, particularly the proof of Theorem 7.7",
        "Explanation": "The proof attempts to find vectors $v_1, v_2, v_3$ in $L \\otimes \\mathbb{R}$ satisfying conditions derived from the matching definition and the properties of the lattices $L_1$ and $L_2$. For the example considered (non-symplectic type $p_1=3$ with $(L^{\\rho^2})^\\perp = A_2$ and Fano type $b^2(V)=1$), $L_1 = L^{\\rho^2}$ and $L_2$ is a rank 1 hyperbolic lattice. The proof chooses $v_2 \\in (L^{\\rho^2})^\\perp \\otimes \\mathbb{R} = A_2 \\otimes \\mathbb{R}$. However, $v_2$ must also be in $L_2 \\otimes \\mathbb{R}$. Since $L_2$ is hyperbolic and $A_2$ is positive definite, their intersection in $L \\otimes \\mathbb{R}$ is $\\{0\\}$ unless $L_2$ is contained in $A_2$, which is impossible for signature reasons. Thus, $v_2$ must be zero, which cannot be a K\\\"ahler class. This indicates the chosen lattice setup for the matching is incompatible with the requirements. The erratum does not fix this specific issue in the matching construction."
      }
    ],
    "token_usage": {
      "input": 37566,
      "thinking": 12012,
      "output": 1061
    }
  },
  {
    "entry_id": 26,
    "retraction_id": "1307.5957v4",
    "paper_id": "1307.5957v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Theorem 2.1 and Proof",
        "Location": "Section 2.1, Theorem 2.1 and its proof",
        "Explanation": "The statement of Theorem 2.1 is unusual and not a standard estimate for NLS. The proof is inadequate, lacking any derivation steps. It relies on an incorrect application of the Poincar\\u00e9 inequality on $L^2(\\R)$ and does not demonstrate how conservation laws or the fundamental theorem of calculus lead to the stated inequality."
      },
      {
        "Problem": "Fundamental Misunderstanding of Lagrangian Mechanics",
        "Location": "Section 3, Proposition 3.1 and its proof",
        "Explanation": "The paper uses an incorrect Lagrangian density for the NLS field and attempts to apply the Euler-Lagrange equation for a particle coordinate $x(t)$ to a Lagrangian functional defined for a field $u(t,x)$. The resulting equation (3.2) and its derivation are conceptually flawed and mix concepts from particle mechanics and field theory incorrectly."
      },
      {
        "Problem": "Inconsistent NLS Definition and Parameters",
        "Location": "Section 1 (NLS equation), Section 2 (Potential energy, Energy conservation)",
        "Explanation": "The notation for the Laplacian is inconsistent ($\\Delta_{\\R^{d+1}}$ vs $\\Delta_{\\R^d}$). The dimension $d$ is stated inconsistently ($d \\geq 1$, $d=2$ for initial condition, $d=1$ for main results). The formula for potential energy $V(t)$ is inconsistent with the energy conservation formula (2.7) and the NLS equation (1.1)."
      },
      {
        "Problem": "Incorrect Action Functional",
        "Location": "Section 3.1, equation (3.5)",
        "Explanation": "The action functional defined is based on an incorrect Lagrangian density for the NLS equation. Varying this action functional will not yield the NLS equation (1.1) via the principle of least action."
      },
      {
        "Problem": "Potentially Incorrect Stress Tensor Formula",
        "Location": "Section 2, equation (2.4)",
        "Explanation": "The formula for the tensor $F_{jk}$ (related to stress/momentum flux density) appears non-standard for the NLS equation, particularly the term involving $\\Delta(|u|^2)$. This formula is used in the conservation law $\\partial_{t}F_{j0}+\\partial_{x_{k}}F_{jk}=0$ and its derivation from the NLS equation is not shown."
      }
    ],
    "token_usage": {
      "input": 4610,
      "thinking": 5416,
      "output": 583
    }
  },
  {
    "entry_id": 27,
    "retraction_id": "2211.05302v2",
    "paper_id": "2211.05302v1",
    "retraction_comment": "We just noted the explanation on phase retardation was incorrect and accordingly, the inhibition mechanism of zeroth-order light was not properly elucidated. We will submit a revised version soon",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent and likely incorrect theoretical model for the SLM.",
        "Location": "Page 1-2, Equations (1) and (3), and surrounding text",
        "Explanation": "The paper uses Equation (1) which describes the tilting angle for a twisted nematic liquid crystal cell. However, it then uses Equation (3) for phase retardation, which is applicable to parallel-aligned liquid crystal cells, and mentions 'parallel aligned LC cells' in the text. The specific experimental SLM (LETO PLUTO) is a Liquid Crystal on Silicon (LCoS) device, typically used as a phase-only SLM, which is often parallel-aligned or has a small twist optimized for specific polarization. This inconsistency and likely misapplication of the theoretical model invalidate the theoretical analysis and simulations based on it."
      },
      {
        "Problem": "Unsound theoretical basis for voltage optimization.",
        "Location": "Page 2-3, Figure 1 and associated text",
        "Explanation": "The paper determines optimal Bright (Vo) and Dark (Vc) voltages based on theoretical curves derived from Equations (1)-(4). Since the underlying theoretical model (specifically the phase retardation formula in Eq. 3 and potentially the application of Eq. 4) is likely incorrect for the SLM type used, the theoretical justification for the chosen optimal voltages is flawed. While experimental results show practical improvement, the paper's explanation for the optimality is based on an unsound theoretical foundation."
      },
      {
        "Problem": "Insufficient theoretical explanation for the reduction of pixelation-induced zeroth-order light.",
        "Location": "Page 1-2, Theoretical background section",
        "Explanation": "The paper claims to eliminate zeroth-order light caused by pixelation by adjusting Vc and Vo. However, the provided theoretical model (Equations 1-5) primarily describes the voltage-dependent phase/amplitude modulation of the liquid crystal cells. It does not explicitly model how these voltage adjustments specifically reduce the diffraction effects caused by the pixelated structure (e.g., fill factor, grid diffraction), which is the stated origin of the zeroth order. The link between the voltage-controlled LC behavior and the reduction of the pixelation-induced zeroth order is not theoretically derived or explained within the provided framework."
      },
      {
        "Problem": "Unjustified application of the intensity formula (Eq. 4) without full polarization details.",
        "Location": "Page 2, Equation (4) and surrounding text, Figure 3(g)",
        "Explanation": "Equation (4) relates intensity to phase retardation and incident polarization angle $\\psi$. The paper states $\\psi$ is slightly larger than zero in practice, implying the SLM is not in a pure phase-only mode according to this equation. For a twisted nematic SLM (if applicable) or a parallel-aligned SLM used for phase-only modulation, the intensity modulation depends heavily on the input and output polarization states relative to the LC director. The paper does not fully describe the polarization optics used in the theoretical model or simulation, nor does it justify the applicability of Equation (4) to the specific SLM and experimental setup (Fig 3g shows a polarizer before the SLM, but the output analysis is not detailed in relation to the theory). This lack of detail makes the application of Eq. 4 questionable and potentially inaccurate for modeling the SLM's intensity response."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 3573,
      "output": 736
    }
  },
  {
    "entry_id": 28,
    "retraction_id": "1910.05809v3",
    "paper_id": "1910.05809v2",
    "retraction_comment": "Need to fix some error in the paper. In the last step of the proof, the hypersurface of the minimal principle curvature equal to zero may be tangent to the boundary of the domain",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect PDE inequality used for the smallest principal curvature",
        "Location": "Proof of Theorem 2.1, Lemma 2.1 and subsequent arguments",
        "Explanation": "Lemma 2.1 claims that the Laplace-Beltrami operator of the smallest principal curvature $\\kappa_1^T$ satisfies $\\Delta^{\\Sigma^T}\\kappa^T_1 \\leq 0$. However, the derived inequality is $\\Delta^{\\Sigma^T}\\kappa^T_1 \\leq (nH^T\\kappa^T_1 - |A^T|^2)\\kappa^T_1$ (or similar, including negative definite terms). This inequality is not of the form $\\Delta \\phi \\leq 0$ or $\\Delta \\phi \\leq C \\phi$ with $C \\leq 0$, which is required for the subsequent application of the maximum principle or Hopf boundary point lemma at a boundary minimum $\\kappa_1^T(P)=0$. This invalidates the conclusion that the normal derivative $\\partial_n \\kappa_1^T(P) > 0$."
      },
      {
        "Problem": "Unjustified smoothness assumption for the smallest principal curvature",
        "Location": "Proof of Theorem 2.1, analysis of $\\kappa_1^T$ near the boundary point P",
        "Explanation": "The proof applies standard PDE techniques (computing the Laplacian, using the Hopf lemma) to the smallest principal curvature $\\kappa_1^T$. This requires $\\kappa_1^T$ to be smooth in a neighborhood of the boundary point $P$ where $\\kappa_1^T(P)=0$. While the principal curvatures are distinct at $P$ ($\\kappa_1(P)=0 < \\kappa_i(P)$ for $i \\geq 2$), this does not guarantee smoothness of $\\kappa_1^T$ in a neighborhood, as eigenvalues of a matrix family are generally only smooth where they are distinct. The smoothness of $\\kappa_1^T$ near a point where it vanishes and potentially merges with other eigenvalues is a non-trivial regularity result that is assumed without justification, rendering the subsequent PDE analysis invalid."
      },
      {
        "Problem": "Incorrect structure and determinant calculation for the Hessian at the boundary",
        "Location": "Proof of Theorem 2.1, equation (2.35) and subsequent determinant calculation",
        "Explanation": "The Hessian matrix of $u^T$ at a boundary point $P$ where $u^T=0$ is presented in equation (2.35) as having zero mixed tangential-normal entries $u^T_{kn}(P)$ for $k<n$ in the curvature frame of the boundary $\\Gamma^T$. This is generally incorrect; these terms are non-zero unless $P$ is a critical point of $u_n$ restricted to the boundary. The subsequent determinant calculation is based on this incorrect matrix structure. While the conclusion about the multiplicity of the zero eigenvalue might coincidentally be correct, the presented derivation is flawed."
      }
    ],
    "token_usage": {
      "input": 9647,
      "thinking": 16700,
      "output": 660
    }
  },
  {
    "entry_id": 29,
    "retraction_id": "1108.1348v2",
    "paper_id": "1108.1348v1",
    "retraction_comment": "Withdrawn because of a crucial error in eq.(15)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Dimensional inconsistency in the action formulation",
        "Location": "Section 2, Eq. (4)",
        "Explanation": "The dimensions of terms outside the $N[\\dots]$ bracket in the action, specifically $2(1-\\lambda) K\nabla \nu$ and $(1-\\lambda)(\nabla \nu)^2$, do not match the dimension of terms inside the bracket ($\\sqrt{g} N [\\dots]$) or the required dimension ($z+d$) for a dimensionless action integral with the stated dimensions of fields and $z=3, d=3$. This suggests a fundamental inconsistency in the action as written."
      },
      {
        "Problem": "Incorrect claim about physical relevance of static solutions",
        "Location": "Section 3.1, Conclusions (Section 6)",
        "Explanation": "The paper claims that static spherically symmetric solutions ($n=0, B \neq 0$) cannot reproduce Newton's Law if the auxiliary field $A$ is independent of the metric. However, the static metric with $f(r)=1-2B/r$ is the standard Schwarzschild metric, which is known to reproduce Newton's Law in the weak field limit. This contradicts the standard interpretation of this metric and the results presented in the paper's own previous work (Ref. [15]) for the $\\lambda=1, n=0$ case."
      },
      {
        "Problem": "Reliance on non-standard regularization for divergent integral",
        "Location": "Section 3.2, Eq. (14), and subsequent discussion",
        "Explanation": "In analyzing the $B=0, n \neq 0$ case, the paper evaluates the Hamiltonian constraint integral, which is shown to be divergent over the physical domain $(0, \\infty)$. The paper uses a non-standard regularization (integrating over a finite range in $\\ln r$) to obtain a finite result and concludes that the only solution is $n=0$. Drawing physical conclusions from setting a divergent integral to zero via such regularization is mathematically unsound. The divergence itself indicates that solutions of this form are not well-behaved over the full spatial domain."
      },
      {
        "Problem": "Inconsistent argument in the Horava-Melby Thompson interpretation",
        "Location": "Section 5",
        "Explanation": "The analysis of the Horava-Melby Thompson approach calculates the asymptotic form of the auxiliary field $A$ using an equation (Eq. (12)) that includes terms dependent on a non-zero shift function $n(r)$. However, the subsequent conclusion is that oscillations in the potential are removed only if the integration constants $a=b=0$, which implies $n(r)=0$. If $n(r)=0$, the equation for $A$ (Eq. (12)) simplifies significantly (as shown in Section 3.1), and the asymptotic form of $A$ used in the calculation is no longer valid, making the argument inconsistent."
      },
      {
        "Problem": "Oscillating behavior in asymptotic solutions for $B \neq 0, n \neq 0$",
        "Location": "Section 3.3, Eq. (18)",
        "Explanation": "For fixed $\\lambda \neq 1$ and $B \neq 0$, the asymptotic analysis for large $r$ yields solutions for the shift function $n(r)$ that result in a gravitational potential with oscillating terms proportional to $1/r$. These oscillations are of the same order as the standard Newtonian potential and are not compatible with experimental observations, indicating that these solutions are not physically viable in the infrared for fixed $\\lambda \neq 1$."
      }
    ],
    "token_usage": {
      "input": 12343,
      "thinking": 16772,
      "output": 801
    }
  },
  {
    "entry_id": 30,
    "retraction_id": "1505.02494v2",
    "paper_id": "1505.02494v1",
    "retraction_comment": "This paper has been withdrawn by the author due to crucial sign errors in Theorem 5 and equation (10)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect equivalence between symmetric EiCP-T and optimization problem (P)",
        "Location": "Corollary 1, Section 3",
        "Explanation": "The KKT conditions derived from maximizing the Rayleigh quotient lambda(x) subject to the constraints e^T x = 1 and x >= 0 (problem (P)) result in the condition w <= 0, x >= 0, w^T x = 0, where w = (lambda*I - A)x^(m-1). This is a different complementarity problem than the symmetric EiCP-T, which requires w >= 0, x >= 0, w^T x = 0. Therefore, the optimization problem (P) is not equivalent to the symmetric EiCP-T."
      },
      {
        "Problem": "Flawed convergence proof for the Shifted Projected Power Method",
        "Location": "Theorem regarding monotonic convergence, Section 4",
        "Explanation": "The proof claims that the monotonic increase of the shifted objective function hat{f}(x^k) implies the monotonic increase of the original objective function lambda(x^k). This implication is incorrect because the shift parameter alpha_k is adaptively chosen and changes at each iteration, meaning hat{f}(x) = lambda(x) + alpha_k is not the same function across iterations. Thus, the monotonic convergence of lambda(x^k) is not established by this argument."
      },
      {
        "Problem": "Algorithm 1 is incomplete in finding all solutions",
        "Location": "Algorithm 1, Section 4",
        "Explanation": "Algorithm 1 is presented as a procedure to compute 'all the complementary eigenpairs' of GEiCP-T_J. However, the procedure only identifies solutions (lambda, x) where the corresponding vector w = (lambda*B - A)x^(m-1) is the zero vector. It fails to find solutions where w is non-zero but satisfies the complementarity conditions w_J >= 0, x_J >= 0, w_J^T x_J = 0, and w_bar{J} = 0. Therefore, the algorithm is incomplete."
      },
      {
        "Problem": "Lemma 2.1 is incorrect as stated",
        "Location": "Lemma 2.1, Section 2",
        "Explanation": "The lemma claims that if (lambda, x) is a solution of GEiCP-T_J, it is also a solution of GEiCP-T_hat{J} for any hat{J} such that J_0 subset= hat{J} subset= J_1, where J_0 = {i : w_i > 0} and J_1 = {i : x_i >= 0}. Given the definition of GEiCP-T_hat{J} (specifically, the requirement w_bar{hat{J}} = 0 and w_hat{J} >= 0), these conditions are not guaranteed for an arbitrary hat{J} in the specified range. The definition of J_1 as {i : x_i >= 0} is also trivially [n] for any real vector x, making the range J_0 subset= hat{J} subset= [n] and the lemma statement problematic."
      }
    ],
    "token_usage": {
      "input": 22173,
      "thinking": 20642,
      "output": 728
    }
  },
  {
    "entry_id": 31,
    "retraction_id": "1504.07542v2",
    "paper_id": "1504.07542v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial sign error in equation 9",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect incorporation of the external pair potential in the Hamiltonian and gap equation.",
        "Location": "Eqs. 2.1, 2.3",
        "Explanation": "The external pair potential term in the Hamiltonian (Eq. 2.1) includes a phase factor (Δ/|Δ|) that makes the potential strength dependent on the order parameter itself, which is not characteristic of a fixed external field. This leads to a self-consistency equation (Eq. 2.3) that does not match the standard gap equation derived from a BCS Hamiltonian with a constant source term. This fundamental error propagates through the subsequent calculations."
      },
      {
        "Problem": "Invalid linearization of the gap equation and calculation of the gap value from the linearized equation.",
        "Location": "Eqs. 2.5, 2.11, 2.14, 2.15",
        "Explanation": "The paper linearizes the gap equation (Eq. 2.5) assuming the gap approaches zero, but then uses the solution of the resulting linear system (Eqs. 2.14, 2.15) to represent the finite energy gap values when the external potential is non-zero. A linearized equation is only valid for determining the critical temperature (where the gap goes to zero) or the behavior very close to the critical point. Solving it to find the gap value when it is expected to be non-zero is incorrect. The term 1/|Δ| in the linearized equation also makes it ill-defined near zero gap."
      },
      {
        "Problem": "Heuristic and inconsistent construction of the Ginzburg-Landau free energy.",
        "Location": "Eq. 3.5, 3.6",
        "Explanation": "The Ginzburg-Landau free energy is introduced heuristically by adding a term related to the expectation value of the external potential. This term is then arbitrarily modified by a temperature-dependent factor (1-T/T_c*) to match the temperature dependence of the gap derived from the flawed linearized calculation. The free energy is not derived from the microscopic Hamiltonian, and its form is not justified from first principles. This undermines all subsequent results based on this free energy."
      },
      {
        "Problem": "Misinterpretation of the critical temperature in the presence of a source term.",
        "Location": "Eq. 2.17, Fig. 1, surrounding text",
        "Explanation": "The temperature T_c* is defined based on setting the calculated gap Δ_ph to zero in the solution of the linearized gap equation (Eq. 2.17). This temperature is then interpreted as the critical temperature of the superconductor. However, a non-zero external pair potential (source term) generally induces a non-zero order parameter at all temperatures, meaning there is no phase transition where the order parameter vanishes in the usual sense. The concept and definition of T_c* as a critical temperature are therefore flawed."
      },
      {
        "Problem": "Inconsistency between the stated free energy and the derived Ginzburg-Landau equation.",
        "Location": "Eq. 3.5, 3.6, 3.7a",
        "Explanation": "The Ginzburg-Landau equation (Eq. 3.7a) presented in the paper does not correspond to the stated Ginzburg-Landau free energy functional (Eq. 3.5 or 3.6). The variational derivative of the free energy G_s - G_n = a|Ψ|^2 + 2u|Ψ| + ... with respect to Ψ* should yield a different equation than Eq. 3.7a. This inconsistency invalidates the Ginzburg-Landau analysis and the derived properties like critical fields and coherence/penetration lengths."
      }
    ],
    "token_usage": {
      "input": 7572,
      "thinking": 4721,
      "output": 831
    }
  },
  {
    "entry_id": 32,
    "retraction_id": "2012.10766v4",
    "paper_id": "2012.10766v3",
    "retraction_comment": "Propositions 3 and 4 are incorrect, and so is their proof. The proof requires the shifted convolution problem for the coefficients of the cusp forms, which is not presented here. The definition of the mollifier M(f,s) is wrong. It needs to be defined as a convolution inverse of the Fourier coefficients of the automorphic forms",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound proof of Proposition 4",
        "Location": "Section 6, Proof of Proposition 4",
        "Explanation": "The proof requires evaluating the mean square of the mollified L-function, specifically $\\int |L(f, \\sigma_0+it)M(f, \\sigma_0+it)|^2 dt$. This is a twisted fourth moment type integral. The paper introduces Lemma 5, which provides a formula for a twisted second moment type integral $\\int (h/k)^{-it} L(f, 1/2+\\alpha+it)L(f, 1/2+\\beta-it) w(t) dt$. This lemma is not the correct tool for evaluating the required integral. The subsequent discussion references results for different problems (twisted fourth moment of $\\zeta$, first moment of $LM$) without clearly demonstrating how they apply to prove the specific statement of Proposition 4. The connection between the stated lemma and the required integral is missing, rendering the proof of Proposition 4 unsound."
      },
      {
        "Problem": "Main theorems depend on unproven Proposition 4",
        "Location": "Section 3 (The Setup), Section 7 (Independence), Section 8 (Gaussian Process)",
        "Explanation": "The entire proof strategy for Theorem 1 relies on Proposition 4 to establish that $L(f, \\sigma_0+it)M(f, \\sigma_0+it) \\approx 1$, which is crucial for transferring the distribution from the auxiliary prime sum to the L-function. Theorems 2 and 3 (independence and Gaussian process) extend this method and implicitly rely on an analogous result to Proposition 4 for linear combinations of L-functions. Since the proof of Proposition 4 is unsound, the conclusions of Theorems 1, 2, and 3 are not established by the arguments presented."
      },
      {
        "Problem": "Misleading statement regarding mean square of L-function and fourth moment of zeta function",
        "Location": "Section 6, paragraph before Lemma 5",
        "Explanation": "The statement 'Observing the above equation it is now clear that the mean square of the L-function (associated with a holomorphic cusp form) roughly corresponds to the fourth moment of the Riemann zeta function' is mathematically imprecise and potentially misleading in the context of the proof of Proposition 4. The mean square $|L(f,s)|^2$ is related to the Rankin-Selberg convolution $L(f \\times \\bar{f}, s)$, which is a degree 4 L-function. While techniques for studying mean values share common elements, this statement contributes to the lack of clarity in Section 6 regarding the specific integral being evaluated."
      }
    ],
    "token_usage": {
      "input": 34556,
      "thinking": 4577,
      "output": 598
    }
  },
  {
    "entry_id": 33,
    "retraction_id": "1703.02535v2",
    "paper_id": "1703.02535v1",
    "retraction_comment": "Error in the diffusion constant of Theorem 2.2, equation (2.4) due to a delicate issue in the method of the proof which is not trivial to correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The model is defined with an infinite sum over oscillators on the hierarchical lattice, which may not converge in the limit considered.",
        "Location": "Equation (1.15), Section 1.5",
        "Explanation": "The sum $\\sum_{\\zeta \\in \\Omega_N}$ is over a countable infinite set of oscillators. For the stochastic differential equation to be well-defined, this sum must converge. The scaling $K_{d(\\eta, \\zeta)}/N^{2d(\\eta, \\zeta)-1}$ implies the sum converges if $\\sum_{d=1}^\\infty K_d N^{1-d} < \\infty$. However, the paper considers the limit $N \to \\infty$, which makes this convergence condition problematic and suggests the model might be ill-defined in this limit on the infinite lattice."
      },
      {
        "Problem": "There is an inconsistency in the time scaling used for the block order parameter phase.",
        "Location": "Definition (1.18) vs Proof Section 3.2 and Theorem 2.1/2.3",
        "Explanation": "Definition (1.18) defines the phase $\\Phi_\\eta^{[k]}$ at time $N^{-1}t$ based on oscillator phases at time $N^{k-1}t$. The proof sketch in Section 3.2 derives the dynamics for $\\Phi_0^{[k]}(t)$ where the oscillator phases are evaluated at time $N^k t$. This is a direct contradiction in the time variable associated with the phase, making the derived dynamics potentially incorrect for the defined order parameter."
      },
      {
        "Problem": "The natural frequency term in the derived limiting SDE for the block phase appears inconsistent with the original model definition.",
        "Location": "Theorem 2.3",
        "Explanation": "Assuming the SDE in Theorem 2.3 describes the phase of the $k$-block order parameter at time $N^{k-1}t$ (as suggested by the separation of time scales idea and Definition 1.18), the natural frequency term $\\omega_{0^{[k]}}$ does not seem to arise from the average natural frequency of the oscillators within the $k$-block in the $N \to \\infty$ limit, based on the model definition (1.15). This suggests the derived SDE might not be the correct limiting dynamics for the defined model."
      },
      {
        "Problem": "The scaling of the noise term in the original model leads to divergence for higher hierarchical levels in the intended limit.",
        "Location": "Equation (1.15), Section 1.5, and implied in proof Section 3.2",
        "Explanation": "When scaling time by $N^{k-1}$ to analyze the $k$-block dynamics (consistent with Definition 1.18), the noise term for individual oscillators scales as $D \\sqrt{N^{k-1}}$. This diverges as $N \to \\infty$ for $k \\ge 2$. This would typically result in a divergent noise term in the limiting SDE for the block phase, contradicting the finite noise term $\frac{\\sqrt{Q^{[k]}}}{R^{[k]}}$ presented in Theorem 2.3."
      },
      {
        "Problem": "The scaling of the interaction term in the original model leads to divergence for higher hierarchical levels in the intended limit.",
        "Location": "Equation (1.15), Section 1.5, and implied in proof Section 3.2",
        "Explanation": "When scaling time by $N^{k-1}$, the interaction term for individual oscillators involves sums over hierarchical distances $m$ with coefficients scaling as $K_m N^{k-m} - K_{m+1} N^{k-m-2}$. For $m \\le k$, these coefficients diverge as $N \to \\infty$. This suggests the interaction scaling in the original model (1.15) is not appropriate for deriving the dynamics of $k$-blocks on the time scale $N^{k-1}t$ for $k \\ge 1$ in the $N \to \\infty$ limit."
      }
    ],
    "token_usage": {
      "input": 35286,
      "thinking": 15904,
      "output": 913
    }
  },
  {
    "entry_id": 34,
    "retraction_id": "1611.01102v3",
    "paper_id": "1611.01102v2",
    "retraction_comment": "The paper fails to appreciate that the necessitation rule is tacitly presupposed in the formulation of the Girle-Priest tableau rules. If those presuppositions were made explicit, the proofs of this paper would depend on a use of necessitation, contra what was claimed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Formal error in applying the Box-Elimination rule.",
        "Location": "Page 3-4, 'Argument that q is false', Step (11)",
        "Explanation": "The step infers `q = ~□q` in world `k` from `(Def) (q = ~□q) (n)` and `nAk` using the □-Elim rule. However, the □-Elim rule, as stated on page 2, applies to formulas of the form `□p`. The formula `q = ~□q` is not of this form. The application of the rule here is formally incorrect based on the rules provided."
      },
      {
        "Problem": "Implicit and unjustified assumption of the necessity of the definition.",
        "Location": "Page 3-4, 'Argument that q is false', Step (11)",
        "Explanation": "The derivation of the contradiction in world `k` requires the equivalence `q = ~□q` to hold in world `k`. The proof attempts to derive this from the definition holding in world `n` and `nAk`. This step is only valid if the definition `q = ~□q` is assumed to be a necessary truth (or true in all worlds accessible from `n`), allowing `□(q = ~□q)` to be inferred and then □-Elim applied. This crucial assumption is not explicitly stated or justified in the proof steps, and the formal step used is incorrect."
      },
      {
        "Problem": "Questionable admissibility of the self-referential definition within standard modal logic.",
        "Location": "Page 1, Section 2; Page 4, Section 3",
        "Explanation": "The paradox is constructed using a proposition `q` defined by the self-referential equivalence `q = ~□q`. Standard propositional modal logic does not typically provide mechanisms for introducing propositions defined in this self-referential manner within the object language. While the author claims such a definition is admissible, its introduction as a standard premise `q = ~□q` into the system is the source of the inconsistency, suggesting that the standard framework is not equipped to handle such definitions without extension or modification (e.g., using fixed-point semantics)."
      },
      {
        "Problem": "Mischaracterization of the impact on soundness proofs.",
        "Location": "Page 4, Section 3 'Whither Soundness?'",
        "Explanation": "The author concludes that the paradox implies soundness proofs for systems T and stronger depend on inconsistent premises. However, the paradox arises from adding the specific, self-referential premise `q = ~□q` to the system. This shows that the system *plus* this premise is inconsistent. It does not necessarily invalidate the soundness proof for the system *without* this premise, which demonstrates soundness for standard formulas and propositions. The issue lies with the premise `q = ~□q` itself, not necessarily with the standard axioms and rules of T."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 5784,
      "output": 652
    }
  },
  {
    "entry_id": 35,
    "retraction_id": "2205.15802v2",
    "paper_id": "2205.15802v1",
    "retraction_comment": "The proof of Theorem 3 is wrong: in the display equation below Equation (22), bottom of page 15, the gradient of $\\phi_{t+1}$ is missing a factor $1/(\\alpha\\eta_t)$",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Variational Formulation",
        "Location": "Equation (10), Appendix A.1, Appendix A.2, Appendix A.3",
        "Explanation": "The paper defines the variational potential $\\phi(X, A)$ in Equation (10) and claims a relationship $\\psi(X) = \\frac{1}{\\alpha} \\inf_{A \\in \\pd} \\phi(X, A)$. However, the proof of Proposition 1 in Appendix A.1 uses a different definition of $\\phi$ (equivalent to setting $\\alpha=1$ in Equation (10) and removing the $1/\\alpha$ factor outside the infimum) to show the equivalence of the update rules. This inconsistency means the augmented FTRL update (Equation (11)) analyzed in Theorem 2 is not equivalent to the Schatten-1 FTRL update (Equation (8)) as claimed, invalidating the analysis of the latter."
      },
      {
        "Problem": "Flawed Analysis of Augmented FTRL",
        "Location": "Proof of Theorem 2, Appendix A.3",
        "Explanation": "The proof of the regret bound for the augmented FTRL (Theorem 2) incorrectly decomposes the regret term. The update rule (Equation (11)) is a joint minimization over $(X, A)$. The proof, however, splits the regret term as if the minimization were performed sequentially or via block-coordinate descent (minimizing over $X$ with $A_t$ fixed, then over $A$ with $X_{t+1}$ fixed). This decomposition is not valid for the stated joint minimization, and the standard FTRL analysis for jointly convex functions (which $\\phi$ is not necessarily) is not applied, invalidating the derived regret bound."
      },
      {
        "Problem": "Unjustified Use of KT-OCO Bound",
        "Location": "Proof of Theorem 4, Appendix A.4",
        "Explanation": "The parameter-free extension (Theorem 4) relies on combining Schatten-1 FTRL with the Krichevsky-Trofimov (KT-OCO) algorithm. The KT-OCO algorithm requires its scalar gradients to be bounded (e.g., in $[-1, 1]$) for the standard regret bound (Equation (13)) to hold. The scalar gradient for KT-OCO in AdaTask is $s_t = \\frac{\\sqrt{N}}{L}\\langle g_t, [\\tilde{X}_t]_{i_t:} \\rangle$. The proof in Appendix A.4 only shows that the *expected* value of $\\langle G_t, \\tilde{X}_t\\rangle$ is bounded, which implies $\\mathbb{E}|s_t| \\le 1$. However, the KT-OCO bound requires the *realized* values of $s_t$ to be bounded. Since $\\|\\tilde{X}_t\\|_{S(1)} \\le 1$ does not guarantee that individual row norms $\\|[\\tilde{X}_t]_{i_t:}\\|_2$ are bounded by $1/\\sqrt{N}$, the realized $|s_t|$ can exceed 1. Without a bound on the realized scalar gradients, the application of the KT-OCO regret bound is not justified, invalidating Theorem 4."
      }
    ],
    "token_usage": {
      "input": 34260,
      "thinking": 6887,
      "output": 735
    }
  },
  {
    "entry_id": 36,
    "retraction_id": "2006.05804v2",
    "paper_id": "2006.05804v1",
    "retraction_comment": "Lemma 2.2 is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent spatial regularities in the Yang-Mills-Dirac equation for the Dirac spinor.",
        "Location": "Equation (1.11), Theorem 1.2, Section 3.2",
        "Explanation": "The Dirac equation is given by $i\\gamma^\\mu\\partial_\\mu\\psi = -A^\\mu\\gamma_\\mu\\psi$. The stated regularity for $\\psi$ is $B^0_{2,1}$ and for $A$ is $B^{1/2}_{2,1}$. The term $i\\gamma^\\mu\\partial_\\mu\\psi$ involves one spatial derivative of $\\psi$, resulting in a spatial regularity of $0-1=-1$. The term $-A^\\mu\\gamma_\\mu\\psi$ involves a product of $A$ (regularity $1/2$) and $\\psi$ (regularity $0$), resulting in a spatial regularity of $1/2+0=1/2$. An equation cannot hold if the terms on either side have different spatial regularities ($-1$ vs $1/2$). This fundamental inconsistency invalidates the well-posedness result for the Yang-Mills-Dirac system."
      },
      {
        "Problem": "Inconsistent spatial regularities in the wave equation for the Yang-Mills potential in the Yang-Mills-Higgs system.",
        "Location": "Equation (1.5), Theorem 1.1, Section 3.1",
        "Explanation": "The wave equation for $A_\nu$ includes the term $[\\phi,\\partial_\nu\\phi]$. The stated regularity for $A$ is $B^{1/2}_{2,1}$, implying $\\Box A_\nu$ has spatial regularity $1/2-2=-3/2$. The stated regularity for $\\phi$ is $B^{1/2}_{2,1}$, implying $\\partial_\nu\\phi$ has spatial regularity $1/2-1=-1/2$. The product $[\\phi,\\partial_\nu\\phi]$ has spatial regularity $1/2+(-1/2)=0$. An equation cannot hold if the terms on either side have different spatial regularities ($-3/2$ vs $0$). This fundamental inconsistency invalidates the well-posedness result for the Yang-Mills-Higgs system."
      },
      {
        "Problem": "Inconsistent spatial regularities in the wave equation for the curvature in the Yang-Mills-Dirac system.",
        "Location": "Equation (1.13), Theorem 1.2, Section 3.2",
        "Explanation": "The wave equation for $F_{\\mu\nu}$ includes the term $-A_\\mu(\\overline{\\psi}\\gamma_\nu \\psi)$. The stated regularity for $F$ is $B^{-1/2}_{2,1}$, implying $\\Box F_{\\mu\nu}$ has spatial regularity $-1/2-2=-5/2$. The stated regularity for $A$ is $B^{1/2}_{2,1}$ and for $\\psi$ is $B^0_{2,1}$. The term $\\overline{\\psi}\\gamma_\nu \\psi$ has spatial regularity $0+0=0$. The product $A_\\mu(\\overline{\\psi}\\gamma_\nu \\psi)$ has spatial regularity $1/2+0=1/2$. An equation cannot hold if the terms on either side have different spatial regularities ($-5/2$ vs $1/2$). This fundamental inconsistency invalidates the well-posedness result for the Yang-Mills-Dirac system."
      },
      {
        "Problem": "Inconsistent spatial regularities in the wave equation for the curvature in the Yang-Mills-Higgs system.",
        "Location": "Equation (1.8), Theorem 1.1, Section 3.1",
        "Explanation": "The wave equation for $F_{\\mu\nu}$ includes the term $-[\\partial_\\mu\\phi,[A_\nu,\\phi]]$. The stated regularity for $F$ is $B^{-1/2}_{2,1}$, implying $\\Box F_{\\mu\nu}$ has spatial regularity $-1/2-2=-5/2$. The stated regularity for $A$ is $B^{1/2}_{2,1}$ and for $\\phi$ is $B^{1/2}_{2,1}$. The term $\\partial_\\mu\\phi$ has regularity $-1/2$. The term $[A_\nu,\\phi]$ has regularity $1/2+1/2=1$. The product of $B^{-1/2}$ and $B^1$ has spatial regularity $-1/2+1=1/2$. An equation cannot hold if the terms on either side have different spatial regularities ($-5/2$ vs $1/2$). This fundamental inconsistency invalidates the well-posedness result for the Yang-Mills-Higgs system."
      },
      {
        "Problem": "The angular regularity estimate (Lemma 2.3) is stated trivially and its application in bilinear/multilinear estimates is not mathematically justified.",
        "Location": "Section 2.3, Lemma 2.3, Sections 4 and 5",
        "Explanation": "Lemma 2.3 states $\\|P_{K_{N,L}^\\pm}H_lu\\|_{L^2_{t,x}} \\lesssim N^{-\frac12}L^\frac12l\\|P_{K_{N,L}^\\pm}H_lu\\|_{L^2_{t,x}}$, which is a trivial inequality ($1 \\lesssim N^{-1/2}L^{1/2}l$) on the $L^2_{t,x}$ norm itself. The proofs in Sections 4 and 5 apply factors like $N_i^{-1/2}L_i^{1/2}l_i$ to the product of input norms within the bilinear/multilinear estimates. This application is not supported by the stated lemma or standard techniques for $X^{s,b}$ spaces and their angular refinements. This undermines the core argument that angular regularity provides the necessary gain to reach the claimed regularities, especially for terms without null structure."
      }
    ],
    "token_usage": {
      "input": 50169,
      "thinking": 17709,
      "output": 1334
    }
  },
  {
    "entry_id": 37,
    "retraction_id": "1708.02698v3",
    "paper_id": "1708.02698v2",
    "retraction_comment": "It turns out that there is an error in the argument for the curve case in Lemma 2.5 which makes the main result (Theorem 2.4) partially incorrect. We will post a modified version of the paper in which this is fixed. Meanwhile we withdraw the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof does not establish that the final algebra $R^{(d)}$ is a semigroup algebra $\\k[S]$ for $S \\subset \\N \\times \\Z^d$.",
        "Location": "Theorem \\ref{th-projective-degeneration}, property (b') and the conclusion that $X_d$ is a projective toric variety.",
        "Explanation": "The proof constructs a sequence of algebras $R^{(i+1)} = \\gr_v(R^{(i)})$, where $v$ is a valuation derived from a specific prime ideal. While Theorem \\ref{th-finite-generation-symbolic-gr} guarantees finite generation and Proposition \\ref{prop-ass-graded-domain} guarantees $R^{(i)}$ are domains, and the construction ensures a $\\G_m^i$ action on $X_i$ with an $i$-dimensional moment polytope (after twisting), these properties do not imply that $R^{(d)}$ is isomorphic to a semigroup algebra $\\k[S]$ for $S \\subset \\N \\times \\Z^d$. This isomorphism is necessary for $X_d = \\Proj(R^{(d)})$ to be a projective toric variety as defined (closure of a torus orbit)."
      },
      {
        "Problem": "The construction of the flat family using the Rees algebra does not result in a degeneration of the sequence of varieties $X_i = \\Proj(R^{(i)}, d_i)$ to $X_{i+1} = \\Proj(R^{(i+1)}, d_{i+1})$, where $d_i$ is the grading inherited from the previous step.",
        "Location": "Section 2.2, Proof of Theorem \\ref{th-projective-degeneration}, specifically the definition of $X_i$ and properties (a'), (c').",
        "Explanation": "The variety $\\Proj(R)$ depends on the choice of positive grading on $R$. The proof defines $X_i = \\Proj(R^{(i)})$ but the grading is implicitly assumed to be consistent throughout the sequence of degenerations. However, the Rees algebra construction $\\mathcal{A}^{(i)} = \\mathcal{R}_{v_i}(R^{(i)})$ induces a new grading on the special fiber $R^{(i+1)} \\cong \\mathcal{A}^{(i)}/(t)$ and a different grading on the general fiber $R^{(i)} \\cong \\mathcal{A}^{(i)}/(t-a)$. The general fiber $\\Proj(\\mathcal{A}^{(i)}/(t-a))$ is $\\Proj(R^{(i)})$ equipped with a grading induced by the valuation filtration, which is generally different from the grading $R^{(i)}$ inherited as the special fiber from step $i-1$. Thus, the general fiber is not isomorphic to $X_i$ as a projective variety."
      }
    ],
    "token_usage": {
      "input": 20361,
      "thinking": 23723,
      "output": 628
    }
  },
  {
    "entry_id": 38,
    "retraction_id": "1201.3873v3",
    "paper_id": "1201.3873v2",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial gap in the estimates for m>=4",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect identification of polynomial coefficients for m >= 4",
        "Location": "Section 3 (for m=4) and Section 4 (for m >= 6)",
        "Explanation": "When considering polynomials of the form (az_1^2 + bz_2^2 + cz_1z_2)^n, the coefficients of the resulting m=2n homogeneous polynomial are sums of terms involving a, b, c. The paper incorrectly treats individual terms from the expansion (or parts of coefficients) as the actual coefficients of the polynomial when applying the Bohnenblust-Hille inequality. For example, for m=4, the coefficient of z_1^2 z_2^2 is c^2+2ab, but the paper uses c^2 and 2ab separately in the sum of coefficients' powers."
      },
      {
        "Problem": "Incorrect application of the Bohnenblust-Hille inequality for m >= 4",
        "Location": "Section 3 (formula for f_4, g_4) and Section 4 (formula for g_6 and subsequent calculations)",
        "Explanation": "The Bohnenblust-Hille inequality bounds the sum of p-th powers of the *coefficients* of the polynomial. Due to the incorrect identification of coefficients (Problem 1), the paper sums powers of terms that are not the actual coefficients, leading to an incorrect calculation of the left-hand side of the inequality and thus invalidating the derived lower bounds for D_m for all m >= 4."
      },
      {
        "Problem": "Unsound conclusions regarding the hypercontractivity constant and asymptotic behavior",
        "Location": "Section 5",
        "Explanation": "The main conclusions about the lower bound for the hypercontractivity constant C (C >= 1.0845) and the asymptotic behavior of the constants D_m (lim_{m->infty} D_m/D_{m-1} != 1) are derived directly from the lower bounds for D_m calculated in Sections 3 and 4. Since these lower bounds are based on an incorrect method (Problems 1 and 2), the conclusions drawn from them are not supported by the analysis presented."
      }
    ],
    "token_usage": {
      "input": 9316,
      "thinking": 7880,
      "output": 497
    }
  },
  {
    "entry_id": 39,
    "retraction_id": "1006.2189v2",
    "paper_id": "1006.2189v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The proof of the verification of axiom 1 for the smoothing functor that is given in the paper is false, since it would violate what is known in dimension 4. If U is a subset of V and both are diffeomorphic to R^4, then the restriction map of smoothing spaces sm(V) -> sm(U) need not be one-to-one on path components. Thus axiom 1 is violated in dimension 4. The verification of axiom 1 in higher dimensions is probably a consequence of the product structure theorem",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 13024,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 40,
    "retraction_id": "1207.1467v2",
    "paper_id": "1207.1467v1",
    "retraction_comment": "This paper has been withdrawn due to a logica error in equation 1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation showing equivalence of Bird model (with advection) and linear model.",
        "Location": "Section 3.1, after equation (25)",
        "Explanation": "The mathematical steps presented to show that including the advective term involving the air velocity ($\\diver(\\rho^{g_v} \\bv{g_a})$) in the Bird model leads back to the linear advection-diffusion equation are incorrect. Specifically, the expansion and rearrangement of the divergence terms do not follow standard vector calculus rules and algebraic manipulation."
      },
      {
        "Problem": "Incorrect justification for neglecting viscous forces in momentum equation.",
        "Location": "Section 4, first paragraph",
        "Explanation": "The paper claims that viscous forces are negligible when the Péclet number ($Pe$) is approximately 1. The Péclet number is the ratio of advective transport rate to diffusive transport rate, while the ratio of inertial forces to viscous forces is characterized by the Reynolds number. Neglecting viscous forces is only justified when the Reynolds number is small (Stokes flow), not based on the Péclet number."
      },
      {
        "Problem": "Potentially incorrect nondimensionalization of the momentum equation.",
        "Location": "Section 4, after equation (36)",
        "Explanation": "The resulting dimensionless coefficients in the nondimensionalized momentum equation, such as $\\frac{D^2}{L^2 R^{g_v} T}$ and $\\frac{Lg}{R^{g_v} T}$, do not appear to correspond to standard dimensionless groups obtained from scaling the momentum equation. This suggests a potential error in the nondimensionalization process or the choice of characteristic scales, which affects the subsequent magnitude analysis."
      },
      {
        "Problem": "Unjustified conclusion about negligible bulk velocity from natural convection.",
        "Location": "Section 4 and Conclusions",
        "Explanation": "The conclusion that natural convection currents (driven by density gradients) result in a negligibly small bulk velocity compared to diffusion is based on the analysis of the simplified and potentially incorrectly nondimensionalized momentum equation. The analysis presented does not provide a rigorous basis to conclude that the bulk velocity is always negligible in the absence of external forcing."
      },
      {
        "Problem": "Overstated claim regarding the novelty of the thermal diffusion mechanism.",
        "Location": "Section 3.3 and Conclusions",
        "Explanation": "The paper presents the effect of temperature-dependent diffusion coefficient and saturated vapor density on the Fickian flux as an 'alternative explanation' or different 'mechanism' for thermally enhanced diffusion compared to deVries. While the analysis correctly shows how temperature gradients affect diffusion within the standard Fickian framework for mass density, it is not clearly demonstrated how this mechanism is fundamentally different from or an alternative to the mechanism implied or formulated in classical models like deVries, which also account for temperature effects on vapor transport."
      }
    ],
    "token_usage": {
      "input": 21358,
      "thinking": 12117,
      "output": 639
    }
  },
  {
    "entry_id": 41,
    "retraction_id": "1503.03121v2",
    "paper_id": "1503.03121v1",
    "retraction_comment": "This paper has been withdrawn by the author because the duality is indefensible speculation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified Scale Factor Matching Condition",
        "Location": "Section 2, Eq. (11) and subsequent calculation",
        "Explanation": "The calculation of the CBE period relies critically on matching the contracting scale factor $\\hat{a}(t)$ at $t_m=47ky$ (time from bounce) to the expanding scale factor $a(t)$ at $t_m=47ky$ (time from Big Bang). This implies the bounce is the Big Bang, but the matching point is far from $t=0$. This specific matching condition $\\hat{a}(t_m) = a(t_m)$ is arbitrary and not derived from fundamental physics or a requirement for a smooth transition at or near the bounce, invalidating the calculated period of 2.6 Ty."
      },
      {
        "Problem": "Arbitrary Definition of Extroverse Radius",
        "Location": "Section 1, Eq. (9) and Section 2, Eq. (14)",
        "Explanation": "The extroverse radius $R_{EV}(t)$ for $t \\geq t_{DE}$ is defined as simply scaling with the expansion scale factor $a(t)$ from its value at $t_{DE}$. This definition $R_{EV}(t) = \\frac{a(t)}{a(t_{DE})}R_{IV}(t_{DE})$ is not based on standard cosmological horizon definitions (like event horizons) that describe causally disconnected regions in an accelerating universe. This arbitrary definition is crucial for calculating the ratio $f(t_T) = R_{IV}(t_T)/R_{EV}(t_T)$ and subsequently the turnaround time $t_T$, undermining the period calculation."
      },
      {
        "Problem": "CBE Entropy Handling for the Entire Universe",
        "Location": "Section 1, Abstract, Section 4",
        "Explanation": "The CBE model addresses the second law of thermodynamics for the 'introverse' (the particle horizon) by assuming that entropy generated in the 'extroverse' (outside the particle horizon) is 'jettisoned'. However, the extroverse is simply defined as the region containing entropy that is causally disconnected from the introverse. The model does not explain what happens to the extroverse; if it continues to exist, the total entropy of the universe (introverse + extroverse) is still increasing, and the model only achieves a low-entropy state for a selected sub-region, not the universe as a whole."
      },
      {
        "Problem": "CCC Entropy Handling Relies on Unproven Black Hole Entropy Loss",
        "Location": "Section 3, Eq. (18), Section 4",
        "Explanation": "The viability of Penrose's CCC model regarding the second law, as presented, hinges on the assumption that black hole entropy is lost during evaporation. This contradicts the widely accepted view in theoretical physics (supported by AdS/CFT duality, which is mentioned) that information and entropy are preserved. If entropy is preserved, the vast entropy in black holes would be transferred to the subsequent aeon, preventing the universe from returning to a low-entropy state necessary for infinite cyclicity in the manner described by Penrose. The paper acknowledges the debate but proceeds as if entropy loss is possible, which is a critical, unproven assumption for CCC's claimed solution to the entropy problem."
      },
      {
        "Problem": "Weak Basis for Duality Speculation",
        "Location": "Section 4",
        "Explanation": "The speculation that CBE and CCC models are related by a non-trivial isomorphism is based on the premise that both models successfully solve the problem of constructing an infinitely cyclic cosmology consistent with the second law of thermodynamics. However, both models appear to rely on questionable or unproven assumptions regarding entropy handling (discarding regions vs. unproven entropy loss in black hole evaporation). This weakens the foundation for claiming they are two valid solutions to the same difficult problem and thus the basis for the proposed duality."
      }
    ],
    "token_usage": {
      "input": 6402,
      "thinking": 4756,
      "output": 876
    }
  },
  {
    "entry_id": 42,
    "retraction_id": "2405.12710v3",
    "paper_id": "2405.12710v2",
    "retraction_comment": "The author has withdrawn this paper due to a critical definitional error in concept learning for global/local-interaction learning during training. This error led to an alignment issue with the definition of the text-video retrieval task, causing an unfair comparison with state-of-the-art (SOTA) methods. Consequently, this hindered the accurate evaluation of the paper's contributions",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect theoretical complexity analysis",
        "Location": "Introduction, Sec 4.2, Table 5",
        "Explanation": "The paper claims the complexity is $\\mathcal{O}(N_tN_v(1+N_q))$, which only accounts for the final similarity matrix computation. It omits the significant computational cost of the GIM and LIM modules per text-video pair, which involves attention mechanisms dependent on $N_f$, $N_w$, $N_q$, and $N_L$. The actual complexity per pair is much higher, invalidating the theoretical efficiency claim."
      },
      {
        "Problem": "Unfair comparison of FLOPs",
        "Location": "Table 1, Table 5, Sec 4.2",
        "Explanation": "The reported FLOPs only include the 'similarity calculation head,' which is defined inconsistently across methods. For GLSCL and similar methods, this is just the final dot product, while for methods like X-CLIP and X-Pool, it includes their computationally intensive cross-modal interaction modules. This makes GLSCL appear orders of magnitude more efficient than it is in terms of the total computation required to obtain the similarity score for a pair."
      },
      {
        "Problem": "Overstated efficiency claims",
        "Location": "Abstract, Introduction, Sec 4.2",
        "Explanation": "Based on the flawed complexity analysis and unfair FLOPs comparison, the paper claims GLSCL is 'nearly 220 times faster' or has '220 times reduced' computational cost compared to SOTA methods like X-CLIP. While Table 5 shows GLSCL is faster than X-CLIP and X-Pool in terms of inference time, the speedup factor is much smaller (e.g., ~1.2x vs X-CLIP), not 220x. This significantly overstates the practical efficiency gain."
      }
    ],
    "token_usage": {
      "input": 35709,
      "thinking": 5707,
      "output": 425
    }
  },
  {
    "entry_id": 43,
    "retraction_id": "1305.5284v3",
    "paper_id": "1305.5284v2",
    "retraction_comment": "This paper has been withdrawn by the author due to missing phase-space factor in eq(1)/(2), thus the whole structure is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound argument for a pure gluon plasma phase at high temperature.",
        "Location": "Section 'Why Glasma?', argument based on Eq. (1) and (2)",
        "Explanation": "The argument that high temperature favors a pure gluon plasma because the ratio of boson to fermion occupancy approaches infinity as E/T approaches 0 is a misapplication of statistical mechanics. While gluons dominate the degrees of freedom at high T, thermal equilibrium at high temperatures includes both quarks and gluons. The argument does not demonstrate that quarks are absent or significantly suppressed in a thermal phase at high T."
      },
      {
        "Problem": "Unjustified claim of zero photon and dilepton emission from Glasma.",
        "Location": "Section 'Why Glasma?', paragraph starting 'Then photon emission rate...'",
        "Explanation": "The paper claims Glasma emits no photons or dileptons because typical processes involve quarks. However, Glasma is a non-equilibrium state of strong color fields. While thermal emission rates might be suppressed if quarks are truly absent, emission from the non-equilibrium color fields themselves is not necessarily zero and is not addressed or ruled out."
      },
      {
        "Problem": "Highly speculative and unfounded cosmological claims.",
        "Location": "Last two paragraphs of the paper",
        "Explanation": "The proposal that Glasma constitutes dark matter and dark energy is based on loose analogies (non-shining, energy density gradient) and lacks any rigorous theoretical or quantitative basis within established cosmological models. Glasma in heavy ion collisions is a transient state, unlike the stable components required for dark matter and dark energy."
      },
      {
        "Problem": "Explanation for heavy ion puzzles relies on unsound premises.",
        "Location": "Section 'Motivated by this Glasma piture...'",
        "Explanation": "The proposed resolution to the photon/dilepton v2 and pp enhancement puzzles depends critically on the existence of a prolonged, high-temperature phase (Glasma) that emits no electromagnetic radiation. Since the arguments for the existence of a pure-gluon thermal phase and its absolute lack of emission are unsound, the explanation offered for these experimental puzzles is not well-supported."
      }
    ],
    "token_usage": {
      "input": 7292,
      "thinking": 2953,
      "output": 479
    }
  },
  {
    "entry_id": 44,
    "retraction_id": "2307.11176v2",
    "paper_id": "2307.11176v1",
    "retraction_comment": "There is an irrecoverable error in Lemma 2.5. There are counterexamples even in case R=Q[x]. The lemma is crucial for the rest of the paper and it does not work unless strong assumptions are made (like: the modules are graded)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition of the filtration on the tensor product module in Lemma 6.1 is non-standard and its properties are not fully justified.",
        "Location": "Lemma 6.1, page 7",
        "Explanation": "Lemma 6.1 defines the filtration on $M = R[w,w^{-1}] \\otimes_{R[w]} M_0$ as $\\cF^iM = \bigcup_{j \\ge 0} w^{i-j} \\otimes \\cF^j M_0$. Interpreting the union as a sum of images of maps $w^{i-j} \\otimes \\id_{\\cF^j M_0}$, this definition is $\\cF^iM = \\sum_{j \\ge 0} w^{i-j} \\otimes \\cF^j M_0$. This sum is over $j \\ge 0$, which is equivalent to $\\sum_{k \\le i} w^k \\otimes \\cF^{i-k} M_0$. This differs from the standard tensor product filtration $\\sum_{k \\in \\Z} w^k \\otimes \\cF^{i-k} M_0$. While the stated definition seems to satisfy $w\\cF^iM = \\cF^{i+1}M$ and $\bigcup_i \\cF^iM = M$, it is not immediately clear that $\\cF^iM$ is a finitely generated $R[w]$-module for all $i$, which is required for $M$ to be regularly $\\Z$-filtered according to Definition 1.2(b) and Lemma 2.1. The proof that $\\cF^iM$ is finitely generated relies on the ascending chain $\bigcup_{j \\ge 0} w^{i-j} \\otimes \\cF^j M_0$ stabilizing, which is true, but the resulting module $\\cF^iM = w^{i-j'} \\otimes \\cF^{j'} M_0$ for some $j'$ depends on $i$. The non-standard nature of this definition and the lack of explicit justification for all required properties of a regularly $\\Z$-filtered module introduce a potential gap in the proof chain, as subsequent results (Lemmas 5.1, 5.2, and Proposition 7.1) rely on $R[w,w^{-1}]\\otimes C_*$ being a complex of regularly $\\Z$-filtered modules."
      }
    ],
    "token_usage": {
      "input": 16362,
      "thinking": 24855,
      "output": 528
    }
  },
  {
    "entry_id": 45,
    "retraction_id": "0804.4876v3",
    "paper_id": "0804.4876v2",
    "retraction_comment": "A counterexample to Theorem 1.2 has been pointed out to the author (x^2+3 reduced modulo 2). The mistake cannot be corrected at this time",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "False claim of unconditional validity for the Kummer-Dedekind correspondence",
        "Location": "Theorem 1.2 and Remark after Theorem 1.2",
        "Explanation": "Theorem 1.2 claims that for any prime ideal p of k, the exponents e_i in the factorization of c(x) modulo p match the ramification indices e(P_i|p) of the primes P_i above p in K. This is false without the standard condition that the characteristic of the residue field of p does not divide the index [O_K : O_k[alpha]]. When this condition is not met, the structure of O_K/pO_K can differ from that predicted by the factorization of c(x) modulo p, causing the ramification indices e(P_i|p) to differ from the polynomial exponents e_i. The paper explicitly claims to remove all artificial constraints, which is incorrect."
      },
      {
        "Problem": "Unsoundness in the proof of Theorem 1.2 for ramified primes",
        "Location": "Section 4, Proof of Theorem 1.2, Steps 2 and 3",
        "Explanation": "The proof attempts to establish the correspondence between factorization exponents/degrees and ramification indices/residual degrees using the action of the decomposition and inertia groups on the set of roots R. It incorrectly assumes that the sets of roots R_i and R_i^{(j)}, defined by the factorization of the reduced polynomial c-bar(x), form single orbits under the action of the decomposition group D and inertia group E respectively. This assumption is not justified and is generally false when the prime is ramified (i.e., when e_i > 1), because the reduction map from the set of roots R to the set of reduced roots R-bar is not a bijection in the presence of ramification, and the preimage of an orbit is generally a union of orbits."
      }
    ],
    "token_usage": {
      "input": 19077,
      "thinking": 17340,
      "output": 427
    }
  },
  {
    "entry_id": 46,
    "retraction_id": "2105.09970v2",
    "paper_id": "2105.09970v1",
    "retraction_comment": "The proof of the main Lemma (3.11, section 3.4) is incomplete: in the middle of page 22, the fact that $\\gamma$ is weakly distributive is not sufficient to justify the chain of two inclusions used to invoke Proposition 2.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound definition and derivation of the recursive formula for $\\mu_n$",
        "Location": "Section 3.4, Equation (3.2)",
        "Explanation": "The derivation of the recursion formula for $\\mu_n (\\underline{ax}^{\\delta_{n-1}(as')} )$ appears incorrect. It mixes horizontal addition and ideal generation in a way that does not align with the algebraic structure, makes unjustified assumptions about the structure of forests contributing to the set, and the condition for stick equivalence seems misapplied. This formula is crucial for constructing the sequence of algebras $\\calM_n^\\alpha$ and $\\calD_n^\\alpha$ for $n>1$."
      },
      {
        "Problem": "Flawed proof of the simulation lemma (Lemma 3.11)",
        "Location": "Section 3.3, Lemma 3.11",
        "Explanation": "The proof relies heavily on the potentially unsound recursive construction of $\\calD_n^\\alpha$. Furthermore, the definition of $\\alpha(\\underline{x}^{(s)})$ used in the proof (as $\\varphi(\\crochet{\\gamma(\\underline{x}^{\\beta(t)}), \\beta(\\underline{x}^{(t)})})$) is specific to $\\alpha$ being a sequential composition and is not generally defined for any $\\calG \\in \\mathbf{*D}$. The proof structure (induction on $n$) does not align well with the claim about any $\\calG \\in \\mathbf{*D}$ (which is defined by iterated wreath products and division)."
      },
      {
        "Problem": "Ambiguity in the definition of stick equivalence for relabeled sticks",
        "Location": "Section 3.2, definition of $\\underline{x}^{(s)} \\simeq^{(\\alpha)}_n \\underline{y}^{(t)}$",
        "Explanation": "The definition of $\\simeq^{(\\alpha)}_n$ relies on $\\mu_j (\\underline{x}^{\\delta_{j-1}(s)} ) = \\mu_j (\\underline{y}^{\\delta_{j-1}(t)} )$ which involves the relation $\\cong$ on relabeled sticks. The definition of $\\cong$ in Section 3.1.1 is based on original pathwords. It is unclear whether $\\cong$ on relabeled sticks compares the original pathwords or the sequences of relabeled nodes. If it compares original pathwords, the relabeling information is ignored by $\\cong$, which seems inconsistent with the recursive definition of $\\mu_n$. If it compares sequences of relabeled nodes, the definition of $\\cong$ needs to be extended to handle pairs of labels."
      },
      {
        "Problem": "Lack of rigorous justification for the spa-to-forest algebra mapping",
        "Location": "Section 3.1",
        "Explanation": "The association of a forest algebra $\\calH^0$ to a spa $\\calH$ and the homomorphism $\\beta^0$ from $\\beta$ are not formally defined or proven to preserve the necessary structure (e.g., $\\beta^0$ being a forest algebra homomorphism, $V^0$ being a submonoid of $(H^0)^{H^0}$ containing translations, recognition equivalence, wreath product equivalence). This forms the foundation for using forest algebras instead of spas and needs more rigorous treatment."
      }
    ],
    "token_usage": {
      "input": 57485,
      "thinking": 5235,
      "output": 757
    }
  },
  {
    "entry_id": 47,
    "retraction_id": "1508.06018v3",
    "paper_id": "1508.06018v2",
    "retraction_comment": "This paper has been withdrawn by the authors due the fact that the main results Proposition 4.1 and Theorem 4.8 are not correct. Anonymous reviewers notice, that In the former the set B\\A is not necessarily nonempty while, in the latter, the formulation and proof are unclear",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and use of the function alpha in the local Lyapunov analysis.",
        "Location": "Proposition 4.1, Equation (4.5), Proof of Proposition 4.1",
        "Explanation": "The function $\\alpha$ in inequality (4.5) is stated as $\\alpha(|x|_\bA)$, implying it is a function of the distance to the set $\bA$. However, its definition in (4.6) is based on $|x-\\underline{M}|$ and specific $x$ values, not solely on the distance to $\bA$. The proof then uses $\\alpha(|x|)$, which is neither consistent with the definition (4.6) nor the required form $\\alpha(|x|_\bA)$. This makes the core Lyapunov-like argument in Proposition 4.1 unsound, as the decrease condition is not shown to be positive definite with respect to the target set $\bA$ in the required manner."
      },
      {
        "Problem": "A key condition in the main theorem is ill-posed or trivial due to the use of infinity.",
        "Location": "Theorem 4.3, Equation (4.10), Corollary 4.4",
        "Explanation": "The condition $\\max\\{\\overline{M}_{\\infty,i}, \\Gamma_{\\eta,i}(\\overline{M}_{\\infty,1},\\ldots,\\overline{M}_{\\infty,i-1},\\overline{M}_{\\infty,i+1},\\ldots,\\overline{M}_{\\infty,n})\\}>M_{0,i}$ is stated as a requirement for the theorem. However, in Corollary 4.2, $\\overline{M}_{\\infty,i}$ is defined as $\\infty$. Substituting this into the condition results in $\\max\\{\\infty, \\ldots\\} > M_{0,i}$, which simplifies to $\\infty > M_{0,i}$. This inequality is always true for any finite $M_{0,i}$, rendering the condition trivial and incapable of serving as a meaningful constraint or playing any role in the theorem's logic regarding the relationship between the 'local stability' and 'global attractivity' regions."
      },
      {
        "Problem": "The motivating example relies on discontinuous ISS-Lyapunov gains, violating the assumptions of the theorems it illustrates.",
        "Location": "Section 5, Equation (5.1), definition of $\\eta$",
        "Explanation": "The example demonstrates the failure of the global small-gain condition using the function $I_p$ in the definition of the gain $\\eta$. $I_p$ is explicitly defined as discontinuous. However, the definition of ISS-Lyapunov functions (Definition 2.4) requires the gains $\\gamma_{ij}, \\gamma_{iu}$ to be $\\cK_\\infty$ functions and $\\eta_i$ to be MAF, which implies continuity. The example's core premise (that global GSGC fails for systems satisfying the assumptions) is not rigorously established with gains that meet the assumptions, undermining the motivation and illustration of the proposed method."
      },
      {
        "Problem": "Assumption on the derivative of the inverse D-path is stated inconsistently with its likely use in the proof.",
        "Location": "Assumption 3.1 (iv), Proof of Proposition 4.1",
        "Explanation": "Assumption 3.1 (iv) bounds the derivative $(\\sigma_i^{-1})'(r)$ for $r$ in a compact subset of $(\\underline{m},\\overline{m})$. This derivative is evaluated at $r = V_i(x_i)$ in the proof of Proposition 4.1. The proof then uses this condition to bound $c_i \\in \\partial\\sigma_i^{-1}(V_i(x_i))$ for $x_i$ in a set $\bK$ defined based on $|x_i|$ norms. There is no clear mapping or argument provided to show that $V_i(x_i)$ for $x_i \\in \bK$ corresponds to values $r$ in a compact subset of $(\\underline{m},\\overline{m})$. This mismatch between the assumption's statement (on $r=V_i(x_i)$ values) and its application (on $|x_i|$ norms) makes the justification for bounding $c_i$ questionable."
      },
      {
        "Problem": "The definition of the target set A in Proposition 4.1 appears disconnected from the D-path property at the boundary.",
        "Location": "Proposition 4.1, Equation (4.7)",
        "Explanation": "The set $\bA$ is defined using $\\underline{g} = \\max_i \\{\\underline{m}, \\Gamma_{\\eta,i}(\\underline{m}, \\ldots, \\underline{m})\\}$, where $\\underline{m} = \\max_i \\underline{M}_i$. The D-path $\\sigma$ is defined on $[a,b]$ with $\\sigma(a) = \\underline{M}$, and the small-gain condition $\\Gamma_\\eta(\\sigma(r)) \\prec \\sigma(r)$ holds for $r \\in (a,b)$. The definition of $\bA$ is based on evaluating the gain function at the point $(\\underline{m}, \\ldots, \\underline{m})$, which is generally different from the D-path starting point $\\underline{M}$ unless all components of $\\underline{M}$ are equal. It is not clear why the set $\bA$ defined this way should be the target set for solutions based on the D-path property holding for $\\sigma(r)$ where $r \\in (a,b)$ and $\\sigma(a)=\\underline{M}$. This disconnect weakens the argument for convergence to $\bA$ from $\bB \\setminus \bA$."
      }
    ],
    "token_usage": {
      "input": 31086,
      "thinking": 8088,
      "output": 1257
    }
  },
  {
    "entry_id": 48,
    "retraction_id": "1310.8403v3",
    "paper_id": "1310.8403v2",
    "retraction_comment": "This paper has been withdrawn as a bug has been discovered in the proof of Claim 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of anchored rectangles used in the context of the maximum packing problem.",
        "Location": "Section 1.2, condition (ii)",
        "Explanation": "The definition requires anchored rectangles to not contain any other point of P in their interior. This is not the standard definition for the maximum area anchored rectangle packing problem, where rectangles in the packing are only required to be interior-disjoint from each other, not empty of other points from P. This invalidates subsequent arguments that rely on properties of 'empty' rectangles like V(p1) and H(p1) in relation to the rectangles in the maximum packing R(Pn)."
      },
      {
        "Problem": "Flawed proof technique in Lemma 2 and Lemma 3.",
        "Location": "Section 2.2, Proofs of Lemma 2 and Lemma 3",
        "Explanation": "The proofs attempt to characterize the MIN-MAX point set by considering perturbations of points that bound 'empty' rectangles (V(p1), H(p1)). The arguments incorrectly assume that moving such a point only affects a limited number of rectangles in the maximum packing in a simple, predictable way. The maximum packing configuration is globally determined by all points, and perturbing one point can have complex, non-local effects on the optimal packing structure and total area, invalidating the comparisons of areas used in the proofs."
      },
      {
        "Problem": "Missing or fundamentally flawed proof for Theorem 1.",
        "Location": "Section 2.2, Theorem 1",
        "Explanation": "The theorem claims that a MIN-MAX point set must lie on the principal diagonal, which is a crucial step for the final conclusion. However, the proof is missing. The provided sketch is a non-sequitur that incorrectly infers the global minimum area from the minimum area achieved by point sets restricted to the principal diagonal (Lemma 1)."
      },
      {
        "Problem": "The final conclusion (Theorem 2) relies on unproven and flawed intermediate results.",
        "Location": "Section 2.2, Theorem 2",
        "Explanation": "The proof of Theorem 2 directly depends on Theorem 1 (claiming MIN-MAX sets are on the diagonal) and implicitly on Lemma 2 and 3 (attempting to characterize the MIN-MAX set). Since Theorem 1 is unproven and the proofs of Lemma 2 and 3 are unsound, the final conclusion that the maximum area is always greater than 1/2 is not supported by the arguments presented."
      }
    ],
    "token_usage": {
      "input": 9355,
      "thinking": 3429,
      "output": 557
    }
  },
  {
    "entry_id": 49,
    "retraction_id": "2003.05237v3",
    "paper_id": "2003.05237v2",
    "retraction_comment": "There is an issue in the proof of Lemma 3.7: evaluation of the involved classes gives back the same values for the coinvariants and not necessarily for the coefficients themselves. At the moment I do not see how to fix it. The lemma is needed in the proof of the main Theorem",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition and equivariance check for the cochain map used to define the pullback.",
        "Location": "Lemma 3.2",
        "Explanation": "The definition of the map $\\upC^\bullet(F)$ from $\\calB^\\infty((\bbH^n_{\bbC})^{\bullet+1};\bbR)$ to $\\upL^\\infty_{\textup{w}^\\ast}((\bbH^n_{\bbC})^{\bullet+1};\\upL^\\infty(\\Omega))$ and the subsequent check for $\\Gamma_\\ell \times \\Gamma_r$-equivariance appear inconsistent with the stated actions on the domain and codomain complexes. This map is central to defining the pullback in cohomology in Proposition 3.3."
      },
      {
        "Problem": "Flawed derivation relating the pullback of the volume cocycle to the integral of the pullback volume form.",
        "Location": "Lemma 3.4, Equation (4)",
        "Explanation": "The derivation of the coboundary relation in Equation (4) relies on equating the value of the volume cocycle $\\vol_n$ applied to points with the integral of the volume form $\\omega_n$ over a simplex formed by those points, and incorrectly applies the definition of the map $\\upC^{2n}(F)(\\vol_n)$. The volume cocycle $\\vol_n(a_0, \\dots, a_{2n})$ is a scalar value, while $\\upC^{2n}(F)(\\vol_n)(a_0, \\dots, a_{2n})(x)$ is defined as $\\vol_n(\\chi(x)F(a_0,[x]), \\dots, \\chi(x)F(a_{2n},[x]))$, which is also a scalar value for each $(a,x)$. The subsequent steps confuse this scalar value with the integral of the volume form over a simplex. This step is crucial for relating the Euler number to the Jacobian of the natural map in Theorem 3.5."
      },
      {
        "Problem": "Incorrect justification for atomless slices of the boundary map.",
        "Location": "Lemma 3.1",
        "Explanation": "The proof that the boundary map slices are atomless relies on the image of the cocycle $\beta_\\Omega$ being Zariski dense in $\\pu(n,1)$ by Borel Density Theorem. Borel Density Theorem applies to the image of the lattice in the ambient group, not the image of a cocycle into the lattice itself. While the conclusion that slices are atomless is likely true for non-trivial ergodic couplings (e.g., based on the image of the cocycle being unbounded), the provided justification is incorrect."
      }
    ],
    "token_usage": {
      "input": 29203,
      "thinking": 9303,
      "output": 585
    }
  },
  {
    "entry_id": 50,
    "retraction_id": "2203.03600v2",
    "paper_id": "2203.03600v1",
    "retraction_comment": "The main technical result, Lemma 4, has a major error in the proof: The claim in the proof \"... we could decompose $y^i$, and therefore $y$ into at least two sign-compatible, non-zero cycles of $\\mc A$ ...\" is NOT true. This claim is based on our claim in Lemma 3 that the decomposition of cycles $y^i$ into bricks $y^{i^j}$ yields cycles $y^{i^j}$ of the N-fold matrix $\\mc A$. This is not true",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of the main $\\ell_1$-norm bound for N-fold matrices",
        "Location": "Section 4, Lemma 3 (Lemma 4 in the text)",
        "Explanation": "The proof relies on decomposing a vector $y^i$ (which is defined based on a partition of the A-matrix rows and is not necessarily a cycle of the full matrix $\\mathcal{A}$) into vectors $\\yij_k$ with bounded $\\ell_1$ norm. This decomposition step (Lemma 2 in the text, Lemma 3 in the proof) is not correctly justified by the properties of $y$ or the partition structure, and the subsequent application of Steinitz Lemma does not appear to yield a valid decomposition of $y$ into cycles of $\\mathcal{A}$. This invalidates the derived upper bound on the $\\ell_1$-norm of Graver basis elements of $\\mathcal{A}$ and consequently the run time stated in Theorem 1."
      },
      {
        "Problem": "Incorrect calculation of partition parameter $p_B$ for $\\QCmaxcc$",
        "Location": "Section 5.1.3, Corollary 2",
        "Explanation": "The added capacity constraint $\\sum x^i_j \\leq c_i$ introduces a row $(1, \\dots, 1)$ in the $B^{(i)}$ matrix. This row's support $\\{1, \\dots, d\\}$ overlaps with the support of the original row $(p_1, \\dots, p_d)$ (assuming $d \\geq 1$ and at least one $p_j \\neq 0$). The row-support graph for $B^{(i)}$ will have these two rows connected, resulting in a partition parameter $p_B \\geq 2$ (specifically, $p_B=2$ if $d \\geq 2$ and some $p_j \\neq 0$, or $p_B=d$ if $d=1$), not 1 as used in the analysis. This affects the derived run time."
      },
      {
        "Problem": "Incorrect calculation of partition parameter $p_B$ for $\\QCmaxr$ and $\\QCmaxd$",
        "Location": "Section 5.1.3, Corollary 3",
        "Explanation": "For $\\QCmaxr$, the constraints $s^i_j - s^i_{j-1} - p_{j-1} x^i_{j-1} \\geq 0$ for $j=2, \\dots, d$ introduce rows in $B^{(i)}$ whose supports overlap on the $s^i_j$ variables. These $d-1$ rows, along with the $s^i_d + \\pmax x^i_d \\leq s_i T$ row, form a connected component in the row-support graph of size at least $d$. Thus, $p_B$ should be at least $d$, not 1. For $\\QCmaxd$, the constraints $s^i_j + p_j x^i_j \\leq d_j$ also introduce overlaps. The partition parameter $p_B$ for $\\QCmaxd$ is $\\bigO(d)$, not 1. This significantly affects the derived run times."
      },
      {
        "Problem": "Inconsistent application of the run time formula from Theorem 1 in application corollaries",
        "Location": "Section 5, Corollaries 1, 2, 3, 4, 5",
        "Explanation": "The run time formula in Theorem 1 includes factors $nt \\log(nt)$ and $(S_A)^{\\bigO(r+s)}$ which depend on problem-specific parameters ($d, k, m, |V(G)|$). In several corollaries, these factors appear to be omitted or absorbed into other terms (e.g., $d^{\\bigO(d)}$ from $(S_A)^{\\bigO(r+s)}$ for QCmax/QCmin, or $k \\log(|V(G)| k)$ for Minimum Sum Coloring) without clear justification based on the relative sizes of parameters. The stated run times may therefore be understated compared to the full bound derived from Theorem 1 and the calculated parameters."
      },
      {
        "Problem": "Incorrect exponent in the run time for $\\RCmax$",
        "Location": "Section 5.2",
        "Explanation": "Based on the derived parameters $r=(d+1)^K, s=2, p_A=1, p_B=1, S_A=(d+1)^K, \\Delta=\\pmax$, the exponent in the $(p_A p_B \\Delta)$ term of the run time from Theorem 1 is $\\bigO(r p_A p_B + s p_A p_B) = \\bigO((d+1)^K \\cdot 1 \\cdot 1 + 2 \\cdot 1 \\cdot 1) = \\bigO((d+1)^K)$. The claimed exponent $\\bigO(K d^K)$ in the corollary is different from this derivation."
      }
    ],
    "token_usage": {
      "input": 20737,
      "thinking": 22732,
      "output": 1155
    }
  },
  {
    "entry_id": 51,
    "retraction_id": "2001.10983v3",
    "paper_id": "2001.10983v2",
    "retraction_comment": "A case in the proof of Proposition 2.8 was overlooked (thanks to [REDACTED-NAME] for pointing out this) and I withdraw the paper until that gap is filled",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof for generating the Weyl group from a set of minimal norm vectors.",
        "Location": "Section 2.3, Proposition 2.3.1 and Lemma 2.3.3",
        "Explanation": "The proof of Lemma 2.3.3, which claims that every root vector admits a 'good sequence' allowing its reflection to be generated by reflections of a given set of minimal norm vectors spanning the lattice, is incorrect. The argument that $u_0-v$ has a shorter length and belongs to the set of roots without a good sequence is not justified. This invalidates Proposition 2.3.1 and the subsequent conclusion that the monodromy group is $W(E_6)$."
      },
      {
        "Problem": "Incorrect assumption that birational equivalence implies isomorphism of $H^0(\\Omega^p)$ for $p < \\dim$.",
        "Location": "Section 3.3, Equation (\\ref{eq_geometry_trivial})",
        "Explanation": "The argument claims that because $\\mathcal{X}_T$ is birational to $T \times X_H$, their spaces of holomorphic $(n-1)$-forms are isomorphic ($H^0(\\Omega^{n-1}_{\\mathcal X_T}) \\simeq H^0(\\Omega^{n-1}_{T\times X_H})$). This is generally false for $p < \\dim$. Birational maps do not preserve $H^0(\\Omega^p)$ for $p$ less than the dimension of the varieties."
      },
      {
        "Problem": "Incorrect short exact sequence relating differential forms on a divisor to the ambient space.",
        "Location": "Section 3.3, Equation (\\ref{eq_ses_conormal})",
        "Explanation": "The sequence $0 \to \\Omega^{p-1}_{\\mathcal X_T}(-1,-1) \to \\Omega^p_{T\times X}|_{\\mathcal X_T} \to\\Omega^p_{\\mathcal X_T}\to 0$ used to relate differential forms on the smooth divisor $\\mathcal{X}_T$ to those on the ambient space $T \times X$ is incorrect for $p > 1$. The standard sequence involves the conormal bundle, which is $\\mathcal{O}_{\\mathcal{X}_T}(-1,-1)$ in this case, but the exterior power structure is different."
      },
      {
        "Problem": "Invalid application of Kodaira vanishing based on incorrect sequences.",
        "Location": "Section 3.3, following Equation (\\ref{eq_ses_conormal})",
        "Explanation": "The conclusion that the composition $H^q(\\Omega_{T\times X}^p)\to H^q(\\Omega^p_{T\times X}|_{\\mathcal X_T}) \to  H^q(\\Omega^p_{\\mathcal X_T})$ is an isomorphism for $p+q<n$ is derived from long exact sequences associated with the incorrect short exact sequences (\\ref{eq_ses_define}) and (\\ref{eq_ses_conormal}). This invalidates the derived isomorphism $H^0(\\Omega^{n-1}_{\\mathcal X_T})\\simeq H^0(\\Omega^{n-1}_{T\times X})$. "
      },
      {
        "Problem": "False contradiction derived from incorrect comparison of Hodge numbers.",
        "Location": "Section 3.3, comparison of (\\ref{eq_geometry_trivial}) and (\\ref{eq_geometry_smooth})",
        "Explanation": "The argument concludes $H^0(\\Omega_{X_H}^{n-1})\\simeq H^0(\\Omega_X^{n-1})$. For $d>n>1$, $H^0(\\Omega_{X_H}^{n-1}) \neq 0$ while $H^0(\\Omega_X^{n-1}) = 0$, leading to a contradiction $0 \neq 0$. However, this comparison is based on the flawed steps (Problems 2, 3, and 4) regarding the relation between Hodge numbers of $\\mathcal{X}_T$, $T \times X_H$, and $T \times X$. The derived contradiction is therefore invalid, and the proof of the theorem is unsound."
      }
    ],
    "token_usage": {
      "input": 20181,
      "thinking": 6032,
      "output": 949
    }
  },
  {
    "entry_id": 52,
    "retraction_id": "2307.05226v3",
    "paper_id": "2307.05226v2",
    "retraction_comment": "The paper has been withdrawn because of the basic mistake: the map $f$ has in general rank q, not p < q (Section 3)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumptions about the pullback foliation structure",
        "Location": "Section 3, Proposition 3.2 proof",
        "Explanation": "The proof of Proposition 3.2 assumes that the leaves of the reduced pullback foliation \\mathcal{G} are precisely the level sets Y_c = {g=c} for g_i = f_i \\circ \\phi. While the sheaf generated by d(f_i \\circ \\phi) defines the tangent spaces to these level sets, \\mathcal{G} is the reduction of the pullback foliation, and its leaves are not necessarily the full level sets Y_c. The argument using the projection \\pi_c and graph representation of Y_c over Y_0 relies on this assumption and properties of Y_c that are not guaranteed for the leaves of \\mathcal{G} in general."
      },
      {
        "Problem": "Unclear application of Saito's theorem",
        "Location": "Section 5, Proof of Proposition 4.1",
        "Explanation": "The application of Saito's theorem (Theorem 1.4) to derive the ideal membership y_s^N \\cdot \\tau_J \\in \\sum_{i=1}^q \\widetilde{df_i} \\wedge \\Omega^{n-p-1} is not clearly justified. Theorem 1.4 is stated for elements in a free module over a noetherian ring, typically applied to sequences of elements defining a complex. Its application to differential forms in this specific context, involving the forms \\tau_J and \\widetilde{df_i}, requires a more explicit and verified setup."
      },
      {
        "Problem": "Unjustified inclusion of differential form ideals",
        "Location": "Section 5, Proof of Proposition 4.1",
        "Explanation": "The inclusion \\sum_{i=1}^q \\widetilde{df_i} \\wedge \\Omega^{n-p-1} \\subset \\sum_{j=1}^n \\phi_j \\cdot \\Omega^{n-p} used in Section 5 lacks justification. The forms \\widetilde{df_i} = d(f_i \\circ \\phi) are related to the pullback of the ideal defining X, while the forms \\phi_j \\cdot \\Omega^{n-p} are related to the components of the map \\phi. There is no clear reason or standard result provided to support this inclusion, which is crucial for the subsequent steps."
      },
      {
        "Problem": "Misapplication of Lemma 5.1",
        "Location": "Section 5, Proof of Proposition 4.1",
        "Explanation": "The final contradiction step misuses the derived ideal membership and Lemma 5.1. The derived membership, evaluated on a slice, is a^N \\cdot \\det(\\partial\\psi_i / \\partial y_j) \\in \\langle \\tilde{\\phi}_1, \\dots, \\tilde{\\phi}_n \\rangle, where \\psi = (\\phi_1, \\dots, \\phi_p)|_{L_a} and \\tilde{\\phi} = \\phi|_{L_a}. Lemma 5.1 states that the Jacobian of a finite map \\chi: (\\mathbb{C}^p, 0) \\to (\\mathbb{C}^p, 0) is not in the ideal generated by its components \\langle \\chi_1, \\dots, \\chi_p \\rangle. The paper applies this lemma to \\psi, but the ideal derived from the previous steps is \\langle \\tilde{\\phi}_1, \\dots, \\tilde{\\phi}_n \\rangle, which is generated by all n components of \\tilde{\\phi}, not just the p components of \\psi. The ideal \\langle \\psi_1, \\dots, \\psi_p \\rangle is different from \\langle \\tilde{\\phi}_1, \\dots, \\tilde{\\phi}_n \\rangle, rendering the contradiction invalid."
      }
    ],
    "token_usage": {
      "input": 13850,
      "thinking": 16495,
      "output": 886
    }
  },
  {
    "entry_id": 53,
    "retraction_id": "1702.07688v4",
    "paper_id": "1702.07688v3",
    "retraction_comment": "I no longer believe that the conclusions are supported by the calculations done in this manuscript. The paper tried to determine what will limit the precision in practice. I incorrectly pointed to small 1 qubit (precision) errors happening everywhere in the circuits",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The error model for 'finite precision on the direction of the measurement' is specific and its generality/physical relevance is not fully justified.",
        "Location": "Page 2, 'finite precision error model' description; Equation 4.",
        "Explanation": "The paper models measurement imperfection by introducing a specific type of error into the CNOT gates used for stabilizer measurement. This error replaces the ideal Z_i operator in the CNOT definition with a rotated operator $\\vec{m}_\\epsilon \\cdot \\vec{\\Sigma}_i$. It is not rigorously established that this specific gate imperfection model is the primary way measurement direction precision limits manifest in physical systems, nor is it proven that this type of error cannot be effectively handled by standard fault-tolerant measurement protocols designed to protect against errors in circuit components."
      },
      {
        "Problem": "The paper's dismissal of standard fault-tolerant measurement circuits is not fully substantiated.",
        "Location": "Page 2, discussion after Figure 2; Figure 1b description.",
        "Explanation": "Fault-tolerant measurement circuits (like the one in Figure 1b) are specifically designed to prevent errors in the measurement apparatus (including CNOT gates and ancillas) from corrupting the logical state or introducing uncorrectable errors. The paper claims these circuits 'do not help here' but does not provide a rigorous analysis or simulation showing that its specific CNOT error model, when used within a complete fault-tolerant measurement scheme, still results in the observed high logical error rate and linear scaling with p_epsilon, thereby defeating the purpose of fault tolerance."
      },
      {
        "Problem": "The interpretation and comparison of the error scaling results could be clearer.",
        "Location": "Abstract, Introduction, Figure 2 caption, Figure 3 caption, Conclusion.",
        "Explanation": "The paper contrasts the quadratic scaling of logical error with discrete error probability (p_d) against the linear scaling with the continuous error parameter (p_epsilon). However, p_epsilon is defined as proportional to the square of the angular deviation (epsilon^2). This means the logical error scales quadratically with epsilon (E_0 \\propto epsilon^2). While this is different from the epsilon^4 scaling expected from standard QEC (if physical error probability is \\propto epsilon^2), presenting it simply as a shift from quadratic to linear scaling based on the parameter p_epsilon might obscure the underlying dependence on the fundamental physical imperfection epsilon."
      }
    ],
    "token_usage": {
      "input": 8148,
      "thinking": 5396,
      "output": 533
    }
  },
  {
    "entry_id": 54,
    "retraction_id": "1408.2493v2",
    "paper_id": "1408.2493v1",
    "retraction_comment": "This paper has been withdrawn by the author. The proof of Theorem 6.2 is incorrect and the Theorem probably fails to be true",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed construction of the $<$-least sequence in Cantor space.",
        "Location": "Theorem 7, Proof (i) $\\Rightarrow$ (ii), definition of $\\beta$",
        "Explanation": "The proof attempts to construct the $<$-least element of $\\mathcal{C}$ that does not meet a decidable set $D_{\\overline \\alpha n}$ in the case where $D_{\\overline \\alpha n}$ is not a bar in $\\mathcal{C}$. The existence and constructibility of such an element is not guaranteed in intuitionistic mathematics. The recursive definition provided for $\\beta^n$ does not appear to define a sequence with the properties required for the subsequent steps of the proof, specifically the claim that $\\overline{\\beta^n}m$ does not belong to $D_{\\overline \\alpha n}$ for any $m$. This invalidates the implication $\\mathbf{CBW}(\\mathcal{N}) \\Rightarrow \\mathbf{OI}(\\mathcal{C})$. This breaks the chain of equivalences claimed in the paper."
      },
      {
        "Problem": "Incorrect claim about the Kleene-Brouwer ordering of constructed sequences.",
        "Location": "Theorem 11, Proof (ii) $\\Rightarrow$ (iii), construction of $\\zeta$",
        "Explanation": "The proof constructs a sequence $\\zeta(m)$ of finite sequences, where $\\zeta(m)$ is the code of the sequence enumerating the $m$ elements of $E_{\\overline \\delta(\\varepsilon(m))}$ in increasing order. The proof claims that this sequence $\\zeta(m)$ is strictly decreasing in the Kleene-Brouwer ordering ($\\<_{KB}$). This claim is false in general. While $E_{\\overline \\delta(\\varepsilon(m))}$ is a proper subset of $E_{\\overline \\delta(\\varepsilon(m+1))}$, the sequence enumerating the larger set in increasing order is not necessarily smaller in the Kleene-Brouwer ordering than the sequence enumerating the smaller set. This invalidates the implication $\\mathbf{Bar} \\subseteq \\mathbf{WF} \\Rightarrow \\mathbf{EnDec?!}$, breaking the chain of equivalences."
      }
    ],
    "token_usage": {
      "input": 92240,
      "thinking": 19072,
      "output": 491
    }
  },
  {
    "entry_id": 55,
    "retraction_id": "2112.06228v2",
    "paper_id": "2112.06228v1",
    "retraction_comment": "Theorem 4.3 is missing the terms corresponding to the linear pentagon equation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof that the map sigma^n is a shuffle algebra morphism.",
        "Location": "Theorem 3.3, Proof",
        "Explanation": "The proof relies on the shuffle product identity for iterated integrals. However, the forms used in the integral representation of the coefficients (specifically, (x^n)/(1-x) dx for n >= 1) do not satisfy the necessary conditions (such as forming a flat connection) for this identity to hold in general. This invalidates the claim that sigma^n is a shuffle algebra morphism, which is crucial for proving that the new series satisfy the pentagon and hexagon equations."
      },
      {
        "Problem": "Misidentification of the coefficients resulting from the virtual poset construction.",
        "Location": "Section 3.3, Equation (4.2), Corollary 4.2",
        "Explanation": "The coefficients defined by the virtual poset operations in Section 3.3 correspond to iterated sums with conditions on the differences between consecutive indices (e.g., n_i - n_{i-1} >= n+1). However, the paper claims these coefficients are equal to truncated multiple zeta values defined by conditions on the indices themselves relative to a parameter m (e.g., m < n_1, n_1+m < n_2, ...). These two types of sums are different, meaning the explicit description of the coefficients of the proposed new associators is incorrect."
      }
    ],
    "token_usage": {
      "input": 40366,
      "thinking": 10396,
      "output": 320
    }
  },
  {
    "entry_id": 56,
    "retraction_id": "1311.7114v2",
    "paper_id": "1311.7114v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the derivation of equation 24 and 25",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for partitioned kinetic energy integrals.",
        "Location": "Section II.B, Kinetic energy integrals subsection",
        "Explanation": "The formula provided for the partitioned kinetic energy integral over s-functions, $\\mathcal{T}_{rs}^{(p)} = -\\frac{1}{2}[ 3\\eta-2\\eta^2 (\\mathbf{R_A}-\\mathbf{R_B})^2]S_{rs}^{(p)}$, incorrectly assumes that the one-electron projection operator $\\theta_p(\\rr)$ can be factored out or treated as a constant when applying the Laplacian operator $\\nabla^2_\\rr$. The Laplacian acts on the basis function $\\phi_s(\\rr)$, and the product $\\theta_p(\\rr)\\nabla^2_\\rr \\phi_s(\\rr)$ must be integrated over space. The provided formula does not correctly account for the spatial dependence of $\\theta_p(\\rr)$ and its interaction with the derivative, rendering the calculated partitioned kinetic energy contributions incorrect."
      },
      {
        "Problem": "Incorrect formula for partitioned nuclear attraction integrals.",
        "Location": "Section II.B, Nuclear attraction integrals subsection",
        "Explanation": "The formula provided for the partitioned nuclear attraction integral over s-functions, $V_{rs}^{(p)} = 2(\\frac{\\zeta}{\\pi})^{1/2}\\sum_\\alpha F_0(\\zeta(\\RR_{P}-\\RR_\\alpha)^2) S_{rs}^{(p)}$, incorrectly assumes that the nuclear attraction potential $\\sum_\\alpha \\frac{Z_\\alpha}{|\\rr-\\RR_\\alpha |}$ can be factored out or treated as a constant over the region defined by $\\theta_p(\\rr)$. The integral requires integrating the product $\\phi_r(\\rr)\\theta_p(\\rr)\\sum_\\alpha \\frac{Z_\\alpha}{|\\rr-\\RR_\\alpha |}\\phi_s(\\rr)$ over space. The provided formula incorrectly relates this integral to the partitioned overlap $S_{rs}^{(p)}$ and a standard Boys function, which is only valid for the full (unpartitioned) nuclear attraction integral, thus leading to incorrect partitioned nuclear attraction energy contributions."
      },
      {
        "Problem": "Incorrect formula for partitioned two-electron integrals.",
        "Location": "Section II.B, Two-electron integrals subsection",
        "Explanation": "The formula provided for the partitioned two-electron integral over s-functions, which involves products of partitioned overlaps $S_{rs}^{(p)}S_{tu}^{(q)}$ and a standard Boys function $F_0(\\tau)$, is fundamentally incorrect. The two-electron integral involves the non-separable Coulomb interaction term $\\frac{1}{|\\mathbf{r}_1-\\mathbf{r}_2|}$ and the two-electron projection operator $\\Theta_{p,q}(\\rr_1,\\rr_2) = \\frac{1}{2}(\\theta_p(\\rr_1)\\theta_q(\\rr_2) + \\theta_p(\\rr_2)\\theta_q(\\rr_1))$. The integral $\\int d\\mathbf{r}_1 d\\mathbf{r}_2 \\frac{\\Theta_{p,q} (\\rr_1,\\rr_2)}{|\\mathbf{r}_1-\\mathbf{r}_2|} \\phi_r(\\mathbf{r}_1)\\phi_s(\\mathbf{r}_1)\\phi_t(\\mathbf{r}_2)\\phi_u(\\mathbf{r}_2)$ cannot be factorized into a product of partitioned one-electron integrals (like overlaps) and a standard Boys function. This formula represents a severe misapplication of standard integral evaluation techniques to the partitioned integrals, invalidating the calculated partitioned two-electron energy contributions."
      }
    ],
    "token_usage": {
      "input": 10854,
      "thinking": 3314,
      "output": 830
    }
  },
  {
    "entry_id": 57,
    "retraction_id": "1206.3652v3",
    "paper_id": "1206.3652v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in Theorem 2.6 under the metric of Grassmannian manifolds induced from the riemannian submersion",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incomplete characterization of complete totally geodesic 2-dimensional submanifolds.",
        "Location": "Theorem 3.2",
        "Explanation": "Theorem 3.2 assumes that the tangent space at the origin is spanned by vectors $\\hat{X}, \\hat{Y}$ satisfying the condition $X^*X = \\lambda I_n$ and $X^*Y = \\mu I_n$. This is a strong, unjustified assumption that does not hold for arbitrary 2-dimensional Lie triple systems in $\\frakm$, which correspond to complete totally geodesic surfaces through the origin in a symmetric space. Thus, the theorem does not characterize all such submanifolds."
      },
      {
        "Problem": "Incorrect formula for the holonomy displacement in the complex case.",
        "Location": "Theorem 3.3 and its proof (case 2)",
        "Explanation": "For a complex totally geodesic surface characterized by Theorem 3.2 (2), the tangent space is spanned by $\\hat{X}, \\widehat{iX}$ with $X^*X = \\lambda I_n$ for some $\\lambda > 0$. The holonomy displacement, calculated using the bundle map from the Hopf bundle and the induced metric, should be $e^{-i\\lambda A(\\gamma)/(2n)} I_n$, where $A(\\gamma)$ is the area on the surface. The stated formula $e^{\\frac{1}{2} A(\\gamma) i}$ implies $-i\\lambda/(2n) = i/2$, leading to $\\lambda = -n$, which contradicts the requirement that $\\lambda > 0$. There is a sign error and a factor error related to $\\lambda$ and $n$ in the formula."
      },
      {
        "Problem": "The main conclusion is only proven for a restricted class of totally geodesic surfaces.",
        "Location": "Theorem 3.3",
        "Explanation": "Theorem 3.3 relies entirely on the characterization of totally geodesic surfaces provided in Theorem 3.2. Since Theorem 3.2 only characterizes a special subset of these surfaces (as noted in Problem 1), the conclusion of Theorem 3.3 is only valid for this restricted subset, not for all complete totally geodesic 2-dimensional submanifolds in $G_{n,m}$ as implied by the abstract and introduction."
      }
    ],
    "token_usage": {
      "input": 13678,
      "thinking": 10903,
      "output": 521
    }
  },
  {
    "entry_id": 58,
    "retraction_id": "1511.00057v2",
    "paper_id": "1511.00057v1",
    "retraction_comment": "Several proofs were found to be incomplete or in error including the proof that quantum rotations can induce arbitrary noise weights. A fully corrected version of this paper is published as: A. Paris, G. Atia, A. Vosoughi, and S. Berman, \"Hidden quantum processes, quantum ion channels, and 1/f-type noise\", [REDACTED-NAME], vol. 30, num. 7, pp. 1830-1929 (2018), doi:https://doi.org/10.1162/neco_a_01067",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Non-standard definition of multi-time quantum state.",
        "Location": "Section 2.2.1, Definition 2.2.1",
        "Explanation": "Standard quantum mechanics defines states at a single time. Multi-time properties are typically described using time-evolved operators or path integrals, not states on tensor products of Hilbert spaces associated with different time points. This definition lacks a clear justification from established quantum principles."
      },
      {
        "Problem": "Non-standard definition of multi-time expectation value.",
        "Location": "Section 2.2.1, Definition 2.2.4",
        "Explanation": "The formula Trace(A₁ ⊗ ... ⊗ Aₙ ⋅ Ψ(t₁, ..., tₙ)) is not the standard method for calculating expectation values of operators at different times in quantum mechanics. Standard methods involve time evolution of operators or states within a single Hilbert space framework. This definition's physical meaning and consistency are dependent on the validity of the non-standard state definition."
      },
      {
        "Problem": "Unjustified construction of Activated Measurement Process.",
        "Location": "Section 2.3, Definition 2.3.6",
        "Explanation": "The differential equations defining the time evolution of the multi-time state Ψ(t₁, ..., tₙ) are not standard in quantum dynamics or measurement theory. Their structure, particularly the equation for ∂/∂tₙΨ(t₁, ..., tₙ), seems inconsistent with the tensor product structure and the marginalization requirement for a formal quantum stochastic process."
      },
      {
        "Problem": "Incomplete Proof of DHAMM Theorem.",
        "Location": "Section 2.5, Proof of Theorem 2.5.2",
        "Explanation": "The proof sketch correctly shows that single-time probabilities in the diagonalizing basis follow a Markov process. However, it fails to demonstrate that the multi-time state Ψ(t₁, ..., tₙ), as defined in the proposed framework, satisfies the properties required for its diagonal elements to represent the joint probabilities of a formal HMM, specifically the multi-time consistency conditions."
      },
      {
        "Problem": "Problematic Definition of Configuration Energy Operator and Ion Activator.",
        "Location": "Section 3.1, Definitions 3.1.1 and 3.1.2, Theorem 3.1.3(ii)",
        "Explanation": "Solving Eq 3.1.1 for a suitable E is non-trivial and its feasibility for relevant K matrices is not shown. Defining Q(T) only by its squared moduli matrix |Q(T)|² means the operator itself is not uniquely determined, introducing ambiguity into the definition of the HQM. The claimed distributional equivalence to the HMM (Thm 3.1.3(ii)) relies on an unproven link between K and |Q(T)|²."
      }
    ],
    "token_usage": {
      "input": 26438,
      "thinking": 8116,
      "output": 650
    }
  },
  {
    "entry_id": 59,
    "retraction_id": "1704.08680v2",
    "paper_id": "1704.08680v1",
    "retraction_comment": "Withdrawn by the author. In particular, Lemma 4 and hence Lemma 5 are incorrect invalidating the claimed result",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 1 regarding the composition of the frontier nodes.",
        "Location": "Section 2.2, Lemma 1",
        "Explanation": "The proof claims that if a minimally violated set C in Phase II has |δ+(C) ∩ T1'| > 1, then the nodes in C incident to these edges (the frontier Δ+(C) ∩ T1') must be Steiner nodes. The argument relies on the reverse-delete step in Phase I, claiming that if a terminal r_j were in the frontier, the edge incident to it in δ+(C) ∩ T1' would have been deleted. This logic is flawed because it assumes connectivity through other parts of C and other frontier edges exists in T1' at the time of deletion, which contradicts the fact that T1' is a tree and edges are kept if essential for terminal connectivity."
      },
      {
        "Problem": "Flawed proof of Lemma 2 relating the number of degree 1 duals to higher degree duals.",
        "Location": "Section 2.2, Lemma 2",
        "Explanation": "This lemma's proof directly depends on the correctness of Lemma 1. Furthermore, it assumes that specific sets of terminals, whose connectivity to the root in T1' defines certain branches, correspond to the minimally violated sets in Phase II (the set $\\mathcal{C}$). The algorithm defines minimally violated sets in Phase II based on the current partial solution T2, not on connectivity in the final T1'. There is no justification that the sets C' constructed in the proof are indeed the sets in $\\mathcal{C}$ used in the current iteration of Phase II."
      },
      {
        "Problem": "Flawed proof of Lemma 3 bounding the cost of short-cut edges.",
        "Location": "Section 2.2, Lemma 3",
        "Explanation": "The lemma attempts to bound the cost of a short-cut edge e_i' by the sum of dual values from Phase I (y^1). The short-cutting operation occurs in Phase III, which uses duals y^3 that grow based on rates determined by T1'. The inequality $c(e_i') \\leq y_{C_1}^1+y_{C_2}^1$ is not justified by the primal-dual process described, as edge costs become tight against the sum of duals *at the time of their inclusion*. The proof seems disconnected from the actual mechanism of Phase III and how the final tree T is constructed and costed."
      },
      {
        "Problem": "Incorrect analysis relating the cost of the final tree to the dual solution.",
        "Location": "Section 2.2, Theorem Proof",
        "Explanation": "The proof attempts to show $c(T) \\leq \\sum_{S} |\\delta_1(S)|y_S^2$. The final tree is T, which is T2' modified by short-cutting in Phase III. The dual solution constructed in Phase III is y^3. The analysis should relate $c(T)$ to $y^3$. The inequality $c(T) \\leq \\left(\\sum_{e \\in T'} y_{C_1(e)}^2+y_{C_2(e)}^2\right) + \\left(\\sum_{e \\in T-T'} \\sum_{S:e \\in \\delta^+(S)} y_S^2\right)$ is not correctly derived from the primal-dual process or the short-cutting operation, relying on the flawed Lemma 3 and misapplying the tightness condition."
      },
      {
        "Problem": "Tight example contradicts the claimed 6/5 approximation ratio.",
        "Location": "Section 2.3, Figure 4 and accompanying text",
        "Explanation": "The paper claims the tight example shows a ratio arbitrarily close to 6/5. The optimal solution is stated to have cost (5/2+2epsilon)k, which corresponds to taking edges {(a_i, r)} and {(b_i, r)}. The algorithm's solution cost is shown to be 3k (e.g., taking edges {(a_i, s_i)}, {(s_i, r)}, and {(b_i, s_i)} after reverse-delete). The ratio is 3k / (k(5/2+2epsilon)) = 3 / (2.5 + 2epsilon), which approaches 3/2 as epsilon approaches 0. This contradicts the claimed 6/5 ratio and the tight example's purpose."
      }
    ],
    "token_usage": {
      "input": 17581,
      "thinking": 11285,
      "output": 1005
    }
  },
  {
    "entry_id": 60,
    "retraction_id": "2406.04846v2",
    "paper_id": "2406.04846v1",
    "retraction_comment": "The claim in this manuscript is incorrect due to a mistake in Eq. (6). The reason is that expression in Eq. (6) is derived in real arithmetic. It is incompatible with the modulo 2 arithmetic in the state ket",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Circular dependency in the recursive construction",
        "Location": "Method section, Figs 1 and 2",
        "Explanation": "The proposed method implements P(alpha)_L using gate teleportation (Fig 2), which requires a |Theta(alpha)>_L state and a P(2*alpha)_L gate. The |Theta(alpha)>_L state is prepared (Fig 1) using P(alpha)_L and P(-alpha)_L gates. This creates a circular dependency where the gate being implemented is required for its own implementation via state preparation."
      },
      {
        "Problem": "Incorrect direction of recursion for angle approximation",
        "Location": "Method section, description of recursion",
        "Explanation": "The paper describes the recursion as P(alpha) <= P(2*alpha), meaning P(alpha) is implemented using P(2*alpha). To approximate an arbitrary angle, one typically builds it from a base angle (like pi/4) by repeatedly combining gates or using magic states for smaller angles. The described recursion goes in the opposite direction (doubling the angle), which is not suitable for approximating arbitrary angles from a fixed base set like {P(pi/4)}."
      },
      {
        "Problem": "Mischaracterization of the logical gate implementation as 'transversal'",
        "Location": "Method section, Eq (4)",
        "Explanation": "Eq (4) describes the logical P(alpha)_L gate as a tensor product of physical P(alpha*v_j) gates with varying angles v_j. The paper claims this is 'transversal'. A transversal gate applies the *same* gate (or its inverse/conjugate) to each physical qubit. This implementation is a product gate, not a transversal gate, and its fault-tolerance properties are not guaranteed by transversality."
      },
      {
        "Problem": "The gate set depends on the desired accuracy epsilon",
        "Location": "Conclusions section",
        "Explanation": "The paper states that the required gate set includes P(pi*l/2^m) where m depends on epsilon. This means the gate set is not fixed and finite, which is a key assumption in the standard Solovay-Kitaev theorem and the Nielsen-Chuang challenge the paper references. The problem being solved is therefore different, making the comparison of gate counts and the claim of not using Solovay-Kitaev in this context potentially misleading."
      },
      {
        "Problem": "State preparation circuit requires the target gate",
        "Location": "Method section, Fig 1",
        "Explanation": "The circuit in Fig 1 prepares the |Theta(alpha)>_L state using the P(alpha)_L gate itself. This state is then used in the gate teleportation circuit (Fig 2) to implement P(alpha)_L. This specific step is the source of the circular dependency, making the state preparation method unsuitable as a primitive for recursively implementing P(alpha)_L from simpler gates."
      }
    ],
    "token_usage": {
      "input": 6273,
      "thinking": 3552,
      "output": 659
    }
  },
  {
    "entry_id": 61,
    "retraction_id": "2306.09163v2",
    "paper_id": "2306.09163v1",
    "retraction_comment": "Theorem 1 is false for A = F_2[x]/(x^3): (A, +) \\cong C_2 x C_2; (A, \\circ) \\cong C_4",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of the numerator in the Galois Correspondence Ratio (GCR) formula.",
        "Location": "Section 1, definition of GCR for Hopf-Galois structure from a skew brace.",
        "Explanation": "The paper states that for a Hopf-Galois structure arising from a skew brace $(B, *, \\circ)$, the GCR is $i(B)/s(B, \\circ)$, where $i(B)$ is the number of left ideals of the brace $B$. For the specific case where $B=A$ is a nilpotent $\\Fp$-algebra with operations $(+, \\circ)$, the paper uses $i(A)$ to denote the number of left ideals of the *algebra* $A$. However, a left ideal of the brace $(A, +, \\circ)$ is a subset $I \\subseteq A$ that is a subgroup of $(A, +)$ (i.e., an $\\Fp$-subspace) and satisfies $a \\circ I \\subseteq I$ for all $a \\in A$. This condition, $a+x+ax \\in I$ for all $a \\in A, x \\in I$, is not equivalent to $I$ being a left ideal of the algebra $A$ (where $ax \\in I$ for all $a \\in A, x \\in I$). The number of brace left ideals is generally different from the number of algebra left ideals, invalidating the use of the latter in the GCR calculation."
      },
      {
        "Problem": "Unsound proof for the equality of the number of subgroups of $(A, \\circ)$ and $(A, +)$.",
        "Location": "Theorem 1 and its proof (Section 2).",
        "Explanation": "Theorem 1 claims that for a finite nilpotent $\\Fp$-algebra $A$, the number of subgroups of the adjoint group $(A, \\circ)$ is equal to the number of subgroups of the additive group $(A, +)$ (which are the $\\Fp$-subspaces of $A$). The proof attempts to establish this equality by arguing that the standard RREF matrix technique used for counting subspaces applies identically to counting $\\circ$-subgroups. However, the $\\circ$-operations ($a \\circ b = a+b+ab$ and $r_\\circ a = ra + \\binom{r}{2}a^2 + \\ldots$) do not correspond to standard elementary row operations on the coordinate matrix in the same way that $+$-operations do. The set of $\\circ$-subgroups is generally different from the set of $+$-subgroups (subspaces), and their counts are not necessarily equal. This invalidates the denominator used in the GCR calculations in subsequent sections."
      }
    ],
    "token_usage": {
      "input": 9587,
      "thinking": 8380,
      "output": 597
    }
  },
  {
    "entry_id": 62,
    "retraction_id": "1607.07976v3",
    "paper_id": "1607.07976v2",
    "retraction_comment": "The statement about approximate equality of phase and group velocities is incorrect. Therefore, all arguments based on this statement are unfounded",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound justification and circularity in the adiabatic assumption and its condition.",
        "Location": "Section IV.A, Page 24-25, Eq. (12)",
        "Explanation": "The core assumption that the plasma evolves very slowly in the Pulse Co-Moving (PCM) frame due to ignorable radiation back-reactions is justified intuitively but not rigorously quantified *before* applying the assumption. The derived necessary condition for adiabaticity (Eq. 12) is obtained *from* the adiabatic model itself, creating a circular argument for its validity. The simulations presented show that this assumption breaks down in the studied regimes, particularly for longer pulses or at higher densities."
      },
      {
        "Problem": "Questionable derivation of the global momentum evolution equation (Eq. 9a).",
        "Location": "Page 27, Eq. (9a)",
        "Explanation": "The step of directly equating the time derivative of the global electromagnetic momentum KF in the laboratory frame to the source term -1/2 ε0 Ew^2, which is related to the rate of change of KF in the PCM frame (Eq. 7b), lacks rigorous justification via Lorentz transformation. This is particularly problematic when the PCM frame velocity (vg) is changing, as described by the subsequent Eq. (9b)."
      },
      {
        "Problem": "Unjustified claim of 'proven equality' of local phase velocities and the concept of 'pure radiation'.",
        "Location": "Abstract, Page 7, Page 21, Section IV.C",
        "Explanation": "The claim of a 'proven equality' between the local phase velocities of the laser pulse and the plasma wave is stated as an observation from simulations, not a theoretical derivation, yet it is used as a fundamental basis for the theoretical approach. Furthermore, the explanation that the laser pulse is 'pure radiation' with equal local phase and group velocities contradicts standard wave physics concepts and is not justified within the paper's framework."
      },
      {
        "Problem": "Inconsistency in the spectral analysis derivation (Eqs. 11a, 11b).",
        "Location": "Page 40, Eqs. (11a), (11b)",
        "Explanation": "The derivation of frequency and wavenumber shifts assumes that the original pump frequency and wavenumber are preserved in the PCM frame (ωPCM = ω0|PCM, kPCM = [k0 + Δk]|PCM). This assumption appears inconsistent with the paper's own Eq. (10), which shows that the carrier frequency and wavenumber (ω0, k0) are evolving in the laboratory frame due to pulse depletion. The spectral shifts should likely be related to the *instantaneous* carrier frequency/wavenumber, not the initial ones."
      },
      {
        "Problem": "Reliance on the relativistic particle analogy for pulse evolution.",
        "Location": "Page 27-28, Eqs. (8), (9b)",
        "Explanation": "The derivation of the group velocity evolution (Eq. 9b) relies heavily on treating the entire pulse as a single relativistic particle with a constant 'rest mass' H0 = HFT|PCM. The constancy of H0 is derived under the adiabatic assumption. Applying this analogy to describe the pulse's evolution, especially in regimes where the adiabatic assumption is shown to break down, is a significant simplification that may not accurately capture the complex dynamics of an evolving wave packet in a nonlinear medium."
      }
    ],
    "token_usage": {
      "input": 13282,
      "thinking": 4166,
      "output": 761
    }
  },
  {
    "entry_id": 63,
    "retraction_id": "2006.15984v5",
    "paper_id": "2006.15984v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial definition error of Canonical Huffman Table",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Non-compliant Huffman Table Structure",
        "Location": "Section 3, Section 4.1.1, Section 4.2, Fig. 4, Fig. 6",
        "Explanation": "The proposed method creates multiple Variable Length Codes (VLCs) for a single Run/Size (RS) symbol and represents this mapping by adding duplicate entries for the same RS value in the HUFFVAL list of the Define Huffman Table (DHT) segment. The JPEG standard requires a unique Huffman code for each unique symbol listed in HUFFVAL. Including the same RS value multiple times with different implied codes is non-standard and will likely cause standard JPEG decoders to fail or produce incorrect results, contradicting the claim that marked images are directly decodable without distortion."
      },
      {
        "Problem": "Invalid Huffman Tree Construction Process",
        "Location": "Section 4.2, Fig. 6",
        "Explanation": "The description and example of building a Huffman tree from a list containing duplicate symbols (estimated post-embedding frequencies for the same NFRS) is not a standard procedure in Huffman coding. Standard algorithms operate on unique symbols to assign a unique code to each. The method does not clearly explain how this non-standard tree construction results in multiple, distinguishable VLCs for a single RS symbol in a way that is compatible with standard JPEG decoding and allows for data embedding and extraction based on which VLC is used."
      },
      {
        "Problem": "Data Extraction Relies on Non-Standard Structure",
        "Location": "Section 5.2, Step 1",
        "Explanation": "The data extraction process begins by parsing the modified DHT segment to reconstruct the customized Huffman table and mapping. If the DHT segment modification (adding duplicate RS entries) results in a non-standard or invalid structure (as suggested by the issues with the table structure and construction), a standard JPEG parser used during data extraction will likely fail to correctly interpret the DHT segment and reconstruct the mapping, preventing successful data extraction and reversibility."
      }
    ],
    "token_usage": {
      "input": 29085,
      "thinking": 4011,
      "output": 443
    }
  },
  {
    "entry_id": 64,
    "retraction_id": "1512.06616v5",
    "paper_id": "1512.06616v4",
    "retraction_comment": "Withdrawn after detection of a major error in the C-E expansion",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The derivation of the diffusive transmission conditions relies on the Maxwell-Boltzmann approximation of Fermi-Dirac statistics, which is not generally valid for graphene.",
        "Location": "Section 4, Section 5.1, Section 5.2, Section 6",
        "Explanation": "The paper approximates the Fermi-Dirac distribution with a Maxwell-Boltzmann distribution (Eq. \\eqref{Mdef}) to simplify the relation between density and chemical potential (Eq. \\eqref{AMB}) and derive the diffusive transmission conditions (Eq. \\eqref{zones}). This approximation is only valid in the non-degenerate limit ($A_s \\ll 0$), which is not generally applicable to graphene, a zero-gap semiconductor where Fermi-Dirac statistics are crucial, especially near the Dirac point. This approximation fundamentally alters the carrier statistics and invalidates the derived boundary conditions and the final model (Eq. \\eqref{QDM}) outside the non-degenerate regime."
      },
      {
        "Problem": "The derivation of the order $\tau$ diffusive transmission conditions from the boundary layer analysis appears incorrect.",
        "Location": "Section 5.2, derivation of Eq. \\eqref{cond1} and \\eqref{zones}",
        "Explanation": "The Chapman-Enskog expansion with boundary layer correction requires the $\\mathcal{O}(\tau)$ terms in the transmission conditions to balance. The correct balance at the interface $x=0$ should involve the non-homogeneous term from the boundary layer equation's boundary condition (Eq. \\eqref{Milne3}), which is $\\mathcal{B}(h)$. The resulting condition on the asymptotic correctors $\tilde{\theta}^\\infty$ should be $2\\mathcal{B}(h|_{\\xi=0}) - \\mathcal{B}(\tilde{\theta}^\\infty) = 0$, not the condition presented in Eq. \\eqref{cond1}. This error leads to incorrect diffusive transmission conditions at order $\tau$ (Eq. \\eqref{zones}) and affects the final proposed model (Eq. \\eqref{QDM})."
      },
      {
        "Problem": "The existence and uniqueness of the asymptotic corrector densities $n_s^{i,\\infty}$ from the described Milne problem system are not rigorously justified.",
        "Location": "Section 5.2, Theorem \ref{T1}, Section 6",
        "Explanation": "The derivation of the diffusive transmission conditions relies on the existence and uniqueness of asymptotic values $n_s^{i,\\infty}$ for the boundary layer corrector $\theta_s^i$. These values are claimed to result from solving a system of coupled Milne problems (Eq. \\eqref{Milne}). However, the Milne problem system presented is non-standard, featuring a density-dependent equilibrium term ($\theta_s^{i,\\mathrm{eq}}$ depends on $\bk{\theta_s^i}$) and a non-homogeneous boundary condition (Eq. \\eqref{Milne3}) that depends on the bulk solution gradients. The paper cites classical results for standard linear Milne problems but does not provide a rigorous justification for the existence and uniqueness of the asymptotic states $n_s^{i,\\infty}$ for this specific, more complex system. Without this, the constants $n_s^{i,\\infty}$ in the final model (Eq. \\eqref{QDM}) are not rigorously defined."
      }
    ],
    "token_usage": {
      "input": 14348,
      "thinking": 7342,
      "output": 716
    }
  },
  {
    "entry_id": 65,
    "retraction_id": "2309.14057v2",
    "paper_id": "2309.14057v1",
    "retraction_comment": "Our description in Chapter 3, Section 3.2 of the paper is too repetitive with the paper \"Object detection meets knowledge graphs\". There is an error in the description of formula (5) in Section 3.3. And a detailed reasoning process is required for formula (5). Therefore, we wish to request a retraction of the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Focal Loss formulation in the multi-label classification network.",
        "Location": "Section 3.3, Equation (5)",
        "Explanation": "The formula for the modulation factor $s_i = e^{-\\log(p_t)}$ is mathematically equivalent to $s_i = 1/p_t$. This is not the standard $(1-p_t)^\\gamma$ modulation used in Focal Loss and results in a loss function that behaves differently, potentially penalizing hard examples more heavily than intended, which could negatively impact the training of the classification network and the quality of generated pseudo-labels."
      },
      {
        "Problem": "Dimensionally inconsistent matrix multiplication in the GRM module.",
        "Location": "Section 3.4, Equation (8), Figure 5",
        "Explanation": "The matrix multiplication $H_v V^{l+1}$ described for fusing graph reasoning output with visual features is dimensionally inconsistent ($H_v \\in R^{C \\times HW}$, $V^{l+1} \\in R^{C \\times D}$). This makes the core operation of the proposed GRM module unclear and potentially unreproducible as described, casting doubt on the validity of the segmentation results attributed to GRM."
      },
      {
        "Problem": "Lack of detailed specification for the semantic relationship matrix construction.",
        "Location": "Section 3.2",
        "Explanation": "The method for constructing the semantic relationship matrix $E$ from ConceptNet using random walks with restarts is described conceptually but lacks specific parameters (e.g., restart probability $\\alpha$, number of steps, handling of ConceptNet edge types/weights). These details are crucial for reproducing the matrix and assessing its quality and properties, which are fundamental inputs to the graph reasoning modules."
      },
      {
        "Problem": "Overstated novelty claim for the classification network component.",
        "Location": "Section 3.3, Section 2.4, Introduction",
        "Explanation": "The multi-label classification network architecture, particularly the integration of GCN with label embeddings and visual features, closely resembles the established ML-GCN framework. While applying this approach to the WSSS classification stage is a valid contribution, presenting it as a fundamentally \"new framework\" or significantly different from existing GCN-based multi-label classification methods might be an overstatement, potentially affecting the perceived novelty of the work."
      },
      {
        "Problem": "Potential negative impact of the incorrect Focal Loss on downstream segmentation.",
        "Location": "Section 3.3, Section 3.4, Section 5.1.2",
        "Explanation": "The segmentation network is trained using pseudo-labels generated by the classification network. Since the classification network is trained using a potentially incorrect Focal Loss formulation (Problem 1), the generated pseudo-labels might be suboptimal or contain unexpected biases. This could negatively impact the training and performance of the downstream segmentation network, potentially affecting the validity of the final segmentation results."
      }
    ],
    "token_usage": {
      "input": 15131,
      "thinking": 7188,
      "output": 656
    }
  },
  {
    "entry_id": 66,
    "retraction_id": "1206.0667v2",
    "paper_id": "1206.0667v1",
    "retraction_comment": "This paper is withdrawn by the author because the paper did not prove the second inequality of (4.3), which is unlikely to hold in general",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of chains and boundaries in cliff-wall surgery.",
        "Location": "Section 2, Definition 2.3, Proposition 2.2, Equation 2.6.",
        "Explanation": "The paper defines chains $\\sigma_F$, $\\sigma_{F;[-+]}$, and $\\sigma_{F;\\Delta^2}$ and states boundary relations between them (Eq 2.6, Prop 2.2, Def 2.3). These relations are contradictory. Specifically, Eq 2.6 implies $\\sigma_F + \\sigma_{F;[-+]}$ is a cycle, while Proposition 2.2 states its boundary is non-empty (a union of triangles). This inconsistency invalidates the construction of the basic Lagrangian cycle $\\sigma_F^{add}$ as a cycle and arguments relying on its cycle property (e.g., Lemma 2.4)."
      },
      {
        "Problem": "Confusion between $T^*\\Delta$ and $M \\times M$ and misidentification of Lagrangians.",
        "Location": "Abstract, Equation 1.1, Section 4 (e.g., Lemma 4.2).",
        "Explanation": "The paper identifies the Lagrangian submanifold $\\phi_{\\mathbb F_i}^1(o_\\Delta)$ (in $T^*\\Delta$) with the graph $\\Graph \\phi_{F_i}^1$ (in $M \\times M$). While $T^*\\Delta$ can be locally identified with a neighborhood of the diagonal in $M \\times M$, these two Lagrangians are generally distinct submanifolds. This confusion affects the geometric interpretation of the basic phase function $f_F$ (defined for Lagrangians in $T^*\\Delta$) and the relationship between the graph selector $\\sigma_F$ (graph of $df_F$ in $T^*\\Delta$) and the Lagrangian $\\phi_F^1(o_\\Delta)$."
      },
      {
        "Problem": "Flawed application of Stokes' theorem in estimating the integral of the generating function.",
        "Location": "Section 3, equation following Lemma 3.3.",
        "Explanation": "The derivation of the key identity $\\int_{\\Tr_{\\CG}(\\phi_{\\mathbb G}^1(o_\\Delta))} \\Theta \\wedge \\Omega_1^n = \\int_{\\Xi} d\\Theta \\wedge \\Omega_1^n + \\int_{\\Xi|_{s=1}} \\Theta \\wedge \\Omega_1^n$ appears incorrect. The dimensions of the forms and chains involved suggest the last term should be zero by dimension, and the equation does not follow from the standard Stokes' theorem applied to the chain $\\Xi$. This invalidates the estimate in Theorem 3.1, which is crucial for the final contradiction argument."
      },
      {
        "Problem": "Incorrect assumption about the location of points on the boundary of the graph selector.",
        "Location": "Section 4, Lemma 4.2 and its proof.",
        "Explanation": "The proof of Lemma 4.2 assumes that a point ${\\bf x}_0$ chosen from $\\del \\Sigma_G$ (the boundary of the closure of the graph of $df_G$ in $T^*\\Delta$) is also contained in $\\Graph \\phi_G^1$ (the graph of $\\phi_G^1$ in $M \\times M$). As discussed in Problem 2, these are generally different sets. This incorrect assumption affects the construction of the surface $C_{{\\bf x}_0{\\bf x}}$ and the subsequent estimate in Theorem 4.3, which is vital for comparing the generating function and the basic phase function."
      }
    ],
    "token_usage": {
      "input": 19218,
      "thinking": 20017,
      "output": 825
    }
  },
  {
    "entry_id": 67,
    "retraction_id": "1503.03000v3",
    "paper_id": "1503.03000v2",
    "retraction_comment": "This paper has been withdrawn by the author because the renormalization constructed in it is not compatible with renormalization in perturbative quantum field theory. Main Theorem of \\S5 is not true",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The mapping from the Moyal product expansion to the sum over graphs and its compatibility with the chosen Hopf algebra structure is not rigorously defined.",
        "Location": "Section 1 (Eq 6 description), Section 2 (Hopf algebra definition)",
        "Explanation": "The description of how the time-ordered Moyal product expansion decomposes into a sum over graphs $U = \\sum_\\Gamma U(\\Gamma)$ is vague, particularly regarding the 'contraction of tensors' using the symplectic form, which doesn't fully capture the Moyal product. The subsequent application of a Hopf algebra structure on abstract graphs relies on a precise correspondence between these abstract graphs and the terms $U(\\Gamma)$, which is not established. The coproduct definition (Eq 8) is based on internal lines and subgraphs, and its compatibility with the structure of terms arising from the Moyal product for general Hamiltonians is not demonstrated."
      },
      {
        "Problem": "The critical 'main technical assumption' regarding the form of divergences is not justified for the broad class of Hamiltonians considered.",
        "Location": "Section 2, paragraph starting 'To overcome this difficulty,'",
        "Explanation": "The assumption that the divergent part $T(U_\\e(\\Gamma))$ is a polynomial in $\\e^{-1}$ and $\\log\\e$ without a constant term is essential for the definition of the projector $T$ and the entire renormalization procedure. While this holds for specific theories and regularizations (like renormalizable QFTs with dimensional regularization), the paper claims to handle 'arbitrary Hamiltonians (local or non-local)'. For such general Hamiltonians, divergences can be more complex, potentially invalidating the assumption and the subsequent construction."
      },
      {
        "Problem": "The convergence of the infinite sum defining the renormalized evolution operator is not addressed.",
        "Location": "Section 2, Definition (Eq 15)",
        "Explanation": "The renormalized evolution operator is defined as an infinite sum over all graphs, $\\tilde U=\\sum_\\Gamma R(\\Gamma)|_{\\e=0}$. For this definition to be mathematically rigorous and represent a non-perturbative object, the convergence of this sum in a suitable topological space (e.g., $SV'$) must be proven. The paper provides no discussion or proof of this convergence, which is a fundamental requirement for a non-perturbative construction."
      },
      {
        "Problem": "The connection between the presented renormalization scheme and standard perturbative QFT results is unclear and requires significant, unexplained steps.",
        "Location": "Section 5, Theorem and Comment",
        "Explanation": "The paper claims its construction recovers standard renormalized perturbative QFT results. However, the 'Comment' states that this requires changing the regularization, transforming the renormalization scheme from 'all graphs' to 'one-particle irreducible graphs', and adding further counterterms. These steps are non-trivial and not explained within the paper's framework. Standard BPHZ renormalization (as in [1]) is typically based on a Hopf algebra structure specific to 1PI graphs. The use of a Hopf algebra of 'all graphs' here, combined with the need for these additional transformations, suggests the presented scheme is not a direct equivalent or generalization of the standard one, and the claim of recovering standard results is not fully substantiated by the provided construction."
      }
    ],
    "token_usage": {
      "input": 7356,
      "thinking": 4306,
      "output": 722
    }
  },
  {
    "entry_id": 68,
    "retraction_id": "2010.16005v2",
    "paper_id": "2010.16005v1",
    "retraction_comment": "There is a potential issue with trilinear estimates and the indices needs to be adjusted",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect assumption about the Fourier transform of the Riesz derivative term.",
        "Location": "Section 3, Proof of Theorem 2, first paragraph",
        "Explanation": "The proof of the trilinear estimate for the term $i u \\p_{|x|}(|u|^2)$ assumes that its Fourier transform is proportional to $-|\\xi| \\widehat{f}*\\widehat{g}*\\widehat{h}$. The term is $u \\p_{|x|}(u\\bar{u})$, and its Fourier transform is $\\widehat{u} * (-|\\cdot| (\\widehat{u} * \\widehat{\\bar{u}}))$. The product rule for the Riesz derivative is not the standard Leibniz rule, and the Fourier transform of the term is a different convolution structure than assumed, invalidating the subsequent estimates."
      },
      {
        "Problem": "Incorrect application of Lemma 3.2 (Calculus Estimates, eq 3.2).",
        "Location": "Section 3, Proof of Theorem 2, after the $\\tau_1$ integral",
        "Explanation": "The integral over $\\xi_1$ is of the form $\\int \\frac{d\\xi_1}{\\langle{}\\tau - \\tau_2 - P(\\xi_1)\\rangle{}^{2b'}}$ where $P(\\xi_1)$ is a cubic polynomial in $\\xi_1$. Lemma 3.2 (eq 3.2) is of the form $\\int \\frac{dx}{\\langle{}x\\rangle{}^{2l}|\\alpha-x|^\frac{1}{2}}$. The integral over $\\xi_1$ does not match the required form for applying Lemma 3.2, rendering this step mathematically unsound."
      },
      {
        "Problem": "Unjustified inequality (3.4) and subsequent steps in the $\\xi_2$ integral.",
        "Location": "Section 3, Proof of Theorem 2, inequality (3.4) and following steps",
        "Explanation": "The inequality (3.4) relating a polynomial in $\\xi_2$ of degree at least 4 to an expression involving $\\langle{}\\xi_2\\rangle{}^{1.5}|\\xi_2-(4\\tau-\\gamma(\\xi))|^{\\frac{1}{2}}|\\xi|^{\\frac{1}{2}}$ is not justified and appears incorrect based on the polynomial degrees. The subsequent application of Lemma 3.2 to the $\\xi_2$ integral relies on this inequality and is therefore also invalid."
      },
      {
        "Problem": "The derived bound for the multiplier norm likely fails near $\\xi=1$.",
        "Location": "Section 3, Proof of Theorem 2, final inequality check",
        "Explanation": "The proof concludes by claiming the bound $\\frac{|\\xi|^{3/4}}{\\langle{}\\tau-\\gamma(\\xi)\\rangle{}^{1-b'}\\langle{}4\\tau-\\gamma(\\xi)\\rangle{}^\frac{1}{4}}\\lesssim{1}$ holds for $b' \\le 3/4$. However, near $\\xi=1$, $\\gamma(\\xi)$ has a simple root. If $\\tau \\approx \\gamma(1)$, the expression behaves like $1/|\\xi-1|^{1/4}$, which is unbounded as $\\xi \\to 1$. This indicates a failure in the preceding estimates leading to this bound."
      }
    ],
    "token_usage": {
      "input": 20202,
      "thinking": 10175,
      "output": 782
    }
  },
  {
    "entry_id": 69,
    "retraction_id": "2305.08639v2",
    "paper_id": "2305.08639v1",
    "retraction_comment": "Proof of Theorem 5.4 is wrong. In particular, the map that is claimed to be a homomorphism, it is not a homomorphism. Also, some of the main results of the paper rely on that Theorem",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of the binary operation (a,b) and derived relations in Lemma 4.2.",
        "Location": "Section 4.1, Definition of N; Section 4.2, Lemma 4.2",
        "Explanation": "The paper defines (a,b) as abab^{-1}a^{-1}b^{-1}, which is a non-standard operation. The derived relations in Lemma 4.2, such as (u^x, l) = (u,x)(x,l^u), do not appear to hold under standard group theory identities, even accounting for the non-standard definition and working modulo [pi, N]. For example, using (ab,c) = (a,c)^b(b,c) and (a,c)^b = (a,c) mod [pi,N], (u^x, l) = (x u x^{-1}, l) = (x u, l)^{x^{-1}} (x^{-1}, l) = (x u, l) (x^{-1}, l) = (x,l)^u (u,l) (x^{-1}, l) = (x,l)(u,l)(x^{-1},l). Using (x^{-1},l) = (l^{-1},x^{-1}) = (x,l), this gives (u^x, l) = (x,l)^2(u,l), which is not the stated relation 3. The incorrect relations undermine the structure of N/[pi,N] and the subsequent calculations of generators and ranks for \\tilde{A}_n, invalidating the proofs of Propositions 4.3, 4.4, and consequently Theorems A, B, and C."
      },
      {
        "Problem": "Flawed proof of the trivial action of G_n^3 on pi/N.",
        "Location": "Section 5.1, Proposition 5.1",
        "Explanation": "The proof claims that for f in G_n^3 (generated by \\sigma_i^3), f acts trivially on \\pi/N. Specifically, it shows \\sigma_i^3(x_i) \\equiv x_i \\bmod(N). However, \\sigma_i^3(x_i) = x_i x_{i+1} x_i x_{i+1} x_i^{-1} x_{i+1}^{-1} x_i^{-1}. The claim that this is congruent to x_i modulo N (generated by (u,v) = uv u^{-1} v^{-1} u^{-1} v^{-1}) is not justified and appears incorrect. For the Johnson homomorphism construction to be valid as presented, the group must act trivially on the quotient group's 'base' (here \\pi/N). If the action is not trivial, the map \\delta and the subsequent homomorphisms \\tau and \\phi are not well-defined as stated, invalidating Theorem A."
      },
      {
        "Problem": "Flawed proof of the trivial action of B_n[3] on pi/M, including unverified complex calculation.",
        "Location": "Section 5.2, Proposition 5.3",
        "Explanation": "The proof claims that for f in B_n[3], f acts trivially on \\pi/M. This relies on the action of \\sigma_i^3 (already questioned in Proposition 5.1) and the action of mod-3 center maps like A. The calculation for A(a_i)a_i^{-1} is presented as extremely long, complex strings of symbols without simplification or justification that they belong to M/[pi,M]. This calculation is impossible to verify as presented and is highly suspicious. If the action of B_n[3] on \\pi/M is not trivial, the homomorphism \\psi and \\psi' are not well-defined as stated, invalidating Theorem C."
      },
      {
        "Problem": "Insufficient proof for the image of the symplectic representation of congruence subgroups.",
        "Location": "Section 3, Proposition 3.1 (Theorem D in the paper)",
        "Explanation": "The proof claims that \\rho(B_n[m]) = Sp_{n-1}(\\mathbb{Z})[m] for n odd, m >= 2. The argument for the inclusion Sp_{n-1}(\\mathbb{Z})[m] < \\rho(B_n[m]) is flawed. It shows that any element b in Sp_{n-1}(\\mathbb{Z})[m] is in \\rho(B_n[2]) and satisfies \\rho(\\sigma) \\equiv I \\pmod m for some \\sigma in B_n[2]. This only implies b is in \\rho(B_n[2]) \\cap Sp_{n-1}(\\mathbb{Z})[m], not necessarily in \\rho(B_n[m]) (which requires \\sigma to be in B_n[m]). The definition of B_n[m] is the kernel of the mod-m representation, not the preimage of the mod-m congruence subgroup under \\rho. This invalidates Proposition 3.1 and affects Theorem D."
      },
      {
        "Problem": "Incorrect method used to prove Lemmas 3.2 and 3.3 by dividing short exact sequences.",
        "Location": "Section 3, Lemma 3.2 and Lemma 3.3",
        "Explanation": "Both lemmas attempt to prove isomorphisms between quotient groups by 'dividing' short exact sequences. This operation is not generally valid in group theory. Given exact sequences 1 -> A -> B -> C -> 1 and 1 -> A' -> B' -> C' -> 1 with A' subset A, B' subset B, C' subset C, the sequence 1 -> A/A' -> B/B' -> C/C' -> 1 is not necessarily exact. The proofs provided do not establish the necessary conditions for such a quotient sequence to be exact or for the claimed isomorphisms to hold. This fundamentally invalidates Lemmas 3.2 and 3.3, and consequently Theorem E which relies on them."
      }
    ],
    "token_usage": {
      "input": 33923,
      "thinking": 6022,
      "output": 1363
    }
  },
  {
    "entry_id": 70,
    "retraction_id": "1706.06242v2",
    "paper_id": "1706.06242v1",
    "retraction_comment": "An error has occurred: The classical Kolmogorov result about characterization of compactness is usually applied with linear operators. Unfortunately, commutator of Hardy-Littlewood maximal operator is a sublinear one",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The operator defined as the 'commutator' is non-standard and non-negative, fundamentally different from the standard commutator studied in the literature.",
        "Location": "Definition 2.2",
        "Explanation": "The definition includes an absolute value inside the integral and supremum, resulting in a non-negative operator. This is not the standard definition of a commutator, which is typically $bT(f) - T(bf)$ or its multilinear variants. The results claimed are therefore not about the standard commutator of the Hardy-Littlewood maximal operator, despite the terminology used in the title, abstract, and introduction, which misrepresents the contribution."
      },
      {
        "Problem": "The proof of Theorem 1.1 relies on a flawed inequality in Claim 1, Case 1.",
        "Location": "Proof of Theorem 1.1, Claim 1, Case 1",
        "Explanation": "The inequality $C M(f_1)(x)M(f_2)(x) \\leq C\\frac{|x-x'|^{\\alpha}}{|B_{2}|^{\\alpha/n}}M(f_{1})(x)M(f_{2})(x)$ is used. When $r \\leq |x-x'|$, $|B_2| \\approx |x-x'|^n$, so $|B_2|^{\\alpha/n} \\approx |x-x'|^\\alpha$. The inequality reduces to $1 \\leq C$, which is trivial, but it does not introduce the required $|x-x'|^\\alpha$ factor from the Lipschitz condition. The way the geometric factor $|x-x'|^\\alpha / |B_2|^{\\alpha/n}$ is used here seems incorrect and does not properly reflect the Lipschitz property of the symbol."
      },
      {
        "Problem": "The proof of Theorem 1.1 relies on a flawed estimate in Claim 1, Case 2.",
        "Location": "Proof of Theorem 1.1, Claim 1, Case 2, estimate for $I_2$ and $I_3$",
        "Explanation": "The estimate $I_2 \\leq C\\frac{|x-x'|^{\\alpha}}{|B_{2}|^{\\alpha/n}}M_{s}(f_{1})(z)M(f_{2})(x)$ (and similarly for $I_3$) appears incorrect. The derivation leads to a term involving $(\\frac{|x-x'|}{r})^{1/s'}$, and equating this to $\\frac{|x-x'|^\\alpha}{r^\\alpha}$ requires $(\\frac{|x-x'|}{r})^{1/s'-\\alpha} \\lesssim 1$. Since $r > |x-x'|$ and $1/s' > \\alpha/n > \\alpha$ (for $s < n/(n-\\alpha)$), the exponent $1/s'-\\alpha$ is positive. The inequality $(\\frac{|x-x'|}{r})^{1/s'-\\alpha} \\lesssim 1$ is not guaranteed for all $r > |x-x'|$. The exponents do not match correctly."
      },
      {
        "Problem": "The proof of Theorem 1.2 incorrectly assumes that symbols in CMO are bounded and have bounded gradients.",
        "Location": "Proof of Theorem 1.2, conditions (i) and (ii)",
        "Explanation": "The proof for norm boundedness (i) uses the inequality $|[b_i,\\mathcal{M}]_i(\\vec{f})(x)| \\leq 2\\|b_i\\|_{L^\\infty} \\mathcal{M}(f_1, f_2)(x)$, which requires $b_i \\in L^\\infty$. The proof for translation continuity (ii) uses estimates like $|b_1(x+t)-b_1(y_1)| \\leq C|t|\\|\\nabla b_1\\|_\\infty$ or $|b_1(x+t)-b_1(y_1)| \\leq \\|b_1\\|^{1/s}_{\\infty}\\|\\nabla b_1\\|^{1/s'}_{\\infty}|x+t-y|^{1/s'}$, which require $b_1$ to be Lipschitz or $C^1$ with bounded gradient, and $b_1 \\in L^\\infty$. Functions in CMO are not necessarily bounded or differentiable with bounded gradients. This invalidates the arguments for conditions (i) and (ii) of the compactness criterion for $b_i \\in CMO$."
      },
      {
        "Problem": "The proof of Theorem 1.2 uses an unjustified and likely incorrect decay estimate for the operator away from the origin.",
        "Location": "Proof of Theorem 1.2, condition (iii)",
        "Explanation": "To show uniform control away from the origin, the proof claims $|[b_{1},\\mathcal{M}]_{1}(f_{1},f_{2})(x)|\\lesssim |x|^{-n-n/p_{2}}$ for large $|x|$. This power decay estimate for the defined operator is not a standard result and is not justified in the paper. Standard maximal functions do not generally exhibit such polynomial decay for $L^p$ functions when $p>1$. This invalidates the argument for condition (iii) of the compactness criterion."
      }
    ],
    "token_usage": {
      "input": 12989,
      "thinking": 11298,
      "output": 1183
    }
  },
  {
    "entry_id": 71,
    "retraction_id": "1510.01988v2",
    "paper_id": "1510.01988v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to an error in Lemma 2; terms involving the normal derivative of $\\rho$ are missing",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of the residue of the vector field at the singularity.",
        "Location": "Page 4, calculation following Equation (2)",
        "Explanation": "The calculation of the limit of the boundary integral $\\int_{\\Sigma \\cap \\partial D_{\\epsilon}(y)} \\langle W, \\nu\\rangle_{\\rho^2 g}$ as $\\epsilon \\searrow 0$ appears incorrect. The vector field $W$ has a singularity of the form $-c \\frac{x-y}{|x-y|^k_g}$ near $y$. The standard residue calculation for such a singularity in a $k$-dimensional manifold with metric $\\rho^2 g$ should result in a limit proportional to $-c \\omega_k \\rho^{2-k}(r)$, or more precisely, the flux is related to the coefficient of the $1/|x-y|^{k-1}$ term in the $\rho^2 g$ metric. The paper's calculation results in a positive value $\\frac{\\omega_k}{2}$, while the singularity structure suggests a negative value. This error invalidates the subsequent inequality derived from the divergence theorem."
      },
      {
        "Problem": "Incorrect area calculation used in the residue limit.",
        "Location": "Page 4, calculation following Equation (2)",
        "Explanation": "The formula used for the area of the intersection $|\\Sigma \\cap \\partial D_{\\epsilon}(y)|_{\rho^2 g} = \\frac{\rho^{k-1}(r)}{2}\\omega_k |x-y|^{k-1}+o(\\epsilon^{k-1})$ seems incorrect. The area of a small sphere of radius $\\epsilon$ in a $k$-dimensional manifold with metric $\\rho^2 g$ is approximately $\\omega_k \\epsilon^{k-1}$. The paper's formula includes an extra factor $\\rho^{k-1}(r)/2$ and uses $|x-y|^{k-1}$ instead of $\\epsilon^{k-1}$ (where $\\epsilon$ is the radius in the $\rho^2 g$ metric and $|x-y|$ is the distance in the $g$ metric, related by $\\epsilon \\approx \\rho(r)|x-y|$). This error contributes to the incorrect residue calculation."
      },
      {
        "Problem": "Invalid conclusion from the divergence theorem.",
        "Location": "Page 4, final paragraph of the proof",
        "Explanation": "Due to the incorrect residue calculation, the application of the divergence theorem leads to the inequality $\\frac{1}{2 I(r)} |\\Sigma|_{\rho^2 g} + \\omega_k \\geq 0$. This inequality is always true since $|\\Sigma|_{\rho^2 g} \\geq 0$ and $\\omega_k > 0$, and therefore does not imply the desired sharp area bound $|\\Sigma|_{\rho^2 g} \\geq |B^k(r)|_{\rho^2 g} = \\omega_k I(r)$. The proof fails to establish the main theorem."
      }
    ],
    "token_usage": {
      "input": 9036,
      "thinking": 33875,
      "output": 684
    }
  },
  {
    "entry_id": 72,
    "retraction_id": "1212.5552v2",
    "paper_id": "1212.5552v1",
    "retraction_comment": "There are signal errors in eqs. (17) to (25)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Discrepancy in Residual Entropy Calculation",
        "Location": "Section 5, specifically the calculation of residual entropy at phase boundaries",
        "Explanation": "The paper claims a non-trivial residual entropy $S=\\ln(2)-\\ln(3-\\sqrt{5})$ at the phase boundaries $\\mu=1$ and $\\mu=2$ (for $t=V=V_1=1$). However, calculation from the zero-temperature limit of the derived partition function per unit cell yields $S = k \\ln(\\frac{1+\\sqrt{5}}{2})$ at $\\mu=1$ and $S = k \\ln(1+\\sqrt{2})$ at $\\mu=2$. The claimed value $\\ln(\\frac{3+\\sqrt{5}}{2})$ does not match these results, casting doubt on the quantitative findings regarding frustration and residual entropy."
      },
      {
        "Problem": "Inconsistent Sign in Effective Interaction Parameter $\\tilde{V}$",
        "Location": "Eq. (25) and Eq. (32)",
        "Explanation": "The effective Hamiltonian in Eq. (25) contains a term $+\\widetilde{V}\\textbf{n}_{d,i}\\textbf{n}_{d,i+1}$. The derivation in Eq. (32) gives $\\tilde{V}=\\frac{1}{\\beta}\\ln\\left(\\frac{w_{1}^{2}}{w_{2}w_{0}}\\right)$. The transfer matrix (Eq. 34) and its relation to $x, y$ imply an effective interaction term $-\\frac{1}{\\beta}\\ln y \\textbf{n}_{d,i}\\textbf{n}_{d,i+1}$. Using $y=\\exp(-\\beta\\tilde{V}_{paper})$, this term is $+\\tilde{V}_{paper}\\textbf{n}_{d,i}\\textbf{n}_{d,i+1}$. If the $\\tilde{V}$ in Eq. (25) is the same as in Eq. (32), there is a sign inconsistency between the effective Hamiltonian formulation and the derived parameter value. This affects the physical interpretation of the effective interaction between nodal sites."
      },
      {
        "Problem": "Ground State Phase Diagram Derivation Method",
        "Location": "Section 3",
        "Explanation": "The ground state phase diagram is presented based on comparing energies $E_k$ associated with specific configurations of the triangular plaquette sites and fixed total occupation $\\overline{n}_d$ of the nodal sites within the local $\\textbf{H}_{i,i+1}$ unit. The true ground state of the entire chain is determined by minimizing the total energy over all possible configurations of all sites, or equivalently, by taking the zero-temperature limit of the free energy derived from the exact partition function. While the resulting phase boundaries might be correct, the method described in Section 3 is not a rigorous derivation for a 1D chain and lacks justification for why comparing these specific local energies yields the global ground state diagram."
      },
      {
        "Problem": "Inconsistent Use of $\\overline{n}_d$ in Ground State Descriptions",
        "Location": "Section 2 (Eigenvalues) and Section 3 (Ground State Energies and Eigenvectors)",
        "Explanation": "The eigenvalues $E_k$ are derived as functions of $\\overline{n}_d = \\textbf{n}_{d,i}+\\textbf{n}_{d,i+1}$, which can be 0, 1, or 2. However, in the ground state analysis (Section 3), specific ground states (e.g., $\\rho=0, 1, 3, 4$) are associated with a single, fixed value of $\\overline{n}_d$ for every unit cell along the chain. The ground state of the chain is a configuration of all nodal sites $\\{n_{d,i}\\}$, not a uniform, fixed value of $\\overline{n}_d$ per bond. This presentation is confusing and inconsistent with the decoration transformation approach, which sums over internal degrees of freedom for *given* nodal site configurations, not fixed $\\overline{n}_d$ values."
      },
      {
        "Problem": "Clarity on Ground State Configurations and Density",
        "Location": "Section 3 (Ground State Eigenvectors) and Section 5 (Particle Density)",
        "Explanation": "The ground state eigenvectors (Eqs. 16-21) are presented as product states over $i$, implying uniform configurations of both plaquette and nodal sites along the chain. For example, $|S1\\rangle$ implies one particle on the plaquette and zero on site $d_i$ for all $i$, with $d_{i+1}$ also empty (since $\\overline{n}_d=0$ is associated with this state). While such uniform configurations can be ground states in 1D models, the paper does not explicitly justify why these specific uniform configurations represent the true ground states for the given densities, especially considering the possibility of non-uniform or more complex ground states in frustrated systems. The connection between the listed product states, their associated energies (which depend on $\\overline{n}_d$), and the average density $\\rho$ is not fully transparent."
      }
    ],
    "token_usage": {
      "input": 14199,
      "thinking": 21718,
      "output": 1163
    }
  },
  {
    "entry_id": 73,
    "retraction_id": "1612.09148v2",
    "paper_id": "1612.09148v1",
    "retraction_comment": "The second equality in eq. 11 does not hold for the general case. Thus, the conclusion does not follow from the premises and the claim of the paper is not proven",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect symmetry assumption for force constants used in deriving the real form.",
        "Location": "Derivation between Eq. (10) and (11)",
        "Explanation": "The derivation of the proposed real form of the dynamical matrix relies on the assumption $\\Phi_{i\\alpha}^{i'\\alpha'}(n)=\\Phi_{i\\alpha}^{i'\\alpha'}(-n)$. The correct symmetry relation for force constants in a crystal, derived from the symmetry of the full force constant matrix and translational symmetry, is $\\Phi_{i\\alpha}^{i'\\alpha'}(n) = \\Phi_{i'\\alpha'}^{i\\alpha}(-n)$. Using the correct symmetry leads to the standard Hermitian property of $D(\\mathbf{q})$, not a purely real form."
      },
      {
        "Problem": "Flawed manipulation of the summation in deriving the real form.",
        "Location": "Derivation between Eq. (10) and (11)",
        "Explanation": "The step combining terms for $n$ and $-n$ in the sum to obtain the cosine form is mathematically incorrect. The sum $\\sum_n f(n) e^{i\\mathbf{q}\\cdot\\mathbf{R}_n}$ cannot generally be rewritten as $\\sum_n f(n) \\cos(\\mathbf{q}\\cdot\\mathbf{R}_n)$ by simply averaging terms. The correct pairing using the actual symmetry $\\Phi_{i\\alpha}^{i'\\alpha'}(n) = \\Phi_{i'\\alpha'}^{i\\alpha}(-n)$ leads to the standard Hermitian form, not the proposed real form."
      },
      {
        "Problem": "Unsound argument for reality based on real eigenvectors.",
        "Location": "Paragraph starting 'The last conclusion is actually proven...'",
        "Explanation": "The argument that the dynamical matrix $D(\\mathbf{q})$ must be real because its eigenvectors can be made real is incorrect. While a Hermitian matrix can be diagonalized by a unitary matrix $U$ ($D = U \\Lambda U^\\dagger$), and real/imaginary parts of complex eigenvectors are also eigenvectors, the standard eigenvectors $\\varepsilon_{i\\alpha}$ of $D(\\mathbf{q})$ are generally complex for $\\mathbf{q} \\neq 0$. The matrix $U$ is generally complex and unitary, not real and orthogonal. The existence of real normal coordinates does not imply $D(\\mathbf{q})$ is real."
      },
      {
        "Problem": "Incorrect main conclusion about the reality of $D(\\mathbf{q})$.",
        "Location": "Abstract, Introduction, Conclusions",
        "Explanation": "The central claim that the dynamical matrix $D(\\mathbf{q})$ is real is incorrect for general wave vectors $\\mathbf{q} \\neq 0$. The standard dynamical matrix is Hermitian, which guarantees real eigenvalues, but it is generally complex. The proposed real form is derived based on incorrect symmetry assumptions and mathematical manipulations."
      },
      {
        "Problem": "Mischaracterization of standard $D(\\mathbf{q})$ and conditions for Hermiticity.",
        "Location": "Introduction, paragraph starting 'Finally, we need to review...'",
        "Explanation": "The paper states the standard form Eq. (1) is 'not explicitly Hermitian'. While not explicitly real, it *is* Hermitian for an infinite perfect crystal due to the underlying force constant symmetries. The paper also incorrectly implies that Hermiticity is only guaranteed under periodic boundary conditions or for infinite crystals due to the 'central symmetry of the lattice of unit cells' allowing pairing of $n$ and $-n$. This pairing is precisely what ensures Hermiticity in the standard form, and its breakdown (e.g., at surfaces) is why Hermiticity is lost there. The paper confuses the property of being Hermitian with the property of being real."
      }
    ],
    "token_usage": {
      "input": 3381,
      "thinking": 4884,
      "output": 843
    }
  },
  {
    "entry_id": 74,
    "retraction_id": "1205.5450v3",
    "paper_id": "1205.5450v2",
    "retraction_comment": "The paper has been withdrawn due to an error in the maximal norm estimate that we haven't been able to overcome",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Local well-posedness proof relies on bounding a term in the weighted $L^2$ norm estimate using a space-time norm not included in the defined solution space.",
        "Location": "Section 3, estimate (3.11)",
        "Explanation": "The estimate for $\\||x|^\\rho \\Psi(u)\\|_2$ includes the term $c(1+T)T^{1/2}\\|u\\|_{L^2_xL^{\\infty}_T}\\|D^{\\rho(1+a)}\\partial_xu\\|_{L^{\\infty}_xL^2_T}$. The norm $\\|D^{\\rho(1+a)}\\partial_xu\\|_{L^{\\infty}_xL^2_T}$ is not part of the norm $\\cuatro u\\cuatro$ defining the space $X_{r,T}$ where the contraction principle is applied. Thus, this term cannot be bounded by $C \\cuatro u\\cuatro^2$, which is necessary for the contraction argument to hold."
      },
      {
        "Problem": "Global well-posedness proof relies on properties of solutions from other works, but uses a space-time derivative norm not guaranteed by those properties for the full range of the parameter $a$.",
        "Location": "Section 3, estimate (3.12)",
        "Explanation": "The global extension argument for $\\||x|^\\rho u\\|_2$ uses the term $c(1+T)T^{1/2}\\|u\\|_{l^2_j(L^{\\infty}([j,j+1]\\times [0,T]))}\\| D^{\\rho(1+a)}\\partial_xu\\|_{l^{\\infty}_j(L^2([j,j+1]\\times [0,T]))}$. While $\\|u\\|_{l^2_j(L^{\\infty})}$ is controlled by the class (3.13) from \\cite{KePoVe}, the norm $\\| D^{\\rho(1+a)}\\partial_xu\\|_{l^{\\infty}_j(L^2)}$ is not controlled by $\\| D^{s-(1-a)/2}\\partial_xu\\|_{l^{\\infty}_j(L^2)}$ (from (3.13)) for $a \\in (\\frac{-2+\\sqrt{7}}{3}, 1)$, because $\\rho_a(1+a) > s-(1-a)/2$ in this range. This invalidates the global extension argument for this range of $a$."
      },
      {
        "Problem": "Global well-posedness proof uses the $H^1$ norm of the solution in an estimate, which is not controlled by the $H^s$ norm when $s<1$.",
        "Location": "Section 3, estimate (3.12)",
        "Explanation": "The estimate for $\\sup_{t\\in [0,T]}\\||x|^\\rho u_3\\|_2$ includes the term $c(1+T)T\\,\\sup_{t\\in[0,T]}\\|u(t)\\|_{1,2}^2$. The solution $u_3$ is known to be in $C([0,T]: H^s(\\R))$. However, if $s < 1$, the $H^1$ norm is not bounded by the $H^s$ norm. The condition $s > 3/2-3a/4$ allows $s < 1$ for $a \\in (2/3, 1)$. Thus, for $a$ in this range, this term cannot be bounded by $C \\sup_{t\\in[0,T]}\\|u(t)\\|_{s,2}^2$, which is needed for the global argument."
      }
    ],
    "token_usage": {
      "input": 28295,
      "thinking": 21407,
      "output": 859
    }
  },
  {
    "entry_id": 75,
    "retraction_id": "1806.09512v2",
    "paper_id": "1806.09512v1",
    "retraction_comment": "The calculations are not strictly correct because the Fermi momenta for protons and neutrons were not scaled correctly",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Assumption of constant effective mass M* per nucleus despite evidence of kinematics dependence.",
        "Location": "Section II (Formalism), Section IV.12 (M* uncertainty), Section IV.13 (Predictions for 48Ti and 40Ar), Figures 13, 14, 15.",
        "Explanation": "The model assumes a single, constant value for the relativistic effective mass M* for each nucleus. However, the paper's own analysis of experimental data (Figs. 13, 14) shows that the effective mass derived from the quasielastic peak position varies significantly with energy transfer (omega). This contradicts the model's fundamental assumption and limits its ability to accurately describe cross sections across different kinematics for a given nucleus, as demonstrated by the need for different M* values to fit the 12C and 48Ti data in Fig. 15 for a specific kinematics."
      },
      {
        "Problem": "Assumption of a single universal scaling function f*(psi*) for both longitudinal and transverse responses.",
        "Location": "Section II (Formalism, Eq. 5), Section III (The SuSAM* approach).",
        "Explanation": "The model assumes that both the longitudinal (RL) and transverse (RT) nuclear response functions, when divided by their respective single-nucleon contributions (rL, rT), scale with the same universal function f*(psi*), i.e., RL/rL = RT/rT = f*. While the relativistic mean field theory provides a framework for calculating RL and RT in the medium, it does not generally predict that the ratios RL/rL and RT/rT are equal or scale with the same function beyond the simplest relativistic Fermi gas approximation. This assumption is central to the model's structure, and its potential invalidity could undermine the interpretation of the extracted scaling function as a universal nuclear property."
      },
      {
        "Problem": "Unjustified claim of gauge invariance for the medium-modified current.",
        "Location": "Section I (Introduction), Section II (Formalism, Eq. 10, 11).",
        "Explanation": "The paper claims that the SuSAM* approach keeps gauge invariance, attributing it to the effective mass accounting for the energy shift. The model uses the CC2 current operator, which is gauge invariant for free, on-shell nucleons. However, the application of this operator in the medium involves using effective mass in the spinors and modifying the form factors according to Eq. (10) and (11). This modification is an ansatz based on the structure of Dirac spinors in the medium. The paper does not provide a derivation or justification for the gauge invariance of this specific medium-modified current operator in the nuclear medium, which is a complex theoretical problem. If the current is not gauge invariant, the calculated response functions and cross sections are theoretically inconsistent."
      },
      {
        "Problem": "Poor quantitative description for heavy nuclei.",
        "Location": "Section IV.10 (208Pb), Section IV.11 (238U), Table II (chi^2/N'QE values).",
        "Explanation": "While the model aims to provide a global description for nuclei from A=2 to A=238, the quantitative agreement for the heaviest nuclei (208Pb and 238U) is significantly worse than for lighter and medium-mass nuclei, as indicated by the higher chi^2/N'QE values (1.223 for Pb, 1.74 for U) compared to values typically below 0.8 for lighter nuclei. This suggests that the model's assumptions, including the universality of the scaling function and the parameterization via kF and M*, are less valid for heavy nuclei, potentially due to stronger final-state interactions or other nuclear effects not fully captured by the model."
      },
      {
        "Problem": "Sensitivity of the scaling band extraction to selection criteria and parameterization.",
        "Location": "Section III.1 (The scaling function), Section III.3 (The global fit), Figure 1.",
        "Explanation": "The phenomenological scaling function and its uncertainty band are extracted from the data using a multi-step procedure involving density criteria for data selection and parameterization using a specific functional form (sum of Gaussians modified by a Fermi function). The global fit procedure optimizes parameters based on maximizing points within a fixed-width band, while the final band width is determined by a subsequent density criterion. While the similarity between bands B and C suggests some robustness, the exact shape and width of the band, and thus the definition of the 'universal' scaling function, are dependent on these specific methodological choices. This affects the rigor of the claim of a uniquely determined universal scaling function and band."
      }
    ],
    "token_usage": {
      "input": 26133,
      "thinking": 4946,
      "output": 1032
    }
  },
  {
    "entry_id": 76,
    "retraction_id": "2102.11234v2",
    "paper_id": "2102.11234v1",
    "retraction_comment": "In step (3) of the proof of Theorem 1.3. it is claimed that $\\delta^2_{N,N} = 2\\delta$. This is not the only case that can occur and therefore there is a gap in the proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed definition and use of h_i(N) and Lemma 2.1",
        "Location": "Section 2, Lemma 2.1",
        "Explanation": "The definition of h_i(N) is given only for the one-dimensional case and is not properly extended to multi-dimensional Kronecker sequences. Lemma 2.1, which claims a shift property for h_i(N), relies on an incorrect transformation R_alpha and does not hold in general for the sequence points n*alpha mod L. This lemma is foundational for subsequent proofs (Theorem 2.2, Theorem 3.1, etc.), rendering them unsound."
      },
      {
        "Problem": "Unsound proof of Theorem 2.2 ($g^2(d,q) \\leq g(d,q)+1$)",
        "Location": "Section 2, Theorem 2.2",
        "Explanation": "The proof relies heavily on the flawed Lemma 2.1. The arguments regarding the relationship between the sets of distances A_N, B_N and A_{N-1}, B_{N-1} are difficult to follow and appear logically inconsistent, particularly the claims about how the number of distinct distances changes from N-1 to N. This theorem's proof is not valid."
      },
      {
        "Problem": "Unsubstantiated claim in Theorem 1.1 (Theorem 3.1 in abstract/intro, Theorem 2.4 in text) that $g_N \\geq 9$ for infinitely many N in d=3",
        "Location": "Section 1, Theorem 1.1; Section 2, Numerical experiments",
        "Explanation": "The conclusion that g_N >= 9 for infinitely many N, which is the main result contradicting the Haynes-Marklof conjecture, is not supported by the provided evidence. The numerical example shows g_39=6 and g_39^2=9 for a specific N, not g_N >= 9. The argument attempting to link g_N^2=9 to g_N >= 9 relies on the flawed Theorem 2.2 and Corollary 2.3. The numerical example does not provide an improved lower bound for g(3,2) (6 is not greater than 7)."
      },
      {
        "Problem": "Unsound proof of Corollary 2.3",
        "Location": "Section 2, Corollary 2.3",
        "Explanation": "This corollary, stating that if g_N^2 equals the maximal possible value g^2(d,q), then g_N must be 1, is derived directly from the flawed proof of Theorem 2.2. The reasoning presented in the proof of Theorem 2.2 does not logically lead to this conclusion, and the corollary is likely false."
      },
      {
        "Problem": "Unsound proofs of construction theorems (Theorem 3.1, Theorem 3.3, Theorem 1.3)",
        "Location": "Section 3, Theorem 3.1, Theorem 3.3, Theorem 1.3",
        "Explanation": "The proofs for the existence of multi-dimensional Kronecker sequences with a small number of nearest neighbor distances (specifically g_N=1 for infinitely many N) rely on the flawed Lemma 3.1 and its implications for the behavior of h_1(N). The connection between the continued fraction properties and the multi-dimensional nearest neighbor distances is not correctly established through this lemma, rendering the proofs of these construction theorems invalid."
      }
    ],
    "token_usage": {
      "input": 13126,
      "thinking": 8977,
      "output": 790
    }
  },
  {
    "entry_id": 77,
    "retraction_id": "1303.3756v2",
    "paper_id": "1303.3756v1",
    "retraction_comment": "This paper has been withdrawn by the author because Jarzynski's equality takes also processes into consideration which do not satisfy the 2nd law. Consequently, a modified non-equilibrium thermodynamics has to be developped taking into account the \"anti-irreversible admixtures\"",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misunderstanding the domain of validity of the Jarzynski equality.",
        "Location": "Abstract, Section 4 (Eq. 31), Section 5 (scheme d1, d2)",
        "Explanation": "The paper claims the Jarzynski equality $\\overline{\\exp(-\\beta W)}=\\exp(-\\beta \\Delta F)$ is only valid in the reversible limit. This is incorrect. The equality holds for non-equilibrium processes starting from an initial equilibrium state (canonical ensemble). The average is over the work done along these non-equilibrium paths. The equality reduces to the reversible work theorem ($\\overline{W}=\\Delta F$) only when the process is reversible, but the equality itself is a general result for finite-time, irreversible transformations starting from equilibrium."
      },
      {
        "Problem": "Incorrect derivation or interpretation of the relationship between the Second Law inequality and the Jarzynski equality.",
        "Location": "Section 3.2 (Eqs. 26, 28, 30, 31), Section 5 (scheme d1, d2)",
        "Explanation": "The paper derives the Second Law inequality $\\Delta F - \\overline{W} \\leq 0$ (Eq. 28) from the general Second Law. It then seems to incorrectly imply that the Jarzynski equality (Eq. 30/31) follows from this only in the reversible case. In fact, Jarzynski's equality is a distinct result from statistical mechanics that implies the Second Law inequality via Jensen's inequality, not the other way around. The paper's presentation suggests a confusion between these two fundamental results."
      },
      {
        "Problem": "Flawed logic in the concluding scheme relating reversibility, the Second Law, and the Jarzynski equality.",
        "Location": "Section 5, scheme (d1, d2)",
        "Explanation": "The scheme presented in Section 5 contains logical errors. Specifically, stating that the Jarzynski equality $\\exp(-\\beta \\Delta F) = \\overline{\\exp(-\\beta W)}$ implies or is equivalent to reversibility is false. The equality holds for irreversible processes starting from equilibrium. This flawed logic forms the basis of the paper's rejection of Jarzynski's conclusions."
      },
      {
        "Problem": "Misinterpretation of the role of the canonical ensemble in Jarzynski's work.",
        "Location": "Section 3, Section 5",
        "Explanation": "The paper argues that Jarzynski's presupposition of a canonical ensemble implies that the system is in equilibrium or that the process is reversible. This misinterprets Jarzynski's setup. The canonical ensemble describes the initial state distribution for an ensemble of systems. Each system then evolves non-equilibriumly under the influence of a time-dependent parameter. The average is taken over the work done on these non-equilibrium trajectories starting from the specified initial equilibrium distribution."
      }
    ],
    "token_usage": {
      "input": 7746,
      "thinking": 3016,
      "output": 654
    }
  },
  {
    "entry_id": 78,
    "retraction_id": "2002.03104v2",
    "paper_id": "2002.03104v1",
    "retraction_comment": "As pointed out by [REDACTED-NAME] via MO: \"This only shows that there is no trivial, i.e. purely analytic, argument proving that this expression is unbounded. But there might be only finitely many odd perfect numbers, or there might be some relation between n and q, which implies that the ratio is bounded.\"",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The core assumption that a specific sum involving divisor functions is unbounded is unproven.",
        "Location": "Section 3, point (1) and used throughout Section 3 (4), Section 4 (Theorem 1, Theorem 3, final theorem)",
        "Explanation": "The paper's main argument relies on the assumption that the expression $\\frac{\\sigma(q^2)}{n}+\\frac{\\sigma(n)}{q^2}$ is unbounded for odd perfect numbers. This is stated as an expectation based on an analogy with $z+1/z$, not a proven mathematical fact. This unproven assumption is used as the basis for contradictions in multiple proofs (Section 3 (4), Theorem 1, Theorem 3, and the final theorem), rendering them unsound and invalidating the paper's main conclusion."
      },
      {
        "Problem": "Incorrect logical equivalence stated in Corollary 2.",
        "Location": "Corollary 2",
        "Explanation": "The corollary claims the equivalence $\\sigma(q^2) < \\sigma(n) \\iff \\frac{\\sigma(q^2)}{n} < \\frac{\\sigma(n)}{q^2}$. This is equivalent to $\\sigma(q^2) < \\sigma(n) \\iff \\sigma(q^2) q^2 < \\sigma(n) n$, which is generally false unless $q^2=n$ (which is ruled out). The second part of the biconditional chain presented in the corollary is incorrect."
      },
      {
        "Problem": "Proofs in Section 3, point (4) are unsound.",
        "Location": "Section 3, point (4)",
        "Explanation": "The proofs that $\\sigma(n) \\neq \\sigma(q^2)$, $\\sigma(q^2) \\neq n$, and $\\sigma(n) \\neq q^2$ all conclude by stating that a derived inequality contradicts the statement in Section 3, point (1). As noted in the first problem, the statement in Section 3, point (1) is an unproven assumption, not a proven fact. Therefore, these proofs are unsound."
      },
      {
        "Problem": "Proof of Theorem 1 is unsound.",
        "Location": "Theorem 1",
        "Explanation": "The proof of Theorem 1 concludes by stating that a derived inequality contradicts the statement in Section 3, point (1). As noted in the first problem, the statement in Section 3, point (1) is an unproven assumption, not a proven fact. Therefore, the proof of Theorem 1 is unsound."
      },
      {
        "Problem": "Proof of Theorem 3 is unsound.",
        "Location": "Theorem 3",
        "Explanation": "The proof of Theorem 3 concludes by stating that a derived inequality contradicts the statement in Section 3, point (1). As noted in the first problem, the statement in Section 3, point (1) is an unproven assumption, not a proven fact. Therefore, the proof of Theorem 3 is unsound."
      }
    ],
    "token_usage": {
      "input": 4073,
      "thinking": 9619,
      "output": 691
    }
  },
  {
    "entry_id": 79,
    "retraction_id": "1401.5295v2",
    "paper_id": "1401.5295v1",
    "retraction_comment": "This paper has been withdrawn due to non-inclusion of some terms in equation 16",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The central claim of a topological phase transition occurring without gap closing at the critical point is not sufficiently supported by the mean-field analysis.",
        "Location": "Section IV.A, Section V",
        "Explanation": "The paper claims a first-order topological phase transition occurs without the energy gap closing at the critical point ($V_{c2}$). This is a highly unusual and significant claim. However, the mean-field analysis presented, including the energy landscape (Fig 4) and edge state spectra (Fig 5), does not provide sufficient direct evidence that the bulk energy gap remains open for all relevant excitations *at the exact transition point* where the two mean-field ground states become degenerate. Mean-field theory is an approximation and may not accurately capture the gap behavior at criticality."
      },
      {
        "Problem": "The reliance on mean-field theory for concluding the absence of gap closing at a quantum phase transition is potentially unsound.",
        "Location": "Section IV, Section V",
        "Explanation": "The entire analysis of phase transitions is based on a mean-field approximation. While MFT can indicate the presence of different phases and first-order transitions, it neglects quantum fluctuations which are crucial near quantum phase transitions. Relying solely on MFT to conclude that a topological transition occurs *without gap closing* is potentially unsound, as fluctuations could induce gap closing or alter the nature of the transition in a more complete treatment."
      },
      {
        "Problem": "The method for calculating Chern numbers in the symmetry-broken phases is not explicitly described, making the claimed change in topological invariant less verifiable.",
        "Location": "Section IV.A, Section IV.B",
        "Explanation": "The paper identifies topological phases by their Chern numbers, including in phases (PH2, PH3) where translational symmetry is broken. While Chern numbers can be calculated in such phases by defining a larger magnetic unit cell and a reduced Brillouin zone, the paper does not explicitly describe how this calculation was performed for the broken-symmetry phases, nor does it show the integration of the Berry curvature over the appropriate, reduced Brillouin zone. This lack of detail makes the claimed change in topological invariant (and thus the topological nature of the transition) less verifiable from the text."
      },
      {
        "Problem": "The statement regarding particle-hole symmetry is potentially confusing or incorrect.",
        "Location": "Section II.C",
        "Explanation": "The statement that particle-hole symmetry exists only for 'half filling' and the Hamiltonian is invariant only then is potentially misleading or incorrect for the given model. The particle-hole transformation (Eq 5) is an anti-unitary symmetry of the Hamiltonian (Eq 1) itself, regardless of the filling factor. While the ground state at a specific filling (like 1/2q) may not preserve this symmetry, the Hamiltonian possesses it."
      }
    ],
    "token_usage": {
      "input": 15389,
      "thinking": 3728,
      "output": 620
    }
  },
  {
    "entry_id": 80,
    "retraction_id": "1402.6435v2",
    "paper_id": "1402.6435v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in page 20",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Proof of a Key Lemma (Corollary 3.8)",
        "Location": "Corollary 3.8",
        "Explanation": "The proof that $\\vol^0(\\overline{D})=\\vol(D)$ for a nef and big adelic divisor $\\overline{D}$ relies on approximating $\\overline{D}$ by arithmetic divisors $(\\mathscr{D}, g_\\infty)^a$ where $\\mathscr{D}$ is relatively nef on a global model. This approximation property is not guaranteed by the standard definition of a vertically nef divisor, which involves local approximations at each place. While the result itself is known for standard nef big divisors and can be proven using approximation by ample nef divisors, the proof presented in the paper is unsound under the standard definition of vertically nef."
      },
      {
        "Problem": "Non-standard Definition of Vertically Nef",
        "Location": "Definition 2.4",
        "Explanation": "The definition of a vertically nef adelic divisor given in the paper requires a global approximation property by a relatively nef divisor on an $O_K$-model. This is a stronger condition than the standard definition used in the literature, which requires only local approximation at each place. This non-standard definition is used in the proof of Corollary 3.8, leading to the issue described in Problem 1. If the main theorem is intended for the standard class of vertically nef divisors, the definition is incorrect. If it is intended for this specific, potentially smaller class, the scope is not clearly stated."
      },
      {
        "Problem": "Implicit Assumption of Geometric Irreducibility",
        "Location": "Section 3, Section 5",
        "Explanation": "The construction and properties of the arithmetic Okounkov body and concave transform in Section 3 rely on the assumption that the variety $X$ is geometrically irreducible. This assumption is not explicitly stated for the main theorems in Section 5, which depend on these results. If the theorems are meant to apply to varieties that are not geometrically irreducible, the arguments based on the Okounkov body might not be valid as presented."
      }
    ],
    "token_usage": {
      "input": 33159,
      "thinking": 11379,
      "output": 466
    }
  },
  {
    "entry_id": 81,
    "retraction_id": "2210.17003v2",
    "paper_id": "2210.17003v1",
    "retraction_comment": "The main theorems of the paper (Theorem 13 and 17) are wrong. The statements are only valid in R^2",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Theorem 1 claims that if the three points x, R_A(x), and R_B(R_A(x)) are distinct, their circumcenter is 0. This is incorrect.",
        "Location": "Proof of Theorem 1, Case where cardinality of {x, y, z} is 3",
        "Explanation": "While reflections onto cones preserve norm, meaning x, R_A(x), and R_B(R_A(x)) lie on a sphere centered at 0, their circumcenter is the center of the smallest sphere passing through them. This circumcenter is generally not the origin unless the origin lies in the affine hull of the three points, which is not guaranteed."
      },
      {
        "Problem": "The proof of Theorem 1 contains logical gaps and unproven claims in the case where the cardinality of {x_1, y_1, z_1} is 2 and x_1 = z_1.",
        "Location": "Proof of Theorem 1, Case (i)(c), subcase x_1=z_1",
        "Explanation": "The proof claims C_T(x_1) = (x_1+y_1)/2 = (y_1+z_1)/2 = P_q(x_1)=q where q=P_A(x_1)=P_B(y_1). The equality P_A(x_1)=P_B(y_1) is not generally true for arbitrary closed convex cones A and B, and the step P_q(x_1)=q is trivial but does not justify the preceding equalities or the claim that C_T(x_1) equals q. This subcase's argument is unsound."
      },
      {
        "Problem": "The proof of Theorem 2 incorrectly applies Theorem 1.",
        "Location": "Proof of Theorem 2, last paragraph",
        "Explanation": "Theorem 1 proves finite convergence for closed convex *cones*. The proof of Theorem 2 attempts to apply this result to the sets ((A ∩ B_r(x^*)) - x^*) and ((B ∩ B_r(x^*)) - x^*). These sets are intersections of shifted polyhedral sets with a ball, and are generally not cones. Applying a theorem about cones to non-cone sets is an invalid step."
      },
      {
        "Problem": "The proof of Theorem 2 misunderstands the implication of the sequence entering a ball around the limit point.",
        "Location": "Proof of Theorem 2, second paragraph",
        "Explanation": "The proof claims that solving the original problem x ∈ A ∩ B is equivalent to solving x ∈ ((A ∩ B_r(x^*)) - x^*) ∩ ((B ∩ B_r(x^*)) - x^*) for the iterates x_n when n>N. The sequence x_n is generated by applying CRM to A and B, not to the shifted and truncated sets. The behavior of the sequence near the intersection point needs to be related to the local geometry of A and B at x^* (e.g., tangent cones), not by switching the problem to finding the intersection of different sets."
      }
    ],
    "token_usage": {
      "input": 6465,
      "thinking": 7688,
      "output": 753
    }
  },
  {
    "entry_id": 82,
    "retraction_id": "1503.00700v2",
    "paper_id": "1503.00700v1",
    "retraction_comment": "This preprint was withdrawn because the theoretical discussion of the inferred temperature of qubit couplers assumes an equilibrium distribution, which is not the case during the annealing cycles",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound physical model used for calculating J-offsets",
        "Location": "Section IV, Equation 9 and surrounding text",
        "Explanation": "The paper uses a Boltzmann distribution for a two-level system (Equation 9) to model the expectation value of a spin pair <s_i s_j> in a highly coupled system where all J_kl are set to a uniform value J and h_i=0. This model is physically incorrect for a coupled system, as the expectation value of a spin pair depends on the full partition function of the interacting system, not just a simple two-level model for the pair. The derived J_0l offsets and T_l parameters from fitting to this incorrect model lack physical justification."
      },
      {
        "Problem": "Limited validation scope for generality claim",
        "Location": "Section V, Section VI",
        "Explanation": "The effectiveness of the proposed calibration method is demonstrated only for the trivial 'null problem' where all h_i and J_ij are intended to be zero. The paper claims the method is 'general' and 'should be helpful to other problems of interest' but provides no evidence or theoretical argument to support that offsets derived from this specific, decoupled or uniformly coupled, configuration will effectively correct biases in problems with arbitrary, problem-specific h_i and J_ij values."
      },
      {
        "Problem": "Ambiguity in the composite correction method description",
        "Location": "Section V, Table 3 and surrounding text",
        "Explanation": "The description of how the composite h and J corrections were calculated and applied in Case f) of Table 3 is not fully clear. The statement 'compute the h corrections, apply them when measuring the J correction, and then apply these two corrections' lacks the precise details needed to reproduce the experiment or fully understand how the J-offsets were derived in the presence of non-zero h-offsets, especially given the unsound model used for J-offsets."
      },
      {
        "Problem": "Lack of context regarding standard calibration procedures",
        "Location": "Section II, Section VI",
        "Explanation": "The paper refers to 'standard calibrations' performed by system operators but does not describe what these procedures entail. Without understanding the existing calibration baseline, it is difficult to assess the true practical significance and added value of the proposed user-side method beyond simply measuring the state of the machine after standard calibration."
      },
      {
        "Problem": "Speculative interpretation of the 'temperature' fitting parameter",
        "Location": "Section IV, Figure 8(d) and Table 2 discussion",
        "Explanation": "While the paper correctly identifies the T_l parameter derived from the J-sweep fit (Equation 9) as a 'fitting parameter' and not a physical temperature, the subsequent interpretation of its low value as 'a measure of the improvement of the quantum annealing computation over an equilibrium classical device' is speculative. This interpretation is based on a parameter derived from fitting data to a physical model that is acknowledged to be unsound for the system being studied."
      }
    ],
    "token_usage": {
      "input": 12843,
      "thinking": 5346,
      "output": 671
    }
  },
  {
    "entry_id": 83,
    "retraction_id": "1202.1896v2",
    "paper_id": "1202.1896v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical mistake in the circle graph algorithm",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Lemma and Reduction for Permutation Graphs",
        "Location": "Section 2, Lemma and Theorem 1 proof",
        "Explanation": "The lemma defines an 'optimal' coloring in an unusual way and claims that uncolored vertices in such a coloring correspond precisely to line segments crossing a set of non-intersecting scanlines. The proof relies on the assumption that components of colored vertices are uniformly colored (all black or all white), which is not required by the black-and-white coloring problem definition (only that no black vertex is adjacent to a white vertex). This flawed lemma undermines the basis for the dynamic programming approach described in the theorem."
      },
      {
        "Problem": "Incorrect Dynamic Programming Combination for Permutation Graphs",
        "Location": "Section 2, Theorem 1 proof",
        "Explanation": "The dynamic programming approach for permutation graphs splits a piece into two smaller pieces using an intermediate scanline. It proposes combining colorings from the two sub-pieces by simply summing the counts of black and white vertices ($b_1+b_2, w_1+w_2$). This is incorrect because vertices in one sub-piece can be adjacent to vertices in the other sub-piece (their line segments can cross), and the DP state $(b', w')$ does not capture the necessary boundary information to ensure that combining valid colorings from sub-problems results in a valid coloring for the larger piece."
      },
      {
        "Problem": "Unjustified Reduction for Circle Graphs",
        "Location": "Section 3, Paragraph 3",
        "Explanation": "The paper states that 'it is easy to see that the black-and-white coloring problem reduces to finding a collection of noncrossing scanlines' for circle graphs. This claim is not justified and appears to rely on the same flawed logic used for permutation graphs regarding the structure of colored components and their separation by scanlines. Without a valid reduction, the subsequent dynamic programming approach based on scanlines lacks a proper foundation."
      },
      {
        "Problem": "Unsound Dynamic Programming Approach for Circle Graphs",
        "Location": "Section 3, Theorem proof",
        "Explanation": "The dynamic programming approach for circle graphs is described with a complex and unclear state definition involving scanline chains, a region R where all vertices are assumed to be colored black, and counts of chords crossing scanlines. This state definition seems arbitrary and not justified as being sufficient to capture all necessary information for combining sub-problem solutions. The description of state transitions and table computation is vague, making it impossible to verify the correctness or completeness of the DP for finding *any* valid black-and-white coloring."
      }
    ],
    "token_usage": {
      "input": 6404,
      "thinking": 2594,
      "output": 580
    }
  },
  {
    "entry_id": 84,
    "retraction_id": "1304.5962v2",
    "paper_id": "1304.5962v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound determination of the cancellation region.",
        "Location": "Section 2, Lemma 1 and its proof.",
        "Explanation": "The paper claims the seller's cancellation region for $\\tau \\geq \\tau^*$ is restricted to the single point $S=K$. This is highly unusual and likely incorrect for a call option with cancellation payoff $\\max(S-K,0)+\\delta$. The proof provided for this claim is flawed, relying on unproven inequalities and an incorrect application of the cancellation payoff for $S \\leq K$. A correct analysis of the seller's optimal stopping problem would typically yield a cancellation region $S \\geq c(\\tau)$ for a call."
      },
      {
        "Problem": "Incorrect assumption about the continuation region for small remaining time.",
        "Location": "Section 2, definition of $\\mathcal{C}_1$ and equation (4).",
        "Explanation": "The paper assumes that for $\\tau \\leq \\tau^*$, the option value is equal to the standard European option price $v^E(S,\\tau)$ for all $S$. This implies the seller would never cancel in this time period. However, the seller's right to cancel exists at any time $t<T$ if $V(S_t, T-t) \\geq \\max(S_t-K,0)+\\delta$. This condition might be met for certain $S$ values even when $T-t \\leq \\tau^*$, especially for large $S$ or small $\\delta$."
      },
      {
        "Problem": "PDE problem formulation based on incorrect regions.",
        "Location": "Equations (4)-(7).",
        "Explanation": "The partial differential equation problem solved in Section 3 is formulated based on the assumed cancellation region ($S=K$ for $\\tau \\geq \\tau^*$) and continuation region ($\\tau \\leq \\tau^*$ for all $S$, and $S \\neq K$ for $\\tau > \\tau^*$). Since the determination of these regions is unsound (Problems 1 and 2), the PDE problem does not accurately model the option value."
      },
      {
        "Problem": "Pricing formula derived from an incorrect model.",
        "Location": "Section 3, Theorem 3.",
        "Explanation": "The explicit pricing formula provided in Theorem 3 is the solution to the PDE problem (4)-(7). As this PDE problem is based on incorrect assumptions about the option's continuation and cancellation regions, the resulting pricing formula is likely incorrect for the described cancellable European option."
      }
    ],
    "token_usage": {
      "input": 9193,
      "thinking": 8550,
      "output": 574
    }
  },
  {
    "entry_id": 85,
    "retraction_id": "1908.07349v3",
    "paper_id": "1908.07349v2",
    "retraction_comment": "the results of theorem 2 is not correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation of the bounds for the coefficient $a_3$ in Theorem 5.2.",
        "Location": "Proof of Theorem 5.2, paragraph starting 'In order to deduce an estimation...'",
        "Explanation": "The proof states that subtracting equation (5.1.31) from (5.1.30) yields the inequality $|a_3|\\leq |a_{2}^{2}|+\\frac{B_{1}|\\tau|}{(1+2\\lambda+6\\delta)}$. Subtracting these equations actually gives $2a_3 - 2a_2^2 = \\frac{\\tau}{1+2\\lambda+6\\delta} [B_1(c_2-d_2) + B_2(c_1^2-d_1^2)]$. Using the fact that $c_1 = -d_1$ (from equations 5.1.28 and 5.1.29), this simplifies to $a_3 - a_2^2 = \\frac{\\tau B_1}{2(1+2\\lambda+6\\delta)} (c_2-d_2)$. Applying the triangle inequality and the bounds $|c_2|\\leq 1, |d_2|\\leq 1$ gives $|a_3 - a_2^2| \\leq \\frac{|\\tau| B_1}{1+2\\lambda+6\\delta}$. This is a bound for $|a_3 - a_2^2|$, not $|a_3|$. The presented derivation step does not logically lead to the stated inequality for $|a_3|$, rendering this part of the proof unsound, even though the final bounds for $|a_3|$ might be derivable through a different correct sequence of steps using the same initial equations."
      },
      {
        "Problem": "Incorrect general formula for the coefficient of the Faber polynomial expansion of a composite function.",
        "Location": "Equations (5.1.15) and (5.1.16)",
        "Explanation": "The paper states that $\\varphi(u(z))=1-\\sum_{n=1}^{\\infty}B_1 \\mathcal{K}_{n}^{1}(c_1,...,c_n;B_1,...,B_n)z^n$ and similarly for $\\varphi(v(w))$. Given $\\varphi(z) = 1 + B_1 z + B_2 z^2 + \\dots$ and $u(z) = c_1 z + c_2 z^2 + \\dots$, the coefficient of $z^n$ in $\\varphi(u(z))$ is generally given by $\\sum_{k=1}^n B_k \\mathcal{K}_n^k(c_1, \\dots, c_n)$. The formula $\\mathcal{K}_n^1(c_1, \\dots, c_n)$ is simply $c_n$. The stated formula implies that the coefficient of $z^n$ in $\\varphi(u(z))$ is $-B_1 c_n$, which would mean $\\varphi(u(z)) = 1 - B_1 u(z)$. This is only true if $\\varphi(z) = 1 - B_1 z$, which contradicts the general form of $\\varphi(z)$. While this error does not invalidate the conclusion of Theorem 5.1 because the specific assumption $a_k=0$ for $k<n$ simplifies the correct general formula to $B_1 c_{n-1}$ for the coefficient of $z^{n-1}$, the general formula presented is incorrect and indicates a misunderstanding or misstatement of the Faber polynomial technique for composite functions."
      }
    ],
    "token_usage": {
      "input": 13211,
      "thinking": 17450,
      "output": 830
    }
  },
  {
    "entry_id": 86,
    "retraction_id": "1310.0331v4",
    "paper_id": "1310.0331v3",
    "retraction_comment": "this paper has been withdrawn by the author due to a crucial error in equation 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation for N=2 Laughlin wavefunction example",
        "Location": "Section II, Eq (2)",
        "Explanation": "The specific coefficients chosen in Eq (2) for the pairwise entangled state do not reproduce the standard N=2, v=1/3 Laughlin wavefunction (z_A-z_B)^3. Comparing the polynomial parts, the signs of the z_A^3 and z_B^3 terms are opposite."
      },
      {
        "Problem": "Misinterpretation of wavefunction decomposition structure",
        "Location": "Section II, Eq (5) and (7) and surrounding text",
        "Explanation": "The decomposition of the N=3 and N=4 Laughlin wavefunctions into sums of terms like those in Eq (5) and (7) is interpreted as representing states where 'only two fermions are entangled'. This is a misinterpretation; these are specific linear combinations of basis states, and the entanglement of the total Laughlin state is a complex many-body property, not accurately described as a sum of states with only pairwise entanglement in this manner."
      },
      {
        "Problem": "Unjustified constraint on particle numbers in statistical mechanics derivation",
        "Location": "Section III, Eq (10), (13) and surrounding text",
        "Explanation": "The derivation of modified Bose-Einstein and Fermi-Dirac statistics relies on the assumption that the described entanglement implies that the number of particles in energy level ε_i must be equal to the number of particles in ε_{i+1} (n_i=n_{i+1} for i=1,3,5,...) in every microstate included in the partition function sum. This strong constraint is not justified by the vague description of the entanglement and is likely incorrect for typical entangled states, invalidating the derived statistics."
      },
      {
        "Problem": "Vague definition of entanglement in Section III",
        "Location": "Section III, first paragraph",
        "Explanation": "The description of the entanglement ('every particle in energy level ε_i is entangled with a particle in the energy level ε_{i+1}') is too vague to rigorously define the set of allowed states or justify the strong constraint (n_i=n_{i+1}) used in the statistical mechanics calculation. Different interpretations of this entanglement could lead to different or no constraints on occupation numbers in the partition function."
      },
      {
        "Problem": "Unsupported claim about fractional statistics from pairwise entanglement",
        "Location": "Section II, first paragraph",
        "Explanation": "The initial claim that the general pairwise entanglement form in Eq (1) implies fractional statistics with a filling factor v=2/M is stated without sufficient justification or derivation. The connection between this specific entanglement structure and the topological properties typically associated with fractional statistics is not established."
      }
    ],
    "token_usage": {
      "input": 6575,
      "thinking": 5647,
      "output": 638
    }
  },
  {
    "entry_id": 87,
    "retraction_id": "2308.02854v2",
    "paper_id": "2308.02854v1",
    "retraction_comment": "The assumption that the convex hull of d+2 points in R^d is either a d-simplex or a bi d-simplex is true only in d<4. In higher dimensions, there are more simplical polytopes, among which the cyclic polytope maximalizes the number of facets. As a consequence, there is no simple linear relation between the number of vertices and facets in d>3, from which one could connect the expected values",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof relies on a linear relation between face counts that is not generally valid for d > 3.",
        "Location": "Section 3, Proof of Theorem 1",
        "Explanation": "The proof assumes that the relation (d - 1) f_0(H_{d+2}) - f_{d-1}(H_{d+2}) = (d - 2) (d + 1) holds for all possible structures of H_{d+2}. While this relation holds when H_{d+2} is a d-simplex (f_0=d+1, f_{d-1}=d+1), it does not hold when H_{d+2} is a simplicial d-polytope with d+2 vertices (f_0=d+2, f_{d-1}=2(d+1)) for d > 3. Since H_{d+2} can be either of these structures (almost surely), the relation does not hold generally, and taking its expectation is invalid, rendering the derived formula unsound for d > 3. The coincidence that this relation holds for both structures in d=3 masked this error."
      }
    ],
    "token_usage": {
      "input": 5531,
      "thinking": 10294,
      "output": 262
    }
  },
  {
    "entry_id": 88,
    "retraction_id": "1501.01153v3",
    "paper_id": "1501.01153v2",
    "retraction_comment": "Submission withdrawn due to the error in equation 35 on dimensional grounds",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect treatment of nucleon gas thermodynamics",
        "Location": "Section 5, Equation (5.14) and subsequent derivations for the baryonic case",
        "Explanation": "The paper models the nucleon gas using the partition function formula for massless fermions (Eq. 3.13), which is inappropriate for massive baryons like nucleons. This invalidates the calculation of nucleon pressure and the subsequent determination of the critical temperature for the baryonic case."
      },
      {
        "Problem": "Unjustified relation between bag constant and glueball mass",
        "Location": "Section 4, Equation (4.2)",
        "Explanation": "The paper establishes a crucial link between the dual QCD model and the bag model by relating the bag constant B to the vector glueball mass mB via a specific formula (Eq. 4.2). This relation is presented without a clear derivation or sufficient theoretical justification within the paper, weakening the foundation of the combined model."
      },
      {
        "Problem": "Use of SU(2) color for QGP analysis",
        "Location": "Section 3, Degeneracy factors (gf, gb) used in Equation (3.15) and throughout the QGP analysis",
        "Explanation": "The paper uses degeneracy factors corresponding to SU(2) color QCD (gf=16, gb=6) for the QGP phase. Standard discussions of QGP and comparisons with lattice QCD results are based on SU(3) color, making the relevance of the presented results to the physical QGP questionable."
      },
      {
        "Problem": "Simplified QGP equation of state",
        "Location": "Section 4, Equations (4.7), (4.8), and Section 5, Equations (5.8), (5.9)",
        "Explanation": "The QGP phase is modeled as a non-interacting gas of massless quarks and gluons plus a bag constant. This ideal gas approximation is a significant simplification, especially near the critical temperature where interactions are known to be strong (as indicated by the paper's own analysis of trace anomaly), limiting the accuracy of the quantitative results and conclusions about the transition dynamics."
      }
    ],
    "token_usage": {
      "input": 21393,
      "thinking": 6215,
      "output": 481
    }
  },
  {
    "entry_id": 89,
    "retraction_id": "1910.10153v2",
    "paper_id": "1910.10153v1",
    "retraction_comment": "The function \\phi(x) which we define above Eq.8 is infinitely peaked in the thermodynamic limit; the long-time-tail behavior enters through higher derivatives of the entropy",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified Spatial Factorization of Many-Body Eigenstates",
        "Location": "Introduction, Derivation section",
        "Explanation": "The core assumption that a many-body eigenstate of the entire system can be approximated as a product of eigenstates of weakly coupled blocks of size $\\xi(\\omega)$ is not a standard consequence of ETH and lacks rigorous justification. ETH describes properties of matrix elements within global eigenstates, not a spatial factorization of the eigenstates themselves. This assumption underpins the entire perturbative calculation of transport."
      },
      {
        "Problem": "Overly Strong RMT/ETH Assumption for Matrix Elements",
        "Location": "Derivation section, Eq. (4)",
        "Explanation": "The assumption that matrix elements of local operators within a thermalized block are constant up to energy differences of order $U$ (Eq. 4) goes significantly beyond the standard understanding of ETH. ETH suggests matrix elements are smooth functions of energy difference, becoming constant only for differences below the block's Thouless energy (which scales as $\\omega$). Assuming constancy up to the bandwidth $U$ implies instantaneous relaxation within the block on timescales much faster than $1/\\omega$, which seems inconsistent with the premise that $\\xi$ is determined by diffusion over time $1/\\omega$."
      },
      {
        "Problem": "Unjustified Incoherent Summation of Current Contributions",
        "Location": "Derivation section, following Eq. (S2)",
        "Explanation": "The derivation assumes incoherent summation of current contributions across the block boundary (sum over $\\ell$ and $O$ in Eq. S2 leading to the factor $L^d/\\xi^{d-1}$). While high temperature might suppress single-particle coherence, it is not clearly justified why many-body matrix elements of local operators across different boundary segments should add incoherently, especially when considering transitions between many-body eigenstates of the blocks. This step relies on an unproven assumption about the structure of many-body eigenstates and current operators in the coarse-grained picture."
      },
      {
        "Problem": "Mixing Zero-Temperature Response and Finite-Temperature Thermodynamics",
        "Location": "Derivation section, leading to Eq. (7) and (S14)",
        "Explanation": "The low-temperature derivation relates the average matrix element between finite-temperature block eigenstates to the zero-temperature non-local conductivity $\\sigma(q=\\xi_T^{-1}, \\nu=T, T=0)$ divided by the density of states at energy $T$. This connection between a zero-temperature ground-state response function and matrix elements between finite-temperature many-body states at energy $T$ seems conceptually problematic and lacks clear justification."
      },
      {
        "Problem": "Validity of Derived Relations Dependent on Unsound Assumptions",
        "Location": "Main Results, Eq. (3); Derivation section, leading to Eq. (9)",
        "Explanation": "The derived generalized Wiedemann-Franz law (Eq. 3/9) and the functional form of $K_{ij}(\\omega)$ rely entirely on the specific expressions obtained from the preceding derivations (Eqs. 5 and 7). Since these derivations are based on several strong and potentially unsound assumptions (spatial factorization of eigenstates, RMT approximation, incoherent summation, low-T matrix element relation), the validity of the derived relations between transport coefficients is directly dependent on the validity of these underlying assumptions."
      }
    ],
    "token_usage": {
      "input": 20473,
      "thinking": 2672,
      "output": 752
    }
  },
  {
    "entry_id": 90,
    "retraction_id": "1306.5006v3",
    "paper_id": "1306.5006v2",
    "retraction_comment": "We have decided to withdraw the paper due to a crucial error in equation (9), that is in the definition of the p-value. This invalidates the results reported into the manuscript",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Multiple Testing Problem in Graphical Interpretation",
        "Location": "Sections 2, 4, 5",
        "Explanation": "The autodependogram and KL-autodependogram use a single critical line at level alpha for simultaneously testing independence at multiple lags. This approach does not control the family-wise error rate (FWER) or false discovery rate (FDR) across lags. Consequently, the probability of falsely identifying at least one significant lag is much higher than alpha, making the visual interpretation of significance misleading."
      },
      {
        "Problem": "Simulation Study Does Not Evaluate Overall Diagram Performance",
        "Location": "Section 6",
        "Explanation": "The simulation study evaluates the size and power of the independence test for each lag individually. It does not assess the performance of the graphical tool (ADF or KL-ADF) in controlling the overall error rate (like FWER or FDR) when considering multiple lags simultaneously, which is the intended use case of the diagram with a critical line. This limits the conclusions about the diagram's effectiveness in practice."
      },
      {
        "Problem": "Application to Potentially Non-Stationary Data",
        "Location": "Section 5",
        "Explanation": "The method relies on assumptions of strict stationarity and ergodicity. The application to financial time series (FTSE MIB returns), which are known to exhibit non-stationarity (particularly in volatility), may violate the assumptions underlying the permutation test and kernel density estimation, potentially affecting the validity of the results and p-values obtained for this real-world example."
      }
    ],
    "token_usage": {
      "input": 13097,
      "thinking": 4041,
      "output": 353
    }
  },
  {
    "entry_id": 91,
    "retraction_id": "1704.08680v6",
    "paper_id": "1704.08680v5",
    "retraction_comment": "Algorithm does not terminate. Even if fixed, Claim 9 is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Theorem 3 analyzes the cost of components built during the primal-dual process, but the algorithm returns an MST on a subset of edges, whose cost is not directly related by the inductive argument.",
        "Location": "Section 5, Proof of Theorem 3, and Section 4, Algorithm descriptions.",
        "Explanation": "The algorithm's final output T^r is the result of computing a Minimum Spanning Tree on the union of Steiner components (edges in L) after the primal-dual phases. The proof of Theorem 3 uses an inductive argument on the cost of components formed *during* the primal-dual growth process. The cost of the final MST c(T^r) is not necessarily equal to the sum of costs of components at the end of the primal-dual growth, nor is it guaranteed to satisfy the inductive inequality c(C) <= (sum_{i in C cap R} z_i(i)) - t for the final single component."
      },
      {
        "Problem": "The proof of Proposition 1, which calculates the hitting time for Steiner nodes, appears incorrect under the variable dual growth rates used in the algorithm.",
        "Location": "Section 5, Proposition 1 and its proof.",
        "Explanation": "Proposition 1 calculates the hitting time tau^r(v) based on linking times t_i and degree delta. Its proof relies on the assumption that the total rate of increase of sum z_v(i) is equal to the number of components v links to. However, the algorithm description for phases ell >= 2 specifies a variable rate for nodes with delta^{ell-1}(v) >= 2, where the rate per linked component is scaled by |Delta^{ell-1}(v) cap L_v^t|/|L_v^t|. This variable rate contradicts the assumption used in the proof of Proposition 1, invalidating the formula for tau^r(v) and consequently the proof of Theorem 3 for Type 2 events."
      },
      {
        "Problem": "Claim 1, which asserts a specific structure for an optimal solution in I_1, is not rigorously proven and relies on questionable arguments about edge costs and connectivity modifications.",
        "Location": "Section 5, Claim 1 and its proof.",
        "Explanation": "The proof attempts to show that if an optimal solution T contains a Steiner component K_v with E(T) cap L_v being a proper non-empty subset of L_v, T can be modified into another optimal solution where E(T) cap L_v is either L_v or empty. The argument involving deleting links of K_u and adding new links with endpoints in R_u is unclear and does not convincingly demonstrate that the modified solution remains optimal or has the claimed structure. This claim is crucial for the proof of Theorem 4."
      },
      {
        "Problem": "Claim 2, which bounds the sum of distortions for links of a partial Steiner component, appears to use a calculation method inconsistent with the variable dual growth rates.",
        "Location": "Section 5, Claim 2 and its proof.",
        "Explanation": "The distortion D(e_i) = d(e_i) - c_1(e_i) is the difference between the final distance d(e_i) and the original cost c_1(e_i) (which equals the linking time t_i). The proof calculates D(e_i) by integrating the rate of increase of d(e_i) over time. The calculation seems to assume a rate of increase for d(e_i) that is derived from the standard synchronous growth logic (e.g., terms like (delta-1)/delta), rather than the specific variable rate |Delta^{r-1}(v) cap L_v^t|/|L_v^t| used in the algorithm for nodes with delta^{r-1}(v) >= 2. This inconsistency invalidates the bound on the sum of distortions."
      },
      {
        "Problem": "The definition of the cost function c_2 in instance I_2 for edges not in L may violate the distance constraints required for Theorem 4.",
        "Location": "Section 5, Theorem 4 and its proof, equations (1) and (2).",
        "Explanation": "Theorem 4 requires d(u,v) <= (7/6) c_2(u,v) for all edges (u,v) in E. For edges (u,v) in E \\ L, c_2(u,v) is defined as (6/7) c_1(u,v). The algorithm guarantees that the final dual solution z satisfies d(u,v) <= c_1(u,v) for edges (u,v) where u is a terminal and v is a Steiner node on the simplex, or both are terminals (after projection). However, there is no guarantee that d(u,v) <= (6/7) c_1(u,v) holds for all edges in E \\ L with respect to the final dual solution z. This violates a necessary condition for z to be a feasible dual solution for the LP on instance I_2 with costs c_2."
      }
    ],
    "token_usage": {
      "input": 20876,
      "thinking": 6633,
      "output": 1147
    }
  },
  {
    "entry_id": 92,
    "retraction_id": "0710.2117v5",
    "paper_id": "0710.2117v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a critical error in the geometric formulation of the principle of inertial motion",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect geometric properties of Lorentz transformations in Euclidean space.",
        "Location": "Section 2.2, Eq. (5), Page 2",
        "Explanation": "The paper claims that Lorentz transformations preserve ratios of lengths, areas, and volumes in 4D Euclidean space (x, y, z, ct). This is fundamentally incorrect. Lorentz transformations preserve the Minkowski interval (c²t² - x² - y² - z²) and do not preserve Euclidean distances or volumes in this space. This undermines the geometric foundation claimed for the Euclidean interpretation of special relativity."
      },
      {
        "Problem": "Apparent mathematical error or misinterpretation in connecting derived motion law to Broekaert's model.",
        "Location": "Section 5.2, Eq. (13) and Eq. (28), Page 8 and 9",
        "Explanation": "The paper claims that the derived equation for radial acceleration in Model 2 (Eq. 28, dv₂(r)/dt) is Broekaert's result from Eq. (13) (Ÿ = rφ² - ...). Eq. (13) is an equation for the second derivative of the radial coordinate (Ÿ or r̈), which includes an angular momentum term (rφ²). Eq. (28) is an equation for the derivative of the radial speed (v̇), which includes a radial speed squared term (v₂(r)²). These equations have different forms and terms and do not appear to be equivalent, suggesting an error in the derivation or comparison that is central to the paper's claim of resolving the incompatibility."
      },
      {
        "Problem": "Unjustified relation between speeds in different models.",
        "Location": "Section 5.2, Eq. (19), Page 9",
        "Explanation": "The relation v₂(r) = v₁(r)e⁻³ᵏ/ʳ between the radial speeds in Model 1 and Model 2 is introduced without clear derivation or justification from the proposed Euclidean geometric framework or the motion law. This relation is crucial for connecting Broekaert's model (Model 2) to the model compatible with the motion law (Model 1) and makes the proposed 'solution' appear ad-hoc rather than a consequence of the framework."
      },
      {
        "Problem": "Lack of clear derivation and justification for the energy conservation equation within the Euclidean framework.",
        "Location": "Section 4, Eq. (9) and (10), Page 7",
        "Explanation": "The energy conservation equation (Eq. 9) is presented, and its transformation to a 'familiar form' (Eq. 10) involving a position-dependent mass m₀(r) is mentioned. However, the specific form of Eq. (9) and its derivation from the Euclidean geometric principles are not clearly shown. The reliance on Broekaert's work, which uses a different interpretation (Lorentz-Poincaré), raises questions about the internal consistency of the derivation within the proposed Euclidean framework."
      },
      {
        "Problem": "Problematic formulation and application of the Euclidean principle of general covariance.",
        "Location": "Section 3.1, Page 6",
        "Explanation": "The principle states that laws are covariant if geometric relations are conserved under coordinate transformations. However, the paper previously claimed that Lorentz transformations (a specific type of coordinate transformation) preserve Euclidean ratios, which is incorrect. If the principle applies to general coordinate transformations in a curved Euclidean space, these transformations would not generally preserve Euclidean ratios, making the condition for covariance difficult to satisfy or apply meaningfully in the way suggested. This inconsistency weakens the foundation of the proposed covariance principle."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 4513,
      "output": 804
    }
  },
  {
    "entry_id": 93,
    "retraction_id": "1111.3825v3",
    "paper_id": "1111.3825v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in lemma 3.7",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of justification for the existence of a real structure and trivial parabolic structure.",
        "Location": "Introduction (Theorem 1.2), Section 3 (Theorem 3.1, Lemma 3.4, Theorem 3.3)",
        "Explanation": "The paper assumes that the harmonic bundle obtained from the Jost-Zuo theorem [JZ] for a reductive representation with unipotent local monodromy possesses a real structure and trivial parabolic structure. These properties are crucial prerequisites for applying several key results from Mochizuki [M] (specifically Theorem 9.3, Theorem 9.6) which are used to prove Lemma 3.3, Lemma 3.4, and Theorem 3.3 (Purity Theorem). The cited Jost-Zuo theorem does not explicitly state that these properties hold for all such representations, leaving a significant gap in the argument."
      },
      {
        "Problem": "Incorrect definition of the operator K.",
        "Location": "Lemma 3.3 and its proof",
        "Explanation": "The proof of Lemma 3.3 attempts to define the operator K by K(v) := deg^{W(N_1,...,N_n)}(v)·v. This definition is mathematically unsound because deg^W(v) is not a scalar value for an arbitrary vector v, but rather defined for elements within the graded pieces of the weight filtration. While an operator K with the stated properties exists (as described in Mochizuki [M] Lemma 9.6, provided a real structure exists), the definition and proof given in the paper are incorrect. This operator K is used in subsequent crucial steps, including the metric estimates (Lemma 3.4) and the definition of operator A (Definition 3.5), which are essential for the eigenvalue bounds (Proposition 3.4)."
      },
      {
        "Problem": "Unjustified application of the Purity Theorem.",
        "Location": "Theorem 3.3",
        "Explanation": "The paper cites Mochizuki [M] Theorem 9.6 for the Purity Theorem (H^k(Π(N_1,...,N_n)) = W_k(H^k(Π(N_1,...,N_n)))). Mochizuki's theorem explicitly requires the existence of a real structure for the harmonic bundle. As noted in the first problem, the paper does not provide justification that the harmonic bundles obtained from the Jost-Zuo theorem always possess a real structure. Without this prerequisite being established, the Purity Theorem cannot be applied, which invalidates the subsequent derivation of eigenvalue bounds (Proposition 3.4) and the final conclusion."
      },
      {
        "Problem": "Eigenvalue bounds are not properly justified.",
        "Location": "Proposition 3.4",
        "Explanation": "Proposition 3.4 provides crucial bounds on the eigenvalues of the operator A. The proof of these bounds in the cited work ([KK] Proposition 5.11.1) relies heavily on the Purity Theorem for the relevant complex and the properties of the operator K and the metric. Since the paper's justification for the existence of a real structure (needed for the Purity Theorem), the correct definition and properties of K (Lemma 3.3), and the metric estimates (Lemma 3.4) are flawed or incomplete, the derivation of these eigenvalue bounds is not sound. These bounds are essential for the final step of the proof relating L^2 cohomology to intersection cohomology."
      }
    ],
    "token_usage": {
      "input": 9988,
      "thinking": 4056,
      "output": 757
    }
  },
  {
    "entry_id": 94,
    "retraction_id": "1711.04838v3",
    "paper_id": "1711.04838v2",
    "retraction_comment": "Lemma 9.1 is incorrect and so the main result is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed argument that a triple point must be type (1) if its b/t edges end in branch points.",
        "Location": "Lemma 8.4, Proof",
        "Explanation": "The proof relies on Remark 6.2(ii), which incorrectly claims that if a triple point color (x,y,z) satisfies x*y=x, then the entire quandle coloring must be trivial (x=y=z). This is not generally true for quandles. Consequently, the conclusion that T_3 must be of type (1) is not supported; it could potentially be of type (4) with x*y=x, which also results in degenerate b/t edges according to Table 1."
      },
      {
        "Problem": "Flawed argument that the other two triple points (T_1, T_2) must be degenerate for a t-minimal diagram with three triple points.",
        "Location": "Lemma 8.5, Proof",
        "Explanation": "The proof depends on the conclusion of Lemma 8.4 (that T_3 is type (1)), which is not correctly proven. Additionally, the proof introduces an inequality (#d(T_1)+#d(T_2)>=4) derived from Lemma 5.1 (Roseman move R6-) without sufficient justification based on the properties of t-minimal diagrams and the specific edge types mentioned in Lemma 8.3. The argument for connecting edges between triple points is also unclear."
      },
      {
        "Problem": "Flawed proof regarding the number of non-trivial double point circles for a genus-one surface-knot with three triple points.",
        "Location": "Lemma 9.1, Proof",
        "Explanation": "The proof contains contradictions regarding the number of triple points on a double point circle (claiming 3 intersections between C^U and C^L when Lemma 2.1 requires an even number, and the diagram has only 3 triple points total). The homology arguments used (e.g., C^U and C^L are homologous in F, C^U union C^L is homologous to zero) are questionable and not properly justified in the context of double decker sets and surface homology."
      },
      {
        "Problem": "Flawed proof that there is no genus-one surface-knot with triple point number three.",
        "Location": "Theorem 9.2, Proof",
        "Explanation": "The proof attempts to rule out possible double point curve configurations using homology arguments that appear incorrect or are based on undefined terms (e.g., C^U union C^L). Specific cases, like case (5), describe impossible geometric configurations (an edge being two types at the same triple point). The overall reasoning based on intersection numbers and homology generators lacks rigor and appears unsound."
      },
      {
        "Problem": "Flawed argument for determining if a diagram is not t-minimal based on a double decker curve bounding a disk.",
        "Location": "Lemma 5.2, Proof",
        "Explanation": "The proof attempts to show that the original triple point T can be eliminated using Roseman moves R5+ and R6- if a decker curve bounds a disk whose projection interior has at most one triple point. The description of how R5+ and R6- are applied to eliminate the *original* triple point T is unclear and does not follow directly from the properties of these moves as stated. This lemma is used in the proof attempt of Theorem 9.2 (Case 5)."
      }
    ],
    "token_usage": {
      "input": 14248,
      "thinking": 10821,
      "output": 777
    }
  },
  {
    "entry_id": 95,
    "retraction_id": "2010.13204v2",
    "paper_id": "2010.13204v1",
    "retraction_comment": "The conclusion of the paper is likely wrong. The second necessary integration step which is barely mentioned at the end of section B introduces another correlation between the vacuum fluctuations which will negate any gain of the here proposed method. I overlooked this. Thanks to [REDACTED-NAME] for figuring it out",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound derivation of the feedback equation for the power signal amplitude.",
        "Location": "Section 2.1, equation for $P_{Sig}$",
        "Explanation": "The equation $P_{Sig} e^{i\\Omega t} = 2E_{0}^{2}gP_{Sig} e^{i\\left(\\Omega(t-2\tau)+\\phi_{RF}\right)} + E_{0}E_{Sig} e^{i\\Omega(t-\tau)}$ assumes a linear relationship between the complex amplitude of the detected power signal at frequency $\\Omega$ and a delayed version of itself, driven by the input field signal. The actual feedback loop involves detecting power (proportional to $|E_{PD}|^2$, a non-linear process) and using it to amplitude modulate a field. This linear model for the power signal amplitude is not justified and likely incorrect, invalidating the subsequent calculation of signal build-up via geometric series."
      },
      {
        "Problem": "Unsound application of the signal feedback equation to noise.",
        "Location": "Section 2.2, equation for $P_{SN}$",
        "Explanation": "The noise analysis applies the same linear feedback equation derived for the coherent signal amplitude ($P_{Sig}$) to the noise amplitude ($P_{SN}$). This fails to account for how incoherent vacuum noise sidebands interact with the LO carrier and propagate through the non-linear detection and modulation process in the feedback loop. The noise propagation is likely different from the signal propagation, invalidating the noise variance calculation and the comparison of SNR to the cavity case."
      },
      {
        "Problem": "Inconsistent comparison of signal quantities between systems.",
        "Location": "Section 2.1, 2.2, and Summary",
        "Explanation": "The paper compares the field amplitude leaving the regeneration cavity ($E_{det}$) to the power signal amplitude detected within the active system ($P_{Sig}$). These are different physical quantities. While the final SNR comparison seems mathematically consistent based on the (potentially flawed) derivations, the intermediate statements about signal gain (e.g., being larger by $1/\tau_1$) are confusing and based on comparing incomparable measures, potentially misleading the reader about the relative performance."
      }
    ],
    "token_usage": {
      "input": 7354,
      "thinking": 5414,
      "output": 491
    }
  },
  {
    "entry_id": 96,
    "retraction_id": "2208.11892v3",
    "paper_id": "2208.11892v2",
    "retraction_comment": "Lemma 3.2 does not hold. A counter example is $f \\equiv 1$",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of L^p error estimate and its use in W^{1,p} estimate",
        "Location": "Proof of Theorem 2.2, specifically derivation of (8.4) and Step 4 of proof of (8.1) for p >= 2",
        "Explanation": "The substitution of the pressure estimate (8.3) into the L^p duality estimate (7.1) appears to be performed incorrectly, leading to an incorrect intermediate estimate (8.4). The subsequent use of this incorrect estimate (8.4) in the kick-back argument for the W^{1,p} estimate (8.1) is thus flawed, undermining the proof of the main velocity error estimate."
      },
      {
        "Problem": "Unjustified lower bound on the range of p",
        "Location": "Theorem 2.1, Theorem 2.2, and proof of Theorem 2.2",
        "Explanation": "The proof for the W^{1,p} error estimate (8.1) only clearly justifies the upper bound p < 2N/(N-2) arising from the kick-back argument. The lower bound p > 2N/(N+2) is stated as a restriction but is not explicitly derived or justified by the presented arguments and estimates. Terms involving negative powers of h (like h^{1-1/p} or h^{-1/p}) appear in intermediate estimates derived from duality and pressure terms, which can become large for small p, but the specific step requiring p > 2N/(N+2) is missing."
      },
      {
        "Problem": "Potentially incorrect boundary-skin estimate for W^{2,p} functions",
        "Location": "Section 2, Eq (2.4), used in Lemma 7.1 and Lemma 7.2",
        "Explanation": "The estimate ||v||_{L^p(∂Ω_h)} <= C h^2 ||∇^2 v||_{L^p(Ω)} for v in W^{1,p}_0(Ω) ∩ W^{2,p}(Ω) seems stronger than standard trace inequalities on approximate domains. While possibly true due to the boundary approximation, its proof is not provided. If this estimate is incorrect, the bounds for the boundary term R'_5 in the duality arguments (Lemma 7.1, 7.2) are incorrect, which impacts the L^p and W^{-1,p} error estimates and potentially the range of p."
      },
      {
        "Problem": "Missing justification for Super-approximation property (H4)",
        "Location": "Section 2, Assumption (H4)",
        "Explanation": "The super-approximation property (H4) is a critical assumption for the local energy estimates (Proposition 5.1, 5.2). While the remark mentions that such operators can be constructed by modifying existing methods for polygonal domains, the specific construction and verification for the chosen interpolants (I_h, J_h) on the polygonal domain Ω_h (which approximates a smooth domain Ω) are not provided. This leaves a gap in the justification of a key assumption underpinning the local analysis."
      },
      {
        "Problem": "Restrictive mesh assumption for Taylor-Hood elements",
        "Location": "Appendix A.2, Theorem A.2",
        "Explanation": "The construction of the interpolation operator I_h for Taylor-Hood elements relies on the assumption that every triangle has at least one interior vertex. This implies that boundary triangles must have exactly two vertices on the boundary ∂Ω_h (and thus on ∂Ω). This is a restrictive condition on the mesh generation near the boundary for a general smooth domain, potentially limiting the applicability of the construction to specific mesh types."
      }
    ],
    "token_usage": {
      "input": 49582,
      "thinking": 34317,
      "output": 829
    }
  },
  {
    "entry_id": 97,
    "retraction_id": "1507.00282v2",
    "paper_id": "1507.00282v1",
    "retraction_comment": "This paper has been withdrawn due to a crucial error in the proof of Proposition 14. The authors are very thankful to [REDACTED-NAME] for kindly pointing it out",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect calculation of Hodge star operator on basis forms.",
        "Location": "Section 3, after equation (4)",
        "Explanation": "The calculation of the Hodge star operator on the basis forms $\rho$ and $J\rho$ appears incorrect. For example, $\\ast(\\varepsilon^1 \\wedge \\varepsilon^3) = \\varepsilon^2 \\wedge \\varepsilon^4$ and $\\ast(\\varepsilon^2 \\wedge \\varepsilon^4) = \\varepsilon^1 \\wedge \\varepsilon^3$. Thus, $\\ast\rho = \\ast(\\varepsilon^1 \\wedge \\varepsilon^3 - \\varepsilon^2 \\wedge \\varepsilon^4) = \\varepsilon^2 \\wedge \\varepsilon^4 - \\varepsilon^1 \\wedge \\varepsilon^3 = -\rho$. This indicates that $\rho$ is anti-self-dual, not self-dual. Similarly, $J\rho$ is anti-self-dual. The statement 'In particular, all J-anti-invariant forms are self-dual' is incorrect based on this calculation. While J-anti-invariant forms are indeed self-dual in dimension 4 (as they are orthogonal to the self-dual form $\\omega$ within the 3-dimensional space of self-dual forms), the basis calculation shown here is flawed, suggesting a potential issue with the chosen basis or the understanding of duality."
      },
      {
        "Problem": "Incorrect calculation in Proposition 7 relating codifferential and Nijenhuis tensor.",
        "Location": "Section 5, Proposition 7, equation (7)",
        "Explanation": "The calculation leading to the identity $\\sum_i \\phi(e_i, J\nabla_{e_i}X - \nabla_{e_i} JX) = \\sum_i \\phi(e_i, (\nabla_{e_i}J)X)$ in equation (7) appears incorrect. The term $J\nabla_{e_i}X - \nabla_{e_i} JX$ is $-(\nabla_{e_i}J)X$. Thus, the sum should be $\\sum_i \\phi(e_i, -(\nabla_{e_i}J)X) = -\\sum_i \\phi(e_i, (\nabla_{e_i}J)X)$. This sign error propagates through the derivation of equation (8) and the subsequent results in Proposition 7, invalidating the stated relation between $\\delta J\\phi + \\delta\\phi(J\\cdot)$ and $g(J\\phi, N_X)$."
      },
      {
        "Problem": "Incorrect calculation of the metric term in Proposition 7.",
        "Location": "Section 5, Proposition 7, equation (8)",
        "Explanation": "The step $\frac14\\sum_{i,j} \\phi(e_i, Je_j)g\\left((\nabla_X J)e_i, Je_j\right) = \frac14\\sum_{i,j} \\phi(e_i, e_j)g\\left((\nabla_X J)e_i, e_j\right)$ in equation (8) is not justified and appears incorrect. The transformation from summing over $Je_j$ to summing over $e_j$ requires a property like $\\phi(e_i, Je_j)g(A_i, Je_j) = \\phi(e_i, e_j)g(A_i, e_j)$ where $A_i = (\nabla_X J)e_i$. This identity does not hold in general. This error further invalidates Proposition 7 and its consequences."
      },
      {
        "Problem": "Incorrect assumption about the Nijenhuis tensor components in Proposition 6.",
        "Location": "Section 5, Proposition 6, proof after equation (6)",
        "Explanation": "The statement 'Here we have used $N(Z_i,\bar{Z}_j)=0$, which follows immediately from (2)' is incorrect. The Nijenhuis tensor $N(X,Y)$ is not zero when evaluated on a vector from $T^{1,0}M$ and a vector from $T^{0,1}M$. Specifically, $N(Z,\bar{W}) = -\frac{1}{2}[Z,\bar{W}]$ for $Z \\in T^{1,0}M$ and $\bar{W} \\in T^{0,1}M$. Since $[Z,\bar{W}]$ is not generally zero, $N(Z,\bar{W})$ is not generally zero. This invalidates the calculation of $(dJ\\phi)^{1,2}$ and the resulting relation in Proposition 6."
      },
      {
        "Problem": "Incorrect derivation of relations on Nijenhuis tensor coefficients in Proposition 8.",
        "Location": "Section 6, Proposition 8, proof after equation (10)",
        "Explanation": "The derivation of the relations $uN_2=vN_1$ and $uN_4=vN_3$ from the equation $2N(J\\phi)(e_2,e_3,e_4) = 4N_1v - 4N_2 u$ (which itself relies on the flawed Proposition 6) is incorrect. The calculation of $2N(J\\phi)(e_2,e_3,e_4)$ in the proof leads to $2[ u(N'_3 - N'_1 - N'_2 - N'_4) + v(2N'_4 - N'_1 - N'_2) ]$. Equating this to $4(uN'_1 - vN_1)$ (derived correctly in the second part of the proof) yields the equation $u(N'_3 - 3N'_1 - N'_2 - N'_4) + v(2N'_4 - N'_1 - N'_2 + 2N_1) = 0$. This is a single linear relation between $u$ and $v$ with coefficients depending on the $N$ and $N'$ functions. It does not imply the two relations $uN_2=vN_1$ and $uN_4=vN_3$ claimed in the proposition. This invalidates the core argument that $h_J^- \\geq 3$ implies the vanishing of the Nijenhuis tensor."
      }
    ],
    "token_usage": {
      "input": 12143,
      "thinking": 36712,
      "output": 1411
    }
  },
  {
    "entry_id": 98,
    "retraction_id": "1707.00947v2",
    "paper_id": "1707.00947v1",
    "retraction_comment": "I am so sorry, the hypothesis proposed by this paper would be not appropriate because there is no mechanism on which can be based between money and output value in this paper. The equation maybe more empty",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Arbitrary and Unjustified Core Dynamic Equation",
        "Location": "Page 4-5, Equation (2)",
        "Explanation": "The fundamental dynamic equation M(t) - P(t)Y(t) = k * d[P(t)Y(t)]/dt is introduced as a 'speculated' equation without theoretical derivation or justification from economic principles. This lack of foundation for the core dynamic relationship makes the subsequent derivations and conclusions questionable."
      },
      {
        "Problem": "Inconsistent Long-Run Velocity Behavior",
        "Location": "Page 7, 8, 9-10",
        "Explanation": "The model predicts different long-run behaviors for the velocity of money (PY/M) depending on the assumed functional form of money supply M(t). It approaches 1 for constant or linear M, but approaches 1/(1+kq) for exponential M. This inconsistency undermines the generality and theoretical coherence of the model's long-run predictions."
      },
      {
        "Problem": "Contradiction Between Model Predictions and Empirical Evidence",
        "Location": "Page 7, 8, 10, 12, Figure 1",
        "Explanation": "The paper presents empirical evidence (Figure 1) supporting the standard quantity theory result c ≈ q - g in the long run. However, the paper's dynamic model only predicts c = q - g for the specific case of exponential money growth (M(t)=M0*e^(qt)) under a condition (q > -1/k). For other cases analyzed (constant M, linear M), the model predicts c = -g. The empirical evidence contradicts the model's predictions for these other cases, suggesting the model is not generally consistent with the data presented."
      },
      {
        "Problem": "Unjustified Hypothesis of Economic Cycles",
        "Location": "Page 13-19, Figures 2, 3, 4, 5, Tables 2, 3",
        "Explanation": "The hypothesis of 'natural cycle' assumes the economy cycles along the long-run equilibrium line c = q - g for a fixed money growth rate q. This cyclical movement is not derived from the core dynamic model (Eq 2), which describes the path towards equilibrium, not cycles along it. The entire framework of natural and driving cycles is built upon this unproven assumption."
      },
      {
        "Problem": "Misinterpretation of Model Results and Causation",
        "Location": "Page 12, 25, 27",
        "Explanation": "The paper misinterprets the derived relationship between price and output (Eq 16) as both a demand and supply function, which is not supported by the model's structure. It also makes strong claims about causation, such as inflation being 'only' caused by accelerated money growth or decelerated output growth, which are not fully or accurately supported by the model's derived long-run relationships."
      }
    ],
    "token_usage": {
      "input": 7606,
      "thinking": 6451,
      "output": 663
    }
  },
  {
    "entry_id": 99,
    "retraction_id": "2212.04536v2",
    "paper_id": "2212.04536v1",
    "retraction_comment": "Thm. A, Cor. B, are incorrect as stated and would require additional assumptions on q (a result of a missing assumption in another paper). Withdrawn until I obtain a working solution",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 12409,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 100,
    "retraction_id": "1405.2435v10",
    "paper_id": "1405.2435v9",
    "retraction_comment": "lemmas 11 is wrong. The conjecture is not proved.",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Definition and properties of L_u matrices are not justified for solutions to M_u L_x = M_s.",
        "Location": "Definition 1 (dL), Lemma 11, Lemma 12",
        "Explanation": "The matrix L_u is defined with a specific structure (units only in column q and one other column). It is not shown that the matrices L_x representing the mapping x such that Gamma u . x = {q} (solutions to M_u L_x = M_s) must have this specific structure. The space generated by matrices with this structure is not necessarily the space containing the actual solutions L_x, invalidating arguments that rely on L_x having this form."
      },
      {
        "Problem": "Unjustified equality L_x = L_beta y in Lemma 12 proof.",
        "Location": "Lemma 12, proof",
        "Explanation": "The proof claims that for minimal solutions L_x of M_u L_x = M_s and L_y of M_u M_beta L_y = M_s, if (S,x)=(S,y), then L_x = L_beta y. Lemma 5 only states L_x is q-contained in any other solution L_z (L_x ⊑_q L_z), not that L_x equals L_z. This equality is crucial for subsequent steps in the proof but is not justified by previous lemmas."
      },
      {
        "Problem": "Flawed argument and circular reasoning in Lemma 10 proof.",
        "Location": "Lemma 10, proof",
        "Explanation": "The proof of Lemma 10, which is essential for Theorem 1, starts with a circular statement assuming the lemma's conclusion. The connection between the length of words considered in the path construction (Lemma 12) and the dimension of the space of L_x matrices is unclear. The argument that a bounded dimension of the space implies the existence of a word u of a certain length with |N(u)| < n-k is not logically sound as presented."
      },
      {
        "Problem": "Incorrect statement about word length and path dimension.",
        "Location": "Section 7, definition of path",
        "Explanation": "The definition of a path states that 'dim(V_p) is not less than |u| in vertices (M_u,L_x) of path p'. The dimension of the space V_p is the number of linearly independent matrices L_x on the path (the path length). The length of the word |u| associated with a vertex is independent of this dimension, and this statement indicates a misunderstanding of the path construction."
      },
      {
        "Problem": "Reliance on unproven properties of L_u in Lemma 11 proof.",
        "Location": "Lemma 11, proof",
        "Explanation": "The proof that a linear combination of L_w matrices that results in a word matrix must be an L_t matrix with the same (S,t) value relies heavily on the specific structure of L_w (units only in two columns). If L_w could have units in more columns (as general solutions L_x might), the argument about the number of units in specific columns would fail, invalidating the conclusion and the dimension bounds derived from it."
      }
    ],
    "token_usage": {
      "input": 23211,
      "thinking": 8005,
      "output": 756
    }
  },
  {
    "entry_id": 101,
    "retraction_id": "1705.07013v2",
    "paper_id": "1705.07013v1",
    "retraction_comment": "The proofs involve use of structured input states which could not be generalized",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect model of universal deletion machine output state",
        "Location": "Section II, Eq. 4 and subsequent text",
        "Explanation": "The output state parametrization (Eq. 4) assumes constant parameters (η₁, η₂, b⃗, tᵢⱼ), implying a state-independent map where the output is the same for all inputs ρ(m⃗) ⊗ ρ(m⃗). However, a universal deletion machine must preserve the input state on one qubit, making its output inherently state-dependent. This fundamental contradiction means the model used does not represent a universal deletion machine. The application of covariance to derive constraints on these assumed constant parameters is also incorrect for a state-dependent map."
      },
      {
        "Problem": "Flawed definition and calculation of Fidelity of Deletion (Fd)",
        "Location": "Section II, Eq. 7 and surrounding text",
        "Explanation": "The definition of fidelity of deletion Fd = (1+η₂)/2 (Eq. 7) is based on ρ²⁰ᵘᵗ₂ = (1+η₂b⃗⋅σ⃗)/2. For a universal machine, ρ²⁰ᵘᵗ₂ should depend on the input state m⃗. If the blank state is fixed (e.g., |0⟩), Fd should be ⟨0|ρ²⁰ᵘᵗ₂(m⃗)|0⟩, which depends on m⃗. The paper's definition implies Fd is independent of m⃗ and related to η₂ in a way that is inconsistent with the covariant form of ρ²⁰ᵘᵗ₂(m⃗). The use of b⃗ as a parameter in the output state form (Eq. 4) while also implicitly relating it to the blank state in the Fd definition is confusing and likely incorrect."
      },
      {
        "Problem": "Incorrect application of the No Communication Theorem (NCT)",
        "Location": "Section II, starting from Eq. 10",
        "Explanation": "The paper applies the No Communication Theorem by comparing sums of output states for inputs like ρ(↑)⊗ρ(↓) (Eq. 10, 11). These inputs are not of the form ρ ⊗ ρ that a deletion machine is defined to act on, and the assumption of pure state outputs for these mixed inputs is incorrect. The NCT condition should be applied to reduced states on one subsystem for specific input mixtures that are locally indistinguishable, which is not done correctly here. The specific mixtures used in the paper do not satisfy the premise of the NCT condition (∑ pᵢ ρᵢ = ∑ qⱼ σⱼ)."
      },
      {
        "Problem": "Contradictory terminology and conceptual misunderstanding",
        "Location": "Section II, first paragraph and Conclusion",
        "Explanation": "The paper repeatedly refers to the object of study as a 'universal state independent deletion machine'. This term is contradictory. A deletion machine's function (preserving one copy of an unknown state) requires its output to be state-dependent. A state-independent map produces the same output regardless of the input state and cannot perform deletion. This fundamental conceptual error invalidates the problem setup and the interpretation of the results."
      }
    ],
    "token_usage": {
      "input": 8093,
      "thinking": 12288,
      "output": 689
    }
  },
  {
    "entry_id": 102,
    "retraction_id": "1801.01544v2",
    "paper_id": "1801.01544v1",
    "retraction_comment": "We withdraw the manuscript because Lemma 2.3 is false",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect scaling in the blow-up argument for a priori estimates.",
        "Location": "Proof of Theorem 3.1 (Page 9-11), Proof of Theorem 1.2 (Page 11), Proof of Theorem A.1 (Page 25), Equation (3.9).",
        "Explanation": "The blow-up argument relies on scaling the equation $(-\\Delta)^s u_k = f(u_k)$ to obtain a limit equation in $\\mathbb{R}^N$. The scaled equation for $v_k(y) = \\lambda_k^{-1} u_k(x_k + \\lambda_k y)$ should be $(-\\Delta)^s v_k(y) = \\lambda_k^{2s-1} f(\\lambda_k v_k(y))$. For $f(u)=u^p$, this is $\\lambda_k^{2s-1+p} v_k(y)^p$. Equation (3.9) incorrectly states $(-\\Delta)^s v_k(y) = v_k(y)^p$. Since $\\lambda_k \\to 0$, this equality requires $2s-1+p=0$, which contradicts the assumption $p>1$. This fundamental error invalidates the blow-up arguments used to prove the a priori estimates in Theorems 3.1, 1.2, and A.1."
      },
      {
        "Problem": "Incorrect inequality used in Lemma 4.1.",
        "Location": "Proof of Lemma 4.1 (Page 14), inequality (4.6).",
        "Explanation": "The inequality (4.6), $\\int_\\Omega u \\phi_1 dx \\le (2\\lambda_1)^{-1} \\int_\\Omega u^p \\phi_1 dx + (2\\lambda_1)^{-1} \\int_\\Omega \\phi_1 dx$, is used to derive crucial $L^1$ and $L^p(\\Omega, \\delta^s)$ estimates for weak solutions in Lemma 4.1. This inequality appears to be incorrectly derived from Young's inequality or other standard estimates. Lemma 4.1 is a foundational result for the existence theorems (Theorem 1.7, 1.8, 1.10) and the regularity result (Proposition 1.6). Its unsoundness undermines the validity of these subsequent theorems."
      },
      {
        "Problem": "Flawed bootstrap argument for regularity of weak solutions.",
        "Location": "Proof of Proposition 1.6 (Page 12-14).",
        "Explanation": "The proof attempts to show that a weak solution is locally $C^{2s+\\alpha}$ by an iterative bootstrap argument on $L^q$ norms on shrinking balls, using Lemma 2.8(ii). This lemma requires the $L^t$ exponent of the source term to be less than $N/2s$. The argument defines a sequence of exponents $t_k$ and claims $t_{k+1} > t_k$. The conditions required for applying Lemma 2.8(ii) and for the exponent to increase are not rigorously shown to hold for $p$ in the assumed range $(1, p_s)$, making the regularity result questionable."
      },
      {
        "Problem": "Potential issue with integrability assumption in the Mountain Pass argument.",
        "Location": "Proof of Theorem 1.10 (Page 22-23), Claim 2.",
        "Explanation": "The proof of Claim 2, essential for establishing the Palais-Smale condition for the Mountain Pass functional, requires the term $\\int_\\Omega u_\\rho^{p-1} v_n (v_n - v) dx$ to converge to zero. This relies on $u_\\rho^{p-1} \\in L^2(\\Omega)$. Using the estimate $u_\\rho(x) \\le C \\rho |x|^{-(N-s)}$ near $x=0$, the integrability requires $2(p-1)(N-s) < N$. This condition is not guaranteed by the assumption $p < p_s = \\frac{N+s}{N-s}$ unless $N > 4s$. If $N \\le 4s$, the integrability might fail, potentially invalidating the proof of Claim 2 and the existence of a second solution via the Mountain Pass theorem (Theorem 1.10) in this case."
      }
    ],
    "token_usage": {
      "input": 7090,
      "thinking": 10705,
      "output": 1001
    }
  },
  {
    "entry_id": 103,
    "retraction_id": "2101.02111v2",
    "paper_id": "2101.02111v1",
    "retraction_comment": "We have found some data mistakes in our paper. The inverse transition in Section 3 (Figure 3d) and 7.1 (Figure 31) is probably consequence of inappropriate mesh configuration",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound assumption of negligible mean radial velocity in budget and global energy balance derivations.",
        "Location": "Section 4.2 (Reynolds stress transport equation budget) and Section 4.3 (Global energy balance)",
        "Explanation": "The derivations of the Reynolds stress transport equations and the global mean kinetic energy balance assume that the mean radial velocity ($\\overline{u_r}$) is negligible. While this might be true for some cases, the authors themselves note that $\\overline{u_r}$ is non-negligible for the ($\\lambda_z^+,A^+$)=(1695,30) case. Streamwise-varying forcing in a cylindrical geometry can induce mean secondary flows ($\\overline{u_r}, \\overline{u_\\theta}$) that are non-zero even after time and circumferential averaging. Omitting terms involving $\\overline{u_r}$ (e.g., mean convection) in the budget equations and the global energy balance equations makes these derivations incomplete and potentially incorrect, leading to misinterpretations of energy transfer and dissipation, especially for cases where mean secondary flow is significant."
      },
      {
        "Problem": "Potential influence of computational domain length on laminarization conclusion.",
        "Location": "Section 3.1 (Drag reduction performance) and Section 6.1 (Some issues regarding the inverse transition)",
        "Explanation": "The paper reports laminarization for certain control parameters. However, the computational pipe length ($3\\pi D$) is relatively short compared to the length scales of turbulent structures (like puffs or slugs, which can be $\\mathcal{O}(20D)$) known to be relevant for transition and turbulence decay in pipe flow at similar Reynolds numbers. While the authors acknowledge this limitation in the discussion, the conclusion that laminarization is achievable might be specific to this domain size. A domain too short to sustain these larger structures might lead to turbulence decay or laminarization that would not occur in a longer pipe, making the conclusion about the control's ability to laminarize potentially dependent on the computational setup rather than solely the control mechanism."
      }
    ],
    "token_usage": {
      "input": 45900,
      "thinking": 4183,
      "output": 453
    }
  },
  {
    "entry_id": 104,
    "retraction_id": "1703.04839v2",
    "paper_id": "1703.04839v1",
    "retraction_comment": "Our discussion omits the dominant tree-level shift (discussed in 1203.0237) of the Higgs quartic coupling in the full theory relative to the Higgs quartic coupling of the low-energy effective Standard Model. This shift can easily the electroweak vacuum. Therefore our conclusions (and upper bound on $f_a$) are invalid",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Renormalization Group Precision",
        "Location": "Section 2, RG equations and discussion of SM parameters/instability scale",
        "Explanation": "The calculation combines different levels of precision in the Renormalization Group equations (e.g., 1-loop for BSM contributions, 2-loop for SM, while relying on SM instability scale derived from higher loops). This inconsistency can lead to an inaccurate determination of the electroweak vacuum stability boundary in the combined model, affecting the derived upper bound on f_a."
      },
      {
        "Problem": "Simplified Effective Potential Approximation",
        "Location": "Section 2, Eq. 6",
        "Explanation": "The effective potential is approximated as V(h) ≈ λ_h(h) h^4/4. A more complete RG-improved potential includes additional terms (e.g., logarithms) that affect the shape of the potential and the precise location of minima or instability points. Using this simplified form may lead to an inaccurate calculation of the stability condition and the resulting bound on f_a."
      },
      {
        "Problem": "Approximate Threshold Treatment in RG Running",
        "Location": "Section 2, description of s_ϕ, s_Q factors",
        "Explanation": "The decoupling of heavy particles in RG running is modeled using sharp step functions (s_ϕ, s_Q). A more accurate treatment involves smooth transition functions. This approximation can affect the precision of the RG running near threshold scales, impacting the calculated stability boundary and the derived bound on f_a."
      }
    ],
    "token_usage": {
      "input": 8870,
      "thinking": 5692,
      "output": 368
    }
  },
  {
    "entry_id": 105,
    "retraction_id": "1704.03487v2",
    "paper_id": "1704.03487v1",
    "retraction_comment": "Due to the limitations of the interatomic potential used, it was not possible to ensure the accuracy of some of the results in the paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound application of activation energy model for shearing",
        "Location": "Section 4.3, Eq. 4, Fig. 8, Conclusions",
        "Explanation": "The paper uses Friedel's model (Eq. 4) with a 2/3 exponent, which is typically derived for obstacles overcome by bowing (like Orowan or solid solution strengthening), to interpret the activation energy for a shearing mechanism. This model may not accurately describe the stress dependence of the activation energy for shearing, potentially leading to an incorrect quantitative estimate of the activation free energy and an unreliable comparison to other systems like Al-Cu."
      },
      {
        "Problem": "Unvalidated accuracy of interatomic potential for precipitate/interface interaction",
        "Location": "Section 3.1, Section 4.1, Section 4.2, Conclusions",
        "Explanation": "The accuracy of the chosen Mendelev interatomic potential for capturing the energy landscape of dislocation-precipitate interaction, specifically the relative energies of shearing vs. bypassing and the energy cost of creating defects within the precipitate or at the interface during shearing, is not sufficiently validated. While it avoids a specific artifact seen with other potentials, the fundamental energy landscape governing the preference for shearing over bypassing and the resistance to shearing is critical to the paper's conclusions but relies heavily on the potential's accuracy in this complex system."
      },
      {
        "Problem": "Limited precipitate size range studied may not capture mechanism transition",
        "Location": "Section 4.1, Section 4.2, Section 4.3, Conclusions",
        "Explanation": "The simulations are limited to precipitate diameters up to 10 nm. In many alloy systems, the mechanism by which dislocations overcome precipitates transitions from shearing to bypassing (Orowan) as the precipitate size increases. If this transition occurs for Mg17Al12 precipitates larger than 10 nm, the conclusions about shearing being the dominant mechanism and its implications for limited hardening may not apply to alloys containing larger precipitates, which can be present depending on the aging treatment."
      }
    ],
    "token_usage": {
      "input": 16979,
      "thinking": 4276,
      "output": 455
    }
  },
  {
    "entry_id": 106,
    "retraction_id": "2402.04633v2",
    "paper_id": "2402.04633v1",
    "retraction_comment": "An auxiliary result (Theorem 2.4) turns out to be wrong. This invalidates the proof of the main result",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Heavy reliance on a complex adiabatic limit estimate from prior work",
        "Location": "Step 1 of the proof of Proposition 3.1, specifically the application of Corollary 3.3",
        "Explanation": "The proof of the crucial convergence property for the lifted sequence (Corollary 3.3, derived from Theorem B in \\cite{Alvarez1}) relies on a non-trivial estimate (Lemma 3.2 in \\cite{Alvarez1}) for the rescaled Dirac operator $D_h$. This estimate states that the $H^1$ norm of a form is bounded by its $L^2$ norm and the $L^2$ norm of $D_h$ applied to the form, with a constant independent of the scaling parameter $h \\in (0,1]$. While this result is cited from a published paper, its complexity and the fact that the entire proof hinges upon this specific property make it a significant point of reliance. Assuming the correctness and uniform constant property of this lemma from \\cite{Alvarez1}, the subsequent steps in the paper appear sound."
      }
    ],
    "token_usage": {
      "input": 39540,
      "thinking": 23458,
      "output": 244
    }
  },
  {
    "entry_id": 107,
    "retraction_id": "2408.08124v4",
    "paper_id": "2408.08124v3",
    "retraction_comment": "Achieving reliable simulation of closed new domain formation processes using a single phase-field method is unconvincing and requires the use of multiple algorithms for parallel comparison with experiments",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Cutoff frequency calculation error",
        "Location": "Section III, last paragraph",
        "Explanation": "The calculated cutoff frequency using the provided transconductance (gm = 2.75 µS) and input capacitance (Cgs = 12.10 aF, assuming Cgd is negligible or included) is approximately 36.2 GHz (ft = gm / (2πCgs)). This is significantly lower than the reported 0.228 THz (228 GHz), invalidating the claim of achieving a sub-terahertz cutoff frequency."
      },
      {
        "Problem": "Contradiction regarding vacuum in the microcavity",
        "Location": "Section III, first paragraph",
        "Explanation": "The paper states that the air pressure inside the microcavity is determined by the chamber pressure before deposition. This implies the cavity is filled with gas at some pressure, not a vacuum. This contradicts the concept of a 'vacuum microcavity' and the assumption of ballistic electron transport, which is crucial for the claimed high-frequency performance of vacuum field emission devices."
      },
      {
        "Problem": "Insufficient detail on performance simulation methodology",
        "Location": "Section III",
        "Explanation": "The paper mentions using 'charged particle tracking physical field' simulation but does not clearly explain how the electrical parameters necessary for the cutoff frequency calculation (transconductance gm and gate capacitance Cgs+Cgd) were extracted from this simulation. This lack of detail makes the simulation results and the derived cutoff frequency unverifiable and potentially unreliable."
      },
      {
        "Problem": "Inconsistency in fabrication process description",
        "Location": "Section III, third paragraph, and Fig 2",
        "Explanation": "The paper claims that the lithography step shown in Fig 2(b) (presumably referring to the step that creates the pattern in Fig 2(c)) is nonessential. However, Fig 2(b) shows the coating covering the gate area, which would lead to a short circuit. The lithography step to pattern the coating (as implied by Fig 2(c)) appears necessary for the device to function as a transistor, suggesting a misunderstanding or misstatement about the proposed fabrication process."
      },
      {
        "Problem": "Low reported on-state current",
        "Location": "Section III, last paragraph, and Fig 3(b)",
        "Explanation": "The simulation results in Fig 3(b) show an on-state current in the microampere range (up to ~9 µA). While the collection efficiency is high, this current level is typically very low for a high-frequency transistor operating in the THz range and might limit the device's practical power handling capability, despite the claimed high cutoff frequency (even if the calculation were correct)."
      }
    ],
    "token_usage": {
      "input": 898,
      "thinking": 3161,
      "output": 623
    }
  },
  {
    "entry_id": 108,
    "retraction_id": "1901.08297v2",
    "paper_id": "1901.08297v1",
    "retraction_comment": "The significance and novelty of the paper were not addressed. There are a couple of errors about calculations: the excitonic decay rates were computed by solving Eq (11), not based on Eq. (13) that was only an initial guess for the decay rate",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound handling of non-adiabatic coupling breakdown in non-radiative relaxation calculation.",
        "Location": "Page 10, Section II.B.",
        "Explanation": "The authors state that states where the non-adiabatic coupling term is large are neglected in the MEG analysis because their approximation yields \"artificially large\" non-radiative rates. This exclusion removes potentially dominant non-radiative relaxation pathways from the analysis, leading to an incorrect assessment of the competition between MEG and non-radiative relaxation and potentially invalidating conclusions about which process dominates and the existence of phonon bottlenecks."
      },
      {
        "Problem": "Approximation used for calculating excitonic inelastic scattering rates lacks sufficient validation.",
        "Location": "Page 3, Introduction; Page 6, Eq. 13 and surrounding text.",
        "Explanation": "The core rate for the MEG process in excitons (inelastic scattering rate) is calculated using an approximation (Eq. 13) that simplifies the dynamic Bethe-Salpeter equation. This approximation's validity is primarily supported by agreement with a more rigorous method for a smaller cluster (Si20). Its accuracy for the larger clusters (Si26, Si46) and the high excitation energies relevant for MEG is not sufficiently demonstrated, potentially leading to inaccurate MEG rates."
      },
      {
        "Problem": "Reliance on a crude model for non-radiative relaxation rates.",
        "Location": "Page 10, Section II.B.",
        "Explanation": "The non-radiative relaxation rates are calculated using a model based on the adiabatic approximation and perturbation theory, which the authors themselves acknowledge as a \"crude model\". This approach may not accurately capture the complex electron-phonon dynamics and non-adiabatic effects in silicon clusters, especially for high-energy excitations relevant to MEG, potentially leading to unreliable non-radiative rates used for comparison with MEG rates."
      },
      {
        "Problem": "Neglect of intersystem crossing as a relaxation pathway for excitons.",
        "Location": "Page 12, Section III.",
        "Explanation": "The analysis of relaxation pathways for excitons only considers internal conversion and neglects intersystem crossing from singlet to triplet states due to spin-orbit coupling. While spin-orbit coupling might be relatively weak in silicon, this omission could still represent a significant relaxation channel for higher-energy singlet excitons, potentially affecting their lifetime and the overall assessment of MEG efficiency."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 4450,
      "output": 528
    }
  },
  {
    "entry_id": 109,
    "retraction_id": "1705.01127v2",
    "paper_id": "1705.01127v1",
    "retraction_comment": "Paper has been withdrawn since we find that dust effects have an unignorable impact on our analyses. A part of analyses are reported by arXiv:1809.03715",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Severe sample completeness and bias",
        "Location": "Section 2, Figure 1, Section 4.1, Section 4.2",
        "Explanation": "The sample is severely incomplete (e.g., 2.6% above 1 Msun/yr SFR) due to the requirement for AKARI detection, biasing the sample towards galaxies with high IR luminosities. This likely excludes a significant population of galaxies with potentially different Hα/UV ratios (e.g., low IR/UV, high Hα/UV), which could significantly affect the observed distribution of Hα/UV and the strength of its correlation with ΔMS, potentially invalidating the quantitative conclusions about scatter reduction."
      },
      {
        "Problem": "Definitional coupling in correlation analysis",
        "Location": "Section 3, Section 4.1",
        "Explanation": "The deviation from the main sequence (ΔMS) is defined based on the Hα-inferred SFR, and the Hα/UV ratio directly includes the Hα-inferred SFR. This mathematical coupling between the two variables being correlated means that a correlation is expected even if the underlying physical relationship is less direct, making it difficult to isolate the specific contribution of SFH variability versus other factors causing discrepancies between Hα and UV+IR SFRs."
      },
      {
        "Problem": "Strong assumption about Hα/UV interpretation",
        "Location": "Introduction, Section 3, Section 4.1",
        "Explanation": "The paper's core interpretation relies on the assumption that the dust-corrected Hα/UV ratio is primarily a tracer of recent SFH variability (≲ 100 Myr). However, other factors such as variations in the Initial Mass Function (IMF), dust geometry, ionization parameter, or escape fraction of UV photons can also influence this ratio. The paper does not sufficiently explore or rule out the possibility that these other factors might contribute significantly to the observed scatter in Hα/UV and its correlation with the main sequence deviation."
      }
    ],
    "token_usage": {
      "input": 8320,
      "thinking": 4056,
      "output": 445
    }
  },
  {
    "entry_id": 110,
    "retraction_id": "2105.03304v2",
    "paper_id": "2105.03304v1",
    "retraction_comment": "Eq (2.4) is not correct and as such this invalidates Theorem 2.3 and consequently all the claimed results on the modulus of the zeros of chromatic polynomial. As fas as we can tell the results for the edge based block polynomials are correct (this concerns Sections 4 and 5). We will probably resubmit this part as part of a new paper at some point in the future",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect decomposition of blocks in Lemma 2.3.",
        "Location": "Lemma 2.3, Proof",
        "Explanation": "The proof claims that for a connected set S', the blocks B(S') can be decomposed into the blocks of a block path P ⊆ G[S'] and the blocks of the components of G[S'] - E(P). This decomposition of blocks is generally incorrect. The blocks of a subgraph are not necessarily blocks of the supergraph, and the union of blocks of subgraphs does not necessarily form the blocks of the union graph. This invalidates the lemma and its use in Theorem 2.2."
      },
      {
        "Problem": "Incorrect decomposition of blocks in Lemma 4.3.",
        "Location": "Lemma 4.3, Proof",
        "Explanation": "Similar to Lemma 2.3, the proof claims that for an edge set F, the blocks B(V,F) can be decomposed based on an edge-maximal block path H ⊆ (V,F). This decomposition of blocks is generally incorrect, invalidating the lemma and its use in Theorem 4.2."
      },
      {
        "Problem": "Incorrect bounding step in Corollary 3.3.",
        "Location": "Corollary 3.3, Proof",
        "Explanation": "The proof bounds the sum over block paths BP(v,U;G) by a sum over trees T(v,U;G). Specifically, the step ∑_{S∈ BP(v,U;G)} q^{|S|-1}∏_{B∈ B(S)} ∑_{F ⊆ E(B), (B,F) tree} 1 ≤ ∑_{T∈ T(v,U;G)}q^{|E(T)|} is not justified. The set of spanning trees of graphs G[S] for S ∈ BP(v,U;G) is not a subset of T(v,U;G), nor is there a clear weight-preserving map between them that would support this inequality. This invalidates the bound used in the chromatic polynomial application."
      },
      {
        "Problem": "Incorrect statement and proof of Lemma 3.6.",
        "Location": "Lemma 3.6, Statement and Proof",
        "Explanation": "The lemma provides a bound on the sum of q^{|S|-1} over paths S ∈ Π(v,U;T) in a tree T. The inductive step in the proof appears incorrect. The sum over paths starting with an edge to a child v_i ∉ U should be ∑_{i=1}^{Δ-d} q ∑_{S' ∈ Π(v_i, U; T_i)} q^{|S'|-1}, and applying the inductive hypothesis qΔ to the inner sum leads to q(Δ-d)qΔ, which does not yield the desired bound qΔ for the total sum. This invalidates the bound used for large girth graphs."
      },
      {
        "Problem": "Incorrect bounding step in Lemma 5.5.",
        "Location": "Lemma 5.5, Proof",
        "Explanation": "The proof bounds the sum over edge block paths BP*(v,U;G) by a sum over closed walks W^ℓ_v. Specifically, the step ∑_{H∈ BP*(v,U;G)} (|z|a)^{|E(H)|} ≤ ∑_{ℓ≥ 3}W^ℓ_v(|z|a)^ℓ is incorrect. Edge block paths from v to U are not necessarily closed walks starting at v. This invalidates the bound used in the Ising model application."
      }
    ],
    "token_usage": {
      "input": 21533,
      "thinking": 8669,
      "output": 961
    }
  },
  {
    "entry_id": 111,
    "retraction_id": "1608.03378v2",
    "paper_id": "1608.03378v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in equation 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation of mobility data for composite model analysis",
        "Location": "Page 5, Discussion section, paragraph starting \"In our film...\"",
        "Explanation": "The calculation of the geometric parameter (l2/l1) in the composite model relies on the ratio of mobilities in the grain and intergrain regions (mu1/mu2). The paper claims this ratio is \"aroud 200\" based on Figure 6. However, Figure 6 shows the measured effective mobility of the entire composite film, not the individual mobilities of the different phases. Using the effective mobility value directly as the ratio of individual mobilities is a fundamental error in applying the composite model equations, invalidating the derived geometric parameter beta (l2/l1 = 1/4) and the conclusion about the untransitional phase length."
      },
      {
        "Problem": "Inappropriate application of intrinsic semiconductor model for band gap calculation",
        "Location": "Page 5, Discussion section, paragraph starting \"The temperature dependent carrier concentration allows us...\"",
        "Explanation": "The band gap of the semiconducting phase is calculated using the formula for intrinsic carrier concentration in a simple band semiconductor (Eq 14) and plotting ln(n/T^3/2) vs 1/T. VO2 is a strongly correlated electron material, often described as a Mott or Peierls insulator, not a simple intrinsic semiconductor. Its low-temperature transport may involve mechanisms like hopping or variable range hopping, especially in thin films with defects and grain boundaries. Applying the intrinsic semiconductor model without justification is inappropriate and likely leads to an incorrect or misleading band gap value."
      },
      {
        "Problem": "Inconsistency in composite model application above and below MIT",
        "Location": "Page 4-5, Discussion section, paragraphs discussing the composite model application",
        "Explanation": "The composite model is applied differently above and below the MIT. Above MIT, the intergrain region is assumed highly resistive (Schottky barrier), significantly affecting n*. Below MIT, the intergrain region resistivity is assumed comparable to grains (alpha ~ 1), leading to the conclusion that n* is approximately equal to the grain concentration n1. If the intergrain region has a significant volume fraction (beta = 1/4) and its resistivity is comparable to the grains (alpha ~ 1), the composite model equations predict that the intergrain properties should still significantly influence n*. The conclusion n* ~ n1 below MIT appears inconsistent with the model structure and parameters derived for the metallic phase, or it relies on unstated assumptions about the low-temperature behavior of the intergrain phase within the model."
      },
      {
        "Problem": "High film roughness not discussed as affecting transport properties",
        "Location": "Page 2, Table I and associated text describing XRR results",
        "Explanation": "The X-ray reflectivity analysis indicates a high film roughness (55 Å) relative to the film thickness (422 Å). High surface and interface roughness can significantly affect charge transport in thin films due to scattering, non-uniform current paths, and variations in local film properties. These effects can influence the measured effective resistivity, Hall coefficient, and mobility, and may complicate the interpretation based on bulk-like models or simple composite models that assume uniform regions. The paper does not discuss the potential impact of this significant roughness on the transport measurements or their interpretation."
      },
      {
        "Problem": "Lack of justification for specific composite model geometry",
        "Location": "Page 4, Discussion section, paragraph starting \"Here, we attempted to interpret...\"",
        "Explanation": "The analysis relies on a specific composite cube model (Volger's model, as presented in Ref 26) without providing justification for why this idealized geometry is appropriate for describing the complex grain structure and transport in the sputtered polycrystalline VO2 thin film. While some aspects of transport in inhomogeneous materials might be insensitive to geometry, applying a specific model without discussing its limitations or suitability for the actual film morphology weakens the validity of the quantitative conclusions derived from that model, such as the calculated geometric parameter (l2/l1)."
      }
    ],
    "token_usage": {
      "input": 1930,
      "thinking": 3381,
      "output": 891
    }
  },
  {
    "entry_id": 112,
    "retraction_id": "1709.00434v2",
    "paper_id": "1709.00434v1",
    "retraction_comment": "Some of the content, including the assumption of vanishing vector potential at the interface and the application of the formalism to the gapped Dirac materials, are wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption of vanishing vector potential at the interface",
        "Location": "Eq. 17",
        "Explanation": "The assumption that the vector potential $\\bm{A}$ vanishes completely at the interface ($z=0$) is a strong simplification. In electrodynamics, non-zero current densities (like those in the graphene layer) are generally associated with non-zero vector potentials. This assumption is unlikely to hold generally and is not a consequence of the chosen Coulomb gauge alone. It simplifies the electric field expression at the interface but may neglect important contributions to the electromagnetic fields and the resulting current density, potentially affecting the validity of the derived dispersion relation."
      },
      {
        "Problem": "Unsound derivation of edge charge density",
        "Location": "Eqs. 30-32",
        "Explanation": "The derivation of the edge charge density $\\bar{\rho}^{\\,\\pm}_{\\textsc{\\tiny{ED}}}\\!\\left(y\\right)$ from the continuity equation results in an expression (Eq. 31) that includes the derivative of the potential $\\frac{\\mathrm{d}\\bar{\\Phi}^{\\pm}\\!\\left(y\\right)}{\\mathrm{d} y}$ evaluated at $y=0$ inside a Dirac delta function. Since $\\bar{\\Phi}^{\\pm}\\!\\left(y\\right)$ has a discontinuous derivative at $y=0$, this term is ill-defined. The correct approach requires carefully handling the derivative of the product of the Heaviside function and the current density components, leading to a delta function term whose coefficient is the jump in the current component, not involving the undefined derivative of the potential at the boundary."
      },
      {
        "Problem": "Incorrect decomposition of the differential equation for the potential",
        "Location": "Eqs. 46-49",
        "Explanation": "The differential equation for the potential $\\bar{\\Phi}^{\\pm}\\!\\left(y\\right)$ (Eq. 46) has a source term containing a Dirac delta function at $y=0$ (from the edge charge density). Decomposing this equation into separate homogeneous/inhomogeneous equations for $y<0$ and $y>0$ (Eqs. 47, 48) is mathematically incorrect. Applying the differential operator $\\hat{\\mathcal{O}}_{\textsc{\\tiny{0}}}^{y}$ to the piecewise function $\\bar{\\Phi}^{\\pm}\\!\\left(y\\right)$ (Eq. 49) generates delta function terms at $y=0$ on the left-hand side, which are not present in the split equations. The effect of the delta function source term should be incorporated through jump conditions when matching solutions of the homogeneous equation across the boundary, not by splitting the inhomogeneous equation this way."
      },
      {
        "Problem": "Incorrect derivation of the potential derivative jump condition",
        "Location": "Eqs. 54-55",
        "Explanation": "The jump condition for the derivative of the potential at $y=0$ is derived by integrating the differential equation (Eq. 46) across the boundary. This jump should be equal to the negative of the coefficient of the Dirac delta function in the source term. However, the derivation in Eq. 54 uses the incorrectly derived edge charge density (Problem 2) and appears to incorrectly evaluate the integral involving the delta function and the discontinuous derivative, leading to an incorrect jump condition and consequently an incorrect expression for the decay constant $\\kappa_<^{\\pm}$ (Eq. 55). This error propagates directly to the final dispersion relation."
      },
      {
        "Problem": "Insufficient justification for the kernel approximation",
        "Location": "Eqs. 40-44",
        "Explanation": "The approximation of the exact kernel function $L(y)$ by $L_0(y)$ (Eq. 40) is justified by matching the first three moments. While this ensures some similarity in the overall shape, it does not guarantee that the differential operator derived from $L_0(y)$ (Eq. 44) accurately captures the behavior of the original integral operator, especially concerning the handling of discontinuities and the derivation of boundary conditions at the edge. A more rigorous justification is needed to ensure that replacing the integral equation with the derived differential equation is valid in this context."
      }
    ],
    "token_usage": {
      "input": 12356,
      "thinking": 15690,
      "output": 967
    }
  },
  {
    "entry_id": 113,
    "retraction_id": "1610.01669v7",
    "paper_id": "1610.01669v6",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error on linear implication between games",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of Predicative Games",
        "Location": "Definition 3.10",
        "Explanation": "The definition of the set of moves `M_G` for a predicative game `G` as `\\sum_{\\sigma \\in \\mathsf{st}(G)}M_\\sigma` omits the initial question move `q_G` and the strategy name moves `\\circled{sigma}`, despite these moves being used in the definitions of the enabling relation `\\vdash_G` and the set of valid positions `P_G`. This makes the fundamental structure of a predicative game ill-defined."
      },
      {
        "Problem": "Incorrect definition of Product and Composition of PLIs",
        "Location": "Definitions 3.14 and 3.15",
        "Explanation": "The definition of a product of point-wise linear implications (PLIs) as a strategy (`&_{\\sigma : A} \\phi_\\sigma`) has an unusual and likely incorrect definition of its moves and positions. Furthermore, the definition of composition of PLIs (`\\psi \\circ \\phi`) defines a family of strategies, not a single strategy, which is required for composition in a category."
      },
      {
        "Problem": "Incorrect definition of composition in the category WPG",
        "Location": "Definition 3.19",
        "Explanation": "The composition `\\psi \bullet \\phi \\stackrel{\\mathrm{df. }}{=} \\psi \\circ \\phi^\\dagger` is defined using `\\phi^\\dagger` which, based on Theorem 3.9, appears to be the exponential of the game `\\widehat{\\phi}`. This is a game, not a strategy of the correct type (`!A \\multimap !B`) needed for composition with `\\psi : B \to C` (a strategy on `!B \\multimap C`). This confusion between games and strategies makes the category definition unsound."
      },
      {
        "Problem": "Incorrect definitions of CwF projections",
        "Location": "Definition 4.5 (definitions of `p` and `v`)",
        "Explanation": "The first projection `p(A)` is defined as the dereliction `der_\\Gamma`, which is a strategy on `!\\Gamma \\multimap \\Gamma`. However, `p(A)` should be a strategy on `!\\widehat{\\sum}(\\Gamma, A) \\multimap \\Gamma`. Similarly, the second projection `v_A` is defined as `der_{\\uplus A}`, a strategy on `!(\\uplus A) \\multimap \\uplus A`, but it should be a strategy on `!\\widehat{\\sum}(\\Gamma, A) \\multimap \\uplus A\\{\\mathit{p}(A)\\}`. These definitions assign strategies to games of the wrong type, invalidating the CwF structure."
      },
      {
        "Problem": "Incorrect definition of CwF extension (pairing)",
        "Location": "Definition 4.5 (definition of `\\langle\\_,\\_\rangle_\\_`)",
        "Explanation": "The extension `\\langle \\phi, \tau \rangle_A` should be a morphism `\\Delta \to \\Gamma . A`, i.e., a strategy on `!\\Delta \\multimap \\widehat{\\sum}(\\Gamma, A)`. It is defined as the pairing `\\langle \\phi, \tau \rangle`, where `\\phi : \\Delta \to \\Gamma` (strategy on `!\\Delta \\multimap \\Gamma`) and `\tau : \\widehat{\\prod}(\\Delta, A\\{\\phi\\})` (strategy on `!\\Delta \\multimap \\uplus A\\{\\phi\\}`). The pairing `\\langle \\phi, \tau \rangle` results in a strategy on `!\\Delta \\multimap \\Gamma \\& \\uplus A\\{\\phi\\}`, which is not the required target game `\\widehat{\\sum}(\\Gamma, A)`. This invalidates the CwF structure."
      }
    ],
    "token_usage": {
      "input": 106551,
      "thinking": 6658,
      "output": 876
    }
  },
  {
    "entry_id": 114,
    "retraction_id": "1605.05588v2",
    "paper_id": "1605.05588v1",
    "retraction_comment": "It had to be noted that the assumption was made that all sensors have access to all observations and state estimate vectors. In addition, the summations in the DAQKF Algorithm are on all sensors, not just the neighbouring sensors",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Distributed Algorithm Structure",
        "Location": "Algorithm 3, Measurement update step",
        "Explanation": "The algorithm calculates local inverse covariance and state estimates by summing contributions/updates from only the immediate neighbors (m in N_l) instead of all nodes in the network (l in N) as required by the centralized decomposition (equations 3 and 5). This prevents the local estimates from converging to the centralized optimal solution and likely leads to inconsistent estimates across nodes in a general network topology, invalidating the claim of achieving a unique solution."
      },
      {
        "Problem": "Incorrect State Transition Matrix",
        "Location": "Application section, State evolution function equation",
        "Explanation": "The state transition matrix for the state vector [kappa, d(kappa)/dt]^T is given as [[1, Delta T], [0, Delta T]]. For a standard constant velocity model where the second element is the rate of change of the first, the (2,2) element of the matrix should be 1, not Delta T. This fundamental error in the state dynamics model will lead to incorrect state predictions."
      },
      {
        "Problem": "Unsound Linear Model Assumption for Rotation Tracking",
        "Location": "Application section, State vector definition and observation model description",
        "Explanation": "The paper applies a linear Kalman filter (AQKF) to track aircraft rotation, modeling the state (derived from a rotation quaternion) and observations (derived from Euler angles) with linear equations. The relationship between rotation quaternions/Euler angles and sensor measurements (like accelerations) is inherently nonlinear. Using a linear model for a nonlinear system is unsound and will not provide accurate or optimal estimates for aircraft attitude tracking."
      },
      {
        "Problem": "Confidence Measure Validity and Usage",
        "Location": "Section 3, equations (6) and (7), and subsequent text",
        "Explanation": "The derivation of the confidence measure relies on the assumption that neighboring nodes' estimates and covariance matrices are approximately equal at convergence. However, the algorithm's flawed structure (Problem 1) makes such convergence unlikely in a general network. Furthermore, the paper describes the measure but does not specify how it is integrated into the algorithm to detect or handle faulty sensors, despite claiming robustness and demonstrating it in simulation."
      }
    ],
    "token_usage": {
      "input": 10365,
      "thinking": 4656,
      "output": 504
    }
  },
  {
    "entry_id": 115,
    "retraction_id": "2112.14102v2",
    "paper_id": "2112.14102v1",
    "retraction_comment": "The paper was withdrawn due to a mistake in the proof of Theorem 15, in Section 4. The proposed translation is not equirealizable (the cases for disjunction and Release fail)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Typo in ATM construction formula for EXP-hardness of GXZREAL",
        "Location": "Proposition 3.3, Appendix B, formula for \\cal{T}",
        "Explanation": "The formula for the transition relation (\\cal{T}) in the ATM reduction contains a typo in the disjuncts describing the next state of the tape. Specifically, the conjunct \\bigwedge_{j \\neq i} c_i \\leftrightarrow \\LTLcircle c_i should be \\bigwedge_{j \\neq i} c_j \\leftrightarrow \\LTLcircle c_j. This error means the formula does not correctly specify that only the current tape cell changes during a transition, invalidating the reduction from ATM acceptance to unrealizability."
      },
      {
        "Problem": "Flawed inductive step for Disjunction in SLTL to GXZ reduction",
        "Location": "Theorem 4.1, case \\varphi = \\varphi_1 \\lor \\varphi_2",
        "Explanation": "The proposed translation for disjunction introduces a system variable c and a \\psi formula that forces c to remain constant over time (via \\LTLcircle c and \\LTLcircle \\neg c). This restriction on the system's strategy is not present in the original formula \\varphi_1 \\lor \\varphi_2, making the translated formula not equirealizable to the original one. The system should be able to choose which disjunct to satisfy at time 0, but not be forced to maintain that choice forever by the structure of \\psi."
      },
      {
        "Problem": "Incorrect inductive step for Release in SLTL to GXZ reduction",
        "Location": "Theorem 4.1, case \\varphi = \\varphi_2 \\calR \\varphi_1",
        "Explanation": "The proof claims that \\varphi_2 \\calR \\varphi_1 is equirealizable to \\LTLsquare \\chi_1, where \\LTLsquare \\chi_1 is equirealizable to \\varphi_1. This claim is false. The semantics of the Release operator (\\varphi_2 \\calR \\varphi_1 is equivalent to \\LTLsquare \\varphi_2 \\lor (\\varphi_2 \\calU \\varphi_1)) are not equivalent to \\LTLsquare \\varphi_1. This fundamental error invalidates the inductive step for the Release operator and thus the entire reduction from SLTL to GXZ."
      }
    ],
    "token_usage": {
      "input": 18779,
      "thinking": 12356,
      "output": 540
    }
  },
  {
    "entry_id": 116,
    "retraction_id": "1606.07464v6",
    "paper_id": "1606.07464v5",
    "retraction_comment": "The arguments in the Sections 3.2 and 3.3 are not conclusive, and the Markov property is not disproved. Many other statements are though correct, see arXiv:2011.11476v4 (\"Revisiting the stochastic differential equations with multiplicative noise\")",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The disproof of the Markov property relies on an inconsistent comparison of different stochastic interpretations (alpha values).",
        "Location": "Section 3.2, page 6-7",
        "Explanation": "The disproof compares the maximum of a small-time propagator derived from an FPE corresponding to alpha=0 (Itô) without external drift (Eq. 3.4, derived from 3.2) with the steady-state maximum derived from an FPE corresponding to alpha=1/2 (Stratonovich) (Eq. 3.6). Using a small-time propagator from one interpretation/equation to test the Chapman-Kolmogorov equation for a steady state derived from a different interpretation/equation is inconsistent and invalidates the conclusion."
      },
      {
        "Problem": "The central claim that solutions of SDEs with multiplicative noise are not Markovian contradicts standard definitions and theory.",
        "Location": "Introduction (page 2), Section 3.2 (page 6-7), Summary (page 12)",
        "Explanation": "A stochastic differential equation of the form dX = A(X) dt + B(X) dW, regardless of the Itô or Stratonovich interpretation (which affects the form of A), defines a Markov process under standard regularity conditions on A and B. The Fokker-Planck equation describes the evolution of the probability density of this Markov process. The paper's assertion that the process is non-Markovian fundamentally conflicts with this established framework, suggesting a misunderstanding of the definition of an SDE solution as a Markov process."
      },
      {
        "Problem": "The argument for the anti-Itô case (alpha=1) preserving the Markov property on a coarse-grained scale is based on insufficient criteria.",
        "Location": "Section 3.3 (page 7-8)",
        "Explanation": "The argument that alpha=1 is special relies on the peak of the density moving with the velocity of the deterministic drift 'a'. While this is a property of the density peak in the anti-Itô case, it is not a sufficient condition for the underlying stochastic process to be Markovian, even on a coarse-grained scale. The Markov property is a statement about the conditional probability distribution, not just the location of its maximum."
      },
      {
        "Problem": "The paper makes potentially incorrect statements about the maximum of the small-time propagator for alpha=0.",
        "Location": "Section 3.3 (page 7)",
        "Explanation": "The paper states that the solution with w(x,0) = delta(x-x_hat) for the alpha=0 FPE (without external drift) has its maximum at x_hat. However, the preceding calculation on page 6 shows that for alpha=0 (Itô), the maximum of the small-time solution is at x_hat - a_sp tau, not x_hat. This error weakens the subsequent argument for why alpha=1 is special."
      },
      {
        "Problem": "The conclusion that stochastic integrals are affected due to non-independent increments is based on the flawed premise of non-Markovianity.",
        "Location": "Introduction (page 2)",
        "Explanation": "The paper states that the non-Markovian nature implies that the increments in a partitioned time interval are no longer independent, impacting the basis of stochastic integrals (Riemannian sums). Since the premise that the process is non-Markovian within the standard SDE framework is incorrect, this derived consequence regarding the independence of increments and the validity of stochastic integrals is also unfounded."
      }
    ],
    "token_usage": {
      "input": 3478,
      "thinking": 2488,
      "output": 787
    }
  },
  {
    "entry_id": 117,
    "retraction_id": "1806.07478v2",
    "paper_id": "1806.07478v1",
    "retraction_comment": "The results fail to capture the non-simultaneously diagonalizable case",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent notation and derivation in Theorem 3.3 regarding the stiff limit approximation.",
        "Location": "Theorem 3.3, Proof",
        "Explanation": "The theorem states an approximation for $R(hN,hS)$ and then discusses the limit $\\delta \\rightarrow 0$ of $R(hN, h\\delta^{-1}S)$. The derivation of $\\delta R$ in the proof uses $hS$ instead of $h\\delta^{-1}S$, making the connection to the stiff limit analysis unclear and potentially incorrect."
      },
      {
        "Problem": "Major disconnect between the statement and proof of Theorem 3.5.",
        "Location": "Theorem 3.5, Proof",
        "Explanation": "The theorem claims that eigenvalues of $R(hN, h\\delta^{-1}S)$ are close to eigenvalues of $R(hU_N, h\\delta^{-1}U_S)$ as $\\delta \\rightarrow 0$. However, the proof analyzes the eigenvalues of $R(hU_N + h\\delta N, hU_S)$ and relates them to $R(hU_N, hU_S)$. The matrices and perturbation scenarios are different, meaning the proof does not support the theorem's conclusion about the stiff limit of $h\\delta^{-1}S$."
      },
      {
        "Problem": "Application of stiff limit theory to problems with fixed stiffness.",
        "Location": "Section 5.2, specifically the use of $\\mathcal{E}(h_{\\text{max}})$ and Proposition 3.6",
        "Explanation": "The theoretical justification for using scalar test equations (Theorem 3.5) is based on the stiff limit $\\delta \\rightarrow 0$ for the ODE $\\dot{x} = Nx + \\delta^{-1}Sx$. In Section 5.2, the measure $\\mathcal{E}(h_{\\text{max}})$ and Proposition 3.6 are applied to the shallow water model $\\dot{x} = Nx + Sx$ (implicitly $\\delta=1$) at the maximum stable step-size $h_{\\text{max}}$. The theory does not formally establish that the eigenvalue proximity holds for a fixed $\\delta$ at $h_{\\text{max}}$, making the explanation of the shallow water results potentially unsupported by the presented theory."
      },
      {
        "Problem": "Undocumented derivation of the perturbation term in Lemma 3.4.",
        "Location": "Lemma 3.4",
        "Explanation": "The expression for the perturbation $\\delta R$ is given without derivation. While this might be a standard result, it is a crucial intermediate step in the proof of Theorem 3.5 (as written), and its absence makes the argument difficult to verify."
      }
    ],
    "token_usage": {
      "input": 35865,
      "thinking": 3839,
      "output": 629
    }
  },
  {
    "entry_id": 118,
    "retraction_id": "2302.13052v2",
    "paper_id": "2302.13052v1",
    "retraction_comment": "There are some errors and inappropriate writings. Thm 4.16 and don't work well for additive invariants",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of the continuous extension of an invariant.",
        "Location": "Definition on page 13, Construction on page 10",
        "Explanation": "The paper defines the continuous extension of an invariant E as E_cont(C) := Omega E(Calk_kappa(C)^omega). The standard definition of the continuous extension (e.g., in Efimov's work) is the fiber of the map E(D_1^omega) -> E(D_2^omega) for an exact sequence C -> D_1 -> D_2 where D_1 and D_2 are compactly generated. Using the sequence C -> Ind(C^kappa) -> Calk_kappa(C), the correct definition would be fib(E(Ind(C^kappa)^omega) -> E(Calk_kappa(C)^omega)). The paper's definition is missing the first term and the fibration, effectively assuming E(Ind(C^kappa)^omega) is trivial, which is generally false for K-theory."
      },
      {
        "Problem": "False claim about K-theory of compactly generated categories.",
        "Location": "Proposition 3.10 (page 10), Lemma 3.11 (page 10), Lemma 3.24 (page 14)",
        "Explanation": "Proposition 3.10 claims K^cn(Ind(C)^kappa) is trivial using an Eilenberg swindle argument. Lemma 3.11 uses this. Lemma 3.24 claims E(C) is trivial for a compactly generated C if E is an additive/localizing invariant, again citing Eilenberg swindle. The Eilenberg swindle argument for K-theory implies triviality for categories admitting countable *products* (or functors preserving them), not countable *coproducts* (colimits) which compactly generated categories admit. K-theory of a compactly generated category is generally non-zero (e.g., K(Sp) is non-zero). This false claim invalidates Proposition 3.10, Lemma 3.24, and subsequent results relying on them."
      },
      {
        "Problem": "Invalidity of Efimov's theorems on equivalence of invariants.",
        "Location": "Theorem 3.25 (page 14), Theorem 3.26 (page 15)",
        "Explanation": "The proofs of these theorems, which claim an equivalence between additive/localizing invariants on Cat_infty^perf and Pr_st^dual, rely on the incorrect definition of E_cont and the false claim from Lemma 3.24 (Proposition 3.10) that E is trivial on certain compactly generated categories. This invalidates the claimed equivalences."
      },
      {
        "Problem": "Invalidity of co-representability results.",
        "Location": "Theorem 3.28 (page 16), Theorem 3.32 (page 19), Theorem 3.31 (page 17), Theorem 3.34 (page 20)",
        "Explanation": "These theorems derive co-representability properties for K_cont^cn and K_cont based on the invalid equivalences established in Theorems 3.25 and 3.26. Since the foundation is flawed, these co-representability results as stated are not justified by the provided proofs."
      },
      {
        "Problem": "Invalidity of claims about lax symmetric monoidal structure and initiality.",
        "Location": "Section 4, e.g., Proposition 4.3 (page 25), Corollary 4.6 (page 26)",
        "Explanation": "The properties of K_cont^cn and K_cont being lax symmetric monoidal and initial objects in categories of invariants are derived using the invalid equivalences from Theorems 3.25 and 3.26. The proofs provided do not establish these properties due to their reliance on the flawed foundation."
      }
    ],
    "token_usage": {
      "input": 59439,
      "thinking": 7789,
      "output": 885
    }
  },
  {
    "entry_id": 119,
    "retraction_id": "1511.07171v2",
    "paper_id": "1511.07171v1",
    "retraction_comment": "Error in equation 9",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Governing Equation",
        "Location": "Page 2, Eq. (1)",
        "Explanation": "The presented axisymmetric convected Helmholtz equation does not match the standard form derived from linearized fluid dynamics equations for acoustics in a uniform subsonic flow. This fundamental equation forms the basis of the entire formulation."
      },
      {
        "Problem": "Incorrect Green's Function Definition",
        "Location": "Page 2, Eq. (2) and (3)",
        "Explanation": "The definition of the 3D convected Green's function (Eq. 2) and the auxiliary distances `r*` and `R_β*` (Eq. 3) appears incorrect for a convected medium. The standard approach involves a transformed distance based on the Prandtl-Glauert transformation, which is not correctly implemented here."
      },
      {
        "Problem": "Missing and Flawed Integral Equation Derivation",
        "Location": "Page 2-4, Eq. (4), (7), (9)",
        "Explanation": "The derivation of the boundary integral equation (Eq. 9) from the governing equation is not provided. The intermediate equations (4) and (7) contain domain integrals for a homogeneous equation, which is not typical for standard BEM formulations. The transition from these domain integrals to the boundary integral equation is unexplained and appears mathematically unsound."
      },
      {
        "Problem": "Incorrect Treatment of Singular Integrals",
        "Location": "Page 5, Section 3 (Numerical implementation description)",
        "Explanation": "The paper claims that only the trapezoid method is needed for evaluating integrals related to the Green's function and its derivative. BEM integrals involving the Green's function kernel are singular when the source point is on the boundary, requiring special analytical or numerical techniques beyond simple quadrature like the trapezoid method for accurate evaluation."
      },
      {
        "Problem": "Inconsistent and Unjustified Operators",
        "Location": "Page 3, Eq. (5) and Page 4, Eq. (8)",
        "Explanation": "The definition of the 'particular normal derivative' in Eq. (5) is unusual and lacks clear mathematical or physical justification. Furthermore, a different operator is introduced in Eq. (8) using the same notation `d/dn_q`, leading to an inconsistency in the formulation."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 4195,
      "output": 526
    }
  },
  {
    "entry_id": 120,
    "retraction_id": "1106.1331v2",
    "paper_id": "1106.1331v1",
    "retraction_comment": "Withdrawn by the authors. Lemma 7.6 is false as stated, and Appendix B is flawed. Corrected and reorganized versions of the material will be posted in papers with different titles",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 60789,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 121,
    "retraction_id": "2106.14209v3",
    "paper_id": "2106.14209v2",
    "retraction_comment": "The paper builds on the wrong statement in the paper \"The quantum twistor bundle\" Theorem 4.2. Therefore the C*-algebra investigated in the present paper is not the one for the quantum symplectic sphere",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The faithful representation $\\pi$ stated in Lemma 4.1 is incorrect.",
        "Location": "Lemma 4.1, Proof of Theorem 4.3",
        "Explanation": "The formulas provided for the representation $\\pi$ of the generators $y_i^*$ do not satisfy the derived relations (4.1)-(4.3) and do not match the representation cited from D'Andrea and Landi \\cite{dl} under the plausible identification of generators. This invalidates the use of this representation as a tool to prove the isomorphism."
      },
      {
        "Problem": "The definition of the inverse map $\\phi^{-1}$ on partial isometries $S_{e_{i,j}}$ is incorrect.",
        "Location": "Theorem 4.3, Proof of Theorem 4.3",
        "Explanation": "When checking if $\\phi^{-1}$ is a homomorphism by applying the representation $\\pi$ (even the incorrect one from Lemma 4.1) to the image of $S_{e_{i,j}}$, the result $\\pi(\\phi^{-1}(S_{e_{i,j}}))$ does not match $\\rho(S_{e_{i,j}})$ for $i \\leq j$. Specifically, for $i < j$, $\\pi(\\phi^{-1}(S_{e_{i,j}}))$ is zero on the relevant subspace, while $\\rho(S_{e_{i,j}})$ is non-zero. For $i=j$, there is a mismatching scalar factor. This invalidates the claim that $\\phi^{-1}$ is a homomorphism."
      },
      {
        "Problem": "The definition of the map $\\phi$ on generators $y_i^*$ is incorrect.",
        "Location": "Theorem 4.3, Proof of Theorem 4.3",
        "Explanation": "When checking if $\\phi$ is a homomorphism by applying the representation $\\rho$ to the image of $y_i^*$, the result $\\rho(\\phi(y_i^*))$ does not match $\\pi(y_i^*)$ (even using the incorrect $\\pi$ from Lemma 4.1). This invalidates the claim that $\\phi$ is a homomorphism."
      },
      {
        "Problem": "The justification for the invertibility of $|y_i^*|$ on the support of the projection in the proof of Theorem 4.3 is flawed for $i < j$.",
        "Location": "Proof of Theorem 4.3",
        "Explanation": "The proof claims that $|y_i^*|$ is invertible on the support of the projection $\\chi_1(\\sum_{k=j}^{n+1}y_k^*y_k)-\\chi_1(\\sum_{k=j+1}^{n+1}y_k^*y_k)$ for $i \\leq j$. However, for $i < j$, the support of this projection corresponds to states where the index $k_i$ is zero. The representation of $|y_i^*|$ is zero on such states, making it non-invertible. This invalidates the definition of $y_i^*|y_i^*|^{-1}$ on this subspace, which is used in the definition of $\\phi^{-1}(S_{e_{i,j}})$."
      },
      {
        "Problem": "Inconsistent definition of the graph $L_{2n-1}$.",
        "Location": "Definition 2.2, Theorem 4.3",
        "Explanation": "Definition 2.2 describes the graph $L_{2n-1}$ as having $n$ vertices, while the main result (Theorem 4.3) claims an isomorphism to the graph $C^*$-algebra $C^*(L_{2(n+1)-1})$, which implies a graph with $n+1$ vertices. While likely a notational error, this inconsistency introduces confusion regarding the structure of the graph used in the proof."
      }
    ],
    "token_usage": {
      "input": 15156,
      "thinking": 29187,
      "output": 885
    }
  },
  {
    "entry_id": 122,
    "retraction_id": "1608.08317v2",
    "paper_id": "1608.08317v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 13",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of theoretical guarantee for energy-based state targeting with approximate wavefunctions.",
        "Location": "Section 2.1, 2.2, 2.3, 2.4(1)",
        "Explanation": "The theoretical justification for using the parameter $\\omega$ to target states (Lemma 1, Hellmann-Feynman theorem) applies strictly to exact eigenstates. For approximate single-determinant wavefunctions, minimizing $W[\\Phi](\\omega)$ provides an initial guess for variance minimization. There is no formal proof that this initial guess is reliably within the basin of attraction of the variance minimum corresponding to the state closest to $\\omega$. This heuristic link could lead to unreliable state targeting or the inability to find certain states by scanning $\\omega$."
      },
      {
        "Problem": "Physical interpretation of all variance minima as distinct excited states is not fully justified.",
        "Location": "Section 2.2, 2.4(4), Section 4 (especially H2 and HF results)",
        "Explanation": "The method finds local minima of the variance functional within the single-determinant space. While the ground state variance minimum is clear, the physical meaning of excited state variance minima, particularly those not easily found by standard energy-based methods like $\\Delta$-SCF and appearing in regions of strong correlation (corresponding to energy saddle points), is less certain. Their correspondence to FCI states can be complex (e.g., asymptotic limits of multiple states), and their interpretation as distinct, spectroscopically relevant excited states requires further justification."
      },
      {
        "Problem": "The energy potential energy surface is not guaranteed to be smooth with respect to nuclear coordinates.",
        "Location": "Section 5, Figure 6",
        "Explanation": "The $\\sigma$-SCF method minimizes variance, not energy. While the variance is smooth, the energy of the resulting wavefunction is not necessarily a smooth function of nuclear coordinates. This is demonstrated numerically at the Fischer-Coulson point for unrestricted solutions and poses a significant practical problem for applications that rely on energy gradients, such as geometry optimization and molecular dynamics."
      }
    ],
    "token_usage": {
      "input": 18498,
      "thinking": 4584,
      "output": 457
    }
  },
  {
    "entry_id": 123,
    "retraction_id": "1805.10733v3",
    "paper_id": "1805.10733v2",
    "retraction_comment": "The result (eq. 3) is not correct; therefore, latter part which is derived from this result is not correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misinterpretation and mislabeling of the quantity $\\mathcal{C}$",
        "Location": "Methods section, Result section (definition and discussion of $\\mathcal{C}$), Discussion section",
        "Explanation": "The quantity $\\mathcal{C} = \\int_0^\\tau (ds/dt)^2 dt$ is defined and referred to as a \"rate of thermodynamic cost change\". This is incorrect; $\\mathcal{C}$ is an integral over time of the squared statistical speed, not a rate. A rate would be a quantity per unit time. The statement in the Result section that $\\mathcal{C}$ is a \"total loss rate of the entropy change and to also be a rate of the thermodynamic cost change\" is contradictory and confusing."
      },
      {
        "Problem": "Incorrect definition of efficiency $\\eta$ in relation to thermodynamic cost",
        "Location": "Result section (definition of $\\eta$), Discussion section (interpretation of results)",
        "Explanation": "The efficiency is defined as $\\eta = \\mathcal{L}^2/(\\tau \\mathcal{C})$. In the context of thermodynamic speed limits, efficiency is typically defined using the total entropy production $\\int \\dot{\\Sigma} dt$ in the denominator, i.e., $\\eta_{cost} = \\mathcal{L}^2 / (\\tau \\int \\dot{\\Sigma} dt)$. The cited work (Ito 2017) shows $(ds/dt)^2 \\leq \\dot{\\Sigma}$, implying $\\mathcal{C} = \\int (ds/dt)^2 dt \\leq \\int \\dot{\\Sigma} dt$. Therefore, the defined $\\eta$ is an upper bound on the true thermodynamic efficiency ($\\eta \\geq \\eta_{cost}$), and its behavior might not accurately represent the behavior of the actual thermodynamic efficiency."
      },
      {
        "Problem": "Lack of clear and rigorous justification for the link between $\\mathcal{C}$ and thermodynamic cost",
        "Location": "Result section, paragraph introducing $\\mathcal{C}$",
        "Explanation": "The paper states that $\\mathcal{C}$ can be considered related to thermodynamic cost, but the justification provided is vague and potentially incorrect. Without a clear derivation showing how $\\int (ds/dt)^2 dt$ directly represents the thermodynamic cost or its rate in this specific system (beyond being related via an inequality), the interpretation of $\\mathcal{C}$ and the resulting efficiency $\\eta$ as measures of thermodynamic performance is unsound."
      }
    ],
    "token_usage": {
      "input": 5914,
      "thinking": 3613,
      "output": 560
    }
  },
  {
    "entry_id": 124,
    "retraction_id": "1912.00541v2",
    "paper_id": "1912.00541v1",
    "retraction_comment": "As several people have pointed out to me, the last sentence of Lemma 5.3 is not justified. This likely counts as a fatal flaw that invalidates the main theorem (Theorem 5.4). I would like to thank those who took the time to read the preprint and send me their feedback. I hereby retract the claimed result",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof of Lemma 5.1 regarding full models.",
        "Location": "Section 5, Lemma 5.1",
        "Explanation": "The proof claims that if $A_r$ is not a full model of $A$, then the induced map $\\psi^*: \\Hom(G, A_r) \\to \\Hom(G, \\Delta_q)$ is not injective. However, the commutative diagram $\\beta \\circ f^{-1} = \\psi^* \\circ \\left.\\beta\\right|_A$ implies that $\\psi^*$ must be injective because $\\beta$ and $f^{-1}$ are injective maps between their respective domains and codomains. The existence of a homomorphism $\\iota \\notin \\image(\\left.\\beta\\right|_A)$ does not imply collisions under $\\psi^*$. This invalidates the lemma's conclusion that the image of an injective endomorphism always has a full model, a result used later in the main theorem proof."
      },
      {
        "Problem": "Unjustified injectivity claim for $\\phi^*$ in the main theorem proof.",
        "Location": "Section 5, Theorem 5.4 proof",
        "Explanation": "The proof of the main theorem relies on the claim that the induced map $\\phi^*: \\Hom(G, \\Delta_q) \\to \\Hom(G, \\Delta_q)$ is injective, where $\\phi = \\psi_*\\alpha$. The justification provided in the text is unclear and does not rigorously establish this crucial property. The argument relies on a claimed correspondence (5.1) and $\\phi$ being $q$-compatible, neither of which directly implies the injectivity of $\\phi^*$. Without $\\phi^*$ being injective, the subsequent contradiction derived from considering iterates of $\\phi$ does not hold."
      },
      {
        "Problem": "Unjustified claim about the dynamics of $\\phi$.",
        "Location": "Section 5, Theorem 5.4 proof",
        "Explanation": "The proof asserts that for the endomorphism $\\phi: \\Delta_q \\to \\Delta_q$, there exists an integer $N \\geq 1$ such that the restriction of $\\phi^N$ to its image $A_q$ is the identity map on $A_q$ (i.e., $\\phi^N|_{A_q} = \\Id_{A_q}$). This property is not a general characteristic of endomorphisms of finite graphs whose image is a proper subgraph. While the sequence of iterates restricted to the image must eventually enter a cycle, this cycle is not necessarily the identity map. This invalidates the final step of the proof which uses $\\phi^N|_{A_q} = \\Id_{A_q}$ to construct distinct homomorphisms that are mapped to the same image by $(\\phi^N)^*$, leading to a contradiction."
      }
    ],
    "token_usage": {
      "input": 12105,
      "thinking": 26891,
      "output": 642
    }
  },
  {
    "entry_id": 125,
    "retraction_id": "2002.11860v4",
    "paper_id": "2002.11860v3",
    "retraction_comment": "Mistake in Lemma 3 changing the announced rate. Withdrawing while fixing the error",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified equality assumption in Lemma 1 proof.",
        "Location": "Lemma 1 Proof, transition from step 3 to step 4.",
        "Explanation": "In the transition from the third to the fourth displayed equation, the term $\\gamma_t\\langle \\balpha_t, \\XX(\\sss_t - \\ww_{t-1})\\rangle$ is replaced by $\\gamma_t\\langle \\balpha_t, \\XX(\\ww_\\star - \\ww_{t-1})\\rangle$. This replacement is not justified by the LMO optimality condition (Opt. of $\\sss_t$), which only guarantees $\\langle \\balpha_t, \\XX(\\sss_t - \\ww)\\rangle \\leq 0$ for any $\\ww \\in \\CC$, not equality for a specific $\\ww_\\star$. This step is critical for deriving the subsequent inequalities and appears to be unsound."
      }
    ],
    "token_usage": {
      "input": 43117,
      "thinking": 5889,
      "output": 217
    }
  },
  {
    "entry_id": 126,
    "retraction_id": "2109.13007v2",
    "paper_id": "2109.13007v1",
    "retraction_comment": "We found a gap in the claim 1 (we can not solve it)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of Proposition 1 contains confusing and potentially incorrect steps regarding the rotation and the location of the distance-realizing points.",
        "Location": "Proposition 1, Proof",
        "Explanation": "The rotation matrix definition used in the proof (referencing equation \\eqref{matriz}) is tied to a specific basis involving $\\nu$ and $\\eta$, but the rotation is applied with respect to points $p_1, p_2$ or their orthonormalization, which may not align with this basis. Furthermore, the claim that the set of intersection points contains $p_2$ because $p_1$ and $p_2$ realize the distance is not justified and makes the subsequent argument unclear."
      },
      {
        "Problem": "The proof of Claim 2, which is essential for Theorem A, is logically unsound and difficult to follow.",
        "Location": "Proof of Theorem A, Claim 2",
        "Explanation": "The argument involving the rotation family $\\{\\rho(\\theta, \\Sigma_2^+)\\}$, the set $\\mathcal{I}[\\overline{p}_1, \\overline{p}_2]$, and the point $p_0$ contains logical gaps and unjustified claims (e.g., $\\Sigma_1^+ \\cap \\rho(\\theta, \\Sigma_2^+ \\cap \\mathcal{I}[\\overline{p}_1, \\overline{p}_2]) = \\emptyset$). This makes the conclusion that $\\Sigma_1^+$ coincides with a rotated version of $\\Sigma_2^+$ unconvincing and undermines the proof of Theorem A."
      },
      {
        "Problem": "The proof of Corollary B is incorrectly formulated and misapplies the conclusion of Theorem A.",
        "Location": "Proof of Corollary B",
        "Explanation": "The proof attempts to use Theorem A to show that $\\Sigma^+ = \\Sigma \\cap \\mathcal{H}_+[\nu]$ is connected. However, it applies Theorem A (stated for two distinct minimal hypersurfaces) to parts of a single hypersurface (denoted confusingly as $\\Sigma_1^+$ and $\\Sigma_2^+$ as parts of $\\Sigma^+$). While Theorem A can be applied to disjoint pieces of a single minimal surface within a domain, the proof does not articulate this correctly, rendering the argument unsound as written."
      },
      {
        "Problem": "The application of the Tangency Principle at boundary points, particularly free boundary points, requires more rigorous justification.",
        "Location": "Proof of Proposition 1, Proof of Theorem A (Claim 1, Claim 2)",
        "Explanation": "The Tangency Principle (Theorem 1) is applied at potential contact points on the boundary of $\\Sigma^+$ (which lies on $\\s^n$ or $\\mathcal{D}[\\nu]$). While the argument in Proposition 1's proof correctly shows normals must be parallel at a free boundary tangency point, the application of the Tangency Principle itself at these boundary types (fixed on $\\mathcal{D}[\\nu]$, free on $\\s^n$) needs explicit reference to appropriate versions of the principle (e.g., for boundaries on supporting hyperplanes or free boundaries), which is not consistently or clearly done."
      }
    ],
    "token_usage": {
      "input": 8233,
      "thinking": 10400,
      "output": 710
    }
  },
  {
    "entry_id": 127,
    "retraction_id": "1305.3218v2",
    "paper_id": "1305.3218v1",
    "retraction_comment": "This paper has been withdrawn by the author. Due to the dependence of f(\\sigma) on z, Lemma 5.3 is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradictory claims within a critical lemma proof.",
        "Location": "Lemma 4.5",
        "Explanation": "The proof of Lemma 4.5 contains two contradictory claims. Claim 1 states that if the edge set $d(f(\\sigma))$ intersects the blocked edge set $z_j$, then the set $y(\\sigma)$ chosen for $\\sigma$ must be $y_j$. Claim 2 states that if $d(f(\\sigma))$ intersects $z_j$, then $y(\\sigma)$ must be different from $y_j$. These two claims are mutually exclusive. The subsequent conclusion of the lemma, which asserts that $d(f(\\sigma)) \\cap z_j = \\emptyset$ for all $j \\in [q-1]$, relies on the logic derived from these contradictory claims. This lemma is fundamental to proving that the constructed shift term is disjoint from the blocked edge set, a property essential for demonstrating that the term contains no small cliques. The presence of this internal contradiction invalidates the lemma and propagates through the rest of the paper's proofs."
      },
      {
        "Problem": "Dependence of subsequent proofs on a flawed core argument.",
        "Location": "Proposition 5.1, Theorem 6.1",
        "Explanation": "The proofs for the non-monotone circuit complexity lower bounds (Proposition 5.1 for bounded depth and Theorem 6.1 for general circuits) directly rely on the shift method and the properties of the constructed shift term established in the monotone case (Proposition 4.1). Specifically, the arguments for ensuring the shift term is contradiction-free and contains no k-cliques in the non-monotone settings generalize the flawed disjointness proof from the monotone case (Lemma 4.5 / Lemma 5.3). Since the foundation of the shift method's correctness is unsound, the conclusions regarding $\\NC \\ne \\NP$ and $\\PP \\ne \\NP$ derived from these proofs are not valid."
      }
    ],
    "token_usage": {
      "input": 75496,
      "thinking": 11276,
      "output": 441
    }
  },
  {
    "entry_id": 128,
    "retraction_id": "1502.02299v3",
    "paper_id": "1502.02299v2",
    "retraction_comment": "This paper has been withdrawn by the authors due to a sign error in the last equation of system (2.11). In turn, this implies a change of sign of the last equation in the linearized system (3.1) as well. The linear three annuli property for solutions to the new system (3.1) is no longer valid",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent geometric setup and coordinate system mapping",
        "Location": "Section 2.2, Definition of $f$ and domain $]0, 2\\pi[$",
        "Explanation": "The paper studies a crack-tip, which corresponds to a single curve emanating from the origin. In polar coordinates $(\\rho, \\theta)$, the jump set is assumed to be near $\\theta=0$. The reparametrization $f(\\phi, t) = e^{t/2} u(\\phi + \\alpha(e^{-t}), e^{-t})$ maps the jump set $\\theta = \\alpha(e^{-t})$ to $\\phi=0$. Using a domain $]0, 2\\pi[$ for $\\phi$ and imposing jump conditions at both $\\phi=0$ and $\\phi=2\\pi$ implies the jump set consists of two curves mapped to these boundaries, which contradicts the single crack-tip geometry. Furthermore, the model function $\\rad(\\phi) = \\sqrt{2/\\pi} \\cos(\\phi/2)$ used in the decomposition has its jump set at $\\phi=\\pi$ on $[0, 2\\pi]$, adding further inconsistency to the problem setup."
      },
      {
        "Problem": "Incorrect linearization of the boundary conditions",
        "Location": "Section 3, derivation of linear system (3.1) boundary conditions",
        "Explanation": "The boundary conditions for the linear system (3.1) are stated as $w_\\phi(0) = -w_\\phi(2\\pi) = -\\dot\\lambda/\\sqrt{2\\pi}$. However, linearizing the nonlinear boundary conditions (2.5) around the base state $f=\\rad, \\vartheta=0$ does not yield these conditions. The linearization of $f_\\phi(0,t) = \\frac{\\varthetad}{1+\\varthetad^2}(-f/2+f_t)(0,t)$ involves the term $\\rad_\\phi(0) = \\sqrt{2/\\pi}/2$ at order $\\varepsilon^0$, which is non-zero, indicating a fundamental issue with the linearization approach or the chosen base state. The resulting linear boundary condition for $w_\\phi(0)$ also differs from the one stated in (3.1)."
      },
      {
        "Problem": "Flawed analysis of the linearized system via odd/even splitting",
        "Location": "Section 3.1, Section 4.1",
        "Explanation": "The analysis of the linear system (3.1) relies on splitting the unknown function $w$ into odd ($w^o$) and even ($w^e$) parts with respect to $\\phi=\\pi$. The boundary conditions derived for the odd part $w^o$ from system (3.1) are $w^o_\\phi(0) = -\\dot\\lambda/\\sqrt{2\\pi}$ and $w^o_\\phi(2\\pi) = \\dot\\lambda/\\sqrt{2\\pi}$. However, the subsequent analysis of $w^o$ in Lemma 4.1 is based on the incorrect assumption that $w^o_\\phi(0)=w^o_\\phi(2\\pi)=0$. This invalidates the spectral decomposition and the three-annuli property derived for the odd part."
      },
      {
        "Problem": "Incorrect system derived for the transformed variable $z$",
        "Location": "Section 3.2",
        "Explanation": "To analyze the even part $w^e$, the paper introduces the variable $z = w^e - \\lambda \\rad_\\phi$. The derivation of the system of equations for $z$ in (3.4) contains errors. Specifically, the first equation $z_t = z/4 + z_{\\phi\\phi} + z_{tt}$ and the boundary condition $z_\\phi(0) = -\\frac{\\lambdad}{\\sqrt{2\\pi}} + \\frac{\\lambda}{2\\sqrt{2\\pi}}$ are incorrectly derived from the system satisfied by $w^e$. This invalidates the subsequent reduction to the Ventsel problem (3.7) and the spectral analysis based on it."
      }
    ],
    "token_usage": {
      "input": 38489,
      "thinking": 18144,
      "output": 954
    }
  },
  {
    "entry_id": 129,
    "retraction_id": "1901.07856v7",
    "paper_id": "1901.07856v6",
    "retraction_comment": "The proof of the the second inequality of Lemma 7 is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect probability calculation for validation success.",
        "Location": "Lemma 3.2, Proof of Lemma 3.2",
        "Explanation": "The probability calculation for the success condition in a phase of the validation algorithm (CV) is incorrect. The condition requires both sets of same-parity edges in a cycle to be monochromatic in the initial random coloring. The probability of this event for a 2k-cycle is K^(2-2k), not (1/K)^(2k-2) as used in the proof. This error invalidates the definition of the forest weight and all subsequent probabilistic analysis based on it."
      },
      {
        "Problem": "Invalid coupling argument between EC and Validation Algorithm.",
        "Location": "Lemma 3.3, Proof of Lemma 3.3",
        "Explanation": "The proof attempts to couple the execution of Algorithm EC with the success of Algorithm CV(F). However, the sequence of recoloring events and the structure of the forest F generated by EC depend on the specific, changing state of the coloring throughout its execution. Algorithm CV(F) checks conditions based on a single initial random coloring for a fixed, pre-determined forest structure F. The random processes are fundamentally different, making the coupling invalid."
      },
      {
        "Problem": "Incorrect claim about color distribution after validation phase.",
        "Location": "Lemma 3.1, Proof of Lemma 3.1",
        "Explanation": "The lemma claims that after each phase of the validation algorithm (CV), the colors are distributed as if assigned independently and uniformly at random. This is false. The fact that the algorithm did *not* return 'failure' in a given phase provides specific information about the colors of the edges in the cycle being considered, introducing dependencies that violate the assumption of independent uniform distribution."
      },
      {
        "Problem": "Algorithm EC does not guarantee properness or 4-acyclicity.",
        "Location": "Algorithm EC description (Section 2.2), Algorithm MA description (Section 2.2)",
        "Explanation": "Algorithm EC's while loop condition (line 7) and the Recolor procedure's while loop condition (line 10) only target cycles of even length >= 6 with homochromatic edges of the same parity. The algorithm does not check for or resolve issues related to properness (adjacent edges having the same color) or bichromatic 4-cycles. Algorithm MA relies on EC producing a proper, 4-acyclic coloring by chance, but the analysis of MA's termination depends on the flawed analysis of EC's termination."
      },
      {
        "Problem": "Recurrence analysis based on incorrect probabilities.",
        "Location": "Subsection 3.3 (Recurrence), Lemma 3.5",
        "Explanation": "The recurrence relation derived in Subsection 3.3 and its subsequent asymptotic analysis (used to bound the probability of Algorithm EC running for a large number of steps) are based on the incorrect probability calculation for the validation algorithm's success (Lemma 3.2). This invalidates the derived bounds on the probability of EC's long execution time (P_n and hat{P}_n) and consequently the main theorem's conclusion about MA's termination."
      }
    ],
    "token_usage": {
      "input": 12470,
      "thinking": 3556,
      "output": 713
    }
  },
  {
    "entry_id": 130,
    "retraction_id": "1912.10027v2",
    "paper_id": "1912.10027v1",
    "retraction_comment": "We have found some errors in the methods, in particular two of the methods are not A-stable",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound Proof of Theorem 1",
        "Location": "Section 3, Theorem 1 Proof",
        "Explanation": "The proof of the central theorem claiming the error structure E^n = Delta t^(p+1) * ste^n_(p+1) + O(Delta t^(p+2)) contains algebraic errors and relies on conditions that appear insufficient to eliminate higher-order terms in the error recursion analysis. Specifically, the derivation of the O(Delta t^(p+1)) terms in the products Q^(n-1) * T_e^(n-2) and Q^(nu+2) * Q^(nu+1) * T_e^nu seems incorrect, and the stated conditions (3.6b)-(3.6d) do not appear sufficient to make these terms vanish. This undermines the theoretical basis for the claimed p+1 order convergence and the subsequent post-processing to p+2."
      },
      {
        "Problem": "Post-processing relies on unproven error structure",
        "Location": "Section 3.2",
        "Explanation": "The post-processing procedure is designed to remove the leading error term Delta t^(p+1) * ste^n_(p+1) based on the error structure claimed in Theorem 1. Since the proof of Theorem 1 is unsound, the error is not guaranteed to have this precise form. Consequently, the post-processing is not theoretically guaranteed to yield a solution of order p+2."
      },
      {
        "Problem": "Lack of clarity and rigor in proof",
        "Location": "Section 3, Theorem 1 Proof",
        "Explanation": "Beyond the apparent insufficiency of the conditions, the intermediate steps in the proof of Theorem 1 contain algebraic manipulations and simplifications that are difficult to follow and appear incorrect (e.g., in the analysis of the O(Delta t^(p+1)) terms in Q^(n-1) * T_e^(n-2) and Q^(nu+2) * Q^(nu+1) * T_e^nu). This lack of rigor makes it impossible for a reader to verify the correctness of the proof."
      }
    ],
    "token_usage": {
      "input": 36361,
      "thinking": 31006,
      "output": 481
    }
  },
  {
    "entry_id": 131,
    "retraction_id": "1502.05353v3",
    "paper_id": "1502.05353v2",
    "retraction_comment": "This paper has been withdrawn due to some errors. The main error is the wrong spin function of Eq. (5), which makes equations (13) and (14) incorrect, and in turn puts doubts on the final conclusions",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition and calculation of the direct exchange integral (Jd).",
        "Location": "Page 10, Eq. 13; Page 12, Eq. 18",
        "Explanation": "The direct exchange integral Jd is defined as proportional to the overlap integral O12 multiplied by the diagonal energy 2*tilde{epsilon}+. This is not the standard definition of an exchange integral, which arises from the off-diagonal matrix element of the electron-electron repulsion operator between product wave functions. This fundamental error invalidates the calculated values of Jd in Table 1 and subsequent comparisons."
      },
      {
        "Problem": "Incorrect definition and calculation of the hopping parameters (tau and tilde{tau}).",
        "Location": "Page 15, Eq. 19-21",
        "Explanation": "The hopping parameters are defined as matrix elements of two-particle Hamiltonians (Hab,<ij> or H<ij>) between single-particle wave functions (psi_i, psi_j). Standard hopping integrals in tight-binding models are single-particle matrix elements of the kinetic energy and potential operators between orbitals on different sites. The subsequent calculation and approximation appear inconsistent with standard methods, invalidating the calculated values."
      },
      {
        "Problem": "Arbitrary form and likely incorrect coefficient of the direct exchange term in the modified Hamiltonian.",
        "Location": "Page 18, Conclusion 4; Page 19, Eq. 27",
        "Explanation": "The proposed direct exchange term 4Jd Si.Sj in the modified Hamiltonian is introduced with an arbitrary coefficient (4) and sign, which are not justified by standard theoretical frameworks for magnetic interactions. Adding this term to the t-J Hamiltonian, an effective model, without a rigorous derivation from a more fundamental model is also problematic."
      },
      {
        "Problem": "Error in the calculation of the critical doping.",
        "Location": "Page 19, Case (A) critical doping calculation",
        "Explanation": "The energy balance equation used to determine the critical doping by equating the energies of the ordered and metallic phases appears to be incorrectly formulated or solved. This invalidates the calculated critical doping values for all cases (A, B, C) and the conclusion that the proposed modified Hamiltonian provides better agreement with experimental optimal doping."
      }
    ],
    "token_usage": {
      "input": 5800,
      "thinking": 6256,
      "output": 519
    }
  },
  {
    "entry_id": 132,
    "retraction_id": "1808.08722v2",
    "paper_id": "1808.08722v1",
    "retraction_comment": "We find the polarization degrees of freedom of the squeezed light had not been treated properly in our analysis, which would affect our results significantly especially in the case of dissipative quantum walks. A new analysis is currently underway. We thank [REDACTED-NAME] for help in clarifying these issues",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsoundness of unitary QW codewords for error correction",
        "Location": "Section II A, paragraph discussing Fig. 2",
        "Explanation": "The momentum distributions of the unitary quantum walk (QW) codewords $|0\\rangle_{\\rm QW}$ and $|1\\rangle_{\\rm QW}$ (Fig. 2b) are broad Gaussians, lacking the periodic peak structure necessary for effective momentum error correction in the Gottesman-Kitaev-Preskill (GKP) scheme. This contradicts the claim that these states can be adopted to correct shift errors, as momentum shifts cannot be reliably measured or corrected from such a distribution."
      },
      {
        "Problem": "Missing analysis of success probability for dissipative QW encoding",
        "Location": "Section II B, discussion around Eq. (14)",
        "Explanation": "The generation of the dissipative quantum walk (dQW) codewords is probabilistic due to the required projection measurement onto the diagonal polarization $|D\\rangle$. The paper calculates the properties of the state conditioned on successful projection but does not analyze the success probability (${\\cal N}^2 = |\\alpha|^2 Z_N + |\\beta|^2 Z_{N+1}$). This probability decreases with the number of steps $N$ (approximately as $1/\\sqrt{N}$ for large $N$) and is a critical factor for assessing the experimental feasibility and resource cost of the scheme, as it implies significant state loss."
      }
    ],
    "token_usage": {
      "input": 14519,
      "thinking": 4466,
      "output": 326
    }
  },
  {
    "entry_id": 133,
    "retraction_id": "2406.11623v4",
    "paper_id": "2406.11623v3",
    "retraction_comment": "Some errors appeared in the article that seem difficult to correct. For example, the Green function $G_R(o,x)$ for the geodesic ball $B(R)$ was misunderstood to satisfy the Dirichlet boundary condition on the geodesic sphere $\\partial B(R)$, however, this is not the case",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect exhaustion of the geodesic ball by the defined domains.",
        "Location": "Section 2.1, definition of $\\Delta(r)$ and the claim $\\bigcup_{n=1}^\\infty\\Delta(r_n)=B(R)$.",
        "Explanation": "The domains $\\Delta(r)$ are defined as level sets of the Green function $G_R(o,x)$ for $B(R)$ above a threshold value. As $r \\to R$, this threshold approaches a positive constant. Since $G_R(o,x)=0$ on the boundary $\\partial B(R)$, the union of $\\Delta(r)$ for $r \\to R$ does not include $\\partial B(R)$, and therefore does not exhaust the entire geodesic ball $B(R)$. This is a fundamental issue for defining Nevanlinna theory on $B(R)$ using these domains."
      },
      {
        "Problem": "Flawed estimate for the harmonic measure on the boundary of $\\Delta(r)$.",
        "Location": "Section 2.2, Theorem $\\ref{hhh}$ and its proof.",
        "Explanation": "The derivation of the estimate for $d\\pi_r$ relies on a limit calculation $\\lim_{r\\to R}\\lim_{t\\to r}\\frac{r-t}{\\rho_{t, \\vec{\\nu}}(x)}=1$. This calculation is not rigorously justified and appears to assume that the level sets of $G_R(o,x)$ are approximately spherical near the boundary $\\partial B(R)$, which is not generally true. This estimate is crucial for the subsequent Calculus Lemma."
      },
      {
        "Problem": "Unsound Calculus Lemma due to incorrect differentiation formula.",
        "Location": "Section 4.1, Theorem $\\ref{calculus}$ and its proof.",
        "Explanation": "The proof of the Calculus Lemma uses an incorrect formula for the derivative of a volume integral over a domain $\\Delta(r)$ that depends on the parameter $r$. Specifically, the step $\\frac{d}{dr}\\left(\\frac{1}{4rF_R(r)}\\frac{d}{dr} \\int_{\\Delta(r)}g_r(o,x)kdv\\right)= \\int_{\\partial\\Delta(r)}kd\\sigma_r$ is not correctly derived. This lemma is a cornerstone for bounding boundary integrals in terms of volume integrals."
      },
      {
        "Problem": "Unsound Logarithmic Derivative Lemma.",
        "Location": "Section 4.2, Theorem $\\ref{log1}$ and its proof.",
        "Explanation": "The proof of the Logarithmic Derivative Lemma relies directly on the result of the Calculus Lemma (Theorem $\\ref{calculus}$). Since the Calculus Lemma is unsound due to the incorrect differentiation formula used in its proof, the Logarithmic Derivative Lemma is also unsound."
      },
      {
        "Problem": "Unsound Second Main Theorem.",
        "Location": "Section 5.1, Theorem $\\ref{main}$ and its proof.",
        "Explanation": "The proof of the Second Main Theorem relies on bounding the boundary integral term $\\int_{\\partial\\Delta(r)}\\log\\xi d\\pi_r$ using the Logarithmic Derivative Lemma (Theorem $\\ref{log1}$) and the Calculus Lemma (Theorem $\\ref{calculus}$). Since these lemmas are unsound, the proof of the Second Main Theorem is invalid. Consequently, the derived defect relations and Picard theorem are also invalid."
      }
    ],
    "token_usage": {
      "input": 26566,
      "thinking": 5667,
      "output": 795
    }
  },
  {
    "entry_id": 134,
    "retraction_id": "2108.09325v2",
    "paper_id": "2108.09325v1",
    "retraction_comment": "Several sections, particularly Section 5, contain an error interpreting the mutual inclination directly as the obliquity",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Neglect of Octupole Effects in Population Synthesis",
        "Location": "Section 3, Fig 4, Eqns 1, 3, 4",
        "Explanation": "The population synthesis results, which are central to the paper's conclusion about the resulting obliquity distribution, are based on simplified secular equations (Eqns 1, 3, 4) that neglect octupole terms. Octupole effects can qualitatively change Kozai-Lidov dynamics, including the relationship between initial and minimum inclination and the maximum eccentricity reached, especially for certain orbital configurations. Without including these effects in the population synthesis, the predicted obliquity distribution may be inaccurate, potentially invalidating the claim that warm starts in the GR-reduced regime produce the observed perpendicular distribution."
      },
      {
        "Problem": "Unclear and Potentially Misleading Definition of the GR-Reduced Parameter Space",
        "Location": "Section 3, Fig 3",
        "Explanation": "Figure 3 attempts to map the parameter space where GR-reduced HEM occurs. However, the definition of the colored areas and the boundaries between different regimes (no HEM, GR-reduced HEM, full amplitude HEM) are not clearly or quantitatively defined based on the underlying dynamics (e.g., specific ranges of $\\epsgr$ and companion strength parameters). This ambiguity makes it impossible to verify the parameter space mapping and the subsequent claim that common companions fall into the relevant region for warm starts, which is a key premise for the population synthesis."
      },
      {
        "Problem": "Insufficient Justification for Neglecting Cold Starts",
        "Location": "Section 1, Section 5",
        "Explanation": "The paper proposes that warm starts explain perpendicular planets but acknowledges that cold starts (>1 AU) would typically lead to 40/140 degree obliquities. Given that cold Jupiters are common, the lack of a significant observed population of hot planets with 40/140 degree obliquities (assuming they haven't realigned) is a tension. The paper offers speculative reasons (disk migration, protection by other planets) why cold starts might not lead to HEM or observable 40/140 obliquities. Without stronger evidence or modeling to support these explanations, the scenario for warm starts feels incomplete and doesn't fully address the broader context of HEM origins and the observed obliquity distribution."
      }
    ],
    "token_usage": {
      "input": 8151,
      "thinking": 4323,
      "output": 519
    }
  },
  {
    "entry_id": 135,
    "retraction_id": "1705.00151v2",
    "paper_id": "1705.00151v1",
    "retraction_comment": "We apologize that in the results and algorithms of Section 4.1, Proposition 4.1 and Lemma 4.2, there are some missing conditions and assumptions on the hypergraphs. Hence we want to withdraw the manuscript. Moreover, we want to work out more results, and merge this manuscript together to write a publishable paper",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and computation of H_0",
        "Location": "Definition 4, Proposition 4.2, Algorithm 2",
        "Explanation": "Definition 4 seems intended for n >= 1. Proposition 4.2 provides a definition/computation for H_0 based on path components of H_0 union H_1, which appears inconsistent with extending Definition 4 to n=0 (especially if H_0 is empty) and relies on an implicit assumption about H_0 (e.g., containing all vertices) not required by the hypergraph definition."
      },
      {
        "Problem": "Unsoundness in the path-connected decomposition heuristic for embedded homology",
        "Location": "Section 4.1, Algorithm 4",
        "Explanation": "The algorithm claims H_n(H) is isomorphic to the direct sum of H_n of its path-connected components H(n,k). This relies on the homology of the union of hypergraphs being the direct sum of the homology of components, which is generally false if the components share vertices, even if they are path-disconnected within H(n)."
      },
      {
        "Problem": "Unsoundness in the hyperedge collapsing heuristic for embedded homology",
        "Location": "Section 4.1, Proposition 4.3, Algorithm 5",
        "Explanation": "The heuristic relies on Proposition 4.3, which claims H_*(H) is isomorphic to H_*(H^d(v)) under certain conditions. This proposition's proof relies on an extremely strong and likely false condition (St_K_H(sigma) is a subset of H) for a 'simplicial-like' hyperedge and an unproven lemma under strong assumptions, making the heuristic unsound for general hypergraphs."
      },
      {
        "Problem": "Unsoundness in the improved embedded homology algorithm",
        "Location": "Section 4.1, Algorithm 6",
        "Explanation": "This algorithm combines the unsound decomposition (Algorithm 4) and collapsing (Algorithm 5) heuristics. Additionally, it claims H_n(Cr(H)(n,k)) is isomorphic to H_n(Cr(K_Cr(H)(n,k))) when (Cr(H)(n,k))_(n+1) is empty, incorrectly equating embedded homology of a hypergraph to simplicial homology of the core of its associated simplicial complex."
      },
      {
        "Problem": "Unsoundness in the torsion bound estimation for embedded homology",
        "Location": "Section 4.3, Algorithm 10",
        "Explanation": "The argument for applying the torsion bound from simplicial homology to embedded homology is based on incorrect claims about the relationship between embedded homology groups and simplicial homology groups (H_n(H) is a subset of Coker pi_n) and the structure of boundary map images, making the derived bound potentially incorrect."
      }
    ],
    "token_usage": {
      "input": 32306,
      "thinking": 16908,
      "output": 646
    }
  },
  {
    "entry_id": 136,
    "retraction_id": "1701.02653v2",
    "paper_id": "1701.02653v1",
    "retraction_comment": "This paper has been withdrawn to an error in Proposition 8 when moving from the quenched to the annealed measure. Thus, it is not a straightforward adaptation of the theorem cited",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misapplication of duality relation in Proposition 2.",
        "Location": "Proposition 2, proof, final paragraph.",
        "Explanation": "The proof of Proposition 2 defines a non-standard coalescing random walk process $\\xi_t$ where the particle starting at the root follows a predetermined random walk $X_t$. The quantity $N_t(X_t)$ is the number of particles at $X_t$ in this modified process. The proof then equates $\\E[N_t(X_t)]$ to $\\E[|\\zeta_t^{(\\rho)}|]$ by citing the duality relation $\\zeta_t^{(\\rho)} \\stackrel{d}{=} \\{x\\colon \\xi_t^x = \\xi_t^{\\rho}\\}$. This duality relation holds for the standard coalescing random walk, not the modified process used in the proof. Therefore, the bound derived for $\\E[N_t(X_t)]$ does not apply to $\\E[|\\zeta_t^{(\\rho)}|]$, invalidating the subsequent steps that rely on this bound."
      },
      {
        "Problem": "Incorrect calculation/inequality for particle count dynamics in Proposition 2.",
        "Location": "Proposition 2, proof, inequality for $N_t(X_t)$.",
        "Explanation": "Even assuming the non-standard process defined in the proof, the inequality $N_t(X_t) \\leq 1 + \\sum_{((v,w),s) \\in U_{\\gamma}(t)} N_s^{\\gamma}(v) + \\sum_{s \\leq t\\colon X_s \\neq X_{s^-}}N_{s^-}^{\\gamma}(X_s)$ appears to incorrectly model the dynamics of particle merging. Specifically, the term summing $N_{s^-}^{\\gamma}(X_s)$ over jump times of $X_t$ does not accurately capture how the number of particles at $X_t$ changes when $X_t$ jumps into an occupied vertex. This makes the derived bound for $\\E[N_t(X_t)]$ unreliable."
      },
      {
        "Problem": "Non-standard and potentially incorrect analysis of modified voter model in Proposition 2.",
        "Location": "Proposition 2, proof, paragraph starting 'First we estimate $\\E[\\,N_s^{\\gamma}(v) \\mid \\gamma\\,]$'.",
        "Explanation": "The proof introduces a modified voter model $\\{\\zeta_r\\}$ to analyze $\\E[N_s^{\\gamma}(v)]$. The described transition rules for this process, particularly the rule that removes vertices from the cluster if they are on the path $\\gamma$, do not correspond to standard voter model dynamics or their known duals. This makes the subsequent claim that $|\\zeta_r|$ is a supermartingale and the resulting bound $\\E[N_s^{\\gamma}(v)] \\leq 1$ questionable."
      }
    ],
    "token_usage": {
      "input": 7986,
      "thinking": 11525,
      "output": 667
    }
  },
  {
    "entry_id": 137,
    "retraction_id": "2011.07585v2",
    "paper_id": "2011.07585v1",
    "retraction_comment": "The article contains wrong idea. There was mistake in the H3 assumption",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect proof of property (H3) in Lemma 2",
        "Location": "Page 3, Lemma 2",
        "Explanation": "The proof of Lemma 2, which aims to show that the chosen function h_k satisfies property (H3) required by Algorithm 1, uses the inequality E[f(x_k)] <= E[H_k(x_k)]. This inequality is generally false because H_k(x) = f(x) + (kappa/2)||x - y_{k-1}||^2, implying f(x) = H_k(x) - (kappa/2)||x - y_{k-1}||^2. This invalidates the proof that (H3) holds, which is crucial for the convergence guarantees of the Catalyst framework (Algorithm 1)."
      },
      {
        "Problem": "Inconsistent problem formulation and inner solver application in decentralized setting",
        "Location": "Section 2, Section 3.3",
        "Explanation": "The paper applies the Catalyst framework (Algorithm 1), designed for optimizing a single variable x in R^d, to accelerate the convergence of the average variable (overline x) in a decentralized setting where the algorithm (DSGD) operates on a matrix of variables X in R^{d x n}. The inner subproblem H_k(x) is defined for a single variable x in R^d, while Algorithm 1.2 operates on matrices X_k, Y_k. It is not rigorously shown how the decentralized DSGD algorithm, which minimizes a sum of local functions while maintaining consensus, can effectively solve the required centralized subproblem H_k(x) or a properly defined decentralized equivalent tilde H_k(X) with the convergence properties needed by Catalyst. The definition of Y_k as a matrix in Algorithm 1.2 further adds to this inconsistency regarding the variable space of the subproblem."
      },
      {
        "Problem": "Incorrect variance and gradient terms used in the accelerated complexity analysis",
        "Location": "Section 3.3 (Equation 2), Appendix 4.4",
        "Explanation": "The final accelerated convergence rate formula (Equation 2) uses the variance (sigma_bar^2) and gradient at optimum (zeta_bar^2) terms from the original function f. However, the inner solver in the Catalyst framework minimizes the auxiliary function H_k(x) = f(x) + (kappa/2)||x - y_{k-1}||^2. The stochastic properties (variance of stochastic gradients, gradient at the optimum of the subproblem) of H_k are different from those of f. The convergence rate of the inner solver (DSGD applied to the subproblem) should depend on the properties of H_k, not f. Using the parameters of f in the final rate for the accelerated algorithm is incorrect and leads to an unsubstantiated complexity claim."
      },
      {
        "Problem": "Unsound analysis of the number of inner iterations",
        "Location": "Appendix 4.1, Appendix 4.3",
        "Explanation": "The calculation of the number of inner iterations t_k required for each subproblem in Appendix 4.1 and Appendix 4.3 relies on bounding the term H_k(x_{k-1}) - H_k^*. The derivation of this bound in Appendix 4.1 appears flawed, stemming from the incorrect steps in Lemma 2. Specifically, the bound H_k(x_{k-1}) - H_k^* <= (S+1)epsilon_{k-2} is not convincingly justified. This makes the subsequent calculation of the total complexity of the accelerated algorithm by summing the inner iteration counts unreliable."
      }
    ],
    "token_usage": {
      "input": 13754,
      "thinking": 7639,
      "output": 815
    }
  },
  {
    "entry_id": 138,
    "retraction_id": "1803.09392v2",
    "paper_id": "1803.09392v1",
    "retraction_comment": "This paper is withdrawn as the proof of Lemma 2.4 is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous and potentially ill-posed definition of the lattice $\\cL$",
        "Location": "Section 2",
        "Explanation": "The definition of the $\\Z G$-lattice $\\cL$ is unclear regarding the index of the intersection $\\cap_v$ and the scope of the defined local modules $\\cL_v$. It defines $\\cL_v$ only for a single chosen place $v(w)$ above each $w$, but the intersection seems to imply $v$ runs over all places of $N$. This makes the construction of $\\cL$ ambiguous and potentially mathematically unsound as written."
      },
      {
        "Problem": "Incorrect assumption on the equality of classes in $\\Cl(\\Z G)$",
        "Location": "Section 3, Proof of Theorem \\ref{T:tboas}",
        "Explanation": "The proof concludes that $\\Omega(N/F, 2) = (A_{N/F})$ in $\\Cl(\\Z G)$ by using the relation $\\Omega(N/F, 2) = (\\cL)$ in $\\Cl(\\Z G)$ and stating $\\cL = \\alpha A_{N/F}$ for some $\\alpha \\in O_F$. The equality $(\\alpha A_{N/F}) = (A_{N/F})$ in $\\Cl(\\Z G)$ is implicitly assumed but is generally false for $\\alpha \\in O_F$ unless $\\alpha$ satisfies restrictive conditions (e.g., $\\alpha^{[F:\\Q] \\cdot \\text{rank}_{O_FG}(A_{N/F})}$ is a global unit whose determinant image is in the image of local unit determinants), which are not mentioned or guaranteed by the choice of $\\alpha$."
      },
      {
        "Problem": "Issues with non-integer valuations in local constructions",
        "Location": "Section 2, Definition of $\\wt{U}_v(1)$, Remark \\ref{R:mult}, Lemma proof",
        "Explanation": "When $N/F$ is tame and $A_{N/F}$ exists, the inertia degrees $e_v$ at ramified places $v$ must be odd. The valuation $v_v(\\cL_v) = v_v(\\alpha) + v_v(A_{N_v/F_w}) = v_v(\\alpha) + e_v/2$ is not an integer. Subsequent steps involving $\\exp_v(m \\cL_v)$ and quotients like $U_v(1)/\\exp_v(m \\cL_v)$ appear to rely on properties that hold for ideals with integer valuations (e.g., relating $\\exp_v$ to $1+\\pi_v^t O_{N_v}$), leading to potential unsoundness in the definition of $\\wt{U}_v(1)$ and the calculation of the class in the Lemma."
      },
      {
        "Problem": "Incorrect application of Chinburg's local class result",
        "Location": "Section 2, Lemma proof",
        "Explanation": "The proof of the Lemma refers to Chinburg's result (Proposition \\ref{P:key}) concerning the class of $U_v(1)/(1+\\pi_v^{t_v}O_{N_v})$ for integer $t_v$. Applying this result or its method to $U_v(1)/\\exp_v(m \\cL_v)$ implicitly requires the valuation $v_v(m \\cL_v)$ to behave like an integer valuation, which is not the case when $N/F$ is tame and $A_{N/F}$ exists (as $e_v$ is odd), making the application unsound."
      },
      {
        "Problem": "Incorrect statement about the form of local fractional ideals",
        "Location": "Section 2, Remark \\ref{R:mult}",
        "Explanation": "The statement that for $\\beta \\in O_F$, $\\beta \\cdot \\cL_v = \\pi_{v}^{t_{v}} \\cdot O_{N_v}$ for some $t_v \\in \\Z_{\\geq 0}$ is incorrect when $v_v(\\beta \\cL_v)$ is not an integer. This occurs when $N/F$ is tame and $A_{N/F}$ exists (since $e_v$ is odd), as $v_v(\\beta \\cL_v) = v_v(\\beta) + v_v(\\alpha) + e_v/2$. This suggests a fundamental issue in handling the valuations of the involved fractional ideals when the exponents are not integers, which is central to the definition and properties of $A_{N/F}$ in this context."
      }
    ],
    "token_usage": {
      "input": 8305,
      "thinking": 21854,
      "output": 1060
    }
  },
  {
    "entry_id": 139,
    "retraction_id": "1709.04340v2",
    "paper_id": "1709.04340v1",
    "retraction_comment": "A problem with the proofs of Propositions 2 and 3 (a gap or fault in the reasoning used to claim that the expression in (3.9) is dominated by that in (3.11)); a similar problem with the proof of Proposition $1'$ (it is hard to justify the particular application of the Bourgain-Guth reduction theory implicit in a paragraph above Proposition $1'$). Theorems 1, 2 and 3 lose their status as theorems",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect simplification of bound in Section 6 affecting Theorem 3 for $\\nu \\leq 5$",
        "Location": "Section 6, paragraph containing (6.8)",
        "Explanation": "The simplification of the bound on $A_q^{1/q}$ for $\\nu \\leq 5$ relies on inequalities involving the relative sizes of $K$ and $L$ (e.g., $L^{2(\\nu-3)}/K^{\\nu-2} \\ll \\dots$) that are not generally true for all parameter ranges covered by the case $K < L^2$ (where Proposition 2 is applied). This affects the exponents in (6.8) and consequently the bounds in Theorem 3 for $\\nu \\leq 5$."
      },
      {
        "Problem": "Incomplete proof of Theorem 1 due to incorrect parameter range assumption",
        "Location": "Section 8, paragraph before (8.7)",
        "Explanation": "The proof of Theorem 1 relies on bounding the exponential sum $S^*$ using results from the First Spacing Problem (analogues of Proposition 2 and 3). The text claims that the parameter ranges satisfy $L^2 > K$, which is used to justify applying only the bound corresponding to this case (an analogue of (6.3) derived from Proposition 2). However, analysis of the parameter ranges in Section 8 shows that $L^2 > K$ is not always satisfied. The proof does not provide a bound for $S^*$ in the case $K \\geq L^2$ (which would require an analogue of (6.5) derived from Proposition 3), rendering the proof of Theorem 1 incomplete."
      }
    ],
    "token_usage": {
      "input": 34028,
      "thinking": 16603,
      "output": 381
    }
  },
  {
    "entry_id": 140,
    "retraction_id": "1106.5292v3",
    "paper_id": "1106.5292v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (5)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Jordan frame metric equation derivation",
        "Location": "Section 3.2, Eq. 15",
        "Explanation": "The variation of the kinetic term $-\\frac{1}{2}\\int d^n x \\sqrt{-\\bar g} \\nabla^c\\phi \\nabla_c\\phi$ with respect to the metric $\\bar g^{ab}$ yields $\\sqrt{-\\bar g} (-\\frac{1}{2}\\nabla_a\\phi \\nabla_b\\phi + \\frac{1}{4}\\nabla^c\\phi \\nabla_c\\phi \\bar g_{ab})$. The term $\\frac{1}{4}\\nabla^c\\phi \\nabla_c\\phi \\bar g_{ab}$ is missing from the expression for the variation of $S_J$ that leads to Eq. 15. This makes Eq. 15 incorrect."
      },
      {
        "Problem": "False claim about the trace of the transformed Einstein equation",
        "Location": "Section 3.3, paragraph after Eq. 17",
        "Explanation": "The paper claims that contracting the left-hand side of Eq. 17 (derived from the Einstein equation) with $\\bar g^{ab}$ yields a multiple of the left-hand side of Eq. 16 (the Jordan frame scalar equation). A direct calculation shows that the trace of Eq. 17 is not proportional to the left-hand side of Eq. 16. This invalidates a key step in the paper's argument for incompatibility."
      },
      {
        "Problem": "Conclusion of incompatibility based on incorrect equations",
        "Location": "Section 3.3, conclusion paragraph",
        "Explanation": "The paper concludes that the equations of motion in the Einstein and Jordan frames are incompatible based on the difference between Eq. 17 (correctly derived from the Einstein equation) and Eq. 15 (incorrectly derived from the Jordan frame action). The standard result in the literature is that the correctly derived equations of motion in both frames are equivalent. The discrepancy found in the paper is a consequence of the error in deriving Eq. 15, not a fundamental mathematical inequivalence between the frames."
      }
    ],
    "token_usage": {
      "input": 8351,
      "thinking": 38347,
      "output": 497
    }
  },
  {
    "entry_id": 141,
    "retraction_id": "1903.00526v2",
    "paper_id": "1903.00526v1",
    "retraction_comment": "An error occurs in Section 5. Post-measurement results in the RTO experiment are improperlystated to directly apply to the entangled measurement state itself. This puts the conclusions stated in the abstract into question",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect reinterpretation of product states",
        "Location": "Abstract, Page 1, Page 5, Page 7",
        "Explanation": "The paper reinterprets the product state |A1>|B1> to mean \"A has property |A1> if and only if B has property |B1>\". In standard quantum mechanics, a product state |A1>|B1> describes a composite system where subsystem A is in state |A1> and subsystem B is in state |B1>, meaning A possesses the property associated with |A1> and B possesses the property associated with |B1>. The proposed \"if and only if\" phrasing describes a correlation, which is a property of the joint state, not the individual product state basis vectors themselves. This reinterpretation is a fundamental departure from standard quantum mechanics without sufficient justification."
      },
      {
        "Problem": "Flawed argument connecting RTO experiment results to the reinterpretation of product states",
        "Location": "Page 3, Page 4, Page 5",
        "Explanation": "The paper uses the RTO experiment results, specifically the phase-dependent correlations and the mixed local states (Table 1), to argue that the entangled state (2) must be a superposition of correlations, thereby necessitating the reinterpretation of product states. However, these experimental results and their description (mixed local states, phase-dependent correlations) are standard features of entangled states and are fully consistent with the standard interpretation of (2) as a superposition of joint states |A1>|B1> and |A2>|B2>. The correlations arise *from* the entanglement structure, not from a redefinition of the product state basis vectors. The argument incorrectly uses standard consequences of entanglement to justify a non-standard interpretation of the basis states."
      },
      {
        "Problem": "The proposed interpretation does not fully resolve the definite outcomes problem",
        "Location": "Abstract, Page 1, Page 7",
        "Explanation": "The paper claims that interpreting the entangled state (2) as a superposition of correlations (\"|A1> if and only if |B1>, and |A2> if and only if |B2>\") makes it non-paradoxical and definite, resolving the problem of definite outcomes. However, this is still a superposition of two distinct possibilities for the composite system's state/properties (whether interpreted as joint properties or correlations). The core problem of definite outcomes in quantum measurement is explaining why, upon measurement, only *one* of the terms in the superposition is observed, rather than the system remaining in the superposition. The proposed reinterpretation of the terms does not inherently explain this selection process or the apparent collapse."
      },
      {
        "Problem": "Misleading use of the term \"decoherence\"",
        "Location": "Page 3, Page 5, Page 7",
        "Explanation": "The paper states that entanglement \"decoheres\" both photons (Page 3, Page 5). While entanglement leads to the subsystems being described by mixed states (which is related to decoherence in the context of interaction with an environment), the term \"decoherence\" typically refers to the loss of coherence due to interaction with an environment, leading to a transition from a pure state to a mixed state. In the case of entanglement between two subsystems A and B, the *composite* system AB remains in a pure state (2), and the coherence is present in the correlations between A and B. The subsystems A and B are in mixed states (3) and (4) when considered in isolation (by tracing over the other subsystem), but this is a consequence of entanglement, not necessarily \"decoherence\" of the subsystems themselves in the usual sense. The author later clarifies that entanglement \"shifts coherence to the composite system\" (Page 4, Page 7), which is more accurate, but the initial use of \"decoheres both photons\" is potentially misleading."
      },
      {
        "Problem": "Incomplete explanation of the transition to a single outcome",
        "Location": "Section 3, Page 5-7",
        "Explanation": "The paper describes the measurement process as a unitary evolution into the entangled state (2), followed by a \"collapse\" at the instant of entanglement, leading to the subsystems being in ontological mixtures (3) and (4). It then invokes the irreversibility of macroscopic recording (FAPP) to explain the single observed outcome. However, the transition from the pure entangled state (2) to a single definite outcome (e.g., A1 and B1) is not fully explained by the unitary evolution or the FAPP irreversibility of recording. The paper states that \"nonlocal properties of entanglement guarantee that one and only one outcome is realized\" (Page 7), but this is a statement of the outcome, not a mechanism derived from the proposed interpretation or the described process. The core issue of how the system selects a single branch from the superposition (2) is not clearly resolved."
      }
    ],
    "token_usage": {
      "input": 2446,
      "thinking": 3232,
      "output": 1071
    }
  },
  {
    "entry_id": 142,
    "retraction_id": "1503.07411v2",
    "paper_id": "1503.07411v1",
    "retraction_comment": "This paper has been withdrawn due to a gap in the proof of Proposition 2.19",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof of the main theorem (Theorem 1.1) assumes the target of the birational map is a del Pezzo fibration over $\\mathbb{P}^1$, which is not required by the definition of birational rigidity.",
        "Location": "Theorem 1.1, Section 2.4 (Proof of Theorem 1.1)",
        "Explanation": "The definition of birational rigidity requires considering birational maps to *any* Mori fiber space $X'/S'$. The proof constructs a sequence of birational automorphisms $g_i: X \\ratmap X$ and analyzes the birational transform $\\mathcal{H}_k$ of the initial linear system $\\mathcal{H}_0$ via $f_k = f \\circ (g_{k-1} \\circ \\dots \\circ g_0)^{-1}$. The argument in Proposition 2.12, which is crucial for concluding that $f_k$ is square, assumes that the target $X'$ is a del Pezzo fibration over $\\mathbb{P}^1$ (using $\\mathcal{H}' \\sim_{\\mathbb{Q}} - \\mu' K_{X'} + \\nu' F'$ where $F'$ is a fiber over $\\mathbb{P}^1$). This assumption is not justified by the definition of birational rigidity, which allows $X'$ to be any Mori fiber space over any base $S'$. This invalidates the conclusion that $X/\\mathbb{P}^1$ is birationally rigid in the general sense."
      },
      {
        "Problem": "The proof relies on applying results concerning non-canonical singularities to points defined as 'weak maximal centers', which is not justified.",
        "Location": "Lemma 2.11, Proposition 2.12",
        "Explanation": "Lemma 2.11 and Proposition 2.12 aim to show that if there are no curve or singular point weak maximal centers, the birational map is square. Proposition 2.12 uses inequalities derived from Corti's Theorem 3.12, which applies to non-canonical centers of $K_X + \\frac{1}{\\mu} \\mathcal{H}$. The definition of a weak maximal center in the paper ($m_E(\\mathcal{H}) > \\mu a_E(K_X)$) is different from the standard definition of a non-canonical center ($a_E(K_X) + \\frac{1}{\\mu} m_E(\\mathcal{H}) < 0$). For terminal singularities ($a_E(K_X) > 0$), a weak maximal center is not necessarily a non-canonical center. Applying theorems about non-canonical centers to weak maximal centers is not justified and appears unsound, invalidating the argument in these propositions."
      },
      {
        "Problem": "The formula for the pullback of a fiber used in the proof of Lemma 2.11 is incorrect.",
        "Location": "Lemma 2.11",
        "Explanation": "The proof uses the relation $F'_i = p^*F_i - \\sum c_{ij} E_{ij}$, where $F'_i$ is the strict transform of the fiber $F_i$ and $E_{ij}$ are $p$-exceptional divisors. The correct relation for the pullback of a divisor is $p^*D = \\tilde{D} + \\sum m_E(D) E$, where $\\tilde{D}$ is the strict transform and $m_E(D)$ is the multiplicity of $D$ along $E$. For a fiber $F_i$, the relation should be $p^*F_i = F'_i + \\sum c_{ij} E_{ij}$, where $E_{ij}$ are $p$-exceptional divisors contracted to points in $F_i$ and $c_{ij}$ are positive integers. This error affects the definition of $\\lambda_i$ and the subsequent calculation of discrepancies, undermining the proof of the lemma."
      },
      {
        "Problem": "The calculation of the self-intersection number $(-K_X)^3$ for the constructed del Pezzo fibrations $X_n$ appears incorrect.",
        "Location": "Lemma 3.5",
        "Explanation": "The paper calculates $(-K_X)^3 = 12 - 5n$. Based on the description of $X_n$ as a hypersurface of class $4H$ in the weighted projective space bundle $P_n = \\text{Proj}_{\\mathbb{P}^1}(\\mathcal{O}^3 \\oplus \\mathcal{O}(-n))$, the canonical divisor is $-K_X \\sim H + (2-n)F$. Using standard intersection theory on such bundles, $(-K_X)^3$ is calculated as $12 - 10n$. While the final inequality in Lemma 3.5 holds with the corrected value, the calculation itself is erroneous."
      }
    ],
    "token_usage": {
      "input": 25934,
      "thinking": 23303,
      "output": 1082
    }
  },
  {
    "entry_id": 143,
    "retraction_id": "1602.03949v2",
    "paper_id": "1602.03949v1",
    "retraction_comment": "This paper has been withdrawn by the author due to the different description of second-order correlation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition of Signal-to-Noise Ratio (SNR) used in Equation (1) is non-standard for imaging and ghost imaging. It calculates the ratio of the sum of object pixels to the sum of the difference between object and reconstructed image pixels. This metric is more akin to a fidelity or PSNR measure and does not represent the conventional definition of SNR (e.g., mean signal divided by standard deviation of noise), which quantifies the ability to distinguish signal from noise fluctuations. Using this non-standard definition makes the claim of \"improving signal-to-noise ratio\" potentially misleading, as the observed improvement might reflect increased image fidelity or reduced overall error rather than improved robustness against noise in the conventional sense.",
        "Location": "Equation (1), Page 2",
        "Explanation": "The formula `SNR = 20 * log10 | Sum(S(x,y)) / Sum(S(x,y) - O(x,y)) |` is used. S(x,y) is the binary object, O(x,y) is the reconstructed image. This is not the standard definition of SNR in imaging (mean/std dev). The conclusions about SNR improvement are based on this metric, which may not reflect the system's performance in overcoming noise fluctuations."
      },
      {
        "Problem": "The comparison labeled \"direct imaging\" in Figure 3 appears to be based on analyzing the raw speckle patterns captured by the camera in the idler arm of the ghost imaging setup, rather than a true direct image of the object. The camera in the idler arm receives light that has interacted with the object in the signal arm and been split by BS2. This is part of the ghost imaging process, not a standard direct imaging setup where the object is focused onto the sensor. Comparing the filtering effect in ghost imaging to this mislabeled \"direct imaging\" is misleading and weakens the argument that filtering is particularly beneficial for ghost imaging compared to conventional imaging.",
        "Location": "Figure 3, Page 2",
        "Explanation": "Figure 3 presents results for \"direct imaging SNR\". However, the experimental setup (Figure 1) shows the camera is in the idler arm, capturing speckle patterns. Analyzing these patterns without correlation is not direct imaging of the object. The comparison is therefore based on an invalid premise."
      },
      {
        "Problem": "The experimental setup involves mixing a strong, wideband thermal background with the narrowband signal *before* the object and filter. While a filter is placed in the signal arm *after* the object, the idler arm receives unfiltered broadband background light (in addition to the signal component split by BS2). The correlation process relies on correlating the signal arm measurement (filtered) with the idler arm measurement (unfiltered broadband background + signal). The presence of significant unfiltered broadband background in the idler arm could introduce noise into the correlation, and the paper does not fully explain how this is handled or its impact, beyond stating that the iris controls the total light. While the filtering in the signal arm helps, the unfiltered background in the idler arm remains a potential source of noise that is not explicitly addressed in the context of the correlation calculation.",
        "Location": "Figure 1 (Experimental setup), Page 1; Section 2 (Method & Result), Page 1",
        "Explanation": "The background light is mixed before the object and filter. The filter is only in the signal arm. The idler arm camera receives unfiltered broadband background light. The correlation is performed between the filtered signal arm measurement and the idler arm measurement containing unfiltered background. The impact of this unfiltered background on the correlation noise is not clearly analyzed or mitigated, potentially affecting the interpretation of the results."
      }
    ],
    "token_usage": {
      "input": 640,
      "thinking": 3781,
      "output": 797
    }
  },
  {
    "entry_id": 144,
    "retraction_id": "2203.01307v2",
    "paper_id": "2203.01307v1",
    "retraction_comment": "Lemma 2.1 is true for Heisenberg type groups, but in general not for M_tivier groups, cf. Eq. (2.4) of M_ller and Stein [MS94]",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 28428,
      "thinking": 22750,
      "output": 1
    }
  },
  {
    "entry_id": 145,
    "retraction_id": "2112.10980v2",
    "paper_id": "2112.10980v1",
    "retraction_comment": "There is an error in the proof of the co-primality statement in Proposition 6. The author has constructed examples of knots with integer surgeries so that the orders of the groups generated by these knots and their surgery duals have a non-trivial common factor, so in fact the co-primality statement in Proposition 6 is false",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Trace Manifold",
        "Location": "Section 2, Proposition 6 and Theorem 7",
        "Explanation": "Section 2 defines integral surgery using an integral longitude (0/1 surgery) and studies its trace $W_\\lambda(K)$. Proposition 6 proves properties of this specific trace manifold. Theorem 7, however, is about 1/2-surgery, but its proof applies Proposition 6 to the trace of this 1/2-surgery. The trace of 0/1-surgery and the trace of 1/2-surgery are different 4-manifolds, rendering the application of Proposition 6 in the proof of Theorem 7 incorrect."
      },
      {
        "Problem": "Flawed Co-primality Proof",
        "Location": "Proposition 6",
        "Explanation": "The proof that $|K|$ and $|K^*|$ are co-prime relies on identifying a generator of the free part of $H_2(W, \\partial W)$ using torsion classes $[\\chi, -K]$ and $[\\chi^*, K^*]$ and their pairing with $[\\hat\\Sigma_K]$. The argument that $PD(n\\cdot [\\chi, -K] + n^* \\cdot [\\chi^*, K^*])([\\hat\\Sigma_K])=1$ is based on a misunderstanding of the relevant homology/cohomology pairings and the nature of the classes $[\\chi, -K]$ and $[\\chi^*, K^*]$ (which are torsion in $H_2(W, \\partial W)$). This invalidates the conclusion that $|K|$ and $|K^*|$ are co-prime, which is essential for Theorem 7."
      },
      {
        "Problem": "False Premise on Knot Determinant",
        "Location": "Proof of Theorem 2",
        "Explanation": "The proof of Theorem 2 claims that $|\\kappa| \\equiv 1 \\pmod 2$ because $|H_1(\\Sigma(K))|$ (which is the determinant of the knot $K$ in $S^3$) is odd. The determinant of a knot in $S^3$ is not always odd (e.g., the determinant of the knot $8_{17}$ is 16). This false premise is used to satisfy a condition ($|K| \\equiv 1 \\pmod 2$) required for the application of Theorem 7, thus invalidating the proof of Theorem 2."
      }
    ],
    "token_usage": {
      "input": 6388,
      "thinking": 10938,
      "output": 551
    }
  },
  {
    "entry_id": 146,
    "retraction_id": "2006.16461v2",
    "paper_id": "2006.16461v1",
    "retraction_comment": "withdrawn due to an error in Lemma 4.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for N(1,p,q) and definition of r,s",
        "Location": "Theorem 2.8, Definition of r and s in Introduction",
        "Explanation": "The formula for N(1,p,q) attributed to Honda in Theorem 2.8, N(1,p,q) = |(r_0+1)...r_k|, appears incorrect when compared to Honda's actual result N(1,p,q) = p_{k-1} for p/q=[a_0,...,a_k]. The definitions of r and s, crucial for the main theorem's formula, are based on this potentially incorrect formula and the negative continued fraction of -p/q. This invalidates the base case used to solve the recurrence relation."
      },
      {
        "Problem": "Incorrect description of bypass effect for n=1",
        "Location": "Proposition 3.5",
        "Explanation": "Proposition 3.5 claims that an interior bypass on a tight structure with dividing set (1,-p,q) results in a tight structure with dividing set (1,-p',q') where -p'/q'=[r_0,...,r_k+1]. This specific transformation of the continued fraction of the slope seems inconsistent with the standard bypass operation described in the literature (e.g., by Honda), which corresponds to taking the previous convergent of the slope. This affects the recurrence relation derived in Lemma 4.2, particularly the N(0,p,q) term."
      },
      {
        "Problem": "Algebraic error in recurrence proof for C_n(n+1)",
        "Location": "Proof of Lemma 4.4",
        "Explanation": "The proof of Lemma 4.4 attempts to show that the sequence C_n(n+1) satisfies a specific recurrence relation by using generating functions. The calculation involving the coefficient of x^n in A(x)B(x) results in 2n * (1/n) = 2, while the proof claims this sum is 0. This algebraic error invalidates the proof that C_n(n+1) satisfies the claimed recurrence, and consequently invalidates the proof that C_n((r-s)n+s) satisfies the recurrence for N(n,p,q)."
      }
    ],
    "token_usage": {
      "input": 16585,
      "thinking": 15103,
      "output": 521
    }
  },
  {
    "entry_id": 147,
    "retraction_id": "1811.02204v3",
    "paper_id": "1811.02204v2",
    "retraction_comment": "Some arguments in the proof of Thm. 2.3.3 are erroneous. One of the faulty arguments lies in the estimate on the first line of page 24. The author mistakenly treats the orthogonal decomposition with respect to the unweighted inner product as the one with respect to the weighted one. Contents which are free from irreparable errors are contained in arXiv:1912.08076",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The metric $\\omega_b$ used in Theorem 2.8 is not guaranteed to be K\\\"ahler.",
        "Location": "Theorem 2.8, definition of $\\omega_b$ and proof",
        "Explanation": "The metric $\\omega_b$ is defined as $\\omega + b(\\ibddbar(\\vphi_L+\\psi) - \\ibddbar\\log|\\psi|)$. For $\\omega_b$ to be K\\\"ahler, the form $\\ibddbar(\\vphi_L+\\psi) - \\ibddbar\\log|\\psi| = \\ibddbar(\\vphi_L+\\psi) + \\frac{1}{|\\psi|}\\ibddbar\\psi + \\frac{1}{|\\psi|^2}\\ibar\\diff\\psi \\wedge \\dbar\\psi$ must be non-negative. Assumption (2.2.1) states $\\ibddbar(\\vphi_L+\\psi) + \\beta\\ibddbar\\psi \\geq 0$ for $\\beta \\in [0, \\delta]$. This does not guarantee the non-negativity of $\\ibddbar(\\vphi_L+\\psi) - \\ibddbar\\log|\\psi|$, especially if $\\ibddbar\\psi$ is negative and $1/|\\psi|$ is larger than $\\delta$. This invalidates the use of $\\omega_b$ as a K\\\"ahler metric in the Bochner-Kodaira inequality."
      },
      {
        "Problem": "The positivity condition for the twisted curvature form $\\Theta_\\mu$ in Theorem 2.8 is not guaranteed.",
        "Location": "Proof of Theorem 2.8, calculation of $\\Theta_\\mu$",
        "Explanation": "The proof uses the Bochner-Kodaira inequality with a weight $e^{-\\vphi-\\mu}$ and metric $\\omega_b$. This requires the curvature $\\Theta_\\mu = \\ibddbar(\\vphi_L+\\psi+\\nu+\\mu)$ to be positive enough. The calculation gives $\\Theta_\\mu = \\ibddbar(\\vphi_L+\\psi) + \\beta_\\mu \\ibddbar\\psi + \\dots$, where $\\beta_\\mu = \\frac{\\sigma -\\sigma\\eps}{|\\psi|} + \\frac{2}{|\\psi| \\log|\\frac{\\ell\\psi}{e_\\sigma}|} + \\frac{3}{|\\psi| \\log|\\ell\\psi|}$. Assumption (2.2.1) guarantees positivity if $\\beta_\\mu \\in [0, \\delta]$. Assumption (2.9.1) bounds $\\frac{5}{|\\psi| \\log|\\frac{\\ell\\psi}{e_\\sigma}|} + \\frac{\\sigma}{|\\psi|}$ by $\\delta$. However, $\\beta_\\mu$ includes the term $\\frac{3}{|\\psi| \\log|\\ell\\psi|}$ which is not controlled by (2.9.1) in relation to $\\delta$. Thus, $\\beta_\\mu$ is not guaranteed to be $\\leq \\delta$, and the required positivity of $\\Theta_\\mu$ is not established."
      },
      {
        "Problem": "The application of Lemma 2.7 in Proposition 2.11 to extend the solution across $P_\\psi$ is not justified.",
        "Location": "Proposition 2.11, application of Lemma 2.7",
        "Explanation": "Lemma 2.7 requires the $(n,0)$-form $u$ to have coefficients in $L^2_{loc}(\\Omega; |\\log|z_1|^2|^{-s})$ with $s>1$. In Proposition 2.11, the form $u_{\\eps',\\eps} + s_{\\eps',\\eps}$ is considered. Near a point in $P_\\psi$ (assumed to be an snc divisor $z_1=0$), the weights for $u_{\\eps',\\eps}$ and $s_{\\eps',\\eps}$ are approximately $\\frac{|z_1|^{-2c}}{|\\log|z_1|^2|^{\\sigma-\\sigma\\eps}(\\log|\\log|z_1|^2|)^2+1}$ and $\\frac{|z_1|^{-2c}}{|\\log|z_1|^2|^{\\sigma-\\sigma\\eps}(\\log|\\log|z_1|^2|)^3}$ respectively (where $\\psi \\sim c \\log|z_1|^2$). These weights are not of the form $|\\log|z_1|^2|^{-s}$ with $s>1$, as they involve $\\log|\\log|z_1|^2|$ terms and the exponent of $|\\log|z_1|^2|$ depends on $\\eps$. Therefore, Lemma 2.7 cannot be applied directly, and the argument for extending the equation across $P_\\psi$ fails."
      }
    ],
    "token_usage": {
      "input": 84934,
      "thinking": 8029,
      "output": 1142
    }
  },
  {
    "entry_id": 148,
    "retraction_id": "1303.6535v2",
    "paper_id": "1303.6535v1",
    "retraction_comment": "Crucial flaw in proof of Theorem 3. The argument only gives a lower bound, not purity as claimed (the latter most likely does not hold except for in small rank)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Corollary 4.4 relies on incorrect geometric descriptions for the case when multiplying by a simple reflection increases length.",
        "Location": "Corollary 4.4",
        "Explanation": "Proposition 4.1 provides geometric descriptions for $C^v \\cap C_w$ when multiplying $w$ by a simple reflection $s$ decreases length ($ws<w$). Corollary 4.4 applies these descriptions (implicitly, via K\"unneth and LES) to the case where multiplying $w$ by $s$ increases length ($ws>w$). The geometric relations for $C^v \\cap C_w$ when $ws>w$ are different from those stated in Proposition 4.1, invalidating the relations between extension groups claimed in Corollary 4.4."
      },
      {
        "Problem": "Theorem 4.5 claims incorrect purity weight for Ext^1 and misrepresents the cited source.",
        "Location": "Theorem 4.5",
        "Explanation": "Ext^1(\\Delta_v,\\Delta_w) is identified with $H_c^{1+\\ell(w)-\\ell(v)}(C^v\\cap C_w)$. For $v \\leq w$, $C^v\\cap C_w$ is a smooth affine variety of dimension $\\ell(w)-\\ell(v)$. The compactly supported cohomology $H_c^k$ of such a variety is pure of weight $k$. Thus, Ext^1(\\Delta_v,\\Delta_w) should be pure of weight $1+\\ell(w)-\\ell(v)$, not 2 (unless $\\ell(w)-\\ell(v)=1$). The cited source [Maz, Theorem 32] for the base case $w=w_0$ also gives a different weight ($1+2(\\ell(w_0)-\\ell(v))$)."
      },
      {
        "Problem": "The main recursive formula in Corollary 4.6 is derived from flawed preceding results.",
        "Location": "Corollary 4.6",
        "Explanation": "Corollary 4.6 is stated as a consequence of Corollary 4.4 and Theorem 4.5. Since both Corollary 4.4 (due to incorrect geometric assumptions) and Theorem 4.5 (due to incorrect purity claim and proof) are unsound, the recursive formula derived from them cannot be considered valid."
      },
      {
        "Problem": "The derivation of case (iii) in Corollary 4.6 from Corollary 4.4(iii) is algebraically incorrect.",
        "Location": "Corollary 4.6(iii) and Corollary 4.4(iii)",
        "Explanation": "Assuming the exact sequence in Corollary 4.4(iii) were correct, taking dimensions yields $\\dim \\Ext^1(\\Delta_v, \\Delta_w) = \\dim \\Ext^1(\\Delta_v, \\Delta_{ws}) + 1 - \\dim \\Ext^1(\\Delta_{vs}, \\Delta_{ws})$. This contradicts the formula claimed in Corollary 4.6(iii), which states $\\dim \\Ext^1(\\Delta_v, \\Delta_w) = \\dim \\Ext^1(\\Delta_v, \\Delta_{ws})$. The derivation is flawed even if the geometric input were correct."
      },
      {
        "Problem": "The relation between dim Ext^1 and the coefficient of q in the R-polynomial is incorrect.",
        "Location": "Concluding observations (i)",
        "Explanation": "The coefficient of $q^k$ in the Kazhdan-Lusztig R-polynomial $R_{v,w}(q)$ is $\\dim H_c^{2k}(C^v \\cap C_w)$. $\\Ext^1(\\Delta_v,\\Delta_w) = H_c^{1+\\ell(w)-\\ell(v)}(C^v\\cap C_w)$. The claimed equality $\\dim H_c^{1+\\ell(w)-\\ell(v)}(C^v\\cap C_w) = (-1)^{\\ell(w)-\\ell(v)} \\dim H_c^2(C^v \\cap C_w)$ is generally false for $\\ell(w)-\\ell(v) > 1$."
      }
    ],
    "token_usage": {
      "input": 5477,
      "thinking": 14981,
      "output": 955
    }
  },
  {
    "entry_id": 149,
    "retraction_id": "1204.0036v3",
    "paper_id": "1204.0036v2",
    "retraction_comment": "This paper has been withdrawn by the authors because Lemma 11, for p>1, is incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unproven claim of unitary invariance of average cost.",
        "Location": "Section 1.3, after definition of $f_t$",
        "Explanation": "The paper claims that the average cost $\\E_{\\hd}(\\mathcal{T}_\\zeta)$ is independent of $\\zeta$ due to unitary invariance. However, the defined homotopy $f_t = f - (1-t)\\Delta(\\czeta)f(\\zeta)$ is not unitarily invariant in the sense required for this conclusion. Specifically, if $g = f \\circ U^{-1}$, the homotopy for $(g, U\\zeta)$ is not simply related to the homotopy for $(f,\\zeta)$ by the action of $U$. Thus, the equality $\\E_{\\hd}(\\mathcal{T}_\\zeta)=\\E_{\\hd\\times\\pc}(\\mathcal{T})$ is not justified by the provided argument."
      },
      {
        "Problem": "Incorrect Gamma function inequality used in the proof of Theorem 3.",
        "Location": "Section 4.2, Proof of Theorem 3, last paragraph",
        "Explanation": "The proof of Theorem 3 relies on the inequality $\\Gamma(x+1/2)\\leq \\sqrt{x}\\,\\Gamma(x)$ for all $x>0$. This inequality is false for $x>1/2$. For example, for $x=1$, $\\Gamma(1.5) = \\sqrt{\\pi}/2 \\approx 0.886$, while $\\sqrt{1}\\Gamma(1) = 1$. For $x=2$, $\\Gamma(2.5) = 3\\sqrt{\\pi}/4 \\approx 1.329$, while $\\sqrt{2}\\Gamma(2) = \\sqrt{2} \\approx 1.414$. The correct inequality for $x>0$ is $\\Gamma(x+1/2) \\geq \\sqrt{x}\\Gamma(x)$ (Gautschi's inequality for $a=1/2$). The use of the incorrect inequality invalidates the subsequent steps in the proof."
      },
      {
        "Problem": "The derived bound in Theorem 3 is based on an incorrect inequality.",
        "Location": "Section 4.2, Proof of Theorem 3",
        "Explanation": "The final bound $\\textnormal{(I)} \\leq 18 C D^{3/2}\\D n^{3/2}\\,N^{3/2}$ is derived using the incorrect Gamma function inequality $\\Gamma(x+1/2)\\leq \\sqrt{x}\\,\\Gamma(x)$. This invalidates the proof of the specific polynomial bound claimed in the theorem. While a polynomial bound might still hold, the proof provided is fundamentally flawed at this step."
      }
    ],
    "token_usage": {
      "input": 31232,
      "thinking": 24138,
      "output": 630
    }
  },
  {
    "entry_id": 150,
    "retraction_id": "2111.11437v6",
    "paper_id": "2111.11437v5",
    "retraction_comment": "There is an error. In section 3.4, the author identifies $Hom_Q(M, _M)$ with the set $Mat_{r \\times r}$ through the decomposition of M into a direct sum of indecomposable modules, and discusses nilpotent matrices in $Mat_{r \\times r}$. This is misleading because here we do not have a natural ring structure on $Mat_{r \\times r}$",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Non-standard definition and properties of dual representation M* not justified.",
        "Location": "Definition 2.3",
        "Explanation": "The definition of the dual representation M* as the minimal element in DExt_Q(M,M) under the degeneration order is non-standard. Its existence, uniqueness, and properties (crucial for Lemma 3.7) are not proven or referenced, undermining subsequent arguments."
      },
      {
        "Problem": "Crucial structural property of dual representation (Lemma 3.7) unproven.",
        "Location": "Lemma 3.7",
        "Explanation": "Lemma 3.7 claims that the dual representation M_lambda* (as defined in the paper) corresponds to a matrix with specific non-zero entries (a_{i,i+1}=1). This structural claim is essential for the proof of Lemma 3.8 and the main theorems (3.9, 3.10, 5.2), but the provided proof is insufficient and lacks rigorous justification or reference."
      },
      {
        "Problem": "Proof of Lemma 3.4 contains incorrect statements and unjustified inequalities.",
        "Location": "Lemma 3.4",
        "Explanation": "The proof incorrectly states that rigid representations with the same dimension vector are isomorphic and uses an unjustified inequality regarding the dimension of extension groups. While the lemma's conclusion might hold under specific conditions (e.g., for indecomposables when the sum of roots is a root), the presented proof is unsound."
      },
      {
        "Problem": "Incorrect inequality stated in Proposition 3.1 (3).",
        "Location": "Proposition 3.1 (3)",
        "Explanation": "The proposition states that if [beta_k, beta_l]^1=1, then beta_k < C beta_k <= beta_l. Based on the root ordering and AR duality ([beta_k, beta_l]^1 = [beta_l, C beta_k]), the correct relation should be beta_k < beta_l < C beta_k. This error in a stated property could potentially affect arguments relying on this specific ordering relation."
      },
      {
        "Problem": "Assumption in Lemma 3.11 and Corollary 4.4 regarding Hom/Ext vanishing not justified.",
        "Location": "Lemma 3.11, Corollary 4.4",
        "Explanation": "Lemma 3.11 and Corollary 4.4 rely on the assumption that [lambda_i, kappa_j]=0 if j-i<-1 for the specific tau-orbit Kostant partitions. This assumption is not proven based on the structure of these partitions and the root ordering, leaving a gap in the combinatorial calculations that support the main theorems."
      }
    ],
    "token_usage": {
      "input": 42503,
      "thinking": 5158,
      "output": 619
    }
  },
  {
    "entry_id": 151,
    "retraction_id": "0912.4084v3",
    "paper_id": "0912.4084v2",
    "retraction_comment": "This paper has been withdrawn by the author. Paper is withdrawn. On review the paper contributes nothing of significance. The runtime analysis of the algorithms presented, while correct in terms of number of operations, does not represent the complexity of the algorithms in terms of \"bits input\". A naive mistake in reasoning",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Algorithm 1 Decomposition Complexity Analysis is unsound.",
        "Location": "Page 3, Section 2.1.1",
        "Explanation": "The analysis claims a worst-case execution time of O(n log10 n) in magnitude. This relies on an incorrect bound for the total number of inner loop iterations (stated as O(n^0.5 log n)) and an incorrect complexity for arithmetic operations (stated as O(n) in bits instead of O(log n)). A correct analysis of the described subtraction-based division leads to a higher complexity, such as O(n (log n)^2) in bits."
      },
      {
        "Problem": "Algorithm 1 Prime Factoring Complexity Analysis is unsound.",
        "Location": "Page 4, Section 2.1.2",
        "Explanation": "The analysis claims a worst-case execution time of O(n^1.5 log10 n) in magnitude for prime factoring. This is based on the incorrect assumption that the decomposition algorithm is executed sqrt(n) times recursively. The number of recursive calls is bounded by the number of prime factors, which is O(log n)."
      },
      {
        "Problem": "Algorithm 2 Sieve Complexity Analysis is unsound.",
        "Location": "Page 5, Section 3.2.2",
        "Explanation": "The analysis for the sieve process, particularly the complexity calculations for Loop 3 and Loop 5, is fundamentally flawed. It involves multiplying unrelated terms and misapplying complexity bounds, leading to an unjustified O(n^2.5) complexity claim for the sieve."
      },
      {
        "Problem": "Algorithm 2 Filter Complexity Analysis is unsound.",
        "Location": "Page 6, Section 3.2.3",
        "Explanation": "The analysis for the filter process claims a worst-case execution time of O(n^2.5). This is based on an incorrect complexity for the summation/addition operation within Loop 7, which is stated as O(n^1) but should be O(log n) in bits. The correct analysis for the described inefficient filter is O(n^1.5 log n) in bits."
      },
      {
        "Problem": "Incorrect initialization in Algorithm 1 implementation.",
        "Location": "Page 8, Section 6.1",
        "Explanation": "The initialization of the remainder variable 'lv_lng_r' as 'n % (x*y)' is incorrect for the relation n = x*y + r where r is the remainder of n divided by x*y. It should be 'n - x*y'. While the subsequent loops might correct the state, the initial state is based on a misunderstanding of the division relation."
      }
    ],
    "token_usage": {
      "input": 3220,
      "thinking": 7956,
      "output": 614
    }
  },
  {
    "entry_id": 152,
    "retraction_id": "2106.04691v2",
    "paper_id": "2106.04691v1",
    "retraction_comment": "Theorem 1.7 is established only under a restrictive hypothesis, not the generality that the authors assert",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 57278,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 153,
    "retraction_id": "1308.2817v2",
    "paper_id": "1308.2817v1",
    "retraction_comment": "The paper has been withdrawn because Eq.(4) is incorrect (isospin CG coefficients have been omitted). The corrected results change some of the discussion for 48Ca while the conclusions for 208Pb are hardly effected. A revised manuscript is under preparation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 9584,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 154,
    "retraction_id": "1412.0982v2",
    "paper_id": "1412.0982v1",
    "retraction_comment": "This paper has been withdrawn by the authors. As pointed out to us by [REDACTED-NAME], [REDACTED-NAME] and [REDACTED-NAME], Theorem 3.1 is incorrect, namely, the zero locus should be larger than that in Theorem 3.1. We are sincerely grateful to them for their valuable comments. Nevertheless, the metrics we constructed have positive sectional curvature almost everywhere on the Gromoll-Meyer sphere and on the homotopy (not diffeomorphic) RP^7",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The necessity part of the condition for non-negative sectional curvature on (Sp(2), g_r) is based on vectors not in the Lie algebra.",
        "Location": "Proposition 2.3, Proof",
        "Explanation": "The vectors $\\xi_1, \\xi_2$ chosen in the necessity proof of Proposition 2.3, specifically $\\xi_1=\\Big(\\begin{array}{cc} tu\\oi &-\\oj\\\\ -\\oj&tv\\oi \\end{array}\\Big)$ and $\\xi_2=\\Big(\\begin{array}{cc} t(r_2-u)\\oj &\\oi\\\\ \\oi&t(r_1-v)\\oj \\end{array}\\Big)$, are claimed to be in $\\mathfrak{sp}(2)$. However, for a matrix $\\begin{pmatrix} x & y \\\\ -\\bar{y} & z \\end{pmatrix}$ to be in $\\mathfrak{sp}(2)$, the diagonal entries $x$ and $z$ must have zero real part. In the chosen vectors, $x_1=tu\\oi$ and $z_1=tv\\oi$. If $u, v$ are real solutions as stated, then $tu\\oi$ and $tv\\oi$ have zero real part only if $u=0$ or $v=0$, or $t=0$, which would make the vectors zero or simplify the problem in a way not intended. If $u, v$ are meant to be in $\\oIm(\\mathbb{H})$, the statement that they are real solutions to quadratic equations is contradictory. This invalidates the necessity part of the proposition."
      },
      {
        "Problem": "The calculation of the squared norm of the gradient of the function F is incorrect for the metric g_r.",
        "Location": "Equation 4.3",
        "Explanation": "The metric $g_r$ is defined by $|\\begin{pmatrix} x & y \\\\ -\\bar{y} & z \\end{pmatrix}|^2_{g_r} = \\frac{r_1}{2}|x|^2+|y|^2+\\frac{r_2}{2}|z|^2$. The gradient vector field $\\nabla F$ at $A$ is given by $\\nabla F|_A=A\\Big(\\begin{array}{cc} 0&-4\\bar{c}d\\\\ 4\\bar{d}c&0 \\end{array}\\Big)$. Let $\\eta_F = \\begin{pmatrix} 0&-4\\bar{c}d\\\\ 4\\bar{d}c&0 \\end{array}\\Big)$. The squared norm is $|\\nabla F|_A|^2_{g_r} = |\\eta_F|^2_{g_r} = \\frac{r_1}{2}|0|^2 + |-4\\bar{c}d|^2 + \\frac{r_2}{2}|0|^2 = 16|\\bar{c}d|^2 = 16|c|^2|d|^2$. Using $|c|^2 = (1+F)/2$ and $|d|^2 = (1-F)/2$, this is $16 \\frac{1+F}{2} \\frac{1-F}{2} = 8(1-F^2)$. Equation 4.3 states $|\\nabla F|^2_{g_r}=4(1-F^2)$, which is incorrect for general $r_1, r_2$ (it is correct only if $r_1=r_2=1$). This error propagates to subsequent calculations involving $|\nabla F|^2$ and the Hessian."
      },
      {
        "Problem": "The formula for the Hessian of F (and phi) appears to be specific to the bi-invariant metric and is likely incorrect for the general metric g_r.",
        "Location": "Equation 4.4, Equation 4.6",
        "Explanation": "The Hessian $H_F(\\xi, \\xi)$ is related to the Levi-Civita connection $\\nabla$ of the metric $g_r$. The connection formula (Lemma 2.1) depends on $r_1, r_2$. The formula $H_F(\\xi,\\xi)=-4F|y|^2+\\langle\\nabla F, \\widehat{\\xi}\\rangle_{g_r}$ (Eq 4.4) and the definition of $\\widehat{\\xi}$ seem to be derived assuming the bi-invariant metric ($r_1=r_2=1$). For a general left-invariant metric $g_r$, the Hessian calculation $g_r(\\nabla_{\\xi_1} \\nabla F, \\xi_2)$ involves the connection $\\nabla$ which is given by Lemma 2.1. The formula used does not appear to correctly incorporate the $r_1, r_2$ dependence from the connection, making the Hessian calculation and subsequent inequalities (4.5, 4.6) unreliable."
      },
      {
        "Problem": "The analysis of the set of points with zero sectional curvature on the Gromoll-Meyer sphere seems flawed.",
        "Location": "Section 3, Theorem 3.1",
        "Explanation": "The analysis of zero curvature in $(\\Sigma^7, \\tilde{g}_r)$ relies on finding horizontal lifts $\\xi_1, \\xi_2$ such that the base curvature formula $K(\\tilde{\\xi}_1, \\tilde{\\xi}_2) = K(\\xi_1, \\xi_2) - |[\\xi_1, \\xi_2]^V|^2$ is zero. The paper analyzes cases (I), (II), (III) for zero curvature planes in $(Sp(2), g_r)$ and then checks conditions for these vectors to be horizontal and their bracket to have a specific vertical component. However, the vectors considered in cases (II) and (III) (e.g., $\\xi_1=\\Big(\\begin{array}{cc} x_1&0\\\\ 0&z_1 \\end{array}\\Big)$) are generally not horizontal lifts of vectors in $T_{[A]}\\Sigma^7$ for arbitrary $A$, as the horizontal space at $A$ is $A \\cdot (\\mathfrak{m} \\oplus \\mathfrak{k}_1)$. A vector $A\\begin{pmatrix} x & y \\\\ -\\bar{y} & z \\end{pmatrix}$ is horizontal if $\\begin{pmatrix} x & y \\\\ -\\bar{y} & z \\end{pmatrix} \\in \\mathfrak{m} \\oplus \\mathfrak{k}_1$, which means $z=0$. The vectors in cases (II) and (III) have $z_1 \\neq 0$ or $z_2 \neq 0$, so they are not horizontal lifts unless $z_1=z_2=0$, which simplifies the cases significantly and contradicts the paper's analysis. This misapplication of the horizontal space concept likely leads to an incorrect description of the zero curvature set $\\pi(\\Omega)$."
      },
      {
        "Problem": "The proof of positive sectional curvature after conformal deformation is invalid.",
        "Location": "Lemma 4.2, Theorem 4.1",
        "Explanation": "The proof of Lemma 4.2, which is crucial for Theorem 4.1, relies on inequalities derived from the Hessian of $\\phi$ and the norm of $\\nabla\\phi$. As noted in problems 2 and 3, the calculation of $|\\nabla F|^2_{g_r}$ (and thus $|\\nabla\\phi|^2_{g_r}$) and the Hessian $H_F$ (and thus $H_\\phi$) are likely incorrect for the metric $g_r$. Specifically, inequality (4.5) and the subsequent arguments depend on these incorrect formulas. Therefore, the conclusion that the conformally deformed metric $\\tilde{g}_r^t$ has positive sectional curvature for small $t$ is not supported by the provided proof."
      }
    ],
    "token_usage": {
      "input": 21487,
      "thinking": 25043,
      "output": 1792
    }
  },
  {
    "entry_id": 155,
    "retraction_id": "1402.3490v2",
    "paper_id": "1402.3490v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error of the combination rule",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The core combination rule uses an unjustified and potentially unsound normalization factor.",
        "Location": "Definition 3, Eq. 10",
        "Explanation": "The normalization factor $1/(1 - K_D)$ with $K_D = K/(Q_1 Q_2)$ is non-standard for combining incomplete mass functions. Its theoretical basis is not provided, and it leads to the rule being undefined under conditions different from standard Dempster's rule (specifically, when $K = Q_1 Q_2$, which can occur even if $K < 1$). This lacks mathematical justification within established frameworks for handling incomplete information."
      },
      {
        "Problem": "The first numerical example fails to apply the proposed combination rule to derive its stated result.",
        "Location": "Example 1, Section 4",
        "Explanation": "Example 1 claims to show how D numbers theory handles non-exclusive concepts like 'High' and 'Medium' and states the combination of $D_1(High)=1$ and $D_2(Medium)=1$ results in $D(High \\cap Medium)=1$. However, applying the proposed D numbers combination rule (Definition 3) to this case results in $K_D = 1$, making the normalization factor $1/(1-K_D)$ undefined. The stated result is not derived from the rule, undermining the example's purpose and suggesting the rule cannot handle this specific case of complete conflict between non-exclusive concepts as presented."
      },
      {
        "Problem": "The theory lacks a formal mathematical framework for representing and operating on non-exclusive elements in the base set.",
        "Location": "Definition 1, Section 3",
        "Explanation": "While the paper claims D numbers theory removes the exclusiveness hypothesis for elements in $\\Theta$ (like linguistic variables), the definition of $\\Theta$ simply states elements are distinct ($F_i \\neq F_j$). It provides no mathematical structure (e.g., a relationship matrix, lattice) to define the nature or degree of overlap between these non-exclusive elements. Consequently, the intersection operation ($B_1 \\cap B_2$) used in the combination rule is undefined for subsets containing these non-exclusive elements, making the rule's application ambiguous in the very scenario it claims to address."
      },
      {
        "Problem": "The paper misrepresents the handling of the exclusiveness hypothesis in Dempster-Shafer theory and its extensions.",
        "Location": "Introduction, Section 2, Example 1",
        "Explanation": "The paper claims the exclusiveness hypothesis in DST fundamentally prevents modeling overlapping concepts like linguistic variables. While standard DST is defined on a mutually exclusive frame, this limitation can often be addressed by defining the frame at a finer granularity or by using extensions of DST specifically designed for non-exclusive frames (e.g., DSmT), which are not discussed or compared against. This mischaracterization weakens the motivation for the proposed theory."
      }
    ],
    "token_usage": {
      "input": 10249,
      "thinking": 5347,
      "output": 651
    }
  },
  {
    "entry_id": 156,
    "retraction_id": "1504.06694v3",
    "paper_id": "1504.06694v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a logical fallacy was made in transition from equation (46) to equations (47)-(50)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound basis for the 'intuitive approach' method.",
        "Location": "Section 2, equations (9) through (16) and subsequent analysis.",
        "Explanation": "The method attempts to find solutions by relating $n!$ to products of terms derived from the general solution of an unrelated linear Diophantine equation ($6x-4y=2$). The equations involving the parameter $t$, such as $(1+2t)(1+3t) = n!/4!$, are introduced without rigorous justification for their connection to the Brocard-Ramanujan equation $n!+1=m^2$. The logic connecting the steps is unclear and appears arbitrary."
      },
      {
        "Problem": "Incorrect algebraic manipulation in the 'intuitive approach'.",
        "Location": "Section 2, equation (13).",
        "Explanation": "The statement $x_1 \\cdot y_1 = (12-1)(10+1)=11^2$ is algebraically incorrect. $12 \\cdot 10 = 120$, while $(12-1)(10+1) = 11 \\cdot 11 = 121$. This indicates a misunderstanding of how the factors $m-1$ and $m+1$ relate to $n!$ and $m^2$."
      },
      {
        "Problem": "Misuse of polynomial identities by equating coefficients of a fixed number.",
        "Location": "Section 3, equations (30) and (35), and the analysis in subsections 3.1 and 3.2.",
        "Explanation": "The paper treats an equation between numbers (where the value 5 is fixed) as a polynomial identity in a variable $x$ and then equates coefficients of powers of 5. This is mathematically invalid. Equating coefficients is a technique applicable to polynomial identities in a variable, not to equations where the 'variable' is a specific constant value."
      },
      {
        "Problem": "Unfounded assumption about the structure of the integer $r$.",
        "Location": "Section 3, subsections 3.1 and 3.2.",
        "Explanation": "The analysis assumes that the integer $r$ (derived from $m=10r+1$ or $m=10r+9$) can be expressed as a polynomial in 5 with integer coefficients, specifically $r = \\sum_{k=0}^{\frac{n}{2}-2} a_k 5^k$. There is no mathematical justification provided for this assumption, which is critical to the subsequent argument."
      },
      {
        "Problem": "Invalid conclusion derived from flawed analysis.",
        "Location": "Section 3, subsections 3.1 and 3.2, last equations in the systems.",
        "Explanation": "The paper concludes that a coefficient $a_{\frac{n}{2}-2}$ must be irrational based on equations like $a^2_{\frac{n}{2}-2} = 6/25$. This conclusion contradicts the assumption that $a_{\frac{n}{2}-2}$ is an integer coefficient. However, since the assumption about $r$ and the method of equating coefficients are invalid, this derived contradiction does not constitute a valid proof that no integer solution $m$ exists for $n \\geq 8$."
      }
    ],
    "token_usage": {
      "input": 5614,
      "thinking": 5427,
      "output": 747
    }
  },
  {
    "entry_id": 157,
    "retraction_id": "1502.02090v5",
    "paper_id": "1502.02090v4",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 3.15",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the projection onto the G2-irreducible component Lambda^2_7.",
        "Location": "Section 3, before Proposition 3.1",
        "Explanation": "The formula F_A^7 = (1/3)(F_A + * (F_A wedge phi)) is used for the projection onto Lambda^2_7. The correct projection is Pi^2_7(f) = (1/2)(f - * (f wedge phi)). This incorrect formula is used in subsequent calculations involving F_A^7."
      },
      {
        "Problem": "Incorrect formula for the Yang-Mills energy.",
        "Location": "Section 3, before equation (3.11) and Section 4, equation (CY1)",
        "Explanation": "The formula ||F_A||^2 = 3||F_A^7||^2 - integral_M tr(F_A^2) wedge phi on G2 manifolds and YM(A) = 4||F_A^0,2||^2 + ||Lambda F_A||^2 + topological constant on Calabi-Yau 3-folds are incorrect. The correct orthogonal decomposition gives ||F_A||^2 = ||F_A^7||^2 + ||F_A^14||^2 on G2 and YM(A) = 2||F_A^0,2||^2 + ||F_A^1,1_0||^2 + 3||phi_A||^2 on Kahler manifolds. These incorrect energy formulas are fundamental to the variational arguments presented."
      },
      {
        "Problem": "Incorrect stability condition used in the proofs.",
        "Location": "Section 3, equation (3.15) and Section 4, equation (CY13)",
        "Explanation": "The stability condition for a Yang-Mills connection requires the second variation of the Yang-Mills energy to be non-negative. The formulas presented, ||Pi^7_2(ud_A eta)||^2 + 2<F_A^7, eta wedge eta> >= 0 on G2 and 4||bar_pa_A eta^0,1||^2 + <F_A^0,2, eta^0,1 wedge eta^0,1> + <Lambda F_A, Lambda([eta^0,1 wedge bar_eta^0,1])> >= 0 on CY, are not the standard second variation formulas and appear to be incorrect or incomplete expressions, undermining the core assumption of the theorems."
      },
      {
        "Problem": "Incorrect definition and properties of the form psi_A on Calabi-Yau manifolds.",
        "Location": "Section 4, equation (CY3) and subsequent derivations",
        "Explanation": "The definition Lambda_bar_Omega(psi_A) = F_A^0,2 is dimensionally incorrect, as psi_A is stated to be a (0,1) form and F_A^0,2 is a (0,2) form. The explicit component formula for psi_A is also incorrect. This form psi_A is central to the arguments in the Calabi-Yau section, rendering them unsound."
      },
      {
        "Problem": "Flawed derivation involving Lie brackets and inner products in the G2 theorem proof.",
        "Location": "Section 3, proof of Theorem 3.1, steps leading to equation (3.16)",
        "Explanation": "The step 0 = <F_A^7, [psi_A omega wedge omega]> = <[*F_A^7, psi_A], omega> involves non-standard notation for brackets of forms and an inner product that is dimensionally inconsistent. The subsequent claim [*F_A^7, psi_A] = *F_A^7 wedge psi_A is also incorrect for non-abelian Lie algebras. These steps are critical for concluding F_A^7=0."
      }
    ],
    "token_usage": {
      "input": 13642,
      "thinking": 11880,
      "output": 893
    }
  },
  {
    "entry_id": 158,
    "retraction_id": "1611.05964v2",
    "paper_id": "1611.05964v1",
    "retraction_comment": "Algorithm 1 is inefficient since line 2 is processed n 3 times need to be changed There are inconsistent notations throughout the manuscript [REDACTED-NAME] are not defined",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of Tensor Nuclear Norm",
        "Location": "Definition 8, Eq. 18, Page 4",
        "Explanation": "The definition of the generalized nuclear norm sums over 'j' up to min(n1, n2). The tensor nuclear norm based on t-SVD is typically defined as the sum of the nuclear norms of the frontal slices in the Fourier domain, which corresponds to summing the singular values of each frontal slice across all slices. The summation over 'j' is incorrect."
      },
      {
        "Problem": "Incorrect definition and application of Weighted Tensor Nuclear Norm",
        "Location": "Definition 9, Eq. 24, Eq. 33, Algorithm 2 step 8, Page 5-6",
        "Explanation": "Similar to the standard tensor nuclear norm definition, the weighted version includes an incorrect summation over 'j'. Furthermore, the weight tensor Wc is applied element-wise to the singular value tensor Σf (which should be diagonal in the Fourier domain), and the weight update formula (Eq. 36) is also element-wise. This is inconsistent with the standard approach of weighting singular values directly."
      },
      {
        "Problem": "Algorithm steps do not correctly solve the weighted nuclear norm proximal problem",
        "Location": "Algorithm 2, steps 6-10, Page 5",
        "Explanation": "The algorithm computes the t-SVD of Z, multiplies the singular value tensor by the weight tensor, reconstructs Z, and then applies unweighted SVT. This sequence does not correspond to the standard method for solving a weighted nuclear norm proximal problem, which involves applying weighted SVT directly to the input tensor (Z). The derivation of these steps from the IAL objective (Eq. 27) appears flawed."
      },
      {
        "Problem": "Inconsistent weight updating scheme",
        "Location": "Eq. 36, Page 6",
        "Explanation": "The weight Wc(i, j, k) is defined element-wise based on Σf(i, j, k). Since Σf is the singular value tensor in the Fourier domain (which should be diagonal), applying weights Wc(i, j, k) where i != j is problematic as Σf(i, j, k) should be zero for i != j. The weights should ideally be defined based on the singular values themselves (the diagonal elements of Σf), not element-wise on the entire tensor."
      }
    ],
    "token_usage": {
      "input": 3736,
      "thinking": 2667,
      "output": 552
    }
  },
  {
    "entry_id": 159,
    "retraction_id": "2206.04913v2",
    "paper_id": "2206.04913v1",
    "retraction_comment": "I really apologize the audience for this withdrawal. The last section has some errors, because the proof of Lemma 4.2 is not true. Also other sections should be improved",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 34071,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 160,
    "retraction_id": "1705.06716v2",
    "paper_id": "1705.06716v1",
    "retraction_comment": "This study needs many major modifications. Majority of the study includes mistakes. For example, all the plots and the numbers that are generated using ALPGEN MC generator in the tables are not correct. In addition, the selected factorization and renormalization scales do not define the correct form of the interaction. Even the title of the study must be changed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound validation of Alpgen LO predictions against measured data.",
        "Location": "Section 3, Tables 7 and 8, Figure 3.",
        "Explanation": "The paper compares Alpgen's Leading Order (LO) cross-section predictions directly with measured experimental results (which include higher-order corrections) and claims good agreement. LO predictions are not expected to match measured values, especially for multi-jet final states where Next-to-Leading Order (NLO) and Next-to-Next-to-Leading Order (NNLO) corrections are significant. The large discrepancies shown (e.g., 50-70% for W+jets) demonstrate this, making the validation unsound."
      },
      {
        "Problem": "Unreliable absolute cross-section predictions for W/Z + jets at 14 TeV.",
        "Location": "Section 3, Tables 9 and 10, Figure 4.",
        "Explanation": "The primary predictions for W/Z + jets cross sections at 14 TeV are based on Alpgen, which is a Leading Order (LO) matrix element generator. As demonstrated by the flawed validation (Problem 1), LO predictions do not reliably predict the absolute cross section compared to measured data or higher-order calculations. Presenting these LO results as the main predictions for 14 TeV without proper higher-order corrections or normalization makes them unreliable for quantitative use."
      },
      {
        "Problem": "Missing theoretical uncertainty estimation for Alpgen predictions.",
        "Location": "Section 3, Tables 9 and 10.",
        "Explanation": "The Alpgen predictions for W/Z + jets cross sections at 14 TeV only include statistical uncertainties. Leading Order (LO) predictions are highly sensitive to theoretical uncertainties arising from the choice of renormalization and factorization scales and Parton Distribution Functions (PDFs). Without quantifying and including these theoretical uncertainties, the reliability and precision of the 14 TeV predictions cannot be properly assessed."
      },
      {
        "Problem": "Inconsistent and unclear presentation of MCFM results in validation table.",
        "Location": "Section 3, Table 6.",
        "Explanation": "Table 6 compares Alpgen, MCFM, and ATLAS results. The table caption states that MCFM provides NLO predictions. However, the values listed for W+0 jet and Z+0 jet match the NNLO values presented in Tables 3 and 4. This inconsistency makes it unclear what order of calculation MCFM is providing for each jet multiplicity in this table, hindering the interpretation of the comparison."
      },
      {
        "Problem": "Overstated agreement between predicted and measured results.",
        "Location": "Section 2, Section 3, Tables 1, 3, 6, 7, 8.",
        "Explanation": "The paper repeatedly claims that predicted results (from MCFM and Alpgen) agree well with experimental data, even when the numerical differences are substantial and clearly outside the stated statistical uncertainties (e.g., W+2 jets in Table 6, W+jets in Table 8). This overstatement of agreement weakens the credibility of the validation steps presented."
      }
    ],
    "token_usage": {
      "input": 13858,
      "thinking": 5606,
      "output": 693
    }
  },
  {
    "entry_id": 161,
    "retraction_id": "1604.05964v2",
    "paper_id": "1604.05964v1",
    "retraction_comment": "equation no. 16 17 and 18 have flaws, result of which final outage derivation is not converging",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Identical Outage Probability Formulas for Primary and Secondary Users",
        "Location": "Equations (18) and (23), Section III",
        "Explanation": "The derived rate CDF formulas for primary (Eq 18) and secondary (Eq 23) users are identical in structure, only differing by the rate threshold variable and a parameter 'd'. However, the system models, interference sources, and CoMP strategies are fundamentally different for primary (cluster-based CoMP, secondary interference) and secondary (cell-based CoMP, primary interference) users. This identical result strongly suggests a fundamental error in the mathematical derivation, as the performance metrics should reflect these distinct scenarios and parameters (e.g., $\\lambda_P$ vs $\\lambda_S$). The second integral term, representing interference, is identical in both formulas despite the interferers being from different point processes ($\\\\Phi_S$ for primary, $\\\\Phi_P$ for secondary)."
      },
      {
        "Problem": "Unsound Assumption of Single Primary Interferer for Secondary Users",
        "Location": "Equation (19) and subsequent derivation for secondary outage, Section III-B",
        "Explanation": "The analysis for secondary users assumes interference from primary BSs ($I_{one,P_i}$) comes from only 'one primary BS located within a cluster'. In a PPP model, if a secondary user is allocated an RB used by primary users (due to mis-detection), it would receive interference from all primary BSs using that RB, distributed according to $\\\\Phi_P$. Modeling this as interference from a single BS is inconsistent with the underlying spatial model and invalidates the interference analysis for secondary users."
      },
      {
        "Problem": "Questionable Derivation of Interference Laplace Transforms and Integrals",
        "Location": "Equations (11) through (17), Section III-A (and implicitly applied in III-B)",
        "Explanation": "The steps leading to the final integral expressions for outage probability (Eq 17 and 18) are highly condensed and difficult to verify. Specifically, the derivation of the Laplace transform for interference from the 'one' interfering BS (Eq 13) and its subsequent integration (second integral in Eq 16, 17) does not appear to follow standard procedures for averaging over distance distributions in PPP and seems incorrect. This undermines the validity of the derived performance metrics."
      },
      {
        "Problem": "Ambiguity and Potential Inconsistency in ZF-DPC Modeling",
        "Location": "Description of $I_{red,P}$ and $I_{Red,S}$, Equations (6), (12), (19), Section III",
        "Explanation": "While the concept of ZF-DPC cancelling interference within a region where CSI is available is mentioned, the precise modeling of the residual interference ($I_{red,P}$ and $I_{Red,S}$) and its Laplace transform (Eq 12) needs clearer justification. The formula (12) seems to represent interference from BSs outside the cancellation region, which is plausible, but the derivation is not shown. The application of ZF-DPC in a PPP context, especially with limited CSI up to the M-th nearest BS, requires careful justification of the resulting interference distribution, which is lacking in the provided steps."
      }
    ],
    "token_usage": {
      "input": 8675,
      "thinking": 4356,
      "output": 724
    }
  },
  {
    "entry_id": 162,
    "retraction_id": "1010.6286v5",
    "paper_id": "1010.6286v4",
    "retraction_comment": "This paper has been withdrawn by the author due to the map described in Thorem 2.4 is not injective",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed definition and properties of the 'couple product'.",
        "Location": "Definition 3.2, Proposition 3.3",
        "Explanation": "The definition of the couple product is non-standard and its properties, particularly Proposition 3.3(4) claiming the coupled subgroup between G and F_k is isomorphic to F_k, are incorrect. The generators of the coupled subgroup inherit relations from the direct product G x F_k. For instance, if G is abelian, the coupled subgroup generated by products of generators will also be abelian, not free. This invalidates subsequent constructions relying on these properties."
      },
      {
        "Problem": "The embedding construction in Theorem 3.4 fails.",
        "Location": "Proof of Theorem 3.4",
        "Explanation": "The construction attempts to map generators u, v of RAAG(Gamma) corresponding to an edge {u, v} in Gamma (meaning u, v should not commute in RAAG(Gamma)) to elements Psi'(u) and Psi'(v) in canonical RAAG(B_n). However, the constructed elements Psi'(u) = Psi(u) psi_{k+2} and Psi'(v) = Psi(v) psi_{k+3} commute in canonical RAAG(B_n) because Psi(u), Psi(v), psi_{k+2}, and psi_{k+3} pairwise commute (as shown by index differences in the B_n generators). This failure to create non-commuting elements invalidates the main embedding theorem."
      },
      {
        "Problem": "Unsound proof for the structure of 2-element subgroups of RAAGs.",
        "Location": "Corollary 4.2",
        "Explanation": "The proof relies directly on the embedding claimed in Corollary 3.5, which is derived from the flawed Theorem 3.4. While the statement that any 2-element subgroup of a RAAG is isomorphic to Z^2, Z, or F_2 is a known result, the proof provided in this paper is not valid as it depends on a non-existent embedding."
      },
      {
        "Problem": "Unsound proof and likely incorrect statement regarding homomorphisms from odd-connected Artin groups.",
        "Location": "Corollary 4.3",
        "Explanation": "The proof relies on the unsound Corollary 4.2. Furthermore, the argument using the exponent sum homomorphism is only applicable if the target RAAG is abelian. The conclusion that any homomorphism from an odd-connected Artin group to an arbitrary RAAG maps all generators to the same element appears incorrect for non-abelian target RAAGs."
      },
      {
        "Problem": "Unsound proof and incorrect statement regarding subgroups generated by linearly independent words.",
        "Location": "Corollary 4.6",
        "Explanation": "The proof relies on a misinterpretation or misapplication of Corollary 4.2. The claim that a set of linearly independent words {w_i} in a RAAG generates a RAAG where the only relations are commutators [w_i, w_j] is false. Linearly independent words can have non-commutator relations among them (e.g., in F_2, the subgroup generated by x, y, and xy is F_2, and x and xy do not commute, but [x, xy] is not trivial). The proof's argument involving projections is also flawed."
      }
    ],
    "token_usage": {
      "input": 10081,
      "thinking": 7326,
      "output": 754
    }
  },
  {
    "entry_id": 163,
    "retraction_id": "0811.2430v4",
    "paper_id": "0811.2430v3",
    "retraction_comment": "The author revised the article and considers that the proof is not rigorous. The main counter-argument is that one should not draw conclusions from a truncated wave-function",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The total state of the two particles is incorrectly formulated as a difference of two components.",
        "Location": "Eq (1), Page 2",
        "Explanation": "The state |ψ> is given as 2⁻¹/² (|ψ₂> − |ψ₁,₁>), where |ψ₂> describes particles detected in the same region and |ψ₁,₁> describes particles detected in different regions. Based on the definitions in (2) and (3) and the experimental setup, the total state resulting from the beam splitters should be a superposition (sum) of these components, not a difference. This fundamental error propagates through the subsequent calculations."
      },
      {
        "Problem": "The symmetry analysis of the state component |ψ₂> is incorrect.",
        "Location": "Eq (5) and surrounding text, Page 2",
        "Explanation": "The author claims that the second line of Eq (5) is antisymmetric under the interchange of particles (interpreted as swapping the L and R source labels). However, performing the L↔R label swap on the terms in the second line shows that it does not result in the negative of the original expression. This indicates a misunderstanding of how particle exchange symmetry applies in this notation."
      },
      {
        "Problem": "The derivation and normalization of the symmetric and antisymmetric components of |ψ₁,₁> are flawed.",
        "Location": "Eq (8) and (9), Page 3",
        "Explanation": "Equations (8) and (9) are presented as the symmetric and antisymmetric parts of |ψ₁,₁> (Eq 6). However, attempting to derive (8) and (9) by applying standard symmetrization/antisymmetrization procedures to (6) reveals errors in both the normalization factor (stated as 1/4 instead of 1/4√2) and the coefficients of several terms. This makes the subsequent probability calculations unreliable, even if the final results (10) and (11) happen to match a specific interpretation."
      },
      {
        "Problem": "The interpretation of the state component |ψ₁,₁> as representing particles that 'never meet' is problematic and leads to a questionable conclusion about non-local symmetry.",
        "Location": "Section 3 (Discussion), Page 4",
        "Explanation": "The paper argues that the symmetry of |ψ₁,₁> is particularly interesting because it describes particles detected in different regions (V and E) that 'never meet'. However, |ψ₁,₁> is merely a component of the total state arising from interference at the final beam splitters (BSᵥ and BS_E), which are locations where particles from different initial paths (A/A' and B/B') converge and could interact/interfere. The symmetry postulate applies to the total state of identical particles, not selectively to components defined by measurement outcomes or specific path combinations after interaction points."
      },
      {
        "Problem": "The conclusion that symmetry (antisymmetry) is produced 'at-a-distance' is based on flawed premises.",
        "Location": "Section 3 (Discussion), Page 4",
        "Explanation": "The main conclusion relies on the idea that the symmetry of |ψ₁,₁> demonstrates a non-local effect because these particles 'never meet'. As discussed in Problem 4, the 'never meet' argument is weak in the context of interference at beam splitters. Furthermore, the symmetry is a property of the overall state of identical particles, not something that is 'produced' for a specific subset of outcomes (|ψ₁,₁>) independently of others (|ψ₂>). The conclusion is built upon the incorrect state formulation and interpretation."
      }
    ],
    "token_usage": {
      "input": 1156,
      "thinking": 20179,
      "output": 797
    }
  },
  {
    "entry_id": 164,
    "retraction_id": "2201.05255v2",
    "paper_id": "2201.05255v1",
    "retraction_comment": "Our definition of the higher Toda brackets is not effective, i.e. not well defined, in the category of pointed spaces",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Domain Mismatch in Bracket Definition for n>=3",
        "Location": "Section 1, Definition of {f_vec}_m_vec, {f_vec}'_m_vec, {f_vec}''_m_vec for n >= 3",
        "Explanation": "For n >= 3, the recursive definition of the brackets results in a set of maps whose domain is derived from the structure of the recursive definition (e.g., Sigma^{n-2}Sigma^{m_n}...Sigma^{m_4}SigmaSigma^{m_[3,2]}X_1 for n >= 4). This derived domain is different from the expected domain Sigma^{n-2}Sigma^{m_[n,1]}X_1 (the domain of the classical n-fold bracket with suspensions m_vec) unless m_1 = 0. This fundamental mismatch means the defined brackets do not produce elements in the claimed target space [Sigma^{n-2}Sigma^{m_[n,1]}X_1, X_{n+1}]."
      },
      {
        "Problem": "Inconsistent Definition and Use of Homeomorphism h_m_vec",
        "Location": "Section 1, Definition of h_m_vec and subsequent theorems (e.g., Theorem 1.2, Theorem 1.4)",
        "Explanation": "The homeomorphism h_m_vec is defined for n >= 4 to map (s^{m_[3,1]}wedge s^1)wedge...wedge(s^{m_n}wedge s^1) to s^{m_[n,1]}wedge s^{n-2}. This corresponds to a map from SigmaSigma^{m_[3,1]}SigmaSigma^{m_4}...SigmaSigma^{m_n}S^0. This space does not match the derived domain of the bracket Sigma^{n-2}Sigma^{m_n}...Sigma^{m_4}SigmaSigma^{m_[3,2]}X_1. The definition of h_m_vec is inconsistent with the space the bracket maps from, making its use in relating the defined bracket to the expected target space or other constructions problematic."
      },
      {
        "Problem": "Flawed Statements in Theorems due to Domain Mismatch",
        "Location": "Theorem 1.2, Proposition 3.2 (1.5), Theorem 1.3, Theorem 1.4, (1.7), (1.8), (1.9)",
        "Explanation": "Many theorems and propositions state equalities or inclusions between sets of maps. However, the domains of the maps on the left and right sides of these relations do not match due to the fundamental domain mismatch in the bracket definition (Problem 1) and the inconsistent definition of h_m_vec (Problem 2). For instance, Theorem 1.2 compares maps from the derived domain with maps from a space related to the expected domain via h_m_vec. The claim that the inclusion is identity when m_vec=(0,...,0) is false because the derived and expected domains differ for n >= 3 even in this case."
      },
      {
        "Problem": "Definitions of {f_vec}'_m_vec and {f_vec}''_m_vec might be too broad",
        "Location": "Section 1, Definitions of {f_vec}'_m_vec and {f_vec}''_m_vec for n >= 4",
        "Explanation": "The definition of {f_vec}'_m_vec takes a union over sequences of not necessarily admissible null homotopies. The definition of {f_vec}''_m_vec takes a union only over the first two null homotopies (A_2, A_1) and ignores admissibility conditions for subsequent null homotopies in the original sequence. These definitions deviate significantly from the standard construction of higher Toda brackets which relies on admissible sequences of null homotopies. While the paper claims they are equal to {f_vec}_m_vec in TOP^w, this might not hold in TOP^* and could lead to these sets being much larger or having different properties than intended."
      }
    ],
    "token_usage": {
      "input": 58438,
      "thinking": 20024,
      "output": 905
    }
  },
  {
    "entry_id": 165,
    "retraction_id": "1601.01217v3",
    "paper_id": "1601.01217v2",
    "retraction_comment": "There is an important mistake in the definition of the global smoothing operator preserving the presymplectic form",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch in required smoothness levels for SCI-action estimates in the abstract normal form theorem application.",
        "Location": "Appendix, Theorem A.1, conditions (A.5) and (A.6); Section 5.2, Lemmas 5.3 and 5.4; Section 4, Proof outlines.",
        "Explanation": "The proof of the main rigidity theorems relies on applying an abstract normal form theorem (Theorem A.1). This theorem requires the SCI-action (push-forward of actions by diffeomorphisms) to satisfy certain tame estimates (A.5 and A.6) involving norms up to level $k+s$, where $s$ is the loss of derivatives from the map H (condition A.4). The map H is constructed using the homotopy operator $h_0$ (Lemma 5.1), which introduces a loss of $s$ derivatives. Lemma 5.4, which provides the crucial quadratic convergence estimate (A.7), indicates a total loss of $s+1$ derivatives (where $s$ is from Lemma 5.1). This implies the abstract theorem's conditions (A.5) and (A.6) should hold with norms up to $k+s+1$. However, the technical lemma for the push-forward action (Lemma 5.3) provides estimates involving norms up to $k+1$ or $k+2$. This discrepancy between the required smoothness levels in the abstract theorem's conditions and the provided estimates for the specific SCI-action means the conditions for applying Theorem A.1 might not be strictly met, potentially invalidating the conclusion that the iterative process converges and thus the rigidity theorems."
      }
    ],
    "token_usage": {
      "input": 48793,
      "thinking": 14227,
      "output": 364
    }
  },
  {
    "entry_id": 166,
    "retraction_id": "1412.3838v2",
    "paper_id": "1412.3838v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in the statement according to which the volume element does not depend on the choice of the time orientation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proposed volume element depends on the choice of time orientation.",
        "Location": "Section 4, Definition of $\\mathbf{\\sigma}(x)$ and Remark 1",
        "Explanation": "The integration domain $\\mathbb{B}_n(x)$ is defined as the unit ball of the positive definite metric $g^{t,+}(x)$. The metric $g^{t,+}(x)$ is constructed using the chosen time orientation vector field $t(x)$. Therefore, the integration domain $\\{y \\in T_xM \\mid g^{t,+}_{ij}(x) y^i y^j \\leq 1\\}$ depends explicitly on $t(x)$, making the resulting volume element $\\mathbf{\\sigma}(x)$ dependent on the choice of time orientation, contrary to the claim in Remark 1 after the definition."
      },
      {
        "Problem": "The proposed volume element does not reduce to the standard Riemannian volume element in the Riemannian case.",
        "Location": "Section 3, Particular case; Section 4, Particular cases, 1)",
        "Explanation": "When the metric is Riemannian, $g_{ij}(x,y) = g_{ij}(x)$, the calculation in the paper leads to $\\mathbf{\\sigma}(x) = 1$, giving the volume element $\\mathbf{\\omega} = dx$. The standard Riemannian volume element is $\\sqrt{|g(x)|} dx$. The proposed definition fails to recover the correct, well-established volume element for Riemannian spacetimes, indicating a fundamental issue with the definition or its derivation."
      },
      {
        "Problem": "The integration domain $\\mathbb{B}_n(x)$ is ambiguously or incorrectly described.",
        "Location": "Section 3, Claim 2 and Definition 1; Section 4, Claim 2 and Definition",
        "Explanation": "The paper claims that the unit ball of the auxiliary metric ($g^t$ in Section 3, $g^{t,+}$ in Section 4) is the Euclidean unit ball $\\mathbb{B}_n$. This is generally false. The unit ball of a positive definite metric $h_{ij}(x)$ is $\\{y \\in T_xM \\mid h_{ij}(x) y^i y^j \\leq 1\\}$, which is a Euclidean ball relative to a basis where $h_{ij}$ is diagonalized, but it is not necessarily the unit ball of the standard Euclidean metric $\\delta_{ij}$. The normalization factor $1/vol(\\mathbb{B}_n)$ (volume of the standard Euclidean unit ball) is applied to an integral over a domain that is not necessarily the standard Euclidean unit ball, contributing to the incorrect Riemannian limit and the dependence on the auxiliary metric/time orientation."
      }
    ],
    "token_usage": {
      "input": 12500,
      "thinking": 6122,
      "output": 610
    }
  },
  {
    "entry_id": 167,
    "retraction_id": "1301.0396v3",
    "paper_id": "1301.0396v2",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in Lemma 2.9",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Potential collapse of $\\aleph_2$ in the countable support iteration.",
        "Location": "Section 4, Iterated forcing setup",
        "Explanation": "The paper uses a countable support iteration of Matet-like forcings of length $\\omega_2$. Matet forcing adds an unbounded real and likely adds new $\\omega_1$-sequences of ordinals. A countable support iteration of such forcings may collapse $\\aleph_2$. The paper assumes $\\aleph_2$ is preserved, which is crucial for the cardinal arithmetic and the overall structure of the model, but this preservation is not justified by a lemma or argument in the text."
      },
      {
        "Problem": "Unjustified Blass-Laflamme task in the good sequence construction.",
        "Location": "Section 4, Definition 4.4 (3) and proof of Lemma 4.2 case (d)",
        "Explanation": "The construction of the good sequence for $\\cU_\beta$ requires fulfilling a task (Def 4.4 (3)) that involves finding a condition in $\\M(\\cU_\beta)$ forcing a property about the generic real $s_\beta$ and a filter $\\cF \\in \bV_\beta$. Specifically, $\bc^3_\\eps \\Vdash \\{n \\such |s_\beta \\cap n| \\in E_\\eps\\} \\in \\cF$. This task is essential for ensuring property (I3), which is used to prove the Filter Dichotomy holds in the final model. The paper does not provide a lemma or detailed argument showing that such a condition always exists or can be constructed within the inductive definition of the good sequence."
      },
      {
        "Problem": "Flawed argument for $\\gro \\leq \\kappa$ in the finite support iteration.",
        "Location": "Section 5, Theorem 5.6 and the definition of $\\cG_\\eps$",
        "Explanation": "The proof of Theorem 5.6 claims $\\gro \\leq \\kappa$ by constructing $\\kappa$ groupwise dense sets $\\cG_\\eps$ with empty intersection. The definition of $\\cG_\\eps$ appears non-standard and unclear (using a filter $\\Phi(\\cC_0)$ in the condition for membership), and the claim that their intersection is empty is not justified. This affects the claimed cardinal characteristic values in the finite support model."
      },
      {
        "Problem": "Flawed argument for property (I4) from property (I5).",
        "Location": "Section 4, Proof of Lemma 4.2 case (c)",
        "Explanation": "The proof claims that property (I4) ($s_\beta \not\\subseteq^* R(s_\\gamma)$) follows from property (I5) ($\\cU_\\gamma$ is countably block-splitting). The logical deduction presented in the text (using $s_\beta \not\\subseteq^* R(\\set(\bc))$ and $R(s_\\gamma) \\subseteq^* R(\\set(\bc))$) is incorrect. While property (I4) interpreted as the enumeration of $s_\beta$ being unbounded over $\bV_\beta$ is likely true and sufficient for Lemma 4.1, the stated argument for the stronger form of (I4) from (I5) is flawed."
      }
    ],
    "token_usage": {
      "input": 26812,
      "thinking": 17438,
      "output": 714
    }
  },
  {
    "entry_id": 168,
    "retraction_id": "1808.04792v3",
    "paper_id": "1808.04792v2",
    "retraction_comment": "The velocities in the radiative transfer analysis for each snapshot of the simulated collapsing core are a factor of 1.732 (the square root of 3) smaller along each of the three dimensions. This error is currently being rectified",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of Turbulence and Sphericity in the Simulation",
        "Location": "Section 2.1, Section 5.2.1",
        "Explanation": "The numerical simulation is spherically symmetric and non-turbulent, starting from a smooth initial perturbation. Real star-forming cores form in highly turbulent, non-spherical environments within molecular clouds. The specific 'outside-in' velocity profile found in this idealized simulation might be an artifact of these simplified initial conditions and symmetry, and may not be representative of the velocity structure in a turbulent collapse, potentially undermining the general applicability of the conclusions to observed turbulent cores."
      },
      {
        "Problem": "Assumption of Constant Molecular Abundances",
        "Location": "Section 2.3",
        "Explanation": "The simulation assumes constant molecular abundances for HCO+ and N2H+. In dense, cold prestellar cores, molecules like HCO+ are known to deplete onto dust grains, particularly in the high-density central regions. This depletion would significantly alter the optical depth distribution and line formation process, affecting the shape of the self-absorbed profile and the velocity inferred by standard methods. Assuming constant abundance likely overestimates the central optical depth for HCO+, which is critical for the self-absorption feature and the density weighting argument."
      },
      {
        "Problem": "Isothermal Assumption",
        "Location": "Section 2.1, Section 2.3",
        "Explanation": "The simulation assumes a constant kinetic temperature (isothermal). Real dense cores often exhibit temperature gradients, typically being colder in the center due to dust shielding. Temperature gradients affect the excitation temperature profile, which is a crucial factor in radiative transfer and line formation. This simplification could impact the accuracy of the synthetic spectra and the derived infall velocities, potentially affecting the comparison with observations."
      },
      {
        "Problem": "Potential Mismatch between Hill5 Model Assumptions and Simulation Physics",
        "Location": "Section 3.2, Section 5.1",
        "Explanation": "The Hill5 model used to infer infall velocities relies on specific, simplified assumptions about the excitation temperature and velocity dispersion profiles within the core (e.g., linear T_ex with optical depth, single velocity dispersion). The paper does not demonstrate that these assumptions are a good approximation for the actual, self-consistently developed profiles in their simulation. If the simulation's profiles deviate significantly from the model's assumptions, the derived v_in^Hill5 values may not reliably represent the velocity structure as seen by the Hill5 method, weakening the quantitative claim of underestimation."
      },
      {
        "Problem": "Generalizability of the Specific Outside-In Velocity Profile",
        "Location": "Section 5.2.1, Section 5.2.3",
        "Explanation": "The paper's central argument that observed subsonic speeds are a misinterpretation hinges on the specific 'outside-in' velocity profile (linear near center, uniform in envelope) being the characteristic outcome of collapse relevant to observed cores. While this profile is a valid solution for certain idealized initial conditions (like the one simulated), it is not definitively established as the generic velocity structure in more realistic turbulent collapse simulations, which are arguably more representative of star formation in molecular clouds. The conclusion might not hold if turbulent collapse produces different velocity fields."
      }
    ],
    "token_usage": {
      "input": 37082,
      "thinking": 6366,
      "output": 717
    }
  },
  {
    "entry_id": 169,
    "retraction_id": "1306.2988v2",
    "paper_id": "1306.2988v1",
    "retraction_comment": "This paper has been withdrawn by the authors. The result claiming a factor 0.56 algorithm is invalid because of a crucial bug in Claim 2 which was brought to our attention by [REDACTED-NAME], [REDACTED-NAME], and [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed counting argument in Lemma 7",
        "Location": "Proof of Lemma 7, Case 2",
        "Explanation": "The proof attempts to relate the number of non-monotone events to Type 1 good events by arguing that a single Type 1 good event $Good_1(s, \\hat{\\rho})$ can be generated by up to $n$ different non-monotone events $\\Gamma(t,n,\\rho)$. However, the permutation $\\rho$ is constructed from $\\hat{\\rho}$ by moving a specific vertex $u=\\hat{\\rho}(t)$ from position $t$ to $n$. The position of $w^*=\\hat{\\rho}(s)$ in $\\rho$ is not arbitrary but is determined by its position $s$ in $\\hat{\rho}$ and the positions $t$ and $n$. The counting argument that leads to the factor $n/t$ in the inequality appears incorrect, potentially invalidating this key lemma used in the LP formulation."
      },
      {
        "Problem": "Flawed proof of LP monotonicity (Lemma 8)",
        "Location": "Proof of Lemma 8, specifically Claim 6 and the overall structure",
        "Explanation": "The proof aims to show that the optimal value of LP(k) lower bounds the optimal value of LP(n) for $k|n$ by averaging variables of an optimal solution for LP(n) over blocks. The calculation in Claim 6, starting with $\\frac{k}{q}\\sum_{t:\\lfloor t/q \\rfloor = i} (1-x^n_t)$, does not correctly represent $k(1-\\hat{x}^k_i)$, where $\\hat{x}^k_i$ is the average of $x^n_t$ over the block. The standard technique for proving such LP monotonicity involves summing the constraints of LP(n) over blocks and using inequalities, which is not correctly applied here. The proof does not rigorously establish the feasibility of the constructed solution $\\hat{s}^k$ for LP(k), invalidating the claim that LP(k) lower bounds LP(n) and thus the 0.56 factor derived from solving LP(400)."
      },
      {
        "Problem": "Unsound simulation argument for Vertex-Iterative upper bound",
        "Location": "Proof of Theorem 10, Lemma 11",
        "Explanation": "The proof of the 0.75 upper bound for vertex-iterative algorithms relies on simulating an arbitrary deterministic vertex-iterative algorithm ${\\mathcal O}$ with a hypothetical 'revealing algorithm' ${\\mathcal A}$ on a specific graph distribution. The simulation rule described, particularly the action taken when ${\\mathcal O}$ queries an edge incident to a vertex already marked inactive by ${\\mathcal A}$ ('the current vertex in our simulation immediately gives up'), is an arbitrary rule that is not proven to ensure that ${\\mathcal A}$'s matching size is always at least that of ${\\mathcal O}$. The definition of the revealing algorithm and the simulation logic appear insufficient to support the claim made in Lemma 11, which is crucial for the subsequent upper bound derivation."
      }
    ],
    "token_usage": {
      "input": 24720,
      "thinking": 10341,
      "output": 707
    }
  },
  {
    "entry_id": 170,
    "retraction_id": "1901.07086v3",
    "paper_id": "1901.07086v2",
    "retraction_comment": "The claim of Main Theorem 1 is wrong. The prime counting function on the complex plan does not satisfy the inequality. The prime number Theorem contradicts the claim",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified link between primes on the real line and Gaussian primes on a specific line segment.",
        "Location": "Section 3, Proof of Main Theorem, Case (I)",
        "Explanation": "The proof assumes that finding primes in the interval $[z_1^2+z_2^2, (kz_1)^2+(kz_2)^2]$ on the real line implies the existence of Gaussian primes on the specific line segment connecting $(z_1, z_2)$ and $(kz_1, kz_2)$. The set of squared moduli of lattice points on this segment is a sparse set of integers, and there is no mathematical basis provided to conclude that any of these values will coincide with the primes found in the continuous interval on the real line."
      },
      {
        "Problem": "Incorrect application of the Generalization of Bertrand's Postulate (Proposition 2).",
        "Location": "Section 3, Proof of Main Theorem, Case (I)",
        "Explanation": "Proposition 2 guarantees $(k-1)$ primes in the interval $[n, kn]$ for $n \\ge f(k)$. The proof attempts to apply this to the interval $[z_1^2+z_2^2, (kz_1)^2+(kz_2)^2]$ (or possibly $[z_1^2+z_2^2, k^2(z_1^2+z_2^2)]$). However, the starting point $z_1^2+z_2^2$ is not guaranteed to be $\\ge f(k)$ based on the condition $\\gcd(z_1, z_2) = f(k)$. Furthermore, the interval is not necessarily of the form $[N, kN]$ for some integer $N$ where Proposition 2 applies directly."
      },
      {
        "Problem": "Misinterpretation and misapplication of Chebyshev's Bias.",
        "Location": "Section 3, Proof of Main Theorem, Case (I) and Case (II)",
        "Explanation": "Chebyshev's Bias describes an asymptotic distribution and a tendency for primes of certain forms (e.g., $3 \\pmod 4$) to predominate up to a certain point. It does not provide a rigorous lower bound on the number of primes of a specific form in a finite interval, let alone guarantee a minimum count like $\frac{k-1}{2}$. Using it to derive a guaranteed minimum number of Gaussian primes is unsound."
      },
      {
        "Problem": "Undefined notation and ambiguous theorem statement.",
        "Location": "Section 3, Main Theorem statement",
        "Explanation": "The notation $\\pi((x,y))$ is not defined. The statement $\\pi\\left((kz_1,kz_2)\right) - \\pi\\left((z_1,z_2)\right) \\geq \frac{k-1}{2}$ is unclear. While $\\pi(R)$ for Gaussian primes typically counts $a+bi$ with $a^2+b^2 \\le R^2$, the proof attempts to count Gaussian primes *on a line segment*, which is a different problem. The theorem statement does not precisely reflect what the proof attempts to demonstrate."
      }
    ],
    "token_usage": {
      "input": 7975,
      "thinking": 5968,
      "output": 708
    }
  },
  {
    "entry_id": 171,
    "retraction_id": "2204.01118v2",
    "paper_id": "2204.01118v1",
    "retraction_comment": "In the proof of Theorem 5, page 10, line 1O, a term was missing in the r.h.s, that is \\|f''\\|_p^p",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed proof sketch for sufficiency condition in Theorem 7",
        "Location": "Section 7, Proof of Theorem 7",
        "Explanation": "The proof sketch for Theorem 7, which provides a sufficient condition for a function f to act on W^m_p(R) when m >= max(2, n/p) or m=2, p=1, attempts to show that the term (f''\\circ g) (partial_j g)(partial_k g) belongs to L_p(R). However, the calculation presented bounds a different quantity, U_j = integral |f''\\circ g|^p |partial_j g|^(2p) dx, which is not the L_p norm of the required term. The subsequent steps involving integration by parts and inequalities applied to U_j do not demonstrate that (f''\\circ g) (partial_j g)(partial_k g) is in L_p(R), leaving the sufficiency proof incomplete or incorrect as presented."
      },
      {
        "Problem": "Incomplete proof sketch for necessity condition in Theorem 9",
        "Location": "Section 11.3, End of the proof of Theorem 9",
        "Explanation": "The proof sketch for the necessity part of Theorem 9 (characterizing acting functions for W^m_p(R) when m=n/p >= 2, p>1) aims to show that f' belongs locally uniformly to W^(m-1)_p(re). The argument uses a specific test function g_b and derives a bound on the L_p norm of partial_1^m(f \\circ g_b) on a cube. This bound implies that f^(m) is in L_p on certain intervals. However, the proof sketch does not demonstrate that f^(k) is in L_p locally uniformly for all 1 <= k <= m, which is necessary for f' to be locally uniformly in W^(m-1)_p(re). The argument is incomplete."
      }
    ],
    "token_usage": {
      "input": 18371,
      "thinking": 15352,
      "output": 452
    }
  },
  {
    "entry_id": 172,
    "retraction_id": "2001.10956v2",
    "paper_id": "2001.10956v1",
    "retraction_comment": "The second equation (2.22) is incorrect. The follow-up of the correct equation demands new developments, which I shall provide in a new version soon. wh",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of operator powers and relation to scaling in Proposition 5.1",
        "Location": "Proposition 5.1, Proof",
        "Explanation": "The expansion of $(T_p^{\\mathrm{dist}})^{2N} = (p^{-\\hf+i\\pi\\E^{\\natural}}+p^{\\hf-i\\pi\\E^{\\natural}})^{2N}$ is incorrectly stated as $\\sum_k \\begin{pmatrix} 2N \\\\ k\\end{pmatrix} p^{(N-k)\b(2i\\pi\\E^{\\natural}-1\\b)}{\\mathfrak B}^1$. The correct expansion is $\\sum_k \\begin{pmatrix} 2N \\\\ k\\end{pmatrix} p^{-N+k} p^{i\\pi(2N-2k)\\E^{\\natural}}{\\mathfrak B}^1$. Furthermore, the operator $p^{i\\pi a \\E^{\\natural}}$ corresponds to a complex scaling $h(p^{-i\\pi a}x, p^{i\\pi a}\\xi)$, not the real scaling $h(qx, q^{-1}\\xi)$ used in Proposition 3.1. This invalidates the use of Proposition 3.1 to bound the terms in the sum."
      },
      {
        "Problem": "Incorrect eigenvalue factor for Eisenstein distributions in Proposition 5.2",
        "Location": "Proposition 5.2, Proof",
        "Explanation": "The action of $(T_p^{\\mathrm{dist}})^{2N}$ on ${\\mathfrak E}_{\\nu}$ is given by $(p^{-\\nu/2} + p^{\\nu/2})^{2N}{\\mathfrak E}_{\\nu}$. The proof incorrectly expands this as $\\sum_k \\begin{pmatrix} 2N \\\\ k\\end{pmatrix} p^{(N-k)\\nu}{\\mathfrak E}_{\\nu}$. The correct expansion is $\\sum_k \\begin{pmatrix} 2N \\\\ k\\end{pmatrix} p^{\\nu(k-N)/2}{\\mathfrak E}_{\\nu}$. This error affects the factor inserted into the integral and potentially the resulting bound."
      },
      {
        "Problem": "Incorrect integral representation of the localized operator in Proposition 5.3",
        "Location": "Proposition 5.3, Proof",
        "Explanation": "The operator $\\Phi_N(-2i\\pi\\E)$ is related to an integral involving scaled versions of the test function $h$. The formula used, $\\intR \\Psi_N(t)\\,h\\l(e^{2\\pi t}x,e^{2\\pi t}\\xi\\r) e^{2\\pi t}dt$, corresponds to the action of $\\intR \\Psi_N(t) e^{2\\pi t \\E} dt$. The correct representation for $\\Phi_N(-2i\\pi\\E)h$ should involve the operator $e^{-2\\pi t \\E}$, leading to scaling by $e^{-2\\pi t}$ and multiplication by $e^{-2\\pi t}$. This error affects the bound derived for the localized distribution."
      },
      {
        "Problem": "Flawed proof of the key estimate in Proposition 3.1",
        "Location": "Proposition 3.1, Proof",
        "Explanation": "The proof attempts to use integration by parts on the integral $I_{n,m}(h^q)$ to relate it to operators like $\\xi + \\frac{1}{2i\\pi}\\frac{\\partial}{\\partial x}$. This approach seems inconsistent with how the operator $\\E$ acts on the distribution ${\\mathfrak B}$ via duality. The derivation of equation (3.22) appears mathematically unsound in this context, undermining the crucial bound (3.27) which is fundamental for later estimates."
      },
      {
        "Problem": "Final theorem relies on flawed intermediate results",
        "Location": "Theorem, Proof",
        "Explanation": "The proof of the main theorem relies on comparing bounds obtained in Propositions 5.1, 5.2, and 5.3. As detailed above, each of these propositions contains critical errors related to operator calculations, their action on distributions, or the application of previous results. Consequently, the comparison of bounds and the contradiction argument used to prove the Ramanujan-Petersson conjecture are invalid."
      }
    ],
    "token_usage": {
      "input": 21310,
      "thinking": 7983,
      "output": 981
    }
  },
  {
    "entry_id": 173,
    "retraction_id": "1407.6492v2",
    "paper_id": "1407.6492v1",
    "retraction_comment": "This paper has been withdrawn by the main author due to the Table 1 and equation 2 errors",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Testing on training data reported as a valid result",
        "Location": "Page 4, Section 3",
        "Explanation": "The paper reports achieving 100% accuracy when training and testing on the same 20,000 data samples. This is a fundamental error in evaluating a machine learning model's generalization ability, as it measures memorization rather than performance on unseen data. This specific result (100%) is therefore invalid as a measure of the method's effectiveness."
      },
      {
        "Problem": "Unclear and potentially incorrect feature definitions",
        "Location": "Page 2, Section 2.1 (Angle Features) and Section 2.2 (Distance Feature)",
        "Explanation": "The mathematical formulas (Equations 1 and 2) for Angle and Distance features appear inconsistent (summing over 'nb' pixels but dividing by 'n' white pixels) and descriptions are vague (e.g., 'agent point', 'ratio as feature' for Transit). This lack of clarity and potential mathematical error makes the feature extraction process difficult or impossible to reproduce and verify."
      },
      {
        "Problem": "Arbitrary image normalization size",
        "Location": "Page 2, Section 2",
        "Explanation": "Images are normalized to a fixed size of 60x30 pixels based on a statistic that >96% of images have width/length less than 30 pixels. Normalizing to a fixed size without considering the original aspect ratio can distort the shape of the numerals, which is critical for recognition. The chosen size seems arbitrary and not well-justified by the provided statistic."
      },
      {
        "Problem": "Inconsistent description of feature vector size",
        "Location": "Page 2, Section 2 and Page 3, Section 2.3",
        "Explanation": "The paper states that 3 features (transit, angle, distance) are computed for each of the 18 blocks, resulting in 54 features total. However, Section 2.3 specifically states that 'A total of 18 features will be extracted for each characters and this will serve as feature vector' for the Transit feature. This creates confusion about the actual composition and total size of the feature vector."
      },
      {
        "Problem": "Missing crucial K-NN parameter",
        "Location": "Page 3, Section 2.4.4 and Section 3",
        "Explanation": "The paper uses a K-Nearest Neighbour (K-NN) classifier but does not specify the value of 'k' used in the experiments. The choice of 'k' is a critical parameter for K-NN that significantly impacts performance. Without this information, the reported results are not fully reproducible."
      }
    ],
    "token_usage": {
      "input": 1414,
      "thinking": 2620,
      "output": 612
    }
  },
  {
    "entry_id": 174,
    "retraction_id": "1802.06370v4",
    "paper_id": "1802.06370v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial explanation error of redundancy",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect fundamental equation used for deriving Hamiltonians",
        "Location": "Section 2, Equation (5), page 4",
        "Explanation": "The equation (5) is presented as the key equation derived from Hamilton's equations and the given \\dot{p} = -dV/dx. However, the correct PDE that a Hamiltonian H(p,x) must satisfy to produce the equation of motion \\ddot{x} = -1/m dV/dx is different. Equation (5) is only equivalent to \\dot{p} = -dV/dx for the standard Hamiltonian H_N, making its use to find general Hamiltonians circular and incorrect."
      },
      {
        "Problem": "Inconsistent assumption in solving for the function F(p,x)",
        "Location": "Section 2, derivation of Cases I, II, III, starting from Equation (8), page 5",
        "Explanation": "The derivation of the function F(p,x) relies on solving equation (8) under the assumption that \\dot{p} = -dV/dx. This assumption is inconsistent with the Hamiltonians H_j (for j>0) subsequently derived, as their corresponding \\dot{p} = -\\partial H_j/\\partial x is generally not equal to -dV/dx. This inconsistency invalidates the solutions found for F(p,x) under the stated conditions."
      },
      {
        "Problem": "Incorrect claim that derived Hamiltonians produce the standard equation of motion",
        "Location": "Section 2, paragraph after Equation (8), page 5",
        "Explanation": "The paper claims that the derived Hamiltonians (e.g., the Cabbatonian H_j) produce the standard equation of motion \\ddot{x} = -1/m dV/dx. However, calculating \\ddot{x} from Hamilton's equations for H_1 yields \\ddot{x} = -1/m e^{-2H_0/m\\lambda_1^2} dV/dx. This is not equal to -1/m dV/dx in general, but only when the initial energy H_0 is zero. The equation of motion must hold for all initial conditions, demonstrating that the derived Hamiltonians are not Newton-equivalent."
      },
      {
        "Problem": "Incorrect claim about Equation (8) being a consequence of Hamilton's equations",
        "Location": "Section 2, Remark 1, page 5",
        "Explanation": "Remark 1 claims that equation (8) (with F=H) is a consequence of Hamilton's equations for a general Hamiltonian H(p,x). Substituting \\dot{p} = -\\partial H/\\partial x and \\dot{x} = \\partial H/\\partial p into (8) (with F=H) gives (-$\\partial$H/$\\partial$x)($\\partial$H/$\\partial$p) + (p/m)($\\partial$H/$\\partial$x) = 0. This is not the identity 0=0 shown in (10) unless p/m = $\\partial$H/$\\partial$p, which is only true for the standard Hamiltonian H_N=p^2/2m+V(x). Therefore, (8) is not a general consequence of Hamilton's equations for an arbitrary H(p,x)."
      }
    ],
    "token_usage": {
      "input": 28694,
      "thinking": 8842,
      "output": 757
    }
  },
  {
    "entry_id": 175,
    "retraction_id": "1403.0340v2",
    "paper_id": "1403.0340v1",
    "retraction_comment": "This paper has been withdrawn by the author because of Projection measurement tacit usage (while generalized one should have been used)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The states defined as the 'stochastic Bell basis' in Section 6.1 (Eqs. 33-36) do not form a basis for the Hilbert space of two bipartite systems (qubit+apparatus).",
        "Location": "Section 6.1, Section 6.2, Eqs. 33-36",
        "Explanation": "Each system (1 and 2) is a composite of a qubit and a two-state apparatus, residing in a 4-dimensional space. The combined space for systems 1 and 2 is 16-dimensional. The 8 states defined in Section 6.1 are specific entangled states within this 16-dimensional space, but they are not linearly independent and do not span the space. The teleportation calculation in Section 6.2 relies on expanding the initial state in terms of these non-basis states, rendering the derivation and conclusions of this section mathematically unsound."
      },
      {
        "Problem": "The teleportation protocol described in Section 6.2 involves a highly complex 6-party state space.",
        "Location": "Section 6.2",
        "Explanation": "The setup involves Alice's initial state (qubit+apparatus system 1) and a shared entangled state (qubit+apparatus system 2 and qubit+apparatus system 3). This means Alice possesses systems 1 and 2, and Bob possesses system 3. The total state is in the Hilbert space of 6 parties (qubit1, app1, qubit2, app2, qubit3, app3). Alice's measurement is on her two composite systems (1 and 2). While mathematically conceivable, this setup is significantly more complex than standard teleportation and its physical feasibility and interpretation are not adequately addressed, making it difficult to assess the practical relevance of the result."
      },
      {
        "Problem": "The definition of a 'stochastic qubit' as a generalized coherent state (GCS) in Section 3 represents entanglement within a single composite system, not entanglement between a distinct qubit and a distinct measuring apparatus.",
        "Location": "Section 3, Eq. 6",
        "Explanation": "The GCS $\\left|\\eta_{\\xi_{q,p}}^{jlJM}\right\rangle$ is defined as a state of a single system with total angular momentum J, formed by coupling the system's spin (j=1/2) with an orbital angular momentum (l) associated with its spatial degrees of freedom. While this state is entangled for l>0, the entanglement is internal to the 'stochastic qubit' entity itself, between its spin and spatial parts. This differs conceptually from the stated goal in the introduction of entangling an 'ordinary qubit' (a separate system) with a 'quantum measuring apparatus' (another separate system)."
      },
      {
        "Problem": "The interpretation of the spatial part of the GCS as a 'micro-detector' and its role in defining the fundamental information unit (stochastic qubit) lacks sufficient justification within the quantum information context.",
        "Location": "Section 2, Section 3",
        "Explanation": "The paper adopts an interpretation from stochastic quantum theory where the spatial part of a GCS represents apparatus properties. Applying this to define a 'stochastic qubit' as an entangled state involving this spatial part is a specific conceptual choice. More justification is needed to explain why this particular form of entanglement (internal to a GCS) is the relevant way to incorporate measurement apparatuses into the definition of a qubit for quantum information processing, and what advantages it offers over standard bipartite entanglement between distinct system and apparatus Hilbert spaces."
      }
    ],
    "token_usage": {
      "input": 16046,
      "thinking": 3897,
      "output": 794
    }
  },
  {
    "entry_id": 176,
    "retraction_id": "2106.01585v2",
    "paper_id": "2106.01585v1",
    "retraction_comment": "The proof of Lemma 3.1 has a gap. While there is exponential mixing for Holder functions, the rate of the mixing depends on the Holder exponent of the function. This leads to a vicious circle",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 32866,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 177,
    "retraction_id": "1509.00106v3",
    "paper_id": "1509.00106v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (21)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent or incorrect Lipschitz constant for the smoothed function's gradient.",
        "Location": "Lemma 1, Section 2; Theorem 1, Section 3; Corollary 1, Appendix A.1",
        "Explanation": "Lemma 1 states that the gradient of the smoothed function f_gamma(x) = max { <Ax, u> - phi(u) - gamma b(Au) : u in U } is Lipschitz continuous with constant L_{f_gamma} = gamma^{-1} * bar{L}_f, where bar{L}_f = 1. This value (bar{L}_f = 1) is used throughout the convergence analysis (Lemma 3, Theorem 1, Corollary 1, Theorem 2). However, standard smoothing theory for max functions of the form max { <Kx, u> - h(u) : u in U } where h(u) is strongly convex with parameter mu_h, yields a Lipschitz constant for the gradient of norm(K)^2 / mu_h. In this paper's composite smoothing case, the term gamma b(Au) acts as the regularizer in u. If b is 1-strongly convex on Uc_A = {Au : u in U}, the strong convexity of gamma b(Au) w.r.t. u on U is gamma * lambda_min(A^T A) if A is injective on U. The Lipschitz constant of nabla f_gamma(x) = A u*_gamma(x) should then be norm(A)^2 / (gamma * lambda_min(A^T A)) if A is injective on U, or more generally, depend on norm(A)^2 and the strong convexity of gamma b(Au) + phi(u) w.r.t. u on U. The claim bar{L}_f = 1 appears incorrect or requires very specific, unstated assumptions on A and b, undermining the validity of the convergence rates derived."
      },
      {
        "Problem": "Invalid choice of the initial smoothing parameter gamma_0 for achieving the stated optimal rate.",
        "Location": "Theorem 1, Section 3",
        "Explanation": "Theorem 1 claims that setting the initial smoothing parameter gamma_0 to a specific value yields the optimal O(1/epsilon) complexity. The formula provided for this gamma_0, gamma_0 := (bar{c}R_0 sqrt(k_0+1)) / (k_0 sqrt(2D_Uc_A(k_0-bar{c}))), is derived by minimizing the upper bound on F(x^k) - Fopt with respect to gamma_0 for a fixed iteration k. However, gamma_0 must be a fixed value chosen *before* the algorithm starts, independent of the iteration counter k. The formula provided implicitly depends on k (as it minimizes the bound for a specific k), making it an invalid choice for a fixed initial parameter. This renders the claim about achieving the optimal rate with this specific gamma_0 choice unsound."
      },
      {
        "Problem": "Unjustified uniqueness of the solution to the maximization subproblem u*_gamma(x).",
        "Location": "Lemma 1, Section 2",
        "Explanation": "Lemma 1 claims that the solution u*_gamma(x) to the concave maximization problem max { <Ax, u> - phi(u) - gamma b(Au) : u in U } exists and is unique. Existence is generally guaranteed for proper, closed, convex functions and compact sets U. However, uniqueness requires the objective function in u to be strictly concave. The objective is <A^T x, u> - phi(u) - gamma b(Au). If phi is only convex (not strictly convex) and b is strongly convex on Uc_A = {Au : u in U} (not necessarily on U), the term gamma b(Au) might not be strongly convex w.r.t. u on U, especially if A is not injective on U. Without guaranteed strong concavity w.r.t. u on U, u*_gamma(x) might not be unique. If u*_gamma(x) is not unique, the gradient nabla f_gamma(x) = A u*_gamma(x) is not well-defined as a single vector, which invalidates the gradient-based steps in Algorithm 1 and the subsequent smoothness analysis."
      },
      {
        "Problem": "Inconsistency between the defined composite smoothing and its application/discussion in examples.",
        "Location": "Section 2, Section 4, Algorithm 1",
        "Explanation": "The paper introduces a novel composite smoothing function f_gamma(x) = max { <Ax, u> - phi(u) - gamma b(Au) : u in U } (Eq. 6) as the basis for Algorithm 1 and its convergence analysis (Theorem 1). However, the discussion of exploiting structures in Section 4 and the numerical examples seem to revert to or imply the use of standard smoothing f_gamma(x) = max { <Ax, u> - phi(u) - gamma b(u) : u in U } (e.g., Section 4.1, 4.2, 4.3, 4.4, Section 6). The Lipschitz constants derived or implied for these examples (e.g., norm(A)^2/gamma) contradict the bar{L}_f = 1 value stated for the composite smoothing in Lemma 1. This inconsistency creates confusion about which method is truly being analyzed and tested, and suggests the theoretical results for the composite smoothing might not apply to the presented examples."
      },
      {
        "Problem": "Primal recovery guarantee relies on potentially flawed dual convergence analysis.",
        "Location": "Theorem 2, Section 5; Appendix A.2",
        "Explanation": "Theorem 2 provides convergence guarantees for a primal sequence recovered via an averaging scheme applied to the iterates of Algorithm 1 solving the dual problem. The proof in Appendix A.2 directly uses the key estimate (Eq. A.1) derived from the dual convergence analysis (Lemma 3), which in turn relies on the Lipschitz constant from Lemma 1 and the parameter updates from Lemma 4. Since the dual analysis appears to contain significant flaws regarding the Lipschitz constant, the choice of initial parameter, and the uniqueness of the subproblem solution, the primal recovery guarantees stated in Theorem 2 are also undermined."
      }
    ],
    "token_usage": {
      "input": 36241,
      "thinking": 6408,
      "output": 1402
    }
  },
  {
    "entry_id": 178,
    "retraction_id": "1905.01749v2",
    "paper_id": "1905.01749v1",
    "retraction_comment": "There is a serious flaw with Theorems 2-4 which makes their results incorrect. We are working on fixing the issue and uploading a new version of this paper. This flaw, however, does not in any way affect the correctness of evaluations and the gains obtained using the proposed approach",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed Theoretical Foundation for Partitioning",
        "Location": "Section 4, Theorems 1, 2, and 3",
        "Explanation": "The proofs provided for Theorems 1, 2, and 3, which are stated as the inspiration for the heuristic, appear unsound. Theorem 1's proof by contradiction lacks rigor in how receiver swaps maintain partition structure. Theorems 2 and 3 seem to misapply or misinterpret the concept of max-min fairness when distributing sender capacity across partitions and individual receivers, weakening the theoretical justification for the proposed partitioning structure."
      },
      {
        "Problem": "Inaccurate and Inconsistent Completion Time Estimation",
        "Location": "Section 5.2 (Algorithm 2), Section 3 (System Model)",
        "Explanation": "Algorithm 2 estimates minimum completion times (κP) for partitions of a new request by calculating max-min fair rates assuming access to all available bandwidth B_e(t) and considering fairness only among the new partitions. This contradicts the system model (Section 3) which defines max-min fairness across *all* ongoing transfers and ignores the significant impact of existing traffic load on the new request's achievable rates and completion times. This estimation is likely inaccurate, especially under load."
      },
      {
        "Problem": "Reliance on Potentially Flawed Estimates for Optimization Metric",
        "Location": "Section 5.4 (Algorithm 4), Section 5.2 (Algorithm 2)",
        "Explanation": "The core decision in the heuristic (selecting the best partitioning layer) relies on minimizing the sum of (partition size * estimated partition completion time) using κP from Algorithm 2. Since Algorithm 2's estimation is likely inaccurate due to ignoring existing load and inconsistent max-min fairness application (as per Problem 2), minimizing this metric might not effectively minimize the actual average receiver completion time in a real, loaded network operating under the stated system model."
      },
      {
        "Problem": "Ambiguity in Simulation's Max-Min Fairness Implementation",
        "Location": "Section 6.2 (Simulations), Section 3 (System Model), Section 5.2 (Algorithm 2)",
        "Explanation": "The simulation evaluation claims to use 'accurate max-min fair rates' but it is unclear whether this implements the system model's definition (fairness across all ongoing trees of all transfers) or the simplified approach used in Algorithm 2 (fairness only among the new request's partitions). This ambiguity makes it difficult to assess whether the simulation results truly validate the heuristic's performance under the system model's intended rate allocation policy, as the heuristic's decisions are based on estimates derived from a potentially different fairness model."
      }
    ],
    "token_usage": {
      "input": 17581,
      "thinking": 3998,
      "output": 598
    }
  },
  {
    "entry_id": 179,
    "retraction_id": "1312.6644v4",
    "paper_id": "1312.6644v3",
    "retraction_comment": "This paper has been withdrawn by the author because Eqs. (7) and (8) are not correct. An update with corrected expressions and plots will follow soon",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Validity of the harmonic approximation at relevant temperatures.",
        "Location": "Section II (Model and Methods), Section III (Results)",
        "Explanation": "The dynamical model relies on a harmonic expansion around the equilibrium positions. However, the results are presented for a regime where normal modes are 'thermally excited' (moderately high temperatures). If thermal fluctuations are large enough to probe the anharmonic parts of the potential (Coulomb repulsion, trap potential), the harmonic approximation breaks down, potentially invalidating the derived Gaussian state, heat flow, and temperature calculations."
      },
      {
        "Problem": "Specific and potentially unrealistic disorder model.",
        "Location": "Section III (Results)",
        "Explanation": "Disorder is introduced by randomly varying the diagonal elements of the potential matrix V (pinning potentials). This is a specific type of diagonal disorder. Realistic disorder in ion crystals might involve variations in ion positions or trap fields affecting off-diagonal coupling terms. The conclusion about 'hyper sensitivity to disorder' and the transition to insulating/normal transport might be specific to this particular disorder model and not general."
      },
      {
        "Problem": "Reliance on the infinite frequency cutoff limit for environment spectral density.",
        "Location": "Section II (Model and Methods), Section III (Results)",
        "Explanation": "The analytic formulas and presented results are derived and computed in the high-cutoff limit (Lambda -> infinity), corresponding to a Markovian environment. While the method is claimed to be valid for finite cutoff, the results are not shown. The transport properties and the effect of disorder can be sensitive to the environment's spectral density and cutoff frequency. The conclusions regarding the transition from anomalous to normal transport might be quantitatively or even qualitatively different for realistic finite-bandwidth environments."
      },
      {
        "Problem": "Restriction to the weak coupling regime.",
        "Location": "Section III (Results)",
        "Explanation": "The numerical results are obtained in the weak coupling limit (gamma_0 = 10^-6). While this regime guarantees the linear scaling of conductivity with length for ideal harmonic chains, it might not fully capture the mechanisms responsible for the transition to normal or insulating transport induced by disorder. Stronger coupling could potentially enhance scattering or localization effects, leading to different disorder sensitivity and transport behavior. The conclusions about hyper sensitivity might be specific to this weak coupling assumption."
      },
      {
        "Problem": "Interpretation of local kinetic temperature in a non-equilibrium steady state.",
        "Location": "Section II (Model and Methods), Section III (Results)",
        "Explanation": "The local temperature is defined based on the momentum dispersion of individual degrees of freedom. While mathematically well-defined as an effective temperature, this does not necessarily imply local thermal equilibrium, which is an underlying assumption for Fourier's law. Interpreting the observed temperature profiles (especially the transition to linearity with disorder) directly in terms of Fourier's law might be misleading without further justification that local equilibrium is established, at least approximately, in the disordered case."
      }
    ],
    "token_usage": {
      "input": 8978,
      "thinking": 3074,
      "output": 649
    }
  },
  {
    "entry_id": 180,
    "retraction_id": "2103.11473v2",
    "paper_id": "2103.11473v1",
    "retraction_comment": "The proof of the cluster property (E4) for the superposition is wrong. [REDACTED-NAME] and [REDACTED-NAME] gave a counterexample s.t. the statement of cluster property can't hold in its full generality",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 17512,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 181,
    "retraction_id": "1303.6851v2",
    "paper_id": "1303.6851v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a loophole in the argument of the classical bound",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed classical model and calculation for CHSH bound",
        "Location": "Section III.A",
        "Explanation": "The 'new classical model' introduced does not represent a local realistic theory, and the quantity for which a 2√2 bound is derived is not the standard CHSH expectation value. This invalidates the claim that nonlocality exists classically in the same sense as quantum nonlocality and undermines the argument that nonlocality is trivial."
      },
      {
        "Problem": "Incomplete derivation of the uncertainty principle",
        "Location": "Section II",
        "Explanation": "The derivation of the uncertainty relation using the method of applying the Cauchy-Schwarz inequality to vectors like ΔA|Ψ⟩ is only strictly valid for pure quantum states |Ψ⟩. The general uncertainty principle holds for mixed states, but its derivation requires a different approach, making the presented derivation incomplete."
      },
      {
        "Problem": "Non-standard interpretation of Bohmian mechanics",
        "Location": "Section IV",
        "Explanation": "In the discussion on hidden variable theories, Bohmian mechanics is described as 'not a kind of HVT' based on a non-standard view of particle position. This deviates from the common understanding of Bohmian mechanics as a hidden variable theory and introduces confusion into the discussion."
      }
    ],
    "token_usage": {
      "input": 10697,
      "thinking": 11907,
      "output": 296
    }
  },
  {
    "entry_id": 182,
    "retraction_id": "1208.2556v2",
    "paper_id": "1208.2556v1",
    "retraction_comment": "This paper has been withdrawn by the author due to some nodes in the graph have not been taken into account",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lemma 2.1 is based on flawed parity arguments and claims a specific trajectory structure without proof.",
        "Location": "Lemma 2.1 and its proof (Page 2)",
        "Explanation": "The proof incorrectly deduces the parity of cycle elements ($d_1$, $d_{i-1}$, $d_{i-2}$) and makes an unjustified leap to claim that any normalized cycle must follow the specific sequence $\\{36k+16, \\ldots, 12k+5\\}$. This sequence itself is not shown to be a valid trajectory segment under Collatz rules, nor is it proven that all cycles must conform to this structure."
      },
      {
        "Problem": "The proof of the main theorem relies entirely on the unproven and incorrect trajectory structure claimed in Lemma 2.1.",
        "Location": "Proof of Theorem 3.1 (Page 3)",
        "Explanation": "The proof attempts to trace backwards from the maximum element $m_0=36k+16$ using inverse Collatz operations, but it explicitly uses and relies on the specific sequence of forms asserted in Lemma 2.1 (e.g., identifying $m_i$ as $12k+5$, $m_{i-1}$ as $24k+10$, etc.). Since Lemma 2.1 is unsound and its claimed sequence is not justified, any conclusion derived solely from its assumed structure is invalid."
      },
      {
        "Problem": "The backward tracing logic in the proof of Theorem 3.1 contains incorrect claims about predecessor nodes based on the provided graph.",
        "Location": "Proof of Theorem 3.1, analysis for k=9q+1 (Page 3)",
        "Explanation": "When analyzing the predecessor of $m_{i-3} \\equiv 9a+4$ (Node E), the proof states the predecessor nodes are B ($9a+8$) and A ($9b+7$). According to the graph (Figure 1), the nodes with edges pointing to E ($9a+4$) are B ($9a+8$) and D ($9b+4$). This discrepancy indicates an error in tracing the graph or applying the modulo 9 logic for backward steps."
      },
      {
        "Problem": "The proof claims contradictions based on calculated predecessor values without demonstrating how these values contradict the properties of a cycle.",
        "Location": "Proof of Theorem 3.1, analysis for various k values (Pages 3-5)",
        "Explanation": "For several cases of k, the proof calculates values for predecessors like $m_{i-5}$ or $m_{i-7}$ (e.g., $64k+24$, $40k+\frac{8(k-1)}{3}+16$) and states these are 'contradictions to $m_0=\\max(M)=36k+16$'. The proof does not explain *why* these specific values constitute a contradiction (e.g., by being larger than $m_0$, leading back to $m_0$ prematurely, or being a forbidden value like a multiple of 3)."
      },
      {
        "Problem": "The proof makes an incorrect statement about the existence of an inverse operation and misattributes the source of a potential contradiction.",
        "Location": "Proof of Theorem 3.1, analysis for k=9q (Page 3)",
        "Explanation": "When analyzing $m_{i-1} \\equiv 9b+1$ (Node H), the proof states 'There is no $m_{i-2}=\\kappa^{-1}(n)$ for \textcircled{\\SMALL{H}} as required from Lemma \ref{lemmax}'. The inverse $\\kappa^{-1}(9b+1) = (9b+1-1)/3 = 3b$ *does* exist. The actual contradiction arises because $3b$ is a multiple of 3 (and generally not 3), which cannot be in a non-trivial cycle. The proof incorrectly claims the non-existence of the inverse and attributes the contradiction to Lemma 2.1 instead of the property of cycle elements."
      }
    ],
    "token_usage": {
      "input": 9730,
      "thinking": 11229,
      "output": 918
    }
  },
  {
    "entry_id": 183,
    "retraction_id": "1804.05635v2",
    "paper_id": "1804.05635v1",
    "retraction_comment": "Theorem 1 is questionable and needs revision. Others parts should also be modified accorrdingly. Before the new version is ready, this version should not be referred",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Consistency proof for winner set is flawed.",
        "Location": "Theorem 4",
        "Explanation": "The proof attempts to show that the decentralized algorithm identifies the same set of winners as the centralized greedy algorithm using valuations as bids. It relies on an inductive argument comparing the ranking and winning status of bids in the decentralized setting (using $b_i \\leq v_i$) with the centralized setting (using $v_i$). However, the relative ranking of bids can change when bids are lower than valuations, meaning the set of higher-ranked winning bids considered by the decentralized algorithm for capacity checks is not necessarily the same as in the centralized algorithm, invalidating the inductive step."
      },
      {
        "Problem": "Algorithms require global knowledge, contradicting decentralization premise.",
        "Location": "Algorithms 2, 3, and 4",
        "Explanation": "The procedures for determining key predecessor (Algorithm 3) and key successor (Algorithm 4), which are central to Algorithm 2 (Best Response) and payment calculation, require sorting all bids by rank and checking resource constraints against all higher-ranked *declared* winners. This implies each agent needs a consistent, global view of all bids and declarations from all other agents, not just its direct competitors ($N_i$). This contradicts the decentralized model suggested by the conflict graph example and the claim that agents only need to interact with competitors."
      },
      {
        "Problem": "Reliance on an unanalyzed penalty mechanism for declaration correctness.",
        "Location": "Section III.A, Equation 9, Theorem 2",
        "Explanation": "The proposed dynamic game and the agent's best response strategy (Equation 9) critically rely on the assumption that agents are penalized if they declare an incorrect win status ($x_i=1$ when $b_i < c_i$ or $x_i=0$ when $b_i > c_i$). This penalty mechanism is not defined, analyzed, or shown to be enforceable in the decentralized setting. Without such a mechanism, agents have incentives to misrepresent their status, undermining the game's integrity and the validity of the resulting allocation and payments."
      },
      {
        "Problem": "Strategy-proofness claim is questionable in a dynamic setting.",
        "Location": "Section I, Section III.C",
        "Explanation": "The paper claims strategy-proofness for winners based on the critical-value payment. This property is typically proven for static, sealed-bid auctions where players make decisions without knowledge of others' bids. In the proposed dynamic game, agents can react to updates from others. While a winner might not be able to reduce their payment by unilaterally changing their *final* bid, the dynamic interaction allows agents to strategically influence the final state (and thus their payment or win status) through a sequence of bid changes, which is not captured by the static strategy-proofness concept."
      },
      {
        "Problem": "Algorithms rely on local, potentially stale information without explicit handling.",
        "Location": "Algorithm 2, Section III.B",
        "Explanation": "In an asynchronous decentralized system, an agent's local copy of other agents' bids and declarations can be outdated. The algorithms for calculating ranks, critical values, and making decisions are based on this local, potentially stale information. While Theorem 1 claims stabilization, the analysis does not explicitly address how the system guarantees convergence to a state that is correct and consistent with a global view, despite agents acting on potentially inconsistent local views."
      }
    ],
    "token_usage": {
      "input": 26716,
      "thinking": 4031,
      "output": 761
    }
  },
  {
    "entry_id": 184,
    "retraction_id": "1503.01380v2",
    "paper_id": "1503.01380v1",
    "retraction_comment": "incomplete and inaccurate, requesting withdrawal immediately. the ranking method is not correct",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proposed Journal Influence Score (JIS) is presented as a new, lightweight measure, but the methodology trains and validates it against the SCImago Journal Rank (SJR). This makes JIS essentially a linear regression approximation of SJR, rather than an independent measure of journal influence.",
        "Location": "Abstract, Section 2.1, Section 3, Conclusions",
        "Explanation": "The paper claims to propose a new score (JIS) but uses historical SJR data as the target variable for regression and validates the results by comparing rankings to SJR. This means the model is designed to predict SJR, not to provide an alternative, independent measure of influence. The 'lightweight' aspect comes from using fewer input variables than SJR might implicitly use, but the output is a proxy for SJR."
      },
      {
        "Problem": "The description of the variable selection process, particularly the application of Principal Component Analysis (PCA) and the final regression model, is inconsistent and unclear.",
        "Location": "Page 2 (Section 2.2), Page 5 (Analysis Phase-III, Principal Component Analysis), Page 6 (Principal Component Analysis, Table, Summary Output)",
        "Explanation": "The paper states the final model is MLR on principal components (Page 2) but later describes PCA as a feature reduction step where original variables are removed based on variance explained and 'percentage match' (Page 5-6). The final regression table (Page 6) shows coefficients for original variable names (Quarter, H-index, etc.), not principal components. This inconsistency makes it impossible to definitively understand the final model structure and its statistical basis."
      },
      {
        "Problem": "The variable selection rule in Analysis Phase-I and Phase-II ('P-value > 0.05 & Correlation Coefficient < 0.4, then remove parameter') is statistically unsound and arbitrary.",
        "Location": "Page 4 (Analysis Phase-I), Page 5 (Analysis Phase-II), Page 3 (Algorithm Step 7)",
        "Explanation": "Standard statistical practice for variable selection in regression typically relies on P-values (to assess significance given other predictors) or measures of multicollinearity (like VIF) and correlation (to understand bivariate relationships), but not a combined rule like this. A variable can have a high P-value but a moderate correlation, or vice-versa. Removing variables based on this specific joint condition lacks theoretical justification and may lead to suboptimal or incorrect model specification."
      },
      {
        "Problem": "The categorical variable 'Quarter' is included directly in the linear regression model as if it were a continuous variable.",
        "Location": "Page 2 (Section 2.2, Model equation), Page 6 (Summary Output, Coefficients table), Page 7 (Regression equation)",
        "Explanation": "Quarter (Q1, Q2, Q3, Q4) represents distinct periods and should be treated as a categorical variable in a regression model, typically using dummy variables. Including it as a single continuous variable assumes a linear relationship between the quarter number (1, 2, 3, 4) and the outcome, which is inappropriate and misinterprets the nature of the data."
      },
      {
        "Problem": "The claim that the method 'does not require any data storage' is misleading, as historical data is necessary to train the regression model.",
        "Location": "Abstract, Page 2 (Section 2.1, first paragraph)",
        "Explanation": "While the method might be lightweight for *applying* the trained model to a new journal, the entire process described involves importing data from SCImago (Step 1, Page 3) and using it to train the regression model (Steps 3-9, 18, Page 3). This training phase explicitly requires storing and processing historical data on journal metrics and their corresponding SJR values. The claim of 'no data storage' is therefore inaccurate."
      }
    ],
    "token_usage": {
      "input": 2962,
      "thinking": 2372,
      "output": 860
    }
  },
  {
    "entry_id": 185,
    "retraction_id": "1711.11197v4",
    "paper_id": "1711.11197v3",
    "retraction_comment": "Theorem 4.3 is false as states and it requires a completely different approach. Section 5 is completely correct but it will developed separately",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of the b-holonomy groupoid's unit space.",
        "Location": "Section 3, Definition of $^b\\mathcal{H}(M,\\cF)$",
        "Explanation": "The definition states that $^b\\mathcal{H}(M,\\cF)$ is the restriction to $M$ of a Blup groupoid $Blup_{r,s}(\\cH(\\widetilde{M},\\widetilde{\\cF}),\\cH(V,\\cF_V))$. The units of $Blup_{r,s}(\\gr_2, \\gr_1)$ are $Blup(\\go_2, \\go_1)$. In this case, the units should be $Blup(\\widetilde{M},V)$. The space $Blup(\\widetilde{M},V)$ is $(\\mathbb{S}(\\cN_V^{\\widetilde{M}})) \\cup (\\widetilde{M} \\setminus V)$, which is not the manifold $M$. The definition of restricting this groupoid to units $M$ is unclear and appears inconsistent with the structure of the Blup groupoid's unit space, invalidating the foundation of the calculus and index theory presented."
      },
      {
        "Problem": "Unclear and likely incorrect definition of the normal bundle $^bN$ used in the topological index.",
        "Location": "Section 4, Definition of $^bN$ and Lemma 4.1",
        "Explanation": "The topological index relies on a vector bundle $^bN$ over $M$, defined as the restriction to $M$ of the normal bundle to $\\widetilde{F}$ in $\\mathbb{R}^N$. The concept of a normal bundle to a foliation $\\widetilde{F}$ in the ambient space $\\mathbb{R}^N$ is not standard unless the leaves are embedded submanifolds of $\\mathbb{R}^N$. Furthermore, the proof of Lemma 4.1 assumes $^b\\widetilde{N}$ is a manifold with boundary $N_V$, which is not generally true for a vector bundle. This invalidates the construction of the topological index and the subsequent Morita equivalence."
      },
      {
        "Problem": "Incorrect application of Blup functoriality in the proof of the b-Connes-Skandalis theorem.",
        "Location": "Section 4, Proof of Theorem 4.1",
        "Explanation": "The proof constructs a groupoid morphism $h:^b\\mathcal{H}(M,\\cF)\\to \\mathbb{R}^N$ using $Blup(h_2)$, where $h_2:\\cH(\\widetilde{M},\\widetilde{\\cF}) \\to \\mathbb{R}^N \\times\\mathbb{R}^N$. The Blup functoriality for groupoids, as presented in Definition 2.4 and Proposition 2.5, applies to immersions of groupoids. The map $h_2$ is not generally an immersion. Applying the Blup functor to a non-immersion in this context is mathematically unsound and invalidates the construction of the morphism $h$ and its use in the proof."
      },
      {
        "Problem": "Inconsistent definition or application of the semi-direct product groupoid.",
        "Location": "Section 5, Proof of Proposition 5.1",
        "Explanation": "The proof of properness for the groupoid $\\Gamma_\\phi^b(\\widetilde{M})_h$ states it is a closed subgroupoid of $(\\widetilde{M}\\times_\\phi \\widetilde{M}\\times \\mathbb{R})_h$. The definition of the semi-direct product $\\gr_h$ in Section 2.3 involves units $M \\times \\mathbb{R}^N$ and arrows $(\\gamma, X)$ with specific source/range maps. The structure and source/range maps implied for $(\\widetilde{M}\\times_\\phi \\widetilde{M}\\times \\mathbb{R})_h$ in the proof (e.g., $s=((y,X+j_0(y)-j_0(x)), Y+\\lambda)$) do not match the definition from Section 2.3. This inconsistency makes the properness argument unreliable."
      },
      {
        "Problem": "Lack of justification for amenability of key groupoids.",
        "Location": "Sections 4 and 5, Proofs of Theorem 4.1 and Theorem 5.1",
        "Explanation": "Both index theorems rely heavily on the Connes-Thom isomorphism, which in the $C^*$-algebra setting requires the groupoids involved (e.g., $^b\\mathcal{H}(M,\\cF)$, $^b\\mathcal{H}(M,\\cF)^{tan}$, $(\\Gamma_\\phi(M))_{FE}$) to be amenable. The paper does not state or provide a proof that these specific Blup or deformation groupoids are amenable. Without this property, the application of the Connes-Thom isomorphism is not justified, invalidating the core arguments of the index theorems."
      }
    ],
    "token_usage": {
      "input": 31906,
      "thinking": 6368,
      "output": 1105
    }
  },
  {
    "entry_id": 186,
    "retraction_id": "2301.09693v2",
    "paper_id": "2301.09693v1",
    "retraction_comment": "An important technical mistake in the set-up of this variant of generalization to Seiberg-Witten equations was pointed out to the author. In particular, the equations are not elliptic as claimed. As a result, any statement about (or uses) regularity and transversality of the moduli space has to be disregarded. However, the moduli space is still compact",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed convergence argument for minimizing sequences in the existence proof.",
        "Location": "Lemma 6.16, Appendix Section 7.2",
        "Explanation": "The proof of Lemma 6.16, which is essential for establishing the existence of a smooth metric satisfying equation (6.11) (Theorem 6.5), relies on showing that a minimizing sequence converges strongly enough. The sketch provided in the appendix appears to incorrectly use Rellich's lemma to deduce C^0 convergence from L^2_1 boundedness. Standard arguments for this type of result are more complex and typically involve elliptic regularity or heat flow methods. Without a correct proof of Lemma 6.16, the existence of the desired metric is not established, invalidating Theorem 6.5 and consequently Theorem 5.4."
      },
      {
        "Problem": "Insufficient justification for a crucial maximum principle estimate.",
        "Location": "Proposition 6.14, Appendix Section 7.1 (Proof of estimate (6.30))",
        "Explanation": "The proof of Proposition 6.14, which is vital for establishing properties of the weak limit of normalized minimizing sequences, depends on the maximum principle estimate (6.30). The derivation of this estimate is sketched in Appendix Section 7.1. While the steps are outlined, a rigorous proof requires careful and detailed calculations involving connections, curvatures, and local frames, which are not fully provided. If this estimate is incorrect, the arguments relying on it, including Proposition 6.14 and 6.15, fail, undermining the proof of Theorem 6.5."
      },
      {
        "Problem": "The definition of $\\phi$-stability is not explicitly stated.",
        "Location": "Section 5 (after Remark 5.3), Section 6 (various propositions and theorems)",
        "Explanation": "The paper's main application in Section 5 and the entire proof in Section 6 hinge on the concept of $\\phi$-stability, referencing Bradlow's definition. However, the definition itself is not included in the paper. This significantly hinders the reader's ability to understand and verify the core arguments, particularly those related to the condition $\\mu_m(\\phi) > 0$ and its connection to the existence of the metric and the properties of the moduli space."
      }
    ],
    "token_usage": {
      "input": 57623,
      "thinking": 4451,
      "output": 516
    }
  },
  {
    "entry_id": 187,
    "retraction_id": "1609.01275v2",
    "paper_id": "1609.01275v1",
    "retraction_comment": "There is a serious error 3 lines below \"Step (II)\". It is not true that \"It follows that the set C' of all oriented colourings for ... is equal to the set of extension colourings.. .\" (In fact they only account for half of the extension colourings.)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition and properties of palindromic polynomials are applied to terms $X_\\mu$ which, for generic origami with reflexive bars, are polynomials in $z_1^{-1}, z_2^{-1}$ involving factors like $(z^{-k}-z^{-l})$. These factors, and thus the $X_\\mu$ terms, do not generally satisfy the required palindrome property $P(w) = c w^{-\\alpha} P(w^{-1})$, where $P(w)$ is the polynomial in $w=z^{-1}$. This undermines the core inductive argument in Section 5.",
        "Location": "Definition 5.1, Section 5 (first paragraph), Lemma 5.1 proof",
        "Explanation": "The paper defines palindromic/antipalindromic for polynomials in $z_1, z_2$ (implicitly, by relating $p(z)$ to $\\overline{p(z)}$ on $\\bT^2$, which implies $p(z) = z^\\alpha p(z^{-1})$ for real coefficients). The terms $X_\\mu$ in the determinant expansion are polynomials in $z_1^{-1}, z_2^{-1}$. For generic origami with reflexive bars, $X_\\mu$ contains factors of the form $(z^{-k}-z^{-l})$. Let $w=z^{-1}$. The polynomial in $w$ is $w^k-w^l$. This polynomial does not satisfy the required palindrome property $P(w) = c w^{-\\alpha} P(w^{-1})$ in general. The claim that $\\pol(\\mu)$ is palindromic or antipalindromic appears false, invalidating the inductive proof of the strong palindrome property."
      },
      {
        "Problem": "The inductive base case (base origami) can have an identically zero origami polynomial ($p_\\O \\equiv 0$). The strong palindrome property holds trivially for $p_\\O \\equiv 0$. The inductive step (Lemma 5.1) proves that if $\\O$ has the strong palindrome property, so does $\\O'$. This does not guarantee that $p_{\\O'}$ is non-zero. The conclusion that the RUM spectrum has dimension 1 requires $p_\\O \\not\\equiv 0$. The paper does not rigorously show that the construction sequence starting from a $p_\\O \\equiv 0$ base origami leads to a non-zero polynomial that satisfies the non-trivial palindrome property.",
        "Location": "Example 1.1, Lemma 3.1, Lemma 5.1",
        "Explanation": "A base origami (Example 1.1) can have a determinant identically equal to zero. While this framework technically satisfies the strong palindrome property ($0 = c z^\\alpha \\bar{0}$), this trivial property does not imply the dimension 1 conclusion for the RUM spectrum. The inductive step preserves the strong palindrome property, but does not prove that the polynomial becomes non-zero or that the non-zero polynomial (if it arises) satisfies the property in a non-trivial way. The paper needs to either start the induction from a base case with a non-zero polynomial or prove that the first non-zero polynomial encountered in the construction sequence satisfies the property."
      },
      {
        "Problem": "The analysis of joint splitting and oriented colouring extensions in Section 4 and the proof of Lemma 5.1 primarily focus on joints not on reflexive bars. The paper states that the analysis applies \"in an exactly similar way\" to joints on reflexive bars, but the structure of the matrix entries and the resulting terms $X_\\mu$ are different for reflexive bars (involving factors like $z^{-k}-z^{-l}$). The proof of Lemma 5.1, particularly the form of the factors $d_i$ and their sums, does not explicitly cover these cases, and the claim that $\\pol(\\mu)$ is palindromic/antipalindromic seems false for these cases (Problem 1).",
        "Location": "Section 4 (discussion of reflexive bars), Figure 2.4, Section 5 (Lemma 5.1 proof)",
        "Explanation": "The paper does not provide a detailed analysis of how joint splitting on a vertex incident to a reflexive bar affects the terms $X_\\mu$ and their palindrome properties. The structure of the matrix entries and the resulting polynomial factors $\\pol(\\mu)$ are different for reflexive bars compared to non-reflexive bars. The argument in Lemma 5.1, which relies on $X_{\\mu'} = d_i X_\\mu$ where $d_i$ is a scalar multiple of a monomial, does not directly apply when $X_\\mu$ and $X_{\\mu'}$ involve factors like $(z^{-k}-z^{-l})$. The claim that the analysis is \"exactly similar\" is not justified."
      },
      {
        "Problem": "The main theorem applies to \"generic\" origami, which includes cases with reflexive bars. The paper claims this implies the dimension 1 phenomenon for the RUM spectrum. However, the presence of reflexive bars can lead to linear subframeworks and potentially a determinant that is identically zero (as in the base case), which would imply a dimension 2 spectrum (the entire torus). The paper does not clearly define the subset of \"generic\" origami for which the dimension 1 conclusion holds, nor does it prove that $p_\\O \\not\\equiv 0$ for this subset using the inductive construction.",
        "Location": "Abstract, Section 1 (definition of generic), Section 2 (Theorem 2.1), Section 6",
        "Explanation": "The term \"generic\" is used to include origami with reflexive bars. Such origami can have $p_\\O \\equiv 0$, leading to a dimension 2 RUM spectrum, contradicting the claimed dimension 1 phenomenon. The paper needs to clarify the scope of the main theorem and its connection to the dimension 1 conjecture, potentially by restricting the class of origami considered or by proving that $p_\\O \\not\\equiv 0$ for the relevant generic cases constructed via joint splitting."
      }
    ],
    "token_usage": {
      "input": 16473,
      "thinking": 14979,
      "output": 1336
    }
  },
  {
    "entry_id": 188,
    "retraction_id": "2106.14795v2",
    "paper_id": "2106.14795v1",
    "retraction_comment": "Proof of Threorem 17, part 2 not correct as displayed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect definition of the multiplier in the continuous optimality conditions.",
        "Location": "Theorem 2.4, equations (1)-(2), definition of $\\bar \\Phi$",
        "Explanation": "The multiplier in the subgradient condition for the BV seminorm should be the adjoint state $\\bar p$, which solves $-\\bar p'' = \\bar y - y_d$ with homogeneous Dirichlet boundary conditions. The conditions should be $\\int_\\Omega \\bar p \\, d\\bar u' = -\\alpha \\|\\bar u'\\|_{\\mathcal{M}}$ and $\\|\\bar p\\|_{\\mathcal{C}} \\leq \\alpha$. The paper incorrectly defines the multiplier as $\\bar \\Phi = \\int_0^x \\bar p(s) \\, ds$ and states the conditions in terms of $\\bar \\Phi$."
      },
      {
        "Problem": "Incorrect formulation and spaces for the discrete adjoint system.",
        "Location": "Theorem 3.4, equations (5)-(6), spaces for $(\\bar p_h, \\bar q_h)$",
        "Explanation": "The discrete adjoint system for the mixed finite element method should have variables in the dual spaces of the test functions used for the state system. For the state system spaces ($P_0 \\times P_1$) and test spaces ($P_1 \\times P_0$), the adjoint variables should be in $P_1 \\times P_0$, not $P_0 \\times P_1$ as stated. The equations themselves also appear incorrect for the standard discrete adjoint system."
      },
      {
        "Problem": "Disconnect between the problem analyzed theoretically and the problem solved numerically.",
        "Location": "Section 3 (analysis of $(P_{vd})$) and Section 4 (numerical solution of $(\\hat P_h)$)",
        "Explanation": "The theoretical error analysis in Section 3.1 is performed for the solution of the infinite-dimensional problem $(P_{vd})$, where the control $\\bar u$ is in $BV(\\Omega)$. However, the numerical method described and implemented in Section 4 solves the finite-dimensional problem $(\\hat P_h)$, where the control is restricted to be piecewise constant ($u_h \\in P_0$). The error estimates proven for $(P_{vd})$ do not directly apply to the solution obtained numerically from $(\\hat P_h)$."
      },
      {
        "Problem": "Flawed proof for the state error estimate.",
        "Location": "Proof of Theorem 3.6",
        "Explanation": "The first step in the proof, $(\\bar \\st - \\bar \\st_h, g) = -(\\bar \\st - \\bar \\st_h, \\psi')$, appears incorrect. If $(\\phi, \\psi) = \\mathcal{S}(g)$ means $-\\phi''=g$ and $\\psi=\\phi'$, then $g = -\\psi'$. The identity $\\int (y-y_h) g dx = \\int (y-y_h) (-\\psi') dx$ is not generally equal to $\\int (z-z_h) (-\\psi) dx$ via integration by parts, as boundary terms involving $\\psi$ may not vanish. This step is fundamental to the rest of the proof."
      },
      {
        "Problem": "Incorrect derivation of the discrete sparsity structure.",
        "Location": "Lemma 3.5 and subsequent discussion on control structure",
        "Explanation": "The sparsity result is derived from the incorrect discrete optimality conditions (Theorem 3.4). Furthermore, the argument that the support of $(\\Upsilon_h \\bar u)'$ is a subset of grid points based on $|\\bar \\Phi_h(x)|=\\alpha$ is flawed if $\\bar \\Phi_h$ is piecewise quadratic (as suggested by the numerical results), as the maximum/minimum can occur away from grid points. The conclusion that the support is on grid points is correct for the problem $(\\hat P_h)$, but the theoretical justification provided is incorrect."
      }
    ],
    "token_usage": {
      "input": 35607,
      "thinking": 25588,
      "output": 903
    }
  },
  {
    "entry_id": 189,
    "retraction_id": "2108.05981v2",
    "paper_id": "2108.05981v1",
    "retraction_comment": "The article has been withdrawn due to incorrect model formulation. Particularly, introducing the so-called \"field with two elements\" was a mistake that made the main equation (observation) of the paper incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified application of Klein-Gordon equation and derivation of mass formula for a finite field.",
        "Location": "Page 3, Section 2.A, Equations (1)-(4)",
        "Explanation": "The Klein-Gordon equation is a partial differential equation for continuous fields. Applying it to a 'discrete complex scalar finite field' requires rigorous justification for the definition of the discrete Laplacian and the concept of 'wavenumber' (2π/q) in this context. The derivation of the dispersion relation (Eq. 2) and the mass formula (Eq. 4) from a discrete KG equation is not standard and appears to lack a solid mathematical foundation within the framework of finite fields."
      },
      {
        "Problem": "Arbitrary assumption equating the finite field quanta mass at the critical point to the Higgs mass.",
        "Location": "Page 4, Section 2.B",
        "Explanation": "The paper assumes that the mass of the bosons of the finite field at the critical point (mqc) is equal to the mass of the Higgs boson (MH). This assumption is used to calculate qc, which then leads to the observation about the Monster group. This makes the subsequent 'prediction' of the Higgs mass (Eq. 14) circular, as the known Higgs mass was used as input to establish the core relationship."
      },
      {
        "Problem": "Arbitrary assumption equating the critical order of the symmetry group to the Monster group order.",
        "Location": "Page 5, Section 3, Equation (8)",
        "Explanation": "Based on the numerical closeness of the calculated order of SU2(qc^2) and the Monster group order, the paper makes a strong assumption that the critical order of SU2(q*^2) is exactly equal to the Monster group order. This is a 'curious proposal' without theoretical justification within the established framework, yet it is central to determining the value of q* used in the final mass calculation."
      },
      {
        "Problem": "Unsound derivation and identification of m2 with the reduced Planck mass.",
        "Location": "Page 5, Section 3, Equations (11)-(12)",
        "Explanation": "The paper attempts to relate m2 (mass for q=2 field) to the reduced Planck mass (Mp). The argument that extrapolating Eq. 3 to q=2 yields m2 = π is mathematically unsound, as Eq. 3 is derived for the critical point qc, not arbitrary q, and q is a prime power, not a continuous variable allowing a limit to 2. The subsequent replacement of π with m2 in Eq. 11/12 lacks a clear derivation from the proposed finite field framework."
      },
      {
        "Problem": "Incorrect derivation and arbitrary insertion of the factor 24 as spatial dimensions.",
        "Location": "Page 6, Section 3, Equation (13)",
        "Explanation": "The paper inserts the factor 24 into the main observation (Eq. 13) and interprets it as the number of spatial dimensions (D) or CFT central charge. The attempted derivation from a D-dimensional KG equation, stating that -D (2π/qc)^2 = mqc^2 results in |mq| = (2π/qc) * sqrt(D), is mathematically incorrect. The factor 24 appears to be inserted to match the desired numerical result rather than being a consequence of the theoretical framework."
      }
    ],
    "token_usage": {
      "input": 2188,
      "thinking": 1928,
      "output": 761
    }
  },
  {
    "entry_id": 190,
    "retraction_id": "2209.07447v2",
    "paper_id": "2209.07447v1",
    "retraction_comment": "Theorem 11.1 is false : the kernel is not trivial as stated",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The proof sketch for the equivalence between A being a division algebra and Str(A)' being anisotropic is flawed.",
        "Location": "Section 5, Proposition 5.1",
        "Explanation": "The argument that an isotropic group Str(A)' contains a copy of Gm that acts by scalar multiplication on A is incorrect. While the proposition itself is a known result, the provided proof sketch is not valid."
      },
      {
        "Problem": "Lemma 9.2 claims the surjectivity of a map on H^1 groups which is not generally true.",
        "Location": "Section 9, Lemma 9.2",
        "Explanation": "The map H^1(K, mu_3 x mu_3) -> H^1(K, S x SL_1(D)) is induced by (lambda, mu) |-> (lambda, mu). The map from mu_3 is lambda |-> (lambda, lambda^-1). The claimed surjectivity of H^1(K, mu_3 x mu_3) onto H^1(K, S x SL_1(D)) is not generally true for arbitrary fields K and division algebras D or tori S. However, the subsequent argument in Theorem 9.1 does not rely on this surjectivity in the way it is stated, making this issue less critical to the overall proof of Theorem 9.1."
      },
      {
        "Problem": "The justification for the derived group of (P intersect N)^0 being trivial in Lemma 11.2(iii) is incorrect.",
        "Location": "Section 11, Lemma 11.2(iii)",
        "Explanation": "The argument states that L' (isomorphic to SL_4) does not have subgroups of type A2. This is false; SL_4 contains subgroups isomorphic to SL_3 (type A2). The correct reasoning for the derived group being trivial relies on (P intersect N)^0 being a torus, which cannot contain a non-trivial semisimple group like SL_1(D)."
      }
    ],
    "token_usage": {
      "input": 40604,
      "thinking": 18619,
      "output": 461
    }
  },
  {
    "entry_id": 191,
    "retraction_id": "1305.2623v2",
    "paper_id": "1305.2623v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in the calculation of Equation (28)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Contradiction in the definition of cluster member group sizes and its impact on the dominant velocity index.",
        "Location": "Section 2.2.1, Section 3, Theorem 1, Theorem 2",
        "Explanation": "The paper states that there are $u$ groups of cluster members, $G_y$, with $M_y \\sim c_y n^{\\alpha_y}$ members, where $\\alpha_y < 1$ for all $y=1, \\ldots, u$. However, the total number of members is $n$, i.e., $\\sum_{y=1}^u M_y = n$. If $\\alpha_y < 1$ for all $y$, then $\\sum_{y=1}^u M_y = \\sum_{y=1}^u c_y n^{\\alpha_y} = o(n)$, which contradicts the premise of $n$ members. This fundamental contradiction invalidates the model setup. Assuming the authors intended that $\\max_y \\alpha_y = 1$, the definition of $v_* = \\min\\{\\frac{v^{(y)}}{\\alpha_y}|{y=1,2, \\ldots ,u}\\}$ and the identification of dominant groups (those achieving this minimum) might still be incorrect if the minimum is achieved by a group with $\\alpha_y < 1$ while groups with $\\alpha_y=1$ exist. The dominant contribution to the sum of error probabilities $\\sum P(E_i)$ comes from groups maximizing the exponent $\\alpha_y - v^{(y)}/v_*$, which should be the groups with $\\alpha_y=1$ and minimum $v^{(y)}$. The current definition of $v_*$ and the indices $y_j$ does not guarantee this."
      },
      {
        "Problem": "Independence assumption for i.i.d. weak mobility results is not justified.",
        "Location": "Lemma 2 (1-b, 1-c, 1-d, 1-e), Section 6 (Theorem 3, Proposition 7a, Proposition 8)",
        "Explanation": "The proofs for the critical transmission range and probability bounds under i.i.d. weak mobility rely on the asymptotic independence of events related to different cluster members (Lemma 2, 1-b, 1-c) or the applicability of union/Bonferroni bounds based on near-independence (Lemma 2, 1-d, 1-e). The proof sketch for Lemma 2 (1-b) under i.i.d. mobility suggests that the probability of overlap between covered areas of different nodes needs to be negligible. For i.i.d. mobility, the probability of overlap between any two areas is $O(r^2)$. The probability that any pair of the $O(n^2 m^2)$ pairs of events (one for each node-time slot pair) overlap is $O(n^2 m^2 r^2) = O(n^2 m^2 \\frac{\\log n}{n^d}) = O(m^2 n^{2-d} \\log n)$. For this to go to 0, $d$ must be greater than 2. However, the i.i.d. weak parameters condition is $d > \\frac{1}{m-k+1}$, which can be less than or equal to 2 (e.g., $m=k=1, d>1$). Thus, the independence assumption is not justified for the stated condition on $d$, invalidating the results for i.i.d. weak mobility."
      },
      {
        "Problem": "Independence assumption for random walk weak mobility results is not convincingly proven.",
        "Location": "Lemma 2 (1-b, 1-c, 1-d, 1-e), Section 5 (Theorem 1, Proposition 3a, Proposition 4, Theorem 2, Proposition 5, Proposition 6)",
        "Explanation": "Similar to the i.i.d. case, the proofs for the critical transmission range and probability bounds under random walk weak mobility rely on the asymptotic independence of events related to different cluster members (Lemma 2, 1-b, 1-c) or the applicability of union/Bonferroni bounds (Lemma 2, 1-d, 1-e). The proof sketch for Lemma 2 (1-b) under random walk weak mobility attempts to show that the overlap probability between covered areas of different nodes is negligible. However, the sketch contains a potentially flawed integral bound (e.g., the upper bound for $\\mathcal{X}$ in the proof sketch does not clearly go to 0). The independence of events for different nodes in a mobile network is a complex issue and is not convincingly established by the provided sketch for the random walk weak mobility model, invalidating the results for this case."
      },
      {
        "Problem": "Independence assumption for i.i.d. strong mobility precise distribution result seems to require a stronger condition on $d$.",
        "Location": "Lemma 2 (2), Section 6 (Proposition 7b)",
        "Explanation": "The derivation of the precise asymptotic probability distribution for i.i.d. strong mobility relies on the asymptotic independence of the disconnected events $E_i$ for different cluster members (Lemma 2, 2). The proof sketch for Lemma 2 (2) under i.i.d. mobility shows that the probability of any two covered transmission areas (from any node, any time slot) overlapping goes to 0 if $d>2$. If no areas overlap, the events $1_{ij}=0$ are independent for all $i,j$, which implies the $E_i$ events are independent. However, the proof sketch calculates the probability of *any* pair of the $O((nm)^2)$ areas overlapping as $O((nm)^2 r^2) = O(n^2 m^2 \\frac{\\log n}{n^d}) = O(m^2 n^{2-d} \\log n)$. For this to go to 0, $d$ must be strictly greater than 2. The i.i.d. strong parameters condition is stated as $d>2$. While $d>2$ implies $n^{2-d} \\log n \\to 0$, the rate might not be sufficient for the product approximation $\\prod P(\\overline{E_i})$ to hold when $\\sum P(E_i)$ converges to a constant. Typically, for the product of probabilities of rare events to approximate the probability of their intersection, the sum of probabilities of pairwise intersections must be $o(1)$. This requires $O(n^2 P(E_i)^2)$ or $O((\\sum P(E_i))^2)$ to be $o(1)$ for the union bound approach, or more generally, the sum of probabilities of all higher-order intersections to be negligible. The proof sketch for Lemma 2 (2) seems to only show that the probability of *any* two areas overlapping goes to 0, which implies independence of $1_{ij}=0$ events, but not necessarily independence of $E_i$ events without further argument. A more rigorous proof for the independence of $E_i$ events might require a stronger condition on $d$, possibly $d>4$ based on related literature on connectivity in random geometric graphs."
      }
    ],
    "token_usage": {
      "input": 51086,
      "thinking": 15896,
      "output": 1631
    }
  },
  {
    "entry_id": 192,
    "retraction_id": "0909.5521v3",
    "paper_id": "0909.5521v2",
    "retraction_comment": "Manuscript withdrawn, because results are incorrect. If phi = phi_1 AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be expressed as a universal Horn sentence in ESO (NOT even when the structure is ordered)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The crucial Assumption 1, stating that if a conjunction of clauses is equivalent to a Horn formula, then each clause must be Horn, is false.",
        "Location": "Assumption 1, Section 3.1, Section 4.1",
        "Explanation": "The equivalence of formulas is a semantic property. A non-Horn formula can be logically equivalent to a Horn formula. The author provides a counterexample but dismisses it with an informal argument about 'unrelated properties' of BFC and OFC, which is not a formal basis to reject counterexamples to Assumption 1. This assumption is essential for the claim that the OFC part of a P problem's expression must be Horn."
      },
      {
        "Problem": "The argument relies on the Objective Function Constraint (OFC) expression, such as $|S| \\ge K$, being expressible in ESO-ord-\\Pi_1-Horn logic.",
        "Location": "Section 3.1, Remarks 3 and 4, Section 4.1",
        "Explanation": "Expressing cardinality constraints like $|S| \\ge K$ in ESO-ord-\\Pi_1-Horn logic is generally not possible for arbitrary $K$, even with ordered structures and a successor predicate. The author assumes this expressibility for the OFC part of P problems (relying on the false Assumption 1) and then reuses this for NP problems. The cited result from Dawar ([Da09]) directly indicates that the OFC cannot be expressed in this logic, contradicting a core premise of the paper's argument."
      },
      {
        "Problem": "The core argument structure appears circular or based on an invalid transfer of properties from P problems to NP problems.",
        "Location": "Section 3, Section 3.1, Section 4",
        "Explanation": "The argument uses the property that the OFC of a *P problem* is expressible in ESO-ord-\\Pi_1-Horn (derived from Grädel's theorem and the false Assumption 1) and applies this property to the OFC of an *NP problem* (VC/Clique) to conclude that the NP problem is in P. This is only valid if the OFC form itself is independently expressible in the logic, which is not the case (as per the issue with cardinality constraints and Dawar's result). The argument relies on a property derived from a problem being in P to prove that an NP problem is in P."
      }
    ],
    "token_usage": {
      "input": 6051,
      "thinking": 3408,
      "output": 544
    }
  },
  {
    "entry_id": 193,
    "retraction_id": "1810.09527v2",
    "paper_id": "1810.09527v1",
    "retraction_comment": "Appears that the three transitions interpreted as blueshifted molecular emission from methanol and methanimine are recombination line transitions with similar rest frequencies Paper being withdrawn while this is confirmed",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 19523,
      "thinking": 7399,
      "output": 1
    }
  },
  {
    "entry_id": 194,
    "retraction_id": "1603.01872v4",
    "paper_id": "1603.01872v3",
    "retraction_comment": "This paper contains an error: the diagram (13) in the proof of Proposition 6.5 does not strictly commute as claimed. See this https URL for more details. The authors would like to thank [REDACTED-NAME] and [REDACTED-NAME] for finding this error and bringing it to their attention",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 19676,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 195,
    "retraction_id": "2404.01980v6",
    "paper_id": "2404.01980v5",
    "retraction_comment": "There is a flaw in the proof of Theorem 3.3 that the A at t=0 and A at t=T cannot be guaranteed to be identical, thus the key inequality fails",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect derivation of the final contradiction",
        "Location": "Page 3, Proof of Theorem, last paragraph",
        "Explanation": "The proof attempts to derive a contradiction from the inequality $e^{-BT}\\cdot\\frac{4\\pi A-\\kappa(T)A^2}{4\\pi A-\\kappa(0)A^2}\\geq \\frac{\\kappa(T)-1}{\\kappa(0)-1}$ for small $A$. The presented chain of inequalities $e^{-2T}\\geq e^{-BT}\\cdot 1\\geq \\frac{\\kappa(T)-1}{\\kappa(0)-1}>e^{-2T}$ is mathematically unsound. Specifically, the limit of the left side of the first inequality as $A \\rightarrow 0$ is 0, not $e^{-BT}\\cdot 1$. While the correct limit $0 \\geq \\frac{\\kappa(T)-1}{\\kappa(0)-1}$ does lead to a contradiction with the hypothesis $\\kappa(T)-1 > (\\kappa(0)-1)e^{-2T}$ (assuming $\\kappa(0)>1$), the argument as written is flawed."
      }
    ],
    "token_usage": {
      "input": 5007,
      "thinking": 17225,
      "output": 259
    }
  },
  {
    "entry_id": 196,
    "retraction_id": "1105.1572v2",
    "paper_id": "1105.1572v1",
    "retraction_comment": "This was withdrawn because the key distribution figures Figure 1 and 3 in the paper are technically incorrect",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misstatement of QKD eavesdropping detection mechanism",
        "Location": "Page 4, Section IV.D, Tentative Attack",
        "Explanation": "The paper states that Bob detects Oscar's interception because he 'will not receive the expected qubits'. In reality, QKD security relies on detecting the perturbation caused by Oscar's measurement, which manifests as an increased Quantum Bit Error Rate (QBER) in the sifted key, not simply a lack of received photons (which can be due to channel loss)."
      },
      {
        "Problem": "Confusing and potentially flawed presentation of intercept-resend attack analysis",
        "Location": "Page 4, Section IV.D, Intercept-resend strategy and Table 2",
        "Explanation": "The explanation and Table 2 describing the correct rate for Bob's measurements under an intercept-resend attack are confusingly presented. The table entries appear to be contributions to the total correct rate rather than conditional probabilities, and the calculation logic is difficult to follow, potentially misrepresenting how the 25% error rate arises from the probabilities of Oscar's and Bob's basis choices. While the final 25% error rate is a known result for this attack, the paper's derivation is unsound as explained."
      },
      {
        "Problem": "Unclear and potentially unsound explanation of the qutrit-based Byzantine Agreement protocol",
        "Location": "Page 8-9, Section VI.A",
        "Explanation": "The description of the Fitzi, Gisin, and Maurer qutrit protocol for Byzantine Agreement is very difficult to understand from the text provided. The explanation of key steps (like step 6 and the subsequent example analysis) is confusing and does not clearly demonstrate how the protocol works or why qutrits are necessary or provide an advantage over classical methods or qubits, making the claim of a quantum solution's superiority poorly supported within the paper's own explanation."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 7837,
      "output": 433
    }
  },
  {
    "entry_id": 197,
    "retraction_id": "2003.05595v3",
    "paper_id": "2003.05595v2",
    "retraction_comment": "Equation (24) was wrong: algebraic cancellations of this type are invalid in general",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect vanishing of energy term",
        "Location": "Proof of Theorem 1.1, paragraph containing Eq. (14)",
        "Explanation": "The proof claims that the term $\\langle\\xi, d^*\\xi \\wedge d^*\\xi\\rangle = \\langle\\xi, \\Xi \\wedge \\Xi\\rangle$ vanishes. This is based on the argument that the matrix part of the integrand, which is $\\text{trace}(XYZ)$ where $X, Y, Z \\in \\so(m)$, is zero. While $\\text{trace}(XYZ) = -\\text{trace}(ZYX)$ is true for $X,Y,Z \\in \\so(m)$, the integrand involves $\\text{trace}(X^T YZ)$ where $X$ is the matrix part of $\\xi$ and $Y, Z$ are matrix parts of $\\Xi$. This trace is not generally zero, invalidating the conclusion $\\|\\Xi\\|_{L^2}=0$."
      },
      {
        "Problem": "Unjustified existence and regularity of $\\xi$",
        "Location": "Proof of Theorem 1.1, paragraph containing Eq. (15)",
        "Explanation": "The proof assumes that $\\Xi = d^*\\xi$ for some $\\xi \\in W^{1,2}_0$. This specific Hodge decomposition requires solving $\\Delta \\xi = d\\Xi$ with $\\xi=0$ on the boundary. Since $\\Xi \\in L^2$, $d\\Xi = -\\Xi \\wedge \\Xi \\in L^1$. For $n \\ge 2$, an $L^1$ source term for the Laplacian does not guarantee $W^{1,2}$ regularity for the solution $\\xi$, which is required for the energy estimate $\\langle \\xi, dd^*\\xi \\rangle = \\|d^*\\xi\\|_{L^2}^2$."
      },
      {
        "Problem": "Mismatch in domain assumptions",
        "Location": "Theorem 1.1 statement and Proof of Theorem 1.1 (reliance on Lemma 3.1)",
        "Explanation": "Theorem 1.1 states that $U$ is a simply-connected domain. However, the proof relies on Lemma 3.1 (Coulomb gauge existence), which requires the domain $U$ to be smooth and bounded. The validity of Lemma 3.1 and the specific Hodge decomposition used in the proof on a general simply-connected domain (which can be unbounded or non-smooth) is not established."
      }
    ],
    "token_usage": {
      "input": 12361,
      "thinking": 16494,
      "output": 571
    }
  },
  {
    "entry_id": 198,
    "retraction_id": "1609.00445v2",
    "paper_id": "1609.00445v1",
    "retraction_comment": "Withdrawn due to an error in the numerical code, used to obtain the numerical results",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Apparent inconsistency in derived Dzyaloshinsky-Moriya interaction vectors.",
        "Location": "Equation (3), Model section",
        "Explanation": "The derived Dzyaloshinsky-Moriya (DM) vectors for bonds within the (2,3,4) triangle sublattice (e.g., $\\boldD_{\\boldtwo \\boldthree}$ vs $\\boldD_{\\boldtwo \\boldfour}$ and $\\boldD_{\\boldfour \\boldthree}$) appear inconsistent with the expected symmetry relations between these bonds in the pyrochlore lattice. While $\\boldD_{\\boldtwo \\boldfour}$ and $\\boldD_{\\boldfour \\boldthree}$ are proportional to (0,1,1) and (1,1,0) respectively (consistent with standard DM directions for these bond types), $\\boldD_{\\boldtwo \\boldthree}$ is proportional to (-1,0,-1), which seems inconsistent with the symmetry relating the (2,3) bond to the (2,4) and (3,4) bonds. This apparent inconsistency raises concerns about the correctness of the derived Hamiltonian, which forms the basis for all subsequent results and conclusions."
      },
      {
        "Problem": "Unjustified extrapolation from classical mean-field degeneracy to quantum spin liquid stabilization.",
        "Location": "Introduction, Discussion, Numerical results (Fig 4)",
        "Explanation": "The paper identifies regions of macroscopic degeneracy in the classical mean-field ground state and concludes this 'results in the spin liquid' and provides a 'mechanism for the spin liquid'. However, the mean-field approximation neglects quantum fluctuations, which are crucial for $S=1/2$ systems and can lift classical degeneracy, leading to ordered states or a quantum spin liquid through different mechanisms. The classical degeneracy found in MFA is a necessary but not sufficient condition for a quantum spin liquid, and the paper does not provide further analysis (e.g., using methods that include quantum fluctuations) to support the claim of quantum spin liquid stabilization."
      }
    ],
    "token_usage": {
      "input": 12447,
      "thinking": 10811,
      "output": 445
    }
  },
  {
    "entry_id": 199,
    "retraction_id": "1810.09697v2",
    "paper_id": "1810.09697v1",
    "retraction_comment": "We get more general results in Theorem 1.1. Corollary 5.27 and Theorem 1.3 are false",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The definition of a bi-unitary divisor given in the introduction is incorrect.",
        "Location": "Introduction, paragraph 2",
        "Explanation": "The definition 'A divisor D of S is called bi-unitary if gcd_u(D,S/D)=1' is the standard definition of a unitary divisor, not a bi-unitary divisor as used in the literature (e.g., [BeardBiunitary], [Wall]) and implicitly in the rest of the paper's formulas for sigma_star_star. This fundamental misstatement makes the stated definition equivalent to unitary perfect polynomials, contradicting the paper's goals and results."
      },
      {
        "Problem": "The factorization formula for sigma_star_star(T^a) for even 'a' appears incorrect.",
        "Location": "Corollary 2.3 i)",
        "Explanation": "The formula given for sigma_star_star(T^a) when 'a' is even (a in {4r, 4r+2}) does not match the standard definition sigma_star_star(T^(2n)) = sigma(T^(2n)) - T^n or its known factorizations in F_2[x]. This formula seems to mix properties of sigma and sigma_star_star or uses an incorrect factorization based on the binary representation of 'a'."
      },
      {
        "Problem": "The criterion for sigma_star_star(T^c) to split over F_2 is incorrect for even exponents.",
        "Location": "Corollary 2.4 ii)",
        "Explanation": "The corollary states that for an odd irreducible T, sigma_star_star(T^c) splits iff (T is Mersenne AND (c=2 or c=2^gamma-1)). However, sigma_star_star(T^4) is shown to split for Mersenne polynomials T=M_1, M_2, M_3 (Lemma 3.2 ii)), and c=4 is not of the form 2 or 2^gamma-1. This invalidates the splitting criterion for even exponents greater than 2."
      },
      {
        "Problem": "The specific factorization formulas for sigma_star_star(M_2^4) and sigma_star_star(M_3^4) are incorrect.",
        "Location": "Lemma 3.2 ii)",
        "Explanation": "Direct computation of sigma_star_star(M_2^4) = sigma(M_2^4) - M_2^2 in F_2[x] does not yield the polynomial x^2(x+1)^4 M_1M_5 as stated. This specific error impacts the analysis of polynomials with M_2 or M_3 factors raised to the power 4, which are considered in Theorem 1."
      },
      {
        "Problem": "The proofs of the main theorems rely on flawed preliminary results.",
        "Location": "Sections 3, 4, and 5 (Proofs of Theorems 1, 2, and 3)",
        "Explanation": "The arguments and conclusions in the proofs of Theorems 1, 2, and 3 depend heavily on the properties of sigma_star_star derived in the preliminary section (Section 2) and Lemma 3.2. Since Corollaries 2.3, 2.4, and Lemma 3.2 ii) contain critical errors regarding the behavior and factorization of sigma_star_star, the subsequent analysis and the resulting lists of polynomials are likely unsound."
      }
    ],
    "token_usage": {
      "input": 32493,
      "thinking": 13792,
      "output": 787
    }
  },
  {
    "entry_id": 200,
    "retraction_id": "1309.2621v7",
    "paper_id": "1309.2621v6",
    "retraction_comment": "This paper was withdrawn because the author did not prove that the function lambda_0(t) = gamma(t) on page 14 is strictly increasing. This is why we cannot make the crucial time change that proves the main theorem about infinite dimensional SRBM",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified assumption on the form of boundary measures in the Basic Adjoint Relationship.",
        "Location": "Proof of Theorem 3",
        "Explanation": "The proof assumes that the boundary measures nu_i in the Basic Adjoint Relationship (BAR) have a specific density related to the product exponential measure pi. This form is typically derived from the BAR in finite dimensions, but assuming it holds in the infinite-dimensional setting without proof or showing it's the unique solution to the BAR is a critical gap in the verification of the stationary distribution."
      },
      {
        "Problem": "Insufficient justification for tightness in the space of continuous functions on R^infinity.",
        "Location": "Proof of Theorem 2",
        "Explanation": "The proof relies on constructing a stationary process as a weak limit of a sequence of processes in C([0, T], R^infinity). Showing weak convergence requires proving tightness of the sequence. The argument demonstrates marginal tightness for each component process, but this is not sufficient for tightness in C([0, T], R^infinity) with the product topology. Standard tightness criteria for infinite-dimensional function spaces require additional conditions beyond marginal tightness, which are not provided."
      },
      {
        "Problem": "Unjustified convergence of infinite sums of integrals in the martingale property.",
        "Location": "Proof of Theorem 2",
        "Explanation": "The definition of the martingale problems and the convergence arguments involve infinite sums of integrals of the form sum_i int D_i f dL_i. While the test functions depend on finitely many variables and the reflection matrix is banded, the convergence of these infinite sums, particularly in the context of weak convergence of the underlying processes and measures, requires rigorous justification beyond term-by-term convergence, which is not adequately provided."
      },
      {
        "Problem": "Lack of rigorous justification for the quadratic variation calculation used for compact containment.",
        "Location": "Proof of Theorem 2",
        "Explanation": "The proof uses the Burkholder-Davis-Gundy inequality to establish compact containment for the component processes. This relies on calculating the quadratic variation of a local martingale derived from the process components. The calculation presented (e.g., <M^(n)>_t = a_11 t) implicitly assumes a specific semimartingale structure and quadratic variation property that needs to be rigorously derived from the patchwork martingale problem definition in the infinite-dimensional setting, which is more complex than the finite-dimensional case."
      }
    ],
    "token_usage": {
      "input": 35518,
      "thinking": 8896,
      "output": 541
    }
  },
  {
    "entry_id": 201,
    "retraction_id": "0811.0505v2",
    "paper_id": "0811.0505v1",
    "retraction_comment": "This paper has been withdrawn by the author since there were errors in the calculus of the defect coefficient in Page 11. The corrected calculus gives actually zero which do not lead to a contradiction on the continuity of the flow-map of the Benjamin-Ono equation. The author warmly thank [REDACTED-NAME] G_rard for having pointing out this error to him",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition and calculation of L2 norms",
        "Location": "Section 2, Section 4, Lemma 4.2",
        "Explanation": "The paper defines the H^s norm using the l^2 norm of Fourier coefficients, which implies the L2 norm is sqrt(sum |hat{f}(k)|^2) = sqrt(1/(2pi) integral |f|^2 dx). However, in Lemma 4.2, the notation integral_T |f|^2 dx is used, and the calculated limits (e.g., integral_T |cos(nx)|^2 dx = 2pi) suggest this integral is treated as integral_0^{2pi} |f|^2 dx, leading to a factor of 2pi discrepancy with the defined norm. This inconsistency makes it difficult to follow and verify calculations involving L2 norms."
      },
      {
        "Problem": "Incorrect calculation of the limit of the initial L2 norm of the sequence u_0,n",
        "Location": "Lemma 4.2, equation (4.1)",
        "Explanation": "The calculation of the limit of the L2 norm of the initial data sequence, specifically lim_{n->infty} integral_T |cos(nx)|^2 dx = 2pi, appears incorrect. Assuming the L2 norm is defined as sqrt(integral_0^{2pi} |f|^2 dx), the limit should be pi. If the L2 norm is defined as sqrt(1/(2pi) integral_0^{2pi} |f|^2 dx), the limit should be 1/2. This error leads to an incorrect value for alpha^2, the limit of ||u_0,n||^2."
      },
      {
        "Problem": "Incorrect calculation of the limit of the initial L2 norm of the gauge transform sequence w_0,n",
        "Location": "Lemma 4.2, equation (4.2)",
        "Explanation": "The calculation of the limit of the L2 norm of the initial gauge transform sequence, lim_{n->infty} integral_T |w_0,n|^2 = integral_T |w_0|^2 + pi/2, appears incorrect. Based on the definition of w_0,n and standard L2 norms, the limit should be integral_T |w_0|^2 + pi/8 (assuming integral dx norm) or ||w_0||^2 + 1/16 (assuming 1/(2pi) integral dx norm). This error leads to an incorrect value for a(0), the limit of ||w_n(0)||^2."
      },
      {
        "Problem": "The derived contradiction is invalid due to calculation errors",
        "Location": "End of Section 4",
        "Explanation": "The proof of Theorem 1.1 relies on showing a contradiction between the equation satisfied by the gauge transform of a BO solution (3.6) and the equation satisfied by the weak limit of the gauge transforms (4.3). This contradiction arises from a non-zero difference between specific terms involving alpha^2 - ||u_0||^2 and a(t) - ||w(t)||^2. Evaluating this difference at t=0 using the values calculated in Lemma 4.2 leads to a non-zero result. However, when the calculations in Lemma 4.2 are performed correctly, the difference at t=0 becomes zero, meaning the derived contradiction vanishes and the proof as presented is invalidated."
      }
    ],
    "token_usage": {
      "input": 33579,
      "thinking": 27320,
      "output": 772
    }
  },
  {
    "entry_id": 202,
    "retraction_id": "1404.7350v2",
    "paper_id": "1404.7350v1",
    "retraction_comment": "The paper has been withdrawn by the author since Lemma 3.27 is wrong. The author thanks [REDACTED-NAME]",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect application of a known result on small test families.",
        "Location": "Lemma 5.3",
        "Explanation": "Lemma 5.3 claims that if two ultrafilters $\\cV, \\cW$ are not nearly coherent to a $P$-point $\\cE$ and are nearly coherent to each other, then there exists $E \\in \\cE$ such that $f_E(\\cV)=f_E(\\cW)$. The proof cites and applies a result (Banakh-Blass Theorem 21) which holds only if $\\cV$ and $\\cW$ are $P$-points. The lemma is applied in the proof of Lemma 5.4 to arbitrary ultrafilters $\\mathcal{W} \\cap \\bV_\\alpha$ (which are not necessarily $P$-points) and selective ultrafilters $\\mathcal{R}_{i_\\alpha, \\alpha}$ (which are $P$-points). This misapplication invalidates the conclusion of Lemma 5.3."
      },
      {
        "Problem": "The proof of the main theorem relies on a flawed lemma.",
        "Location": "Lemma 5.4",
        "Explanation": "The proof of Lemma 5.4, which aims to show that any ultrafilter in the final model is nearly coherent to one of the constructed ultrafilters ($\\\\cE$ or $\\\\cR_i$), relies critically on Lemma 5.3 in Case 2. Case 2 considers ultrafilters $\\\\cW$ that are not nearly coherent to $\\\\cE$ but are nearly coherent to some $\\\\cR_{i,\\alpha}$. The argument in this case directly uses the conclusion of Lemma 5.3. Since Lemma 5.3 appears to be incorrectly proved for the required generality (as noted in the previous problem), the argument in Case 2 of Lemma 5.4 is unsound, invalidating the proof of the main theorem."
      }
    ],
    "token_usage": {
      "input": 63295,
      "thinking": 9103,
      "output": 432
    }
  },
  {
    "entry_id": 203,
    "retraction_id": "1612.01576v2",
    "paper_id": "1612.01576v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a crucial error in the inductive proof of Theorem 3.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound boosting argument for non-monotone systematic scan.",
        "Location": "Proof of Lemma 4.4, used in Theorem 4.1 and Theorem 6.1(ii).",
        "Explanation": "The proof of Lemma 4.4 claims that $\\Pr[X_{2t}(v) \\neq Y_{2t}(v) \\mid \\mathcal{A}] \\le \\rho(t)$, where $\\mathcal{A}$ is the event that $X_t$ and $Y_t$ disagree in $B_v(2tL)$ and $\\rho(t) = \\max_{X_0,Y_0} \\Pr[X_t(v) \\neq Y_t(v)]$. This step is not justified for systematic scan dynamics. The configurations $X_t, Y_t$ conditioned on $\\mathcal{A}$ are not arbitrary initial configurations, and the maximum disagreement probability $\\rho(t)$ does not necessarily bound the disagreement probability from these specific configurations. This invalidates the $O(\\log n)$ mixing time bound for non-monotone systematic scan."
      },
      {
        "Problem": "Incorrect deduction of spectral gap from mixing time.",
        "Location": "Proof of Theorem 5.1, used in Theorem 6.1(iii).",
        "Explanation": "The proof claims that the $O(\\log n)$ mixing time of the systematic scan chain $P_{eoe}$ implies $\\lambda(P_{eoe}) = \\Omega(1)$. This is incorrect. The standard relationship between mixing time $\\tau_{\\rm mix}$ and spectral gap $\\lambda$ is $\\tau_{\\rm mix}(\\varepsilon) \\ge (\\lambda^{-1}-1)\\log(1/2\\varepsilon)$. An $O(\\log n)$ mixing time implies $\\lambda^{-1}-1 = O(\\log n)$, which means $\\lambda = \\Omega(1/\\log n)$, not $\\Omega(1)$. This invalidates the conclusion that the Swendsen-Wang dynamics has an $O(1)$ relaxation time."
      }
    ],
    "token_usage": {
      "input": 33735,
      "thinking": 6128,
      "output": 472
    }
  },
  {
    "entry_id": 204,
    "retraction_id": "1501.05036v2",
    "paper_id": "1501.05036v1",
    "retraction_comment": "Eq. (9) only implies correlation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unproven Assumption for Main Theorem",
        "Location": "Assumption (H), Section 2.3; Theorem 1, Section 3",
        "Explanation": "Theorem 1, which concludes that the path-averaged scalar becomes uniform along a hyperbolic LCS for large integration times, relies on Assumption (H) that the LCS length shrinks exponentially. This property is assumed but not proven to hold universally for all hyperbolic LCSs defined by the variational criteria (A)-(D) in general unsteady flows. If this assumption is not always valid, the theoretical basis for the claimed alignment is weakened."
      },
      {
        "Problem": "Mismatch Between Theory and Numerical Evidence",
        "Location": "Figure 5(a), Section 4.2; Discussion in Section 4.2",
        "Explanation": "Figure 5(a) shows a strong alignment between contours of the path-averaged scalar and strainlines throughout the domain. However, the theoretical result (Theorem 1) explaining this alignment is specifically derived for hyperbolic LCSs (a subset of strainlines) based on Assumption (H). The paper does not provide a theoretical explanation for the observed alignment with all strainlines, creating a mismatch between the scope of the theory and the numerical evidence presented to support it."
      },
      {
        "Problem": "Inconsistent Application to Attracting LCSs",
        "Location": "Definition 1, Section 2.1; Discussion after Theorem 1, Section 3",
        "Explanation": "The path-averaged scalar is defined as an average over a forward time interval [t0, t0+T]. Attracting LCSs are identified by their length shrinkage in backward time over an interval like [t0, t0-T]. While the paper states Theorem 1 applies to attracting LCSs in backward time, the proof relies on the time interval of averaging matching the direction and interval of length shrinkage. Applying the theorem to the standard forward path average along an attracting LCS identified by backward-time properties is inconsistent and not theoretically justified by the provided proof."
      },
      {
        "Problem": "Unsubstantiated Explanation for Zero Contour Alignment",
        "Location": "Section 4.2, Discussion of Figures 6 and 7; Section 5, Conclusion",
        "Explanation": "The paper explains the observed alignment of LCSs with the zero level set of the path-averaged scalar by suggesting that trajectories starting on LCSs are longer and sample the domain more evenly, leading the average towards the spatial mean (zero). However, the claim that trajectories precisely on LCSs are generally the longest or most chaotic compared to other trajectories is not proven or universally accepted, potentially undermining the proposed explanation for this specific alignment."
      }
    ],
    "token_usage": {
      "input": 16828,
      "thinking": 6025,
      "output": 587
    }
  },
  {
    "entry_id": 205,
    "retraction_id": "1208.6493v2",
    "paper_id": "1208.6493v1",
    "retraction_comment": "This paper has been withdrawn by the author due to an error in a claim about singular supports in the proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect description of the singular support of the periodic distribution $\\widetilde{F}$.",
        "Location": "Proof of Theorem 1.2, after equation (1)",
        "Explanation": "The paper states that the singular support of $\\widetilde{F} = F \\ast \\sum_{n\\in\\mZ} \\delta_{2\\pi n}$ is contained in $\\bigcup_{n\\in\\mZ}(n\\pi,(n+1)\\pi)$. This set is $\\mR \\setminus \\{n\\pi : n \\in \\mZ\\}$. Given that $\\text{supp}(F) \\subset (-\\pi,\\pi)$, the correct singular support of $\\widetilde{F}$ is contained in $\\text{sing supp}(F) + \\text{sing supp}(\\sum \\delta_{2\\pi n}) \\subset (-\\pi,\\pi) + \\{2\\pi n : n \\in \\mZ\\} = \\bigcup_{n \\in \\mZ} (2\\pi n - \\pi, 2\\pi n + \\pi)$. The stated set is incorrect."
      },
      {
        "Problem": "Flawed justification for the product $\\1_{[-\\pi,\\pi]} \\widetilde{F}$ being well-defined.",
        "Location": "Proof of Theorem 1.2, after equation (1)",
        "Explanation": "The paper justifies the product $\\1_{[-\\pi,\\pi]} \\widetilde{F}$ being well-defined by stating that $\\text{sing supp } \\1_{[-\\pi,\\pi]}\\bigcap \\text{sing supp } \\widetilde{F}=\\emptyset$. The singular support of $\\1_{[-\\pi,\\pi]}$ is $\\{-\\pi, \\pi\\}$. Using the paper's stated singular support for $\\widetilde{F}$ (Problem 1), the intersection is $\\{-\\pi, \\pi\\} \\cap (\\mR \\setminus \\{n\\pi : n \\in \\mZ\\}) = \\{-\\pi, \\pi\\}$, which is not empty. The justification provided is thus incorrect based on the paper's own statements. While the product is indeed well-defined because the correct singular support of $\\widetilde{F}$ (as described in Problem 1) is disjoint from $\\{-\\pi, \\pi\\}$, the reasoning presented in the proof is unsound."
      },
      {
        "Problem": "Incorrect statement of the Paley-Wiener-Schwartz theorem bound.",
        "Location": "Proof of Theorem 1.2, after equation (1)",
        "Explanation": "The paper states that since $F\\in \\calE'(\\mR)$ has its support in $(-\\pi,\\pi)$, its inverse Fourier transform $f(z)$ satisfies $|f(z)|\\leq C (1+|z|)^{-N} e^{\\pi  |\\textrm{Im}(z)|}$ for some constants $C,N\\geq 0$. For a general distribution $F \\in \\calE'(\\mR)$, the bound on the entire function $f(z)$ is $|f(z)|\\leq C (1+|z|)^{k} e^{\\pi  |\\textrm{Im}(z)|}$ for some integer $k \\geq 0$. The exponent of $(1+|z|)$ should be non-negative, related to the order of the distribution, not necessarily negative. This incorrect bound is used to justify the convergence of the series $\\sum_{n\\in \\mZ} f(n)e^{-in\\omega}$ in $\\calS'(\\mR)$. While the series does converge in $\\calS'(\\mR)$ because $f(n)$ is polynomially bounded, the justification provided is based on a false statement about the decay of $f(n)$."
      }
    ],
    "token_usage": {
      "input": 5534,
      "thinking": 18253,
      "output": 840
    }
  },
  {
    "entry_id": 206,
    "retraction_id": "1909.06350v2",
    "paper_id": "1909.06350v1",
    "retraction_comment": "The proof contained an error in the definition of the coupling in (4.8) that the authors currently cannot fix. The authors thank [REDACTED-NAME] for pointing this error out to them",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect justification for the averaged bulk local law of the Hermitized matrix.",
        "Location": "Proposition 2.2",
        "Explanation": "The paper claims that Proposition 2.2 follows from [5, Theorem 3.4] using a relation between the trace of the resolvent of H^z and the trace of the resolvent of (X-z)^*(X-z). However, the domain of the spectral parameter w in Proposition 2.2 (|\\Re w|<=C, Im w>=n^{-1+epsilon}) does not ensure that v = w^2 satisfies the condition Im(v) >= n^{-1+epsilon} required by [5, Theorem 3.4] for the averaged local law of (X-z)^*(X-z). Specifically, if w = x + i eta with eta >= n^{-1+epsilon} and |x| is small, Im(w^2) = 2x eta can be smaller than n^{-1+epsilon}. This gap in the justification of Proposition 2.2 is critical as it is used to derive the singular value rigidity in Corollary 2.3, which is a key input for comparing the small singular values (Lemma 3.3) and potentially used in the stochastic advection argument (Lemma 4.2)."
      },
      {
        "Problem": "Incorrect bounds used in the long time Green function comparison theorem.",
        "Location": "Proof of Lemma 4.3, specifically equation (4.19) and subsequent estimates.",
        "Explanation": "The proof of Lemma 4.3 relies on bounds for sums of resolvent entries, such as sum_a G_{ab}(i eta) <= C eta^{-1/2}. These bounds are claimed to follow from the isotropic local law in Proposition 2.1. However, the isotropic local law provides bounds of the form |sum_a G_{ab} - hat{m}| <= n^xi sqrt(2n) (1/sqrt(n eta) + 1/(n eta)). For the relevant range of eta >= eta_2 = n^{-1/2+delta_2}, hat{m}(i eta) ~ 1/eta, and the error term is smaller than |hat{m}|. The correct bound is sum_a G_{ab} ~ 1/eta. Using 1/eta instead of eta^{-1/2} in the estimates for the third and fourth order terms in the cumulant expansion (e.g., in (4.21) and (4.22)) leads to bounds that are too large (e.g., n^{2-3delta_2} instead of n^xi/sqrt(n)eta_2) to prove Lemma 4.3. This error invalidates the long time GFT argument, which is essential for comparing the general case with Ginibre on mesoscopic scales."
      }
    ],
    "token_usage": {
      "input": 37523,
      "thinking": 12879,
      "output": 632
    }
  },
  {
    "entry_id": 207,
    "retraction_id": "0904.3281v2",
    "paper_id": "0904.3281v1",
    "retraction_comment": "The integrality statement is false. See the publication \"A norm compatible system of Galois cohomology classes for GSp(4)\" of the author for a correct statement and proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect norm factor in the definition of the norm map for the elliptic polylogarithm.",
        "Location": "Proposition 2.5, proof",
        "Explanation": "The proof claims that the map induced by the norm morphism N_f on Hom_S(I, I) is the identity. However, standard results (e.g., Kings, Prop. 2.2.1) show that this map is multiplication by the degree of the isogeny f. This implies that N_f(Pol_U') should be deg(f) Pol_U, contradicting the proposition's statement and affecting subsequent results that rely on this norm compatibility."
      },
      {
        "Problem": "Flawed proof of the distribution relation for Eisenstein classes on modular curves.",
        "Location": "Lemma 3.1 (ii), proof",
        "Explanation": "The proof attempts to derive the distribution relation E^k_{alpha, beta} = sum E^k_{alpha', beta'} (where a(alpha', beta') = (alpha, beta)) by applying Lemma 2.6 (Compatibility 2.2 and 2.3) with f being multiplication by a. However, Lemma 2.6 relates classes on different elliptic curves E' and E via an isogeny f: E' -> E, summing over the kernel of f. The application here to multiplication by a on the same curve is incorrect and does not yield the claimed distribution relation, even though the distribution relation itself is a known property of these classes."
      },
      {
        "Problem": "Unsound isomorphism between absolute cohomology and Galois cohomology.",
        "Location": "End of Section 3, before the Corollary",
        "Explanation": "The isomorphism H^1(G_N, R^3s_{N,*}W^{k,k'}) \\sim H^4_{abs}(S(N), W^{k,k'}) is claimed based on the Hochschild-Serre spectral sequence. This isomorphism requires the vanishing of the E_2^{2,3} term, H^2(G_N, R^3s_{N,*}W^{k,k'}), and potentially other terms. The vanishing of H^2(G_N, R^3s_{N,*}W^{k,k'}) is not justified in the text and is generally not true for Galois cohomology of representations, making the claimed isomorphism unsound. This invalidates the translation of the constructed classes in H^4_{abs} to the H^1 group required for the Perrin-Riou conjecture."
      }
    ],
    "token_usage": {
      "input": 16311,
      "thinking": 19009,
      "output": 562
    }
  },
  {
    "entry_id": 208,
    "retraction_id": "1705.03737v2",
    "paper_id": "1705.03737v1",
    "retraction_comment": "This paper contains a flaw that the proposed methods were overfitted thus the experimental results were not suitable. At this point, we do not want to update this article bu are developing a quite new approache where the authors are different from this paper,, and the title of our paper will be changed. 8 pages, 6 figures",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Weak Subjective Evaluation",
        "Location": "Section 5.2, MOS results",
        "Explanation": "The subjective study lacks statistical analysis (e.g., confidence intervals, p-values) to support the claim that DeepView_dec is perceived as having better visual quality than Deep3D, especially given the small difference in MOS values. Without statistical significance testing, the small difference in Mean Opinion Scores between DeepView_dec (-0.37) and Deep3D (-0.48) is insufficient to definitively conclude that DeepView_dec provides a statistically significant improvement in perceived visual quality."
      },
      {
        "Problem": "Missing Justification for YCbCr Subsampling",
        "Location": "Section 3 (Proposed method, DeepView_dec), Section 5.1 (Implementation details)",
        "Explanation": "The DeepView_dec architecture utilizes YCbCr color space conversion and subsamples the Cb and Cr channels by a factor of 2. The paper claims this reduces complexity while approximately maintaining accuracy, but no experimental evidence (e.g., an ablation study comparing with and without subsampling) is provided to support this design choice and its impact on accuracy. The paper introduces YCbCr conversion and CbCr subsampling as a design choice for DeepView_dec, claiming efficiency benefits with minimal accuracy loss. However, no experimental results are presented to validate this claim, making it difficult to assess the impact of this specific architectural decision on the reported performance."
      },
      {
        "Problem": "Potentially Misleading Depth Map Visualization",
        "Location": "Figure 6 and its caption, Section 5.1 (Objective performance)",
        "Explanation": "Figure 6 shows depth maps derived from the output of the networks (including DeepView_dec, which does not explicitly estimate depth) using a block-matching algorithm. While the caption states these are for showing consistency, presenting these derived maps alongside ground truth depth maps might mislead readers into believing the networks (especially DeepView_dec) are learning or producing meaningful depth representations internally, when the visualization is merely a post-hoc analysis of the generated image output. The depth maps shown for DeepView_dec are computed using a standard stereo matching algorithm on the generated right image and the input left image. Since DeepView_dec is a direct image-to-image translation network that does not explicitly estimate disparity or depth, visualizing these derived depth maps as if they represent an internal understanding of scene geometry is potentially misleading and does not validate any learned depth representation within this specific architecture."
      },
      {
        "Problem": "Limited Ablation Studies on Architecture Design",
        "Location": "Section 3 (Proposed method), Section 5.1 (Implementation details)",
        "Explanation": "The paper presents specific FCN architectures (number of layers per module, filter sizes, skip connections, down/up-sampling factors) but lacks comprehensive ablation studies to justify these choices. While the paper mentions exploring optimal settings, the contribution of individual components to the reported accuracy and efficiency is not demonstrated, weakening the claim of having found 'optimal network settings for efficient SIVG'. The paper describes detailed FCN architectures but does not provide experimental results demonstrating the impact of key design choices (e.g., number of layers, specific down/up-sampling factors, skip connections) on performance. This lack of ablation makes it difficult to understand which architectural elements are most critical for achieving the reported accuracy and efficiency."
      },
      {
        "Problem": "Inconsistent Naming of Architectures",
        "Location": "Section 3 (Proposed method), Section 5.2 (Spatial scalability), Table 5 (Computation efficiency)",
        "Explanation": "The paper introduces 'DeepView_ren' and 'DeepView_dec' in Section 3, but later uses the term 'DeepView_rec' in Section 5.2 and Table 5 without clearly defining it in the proposed methods section. Based on context (parameter count, speed, and description in 5.2), 'DeepView_rec' appears to refer to the base FCN encoder-decoder architecture used within DeepView_ren and DeepView_dec. This inconsistent and undefined naming convention makes it confusing to track which specific architecture is being evaluated in different parts of the paper, leading to potential confusion about the experimental results."
      }
    ],
    "token_usage": {
      "input": 9845,
      "thinking": 5663,
      "output": 929
    }
  },
  {
    "entry_id": 209,
    "retraction_id": "2307.01627v2",
    "paper_id": "2307.01627v1",
    "retraction_comment": "The proof of Theorem 2.6 is incorrect. Without this theorem the main claim of the paper becomes unproven",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 10197,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 210,
    "retraction_id": "1907.08721v2",
    "paper_id": "1907.08721v1",
    "retraction_comment": "A wrong fact on Hochschild homology was used in the proof of the main result (section 2, Theorem 2.0.4)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent Grading in Definition of Dual Homological Unit",
        "Location": "Definition 2.0.2, Remark 2.0.3",
        "Explanation": "The definition of the graded dual homological unit I_X^bullet contains contradictory statements regarding its grading and embedding into Hochschild homology. Definition 2.0.2 implies i_E: I_X^k -> Ext^k(E, E tensor omega_X), suggesting I_X^k is related to HH_k(X). However, Remark 2.0.3(3) states I_X^bullet -> HH_bullet(X)[dim X], suggesting I_X^k -> HH_{k+dim X}(X). The functoriality property also suggests I_X^k is related to HH_k(X). This fundamental inconsistency makes the definition mathematically unsound as a graded object related to standard cohomology/homology theories."
      },
      {
        "Problem": "Unjustified Identification of Dual Homological Unit with H^bullet(X, omega_X)",
        "Location": "Remark 2.0.3(2)",
        "Explanation": "The paper claims that for the standard rank function (rank as O_X-module), the dual homological unit is H^bullet(X, omega_X). This crucial identification is stated without proof or sufficient justification. Given the grading inconsistencies (Problem 1), this identification is highly questionable, as standard results relate H^k(X, omega_X) to HH_{dim X - k}(X), which does not align with the stated embeddings into HH_k(X) or HH_{k+dim X}(X)."
      },
      {
        "Problem": "Mathematically Ill-Defined Step in Proof of Theorem 2.0.4",
        "Location": "Proof of Theorem 2.0.4",
        "Explanation": "In the proof of Theorem 2.0.4, the step involving the expression L pi^*(i_{R pi_*(L)}(a)) + 0 is mathematically ill-defined. i_{R pi_*(L)}(a) is an element in an Ext group (specifically, Ext^k(R pi_* L, R pi_* L tensor omega_X) under one interpretation of the grading), not an object in the derived category D^b(X) that can be pulled back by the functor L pi^*. This step is essential for the claimed embedding of the dual homological unit into H^bullet(tilde{X}, omega_tilde{X}). The diagram presented also appears to confuse maps between objects with elements in Ext/Hom spaces."
      },
      {
        "Problem": "Missing Argument for Embedding into H^bullet(tilde{X}, omega_tilde{X}) Subspace",
        "Location": "Proof of Theorem 2.0.4",
        "Explanation": "Even if the ill-defined step (Problem 3) could be corrected, the proof only establishes an embedding of I_{X,v}^bullet into HH_bullet(tilde{X}). To conclude the embedding into H^bullet(tilde{X}, omega_tilde{X}), the proof needs to demonstrate that the image of I_{X,v}^bullet in HH_bullet(tilde{X}) lies specifically within the subspace corresponding to H^bullet(tilde{X}, omega_tilde{X}) under the Hochschild-Kostant-Rosenberg isomorphism and Serre duality. This crucial part of the argument is missing."
      },
      {
        "Problem": "Unclear Definition and Properties of the Trace Map",
        "Location": "Definition 2.0.2, Remark 2.0.3(2)",
        "Explanation": "The definition of the dual homological unit relies on the existence of a map t_E: Hom_{D^b(X)}^bullet(E, S_X(E)[-dim X]) -> I_X^bullet (or Ext^k(E, E tensor omega_X) -> I_X^k under one grading interpretation) satisfying t_E(i_E(a)) = rank(E)a. Remark 2.0.3(2) identifies this map with the trace map for the standard rank case. While a trace map exists for vector bundles, its extension to arbitrary objects in D^b(X) and the verification of the required properties (especially relating Ext groups to H^k(X, omega_X) and the composition property) are non-trivial and are not provided, weakening the foundation of the definition."
      }
    ],
    "token_usage": {
      "input": 10752,
      "thinking": 19322,
      "output": 996
    }
  },
  {
    "entry_id": 211,
    "retraction_id": "1608.07104v2",
    "paper_id": "1608.07104v1",
    "retraction_comment": "This paper has been withdrawn due to errors in the crucial estimates in Lemma 1 and Theorem 5",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Inconsistent definition of the symbol and function spaces",
        "Location": "Section 2, definition of $p_k$ and $X_s^b$",
        "Explanation": "The paper defines the operator $A_s = D^2 + 2s(e^1 + ie^2)\\cdot D$. Its Fourier symbol with respect to the basis $\tilde \\chi_k$ is $\\abs{k + e^2/2}^2 + 2s(e^1 + ie^2) \\cdot (k + e^2/2) = \\abs{k + e^2/2}^2 + 2s(k_1 + i(k_2 + 1/2))$. However, the paper states the symbol is $p_k = \\abs{k + e^2/2} + 2s(k_1 + ik_2) + is$. This stated symbol does not match the operator $A_s$. The spaces $X_s^b$ are defined using this incorrect symbol, making the relationship $(\\widehat{A_s f})_k = p_k \\hat f_k$ false and rendering the definition of the spaces and the properties of $A_s$ and its inverse $G_s$ inconsistent."
      },
      {
        "Problem": "Incorrect estimate in Lemma 1",
        "Location": "Lemma 1, second estimate",
        "Explanation": "The lemma claims $\norm{D u}_{b,s} \\leq 2\norm{u}_{b+1/2,s}$. This inequality is equivalent to $\\sum \\abs{k + e^2/2}^2 \\abs{p_k}^{2b} \\abs{\\hat u_k}^2 \\leq 4 \\sum \\abs{p_k}^{2b+1} \\abs{\\hat u_k}^2$, which requires $\\abs{k + e^2/2}^2 \\leq 4 \\abs{p_k}$ for all $k \\in \\Z^n$. Regardless of whether the correct symbol $\\abs{k + e^2/2}^2 + 2s(k_1 + i(k_2 + 1/2))$ or the paper's stated symbol $\\abs{k + e^2/2} + 2s(k_1 + ik_2) + is$ is used for $p_k$, this inequality fails for large values of $k_1$ (e.g., $k = (K, 0, \\dots, 0)$ for large $K$). This estimate is fundamental for relating the $X_s^b$ norms to Sobolev norms and is used in subsequent proofs (Lemma 2, Theorem 3), invalidating them."
      },
      {
        "Problem": "Incorrect choice of CGO exponents in the uniqueness proof",
        "Location": "Section 4, Step 5",
        "Explanation": "To extract the Fourier coefficient $\\dual{q, \\chi_k}$ from the integral $\\dual{q, u_1 u_2}$, where $u_j = \\chi_{z^j}(1+r_j)$, the sum of the exponents must be $k$, i.e., $z^1 + z^2 = k$. The paper defines $z^1 = -k/2 + t\\eta_1 + is\\eta_2$ and $z^2 = k/2 + t\\eta_1 - is\\eta_2$ (with $k, \\eta_1, \\eta_2$ orthogonal unit vectors and $t = \\sqrt{s^2 - \\abs{k/2}^2}$). The sum of these exponents is $z^1 + z^2 = 2t\\eta_1$. This sum is not equal to $k$ for a general $k \\in \\Z^n$. This invalidates the argument that $\\dual{q, u_1u_2} \to \\dual{q, \\chi_k}$ as $s \to \\infty$, which is the core of Step 5 and the uniqueness proof."
      }
    ],
    "token_usage": {
      "input": 13838,
      "thinking": 9769,
      "output": 910
    }
  },
  {
    "entry_id": 212,
    "retraction_id": "2401.17112v2",
    "paper_id": "2401.17112v1",
    "retraction_comment": "Bug. Lemma 1 is incorrect. The lemma needs the sets to be closed under subtraction which they are not",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Injectivity Lemma",
        "Location": "Lemma 1",
        "Explanation": "Lemma 1 incorrectly states that $\\calH$-independence implies the injectivity of the linear combination map. The proof relies on the difference of coefficients $(\\alpha_i - \\beta_i)$ being in $S_i$, which is not guaranteed for the sets $S_u$ and $S_v$ used later."
      },
      {
        "Problem": "Unjustified Bound on Set System Size",
        "Location": "Theorem 2, Proof of Theorem 3",
        "Explanation": "Theorem 2, which is used to derive the main bound $\\Pi |S_i| \\leq |R|^t$, relies on the incorrect Lemma 1. The number of distinct linear combinations is $|\\{\\Sigma \\alpha_i v_i \\mid \\alpha_i \\in S_i\\}|$, which is not necessarily equal to $\\Pi |S_i|$ when the linear combination map is not injective."
      },
      {
        "Problem": "Injectivity Fails for Chosen Coefficient Sets",
        "Location": "Proof of Theorem 3 (implicit in properties of $S_u, S_v$)",
        "Explanation": "For the sets $S_u=\\{0,1,2,4,5\\}$ and $S_v=\\{0,1,3,5\\}$ used, the difference sets $S_u-S_u$ and $S_v-S_v$ contain zero divisors of possible dot products ($|A_k| \\pmod 6$). This allows non-zero differences $(\\alpha_i - \\beta_i)$ to satisfy the linear system $\\Sigma (\\alpha_i - \\beta_i) w_i = 0$, meaning the map is not injective and the bound $\\Pi |S_i| \\leq |R|^t$ is not valid."
      },
      {
        "Problem": "Incorrect Diagonal Criterion Theorem",
        "Location": "Theorem 4",
        "Explanation": "Theorem 4 incorrectly states that $\\alpha_k (v_k \\cdot v_k) = 0$ with $\\alpha_k \\in S_k$ (where $S_k$ contains non-zero-divisors of $v_k \\cdot v_k$) implies $\\alpha_k = 0$. It implies $v_k \\cdot v_k = 0$. This theorem is not directly used for the main bound but indicates a misunderstanding of the underlying algebraic technique."
      }
    ],
    "token_usage": {
      "input": 3676,
      "thinking": 12702,
      "output": 576
    }
  },
  {
    "entry_id": 213,
    "retraction_id": "1710.01525v2",
    "paper_id": "1710.01525v1",
    "retraction_comment": "We can not prove Lemma 1 in Sect 2.4, and Terras did not prove it either, we misunderstood Terras's result here. Thus our proof about Theorem 2 is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The main theorem (Theorem 1) is false for all even integers n > 1.",
        "Location": "Theorem 1, Section 1",
        "Explanation": "For any even integer n > 1, the first step is division by 2, resulting in s_1 = n/2. Since n/2 < n for n > 0, the Glide G(n) is 1. The sequence from n to s_1 is just n -> n/2. This involves 0 odd steps (O(n)=0) and 1 even step (E(n)=1). Theorem 1 claims that for such n, 2^(E(n)-1) < 3^O(n) < 2^E(n). Substituting O(n)=0 and E(n)=1 gives 2^(1-1) < 3^0 < 2^1, which simplifies to 1 < 1 < 2. This inequality is false."
      },
      {
        "Problem": "A key lemma (Lemma 2) is false for all even integers n > 1.",
        "Location": "Lemma 2, Section 2.3",
        "Explanation": "Lemma 2 claims that for any integer n > 1 with finite Glide G(n) and s_G(n) = K, it must be that n/2 < K < n. As shown in Problem 1, for any even integer n > 1, G(n)=1 and K=s_1=n/2. The claim n/2 < K becomes n/2 < n/2, which is false. The proof of Lemma 2 also implicitly assumes G(n) > 1 or that the last step is a division by 2 from a value greater than n, which is not true when G(n)=1."
      },
      {
        "Problem": "The proof of the main theorem relies on a false inequality derived from Lemma 2 when n is even.",
        "Location": "Proof of Theorem 1, Section 2.3",
        "Explanation": "The proof of Theorem 1 uses the inequality L/2 < s_G(L), which is stated as following from Lemma 2. L is defined as 2^E(n)r + n. If n is an even integer, E(n)=1, so L = 2r + n. Since n is even, L is also even for any integer r. For any even number L > 1, G(L)=1 and s_G(L)=L/2. The inequality L/2 < s_G(L) becomes L/2 < L/2, which is false. This invalidates the subsequent steps in the proof for all even n > 1."
      },
      {
        "Problem": "The derivation of the bound for Res(n) in Lemma 3 is incorrect.",
        "Location": "Lemma 3, Section 2.3",
        "Explanation": "Lemma 3 claims Res(n) = sum_{i=0}^{O(n)-1} (3^(O(n)-1-i) / 2^lambda(i)) < O(n)/3. The proof attempts to show this by claiming (3^(O(n)-1-i) / 2^lambda(i)) < 1/3 for each term. This claim is based on s_u[i] > n and K < n implying (3^(O(n)-i) / 2^lambda(i)) < 1. While (3^(O(n)-i) / 2^lambda(i)) < 1 holds for i < O(n)-1 (assuming s_u[i] > n), it does not imply (3^(O(n)-1-i) / 2^lambda(i)) < 1/3 for all i in the sum. For the last term (i=O(n)-1), the term is 1 / 2^lambda(O(n)-1) = 1 / 2^k_{O(n)-1}, which is not necessarily less than 1/3. The bound Res(n) < O(n)/3 is not correctly derived and appears generally false."
      },
      {
        "Problem": "The proof of Theorem 1 does not establish the strict inequality 2^(E(n)-1) < 3^O(n).",
        "Location": "Proof of Theorem 1, Section 2.3",
        "Explanation": "The proof uses the inequality r(3^O(n) - 2^(E(n)-1)) > n/2 - K, derived from s_G(L) > L/2. This inequality implies 3^O(n) >= 2^(E(n)-1) for sufficiently large r. However, if 3^O(n) = 2^(E(n)-1), the inequality becomes 0 > n/2 - K, or K > n/2. This inequality K > n/2 is true for G(n) > 1 by Lemma 2. Thus, the case 3^O(n) = 2^(E(n)-1) is not ruled out by this argument, and the proof only establishes 2^(E(n)-1) <= 3^O(n) < 2^E(n)."
      }
    ],
    "token_usage": {
      "input": 9860,
      "thinking": 33542,
      "output": 1202
    }
  },
  {
    "entry_id": 214,
    "retraction_id": "2011.05544v2",
    "paper_id": "2011.05544v1",
    "retraction_comment": "Comments are welcome. There is a problem with the Theorem 4.7. Which could be fixed by taking double duals (category of reflexive sheaves) but it ruins the double deformation construction",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Misapplication of Grayson's filtration theorems",
        "Location": "Section 3, derivation of fibration (3.3)",
        "Explanation": "Grayson's filtration theorems (Theorem 3.1, 3.2) primarily apply to the K-theory of additive categories (K-oplus) or relate K-oplus to K. The paper applies the filtration to derive a fibration sequence involving K-theory spaces of exact categories, specifically |d ↦ K((B^q)^n Vect(X×ℤ^d))|, which is not the K-oplus space required by the theorem. This fundamental mismatch invalidates the structure of the derived fibration and the subsequent long exact sequence."
      },
      {
        "Problem": "Incorrect identification of the group structure and elements of the fiber term",
        "Location": "Section 3, Proposition 3.3 and Corollary 3.5",
        "Explanation": "The group π₀(|d ↦ K((B^q)^n Vect(X×ℤ^d), ℊ_m^{∧ 1})|) is π₁ of the space |d ↦ K((B^q)^n Vect(X×ℤ^d), ℊ_m^{∧ 1})|. The paper describes its elements as [(b,Θ)] and claims an additive structure based on composition of automorphisms. This description and group operation are characteristic of K₁ of a category of objects with automorphisms, not the π₁ of the space defined via a homotopy cofiber construction. This misidentification invalidates the argument that the group is torsion based on the finiteness of Aut(b)."
      },
      {
        "Problem": "Incorrect application of Heller's Lemma for K₀⁴",
        "Location": "Section 4, beginning of the section, application of Lemma 4.1",
        "Explanation": "The paper uses Heller's Lemma (Lemma 4.1), which describes relations in K₀ of an exact category, to analyze elements in K₀⁴. For K₀⁴ of an additive category, [J]-[J']=[K]-[K'] if and only if J ⊕ K' ≅ K ⊕ J'. The paper incorrectly concludes that [α]=[β] in K₀⁴ implies α ⊕ γ and β ⊕ γ are extensions of the same objects. This property is derived from Heller's Lemma for K₀ of an exact category, not K₀⁴ of an additive category. This fundamental misunderstanding of K₀⁴ invalidates the subsequent argument structure for proving the triviality of the π₁ group."
      },
      {
        "Problem": "Incorrect derivation of relations from double deformation and square relations",
        "Location": "Section 4, Proposition 4.12",
        "Explanation": "The proof attempts to use the square relations for the double deformation Cₐ,ₐ to show that [α]-[β] is trivial. The derivation of the equality [α]-[β]= -[Õ⊕ B¹ₙ₁]+[Õ⊕ B¹ₙ₂] from the square relation [Cₐ,ₐ|ₜ₀] - [Cₐ,ₐ|ₛ₀] + [Cₐ,ₐ|ₜ₁] - [Cₐ,ₐ|ₛ₁] = 0 appears incorrect based on the definitions in Remark 4.9. This step is crucial for the inductive argument that follows."
      },
      {
        "Problem": "Unsound inductive argument based on 'rank'",
        "Location": "Section 4, Proposition 4.12",
        "Explanation": "The proof of Proposition 4.12 claims that the process of reducing the difference of classes eventually stops because the 'rank of vector bundles is decreasing'. The objects involved are n-dimensional binary complexes of vector bundles, not just vector bundles. The concept of 'rank' for such complex objects is not defined, and it is not clear how this process guarantees a decrease in any well-defined measure that would lead to termination of the argument."
      }
    ],
    "token_usage": {
      "input": 12881,
      "thinking": 6894,
      "output": 1239
    }
  },
  {
    "entry_id": 215,
    "retraction_id": "1301.3486v2",
    "paper_id": "1301.3486v1",
    "retraction_comment": "Withdrawn because certain correction terms that arise in the Lace expansion of Section 3 were not identified and taken into account in the subsequent derivation. A new version with these correction terms included is in preparation",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Circular dependency in the proof of Proposition 4.2(ii) (Positivity and bounds on $\\hat \\Tau_z$).",
        "Location": "Proof of Proposition 4.2, Section 4.2",
        "Explanation": "The proof that $\\hat \\Tau_z(k) \\ge 0$ for $z \\in [0,1)$ uses the bound $\\hat \\Tau_z(k) \\le C/(1-z)$, which is part of the statement being proved. Furthermore, the proof of the bounds $\\hat \\Tau_z(k) \\le C/(1-z)$ and $\\hat \\Tau_z(k) \\le C'/[1-\\hat D(k)]$ uses the identity $p_c \\hat \\Pi_1(0)=1$ from \\eqref{eqPcPi}, which is derived in Section 6, a section whose results depend on Section 4."
      },
      {
        "Problem": "Circular dependency between Proposition 4.2(ii) and the bounds on lace expansion coefficients.",
        "Location": "Proofs of Proposition 4.1, Lemma 4.5 (in supplementary material), Proposition 4.4 (Section 4.2)",
        "Explanation": "The proofs of Proposition 4.1 (Basic properties) and Lemma 4.5 (Diagrammatic bounds), which are foundational for bounding lace expansion coefficients, rely on the positivity and bounds of $\\hat \\Tau_z(k)$ (Proposition 4.2(ii)). However, the proof of Proposition 4.2(ii) itself relies on Proposition 4.1 and results from Section 6 (which depend on Proposition 4.4, which depends on Lemma 4.5 and Proposition 4.2(ii)). This circular structure invalidates the proofs of these key propositions."
      },
      {
        "Problem": "Invalid proof of Theorem 1.3 (Mean-$r$ displacement).",
        "Location": "Proof of Theorem 1.3, Section 7",
        "Explanation": "The proof relies on the asymptotic behavior of $\\hat \\rho_n(k_n)$ and $\\hat \\tau_n(k_n)$ (Theorem 1.2) and bounds on $\\hat \\Tau_z(k)$ (Proposition 4.2(ii)). As noted, the proofs of Theorem 1.2 and Proposition 4.2(ii) are invalid due to circular dependencies, rendering the proof of Theorem 1.3 unsound."
      },
      {
        "Problem": "Invalid proof of Proposition 5.2 (Tightness).",
        "Location": "Proof of Proposition 5.2, Section 5.2",
        "Explanation": "The proof of tightness relies on moment bounds for the displacement (Theorem 1.3). Since the proof of Theorem 1.3 is invalid, the proof of Proposition 5.2 is also invalid."
      },
      {
        "Problem": "Invalid proof of Proposition 5.1 (Finite-dimensional distributions).",
        "Location": "Proof of Proposition 5.1, Section 5.1",
        "Explanation": "The proof relies on the asymptotic behavior of $\\hat \\tau_n(k_n)$ (Theorem 1.2) and bounds on temporal derivatives of coefficients (Proposition 4.4). As noted, the proofs of Theorem 1.2 and Proposition 4.4 are invalid due to circular dependencies, rendering the proof of Proposition 5.1 unsound."
      }
    ],
    "token_usage": {
      "input": 82183,
      "thinking": 7202,
      "output": 791
    }
  },
  {
    "entry_id": 216,
    "retraction_id": "2101.07819v3",
    "paper_id": "2101.07819v2",
    "retraction_comment": "We are withdrawing because of a significant error. The category Weil used to define tangent structures is too strict for the construction of our main example. In particular the map alpha in 7.19 is not well-defined. To resolve this we will replace Weil with a suitable $\\infty$-category and post a new version when possible. We are grateful to [REDACTED-NAME] and [REDACTED-NAME] for pointing out this error",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [],
    "token_usage": {
      "input": 101803,
      "thinking": 65536,
      "output": null
    }
  },
  {
    "entry_id": 217,
    "retraction_id": "1711.07883v3",
    "paper_id": "1711.07883v2",
    "retraction_comment": "The paper has some problems on the Poisson homomorphism from the motivic Hall algebra to the motivic quantum torus",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect simplification of the integrated Hall algebra identity in the DT/PT correspondence proof.",
        "Location": "Section 2.4, last paragraph",
        "Explanation": "The proof applies the motivic integration map $I_\\Lambda$ (a Poisson homomorphism) to the Hall algebra identity $\\srH_{\\leq 1}=\\srH_{0}\\star \\exp(\\{\\eta_{\\infty},-\\})(\\srH_{\\leq 1}^{\\#})$. This yields $I(\\srH_{\\leq 1}) = I(\\srH_0) \\star \\exp(\\{I(\\eta_{\\infty}),-\\} )(I(\\srH_{\\leq 1}^{\\#}))$. The proof then claims this simplifies to $I(\\srH_{\\leq 1})=I(\\srH_{0})\\cdot I(\\srH^{\\#}_{\\leq 1})$ because 'the Poisson brackets vanish'. However, $I(\\eta_{\\infty})$ corresponds to zero-dimensional sheaves and $I(\\srH^{\\#}_{\\leq 1})$ corresponds to stable pairs. The Euler form between these classes is generally non-zero, implying their Poisson bracket is non-zero. Thus, $\\exp(\\{I(\\eta_{\\infty}),-\\} )(I(\\srH_{\\leq 1}^{\\#}))$ is not equal to $I(\\srH_{\\leq 1}^{\\#})$, invalidating the final step of the proof for Theorem 1.1."
      },
      {
        "Problem": "Incorrect simplification of the integrated Hall algebra identity in the Flop formula proof.",
        "Location": "Section 3.4, second to last paragraph",
        "Explanation": "The proof applies the motivic integration map $I_\\Lambda$ (a Poisson homomorphism) to the Hall algebra identity $\\srPH_{\\leq 1}=\\dd^\\prime(\\srH_{\\exc}^{\\#})\\star \\exp\\{\\eta,-\\}(\\srH_{\\leq 1})$. This yields $I(\\srPH_{\\leq 1}) = I(\\dd^\\prime(\\srH_{\\exc}^{\\#})) \\star \\exp(\\{I(\\eta),-\\} )(I(\\srH_{\\leq 1}))$. The proof then claims this simplifies to $I_{\\Lambda}(\\srPH_{\\leq 1})=I_{\\Lambda}(\\dd^\\prime(\\srH_{\\exc}^{\\#}))\\cdot I_{\\Lambda}(\\srH_{\\leq 1})$ because 'the Poisson brackets vanish'. However, $I(\\eta)$ corresponds to objects in $\\sPF[1]$ and $I(\\srH_{\\leq 1})$ corresponds to ideal sheaves. The Euler form between these classes is generally non-zero, implying their Poisson bracket is non-zero. Thus, $\\exp(\\{I(\\eta),-\\} )(I(\\srH_{\\leq 1}))$ is not equal to $I(\\srH_{\\leq 1})$, invalidating the final step of the proof for Theorem 1.2."
      },
      {
        "Problem": "Incorrect simplification of the integrated Hall algebra identity in the Higher Rank DT/PT proof.",
        "Location": "Section 4.3, last paragraph",
        "Explanation": "The proof applies the motivic integration map $I$ (a Poisson homomorphism) to the Hall algebra identity $\\delta_{\\DT}(r,D)=\\exp(\\Ad(\\epsilon(\\cC_{\\infty})))\\star\\delta_{\\PT}(r,D)$. This yields $I(\\delta_{\\DT}(r,D)) = \\exp(\\{I(\\epsilon(\\cC_{\\infty})),-\\} )(I(\\delta_{\\PT}(r,D)))$. The proof then claims this simplifies to $I_{\\Lambda}(\\delta_{\\DT}(r,D))= \\exp(I(\\epsilon(\\cC_{\\infty}))) \\cdot I(\\delta_{\\PT}(r,D))$ because 'the Poisson brackets vanish'. However, $I(\\epsilon(\\cC_{\\infty}))$ corresponds to zero-dimensional sheaves and $I(\\delta_{\\PT}(r,D))$ corresponds to higher rank PT stable objects. The Euler form between these classes is generally non-zero, implying their Poisson bracket is non-zero. Thus, $\\exp(\\{I(\\epsilon(\\cC_{\\infty})),-\\} )(I(\\delta_{\\PT}(r,D)))$ is not equal to $\\exp(I(\\epsilon(\\cC_{\\infty}))) \\cdot I(\\delta_{\\PT}(r,D))$, invalidating the final step of the proof for the higher rank theorem."
      }
    ],
    "token_usage": {
      "input": 32803,
      "thinking": 5153,
      "output": 1005
    }
  },
  {
    "entry_id": 218,
    "retraction_id": "1603.02912v3",
    "paper_id": "1603.02912v2",
    "retraction_comment": "The calculation of the apparent charge density in this paper was wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Fundamental misunderstanding of how fields/densities transform under Lorentz transformation.",
        "Location": "Introduction, paragraph 3; Eq. (1); paragraph 4.",
        "Explanation": "The author claims the standard transformation $\rho' = \\gamma(\\rho - \\mathbf{V} \\cdot \\mathbf{j})$ is incomplete because $\\rho'$ is shown as a function of $(\\mathbf{r}, t)$ instead of $(\\mathbf{r}', t')$. This is incorrect. The standard transformation relates the value of the transformed field $\\rho'$ at a spacetime point $(\\mathbf{r}', t')$ in the new frame S' to the values of the original fields $\\rho$ and $\\mathbf{j}$ at the corresponding spacetime point $(\\mathbf{r}, t)$ in the original frame S. Eq. (1) incorrectly uses $(\\mathbf{r}, t)$ as arguments for $\\rho'$, indicating a confusion between coordinates in different frames."
      },
      {
        "Problem": "Incorrect sign in the presented Lorentz transformation formula for charge density.",
        "Location": "Eq. (1).",
        "Explanation": "The standard Lorentz transformation for charge density from a frame S (where $\\rho=0$) to a frame S' moving with velocity $\\mathbf{V}$ relative to S is $\\rho' = -\\gamma \\mathbf{V} \\cdot \\mathbf{j}$. Eq. (1) shows a positive sign, $\\rho'=\\gamma{\\bf V\\cdot j}$. While potentially a typo, it is a basic error in the fundamental transformation formula presented as the starting point of the argument."
      },
      {
        "Problem": "Flawed physical argument based on electron counting in a sampling cell.",
        "Location": "Paragraphs 5-8, Figure 1, Footnote 2.",
        "Explanation": "The author's argument that evaluating $\\rho'$ using Eq. (1) (with arguments $(\\mathbf{r}, t)$) corresponds to counting electrons at different times $t'$ in the moving frame is based on a misunderstanding. The standard Lorentz transformation correctly calculates the charge density (charge per unit volume at a fixed time $t'$) in the moving frame S'. The author's conclusion that counting at fixed $t'$ yields zero charge density contradicts the standard result, which correctly accounts for length contraction and the contribution from the current to the charge density in the moving frame."
      },
      {
        "Problem": "Incorrect final conclusion that the induced charge density is zero.",
        "Location": "Eq. (4), Paragraph 9.",
        "Explanation": "The paper concludes that the charge density in the moving frame is zero ($\rho'(\\mathbf{r}', t')=0$). This contradicts the standard and well-established result from the Lorentz transformation of the four-current, which predicts a non-zero charge density $\\rho' = -\\gamma \\mathbf{V} \\cdot \\mathbf{j}$ for a moving neutral current distribution where $\\mathbf{V} \\cdot \\mathbf{j} \\neq 0$. The existence of this induced charge density is a standard prediction of special relativity."
      }
    ],
    "token_usage": {
      "input": 2395,
      "thinking": 4417,
      "output": 697
    }
  },
  {
    "entry_id": 219,
    "retraction_id": "2205.10165v2",
    "paper_id": "2205.10165v1",
    "retraction_comment": "It is not proved that the function $S$ is in fact an inner function",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect justification for the convergence of the sequence of functions.",
        "Location": "Remark 1, Section 1",
        "Explanation": "Remark 1 claims that the map $h_z(t) = \\exp(-(1+zt)/(1-zt))$ is a contraction with respect to $t$ for a fixed $z$ in the unit disk, with a contraction constant less than 1 for all $|z|<1, |t|<1$. This is used to imply the convergence of the sequence of functions $S_n$. However, the derivative of this map with respect to $t$ is not bounded by a constant strictly less than 1 uniformly for all $|z|<1, |t|<1$. This invalidates the contraction mapping argument as presented for proving the convergence of the sequence $S_n$ to a unique fixed point."
      }
    ],
    "token_usage": {
      "input": 4683,
      "thinking": 15847,
      "output": 193
    }
  },
  {
    "entry_id": 220,
    "retraction_id": "1511.00570v2",
    "paper_id": "1511.00570v1",
    "retraction_comment": "This paper has been withdrawn because the analysis therein completely oversimplified the physics during primordial nucleosynthesis",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incomplete set of absorbed species after deuterium bottleneck",
        "Location": "Section \"Theory\", equations for number densities for T <= T_B",
        "Explanation": "The analysis only considers the absorption of ^4He and free protons after the deuterium bottleneck breaks. However, other light elements produced during BBN, such as deuterium, tritium, and ^3He, are also present and would be subject to absorption by Macros. Ignoring the absorption of these species, which have different masses and charges, leads to an incomplete picture of how the total baryon number and the relative abundances of different nuclei evolve. This simplification could significantly affect the calculated change in the final ^4He abundance, particularly in the regime after T_B, and thus impact the derived constraints."
      },
      {
        "Problem": "Reliance on a perturbative calculation potentially outside its range of validity",
        "Location": "Section \"Theory\", Equation (8) and the discussion of dashed lines in Results",
        "Explanation": "The calculation of the deviation in ^4He abundance, Delta X_4^Macro, is based on a first-order perturbative expansion in the Macro absorption rates. While the authors acknowledge that the analysis is less reliable when a large fraction of neutrons are absorbed (indicated by dashed lines), the perturbative approach itself might not be sufficiently accurate even for smaller absorption fractions if the cumulative effect over the BBN period is significant. The validity of applying this formula quantitatively to derive constraints requires a more rigorous justification or comparison with a full numerical solution of the coupled rate equations, especially given the sensitivity of the constraints to small changes in X_4."
      },
      {
        "Problem": "Assumption of a fixed deuterium bottleneck temperature (T_B)",
        "Location": "Section \"Theory\", footnote and Discussion section",
        "Explanation": "The analysis assumes that the deuterium bottleneck breaking temperature T_B remains essentially unchanged (within 10%) by the presence of Macros. However, Macro absorption removes baryons from the plasma, which changes the effective baryon-to-photon ratio. The value of T_B is sensitive to this ratio. If Macro absorption is significant, it could shift T_B by more than assumed, altering the duration and conditions of the BBN period before and after the bottleneck. This could invalidate the use of standard model time-temperature relations and the fixed integration limits ([T_F, T_B] and [T_B, infinity)), potentially undermining the foundation of the calculation."
      }
    ],
    "token_usage": {
      "input": 7799,
      "thinking": 10472,
      "output": 529
    }
  },
  {
    "entry_id": 221,
    "retraction_id": "1911.02706v2",
    "paper_id": "1911.02706v1",
    "retraction_comment": "A missing sign in the argument to prove Lemma 2 renders the proof incorrect. The note is withdrawn since we are unable to provide a corrected proof that works with the stated generality",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formula for the divergence of a Hessian.",
        "Location": "Proof of Lemma 1.",
        "Explanation": "The formula $\\delta(h_{\\varphi})=-\\Delta_g d \\varphi + r_g^{ij}\nabla_j \\varphi$ used for $h_\\varphi = \nabla_g d\\varphi$ is incorrect. The correct formula for the divergence of the 2-tensor $\nabla_g d\\varphi$ is $(\\delta(\nabla_g d\\varphi))_i = \nabla^j (\nabla_j \nabla_i \\varphi) = (\\Delta_g d\\varphi)_i$."
      },
      {
        "Problem": "Incorrect formula for the second divergence of a Hessian.",
        "Location": "Proof of Lemma 1.",
        "Explanation": "The expression $\\Delta_g^2 \\varphi + r_g\\cdot \nabla \nabla \\varphi +\frac{1}{2}(\nabla_g s_g,\nabla_g \\varphi)$ is claimed to be equal to $-\\delta\\delta(h_\\varphi) = -\\delta(\\delta(\nabla_g d\\varphi))$, which is incorrect. The operator $\\delta(\\delta(\nabla_g d\\varphi))$ is $\nabla^k \nabla^j (\nabla_j \nabla_k \\varphi)$."
      },
      {
        "Problem": "Unjustified equality in the variation calculation.",
        "Location": "Proof of Lemma 1, calculation lines 2 and 3.",
        "Explanation": "The equality between the variation of the functional $\\int s_g^2 d\\mu_g$ in the direction $h_\\varphi = \nabla_g d\\varphi$ (given by the first line) and the integral expressions in the second and third lines is not justified by standard tensor calculus identities and appears incorrect."
      },
      {
        "Problem": "Incorrect identity for the adjoint of the Hessian operator.",
        "Location": "Proof of Lemma 1, calculation line 3.",
        "Explanation": "The identity $(\nabla_g d)^{*}(\nabla_g d) \\varphi = \\Delta^2_g \\varphi + r_g \\cdot \nabla \nabla \\varphi + \frac{1}{2}(\nabla_g s_g,\nabla_g \\varphi)_g$ is not a standard identity and appears incorrect. The operator $(\nabla_g d)^{*}(\nabla_g d)$ is $\\delta(\\delta(\nabla_g d\\varphi))$."
      },
      {
        "Problem": "The proof that the scalar curvature is constant is invalid.",
        "Location": "Lemma 1.",
        "Explanation": "The proof of Lemma 1 relies on several incorrect tensor identities and unjustified equalities in the calculation involving variations in the direction of Hessians. Consequently, the conclusion that the scalar curvature of a critical metric must be constant is not proven, which invalidates the subsequent derivation of the main result in Theorem 3."
      }
    ],
    "token_usage": {
      "input": 8729,
      "thinking": 9368,
      "output": 654
    }
  },
  {
    "entry_id": 222,
    "retraction_id": "1806.06939v2",
    "paper_id": "1806.06939v1",
    "retraction_comment": "The objective in (8) allows for trivial solutions e.g. the prior",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between Assumed Observation Model and Loss Function",
        "Location": "Section 3.2, Section 3.3",
        "Explanation": "The paper assumes a pixel-wise Gaussian distribution for pre-softmax outputs to model observation uncertainty. However, the training objective uses an L1 loss on these outputs, which is not the negative log-likelihood of the assumed Gaussian distribution. This fundamental mismatch between the probabilistic model and the loss function means the model is not trained to maximize the likelihood under the stated assumptions, undermining the theoretical basis for learning uncertainty."
      },
      {
        "Problem": "Unsound Derivation of Importance Sampling Objective",
        "Location": "Section 3.3, Appendix A",
        "Explanation": "The derivation of the importance sampling based training objective relies on an inequality (e.g., $\\int q \\log p \\leq \\int \\log(qp)$) that appears mathematically incorrect for general distributions $q$ and $p$. This flaw in the theoretical derivation weakens the justification for the proposed training method and the resulting optimization objective."
      },
      {
        "Problem": "Impractical Recognition Network Output Size",
        "Location": "Section 3.3, Section 3.4, Appendix C",
        "Explanation": "The recognition network is designed to predict a Bernoulli probability for every single weight parameter in the generative model. This results in an output tensor size proportional to the total number of weights, which is extremely large for typical deep neural networks. This design choice raises significant concerns about the computational feasibility, memory requirements, and scalability of the recognition network and the overall training process for larger models."
      },
      {
        "Problem": "Inconsistent Probabilistic Output and Evaluation",
        "Location": "Section 3.2, Section 4",
        "Explanation": "While the model predicts parameters for a distribution over pre-softmax outputs (assumed Gaussian), the final output used for prediction and evaluation (e.g., mIoU, CLL) is a categorical distribution obtained after applying softmax. The theoretical framework and loss function do not fully account for the transformation from the assumed pre-softmax distribution to the final categorical output, leading to an inconsistent probabilistic interpretation and evaluation of the model's uncertainty."
      }
    ],
    "token_usage": {
      "input": 17999,
      "thinking": 8051,
      "output": 490
    }
  },
  {
    "entry_id": 223,
    "retraction_id": "1310.8031v2",
    "paper_id": "1310.8031v1",
    "retraction_comment": "The solution for the NS equations provided can only be constant or very small magnitude",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed derivation of the nonlinear term bound in the energy estimate.",
        "Location": "Lemma 4, equations (30)-(36)",
        "Explanation": "The decomposition of the nonlinear term b(u,u,Δ^r u) into terms like (30) and (31) is non-standard and appears incorrect based on derivative counts. The subsequent inequalities (33), (34), (35), and (36) used to bound these terms contain errors, particularly the interpolation inequalities in (34) which use incorrect exponents. This invalidates the crucial energy estimate (27)."
      },
      {
        "Problem": "Incorrect exponent in the nonlinear term bound.",
        "Location": "Equation (27), (40), (41)",
        "Explanation": "The exponent 1 + 4r/(2r-1) = (6r-1)/(2r-1) on ||u(t)||_r in the nonlinear term bound in (27) appears incorrect. For r=1, this exponent is 5, whereas standard estimates for the H^1 norm yield a bound involving ||u||_1^4. This error propagates through the subsequent analysis of the ODE for ||u||_r^2."
      },
      {
        "Problem": "Unjustified claim of global existence time for smooth initial data.",
        "Location": "Equation (43) and Proposal 5",
        "Explanation": "The analysis of the finite time T in (43) derived from the ODE for ||u||_r^2 shows that T depends on r, the constant c_r from the nonlinear estimate, and the initial norm ||u_0||_r. The claim that T approaches infinity as r approaches infinity for general smooth initial data (u_0 in H^∞) is not justified. The constant c_r typically grows rapidly with r, and the norms ||u_0||_r for a non-analytic smooth function also grow rapidly. The argument does not demonstrate that the growth of λ_1^((r-1)/2) is sufficient to overcome these growths, which is generally not the case for non-analytic data. This invalidates the conclusion of global existence for smooth solutions."
      },
      {
        "Problem": "Ambiguous or overly strong assumption on initial data smoothness.",
        "Location": "Proposal 5, condition (38)",
        "Explanation": "The condition sup_{k<∞} ||u_0||_k = K_3 < ∞ is stated for 'smooth initial data'. If 'smooth' means C^∞ or H^∞, this condition implies that the sequence of H^k norms is uniformly bounded, which is equivalent to the initial data being analytic. If the proof relies on this stronger condition (analyticity), it should be stated clearly, and the result (global existence for analytic data) is already known. If 'smooth' means H^∞ without the uniform bound, then the subsequent argument for global existence is flawed (as per the previous problem)."
      }
    ],
    "token_usage": {
      "input": 2704,
      "thinking": 13800,
      "output": 673
    }
  },
  {
    "entry_id": 224,
    "retraction_id": "0904.3516v4",
    "paper_id": "0904.3516v3",
    "retraction_comment": "This paper has been withdrawn by the authors. The present version has several results that are correct, but, there is a problem in the use of sections 7 and 8 to derive generic properties for the set of analytic potentials g. All sections before this are OK",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect identification of deviation functions in the formula for the calibrated subaction.",
        "Location": "Section 5, after Corollary 5.3; Section 6, beginning.",
        "Explanation": "The calibrated subaction $V(x)$ is expressed as the supremum $V(x) = \\sup_w [H_\\infty(w,x) - I^*(w)]$. Here, $H_\\infty$ is the limit of scaled involution kernels for $\\beta_n A$, and is an involution kernel for $A=\\log g$. The deviation function $I^*$ is defined based on the dual potential $A^*=\\log g^*$. However, the correct formula for $V(x)$ derived from the zero-temperature limit should involve the deviation function $I_\\infty^*$ of the dual potential $A_\\infty^*$ associated with the limit kernel $H_\\infty$. The paper does not show that $I^* = I_\\infty^*$, which is a critical assumption for the subsequent arguments regarding the structure of the optimal set $w_x$."
      },
      {
        "Problem": "Inconsistent definition and use of the function W.",
        "Location": "Section 5, after Proposition 5.4; Section 6, beginning.",
        "Explanation": "The function $W$ is defined as $W(w,x) = H_\\infty(w,x) - V^*(w)$, where $V^*$ is a calibrated subaction for $A^*$. The formula for $V(x)$ is then written as $V(x) = \\sup_w [W(w,x) - V^*(w) - I^*(w)]$. This formula is only valid if $W$ is an involution kernel for $A_\\infty^*$, $V^*$ is a calibrated subaction for $A_\\infty^*$, and $I^*$ is the deviation function for $A_\\infty^*$. The paper uses $H_\\infty$ as the involution kernel for $A_\\infty^*$, but uses $V^*$ and $I^*$ associated with $A^*$. The definition of $W$ and its subsequent use in the supremum formula for $V(x)$ are inconsistent with the standard theory and the derivation of $H_\\infty$ from the zero-temperature limit."
      },
      {
        "Problem": "The property 'R* is good for A*' is applied to the wrong deviation function.",
        "Location": "Section 6, discussion about $I^*(w)<K$ and the set of optimal $w_x$.",
        "Explanation": "The argument that the set of optimal $w_x$ (the maximizers of $H_\\infty(w,x) - I^*(w)$) is finite relies on the property that $I^*(w)<\\infty$ implies $w$ is in the pre-orbit of the support of the maximizing measure for $A^*$. This property, termed 'R* is good for A*', is proven for generic $A$ in Theorem 8.2. However, the formula for $V(x)$ involves the deviation function $I_\\infty^*$ for the limit dual potential $A_\\infty^*$, not $I^*$ for $A^*$. The property 'R* is good for A*' (meaning $R_{A^*}(w)>0$ for $w$ not in the pre-orbit of $\\text{supp}(\\mu_{A^*})$) does not automatically transfer to $A_\\infty^*$ and $I_\\infty^*$, which is necessary for the argument to hold."
      },
      {
        "Problem": "The genericity result (Theorem 8.2) does not establish the necessary link between A* and A_infinity*.",
        "Location": "Section 6, Theorem 6.2; Section 8, Theorem 8.2.",
        "Explanation": "Theorem 8.2 proves that for a generic potential $A$, its dual $A^*$ satisfies the property that its deviation function is strictly positive outside the pre-orbit of the support of the maximizing measure. This property ('R* is good for A*') is used in Section 6 to argue for the finiteness of the set of optimal $w_x$. However, the formula for $V(x)$ involves the deviation function of the limit dual potential $A_\\infty^*$, not $A^*$. The genericity result does not establish a relationship between the properties of $A^*$ and $A_\\infty^*$ that would justify applying the 'R* is good for A*' property to the deviation function $I_\\infty^*$."
      }
    ],
    "token_usage": {
      "input": 67159,
      "thinking": 9154,
      "output": 1010
    }
  },
  {
    "entry_id": 225,
    "retraction_id": "1509.01802v3",
    "paper_id": "1509.01802v2",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equations 22 and 23",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect evaluation of the 7-gluon amplitude term 'c' in the DPI limit.",
        "Location": "Section 2.3.1, Eq. (22)-(25)",
        "Explanation": "The calculation of the amplitude term 'c' in the limit relevant for DPI assumes that the intermediate momenta P345 and P671 are proportional to p2 (collinear). This assumption is not generally valid in the double-pole limit P345^2 -> 0, P671^2 -> 0, which is the source of the singularity potentially contributing to DPI. The calculation incorrectly concludes the term is finite and small in this limit."
      },
      {
        "Problem": "Unsound conclusion regarding the enhancement of term 'c' in the DPI configuration.",
        "Location": "Section 3 (Concluding discussion)",
        "Explanation": "The conclusion that the term 'c' of the 7-gluon amplitude is not enhanced in the pairwise back-to-back configuration typical of DPIs is based on the flawed calculation presented in Section 2.3.1. The term 'c' has a double-pole structure (1/(P345^2 P671^2)) which is expected to provide enhancement in the DPI limit where P345^2 and P671^2 are small."
      },
      {
        "Problem": "Conflation of double-pole limit with a specific collinear limit.",
        "Location": "Section 2.3.1 and Section 3",
        "Explanation": "The analysis incorrectly treats the double-pole limit (P345^2 -> 0, P671^2 -> 0) as equivalent to a specific collinear limit (P345 proportional to p2, P671 proportional to p2) for the purpose of evaluating the amplitude's numerator and other factors. The behavior of the amplitude near a double pole involves a more general factorization structure than the simplified collinear evaluation performed."
      },
      {
        "Problem": "Main conclusion regarding DPI contribution is invalidated.",
        "Location": "Section 3 (Concluding discussion)",
        "Explanation": "The paper's main conclusion, that the analyzed 7-gluon tree-level amplitude does not provide a significant contribution to DPIs, is directly dependent on the flawed analysis of term 'c'. A correct evaluation of the amplitude's behavior in the double-pole limit is necessary to draw a valid conclusion about its potential contribution to DPI."
      }
    ],
    "token_usage": {
      "input": 13061,
      "thinking": 8523,
      "output": 559
    }
  },
  {
    "entry_id": 226,
    "retraction_id": "2312.05804v3",
    "paper_id": "2312.05804v2",
    "retraction_comment": "Error in the derivation of equation 11 in section 4.3.1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect formulation of the body-clothing matching loss.",
        "Location": "Section 4.3.2, Equation (12)",
        "Explanation": "The loss function aims to make the body mesh mask equal to the sum of the NeRF clothing mask and the prior clothing mesh mask. This objective is mathematically unsound for achieving the stated goal of fitting the body *inside* the clothing. A correct formulation would typically involve ensuring the body surface is contained within the clothing volume or minimizing penetration."
      },
      {
        "Problem": "Ill-defined comparison in the semantic confidence loss.",
        "Location": "Section 4.3.1, Equation (11)",
        "Explanation": "The loss compares a 3D integrated semantic confidence value along a ray with a 2D semantic feature from a single rendered image. The paper does not clearly define how the 2D feature is mapped or aggregated for comparison with the 3D volumetric integral along the ray, introducing ambiguity and potential errors in the semantic optimization process."
      },
      {
        "Problem": "Absence of collision detection and handling.",
        "Location": "Section 6 (Limitations)",
        "Explanation": "While acknowledged as a limitation, the lack of collision detection between the body and clothing layers is a critical issue for a 'physically-decoupled' model. Without it, interpenetration can occur, leading to unnatural and physically implausible results, especially for complex poses or tight garments, undermining the realism and structural integrity of the layered generation."
      }
    ],
    "token_usage": {
      "input": 24931,
      "thinking": 3406,
      "output": 338
    }
  },
  {
    "entry_id": 227,
    "retraction_id": "1401.1766v5",
    "paper_id": "1401.1766v4",
    "retraction_comment": "This paper has been withdrawn by the author due to errors in figure 1",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Subjective evaluation lacks rigor and standard metrics.",
        "Location": "Results section, page 15-17",
        "Explanation": "The performance evaluation relies on a subjective comparison by 20 graduate students using arbitrary criteria for categorization (e.g., 25% difference threshold). Standard information retrieval evaluation metrics (like Precision, Recall, NDCG) based on ground truth relevance judgments are not used, making the claims of superiority less convincing and the results difficult to reproduce or compare objectively."
      },
      {
        "Problem": "Details of user intention discovery and re-ranking are underspecified.",
        "Location": "Methods section, page 11, Figure 1, Figure 4",
        "Explanation": "A key claimed innovation is the re-ranking of results based on user-selected articles to determine 'true search intention' and calculate 'semantic similarities'. However, the specific methods for extracting key concepts from selected articles, forming the 'additional query', and calculating semantic similarity for re-ranking are not described in sufficient detail, making this core component difficult to evaluate or reproduce."
      },
      {
        "Problem": "IDF calculation for query expansion uses a potentially biased corpus.",
        "Location": "Methods section, page 10",
        "Explanation": "The Inverse Document Frequency (IDF) values used to re-rank concepts for query expansion are calculated using the OHSUMED dataset (a clinically-oriented subset of MEDLINE) instead of the entire MEDLINE database being searched. This could lead to IDF values that are not representative of the full corpus, potentially biasing the concept weighting and query expansion process."
      },
      {
        "Problem": "Query expansion weighting parameter description is confusing or incorrect.",
        "Location": "Methods section, page 10, formula (3)",
        "Explanation": "The formula for weighting concepts for query expansion includes a tuning parameter γ∈[0,1]. The description states it is 'used to increase the p₁ by decreasing γ'. If γ is in [0,1], raising p₁ (a probability) to the power of γ would increase p₁ only if γ < 1, and the phrase 'by decreasing γ' is unclear in this context. The specific value of γ used in experiments is also not provided, hindering reproducibility."
      },
      {
        "Problem": "Fairness of PubMed comparison regarding query interpretation is unclear.",
        "Location": "Results section, page 17-18",
        "Explanation": "The paper highlights PubMed's difficulty with natural language queries (like #17) due to assuming 'AND' operators. While this points to a potential usability issue for novice users, it's unclear how queries were submitted to PubMed in the evaluation (e.g., raw natural language vs. optimized Boolean queries). If raw natural language was used, the comparison might be biased against PubMed's capabilities when used effectively by experienced users or with better query formulation."
      }
    ],
    "token_usage": {
      "input": 6574,
      "thinking": 2202,
      "output": 643
    }
  },
  {
    "entry_id": 228,
    "retraction_id": "2011.03931v2",
    "paper_id": "2011.03931v1",
    "retraction_comment": "There is a error in the experimental EBSD map of albite due to pseudosymmetry. The two parts A and B are actually linked by a 180_ rotation around b-axis. The theory remains valid to my point of view, but the EBSD map of albite cannot be used as an \"experimental proof\". I would like to apologize to the readers of the first versions deposited on Arxiv",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Lack of fundamental physical criterion for 'slight distortion'",
        "Location": "§3.1, §3.2, §4.3, §4.4, §6",
        "Explanation": "The core concept of heteroplane and heterotwin relies on a 'slight distortion' between reticular planes/directions. This is quantified by arbitrary tolerances on length/angle differences and a generalized strain sg. The paper lacks a fundamental physical criterion (e.g., based on energy) for what constitutes a 'slight' distortion that can form a stable twin interface, making the definition and ranking somewhat arbitrary."
      },
      {
        "Problem": "Unjustified hypothesis about intraplanar accommodation",
        "Location": "§3.1, §6, §7",
        "Explanation": "The theory hypothesizes that the distortion associated with the heteroplane is accommodated within the interface or a delocalized zone. This is a critical assumption for the heteroplane to be the composition plane, departing from classical theory. However, the paper does not provide a physical mechanism or energetic justification for this accommodation process."
      },
      {
        "Problem": "Reliance on generalized strain (sg) as the sole predictor of twin likelihood",
        "Location": "§4.4, §6, §7",
        "Explanation": "The theory ranks predicted heterotwins based solely on the generalized strain sg, a purely geometric measure. This ignores the crucial role of the atomic motif, shuffling, and energy barriers, which are essential for twin formation. The fact that some low-sg predictions are not observed, and the authors acknowledge this limitation, weakens the predictive power regarding which twins will actually form."
      },
      {
        "Problem": "Arbitrary choice of tolerances in the search algorithm",
        "Location": "§3.1, §3.2, §4.4",
        "Explanation": "The algorithm for identifying potential heteroplanes depends on arbitrary tolerance values for the difference in length and angle between reticular directions. The resulting list of predicted heterotwins is sensitive to these chosen values, and the paper does not provide a rigorous justification for these specific tolerances, introducing an element of arbitrariness into the prediction process."
      }
    ],
    "token_usage": {
      "input": 12766,
      "thinking": 3444,
      "output": 487
    }
  },
  {
    "entry_id": 229,
    "retraction_id": "1501.02643v7",
    "paper_id": "1501.02643v6",
    "retraction_comment": "This article has been withdrawn due to error in Eq. 8",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unjustified mapping to pseudo-spin Hamiltonian and interaction form.",
        "Location": "Eq. 11a and surrounding text in \"Spin Hall Effect\" section.",
        "Explanation": "The step from the physical SMM + s-d interaction (Eq. 8, 10) to the simplified pseudo-spin model (Eq. 11a) is not rigorously derived or justified. The SMM spin $\\boldsymbol{\\mathcal{S}}$ is a large spin operator, and the interaction $\\boldsymbol{\\mathcal{S}}\\cdot\\boldsymbol{\\sigma}$ is complex. Representing the SMM by a pseudo-spin $\\boldsymbol{\\tau}$ and the interaction as $-\\lambda\\tau_z\\sigma_z$ is a strong, unmotivated approximation that likely does not capture the physics of the original system. The derivation of Eq. 11a from the physical Hamiltonians is missing, making the model's foundation unsound."
      },
      {
        "Problem": "Inconsistent treatment of the SMM tunneling term ($\\Delta_x \\tau_x$).",
        "Location": "Calculation of Hall conductivity in \"Spin Hall Effect\" section, specifically using Eq. 13.",
        "Explanation": "The calculation of the quantized Hall conductivity (Eq. 15-19) is performed using Hamiltonians (Eq. 13) that omit the SMM tunneling term $\\Delta_x \\tau_x$. This term is present in the assumed effective Hamiltonian (Eq. 11a) and is later discussed in the \"Effects of Tunneling\" section. The conclusion about the quantized spin Hall effect relies on a calculation performed on a simplified Hamiltonian where the pseudo-spin $\\tau_z$ is conserved, while the full model Hamiltonian breaks this conservation. This inconsistency invalidates the claim of a quantized spin Hall effect based on this calculation."
      },
      {
        "Problem": "Ambiguity of the pseudo-spin basis and its relation to the combined system.",
        "Location": "Introduction of $\\tau_x, \\tau_z$ in Eq. 11a.",
        "Explanation": "The pseudo-spin $\\boldsymbol{\\tau}$ is introduced without clearly defining the basis it acts upon in the combined electron-SMM Hilbert space. The Hamiltonian (Eq. 11a) is written as if it acts on a tensor product space of electron spin ($\\sigma$) and SMM pseudo-spin ($\\tau$). However, the pseudo-spin $\\tau$ is supposed to represent the SMM's internal state (e.g., tunneling between two low-energy levels). It is unclear how the electron degrees of freedom are coupled to this SMM pseudo-spin space in a consistent manner, especially starting from the s-d interaction $\\boldsymbol{\\mathcal{S}}\\cdot\\boldsymbol{\\sigma}$. This lack of a clear definition for the Hilbert space and operators makes the model formulation ambiguous."
      }
    ],
    "token_usage": {
      "input": 10585,
      "thinking": 3043,
      "output": 645
    }
  },
  {
    "entry_id": 230,
    "retraction_id": "1903.02670v2",
    "paper_id": "1903.02670v1",
    "retraction_comment": "We can not use fixed-point theorem in the spaces defined in section 4.",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Mismatch between stated equations and analytical methods",
        "Location": "Introduction (Equations 1, 2), Section 2 (Definition of semigroup and symbol), Proofs in Sections 2, 3, 4, 6",
        "Explanation": "The linear part of the equations (1) and (2) as written is associated with the Fourier symbol $\\xi^2 + \\mu (1+\\xi^2)^{-1/2}$. This symbol is always positive for $\\mu>0$, implying linear ill-posedness in Sobolev spaces due to exponential growth of solutions. The analytical framework used throughout the paper (e.g., estimates based on the decay of $e^{t\\Phi(\\xi)}$ for large $\\xi$) relies on a semigroup defined by the symbol $\\Phi(\\xi)=-\\xi^2 + \\mu (1+\\xi^2)^{-1/2}$, which exhibits the high-frequency damping ($-\\xi^2$) necessary for well-posedness in these spaces. This fundamental mismatch means the well-posedness theorems (Theorems 1.1-1.5) cannot hold for the stated equations."
      },
      {
        "Problem": "Inconsistent definition and derivation of the studied equation",
        "Location": "Introduction (Equations 1, 2, 3), Section 2 (Definition of $\\Phi(\\xi)$)",
        "Explanation": "The paper presents equations (1) and (2) in the introduction. It then provides a derivation from a physical model (3), which results in a linear part different from (1) and (2). Furthermore, the symbol $\\Phi(\\xi)=-\\xi^2 + \\mu (1+\\xi^2)^{-1/2}$ used for the semigroup in the proofs corresponds to a linear operator ($-\\partial_x^2 + \\mu (1-\\partial_x^2)^{-1/2}$) which is different from the linear parts in both (1), (2) and (3). This inconsistency makes it unclear which equation is actually being studied and whether the results apply to any specific or physically derived model."
      },
      {
        "Problem": "Potential error in the ill-posedness proof for equation (2)",
        "Location": "Proof of Theorem 1.6",
        "Explanation": "The calculation for the second Fréchet derivative of the flow map for equation (2) involves two main terms (corresponding to $v_1 \\partial_x v_2$ and $v_2 \\partial_x v_1$). Using the chosen test functions and approximating the terms for large $N$, the Fourier transforms of these two terms appear to cancel each other out. This suggests a potential error in the calculation, which would invalidate the proof of Theorem 1.6, which claims the flow-map is not $C^2$ at the origin for $s<-1/2$."
      }
    ],
    "token_usage": {
      "input": 27901,
      "thinking": 30206,
      "output": 635
    }
  },
  {
    "entry_id": 231,
    "retraction_id": "1408.0367v2",
    "paper_id": "1408.0367v1",
    "retraction_comment": "This paper has been withdrawn by the author. The paper only considers the omega>k regime, but the undamped modes have omega<k",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect mode equation in radiation era",
        "Location": "Section 3.2, equation $u''+(a\\sigma)u'+k^2u+(am_A)^2u=0$",
        "Explanation": "The mode equation for vector potential fluctuations in conformal time in the radiation era should include a term proportional to $u'$ arising from the expansion ($3Ha - a'/a$). For radiation ($a \\propto \\eta$), this term is $2/\\eta$. The equation used in the paper is missing this crucial time-dependent coefficient, which affects the mode solutions and decay rates."
      },
      {
        "Problem": "Inconsistent calculation and interpretation of decay rates",
        "Location": "Section 3.2, text following equation (\\ref{peq}), and equation (\\ref{rm})",
        "Explanation": "The paper calculates the decay rates $p_1, p_2$ from the characteristic equation of the mode equation. However, the resulting expressions ($p_1 \\approx a m_A^2/\\sigma \\sim e^4 aT$ and $p_2 \\approx a\\sigma \\sim e^{-2} aT$) are not constant in conformal time $\\eta$ (since $a \\propto \\eta$), while the assumed exponential solutions $e^{-p(\\eta-\\eta_r)}$ imply constant decay rates $p$. Furthermore, the calculated values do not match the constant decay rates ($e^2(k^2+e^2)$ and $e^{-2}$) obtained from the characteristic equation if the coefficients $a\\sigma$ and $(am_A)^2$ (or $a^2m_A^2$) are treated as constant in $\\eta$. This indicates a fundamental error in calculating or interpreting the decay rates."
      },
      {
        "Problem": "Unjustified approximation for sourced magnetic field power spectrum",
        "Location": "Section 4, equation (\\ref{pbs}) and the preceding text",
        "Explanation": "The formula for the sourced magnetic field power spectrum $P_B$ is presented as an approximation derived from the Schwinger-Dyson equation $G_S=G_R\\Pi_SG_A$. However, the derivation from the integral expression (\\ref{rsa}) is not provided, and the resulting formula (\\ref{pbs}) appears to be a simplified form that does not rigorously follow from the integral involving the time-dependent Green functions and source term. This approximation lacks justification and may lead to incorrect conclusions about the magnitude and time evolution of the sourced fluctuations."
      },
      {
        "Problem": "Unjustified exponential decay of scalar modes",
        "Location": "Section 4.1 and 4.2, text discussing scalar modes $v$",
        "Explanation": "The paper claims that charged scalar modes decay exponentially in the radiation era due to damping $\\sigma_\\phi$. However, the relevant mode equation $v'' + (2/\\eta + a\\sigma_\\phi) v' + (k^2 + a^2m_\\phi^2) v = 0$ has a time-dependent coefficient $2/\\eta$. Assuming simple exponential solutions $e^{-p\\eta}$ with constant $p$ is not generally valid for such equations, especially for modes that are not deep inside the horizon. The claim of exponential decay with a specific rate ($e^4T/H$) is not properly derived from solving this time-dependent ODE. This affects the calculation of the current source term $\\Pi_S^T$ and the resulting sourced magnetic fields."
      }
    ],
    "token_usage": {
      "input": 7233,
      "thinking": 9829,
      "output": 787
    }
  },
  {
    "entry_id": 232,
    "retraction_id": "1809.01643v2",
    "paper_id": "1809.01643v1",
    "retraction_comment": "Error in proof for efficiency bound. Variation of time variable is not taken into account",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect Semiparametric Identification Formula",
        "Location": "Lemma 1, Proof of Lemma 1 (Appendix A.1)",
        "Explanation": "The formula derived for ATET(1) in Lemma 1 appears incorrect. The proof calculates a conditional expectation that does not equal the standard conditional DiD identification formula, which is stated correctly in equation (2). The subsequent steps in the proof rely on this incorrect equality, leading to a flawed identification result."
      },
      {
        "Problem": "Incorrect Semiparametric Estimator",
        "Location": "Section 2.2, Equation (3), Theorem 1",
        "Explanation": "The proposed semiparametric estimator is directly based on the incorrect identification formula presented in Lemma 1. As the target parameter formula is incorrect, the estimator is likely inconsistent for the true Average Treatment Effect on the Treated (ATET)."
      },
      {
        "Problem": "Incorrect Semiparametric Efficiency Bound",
        "Location": "Theorem 1, Proof of Theorem 1 (Appendix A.2)",
        "Explanation": "The semiparametric efficiency bound derived in the proof of Theorem 1 is based on moment conditions that are formulated using the incorrect identification formula from Lemma 1. Consequently, the derived bound is not the correct efficiency bound for the true ATET(1)."
      },
      {
        "Problem": "Misunderstanding of Linear DiD Model and Flawed Linear Estimator",
        "Location": "Section 2.3, Assumption 9, Lemma 2, Theorem 2, Equation (4)",
        "Explanation": "The paper incorrectly states that including a treatment-time interaction term in the linear model violates the common trend assumption. This interaction term is standard and its coefficient identifies the DiD effect under the common trend assumption. The proposed linear estimation procedure, which estimates coefficients from regressions within each time period and takes their difference, does not correspond to estimating the DiD effect (the difference in time trends, $\beta_1^1 - \beta_1^0$) in the specified linear potential outcome model. This procedure is likely inconsistent for the ATET."
      },
      {
        "Problem": "Unreliable Application Results",
        "Location": "Section 4, Table 1, Figure 1",
        "Explanation": "The empirical application uses the proposed semiparametric and linear estimators. Given the fundamental errors in the theoretical derivation and estimation procedures for both methods, the results presented in the application are likely unreliable and cannot be used to draw valid conclusions about the effect of the employment protection reform."
      }
    ],
    "token_usage": {
      "input": 21906,
      "thinking": 13181,
      "output": 569
    }
  },
  {
    "entry_id": 233,
    "retraction_id": "1203.2581v2",
    "paper_id": "1203.2581v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 2",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Ambiguous definition of pairing interactions and form factors",
        "Location": "Section 'We now turn to discuss...', Eq. 3, and text describing form factors",
        "Explanation": "The paper lists multiple possible form factors for each phenomenological interaction ($V_1, V_2, V_\\bot$) but the BCS equations (Eq. 3) imply a single form factor per interaction type. The mapping from the interactions to the specific symmetry channels discussed (e.g., $S_{x^2+y^2}$, $d_{x^2-y^2}$) is not clearly defined, leading to ambiguity in the model."
      },
      {
        "Problem": "Inconsistent association of form factors with symmetry labels",
        "Location": "Fig. 3(b), Eq. 4, Fig. 4",
        "Explanation": "The paper uses $\\cos k_x \\cos k_y$ as the form factor for the $S_{x^2+y^2}$ symmetry (implied by Fig. 3(b) label and Eq. 4 form), while this form factor is typically associated with $S_{x^2y^2}$ or $d_{x^2-y^2}$ symmetries. This fundamental inconsistency undermines the interpretation of the phase diagram and the resulting gap structures."
      },
      {
        "Problem": "Unusual and unjustified interlayer form factor",
        "Location": "Section 'The corresponding pairing symmetry factors...', Eq. 3",
        "Explanation": "The form factor $\\cos k_z/2$ is listed as a possible interlayer pairing symmetry factor. This functional form is non-standard for interlayer coupling in layered materials and lacks physical justification within common theoretical frameworks."
      },
      {
        "Problem": "Contradiction between phase diagram symmetry label and explicit gap form",
        "Location": "Fig. 4, Eq. 4, Fig. 5",
        "Explanation": "The phase diagram (Fig. 4) identifies an $S_{x^2+y^2}+S_{z^2}$ phase. However, the explicit form of the gap presented for this phase (Eq. 4) uses $\\cos k_x \\cos k_y$ for the intralayer component, which is inconsistent with the $S_{x^2+y^2}$ symmetry label. This contradiction invalidates the interpretation of the nodal structure derived from Eq. 4 as belonging to the claimed $S_{x^2+y^2}+S_{z^2}$ state."
      }
    ],
    "token_usage": {
      "input": 8240,
      "thinking": 3826,
      "output": 570
    }
  },
  {
    "entry_id": 234,
    "retraction_id": "1912.11842v3",
    "paper_id": "1912.11842v2",
    "retraction_comment": "There is a serious mistake in the section 4 in this paper. The paper concludes that there is new particle production in the system due to the plasma oscillation. However, the fact that the imaginary part of the self-energy will always be zero in the nonrelativistic limit indicates no new particle created",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect TFD interaction and field decomposition",
        "Location": "Section II.B, Eq. 19a, Eqs. 26c-26h",
        "Explanation": "The decomposition of fields into background and fluctuation components and the resulting interaction Lagrangian and Feynman rules do not follow the standard Thermo Field Dynamics (TFD) procedure of doubling the Lagrangian (L - \\tilde{L}). This leads to non-standard interaction vertices (Eqs. 26g, 26h) that appear to only couple within physical or tilde sectors, potentially missing crucial thermal mixing effects inherent in TFD."
      },
      {
        "Problem": "Unjustified 'classical limit' approximation and arbitrary background field relation",
        "Location": "Section III.A.1, Eqs. 58a-61a, Eq. 71b",
        "Explanation": "The assumption that statistical averages of full quantum fields can be approximated by products of classical background fields (Eqs. 58a-61a) neglects quantum and thermal fluctuations of the fields. Furthermore, the claim that the classical background fields must satisfy \\psi_0(x)=\\tilde{\\psi}_0(x) (Eq. 71b) is arbitrary and lacks theoretical justification within the TFD framework. These assumptions critically affect the calculation of the background polarization tensor."
      },
      {
        "Problem": "Violation of gauge invariance (Ward Identity)",
        "Location": "Section III.A.3, Eq. 103a",
        "Explanation": "The calculated background polarization tensor (Eq. 103a) is proportional to the metric tensor g^{\\mu\\nu}, which violates the Ward identity k_\\mu \\Pi^{\\mu\\nu}(k)=0 for k^2 \\neq 0. This identity is a fundamental consequence of gauge invariance and should hold for the polarization tensor derived from a gauge-invariant theory. Its violation indicates a fundamental error in the calculation or the theoretical formulation."
      },
      {
        "Problem": "Vacuum polarization calculated at zero temperature",
        "Location": "Section III.B, Eq. 115b, Eq. 116a",
        "Explanation": "The vacuum polarization tensor, a necessary component in a finite-temperature theory, is calculated using zero-temperature Feynman rules (Eq. 115b, 116a) resulting in the standard zero-temperature vacuum polarization (Eq. 116a). This ignores the temperature dependence that should arise from using the temperature-dependent TFD propagators, contradicting the paper's stated goal of developing a finite-temperature theory."
      },
      {
        "Problem": "Incorrect derivation of dispersion relations from the determinant condition",
        "Location": "Section II.D, Eq. 50a, Section IV, Eq. 117a, Eqs. 118a, 119a",
        "Explanation": "The collective mode dispersion relations should be derived from the determinant of the full 8x8 matrix in Lorentz and TFD space (Eq. 50a). The derivation presented uses a 4x4 matrix (Eq. 117a) and simplifies the determinant condition into two separate equations (Eqs. 118a, 119a) in an unjustified manner. This leads to incorrect dispersion relations for the collective modes of the doubled system."
      }
    ],
    "token_usage": {
      "input": 38759,
      "thinking": 6554,
      "output": 759
    }
  },
  {
    "entry_id": 235,
    "retraction_id": "2212.07368v2",
    "paper_id": "2212.07368v1",
    "retraction_comment": "There is an error in the use of Corollary 1 in our Paper, which does not apply in our case",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound application of robust regression due to mischaracterization of MM-estimator robustness to regressor errors.",
        "Location": "Section 4, Step 2 - Shuffled Regression; Section 5.3, Known versus Estimated Support",
        "Explanation": "The paper claims that MM-estimators are robust to errors in the regressors (the estimated sensing matrix $\\hat{\boldsymbol{A}}$). However, standard robust statistics literature indicates that MM-estimators are primarily designed for robustness against outliers in the response variable, not leverage points (outliers in the design matrix/regressors). Using an MM-estimator with an estimated and potentially erroneous $\\hat{\boldsymbol{A}}$ without accounting for errors in the regressors is an unsound application of the method and undermines the justification for this step."
      },
      {
        "Problem": "Lack of theoretical convergence guarantees for the iterative optimization algorithm.",
        "Location": "Section 4, Step 2 - Shuffled Regression; Algorithm 1",
        "Explanation": "The proposed two-step approach involves an iterative alternating minimization scheme (Algorithm 1) to solve a non-convex problem (due to the binary permutation constraint and potentially the robust loss function). The paper does not provide theoretical guarantees that this iterative process converges to the global optimum or even a desirable local optimum. The reliance on running for a fixed number of iterations and selecting the best result is a heuristic that lacks theoretical backing for finding the correct solution, especially under challenging conditions."
      },
      {
        "Problem": "Sensitivity to errors in the initial support estimation from noisy data.",
        "Location": "Section 4, Step 1 - Estimating Support; Remark after Eq 4; Theorem 1; Section 5.3, Known versus Estimated Support",
        "Explanation": "The theoretical uniqueness result (Theorem 1) is established for noiseless data and assumes perfect recovery of the support of the sum signal $\boldsymbol{x}_\\Sigma$. In the practical algorithm, this support is estimated from noisy measurements $\tilde{\boldsymbol{y}}_\\Sigma$. Errors in this initial estimation step directly affect the accuracy of the estimated sensing matrix $\\hat{\boldsymbol{A}}$, which is a critical input to the subsequent robust regression step. While the paper acknowledges error propagation, the impact of these initial estimation errors on the overall performance and the validity of the subsequent steps in the presence of noise is a significant practical challenge that is not fully addressed by the noiseless theory."
      }
    ],
    "token_usage": {
      "input": 30173,
      "thinking": 4141,
      "output": 527
    }
  },
  {
    "entry_id": 236,
    "retraction_id": "1104.1920v2",
    "paper_id": "1104.1920v1",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation 42, 50, 51",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The assumed form of Eve's general collective Gaussian attack is too restrictive.",
        "Location": "Section III, Eq. (21), Page 10",
        "Explanation": "The paper claims to derive bounds against 'all possible collective Gaussian attacks' by assuming Eve's symplectic transformation matrix S has a specific block-diagonal form (Eq. 21). However, a general Gaussian attack involves a symplectic transformation on the combined system of the channel mode and Eve's ancillae, which does not necessarily result in this restricted form for the effective transformation on the signal mode plus ancillae. This means the derived bounds are only valid for a subset of collective Gaussian attacks, not all of them, invalidating the claim of generality and tightness against all such attacks."
      },
      {
        "Problem": "Contradictory claims regarding the dependence of Eve's accessible information on Alice-Bob correlation.",
        "Location": "Page 15 (RR scheme) and Page 23 (DR scheme)",
        "Explanation": "The paper claims that in the reverse reconciliation (RR) scheme, Eve's accessible information (Holevo bound) is independent of the correlation between Alice and Bob modes (Page 15). Conversely, in the direct reconciliation (DR) scheme, it claims Eve's information is strongly dependent on this correlation (Page 23). The derived formulas for the Holevo bound in both schemes (e.g., dependence on V and a^2) clearly show a dependence on parameters characterizing the initial Alice-Bob state (correlation) in both RR and DR cases. This contradiction indicates a fundamental error in the interpretation or derivation of the results."
      },
      {
        "Problem": "Inconsistent claims about the tightness of the derived bounds.",
        "Location": "Abstract, Page 9, Page 15, Page 19",
        "Explanation": "The paper first states that bounds derived based on Eve purifying the Alice-Bob state (Section II) are not tight for mixed entanglement (Page 9). It then claims the new bounds derived in Section III are tight for all CV-QKD protocols involving two-mode entangled states (Abstract, Page 19). However, it also states that the new bounds are identical to those from Section II for the maximally entangled case (Page 15). If the new bounds are identical to the non-tight bounds from Section II in a specific case (maximal entanglement), and the Section II bounds are generally not tight for mixed entanglement, it is contradictory to claim the new bounds are tight for all two-mode entangled states (which include mixed states). Furthermore, the restricted attack model assumed (Problem 1) prevents the bounds from being tight against general collective attacks."
      }
    ],
    "token_usage": {
      "input": 6058,
      "thinking": 3343,
      "output": 589
    }
  },
  {
    "entry_id": 237,
    "retraction_id": "1406.6450v2",
    "paper_id": "1406.6450v1",
    "retraction_comment": "This paper has been withdrawn by the authors due to a gap in the inequality of (2.7)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect condition for the subnormality of the pair (T1, T2).",
        "Location": "Theorem 1.1(iii) and its proof in Section 2",
        "Explanation": "The proof claims that the pair (T1, T2) is subnormal if and only if 0 < epsilon <= 3/8. However, the calculation using Lemma 2.3(iii) in the proof leads to the condition 0 < epsilon <= 1/2. This discrepancy invalidates the paper's central claim that there exists a range of epsilon (specifically, 3/8 < epsilon <= 5/12) where T1+T2 is subnormal but the pair (T1, T2) is not."
      },
      {
        "Problem": "Incorrect condition for the subnormality of the restricted pair (T1, T2)|_N.",
        "Location": "Claim (*) in the proof of Theorem 1.1(ii) and its subsequent derivation",
        "Explanation": "The proof claims that the restriction (T1, T2)|_N is subnormal if and only if 0 < epsilon <= 5/12. A correct application of the subnormal backward extension criterion (Lemma 2.3 or its symmetric version) to this restricted operator shows that it is subnormal if and only if 0 < epsilon <= 1/2. This incorrect condition is used as a step in the argument for the subnormality of T1+T2."
      },
      {
        "Problem": "Incomplete proof for the subnormality of T1+T2.",
        "Location": "Proof of Theorem 1.1(ii)",
        "Explanation": "The proof attempts to show T1+T2 is subnormal by verifying Agler's criterion P_n >= 0 for n >= 1. An expression for P_n is derived, but the argument that P_n >= 0 for all n when 0 < epsilon <= 5/12 is not completed. The provided lower bound for P_n is insufficient to establish its non-negativity for all n, leaving the subnormality of T1+T2 unproven for the claimed range of epsilon."
      }
    ],
    "token_usage": {
      "input": 18589,
      "thinking": 30918,
      "output": 500
    }
  },
  {
    "entry_id": 238,
    "retraction_id": "1510.05979v4",
    "paper_id": "1510.05979v3",
    "retraction_comment": "This paper has been withdrawn by the author due to a crucial error in equation (39)",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The action functional used in Section 3 is incorrect.",
        "Location": "Section 3, equation (AC)",
        "Explanation": "The action functional $\\mathcal{A}^\\sigma(y)$ defined in equation (AC) uses a potential term $\\int_0^1 \\frac{ds}{\\|y(s)-y(0)\\|^\\sigma}$. This term represents the interaction of the mass distribution with a single fixed point $y(0)$. The correct potential energy for a self-interacting continuous mass distribution, corresponding to the Euler-Lagrange equation (EO2) derived in Section 2, should be a double integral representing the interaction between all pairs of mass elements: $-\\frac{1}{2}\\int_0^1\\int_0^1 \\frac{1}{\\|y(s)-y(s')\\|^\\sigma} ds' ds$. The claim that the double integral equals the single integral is false."
      },
      {
        "Problem": "The correct action functional is not coercive.",
        "Location": "Implied by Section 2.1 and Section 3",
        "Explanation": "The correct action functional for the continuous system (EO2) is $\\mathcal{A}_{correct}^\\sigma(y) = \\int_0^1\\frac{v^2}{2}\\|\\dot{y}(s)\\|^2 ds - \\frac{1}{2}\\int_0^1\\int_0^1 \\frac{1}{\\|y(s)-y(s')\\|^\\sigma} ds' ds$. For $0 < \\sigma < 1$, the potential term is negative and becomes unbounded below as the curve $y(s)$ shrinks towards a point (i.e., as $\\|y\\|_{H^1} \\to 0$). This means the functional is not coercive on $\\Lambda$, violating a key requirement for the direct method of calculus of variations used in the paper."
      },
      {
        "Problem": "The potential term of the correct action functional is not weakly lower semi-continuous.",
        "Location": "Implied by Section 2.1 and Section 3",
        "Explanation": "The potential energy term in the correct action functional, $U(y) = \\frac{1}{2}\\int_0^1\\int_0^1 \\frac{1}{\\|y(s)-y(s')\\|^\\sigma} ds' ds$, is a convex functional and thus weakly lower semi-continuous. The potential term in the action is $-U(y)$, which is therefore weakly upper semi-continuous. The action functional is the sum of the kinetic energy (w.l.s.c.) and the negative potential energy (w.u.s.c.), which is not generally weakly lower semi-continuous. This violates another key requirement for the direct method used in the paper."
      },
      {
        "Problem": "The existence proof is for the incorrect functional.",
        "Location": "Section 3.1, Theorem 3.1",
        "Explanation": "The proof in Theorem 3.1 demonstrates the existence of a minimizer for the functional $\\mathcal{A}^\\sigma$ defined in (AC). Since (AC) is not the correct action functional for the system (EO2), the existence of its minimizer does not imply the existence of a solution to (EO2). The proof's steps (coercivity and w.l.s.c.) are shown for (AC), but are not valid for the correct functional (see Problems 2 and 3)."
      },
      {
        "Problem": "Conclusions regarding existence and properties of continuous choreographies are unfounded.",
        "Location": "Section 4, Conclusions",
        "Explanation": "The conclusions state that the variational method establishes the existence of a continuous choreography (a minimizer of $\\mathcal{A}^\\sigma$) in addition to the circle. This is based on the existence proof (Theorem 3.1) and analysis (Propositions 3.2, 3.3) which were performed using the incorrect action functional (AC). Therefore, the paper does not provide a valid variational proof for the existence of continuous choreographies (solutions of EO2) or their properties, other than showing the circle is a solution."
      }
    ],
    "token_usage": {
      "input": 14826,
      "thinking": 11564,
      "output": 933
    }
  },
  {
    "entry_id": 239,
    "retraction_id": "1202.0569v2",
    "paper_id": "1202.0569v1",
    "retraction_comment": "Due to a flaw in Lemma 9, the paper has been withdrawn",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound claim regarding edges in a cut for bridge elimination.",
        "Location": "Lemma 6, Proof",
        "Explanation": "The proof claims that for any bridge $b$ in $G-A$, there must be at least two edges $e', e'' \\in A$ connecting the two components formed by removing $b$ in $G-A$. While bridge-freeness of $G$ implies there are at least two edges in the corresponding cut in $G$ (one being $b$, the others in $A$), there is no guarantee that there are two or more edges from $A$ in this cut. There could be exactly one edge from $A$. The subsequent construction of $A'$ by removing one edge from $A$ for each bridge in $G-A$ is based on this unproven claim and does not guarantee that $G-A'$ is bridge-free."
      },
      {
        "Problem": "Flawed algorithm for finding a bridge-free augmenting set.",
        "Location": "Lemma 7, Proof",
        "Explanation": "The algorithm iteratively modifies the augmenting set $A_i$. Step 2 relies on Lemma 6 to find a proper subset $A'_i \\subset A_i$ such that $G_i - A'_i$ is bridge-free. Since Lemma 6 appears unsound, this step is not guaranteed to succeed as described. Furthermore, the definition of the final set $A' = (A_0 \\cup \\dots \\cup A_i) \\cap E(\\mathcal{C})$ and the claim that it is a $\\mathcal{C}$-augmenting set in $G$ resulting in a bridge-free graph $G-A'$ is not rigorously justified by the algorithm's steps and the properties of the intermediate sets $A_j$ and graphs $G_j$."
      },
      {
        "Problem": "Underspecified and complex argument for existence of specific alternating path edges.",
        "Location": "Lemma 4, Proof, Step 5",
        "Explanation": "The proof of Lemma 4 relies on an algorithm involving alternating paths and twist elimination in the auxiliary graph $K$. Step 5 claims that if the algorithm does not terminate earlier, there must exist an unmatched edge in the current alternating path with a specific type, or a twist is forced. The analysis of vertex and edge types, their connections, and the conditions under which twists occur or specific edge types must appear is highly technical and presented without sufficient detail or formal proof, making the argument difficult to verify and a potential source of error. The definitions of classes and vertex types also appear potentially confusing or inconsistent."
      }
    ],
    "token_usage": {
      "input": 14519,
      "thinking": 11979,
      "output": 580
    }
  },
  {
    "entry_id": 240,
    "retraction_id": "2111.02352v2",
    "paper_id": "2111.02352v1",
    "retraction_comment": "The previous to the last sentence of Section 4, namely that \"This means that $\\hat{Q}$ and, by Lemma 6, $\\hat{Q}$ too, is less than 1.\" is wrong",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed connection between VC and VV probabilities",
        "Location": "Section 4, Lemma 4.3",
        "Explanation": "The proof relies on bounding the probability of the Moser-type algorithm (VC) running for a long time by the probability of the validation algorithm (VV) succeeding on a corresponding witness forest. Lemma 4.3 claims that the probability of a witness forest occurring in VC is bounded by the probability of VV succeeding on that forest. However, VC's coloring process introduces dependencies between vertex colors through recoloring steps, while VV's analysis (based on Lemma 4.4) assumes random colorings at each step. The probability of a specific sequence of events occurring in VC's dependent process is not correctly bounded by the probability of those events occurring in VV's sequence of random colorings. This invalidates the use of the combinatorial sum of forest weights to bound the running time probability of VC."
      },
      {
        "Problem": "Incorrect claim about coloring randomness in VV",
        "Location": "Section 4, Lemma 4.4",
        "Explanation": "Lemma 4.4 states that at the end of each phase of the validation algorithm (VV), each vertex of the graph is colored as if it was independently assigned a color uniformly at random from the palette. This is incorrect. In each phase, only the vertices within the 'scope' of the current badly colored set are recolored randomly. The colors of vertices outside this scope remain unchanged from the previous step. Therefore, the coloring at the end of a phase is not a fresh random coloring of the entire graph. This invalidates the subsequent argument (Fact 2) that the final coloring produced by VC (when it halts) is $\\alpha$-specially proper with positive probability, as that argument relies on the final coloring being effectively random."
      },
      {
        "Problem": "Failure to address all bichromatic 4-cycles",
        "Location": "Section 4, definition of set $\\mathcal{B}$ and Algorithm VC",
        "Explanation": "The set $\\mathcal{B}$ of events that trigger recoloring in Algorithm VC includes 4-cycles only if their opposing vertices do *not* form $\\alpha$-special pairs. The algorithm terminates when there are no pivot vertices of badly colored sets in $\\mathcal{B}$. This implies that upon termination, there are no badly colored 4-cycles *without* special pairs and no badly colored 5-paths (which prevents bichromatic cycles of length $\\geq 6$). However, the algorithm does not address 4-cycles where the opposing vertices *do* form special pairs. While the final coloring produced by Algorithm MA is $\\alpha$-specially proper, which prevents adjacent vertices and vertices forming $\\alpha$-special pairs from having the same color, this is not sufficient to guarantee that all 4-cycles with special pairs are not bichromatic. For example, a 4-cycle $u, x, v, y$ where $v \\in S_\\alpha(u)$ could still be bichromatic if $c(u)=c(y)$ and $c(x)=c(v)$, as long as $c(u) \neq c(v)$ and $c(x) \neq c(y)$. The final coloring is not guaranteed to be acyclic."
      }
    ],
    "token_usage": {
      "input": 14237,
      "thinking": 5990,
      "output": 712
    }
  },
  {
    "entry_id": 241,
    "retraction_id": "2207.08480v2",
    "paper_id": "2207.08480v1",
    "retraction_comment": "Errors in the method to determine the S-transformation coefficients, because the characters for the surfaces are not simply the product of characters for cylinders. Errors in the linear spaces assigned to surfaces in string vertices this http URL concrete definition for open sector linear spaces also required",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Unsound definition of partition function on C0,0,tilde{3}",
        "Location": "Section 3.3, Eq. 30",
        "Explanation": "The partition function on the open sector side (P_mu1mu2^mu3) is defined as a product of characters associated with different regions (a and b) based on a specific time evolution. A partition function for a given surface is a single value (or function of moduli) obtained by tracing over the Hilbert space or path integral, not a product of characters from arbitrary subdivisions. This invalidates the proposed modular invariance constraint on the S-transformation coefficients."
      },
      {
        "Problem": "Unjustified assumption on open sector coefficients equaling fusion coefficients",
        "Location": "Section 1 (Introduction), Section 3.1.2, Eq. 16",
        "Explanation": "The definition of S-transformations relies fundamentally on the assumption that open sector representation coefficients (n) are identical to closed sector fusion coefficients (N). This property is known for specific classes like diagonal RCFTs but is not generally proven or expected for arbitrary CFTs, including those with continuous spectra, severely limiting the claimed applicability of the definition."
      },
      {
        "Problem": "Unjustified assumption of boundary condition completeness",
        "Location": "Section 1 (Introduction), Section 3.2",
        "Explanation": "The definition requires boundary conditions to be complete, meaning there is a bijection between the set of admissible boundary conditions and the set of bulk representations. This is crucial for dimension matching between closed and open sector spaces and for the unconventional sewing. While true for RCFTs (Cardy states), it is highly unlikely to hold for general CFTs with continuous bulk spectra, breaking the foundation of the proposed linear map and sewing procedure."
      },
      {
        "Problem": "Mathematically inconsistent definition of open sector linear space",
        "Location": "Section 3.1.2, Eq. 15",
        "Explanation": "The open sector linear space V_mu1mu2^mu3 is defined as being equal to one space (V_mu3mu1^omega(P2)) when the equal-time curve is in region 'a' and another space (V_mu3mu2^omega(P1)) when it's in region 'b'. A linear space is a static mathematical object; defining it as switching between different spaces based on time evolution or region is mathematically inconsistent, even if their dimensions are claimed to be equal."
      }
    ],
    "token_usage": {
      "input": 50119,
      "thinking": 3095,
      "output": 559
    }
  },
  {
    "entry_id": 242,
    "retraction_id": "2302.04323v3",
    "paper_id": "2302.04323v2",
    "retraction_comment": "The first statement on page 9 is not necessarily true. Roughly speaking, the problem is that the indices \"i_s\" and \"r\" are competing with each other and therefore what I believed to be immediate, as happens naturally in the case of a single index, and as can be seen in the proof of Theorem 6.7 of the FHHMZ reference, is in fact not immediate in the situation where double indices are involved",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "The sequence $(\\vartheta_k)$ is not shown to be weakly null in $[X]$.",
        "Location": "Proof of Main Theorem, Section 3, definition of $(\\vartheta_k)$",
        "Explanation": "The proof relies on the spreading model of $(\\vartheta_k)$ being suppression 1-unconditional. This property is known for spreading models of weakly null sequences. However, the sequence $(\\vartheta_k)$ as defined, $\\vartheta_k = [\\frac{x_{n_{i+1}} + x_{n_{i +2k}}}{2}]_i$, is likely not weakly null in $[X]$. For example, if $X=\\ell_1$ and $x_n=e_n$, the sequence $(\\vartheta_k)$ is not weakly null in $[\\ell_1]$. Without weak nullness, the unconditionality property of its spreading model is not guaranteed by standard results."
      },
      {
        "Problem": "The proof of suppression 1-unconditionality of the spreading model $(\\mathfrak{s}_k)$ is flawed.",
        "Location": "Proof of Main Theorem, Section 3, paragraph starting \"In what follows we shall use that $(x_n)$ is weakly null...\"",
        "Explanation": "The argument attempts to prove suppression 1-unconditionality by contradiction, using approximations of spreading model norms and a weak nullness argument involving a functional $f$. The choice of indices $\\tilde{s}_j$ for the weak nullness property depends on the functional $f$, which in turn depends on the specific vector being normed (via the Hahn-Banach theorem). This violates the requirement that the sequence of indices used to approximate the spreading model norm must be independent of the vector, rendering the argument invalid."
      }
    ],
    "token_usage": {
      "input": 22298,
      "thinking": 25528,
      "output": 399
    }
  },
  {
    "entry_id": 243,
    "retraction_id": "1911.03748v2",
    "paper_id": "1911.03748v1",
    "retraction_comment": "Unfortunately, our proof contains a serious flaw. Specifically, Lemma 5.3 does not prove the assertion it claims to prove and this collapses the entire argument. We thank [REDACTED-NAME] for pointing out the flaw, and apologize to the community for posting an eventually incorrect proof",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Flawed martingale argument in Lemma 5.2",
        "Location": "Lemma 5.2 proof",
        "Explanation": "The proof relies on a martingale argument concerning the decay of Fourier weight beyond level k, which holds for random restrictions. However, the algorithm described makes deterministic choices of variables based on the current function and uses the actual input values, invalidating the expectation calculation required for the martingale property to hold."
      },
      {
        "Problem": "Flawed existence proof in Lemma 5.3",
        "Location": "Lemma 5.3 proof",
        "Explanation": "The proof constructs a decision tree g_S approximating h_S. It then claims the existence of a *fixed* set of variables J and assignment x_J corresponding to a path in the tree such that the leaf value h_S(x_J, 0_{S \\setminus J}) is high. This conclusion does not follow from the properties of the decision tree; the tree only guarantees that the average leaf value (weighted by path probability) is high, not that any specific leaf value is close to the average minus epsilon."
      },
      {
        "Problem": "Flawed block sensitivity argument in Lemma 6.1",
        "Location": "Lemma 6.1 proof",
        "Explanation": "The proof attempts to relate the expected L1 block sensitivity across steps using an inequality involving |f_i(z_{J_i}, 0_{\\bar{J_i}})-\\be[f_i]|/2. This term is not the expected block influence, and the relationship between the expected block sensitivities of the restricted functions across steps is not correctly established for the deterministic algorithm used."
      }
    ],
    "token_usage": {
      "input": 25792,
      "thinking": 17320,
      "output": 379
    }
  },
  {
    "entry_id": 244,
    "retraction_id": "2212.12846v2",
    "paper_id": "2212.12846v1",
    "retraction_comment": "We found an error in Lemma 3.5.--which is used in the subsequent analysis to establish the rate of convergence. Since the error is not fixable, we would like to withdraw the article",
    "checker_model": "Gemini 2.5 Flash",
    "attempt_id": 0,
    "problems": [
      {
        "Problem": "Incorrect bound in Lemma 3.5 for the discrete spatial gradient.",
        "Location": "Lemma 3.5, inequality (3.10)",
        "Explanation": "The derivation of inequality (3.10) leads to $\\mathbb{E}[\\Delta x \\sum_j \\int_0^t |D_+u_j(r)|^2 dr] \\le \\frac{C}{\\eps} \\mathbb{E}[\\Delta x \\sum_j |u_j(0)|^2]$. Since $\\mathbb{E}[\\Delta x \\sum_j |u_j(0)|^2] = \\mathbb{E}[\\|u_{\\Delta x}(0)\\|_{L^2(\\R)}^2] \\le C\\|u_0\\|_{L^2}^2$ for compactly supported $u_0$, the correct bound should be $C/\\eps$, not $C\\Delta x/\\eps$ as stated. This error propagates to subsequent bounds in Section 4."
      },
      {
        "Problem": "Missing a priori estimates for higher moments of the discrete spatial gradient.",
        "Location": "Section 3 (A priori estimations) and Section 4 (Rate of Convergence)",
        "Explanation": "The bounds for several terms in the error analysis (e.g., $\\Hat{\\mathcal{J}}_{4,2}, \\Hat{\\mathcal{J}}_{4,3}, \\Hat{\\mathcal{J}}_{4,4}, \\Hat{\\mathcal{J}}_{4,5}$) involve expectations of sums of powers of $|D_+u_j(s)|$ higher than 2 (e.g., $|D_+u_j|^3$). Lemma 3.5 only provides a bound for the $L^2$ norm of the spatial gradient ($\\mathbb{E}[\\Delta x \\sum_j \\int |D_+u_j|^2]$). Without bounds on higher moments of the discrete spatial gradient, the estimates for these terms in Section 4 are not justified."
      },
      {
        "Problem": "Inconsistent derivation of bounds for specific terms in Section 4.",
        "Location": "Section 4, specifically the bounds for terms like $\\Hat{\\mathcal{J}}_{4,2}, \\Hat{\\mathcal{J}}_{4,3}, \\Hat{\\mathcal{J}}_{4,4}, \\Hat{\\mathcal{J}}_{4,5}$",
        "Explanation": "The derivation steps and the final bounds presented for several terms involving the discrete spatial gradient appear inconsistent with the available estimates. For instance, the bound for $\\Hat{\\mathcal{J}}_{4,2}$ seems to require bounding $\\mathbb{E}[\\Delta y \\sum_j \\int |D_+u_j|^3]$ or similar terms, but the stated bound $C\\frac{\\Delta y}{\\xi\\eps}$ does not match the expected result based on the derivation steps and the available $L^2$ gradient bound from Lemma 3.5 (even if corrected). This suggests errors in the bounding process that invalidate the final error estimate."
      }
    ],
    "token_usage": {
      "input": 68719,
      "thinking": 16107,
      "output": 684
    }
  }
]